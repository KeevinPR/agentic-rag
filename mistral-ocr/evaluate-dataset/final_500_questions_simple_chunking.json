{
  "metadata": {
    "generation_date": "2025-06-27 11:55:39",
    "target_questions": 500,
    "total_questions": 500,
    "generation_method": "chunk_based",
    "statistics": {
      "successful": 500,
      "failed_generation": 0,
      "duplicate_skipped": 6,
      "total_attempts": 506
    }
  },
  "questions": [
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of sharing the 'required error' in the precision analysis method for parallel IIR filters contribute to performance improvements, specifically when using algorithms like PAPBIL and PAUMDA?",
      "topics": [
        "convergence"
      ],
      "answer": "The precision analysis method shares the 'required error' ($E_{\\text {req }}$) across blocks in parallel IIR filters using an Estimation of Distribution Algorithm (EDA). This approach introduces heterogeneity in error tolerance between blocks. The application of the EDA, specifically comparing the PAPBIL and PAUMDA algorithms, along with appropriate precision analysis methods, can lead to cost improvements of up to 37% by distributing the required error and using all distributed errors. This method outperforms existing approaches regardless of the forward precision analysis approach adopted.",
      "chunk_id": 2164,
      "paper_id": "Precision Analysis for an Optimal Parallel IIR Filter s Implementation",
      "paper_title": "Precision Analysis for an Optimal Parallel IIR Filter's Implementation",
      "paper_year": "2022",
      "chunk_content": "The precision analysis of the BWO method allows representing the fractional part of the filter coefficients with the minimum number of bits while respecting the constraints of precision and stability of the filter. Table 4 displays the filter coefficients and their  \n[IMAGE15]  \nFig. 14 Poles \\& Zeros positions before and after the application of our approach (cutoff frequency 3 Hz )\n[IMAGE16]  \nFig. 15 Output signal filter before and after the application of our approach (Cut-off frequency 6 Hz )\nbit-widths calculated through our approach as well as the quantified coefficients. The results are obtained with the following inputs:  \n- Required error : $E_{\\text {req }}=0.01$;\n- Cut-off frequency: 3 Hz ;\n- Input signal: Noisy phase detector output (with $\\mathrm{SNR}=1 \\mathrm{~dB}$ ), considering the input frequency at 8 KHz .  \n[IMAGE17]  \nFig. 16 Poles \\& Zeros positions before and after the application of our approach (cutoff frequency 6 Hz )\n[IMAGE18]  \nFig. 17 Output signal filter before and after the application of our approach (Cut-off frequency 12 Hz )  \n[IMAGE19]  \nFig. 18 Poles \\& Zeros positions before and after the application of our approach (cutoff frequency 12 Hz )  \nTable 4 Quantified coefficients after the application of our approach\nThis paper proposes a new precision analysis method designed for parallel IIR filter. In contrast with the existing literature, we suggest sharing the required error using a metaheuristic known as the Estimation of Distribution Algorithm. We have shown that when the required error is distributed through the blocks, our method outperforms existing approaches thanks to its flexibility that uses all required and distributed errors  \nand to the introduction of an heterogeneity between blocks in terms of the error's tolerance capacity. Actually, this newly adds to the heuristic optimization efforts dedicated in particular to the architectural aspect. Indeed, our results show that the application of the EDA approach, with appropriate precision analysis methods, brings improvements reaching the cost of up to $37 \\%$. Furthermore, our proposal outperforms existing method regardless of the adopted forward precision analysis approach. Within the EDA-based solution, we made a comparison between the convergence speed of the PAPBIL algorithm compared to the PAUMDA one. To demonstrate the efficiency of our method in a specific case study, we have established a simulation analysis of a practical filter used in DPLL applications [43]. This analysis consists of studying the filter output upstream and downstream to highlight that our method doesn't affect the filter characteristics and stability.  \nFunding The authors did not receive support from any organization for the submitted work.\nData Availability The data that support the findings of this study are the benchmarks provided in [36] which have been generated by the authors.\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:55:41",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using Probabilistic Principal Component Analysis (PPCA) with an isotropic Gaussian noise model, how should practitioners calculate the posterior distribution of the latent variables z given the observed data x, and what is the significance of the resulting covariance matrix?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms",
        "Probabilistic Principal Component Analysis",
        "PPCA"
      ],
      "answer": "To calculate the posterior distribution p(z|x) in PPCA with isotropic Gaussian noise, practitioners should use the formula: p(z|x) = (2π)^(-q/2) |σ^(-2) C|^(1/2) * exp[-1/2 {z - C^(-1) W^T (x - μ)}^T (σ^(-2) C) {z - C^(-1) W^T (x - μ)}], where C = W^T W + σ^2 I. Here, W represents the weight matrix, σ^2 is the variance of the isotropic Gaussian noise, μ is the mean of the observed data x, and I is the identity matrix. The covariance matrix within this posterior distribution, specifically (σ^(-2) C)^(-1), provides the precision of the predictions for the latent variables z given x. The elements of this covariance matrix indicate the uncertainty associated with estimating z based on the observed data x.",
      "chunk_id": 6123,
      "paper_id": "Continuous Estimation of Distribution Algorithms with Probabilistic Principal",
      "paper_title": "Continuous estimation of distribution algorithms with probabilistic principal component analysis",
      "paper_year": "2001",
      "chunk_content": "For the isotropic Gaussian noise model $\\epsilon \\sim N\\left(0, \\sigma^{2} \\mathbf{I}\\right)$, equation (3) implies that $\\mathbf{z}$ conditional probability distribution over $\\mathbf{x}$-space is given by $\\mathbf{x} \\mid \\mathbf{z} \\sim N\\left(\\mathbf{W} \\mathbf{z}+\\boldsymbol{\\mu}, \\sigma^{2} \\mathbf{I}\\right)$, i.e,  \n$$\np(\\mathbf{x} \\mid \\mathbf{z})=\\left(2 \\pi \\sigma^{2}\\right)^{-d / 2} \\exp \\left\\{-\\frac{\\|\\mathbf{x}-\\mathbf{W} \\mathbf{z}-\\boldsymbol{\\mu}\\|^{2}}{2 \\sigma^{2}}\\right\\}\n$$  \nWith the marginal distribution of the latent variables $\\mathbf{z} \\sim$ $N(0, \\mathbf{I})$ defined by  \n$$\np(\\mathbf{z})=(2 \\pi)^{-q / 2} \\exp \\left\\{-\\frac{1}{2} \\mathbf{z}^{\\mathrm{T}} \\mathbf{z}\\right\\}\n$$  \nthe marginal distribution for the observed data $\\mathbf{x}$ is obtained by integrating out the latent variables as follows:  \n$$\n\\begin{aligned}\n& p(\\mathbf{x})=\\int p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) d \\mathbf{z} \\\\\n& =(2 \\pi)^{-d / 2}|\\boldsymbol{\\Sigma}|^{-1 / 2} \\exp \\left\\{-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right\\}\n\\end{aligned}\n$$  \nwhere the covariance is specified by $\\boldsymbol{\\Sigma}=\\mathbf{W} \\mathbf{W}^{\\mathrm{T}}+\\sigma^{2} \\mathbf{I}$ and this implies $\\mathbf{x} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$.  \nThe posterior distribution of $\\mathbf{z}$ is easily obtained by standard methods and it also turns out to be normal. That is, $\\mathbf{z} \\mid \\mathbf{x} \\sim N\\left(\\mathbf{W}^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}),\\left(\\sigma^{-2} \\mathbf{W}^{\\mathrm{T}} \\mathbf{W}+\\mathbf{I}\\right)^{-1}\\right)$. Thus the posterior distribution of the latent variables $\\mathbf{z}$ given the observed $\\mathbf{x}$ can be calculated:  \n$$\n\\begin{aligned}\np(\\mathbf{z} \\mid \\mathbf{x})= & (2 \\pi)^{-q / 2}\\left|\\sigma^{-2} \\mathbf{C}\\right|^{1 / 2} \\\\\n& \\times \\exp \\left[-\\frac{1}{2}\\left\\{\\mathbf{z}-\\mathbf{C}^{-1} \\mathbf{W}^{\\mathrm{T}}(\\mathbf{x}-\\boldsymbol{\\mu})\\right\\}^{\\mathrm{T}}\\left(\\sigma^{-2} \\mathbf{C}\\right)\\right. \\\\\n& \\left.\\left\\{\\mathbf{z}-\\mathbf{C}^{-1} \\mathbf{W}^{\\mathrm{T}}(\\mathbf{x}-\\boldsymbol{\\mu})\\right\\}\\right]\n\\end{aligned}\n$$  \nwhere $\\mathbf{C}=\\mathbf{W}^{\\mathrm{T}} \\mathbf{W}+\\sigma^{2} \\mathbf{I}$. The mean of this distribution might then be used to predict $\\mathbf{z}$ for a given $\\mathbf{x}$ and the precision of the predictions would be given by the elements of the covariance matrix.  \nAlthough there is no closed form analytic solution for $\\mathbf{W}$ and $\\sigma$, the parameters for this model can be obtained by iterative procedure, e.g. by using expectation-maximization (EM) algorithms which will be explained in the next section.\nIn the continuous optimization problems, candidate solutions are usually represented as real vectors. PPCA can explain the relationship between each component of promising solution vectors with the latent variables. The procedures used in PPCA to obtain the values of the variables and to generate new instances with those values are described in this section.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:55:44",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Estimation of Distribution Algorithm (EDA) hybridized with variable neighborhood search (VNS), what specific mathematical properties or theoretical guarantees are leveraged in its application to the total flowtime minimization problem, considering that no heuristic is optimal for total flowtime minimization?",
      "topics": [
        "genetic"
      ],
      "answer": "The provided text does not explicitly detail the mathematical properties or theoretical guarantees of the Estimation of Distribution Algorithm (EDA) hybridized with variable neighborhood search (VNS). It only mentions that this hybrid algorithm, along with two genetic local search algorithms (hGLS and tsGLS), improved almost all the best-known solutions in the existing literature for the total flowtime minimization problem. The text does not provide specific convergence conditions, complexity analysis, or performance bounds for the EDA or its components. The total flowtime (TFT) is minimized, where \\$\\operatorname{TFT}\\left(\\pi^{\\*}\\right) \\leqslant \\operatorname{TFT}(\\pi)$ for each permutation $\\pi$ belonging to $\\Pi$, but no theoretical properties of the EDA are given.",
      "chunk_id": 11900,
      "paper_id": "A discrete artificial bee colony algorithm for the total flowtime minimization in permutation flow shops",
      "paper_title": "A discrete artificial bee colony algorithm for the total flowtime minimization in permutation flow shops",
      "paper_year": "2011",
      "chunk_content": "$\\operatorname{TFT}\\left(\\pi^{*}\\right) \\leqslant \\operatorname{TFT}(\\pi)$ for each permutation $\\pi$ belonging to $\\Pi$. Under these specifications, the completion time for the $n$-job and $m$ machine problem is computed as follows:  \n$$\n\\begin{aligned}\n& C\\left(\\pi_{1}, 1\\right)=p_{\\pi_{1}, 1} \\\\\n& C\\left(\\pi_{j}, 1\\right)=C\\left(\\pi_{j-1}, 1\\right)+p_{\\pi_{j}, 1} \\quad j=2, \\ldots, n \\\\\n& C\\left(\\pi_{1}, k\\right)=C\\left(\\pi_{1}, k-1\\right)+p_{\\mu_{1}, k} \\quad k=2, \\ldots, m \\\\\n& C\\left(\\pi_{j}, k\\right)=\\max \\left\\{C\\left(\\pi_{j-1}, k\\right), C\\left(\\pi_{j}, k-1\\right)+p_{\\pi_{j}, k}\\right\\} \\quad j=2, \\ldots, n ; \\quad k=2, \\ldots, m\n\\end{aligned}\n$$  \nMany different algorithms have been proposed over time in an attempt to find the exact solution to minimizing the total flowtime (TFT). Several variants of branch and bound algorithms were developed [4,5,11,41]; Ignall and Scharge [11] were the first to apply the branch and bound scheme based on two lower bounds in the two-machine flow shop problem. Then Bansal [4] extended their idea to the $m$-machine case. Recent publications [5,41] have detailed the development of lower bounding methods either based on Lagrangian relaxation or by introducing slack variables. These exact methods have been successfully implemented in a limited number of small instances due to lengthy execution times. For large instances in the $n$ job and FORMULA_33 - machine total flowtime problem, some efficient heuristics have been developed in [2,7,8,10,23,26,31,45]. The NEH constructive method, proposed by Nawaz et al. [28], was claimed to be the best for makespan minimization in flow shops, but not effective for total flowtime minimization. Therefore, to minimize total flowtime, the heuristics in both Woo and Yim [45] and Framinan and Leisten [7] were founded on different insertion schemes from NEH. Furthermore, a composite heuristic proposed by Allahverdi and Aldowaisan [2] adopted the insertion with pair-wise exchange from Framinan and Leisten [7] to improve their solutions. So far, no heuristic is optimal for total flowtime minimization. In comparison to heuristic methods, metaheuristic methods always obtain better results, as they compose many different kinds of algorithmic components [9,12,21,27,32,42,43,46,48]. Very recently, an estimation of distribution algorithm (EDA) hybridized with variable neighborhood search (VNS) has been introduced in [13]. In addition to EDA, two genetic local search algorithms have been proposed in [24,25]. The first one employs a local search called insertion search with cut and repair, denoted by hGLS, and the second one is the genetic algorithm hybridized with a tabu search, denoted by tsGLS. These three algorithms improved almost all the best known solutions in the existing literature.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:55:46",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantage is gained by generating multiple naive Bayes classifiers within confidence intervals, as opposed to using a single point estimate, according to the description?",
      "topics": [
        "search"
      ],
      "answer": "Generating multiple naive Bayes classifiers, where each classifier's parameters ($p^{*}$) are selected from within their corresponding confidence intervals, allows for the creation of a search space composed of valid tuples. A valid tuple satisfies the conditions $\\sum_{i=1}^{r_{0}} p_{i}^{*}=1$ and $\\forall k \\forall i \\sum_{r=1}^{r_{k}} p_{k, r}^{* i}=1$, ensuring that each classifier represents a valid probability distribution. This approach enables a heuristic optimization algorithm to explore a range of plausible classifiers, evaluated by a fitness function based on the percentage of successful predictions.",
      "chunk_id": 13209,
      "paper_id": "Learning semi naive Bayes structures by estimation of distribution algorithms",
      "paper_title": "Learning semi naive Bayes structures by estimation of distribution algorithms",
      "paper_year": "2003",
      "chunk_content": "Given the dataset, the first step is to calculate the confidence intervals for each conditional probability and for each class probability. For the calculation of the intervals first the point estimations of these parameters must be computed.\nThis way, each conditional probability $p_{k, r}^{i}=P\\left(X_{k}=x_{k}^{r} \\mid C=c_{i}\\right)$, that has to be estimated from the dataset must be computed with the next confidence interval.  \nFor $k=1, \\ldots, n ; i=1, \\ldots, r_{0} ; r=1, \\ldots, r_{k}$ the next formula:  \n$$\n\\left(\\hat{p}_{k, r}^{i}-z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{k, r}^{i}\\left(1-\\hat{p}_{k, r}^{i}\\right)}{N_{i}}} ; \\hat{p}_{k, r}^{i}+z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{k, r}^{i}\\left(1-\\hat{p}_{k, r}^{i}\\right)}{N_{i}}}\\right)\n$$  \ndenotes the interval estimation for the conditional probabilities $p_{k, r}^{i}$, where, $r_{k}$ denotes the possible values of variable $X_{k}$ $r_{0}$ represents the possible values of the class\n$\\hat{p}_{k, r}^{i}$ denotes the point estimation of the conditional probability $P\\left(X_{k}=x_{k}^{r} \\mid C=c_{i}\\right)$ $z_{\\alpha}$ denotes the $\\left(1-\\frac{\\alpha}{2}\\right)$ percentil in the $\\mathcal{N}(0,1)$ distribution\n$N_{i}$ is the number of cases in dataset where $C=c_{i}$\nAlso, in a similar way, the probabilities for the class values $p_{i}=P\\left(C=c_{i}\\right)$, are estimated with the next confidence interval,  \n$$\n\\left(\\hat{p}_{i}-z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{i}\\left(1-\\hat{p}_{i}\\right)}{N}} ; \\hat{p}_{i}+z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{i}\\left(1-\\hat{p}_{i}\\right)}{N}}\\right)\n$$  \nwhere, $\\hat{p}_{i}^{i}$ is the point estimation of the probability $P\\left(C=c_{i}\\right)$\n$z_{\\alpha}$ is the $\\left(1-\\frac{\\alpha}{2}\\right)$ percentil in the $\\mathcal{N}(0,1)$ distribution\n$N$ is the number of cases in dataset\nOnce the confidence intervals are estimated from the dataset, it is possible to generate as many naive Bayes classifiers as needed. The parameters of these naive Bayes classifiers must only be taken inside theirs corresponding confidence intervals.\nIn this way, each naive Bayes classifier is going to be represented with the next tupla of dimension $r_{0}\\left(1+\\sum_{i=1}^{n} r_{i}\\right)$  \n$$\n\\left(p_{1}^{*}, \\ldots, p_{r_{0}}^{*}, p_{1,1}^{* 1}, \\ldots, p_{1,1}^{* r_{0}}, \\ldots, p_{1, r_{1}}^{* r_{0}}, \\ldots, p_{n, r_{n}}^{* r_{0}}\\right)\n$$  \nwhere each component in the tupla $p^{*}$ represents the selected value inside its corresponding confidence interval.  \nThus, the search space for the heuristic optimization algorithm is composed of all the valid tuplas. A tupla is valid when it represents a valid naive Bayes classifier. Formally,  \n$$\n\\sum_{i=1}^{r_{0}} p_{i}^{*}=1 ; \\forall k \\forall i \\sum_{r=1}^{r_{k}} p_{k, r}^{* i}=1\n$$  \nFinally, each generated individual must be evaluated with a fitness function. This fitness function is based on the percentage of successful predictions on each dataset, which means that we are carrying out one wrapper approach.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:55:48",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the U-EDA\n                  2, O-EDA\n                  2, and M-EDA\n                  2 algorithms, which incorporate components of EMSM into EDA\n                  2, what specific modifications to the EDA\n                  2 algorithm's code are required to integrate the simple uniform method, the orthogonal method, and the mirrored sampling, respectively?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Implementation",
        "Sampling Methods"
      ],
      "answer": "To implement U-EDA\n                  2, the EDA\n                  2 code needs to be modified to incorporate the simple uniform method. For O-EDA\n                  2, the orthogonal method must be integrated into the EDA\n                  2's sampling strategy. Similarly, M-EDA\n                  2 requires the mirrored sampling technique to be added to the EDA\n                  2's population update mechanism. Each modification directly replaces or augments the sampling or update steps within the original EDA\n                  2 algorithm.",
      "chunk_id": 1528,
      "paper_id": "An efficient mixture sampling model for gaussian estimation of distribution algorithm",
      "paper_title": "An efficient mixture sampling model for gaussian estimation of distribution algorithm",
      "paper_year": "2022",
      "chunk_content": "All the above investigations verify that EMSM is effective, which can accomplish a good tradeoff between the diversity and the convergence, and thus obtain better solutions and faster convergence speed in EMSM-EDA. Moreover, the simple structure of EMSM is easily applied to various GEDA variants.  \nTable 3\nResults obtained by the Wilcoxon's test on CEC2013 Benchmark functions with 30D, 50D, and 100D.\nTable 4\nThe means and the standard deviations of FEVs obtained by the two algorithms over 25 independent runs on 30 CEC2014 benchmark functions with 30D, 50D, and 100D.\n\"+\", \" \", and \" $\\times$ \" indicate that the performance of $\\mathrm{EDA}^{2}$ algorithm is better than, worse than, and similar to that of EMSM-EDA, respectively.  \nTable 5\nResults obtained by the Wilcoxon's test on CEC2014 Benchmark functions with 30D, 50D, and 100D.\n[IMAGE8]  \nFig. 8. Evolution of FEVs derived from EMSM-EDA and EDA ${ }^{2}$ on 4 functions of CEC2013 benchmark functions with 100D.\nThe aim of this subsection is to identify the effectiveness of three components of EMSM: the simple uniform method, the orthogonal method, and the mirrored sampling. For this reason, the above three components are applied to EDA ${ }^{2}$, and these three algorithms are named as U-EDA ${ }^{2}$, O-EDA ${ }^{2}$, and M-EDA ${ }^{2}$, respectively. Moreover, EDA ${ }^{2}$ and EMSM-EDA are chosen as a basic comparison.  \nTable 6 summarizes the test results of EDA ${ }^{2}$, U-EDA ${ }^{2}$, O-EDA ${ }^{2}$, M-EDA ${ }^{2}$, and EMSM-EDA on IEEE CEC2014 test suite with 30D. From Table 6, EMSM-EDA and EDA ${ }^{2}$ have the best and the worst performance among the five comparison algorithms, respectively. Moreover, U-EDA ${ }^{2}$, O-EDA ${ }^{2}$, and M-EDA ${ }^{2}$ surpass EDA ${ }^{2}$ on 16,18 , and 16 test functions, which means the three components of EMSM play an important role in improving the performance of EDA ${ }^{2}$. In addition, U-EDA ${ }^{2}$, O-EDA ${ }^{2}$, and MEDA $^{2}$ is surpassed by EMSM-EDA on 18, 21, and 21 test functions, respectively. It means that the three components jointly improve the performance of EDA FORMULA_235.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:55:50",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific characteristic of the cost function in iterative algorithms, such as Neural Networks and Genetic Algorithms, presents a significant challenge when applied to the channel assignment problem?",
      "topics": [
        "performance"
      ],
      "answer": "The cost function, representing frequency separation constraints and channel demand, is prone to getting stuck in local minima. This characteristic makes the minimisation of the cost function quite a difficult problem for Neural Networks and Genetic Algorithms.",
      "chunk_id": 6214,
      "paper_id": "An estimation of distribution algorithm for the channel assignment problem",
      "paper_title": "An estimation of distribution algorithm for the channel assignment problem",
      "paper_year": "2006",
      "chunk_content": "$$\n\\left|f_{i k}-f_{j l}\\right| \\geq c_{i j} \\quad \\text { for } i, j=1, \\ldots, n\n$$  \n$k=1, \\ldots, d_{i}, l=1, \\ldots, d_{j}$ except for FORMULA_27.\nMany researchers have investigated the channel assignment problem using non-iterative algorithms (Gamst and Rave, 1982), (Sivaranjan, McElliece and Ketchum1981) and iterative algorithms (Funabiki and Takefyi, 1992), (Kunz, 1991). Neural Networks Algorithms and Genetic Algorithms are among the iterative algorithms in which an energy or cost function representing frequency separation constraints and channel demand is formulated and is then minimised. Unfortunately, the minimisation of the cost function is quite a difficult problem because of the danger of getting stuck in local minima constitutes a major problem. A much more powerful approach to cope with the problem of local minima has been considered in (Beckmann and Killat, 1999), (Fu, Pan and Bourgeois, 2003).  \nThis paper is organised as follows: section 2 gives a brief expose on Estimation of Distribution Algorithms and section 3 presents the new method that we propose in this paper. In section 4 we show the performance of our algorithms in solving some benchmark problems and finally we conclude in section 5 .",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:55:51",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the specific EDA discussed regarding the probability of joint events in the context of Estimation of Distribution Algorithms?",
      "topics": [
        "proof"
      ],
      "answer": "The key takeaway is that the probability of the joint event where multiple $Z_i$ variables equal 1 is less than or equal to the product of the individual probabilities of each $Z_i$ equaling 1, demonstrating a 1-negative correlation. A similar proof applies for 0-negative correlation by considering the complement of the bits and replacing the number of one-bits, $k$, with the number of zero-bits, $n-k$.",
      "chunk_id": 3737,
      "paper_id": "How majority-vote crossover and estimation-of-distribution algorithms cope with fitness valleys",
      "paper_title": "How majority-vote crossover and estimation-of-distribution algorithms cope with fitness valleys",
      "paper_year": "2023",
      "chunk_content": "$$\n\\operatorname{Pr}\\left(Z_{i}=1\\right)=\\left(\\operatorname{Pr}\\left(X_{i}=1\\right)\\right)^{3}+3 \\cdot\\left(\\operatorname{Pr}\\left(X_{i}=1\\right)\\right)^{2}\\left(1-\\operatorname{Pr}\\left(X_{i}=1\\right)\\right)\n$$  \nsince $Z_{i}=1$ if and only if at least two parents have a one-bit at position $i$. Also, $\\operatorname{Pr}\\left(X_{i}=1\\right)=k / n$ for all $i \\in\\{1, \\ldots, n\\}$ (without independence), and, conditioning on an outcome of $X_{1}, \\ldots, X_{i-1}$,  \n$$\n\\operatorname{Pr}\\left(X_{i}=1 \\mid X_{1}, \\ldots, X_{i-1}\\right)=\\frac{k-X_{1}-\\cdots-X_{i-1}}{n-i+1}\n$$  \nsince $k-X_{1}-\\cdots-X_{i-1}$ one-bits are uniformly distributed on the last $n-i+1$ bits. Hence, by the law of total probability, the unconditional probability of $X_{i}=1$ can be written as  \n$$\n\\operatorname{Pr}\\left(X_{i}=1\\right)=\\frac{k-\\mathrm{E}\\left(X_{1}\\right)-\\cdots-\\mathrm{E}\\left(X_{i-1}\\right)}{n-i+1}\n$$  \nIn the following, when considering the set $I=\\{1, \\ldots, \\ell\\}$, we will condition on certain distributions of the $X_{1}, \\ldots, X_{i-1}$, where $i \\leq \\ell$, to estimate the joint probabilities of the $Z_{i}$.  \nUsing the definition of conditional probability, we write  \n$$\n\\operatorname{Pr}\\left(\\cap_{i \\in\\{1, \\ldots, \\ell\\}}\\left\\{Z_{i}=1\\right\\}\\right)=\\prod_{i=1}^{\\ell} \\operatorname{Pr}\\left(Z_{i}=1 \\mid Z_{1}=1 \\cap \\cdots \\cap Z_{i-1}=1\\right)\n$$  \nNow, for any $j \\leq i-1, Z_{j}=1$ is equivalent to $X_{j}^{(1)}+X_{j}^{(2)}+X_{j}^{(3)} \\geq 2$, so $\\mathrm{E}\\left(X_{j} \\mid Z_{j}=1\\right)=\\mathrm{E}\\left(X_{j} \\mid X_{j}^{(1)}+X_{j}^{(2)}+X_{j}^{(3)} \\geq 2\\right) \\geq$ $\\mathrm{E}\\left(X_{j}\\right)$, where the inequality comes from the fact that the three $X_{j}^{(r)}$ are non-negative and that $X_{j}$ is represented by one of these.  \nHence, using (2), we also have  \n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left(X_{i}=1 \\mid Z_{j}=1\\right) & =\\frac{k-\\mathrm{E}\\left(X_{1} \\mid Z_{j}=1\\right)-\\cdots-\\mathrm{E}\\left(X_{i-1} \\mid Z_{j}=1\\right)}{n-i} \\\\\n& \\leq \\frac{k-\\mathrm{E}\\left(X_{1}\\right)-\\cdots-\\mathrm{E}\\left(X_{i-1}\\right)}{n-i}=\\operatorname{Pr}\\left(X_{i}=1\\right)\n\\end{aligned}\n$$  \nSince (1) is monotone increasing in $\\operatorname{Pr}\\left(X_{i}=1\\right) \\in[0,1]$, we have  \n$$\n\\operatorname{Pr}\\left(Z_{i}=1 \\mid Z_{j}=1\\right) \\leq \\operatorname{Pr}\\left(Z_{i}=1\\right)\n$$  \nso altogether  \n$$\n\\operatorname{Pr}\\left(\\cap_{i \\in\\{1, \\ldots, \\ell\\}}\\left(Z_{i}=1\\right)\\right) \\leq \\prod_{i=1}^{\\ell} \\operatorname{Pr}\\left(Z_{i}=1\\right)\n$$  \nwhich proves the 1-negative correlation.\nWe can easily prove the 0 -negative correlation in a symmetric fashion. Formally, if we consider $x^{(1)}, x^{(2)}, x^{(3)} \\in(0,1)^{n}$ to be drawn uniformly at random and independently from the set of bit strings having $n-k$ zero-bits and redefine $X_{i}^{(\\cdot)}$ to be the complement of the $i$-th bit value, then the very same proof as above applies except that any appearance of the number $k$ of one-bits is replaced with the number $n-k$ of zero-bits.  \nFinally, we define a commonly used notion of high probability.\nDefinition 1. We say that an event $A$ happens with high probability if $\\operatorname{Pr}(A) \\geq 1-n^{-c}$ for every constant FORMULA_371.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:55:53",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework described, how does the algorithmic mechanism involving Equations (4a) through (4k) control the state transition process, specifically in terms of updating the completion set \\(C_{v+1}\\) and the active set \\(A_{v+1}\\), based on resource availability and job finish times?",
      "topics": [
        "control"
      ],
      "answer": "The control flow dictates that if Equation (4a) is true, meaning either the eligible set \\(E_v\\) is empty or the resources required by each activity in \\(E_v\\) are less than the balance resources, then Equations (4b)-(4e) are executed, followed by Equation (4k). Equation (4c) updates the completion set \\(C_{v+1}\\) by taking the union of the previous completion set \\(C_v\\) and the set of jobs whose finish times \\(f_j\\) are less than or equal to \\(t_{v+1}\\), where \\(t_{v+1}\\) is the minimum of the finish times of active jobs. The active set \\(A_{v+1}\\) is updated using Equation (4e) by adding the decision set to \\(A_v\\) whose finish times are greater than \\(t_{v+1}\\). If Equation (4f) is true, indicating either no active job is being processed or there is at least one job in \\(E_v\\) where the resources required are less than the balance resources, then Equations (4g)-(4k) are executed. In this case, \\(t_{v+1}\\) and \\(C_{v+1}\\) are copied from the previous state, and Equation (4i) updates \\(A_{v+1}\\) by including the decision set.",
      "chunk_id": 2598,
      "paper_id": "Maximizing Net Present Value for Resource Constraint Project Scheduling Problems with Payments at Event Occurrences Using Approximate Dynamic Programming",
      "paper_title": "Maximizing Net Present Value for Resource Constraint Project Scheduling Problems with Payments at Event Occurrences Using Approximate Dynamic Programming",
      "paper_year": "2024",
      "chunk_content": "$$\n\\begin{gathered}\n\\text { if } \\boldsymbol{q}_{j} \\cdot \\geq \\boldsymbol{Q}_{r j}, \\forall j \\in E_{v} \\text { or } E_{v}=\\varnothing \\\\\nt_{v+1}=\\min \\left(\\left\\{f_{j}: j \\in \\boldsymbol{A}_{v}, f_{j} \\in \\boldsymbol{A}_{v_{t}}\\right\\}\\right) \\\\\n\\boldsymbol{C}_{v+1}=C_{v} \\cup\\left\\{j: f_{j} \\leq t_{v+1}, \\forall j \\in \\boldsymbol{A}_{v}, f_{j} \\in \\boldsymbol{A}_{v_{t}}\\right\\} \\\\\n\\boldsymbol{Q}_{r v+1}=\\boldsymbol{Q} \\cdot-\\sum_{k=1}^{|\\boldsymbol{q}|}\\left[\\boldsymbol{q}_{1} \\ldots \\boldsymbol{q}_{j} \\ldots \\boldsymbol{q}_{l}\\right]^{-1}, j=[1, \\ldots, l] \\in \\boldsymbol{A}_{v} \\\\\n\\boldsymbol{A}_{v+1}=\\left\\{j: f_{j}>t_{v+1}, \\forall j \\in \\boldsymbol{A}_{v}, f_{j} \\in \\boldsymbol{A}_{v_{t}} \\cup x_{v r}\\right\\} \\\\\n\\text { if } \\boldsymbol{q}_{j} \\cdot \\leq \\boldsymbol{Q}_{r j}, \\exists j \\in E_{v} \\text { or } A_{v}=\\varnothing \\\\\nt_{v+1}=t_{v} \\\\\n\\boldsymbol{C}_{v+1}=\\boldsymbol{C}_{v} \\\\\n\\boldsymbol{A}_{v+1}=\\boldsymbol{A}_{v} \\cup x_{v} \\\\\n\\boldsymbol{Q}_{r v+1}=\\boldsymbol{Q} \\cdot-\\sum_{k=1}^{|\\boldsymbol{q}|}\\left[\\boldsymbol{q}_{1} \\ldots \\boldsymbol{q}_{j} \\ldots \\boldsymbol{q}_{l}\\right]^{-1}, j=[1, \\ldots, l] \\in \\boldsymbol{A}_{v} \\\\\n\\boldsymbol{A}_{(v+1)_{j}}=\\left\\{t_{v+1}+d_{j}: j \\in A_{v+1}\\right\\}\n\\end{gathered}\n$$  \nIn this transition, the process must follow a logical control flow. That is, if Equation (4a) is true, Equations (4b)-(4e) are executed, followed by Equation (4k). Equation (4a)  \nchecks whether $E_{v}$, an eligible set at state $S_{v}$, is empty or whether the resources required by each activity of $E_{v}$ are less than the balance resources if $E_{v}$ is not empty. Equation (4a) assesses whether the set of eligible activities at state $S_{v}$, denoted as $E_{v}$, is empty. If $E_{v}$ is not empty, the equation further evaluates whether the resources required for each activity within $E_{v}$ exceed the available balance of resources. Equation (4b) determines the times associated with state $S_{v+1}$ by taking the minimum of the finish times of the active jobs from the state $S_{v}$. In Equation (4c), the completion set $C_{v+1}$ of $S_{v+1}$ is set to the union of $C_{v}$ and the set containing jobs whose finish times are less than equal to $t_{v+1}$. The balance resources for state $S_{v+1}$ are calculated using Equation (4d) or (4j). For each resource, the remaining resource is the difference of the total resource and the sum of the resources currently being used by active jobs at state $A_{v}$. Finally, an active set $A_{v+1}$ is updated by adding the decision set to active set $A_{v}$ whose finish times are greater than $t_{v+1}$. In Equations (4d) and (4j), the value of $|\\boldsymbol{q}|=\\left|\\boldsymbol{q}_{j}\\right|, \\forall j \\in\\{1, . ., J\\}$, as this indicates the different types of resources required by an activity $j$. If $E_{v} \\neq \\varnothing$ in Equation (4a), then Equation (4e) is executed before Equation (4d) by setting $x_{v t}=x_{v}$; if $E_{v}=\\varnothing$, a new $E_{v+1}$ is determined directly after Equation (4d), and we set $x_{v t}=x_{v+1}$. The set $x_{v}$ is determined using Equation (6). If a statement given by Equation (4f) is true, then Equations (4g)-(4k) are executed. That is, if there is no active job being processed or there exists at least one job in the eligible set $E_{v}$ in which the resources required are less than the balance resources checked by Equation (4f), then the time $t_{v+1}$ and completion set $C_{v+1}$ of $S_{v+1}$ are the copies from the previous state. Equation (4i) determines the active set $A_{v+1}$ by including the decision set. Finally, Equation (4k) determines the completion times of the activities in the active set $A_{v}$. We see that the state $S_{v+1}$ depends only on state $S_{v}$, which indicates that the process is a Markov process [56].\n5. Benefit function: Let $\\pi=\\left\\{\\omega_{0}^{\\pi}\\left(S_{0}\\right), \\ldots, \\omega_{\\mathrm{P}}^{\\pi}\\left(S_{F}\\right)\\right\\}$ be the policy containing a sequence of decisions, where $\\omega_{v}^{\\pi}\\left(S_{v}\\right): S_{i} \\rightarrow x_{v}^{\\pi}$. Let $\\psi\\left(S_{v}, x_{v}^{\\pi}, S_{v+1}\\right)$ be the change in the NPV of the project as a result of decision $x_{v}^{\\pi}$ at $S_{v}$ that leads to state $S_{v+1}$. We define the benefit-to-go function with the policy $\\pi$ starting from stage $v$ with state $S_{v}$ as follows:  \n$$\n\\begin{aligned}\n& B_{v}\\left(S_{v}\\right)=\\mathbb{E}\\left[\\sum_{j=v}^{F} \\psi\\left(S_{v}, x_{v}^{\\pi}, S_{v+1}\\right)\\right] \\\\\n& =\\mathbb{E}\\left[\\psi\\left(S_{v}, x_{v}^{\\pi}, S_{v+1}\\right)+B_{v+1}\\left(S_{v+1}\\right)\\right]\n\\end{aligned}\n$$",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:55:56",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners address diversity loss in the probability model, specifically when using a UMDA model with elite clone selection, and what threshold should be applied to the probability values?",
      "topics": [
        "search"
      ],
      "answer": "To address diversity loss when using a UMDA model, practitioners should correct the boundary of the probability model using the equation $\\rho_{i}^{\\'}=\\left\\{\\begin{array}{c} \\gamma, \\rho_{i}<\\gamma \\\\ p_{i}, \\lambda<\\rho_{i}<1-\\gamma \\\\ 1-\\gamma, \\rho_{i}>1-\\gamma \\end{array}\\right.$, where $\\rho_{i}$ is the probability before correction and $\\rho_{i}^{\\'}$ is the probability after correction. The threshold $\\gamma$ is set to $1/n$, where $n$ represents the number of genes. This correction prevents $\\rho_{i}$ from reaching 1 or 0, which slows down the update speed of the probability model and improves population diversity. Also, elite clone selection operation can improve population diversity loss since $X_{i}^{k}$ is obtained by T transformating the sampled solution.",
      "chunk_id": 833,
      "paper_id": "Application of estimation of distribution algorithm in HW SW partition",
      "paper_title": "Application of Estimation of Distribution Algorithm in HW/SW Partition",
      "paper_year": "2014",
      "chunk_content": "Supposing $X_{i}^{j}$ is the $j$ th cloned individual of $\\boldsymbol{X}_{i}$, transformation from $X_{i}^{j}$ to $X_{i}^{j}$ is defined as $\\mathrm{T}\\left(X_{i}^{j} \\rightarrow X_{i}^{j}\\right)$ : randomly select k genes which value equal to 0 and turn them to 1 ; randomly select $\\mathrm{k}+\\mathrm{t}$ genes which value equal to 1 and turn them to 0 . The meaning of T transformation in HW/SW partitioning problem lies in switching the mapping domain of k function blocks in software domain and $\\mathrm{k}+\\mathrm{t}$ function blocks in hardware domain.\nLet $\\operatorname{cost}\\left(X_{i}^{k}\\right)=\\min \\left(\\operatorname{cost}\\left(X_{i}^{j}\\right)\\right), \\boldsymbol{X}_{i} \\in \\mathrm{~s}^{\\prime}(\\mathrm{g}), \\mathrm{j}=1,2, \\ldots, \\mathrm{nc}_{\\mathrm{i}}, \\mathrm{if}$ $\\operatorname{cost}\\left(X_{i}^{k}\\right) \\leq \\operatorname{cost}\\left(\\boldsymbol{X}_{i}\\right), \\boldsymbol{X}_{i}$ is replaced by $X_{i}^{k}$. For $\\boldsymbol{X}_{i} \\in \\mathrm{~s}^{\\prime}(\\mathrm{g})$, the process of elite clone selection operation offers $\\mathrm{nc}_{\\mathrm{i}}$ different search directions in the neighborhood of $\\boldsymbol{X}_{i}$ and makes local search in the neighborhood, the dominance replacement ensures that the solutions will not be worse, and accelerates the convergence speed. After dominance replacement, a new population pop ' $(\\mathrm{g})$ is formed.\nProbability vector $\\rho(g)=\\left(\\rho_{1}, \\ldots \\rho_{k} \\ldots, \\rho_{n}\\right)$ is probability model to describe the distribution of solution space. $\\rho_{k}$ is the probability of $\\mathrm{B}_{\\mathrm{k}}$ mapped to the hardware domain i.e., the probability of $x_{k}=1$. Offspring solutions are generated by sampling from probability model, i.e., a number r can be generated randomly, $\\mathrm{r}_{\\in}[0,1]$ if $\\mathrm{r}<\\rho_{j}, x_{i}=1$; otherwise $x_{i}=0$.  \nThis paper adopts the UMDA [7] probability model, it builds the probability model on $\\mathrm{s}^{\\prime}(\\mathrm{g})$ subset which is composed of $[\\beta * \\mathrm{M}]$ individuals with best fitness in $\\operatorname{pop}^{\\prime}(\\mathrm{g}), \\quad 0<\\beta<1 . \\quad \\rho_{j}$ is updated by (4), $x_{i}^{j}$ is the value of the ith gene of the jth individual:  \n$$\n\\rho_{i}=\\frac{\\sum_{j \\in \\mathrm{~T}^{\\prime}(g)} x_{i}^{j}}{[\\beta * \\mathrm{M}]}\n$$  \nThe probability of generating solution $X$ is calculated by Eq.(5) :  \n$$\n\\rho(X)=\\prod_{i=1}^{n}\\left[\\rho_{i} * x_{i}+\\left(1-\\rho_{i}\\right) *\\left(1-x_{i}\\right)\\right]\n$$  \nInitial population pop (0) is generated randomly with uniform distribution of the solution space, namely $\\rho(0)=(0.5 \\ldots 0.5 \\ldots 0.5)$.\nAlong with the iteration, EDA will lose diversity, population variance is growing smaller, eventually reduces to zero, probability model evolves to only produce same solutions[12].  \nEDA diversity loss occurred in two stages :  \n- Sampling from the probability model to generate population. This diversity loss is due to the fact that variance of population sampled from probability model will be less than the variance of parent population. Elite clone selection operation introduced by part B not only strengthens the local search ability but also improves the population diversity loss problem since $X_{i}^{k}$ is obtained by T transformating the sampled solution.\n- Selecting M solutions to build the probability model of next generation. Usually high fitnesses solutions are selected to build probability model, thus distribution characteristics of good solutions are achieved, but will cause loss of diversity. It can be relieved by slowing down the update speed of probability model, making update speed relatively slower than the search speed of algorithm. Once $\\rho_{j}$ is close enough to 0 or 1 , the value of $x_{i}$ tends to fix and lead to the combination reduction of n genes,i.e., the diversity of population is made to decrease. So the boundary of probability model is corrected by Eq.(6):  \n$$\n\\rho_{i}^{\\prime}=\\left\\{\\begin{array}{c}\n\\gamma, \\rho_{i}<\\gamma \\\\\np_{i}, \\lambda<\\rho_{i}<1-\\gamma \\\\\n1-\\gamma, \\rho_{i}>1-\\gamma\n\\end{array}\\right.\n$$  \n$\\rho_{i}$ is probability before correction, $\\rho_{i}$ is probability after correction, $\\gamma=1 / n$.  \nThe correction prevents $\\rho_{i}$ reaching 1 and 0 , lowers the update speed of probability model, also improves the diversity loss of population and avoids falling into local optimum .",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:55:58",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Estimation of Distribution Algorithms (EDAs) discussed, what are the key differences in the evolutionary model between EDAs and Genetic Algorithms (GAs)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The evolutionary model of EDAs differs from GAs in that GAs simulate biological evolution from the micro-level, while EDAs simulate biological evolution from the macro-level. EDAs do not include traditional crossover, mutation, and genetic manipulation. Instead, EDAs use the learning and sampling of a probability model to generate new populations.",
      "chunk_id": 235,
      "paper_id": "An Estimation of Distribution Algorithm for Steiner Tree Problem",
      "paper_title": "An Estimation of Distribution Algorithm for Steiner Tree Problem",
      "paper_year": "2013",
      "chunk_content": "[^0]:     Corresponding author: Hua Wang  \nEmail address: wanghua@sdu.edu.cn  \nsolution tree with EDA ideas. Simulations made on a variety of undirected and directed graphs indicate that the algorithm is feasible and effective.  \nThis paper consists of six sections. Section 1 describes the research background of Steiner tree problem. Section 2 defines Steiner tree and constructs its mathematical model. Section 3 briefs estimation of distribution algorithm. Section 4 describes the method and detailed steps of solving Steiner tree problem. Section 5 reports the simulation results and analysis. Section 6 is the summary of the research, and meanwhile suggestions for future research are given.\nDefinition 1: Given graph $G=(V, E), V$ is the node set of graph $G, E$ is the edge set of graph $G,|V|$ is the node number of graph $G,|E|$ is the number of edges or links of graph $G$. The cost function of edge cost: $E \\rightarrow R$, the destination node set $D \\subseteq V, m=|D|$, then the minimal Steiner tree is defined as finding the minimal tree covering all the nodes in $D$ from graph $G$. If the tree has the minimum cost, then it is called Steiner tree. Record the tree as $T_{e}\\left(V_{T}, E_{T}\\right)$, where $D \\subseteq V_{T} \\subseteq V, E_{T} \\subseteq E$.  \nTherefore the minimal Steiner tree can be formalized as  \n$$\n\\min \\sum_{e \\in E_{T}} \\operatorname{cost}(e)\n$$\nEstimation of distribution algorithms are stochastic optimization techniques that explore the space of potential solutions by building and sampling explicit probabilistic models of promising candidate solutions. This model-based approach to optimization has allowed EDA to solve many large and complex problems[28,29,30].  \nThe idea of the EDA originated in the genetic algorithm(GA). EDAs are susceptible to what is analogous to premature convergence in genetic algorithms. But the evolutionary model of the EDA is different from GA. In a sense, GA simulates the biological evolution from the micro-level, but the EDA simulates the biological evolution from the macro-level. Traditional crossover, mutation and genetic manipulation are not included in the EDA, instead of by the learning and the sampling of the probability model. This new evolutionary model gives the unique properties of the EDA. EDA were successfully applied to optimization of large spin glass instances. This optimization can usually find the best solution and has higher efficiency.  \nAccording to the degree of complexity of the probabilistic model as well as the different sampling methods, EDA developed many different specific implementation methods, which can be summarized as the following three main steps. Start with a random population of $M$ vector, then implement a loop consisting of  \n1) Select $N$ vectors using a selection method.\n2) We should build a probabilistic model for describing the solution space. According to the assessment of the population, we can choose a good collection of individuals, then construct a description of a probabilistic model of the current solution set by means of statistical learning.\n3) New populations are generated by the probabilistic model of random sampling. That is, sample $M$ vectors from the probability model.  \nThere are many variations. Selection is often done by applying truncation selection to the sampled population. Alternatively, the selected vectors replace a fraction of the selected population from the previous generation rather than the entire population. Likewise, the probability model can be built from scratch at each generation, or can use the model from the previous generation(s) to build the current model. Another source of variation in EDAs is in the allowed structure: UMDA treats each variable independently. MIMIC assumes a chain of interactions, so every variable except the root and the terminal variables are the parent of one node and the child of another. BOA uses a general directed acyclic graph to represent the structure.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:00",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between initializing the population in the EDA and generating a new population, specifically concerning constraints?",
      "topics": [
        "scheduling"
      ],
      "answer": "When initializing the first generation of the population in the EDA, each randomly generated vector \\mathbf{B}_{0,i} is tested for effectiveness based on constraints such as \\(T_{i} \\leq T_{i+1}, \\forall i\\) and schedulability. Vectors not meeting these constraints are eliminated, which requires computational effort. In contrast, generating a new population from the probability model using the Monte Carlo method also requires judging the validity of new individuals, suggesting a trade-off where both steps involve computational cost related to constraint satisfaction, but the initialization phase has a higher cost due to the elimination of ineffective initial solutions.",
      "chunk_id": 8886,
      "paper_id": "Collaborative Optimization Design for Centralized Networked Control System",
      "paper_title": "Collaborative Optimization Design for Centralized Networked Control System",
      "paper_year": "2021",
      "chunk_content": "The estimation of distribution algorithms (EDA) is a new optimization algorithm [26]. Different from the traditional optimization algorithm based on individual population evolution (crossover, mutation, etc.) to realize population evolution, the EDA directly describes the evolutionary trend of the entire group, and uses a probability model for learning and sampling. As a new tool for solving complex optimization problems, EDA can describe the relationship between variables through probability model, which makes it more effective for solving nonlinear and variable coupling optimization problems. Therefore, this paper introduces EDA to solve the scheduling optimization problem of collaborative design based on jitter.  \nThe $i$-th optimization vector in this paper can be designed as (19), shown at the bottom of the page, where $T_{j}^{i}$ represents the sampling period of the closed-loop $j, \\varphi_{j, 1}^{i}$ and $\\varphi_{j, 2}^{i}$ respectively represent the initial phase of data transmission of the controller and sensor of the closed-loop $j$.  \nThere are coupling constraints between the sampling period and the initial phase of each closed loop. Thus, this paper obtains the optimal value by directly completing the evolution based on EDA for the population of vector $\\mathbf{B}$. The algorithm is designed as follows:  \nStep 1: Initialize the first generation of effective population $\\mathbf{B}_{0}$. The initial population is randomly generated in the solution space according to uniform distribution. Due to the need to meet $T_{i} \\leq T_{i+1}, \\forall i$ and schedulability constraints, each group of randomly generated vectors $\\mathbf{B}_{0, i}$ should be tested for effectiveness first, and those that are not satisfied should be eliminated directly until the effective initial population $\\mathbf{B}_{0}$ with population size P is obtained.  \nStep 2: Evaluate the group. Calculate the fitness value $J_{i}$ of each individual, and select the first half to form the dominant group $\\mathrm{X}_{\\mathrm{s}}$.  \nStep 3: Construct a probability model describing the solution space. Construct a probability model based on Gaussian distribution from this dominant group $\\mathrm{X}_{\\mathrm{s}}$.  \nStep 4: Generate a new generation of population from the probability model. The Monte Carlo method is used to estimate the mean vector and covariance matrix of the multivariate Gaussian distribution. Sampling by the probability model to obtain a new population, and judge the validity of the  \n$$\n\\mathbf{B}_{i}=\\left[T_{1}^{i}, T_{2}^{i}, \\ldots, T_{j}^{i}, \\ldots, T_{M}^{i}, \\varphi_{1,1}^{i}, \\varphi_{1,2}^{i}, \\ldots, \\varphi_{j, 1}^{i}, \\varphi_{j, 2}^{i}, \\ldots, \\varphi_{M, 1}^{i}, \\varphi_{M, 2}^{i}\\right]\n$$  \nnew individual, turn to Step 2 until the evolution conditions are satisfied.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:02",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to incorporate the resilience-based surrogate robustness measure (SRM-R) in the multi-objective hybrid estimation of distribution algorithm for the robust job-shop scheduling problem (RJSSP)?",
      "topics": [
        "scheduling",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "To implement the multi-objective hybrid estimation of distribution algorithm incorporating the SRM-R for RJSSP, the code should be structured to first evaluate the robustness of a schedule using the SRM-R. This involves analyzing the disturbance propagation of correlated operations, considering production resilience, and utilizing available information on stochastic deteriorating processing times and slack times within the schedule structure. The SRM-R then provides a robustness estimation that is used within the EDA to find Pareto optimal solutions, balancing schedule performance and robustness. The code should modularize the SRM-R calculation to efficiently estimate robustness, thereby reducing the computational burden associated with simulation-based robustness evaluation.",
      "chunk_id": 1491,
      "paper_id": "Resilience-Based Surrogate Robustness Measure and Optimization Method for Robust Job-Shop Scheduling",
      "paper_title": "Resilience-Based Surrogate Robustness Measure and Optimization Method for Robust Job-Shop Scheduling",
      "paper_year": "2022",
      "chunk_content": "Shichang Xiao ${ }^{1, * *}$, Zigao Wu ${ }^{2}$ and Hongyan Dui ${ }^{3}$\nCitation: Xiao, S.; Wu, Z.; Dui, H. Resilience-Based Surrogate Robustness Measure and Optimization Method for Robust Job-Shop Scheduling. Mathematics 2022, 10, 4048. https://doi.org/ 10.3390/math10214048  \nAcademic Editor: Ripon\nKumar Chakrabortty\nReceived: 28 September 2022\nAccepted: 26 October 2022\nPublished: 31 October 2022\nPublisher's Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nCopyright: (C) 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ $4.0 /$ ).  \n1 School of Logistics Engineering, Shanghai Maritime University, Shanghai 201306, China\n2 Department of Mechanical Engineering, North China Electric Power University, Baoding 071003, China\n3 School of Management Engineering, Zhengzhou University, Zhengzhou 450001, China  \n* Correspondence: scxiao@shmtu.edu.cn\nThis paper addresses the robust job-shop scheduling problems (RJSSP) with stochastic deteriorating processing times by considering the resilience of the production schedule. To deal with the disturbances caused by the processing time variations, the expected deviation between the realized makespan and the initial makespan is adopted to measure the robustness of a schedule. A surrogate model for robust scheduling is proposed, which can optimize both the schedule performance and robustness of RJSSP. Specifically, the computational burden of simulation is considered a deficiency for robustness evaluation under the disturbance of stochastic processing times. Therefore, a resilience-based surrogate robustness measure (SRM-R) is provided for the robustness estimation in the surrogate model. The proposed SRM-R considers the production resilience and can utilize the available information on stochastic deteriorating processing times and slack times in the schedule structure by analyzing the disturbance propagation of the correlated operations in the schedule. Finally, a multi-objective hybrid estimation of distribution algorithm is employed to obtain the Pareto optimal solutions of RJSSP. The simulation experiment results show that the presented SRM-R is effective and can provide the Pareto solutions with a lower computational burden. Furthermore, an RJSSP case derived from the manufacturing environment demonstrates that the proposed approach can generate satisfactory robust solutions with significantly improved computational efficiency.  \nKeywords: production resilience; robust job-shop scheduling; surrogate robustness measure; disturbance propagation; optimization algorithm",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:04",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA component within the KCACIL algorithm?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The effectiveness of the EDA component within KCACIL is evaluated based on solution accuracy, convergence speed, and stability. These metrics are assessed in the context of the CEC 2014 and CEC 2017 test suites, as well as the dynamic economic dispatch (DED) problem.",
      "chunk_id": 4142,
      "paper_id": "A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning",
      "paper_title": "A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning",
      "paper_year": "2023",
      "chunk_content": "The experimental results and statistic analysis in the CEC 2014 and  \nCEC 2017 test suites illustrate that a knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning achieves a trade-off between exploration and exploitation by utilizing the complementary superiority of DE and EDA. KCACIL is superior to most state-of-the-art algorithms and variants with reinforcement learning in terms of solution accuracy, convergence speed, and stability in most cases.  \nThe DE provides powerful exploration, while the EDA promotes local exploitation. The comprehensive collaboration is implemented from the three aspects of diverse algorithms, improvement strategies, and individual interaction. Based on the specific knowledge implicit in three regions, the cross-regional co-evolution guided by reinforcement learning with opposition-based learning, elite strategy, and the revised strategy of the inferior solutions balances the convergence rate and population diversity. The mechanisms of cross-regional self-learning, interactive learning, and self-feedback promote effective knowledge  \nTable 17\nResults on DED problem.\n[IMAGE49]  \nFig. 28. Stability of KCACIL and the comparison algorithms in DED.\nsharing and transfer. Furthermore, search efficiency and convergence accuracy are facilitated.  \nThe inferior solutions with small $Q$ feedback of reinforcement learning and dense aggregation are improved by the revised strategy of the inferior solutions to ameliorate premature convergence. The collaboration of the strategies promotes the rapid population evolution toward the optimal direction and improves the accuracy of the solutions. The individual regeneration mechanism activates the population and effectively avoids evolutionary stagnation. The adaptive strategies of multiple parameters dynamically adjust KCACIL to the appropriate state in different stages. The robustness is improved.\nThe dynamic economic dispatch (DED) problem (Das and Suganthan, 2011) belongs to the hourly scheduling problem. Power demand changes with hours, and a clear 24-h power generation plan is to be\ndeveloped. The objective and constraints of DED are shown in Eqs. (56)(63).  \nFirst, the definition of the symbol used in this engineering application problem is given.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:05",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically focusing on the parallelization of Bayesian optimization?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to design a robust and effective parallel evolutionary algorithm for a wide range of application problems by improving parallel network construction within distributed Bayesian optimization algorithms. This involves estimating the distribution of promising solutions as Bayesian networks and demonstrating its effectiveness through numerical experiments and a real-world application in protein structure prediction, compared to conventional parallelization methods.",
      "chunk_id": 12938,
      "paper_id": "Empirical Studies on Parallel Network Construction",
      "paper_title": "Empirical studies on parallel network construction of Bayesian optimization algorithms",
      "paper_year": "2005",
      "chunk_content": "Masaharu MunetomoInformation Initiative Center, Hokkaido UniversityNorth 11, West 5Sapporo, 060-0811 JAPAN.munetomo@iic.hokudai.ac.jp  \nNaoya MuraoGraduate School of Engineering, Hokkaido UniversityNorth 11, West 5Sapporo, 060-0811 JAPAN.naoya.m@cims.hokudai.ac.jp  \nKiyoshi AkamaInformation Initiative Center, Hokkaido UniversityNorth 11, West 5Sapporo, 060-0811 JAPAN.akama@iic.hokudai.ac.jp\nThis paper discusses a parallel optimization algorithm based on evolutionary algorithms with probabilistic model-building in order to design a robust search algorithm that can be applicable to a wide-spectrum of application problems effectively and reliably. Probabilistic model building genetic algorithm, which is also called estimation of distribution algorithm, is a promising approach in evolutionary computation and its parallelization has been investigated. We propose an improvement of parallel network construction in distributed Bayesian optimization algorithms which estimate distribution of promising solutions as Bayesian networks. Through numerical experiments on an actual parallel architecture, we show the effectiveness of our approach compared to the conventional parallelization. Also we perform experiments on a real-world application problem: protein structure predictions.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:07",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the PBIL probabilistic model, specifically its matrix update rule, influence the exploration-exploitation balance when applied to problems such as multicast routing optimization?",
      "topics": [
        "convergence"
      ],
      "answer": "The PBIL probabilistic model, used within the improved EDA, employs a probabilistic matrix $p=\\left(p_{i j}\\right)$ where $p_{i j}$ represents the probability of selecting edge $e_{i j}$ or $e_{j i}$. This matrix is updated iteratively using the equation $p_{i j}(t+1)=\\rho * p_{i j}(t)+(1-\\rho) *\\left(1+\\frac{1}{N} \\sum_{l=1}^{N} x_{i j}^{l}\\right)$, where $x_{i j}^{l}$ is 1 if edge $e_{i j}$ or $e_{j i}$ is in solution $l$, and 0 otherwise. The parameter $\\rho$ controls the influence of the previous probability $p_{i j}(t)$ on the updated probability $p_{i j}(t+1)$. A larger value of $\\rho$, such as the value 0.8 used, emphasizes the contribution of historical information, promoting exploitation of previously successful edges. Conversely, the term $(1-\\rho) *\\left(1+\\frac{1}{N} \\sum_{l=1}^{N} x_{i j}^{l}\\right)$ encourages exploration by incorporating information from the current elite individuals, selected from the $N$ initial trees. The initial probability $p_{i j}$ is set to $\\frac{1}{|E|}$, giving each edge an equal probability of being chosen, further expanding the initial search scope.",
      "chunk_id": 4690,
      "paper_id": "An improved EDA for solving Steiner tree problem",
      "paper_title": "An improved EDA for solving Steiner tree problem",
      "paper_year": "2015",
      "chunk_content": "According to improved EDA algorithm, Elite individuals will be selected for building the probabilistic model. In this work, $M$ elites are selected as sample individuals which have the lower estimation value as in the $N$ initial trees. PBIL [19] probabilistic model was applied in this paper. The probabilistic matrix $p=\\left(p_{i j}\\right)(0<i, j<V)$ represents the probability model, where $p_{i j}$ denotes the probability of selecting the edge $e_{i j}$ or $e_{j i}$, and it is initialized as $p_{i j}=\\frac{1}{|E|}$; every edge has the same probabilistic to be chosen for constructing the solution expanding the search scope to some extent. In the $t+1$ iteration, the matrix is updated as the following equation:  \n$$\np_{i j}(t+1)=\\rho * p_{i j}(t)+(1-\\rho) *\\left(1+\\frac{1}{N} \\sum_{l=1}^{N} x_{i j}^{l}\\right), 1 \\leq i, j \\leq V\n$$  \nwhere  \n$$\nx_{i j}^{l}= \\begin{cases}1 & , \\forall e_{i j} o r e_{j i} \\in l \\\\ 0, & \\text { otherwise }\\end{cases}\n$$  \n$\\rho$ controls old probabilistic on how to affect the new selection. The larger of the $\\rho$ value indicates more contribution of the information learned from the history. Through extensive experiments we set $\\rho=0.8$.\nOwing to the development of network technology, multimedia applications have flooded the communication networks and expanded in all science and engineering domains, such as the broadcasting, video conference and distance education. These applications have high demands on the bandwidth, latency and energy consumption. To this end, multicast is considered to be an effective solution. In this part, the improved EDA is applied on an application, i.e. multicast routing optimization. The results validated the efficiency and accuracy of the developed algorithm.  \nThe improved EDA was programmed with VC6.0 and run on the machine Intel Pentium_ 4 $3.00 \\mathrm{GHz}, 4 \\mathrm{G}$ memory in the operating system of Windows 7.  \nThe improved EDA algorithm is validated through four scenarios in terms of four aspects in the simulation process, which include the influence of initial population size on search effect, the effect of destination node scale on convergence result, the parameter setting and the comparison among algorithm performance. Two network topologies are employed in order to test the feasibility of the work in this paper. The first network topology used follows certain power law rule. The other one is the random topology. Inet 3.0 [37] adopts PLRG (Power-Law Random Graphs) algorithm and priority attachment. In this paper, B kinds of topologies in SteinLab Repository [39] are used. Figure 2 is the topology graph with 50 nodes generated via Inet 3.0.",
      "question_type": "challenge",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:10",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using the Parzen estimator, how should practitioners balance the scale factor $h_n$ to manage the bias-variance trade-off?",
      "topics": [
        "constraints"
      ],
      "answer": "When using the Parzen estimator $\\hat{\\boldsymbol{p}}_{n}^{S}(z)$, the scale factor $h_n$ regulates the bandwidth of the kernel. A larger $h_n$ reduces the variance but increases the bias due to excessive smoothing. Conversely, a smaller $h_n$ reduces bias but increases variance. To achieve convergence in the mean square sense, $h_n$ should decrease as the sample size $n$ grows, ensuring that $\\lim _{n \\rightarrow \\infty} n d_{n}=\\infty$ to control variance and $\\lim _{n \\rightarrow \\infty} d_{n}=\\infty$ to control bias.",
      "chunk_id": 13192,
      "paper_id": "MOPED  A Multi-objective Parzen-Based Estimation of Distribution Algorithm for Continuous Problems",
      "paper_title": "MOPED: A multi-objective Parzen-based estimation of distribution algorithm for continuous problems",
      "paper_year": "2003",
      "chunk_content": "Let $z$ be a real-valued random variable. Let $p^{z}(\\cdot): \\Re \\rightarrow \\Re, \\cup\\{0\\}$ be the associated PDF. Let $\\boldsymbol{D}_{n}=\\left\\{z_{1}, \\ldots, z_{n}\\right\\}$ be a collection of $n$ independent replicas of $z$. The empirical estimator $\\hat{\\boldsymbol{p}}_{n}^{E}(\\cdot)$ of $p^{z}(\\cdot)$ based on $\\boldsymbol{D}_{n}$ is defined as follows:  \n$$\n\\forall z \\in \\Re \\quad \\hat{\\boldsymbol{p}}_{n}^{E}(z)=\\frac{1}{n} \\sum_{i=1}^{n} \\delta\\left(z-z_{i}\\right)\n$$  \nThe estimator just defined is unbiased everywhere but it converges nowhere to $p^{z}(\\cdot)$ in the mean square sense because $\\operatorname{Var}\\left[\\hat{\\boldsymbol{p}}_{n}^{E}(z)\\right]=\\infty$ irrespective of both $n$ and $z$. This last result is not surprising, since the Dirac's delta is not squared integrable.  \nThe Parzen estimator $\\hat{\\boldsymbol{p}}_{n}^{S}(\\cdot)$ of $p^{z}(\\cdot)$ based on $\\boldsymbol{D}_{n}$ is obtained by convolving the empirical estimator with some squared integrable kernel PDF $g_{s}(\\cdot)$ :  \n$$\n\\forall z \\in \\Re \\quad \\hat{\\boldsymbol{p}}_{n}^{S}(z)=\\int_{-\\infty}^{\\infty} \\hat{\\boldsymbol{p}}_{n}^{E}(x) \\frac{1}{h_{n}} g_{S}\\left(\\frac{z-x}{h_{n}}\\right) d x=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{h_{n}} g_{S}\\left(\\frac{z-z_{i}}{h_{n}}\\right)\n$$  \nThe kernel acts as a low-pass filter whose \"bandwidth\" is regulated by the scale factor $h_{n} \\in \\Re_{s}$. It exerts a \"smoothing\" action that lowers the sensitivity of $\\hat{\\boldsymbol{p}}_{n}^{S}(z)$ w.r.t. $\\boldsymbol{D}_{n}$ so as to make $\\operatorname{Var}\\left[\\hat{\\boldsymbol{p}}_{n}^{S}(z)\\right]<\\infty \\quad \\forall z \\in \\Re$. Thus for any given sample size the larger is the scale factor, the smaller is the variance of the estimator. But the converse is also true: since $\\hat{\\boldsymbol{p}}_{n}^{S}(z)$ is nothing but a mean, then for any given scale factor the larger is the sample size, the smaller is the variance of the estimator (indeed it is inversely proportional to the sample size). Both statements are in fact special cases of the following property:  \n$$\n\\forall z \\in \\Re \\quad \\lim _{n \\rightarrow \\infty} n d_{n}=\\infty \\Rightarrow \\lim _{n \\rightarrow \\infty} \\operatorname{Var}\\left[\\hat{\\boldsymbol{p}}_{n}^{S}(z)\\right]=0\n$$  \nOn the other hand, the same smoothing action produces an unwanted \"blurring\" effect that limits the resolution of the approximation. Intuitively the scale factor should therefore vanish as $n \\rightarrow \\infty$ in order to let the estimator closely follow finer and finer details of the true PDF. Also this last remark finds a precise mathematical rendering in the following property:  \n$$\n\\forall z \\in \\Re \\quad \\lim _{n \\rightarrow \\infty} d_{n}=\\infty \\Rightarrow \\lim _{n \\rightarrow \\infty} E\\left[\\hat{\\boldsymbol{p}}_{n}^{S}(z)\\right]=p^{S}(z)\n$$  \nTo summarize, the conflicting constraints dictated by the bias-variance dilemma can still be jointly satisfied by letting the scale factor decrease slowly enough as the sample size grows. The resulting estimator converges everywhere to the true PDF in the mean square sense irrespective of the kernel employed, provided that it is squared integrable.  \nThe above results were later extended to the multi-variate case by Cacoullos [15].",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:12",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Estimation of Distribution Algorithms (EDAs) UMDA and BUMDA, which are coupled with Genetic Programming (GP) to create GP-U and GP-B algorithms, what is the high-level approach for analyzing their effectiveness and efficiency?",
      "topics": [
        "genetic"
      ],
      "answer": "The effectiveness and efficiency of the GP-U and GP-B algorithms, which are EDAs (UMDA and BUMDA) reformulated to synchronize with the GP mechanism, are analyzed by comparing them to standard Genetic Programming (GP) with totally random hyperparameter settings. This comparison is conducted through experiments to observe the effect of this reformulation.",
      "chunk_id": 9881,
      "paper_id": "Biomedical Classification Problems Automatically Solved by Computational Intelligence Methods",
      "paper_title": "Biomedical Classification Problems Automatically Solved by Computational Intelligence Methods",
      "paper_year": "2020",
      "chunk_content": "The standard C-SVM considers few hyper-parameters, namely: the penalty factor $C$, and the kernel parameters, such as the decaying parameter $\\gamma$, the degree $n$, and the dilation factor $a$ for the RBF, orthogonal and Wavelet kernels, respectively. The work of Sun et al. [51] is the only one that we have identified that addresses the hyper-parameter tuning of orthogonal kernels (through Grid Search). No studies have been found about the influence of the Wavelet kernel parameters, so the values of the dilation parameter $a$ are taken from the original work [31]. The non-parametric and Linear kernels do not possess parameters. From the analysis of these works, the hyper-parameter setting used to perform tuning is summarized in TABLE V.  \nTwo experiments were performed with the settings described in TABLES III-V. The objective of the first experiment is to analyze the effect (in terms of effectiveness and efficiency) of reformulating an EDA to synchronize with the GP mechanism, which is the main idea of the SEEKS algorithm. Both EDAs detailed in Sect. II, UMDA and BUMDA, were implemented so that three different kernel evolutionary algorithms were compared. These algorithms are referred to as GP, GP-U, and GP-B as short names for the standard Genetic Programming with totally random hyperparameter setting, GP coupled with UMDA and GP coupled with BUMDA, respectively.\nThe second experiment is aimed to observe if there exist improvements in classification performance when varying the terminal set of kernels being evolved. Three different terminal sets were employed: the set of classic kernels (clas $=$ $\\{L, R, P\\}$ ), the set of modern kernels (mod $=$ $\\left\\{K_{-} 11, K_{-} 13, H, E, W, G\\right\\}$ ), and the set of all kernels (all $=$ $\\left\\{L, R, P, K_{-} 11, K_{-} 13, H, E, W, G\\right\\})$.  \nBoth experiments were carried out on the same framework, following the methodology described in LISTING 4. Also, they were performed on an Intel ${ }^{\\circledR}$ Core FORMULA_123 i9-9980XE CPU (18 cores) running at 3.0 GHz and with 16 GB of RAM. The algorithms were implemented in the Java programming language using multithreading, where each thread execute an independent call of the SEEKS algorithm. Experimental results were analyzed with the Python programming language and are reported in the following section. Java and Python codes will be updated in the codes folder in [47].",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:14",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What are the fundamental algorithmic differences in generating new solutions between the Estimation of Distribution Algorithm (EDA) using probabilistic logic sampling (PLS) and the Genetic Algorithm (GA) as described?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Genetic Algorithms",
        "probabilistic logic sampling"
      ],
      "answer": "The EDA, as presented, builds a Gaussian network, estimates its parameters, and then generates new solutions by sampling from this distribution using the probabilistic logic sampling (PLS) method, which is a forward sampling strategy. In contrast, the GA employs selection and recombination, incorporating mutation and crossover operators on a population of individuals, where individuals with better fitness values are more likely to be selected for the next generation. The EDA explicitly models and samples from a probability distribution learned from the population, while the GA relies on bio-inspired operators like crossover and mutation to evolve the population.",
      "chunk_id": 12257,
      "paper_id": "Evaluation of Estimation of Distribution Algorithm to Calibrate Computationally Intensive Hydrologic Model",
      "paper_title": "Evaluation of Estimation of Distribution Algorithm to Calibrate Computationally Intensive Hydrologic Model",
      "paper_year": "2016",
      "chunk_content": "Once the structure of the Gaussian network is built and its parameters estimated, new solutions are generated by sampling from this distribution. In this study, sampling was conducted by using the probabilistic logic sampling (PLS) method (Henrion 1986), which is a forward sampling strategy.  \n[IMAGE_0]  \nFig. 1. Flow chart of (a) the estimation of distribution algorithm (EDA); (b) the genetic algorithm (GA)\nThe replacement method determines how new solutions are incorporated into the previous population. It is an effective way to increase the diversity in the population. In this study, the elitist replacement method was used, which is appropriate for the truncation method in the EDA (Lima et al. 2007). In the elitist replacement method, solutions are ordered according to the ranking of their fitness values and a proportion of the worst are replaced with new solutions. The number of replaced solutions is equal to that of new solutions, keeping the population size unchanged.\nThe GA is a loosely modeled optimization methodology, and is the most widely referenced and used automatic optimization method (Goldberg 1989). It is a population-based heuristic search algorithm, simulating the evolutionary process of natural selection and genetics. As shown in Fig. 1, the GA method employs a population of individuals evolving through selection and recombination, which incorporates mutation and crossover operators. The process iterates, and individuals with better fitness values are selected more easily to the next generation.\nThe SCE algorithm was developed for global optimization problems by simulating the natural evolution. It has been applied widely to automatic calibration of hydrologic models and has been proven to be effective and reliable (Duan et al. 1994; Sorooshian et al. 1993). In the SCE algorithm, the initial population is generated randomly. The population is then divided into several communities represented by complexes in the algorithm. Every community evolves independently and each point has the probability to generate offspring. To ensure the competitiveness of evolution, each individual is assessed by its corresponding objective function value. Better individuals have higher competitiveness contributing to reproduction. After several generations, communities are updated through a process of shuffling. This procedure shares the information contained in every community and the searching space is thoroughly explored.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:16",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model, specifically focusing on population initialization and probabilistic model construction?",
      "topics": [
        "heuristic"
      ],
      "answer": "The EDA model execution includes initializing the population using an efficient scheme based on special cases and a heuristic algorithm. Subsequently, a probabilistic model is created based on elite solutions from each generation. To maintain population diversity, mutation is embedded within the algorithm.",
      "chunk_id": 671,
      "paper_id": "Improved estimation of distribution algorithm for the problem of single-machine scheduling with deteriorating jobs and different due dates",
      "paper_title": "Improved estimation of distribution algorithm for the problem of single-machine scheduling with deteriorating jobs and different due dates",
      "paper_year": "2014",
      "chunk_content": "Hua-Ping Wu _ Min Huang\nThis paper investigates single-machine scheduling problem, which is an NP-hard problem, with deteriorating jobs and different due dates to minimize total tardiness. First, two special polynomially solvable cases of the problem and a mixed-integer programming (MIP) model are proposed. Since the large-scale problem needs a long time when the MIP is solved using the CPLEX, the improved estimation of distribution algorithm (EDA) is proposed to solve the problem with a large size. EDA depends on the probabilistic model, which denotes the distribution of decision variables in the feasible region space. Meanwhile, EDA owns efficient search capability and convergence. To obtain an improved initial population, an efficient initialization scheme based on the feature of two special cases and a heuristic algorithm are adopted in the process of constructing the initial population. The probabilistic model is composited based on elite solutions from each generation. Simultaneously, mutation is embedded to maintain the diversity of the population. Compared with the results, numerical experiments show that the proposed algorithm can obtain good near-optimal solutions within a short period.  \nKeywords Single machine $\\cdot$ Deteriorating jobs $\\cdot$ Tardiness $\\cdot$ Estimation of distribution algorithm $\\cdot$ Mixed integer programming model  \nMathematics Subject Classification 00A69  \n[^0]\n[^0]:    Communicated by Jose Mario Martinez.\nH.-P. Wu ( $\\boxtimes$ ) $\\cdot$ M. Huang  \nState Key Laboratory of Synthetical Automation for Process Industries (Northeastern University), College of Information Science and Engineering, Northeastern University, Shenyang 110819, Liaoning, China\ne-mail: wuhuaping2010@126.com\nM. Huang\ne-mail: mhuang@mail.neu.edu.cn",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:17",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when building a Bayesian network in algorithms like BOA and EBNA?",
      "topics": [
        "complexity"
      ],
      "answer": "BOA uses the K2 metric, based on the Bayesian Dirichlet metric, to assess the network quality. EBNA has been tested with different metrics, including the Bayesian information criterion (BIC) and K2+penalty. The complexity of the learnt model in LFDA is controlled by the BIC criterion in conjunction with the maximum number of incoming edges in the network constraint.",
      "chunk_id": 12404,
      "paper_id": "MONEDA  scalable multi-objective optimization with a neural network-based estimation of distribution algorithm",
      "paper_title": "MONEDA: scalable multi-objective optimization with a neural network-based estimation of distribution algorithm",
      "paper_year": "2016",
      "chunk_content": "A very popular foundation for MOEDAs is a range of EDAs that builds the population model using a Bayesian network. The Bayesian optimization algorithm (BOA) [104], the estimation of Bayesian network algorithm (EBNA) [51] and the learning factorized distribution algorithm (LFDA) [96] are members of this group.  \nThe exhaustive synthesis of a Bayesian network [101] from the algorithm's population is a NP-hard problem. Therefore, the intention behind the above approaches is to provide heuristics for building the network of reasonable computational complexity. BOA uses a socalled K2 metric, based on the Bayesian Dirichlet metric [36], to assess the network quality. A simple greedy algorithm that adds edges in each iteration. EBNA, on the other hand, has been tested with different metrics, like the Bayesian information criterion (BIC) [119], K2+penalty and on testing conditional (in)dependencies between variables. LFDA relies on the greedy algorithm introduced by FDA. The complexity of the learnt model is controlled by the BIC criterion in conjunction with the maximum number of incoming edges in the network constraint.  \nMost BOA-based MOEDAs are a combination of a BOA-based model-building scheme with an already existing Pareto-based fitness assignment. This is the case of the multiobjective BOA (mBOA) [70] that exploits the fitness assignment used in NSGA-II. A later algorithm based on hierarchical BOA (hBOA) [102, 103, 106], called mhBOA [69] also used the same form of fitness assignment. A similar idea is proposed in [81,97], where the mixed BOA (mBOA) [98] is combined with the SPEA2 selection scheme to form the multi-objective mBOA (mmBOA).  \nMulti-objective real BOA (MrBOA) [1] also extends a preexisting EDA, in this case the real BOA (rBOA) [3]. RBOA performs a proper problem decomposition by means of a Bayesian factorization and probabilistic building-block crossover. To do this, it employs mixture models at the level of subproblems. MrBOA combines the fitness assignment of NSGA-II with rBOA.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:19",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of using Bayesian networks within the framework of Estimation of Distribution Algorithms, particularly concerning the estimation and generation of solutions?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary purpose is to model the joint probability distribution of promising solutions by constructing a Bayesian network. This network, defined by directed acyclic graphs, encodes probabilistic relationships between variables $X_i$, allowing for the generation of new candidate solutions that reflect the properties of the given data. The construction of the network estimates the joint distribution $p(X)=\\prod_{i=0}^{n-1} p(X_{i} | \\Pi_{X_{i}})$, while generating instances uses this distribution to create new solutions, effectively addressing the core challenges in EDAs.",
      "chunk_id": 6541,
      "paper_id": "Linkage Problem",
      "paper_title": "Linkage Problem, Distribution Estimation, and Bayesian Networks",
      "paper_year": "2000",
      "chunk_content": "Bayesian networks (Howard and Matheson, 1981; Pearl, 1988) are often used for modeling multinomial data with both discrete and continuous variables. A Bayesian network encodes  \n[IMAGE0]  \n$$\np(X)=p\\left(X_{0}\\right) \\cdot p\\left(X_{1} \\mid X_{0}\\right) \\cdot p\\left(X_{2} \\mid X_{0}, X_{1}\\right) \\cdot p\\left(X_{3} \\mid X_{1}\\right)\n$$  \nFigure 2: A simple example of a Bayesian network and the encoded joint distribution.\nthe probabilistic relationships between the variables contained in the modeled data. It represents the structure of a problem. Bayesian networks can be used to describe the data as well as to generate new instances of the variables with similar properties as those of given data. Each node in the network corresponds to one variable. Both the variable and the node corresponding to this variable will be denoted in this text by $X_{i}$. The relationship between two variables is represented by an edge between the two corresponding nodes. The edges in Bayesian networks can be either directed or undirected. In this paper, only Bayesian networks represented by directed acyclic graphs will be considered. The modeled data sets will be defined within discrete domains.  \nMathematically, an acyclic Bayesian network with directed edges encodes a joint probability distribution. This can be written as  \n$$\np(X)=\\prod_{i=0}^{n-1} p\\left(X_{i} \\mid \\Pi_{X_{i}}\\right)\n$$  \nwhere $X=\\left(X_{0}, \\ldots, X_{n-1}\\right)$ is a vector of all the variables in the problem, $\\Pi_{X_{i}}$ is the set of parents of $X_{i}$ in the network (the set of nodes from which there exists an edge to $X_{i}$ ), and $p\\left(X_{i} \\mid \\Pi_{X_{i}}\\right)$ is the conditional probability of $X_{i}$ conditioned on the variables FORMULA_22. A directed edge relates the variables so that in the encoded distribution, the variable corresponding to its ending node will be conditioned on the variable corresponding to its starting node. More incoming edges into a node result in a conditional probability of the corresponding variable with conjunctional condition containing all its parents. A simple example of a Bayesian network and the joint distribution encoded by this network can be found in Figure 2.  \nThe network, i.e., the relationships between the variables, can be either known or unknown. If the network is known, the joint distribution encoded by the network can be used to generate new candidate solutions throughout whole optimization. If the network is unknown, i.e., we don't know which variables are correlated or there is some uncertainty about that, the network has to be determined as well. The following sections address the two important questions:  \n- How to determine the network that would serve as a good model for a given data set?\n- How to use the network to generate new instances that would best match the given data?  \nNote that the two questions above directly correspond to the two questions arising with the use of EDAs. Constructing the Bayesian network for a given set of promising solutions corresponds to estimating their joint distribution. Generating new instances according to the constructed network is, in fact, generating new solutions according to the joint distribution encoded by this network.",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:21",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of selecting an EDA algorithm with global search capability influence the solution finding process, as compared to traditional Model Predictive Control (MPC) methods?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The text indicates that an EDA algorithm with global search capability is selected as the solver to guide the evolution toward the optimal solution by making full use of the statistical information of each individual. This approach contrasts with traditional MPC, which, in this instance, uses a Markov chain model without self-update and a shooting method to obtain candidate solutions. The proposed strategy, employing the EDA, achieves a shorter computational time (289 s) compared to the traditional MPC (421 s) because it leverages the statistical information to efficiently navigate the search space.",
      "chunk_id": 1488,
      "paper_id": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_title": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_year": "2022",
      "chunk_content": "[IMAGE19]  \nFig. 14. RMSE and standard deviation of the velocity forecast results.  \nTABLE VI\nEVALUATION RESULTS OF ALGORITHMIC PERFORMANCE  \namong these methods. Compared to the ECMS strategy, the proposed strategy allows the distribution of the engine working points to be more reasonable. Therefore, sound fuel economy is achieved by the proposed strategy.\nTo evaluate the algorithmic performance, the traditional MPC is selected to make a comparison with the proposed strategy. In the traditional MPC, velocity forecasting is realized by using the Markov chain model without self-update, and the shooting method is selected to obtain the candidate solutions. When the WVCITY cycle was repeated four times, the RMSE and standard deviation of the velocity forecast results are shown in Fig. 14. It is observed that as the prediction horizon increases from 5 to 15 s , the RMSE in the Markov chain model without self-update grows from 1.914 to $7.136 \\mathrm{~km} / \\mathrm{h}$, whereas the RMSE of the velocity forecast with the self-update mechanism only grows from 1.302 to $6.236 \\mathrm{~km} / \\mathrm{h}$. The standard deviations for these two forecasting methods in the 5 s forecasting situation are relatively small, approximately 0.51 and 0.29 , respectively. As the horizon increases, the prediction results become less precise for both methods. This is because under the Markov chain model, the causal link between predicted and current velocities is ambiguous, especially in the larger predictive horizon. Regardless, the proposed strategy obtains better prediction accuracy than the traditional MPC in the same horizon through the recursive mechanism.  \nThe evaluation results between traditional MPC and the proposed strategy are summarized in Table VI. The total cost of the traditional MPC is 37.47 CNY over the $4 \\times$ WVCITY cycle, whereas the total cost of the proposed strategy is reduced by $4.93 \\%$ in comparison with that of traditional MPC. More importantly, the computational time that each method takes to obtain the optimal solution is critical, especially if targeting a real-time application where computational resources on board  \n[IMAGE20]  \nFig. 15. Framework of the HIL test bench.  \nTABLE VII\nTECHNICAL DESCRIPTION OF THE MODULES  \nare limited. The computational time of traditional MPC is 421 s over the testing cycle, while the value of the proposed strategy is only up to 289 s . It can be noted that the elapsed time with the proposed strategy is shorter than that of traditional MPC, whose reduction is up to FORMULA_157. The reasons for these achievements can be summarized as follows: first, more accurate short-term velocity prediction is the basis of the energy management of PHEBs based on MPC, and second, the EDA algorithm with global search capability is selected as the solver to guide the evolution toward the optimal solution by making full use of the statistical information of each individual. To summarize, the proposed strategy with the shorter computational time requirement exhibits outstanding fuel savings ability.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:23",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the EDA named UMDA to estimate the population distribution, given that it assumes no interrelation among variables?",
      "topics": [
        "fitness"
      ],
      "answer": "For the Univariate Marginal Distribution Algorithm (UMDA), the implementation requires factorizing the n-dimensional joint probability distribution \\(p_{l}(\\mathbf{x})\\) as a product of n-univariate and independent probability distributions \\(p_{l}(x_{i})\\). Each univariate marginal distribution is estimated from marginal variables using the formula \\(p l(\\mathbf{x})=\\frac{\\sum_{j=1}^{N} \\delta_{i}\\left(X_{i}=x_{i} \\mid D_{j}^{\\text {Selected }}\\right)}{N}\\), where \\(\\delta_{i}\\left(X_{i}=x_{i} \\mid D_{j}^{\\text {Selected }}\\right)=1\\) if the \\(j^{\\text {th }}\\) gene of the selected population \\(D_{j}^{\\text {Selected }}\\) is \\(X_{i}=x_{i}\\) and 0 otherwise, and N is the number of selected individuals.",
      "chunk_id": 407,
      "paper_id": "An Estimation-of-Distribution Algorithm Approach to Redundancy Allocation Problem for a High-Security System. IEEJ",
      "paper_title": "An Estimation-of-Distribution Algorithm Approach to Redundancy Allocation Problem for a High-Security System",
      "paper_year": "2014",
      "chunk_content": "$$\np l(x)=\\prod_{i=1}^{n} p l\\left(x_{i}\\right)\n$$  \n4.1.2 Objective Function The objective function or fitness function has been applied to transform the constrained problem into a non-constrained problem, by including a penalty function in the objective function to restrict infeasible solutions for any violation of the constraints. To guarantee the efficiency of the optimal solution for high constrained solutions, this function is used to calculate the fitness values of the solutions obtained in each generation.  \n$$\n\\operatorname{evalf}(\\mathbf{x})=A(\\mathbf{x}) \\times q(\\mathbf{x})\n$$  \nwhere, $A(\\mathbf{x})$ and $q(\\mathbf{x})$ are the system availability and penalty functions, respectively. We calculate the value of $q(\\mathbf{x})$ for each individual. The penalty approach here adjusts the ratio of penalties adaptively at each generation to achieve a balance between the preservation of information, the selective pressure for infeasibility and the avoidance of excessive penalization.\n4.1.3 Estimation In the EDA, a Gaussian distribution algorithm is usually used in the following for estimating the population distribution:  \n$$\np_{l}(\\mathbf{x})=p l\\left(\\mathbf{x} \\mid D_{l}^{S \\text { selected }}\\right)=\\prod_{i=1}^{n} p_{l}\\left(x_{i}\\right)\n$$  \nHowever, the UMDA does not consider any dependencies between its variables ${ }^{(21)}$. The problems are assumed to have no interrelation among the variables. Hence, the $n$ dimensional joint probability distribution is factorized as a product of $n$-univariate and independent probability distribution ${ }^{(7)}$. The $n$-dimensional joint probability distribution $p_{l}(\\mathbf{x})$ factorizes as a product of $n$-univariate and independent probability distributions $p_{l}\\left(x_{i}\\right)$, that is $p l$, where $x_{i}(i=1, \\cdots, n)$ represents the individual of $n$ genes and $D_{l}$ denotes the population of individuals selected from the population in the $l_{t h}$ generation. Similarly, $D_{l}^{N}$ represents the population of the $N$ individuals selected from $D_{l}$. This joint probability must be estimated every generation from one individual $\\mathbf{x}$ being  \namong the selected individuals. Therefore, each univariate marginal distribution is estimated from marginal variables as follows:  \n$$\np l(\\mathbf{x})=\\frac{\\sum_{j=1}^{N} \\delta_{i}\\left(X_{i}=x_{i} \\mid D_{j}^{\\text {Selected }}\\right)}{N}\n$$  \nwhere $\\delta_{i}\\left(X_{i}=x_{i} \\mid D_{j}^{\\text {Selected }}\\right)=1$ if $j^{\\text {th }}$ of the $D_{j}^{\\text {Selected }} i^{\\text {th }}$ gene is $X_{i}=x_{i}$ and 0 otherwise.\n4.1.4 Sampling Function Once the probabilistic model has been estimated from the selected individuals the model is sampled to generate new individuals (new solutions). In this research the new population is sampled from a univariate Gaussian model. The objective is to sample new individuals that concentrate around the optimum solution.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:25",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, how does the matrix cube, denoted as \\(\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}\\), capture and retain information about job order and job block distribution within the selected superior solutions, and what is the significance of the submatrices \\(\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\boldsymbol{x})\\) in this process, given that \\(n\\) represents the number of jobs and \\(gen\\) represents the generation number?",
      "topics": [
        "mutation"
      ],
      "answer": "The matrix cube \\(\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}\\) captures job order and job block distribution by recording the frequency of job \\(\\pi_{\\text {Shoor }}^{\\text {gen }, k}(x+1)\\) appearing immediately after job \\(\\pi_{\\text {Shoor }}^{\\text {gen }, k}(x)\\) at position \\(x\\) in superior solutions, using the indicator function \\(I F_{n \\times n \\times n}^{\\text {gen }, k}(x, y, z)\\) which is 1 if job \\(y\\) is at position \\(x\\) and job \\(z\\) is at position \\(x+1\\), and 0 otherwise. The matrix \\(\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(x, y, z)\\) sums these indicators across all superior solutions, providing a count of each job pair \\((y, z)\\) at each position \\(x\\). The submatrices \\(\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\boldsymbol{x})\\), which are two-dimensional submatrices, record the characteristic information about job order and job block distribution at the \\(x\\)th position in all superior solutions, effectively determining the priority of each job and the distribution of the job block \\([\\boldsymbol{y}, \\boldsymbol{z}]\\) at that position, thus retaining total order relationships via the series of position-based submatrices \\(\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\mathbf{1}), \\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\mathbf{2}), \\ldots \\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\boldsymbol{n})\\).",
      "chunk_id": 2040,
      "paper_id": "A matrix-cube-based estimation of distribution algorithm for blocking flow-shop scheduling problem with sequence-dependent setup times",
      "paper_title": "A matrix-cube-based estimation of distribution algorithm for blocking flow-shop scheduling problem with sequence-dependent setup times",
      "paper_year": "2022",
      "chunk_content": "In general, permutation-based solutions have a number of distinguishing features, including the priority order of jobs and the distribution characteristics of job blocks. In this subsection, a multidimensional probabilistic model is proposed to capture promising patterns and adequately accumulate valuable structural information, which can effectively drive the search toward high-quality regions.\n$\\pi_{\\text {Shoor }}^{\\text {gen }, k}(x+1)$ that appears immediately after the job $\\pi_{\\text {Shoor }}^{\\text {gen }, k}(x)$ located at the $x$ th position in $\\boldsymbol{\\pi}_{\\text {Shoor }}^{\\text {gen }, k}$ can be recorded separately by using the indicator function $I F_{n \\times n \\times n}^{\\text {gen }, k}(x, y, z)$, as given in Eq. (20).  \n$$\n\\begin{gathered}\nI F_{n \\times n \\times n \\times n}^{\\text {gen }, k}(x, y, z)=\\left\\{\\begin{array}{c}\n1, \\text { if } y=\\boldsymbol{\\pi}_{\\text {Shoor }}^{\\text {gen }, k}(x) \\text { and } z=\\boldsymbol{\\pi}_{\\text {Shoor }}^{\\text {gen }, k}(x+1) \\\\\n0, \\text { else } \\\\\nx=1, \\ldots, n-1 ; y, z=1, \\ldots, n ; k=1, \\ldots, \\text { spsize }\n\\end{array}\\right. \\text {, }\n\\end{gathered}\n$$  \nThen, the characteristic information about the order of jobs and the  \ndistribution of blocks for each of the selected superior solutions is obtained based on Eq. (21).  \n$$\n\\begin{aligned}\n& M C_{n \\times n \\times n}^{\\text {gen }}(x, y, z)=\\sum_{k=1}^{n p n \\times p} I F_{n \\times n \\times n}^{\\text {gen }}(x, y, z) \\\\\n& \\quad x=1, \\ldots, n-1 ; y, z=1, \\ldots, n\n\\end{aligned}\n$$  \nFinally, the detailed definition of the proposed matrix cube is described below.  \n$$\n\\begin{aligned}\n& M C_{n \\times n \\times n}^{\\text {gen }}(x, y)=\\left[M C_{n \\times n \\times n}^{\\text {gen }}(x, y, 1), M C_{n \\times n \\times n}^{\\text {gen }}(x, y, 2), \\ldots, M C_{n \\times n \\times n}^{\\text {gen }}(x, y, n)\\right]_{1 \\times n} \\\\\n& x=1,2, \\ldots, n-1 ; y=1,2, \\ldots, n \\\\\n& M C_{n \\times n \\times n}^{\\text {gen }}(x)=\\left[\\begin{array}{c}\nM C_{n \\times n \\times n}^{\\text {gen }}(x, 1) \\\\\n\\vdots \\\\\nM C_{n \\times n \\times n}^{\\text {gen }}(x, n)\n\\end{array}\\right]_{n=1}^{x} \\\\\n& =\\left[\\begin{array}{ccc}\nM C_{n \\times n \\times n}^{\\text {gen }}(x, 1,1) & \\cdots & M C_{n \\times n \\times n}^{\\text {gen }}(x, 1, n) \\\\\n\\vdots & \\ddots & \\vdots \\\\\nM C_{n \\times n \\times n}^{\\text {gen }}(x, n, 1) & \\cdots & M C_{n \\times n \\times n}^{\\text {gen }}(x, n, n)\n\\end{array}\\right]\n\\end{aligned}\n$$  \nAccording to Eq. (23), the two-dimensional submatrix $\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\boldsymbol{x})$ can record the characteristic information about job order and job block distribution at the $x$ th position in all superior solutions. In other words, the matrix cube structure can exactly determine the priority of each job and the distribution of the job block $[\\boldsymbol{y}, \\boldsymbol{z}]$ located in the $x$ th position of the $k$ th individual in $\\boldsymbol{S P o p}(\\boldsymbol{g e n})$, i.e., $\\left[\\pi_{\\text {Shor }}^{\\text {gen }}(x), \\pi_{\\text {Shor }}^{\\text {gen }}(x+1)\\right]$, it can retain total order relationships via a series of position-based submatrices, i.e., $\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\mathbf{1}), \\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\mathbf{2}), \\ldots \\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}(\\boldsymbol{n})$. Thus, these advantageous characteristics or promising patterns derived from superior solutions can be effectively and intuitively recognized and retained. By adopting the matrix cube $\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}$ described above, the multi-dimensional probabilistic model can be established. To illustrate the proposed $\\boldsymbol{M C}_{n \\times n \\times n}^{\\text {gen }}$, an example of five superior solutions (quize $=5$ ) containing four jobs $(n=4)$ is used to instantiate it. In this case, the size of $\\boldsymbol{S P o p}(\\boldsymbol{g e n})$ is quize $=5$ and gen $=1$. The selected superior solutions are $\\pi_{\\text {Shor }}^{1,1}=$ $\\left[\\pi_{\\text {Shor }}^{1,1}(1), \\pi_{\\text {Shor }}^{1,1}(2), \\quad \\pi_{\\text {Shor }}^{1,1}(3), \\pi_{\\text {Shor }}^{1,1}(4)\\right]=\\left[\\begin{array}{llll}1, & 2, & 3, & 4\\end{array}\\right], \\quad \\pi_{\\text {Shor }}^{1,1}=$ $\\left[\\pi_{\\text {Shor }}^{1,2}(1), \\pi_{\\text {Shor }}^{1,2}(2), \\quad \\pi_{\\text {Shor }}^{1,2}(3), \\pi_{\\text {Shor }}^{1,2}(4)\\right]=\\left[\\begin{array}{llll}2, & 3, & 1, & 4\\end{array}\\right], \\quad \\pi_{\\text {Shor }}^{1,2}=$ $\\left[\\pi_{\\text {Shor }}^{1,2}(1), \\pi_{\\text {Shor }}^{1,2}(2), \\quad \\pi_{\\text {Shor }}^{1,2}(3), \\pi_{\\text {Shor }}^{1,2}(4)\\right]=\\left[\\begin{array}{llll}3, & 2, & 1, & 4\\end{array}\\right], \\quad \\pi_{\\text {Shor }}^{1,4}=$ $\\left[\\pi_{\\text {Shor }}^{1,4}(1), \\pi_{\\text {Shor }}^{1,4}(2), \\quad \\pi_{\\text {Shor }}^{1,4}(3), \\pi_{\\text {Shor }}^{1,4}(4)\\right]=\\left[\\begin{array}{llll}4, & 3, & 2, & 1\\end{array}\\right], \\quad \\pi_{\\text {Shor }}^{1,5}=$ $\\left[\\pi_{\\text {Shor }}^{1,5}(1), \\pi_{\\text {Shor }}^{1,5}(2), \\pi_{\\text {Shor }}^{1,5}(3), \\pi_{\\text {Shor }}^{1,5}(4)\\right]=\\left[\\begin{array}{llll}4, & 3, & 1,2\\end{array}\\right]$, respectively. For the first position $(x=1)$ of all individuals, it is clear that job blocks [1,2] (i. e., $\\boldsymbol{y}=1, \\boldsymbol{z}=2),[2,3]$ (i.e., $\\boldsymbol{y}=2, \\boldsymbol{z}=3),[3,2]$ (i.e., $\\boldsymbol{y}=3, \\boldsymbol{z}=2$ ), and $[4,3]$ (i.e., $\\boldsymbol{y}=4, \\boldsymbol{z}=3$ ) appeared in these individuals from $\\pi_{\\text {Shor }}^{\\text {gen }, 1}$ to $\\pi_{\\text {Shor }}^{\\text {gen }}$, is recorded in accordance with Eqs. (20)-(23) as follows:  \n$$\n\\begin{aligned}\n& M C_{4 \\times 4 \\times 4}^{1}(1,1,2)=\\sum_{k=1}^{5} I F_{4 \\times 4 \\times 4}^{1,1}(1,1,2)=I F_{4 \\times 4 \\times 4}^{1,1}(1,1,2) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,2}(1,1,2)+I F_{4 \\times 4 \\times 4}^{1,3}(1,1,2)+I F_{4 \\times 4 \\times 4}^{1,4}(1,1,2) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,5}(1,1,2)=1+0+0+0+0=1 \\\\\n& M C_{4 \\times 4 \\times 4}^{1}(1,2,3)=\\sum_{k=1}^{5} I F_{4 \\times 4 \\times 4}^{1,4}(1,2,3)=I F_{4 \\times 4 \\times 4}^{1,1}(1,2,3) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,2}(1,2,3)+I F_{4 \\times 4 \\times 4}^{1,3}(1,2,3)+I F_{4 \\times 4 \\times 4}^{1,4}(1,2,3) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,5}(1,2,3)=0+1+0+0+0=1 \\\\\n& M C_{4 \\times 4 \\times 4}^{1}(1,3,2)=\\sum_{k=1}^{5} I F_{4 \\times 4 \\times 4}^{1,4}(1,3,2)=I F_{4 \\times 4 \\times 4}^{1,1}(1,3,2) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,2}(1,3,2)+I F_{4 \\times 4 \\times 4}^{1,3}(1,3,2)+I F_{4 \\times 4 \\times 4}^{1,4}(1,3,2) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,4}(1,3,2)=0+0+1+0+0=1\n\\end{aligned}\n$$  \n$$\n\\begin{aligned}\n& M C_{4 \\times 4 \\times 4}^{1}(1,4,3)=\\sum_{k=1}^{5} I F_{4 \\times 4 \\times 4}^{1,4}(1,4,3)=I F_{4 \\times 4 \\times 4}^{1,1}(1,4,3) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,2}(1,4,3)+I F_{4 \\times 4 \\times 4}^{1,3}(1,4,3)+I F_{4 \\times 4 \\times 4}^{1,4}(1,4,3) \\\\\n& +I F_{4 \\times 4 \\times 4}^{1,5}(1,4,3)=0+0+0+1+1=2\n\\end{aligned}\n$$  \nThe remaining elements in $\\boldsymbol{M} \\boldsymbol{C}_{4 \\times 4 \\times 4}^{\\text {gen }}(\\mathbf{1})$ are set to zero. Likewise, for the second position $(x=2)$ of all individuals, job blocks $[2,1]$ (i.e., $y=$ $2, z=1),[2,3]$ (i.e., $y=2, z=3),[3,1]$ (i.e., $y=3, z=1)$, and $[3,2]$ (i. e., $\\boldsymbol{y}=3, \\boldsymbol{z}=2$ ) can also be recorded, respectively. Then we have.  \nFORMULA_364",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:29",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "In HEDA, how does the mutation strategy balance exploration and exploitation when generating new individuals?",
      "topics": [
        "mutation"
      ],
      "answer": "In HEDA, the mutation strategy introduces exploration by giving each variable of an individual a probability, denoted as $p_{m}$, to be generated randomly with uniform distribution across the entire search space. Conversely, with a probability of $1-p_{m}$, the variable is generated according to the histogram model, which represents exploitation of the learned distribution.",
      "chunk_id": 6242,
      "paper_id": "Optimizing Continuous Problems Using Estimation of Distribution Algorithm Based on Histogram Model",
      "paper_title": "Optimizing continuous problems using estimation of distribution algorithm based on histogram model",
      "paper_year": "2006",
      "chunk_content": "In HEDA, the population is sampled according to the model as follows: First, the bin $j$ is selected according to the probability of $H^{\\prime}(j)$; then an individual is generated in the searching space of the bin $j$ with uniform distribution.  \nIn order to enhance the diversity of population, mutation strategy is used. In HEDA, the mutation strategy means that each variable of an individual has a probability to be generated randomly. Here \"randomly\" means that the variable of an individual is generated with uniform distribution in the whole searching space. If the mutation rate is set $p_{m}$, that means there is a possibility of $p_{m}$ for each variable of each individual to be generated randomly and a possibility of $1-p_{m}$ for it to be generated according to the histogram model.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:31",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for the HFS-UPM model, what data structures are required to represent the processing sequences of jobs at each stage, and how are these sequences denoted?",
      "topics": [
        "search"
      ],
      "answer": "For the HFS-UPM model, the processing sequence of jobs at stage `j` is represented by $\\pi_{j}$, where $\\pi_{j} = {\\pi_{j}(1), \\pi_{j}(2), \\ldots, \\pi_{j}(i), \\ldots, \\pi_{j}(n) | j \\in \\mathbf{S}}$. Specifically, $\\pi_{j}(i)$ denotes the job processed in the $i$-th position at stage $j$. The set of all stages is denoted by $\\mathbf{S} = {1, 2, \\ldots, j, \\ldots, s}$, where $s$ is the total number of stages and $n$ represents the total number of jobs. Therefore, a suitable data structure would be an array (or list) of arrays (or lists), where the outer array represents the stages and the inner arrays represent the processing order of jobs at that stage. The completion time of job $\\pi_{s}(i)$ at the final stage $s$ on machine $k_{s}$ is denoted by $C_{\\pi_{s}(i), s, k_{s}}$, which may require a separate data structure (e.g., a matrix or a dictionary) to store the completion times for each job on each machine at the final stage.",
      "chunk_id": 9323,
      "paper_id": "An improved gravitational search algorithm to the hybrid flowshop with unrelated parallel machines scheduling problem",
      "paper_title": "An improved gravitational search algorithm to the hybrid flowshop with unrelated parallel machines scheduling problem",
      "paper_year": "2021",
      "chunk_content": "$P_{\\text {size }} \\quad$ the population size, which means the total number of the individuals\n$u p \\quad$ the number of machines at the first stage\ndown an integer with the value 1\n$t_{\\max } \\quad$ maximum number of iterations\n$C R \\quad$ the crossover rate\n$F_{D E} \\quad$ the scaling factor\n$w_{\\max } \\quad$ the maximum value of the weight\n$w_{\\min } \\quad$ the minimum value of the weight\n$i_{a}$ and $j_{a} \\quad$ the serial number of the $i$-th and $j$-th individuals in algorithms $\\left(i_{a} \\neq j_{a}\\right)$;\n$r_{1}, r_{2}, r_{3} \\quad$ three different integers ranging from 1 to $P_{\\text {size }}$.\n$i \\quad$ the serial number of the $i$-th job $(i \\in \\mathbf{J}),($ in the original standard GS algorithm, it means $i$-dimension space)\n$n \\quad$ the original meaning is the dimension of the search space, here it means the total number of the jobs to be machined.\nHFS-UPM Model\nJ the set of jobs, $\\mathbf{J}=\\{1,2, \\ldots, i, \\ldots n\\}$\n$\\mathbf{S} \\quad$ the set of stages, $\\mathbf{S}=\\{1,2, \\ldots, j, \\ldots, s\\}$\n$\\mathbf{M} \\quad$ s sets of machines, $\\mathbf{M}=\\left\\{\\mathbf{M}_{1}, \\mathbf{M}_{2}, \\ldots, \\mathbf{M}_{j}, \\ldots\\right.$, $\\left.\\mathbf{M}_{\\mathrm{s}} \\mid \\mathrm{j} \\in \\mathrm{S}\\right\\}$\n$\\mathbf{M}_{j} \\quad$ the set of machines at the stage $j, \\mathbf{M}_{j}=$ $\\{1,2, \\ldots, k_{j}, \\ldots, m_{j} \\mid 1 \\leq m_{j}<n\\}$\n$\\pi_{j} \\quad$ the processing sequence of jobs at the stage $j$, $\\pi_{j}=\\left\\{\\pi_{j}(1), \\pi_{j}(2), \\ldots, \\pi_{j}(i), \\ldots, \\pi_{j}(n) \\mid j \\in \\mathbf{S}\\right\\}$\n$\\pi_{1} \\quad$ the processing sequence of jobs at the stage one, $\\pi_{1}=\\left\\{\\pi_{1}(1), \\pi_{1}(2), \\ldots, \\pi_{1}(i), \\ldots, \\pi_{1}(n)\\right\\}$\n$\\pi_{s} \\quad$ the processing sequence of jobs at the final stage $s, \\pi_{s}=\\left\\{\\pi_{s}(1), \\pi_{s}(2), \\ldots, \\pi_{s}(i), \\ldots, \\pi_{s}(n)\\right\\}$\n$\\mathbf{C}_{\\pi_{s}(i), s}$ the completion time set of the job $\\pi_{s}(i)$ at the final stage $s, \\mathbf{C}_{\\pi_{s}(i), s}=\\left\\{C_{\\pi_{s}(1), s, k_{s}}, C_{\\pi_{s}(2), s, k_{s}}, \\ldots\\right.$, $\\left.C_{\\pi_{s}(i), s, k_{s}}, \\ldots, C_{\\pi_{s}(n), s, k_{s}} \\mid k_{s} \\in \\mathbf{M}_{s}\\right\\}$\n$\\mathbf{I M}_{j} \\quad$ the idle moment set of the machine $k_{j}$ at the stage $j, \\mathbf{I M}_{j}=\\left\\{I M_{1, j}, I M_{2, j}, \\ldots, I M_{k_{j}, j}, \\ldots\\right.$, $\\left.I M_{m_{j}, j} \\mid j \\in \\mathbf{S}\\right\\}$\nNM the serial numbers of the available machines that can be used at the earliest at each stage, $\\mathbf{N M}=\\left\\{N M_{j} \\mid j \\in \\mathbf{S}\\right\\}$",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:33",
      "generation_style": "implementation_focused"
    },
    {
      "question": "Within the strategic search methodology for the Estimation of Distribution Algorithm (EDA), how are probabilistic vectors, denoted as $\\mathbf{p}$, used to guide the search process in the Outside Clusters Search (OCS) phase, and what mechanism is employed to generate complementary vectors for population initialization?",
      "topics": [
        "complexity"
      ],
      "answer": "In the Outside Clusters Search (OCS) phase, probabilistic vectors $\\mathbf{p}$ are derived from parallel dynamic $K$-means clustering of solutions returned by slave Genetic Algorithms (GAs). These vectors, equivalent to the estimated mean $\\hat{\\mu}$ from the UMDAc model, represent specific regions in the search space. To avoid premature convergence, the master process instructs slaves to initialize populations outside of these identified clusters. This is achieved by generating a complementary vector. If $\\mathbf{p}=\\left(\\hat{\\mu}_{1, j}, \\hat{\\mu}_{2, j}, \\ldots, \\hat{\\mu}_{n, j}\\right)$ represents the probabilistic estimation vector of the $j$-th cluster, the master generates a complementary vector as $\\mathbf{p}=\\left(b-\\hat{\\mu}_{1, j}, b-\\hat{\\mu}_{2, j}, \\ldots, b-\\hat{\\mu}_{n, j}\\right)$, where $b$ equals the upper limit of the search domain if $\\hat{\\mu}_{i, j}>0$, or $b$ equals the lower limit if $\\hat{\\mu}_{i, j} \\leq 0$ within the search domain $[-b, b]$.",
      "chunk_id": 943,
      "paper_id": "ASYNCHRONOUS PARALLEL ALGORITHMS FOR STRATEGIC HYBRID SEARCHING BASED ON A MIXTURE GAUSSIAN MODEL",
      "paper_title": "ASYNCHRONOUS PARALLEL ALGORITHMS FOR STRATEGIC HYBRID SEARCHING BASED ON A MIXTURE GAUSSIAN MODEL",
      "paper_year": "2014",
      "chunk_content": "The order of probabilistic search space exploration (strategy) is of vital importance, as experimentally proved in [12]; hence the master performs this task in four sequentially arranged phases, as follows, to accomplish what we call \"strategic search\".\nWide-range search (WRS): At the beginning of the search in early iterations, the GA population member initialization must be random to explore a much wider area of the search space (the location of the global optimum is entirely unknown).\nOutside clusters search (OCS): When there is a large enough number of solutions returned by the slaves GAs, parallel dynamic $K$-means clustering is performed. The results of clusters are used to form vectors $\\mathbf{p}$ as per the EDA probabilistic model, calculated above as $\\hat{\\mu}$. In our past works cited above, UMDAc was used to model the vector as shown in Equation (4). In the present study, enhancements are made, and Equation (5) is used to calculate the probability distribution vector $\\hat{\\mu}$. The vector represents a specific area within the search space. In this phase, the master instructs slaves to perform initialization outside of clusters to avoid premature convergence (i.e., it uses complements of a determined vector). If $\\mathbf{p}=\\left(\\hat{\\mu}_{1, j}, \\hat{\\mu}_{2, j}, \\ldots, \\hat{\\mu}_{n, j}\\right)$ is the probabilistic estimation vector of the $j$-th cluster, the master generates a complementary vector as $\\mathbf{p}=\\left(b-\\hat{\\mu}_{1, j}, b-\\hat{\\mu}_{2, j}, \\ldots, b-\\hat{\\mu}_{n, j}\\right)$, where $b=$ upper limit of search domain if $\\hat{\\mu}_{i, j}>0$, or $b=$ lower limit if $\\hat{\\mu}_{i, j} \\leq 0$ in $[-b, b]$. Cumulative clustering (CC): In this phase, the same process as in OCS is used to get probabilistic vectors, but with an increased number of solutions to be clustered. Here, the master estimates new vectors at each iteration, and the number of solutions to be clustered in the current iteration is greater than in the previous iteration. The population initialization is done using a vector $\\mathbf{p}=\\left(\\widehat{\\mu}_{\\mathbf{1}, \\mathbf{j}}, \\widehat{\\mu}_{\\mathbf{2}, \\mathbf{j}}, \\ldots, \\widehat{\\mu}_{\\mathbf{n}, \\mathbf{j}}\\right)$ (i.e., within the estimated area). Here, every slave is assigned a specific area to search within the larger search space. Best cluster focusing (BCF): Using the results of CC, the master can make a very good guess where the best solution lies. The qualities of solutions returned by all slaves that have been assigned by different clusters are compared. Hence, a final search is done by all slaves focusing on promising areas using only the $\\mathbf{p}$ value that resulted in the best solutions.  \nIn each of the phases described above, except WRS, every slave is assigned by one probability distribution vector; to initialize a new population for their respective GAs (sampling) they assume a Gaussian distribution with mean $\\mathbf{p}$ and standard deviation calculated by the master for a cluster.  \nRegarding the master-slave model, some limitations are mentioned in [23], but our present approach accepts these limitations in favor of accuracy and algorithm performance (solution quality). When the master process is the backbone of the architecture, it enables better control of probabilistic estimation for the slave initialization process, and in case of failure the slaves will assume random initialization. According to previous studies, creating a network of slaves (migration of chromosomes) helps to boost search performance [24], but we tried to reduce algorithm complexity as well as communication overhead by completely removing inter-slave communication.\n3.3. Parallel processing. In this research we have adopted a shared-memory parallel processing technique using a multi-core processing unit. We use master-slave cooperation to execute, in parallel, an asynchronous strategic hybrid algorithm using a Gaussian mixture model without variable dependency. We also perform, in parallel, dynamic $K$ means clustering in the EDA part of our algorithm during the solution space estimation  \n[IMAGE_2]",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:36",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs using Bayesian Networks (BNEDA) when applied to feature selection?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to verify if incorporating prior knowledge impacts the performance of the proposed BNEDA when applied to feature selection on UCI datasets. Performance is evaluated by comparing the mean accuracy of the proposed methods to the original BOA and reference methods like ALL (no feature selection) and HILL (Hill-climbing wrapper), using paired two-sided t-tests at a 95% confidence level.",
      "chunk_id": 12930,
      "paper_id": "Using prior knowledge to improve the performance of an estimation of distribution algorithm applied to feature selection",
      "paper_title": "Using prior knowledge to improve the performance of an estimation of distribution algorithm applied to feature selection",
      "paper_year": "2005",
      "chunk_content": "This section describes the experiments performed. The purpose of experiments is to verify if the use of prior knowledge actually impacts on the performance of the proposed BNEDA's when applied to 8 data sets from UCI collection [11]. Mean accuracy is observed, and it is straightforward to verify if significant increase occurs, comparing each of the proposed methods to the original BOA (and to the other reference methods) using paired two-sided $t$ tests for each comparison, at a $95 \\%$ confidence level. Table 1 summarizes the data sets used in experiments.  \nTable 1. Data sets used in experiments.  \nThe mean accuracy of the three methods proposed is also compared to other two references, in order to allow a better discussion about the results obtained. These reference methods are (i) do no feature selection\nat all, therefore using all attributes (called the ALL method) and (ii) use a Hill-climbing, non-evolutionary wrapper (called HILL), from the WEKA library [13].  \nThe data sets differ in some aspects. The number of instances ranges widely, from 303 to 3163 , and the characteristics of data vary from the numerical majority to a categorical dominance. The choice of so diverse data sets was motivated by the explicit intention of representing situations which can be found in practical applications, and therefore be able to discuss robustness of the proposed methods. Also, these data sets are often used in benchmark evaluations related to feature selection [15].  \nProposed and reference methods are evaluated through a 5 -fold cross validation, followed by a 2 -fold. In each of five iterations the data set was divided in half - namely halves 1 and 2. Initially, half 1 is used for training and half 2 for validation; afterward the opposite occurs. Therefore, each wrapper is executed 10 times for each data set. For each set of attributes obtained by a wrapper, the performance must be calculated, by recording the accuracy reported by Naive Bayes, for each of the resulting subsets. Accuracy is averaged for each method, when applied to each data set. In order to allow performing paired FORMULA_32 tests, the same 10 partitions are preserved and used in all methods.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:38",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the optimization of a function $f(x) = (f_i(x), \\ldots, f_D(x))$ where $i = 1, \\ldots, D$, subject to constraints $e(x) = (e_i(x), \\ldots, e_J(x)) \\geq 0$, where $j = 1, \\ldots, J$, and $x$ belongs to the set $S$, particularly concerning the concept of Pareto optimality?",
      "topics": [
        "optimization"
      ],
      "answer": "The optimization problem described involves minimizing the function $y = f(x)$ subject to the constraint $e(x) \\geq 0$, where $x$ belongs to the set $S$. The core principle revolves around finding a solution $x^{*}$ within $S$ that is Pareto optimal. A Pareto optimal solution $x^{*}$ is one where it's impossible to improve one objective $f_i(x)$ without worsening at least one other objective $f_j(x)$. The set of all Pareto optimal solutions forms the Pareto Front, representing the best possible trade-offs between the different objectives $f_i(x)$.",
      "chunk_id": 7251,
      "paper_id": "Multi-objective evolutionary of Distribution Algorithm using kernel density estimation model",
      "paper_title": "Multi-Objective Evolutionary of Distribution Algorithm Using Kernel Density Estimation Model",
      "paper_year": "2010",
      "chunk_content": "_______, ________________________________, ____________________,   \n 973 (2009CB320603), __________ (20876044), 863 ____(2008AA042902),_____(09DZ1120400),_________(Project number: B504)  \n_______:\n$y_{i}=f_{i}(x), \\quad i=1, \\ldots, D$\nMinimize $y=f(x)=\\left(f_{i}(x), \\ldots, f_{D}(x)\\right)$\nsubject to $e(x)=\\left(e_{i}(x), \\ldots, e_{J}(x)\\right) \\geq 0$\n$x \\in S$\n,  $y$  $x$ ,  $x$  $P$ \n  $\\left(x_{1}, \\cdots, x_{p}\\right)$,       $J$    : $e_{j}(x) \\geq 0, \\quad j=1, \\ldots, J: S$ ________  \n_______________,___________ $x^{*} \\in S$ , $S$ ___ $x^{*}$ , $x^{*}$ _____ Pareto ______________ $f(x)$ , Pareto ___ Pareto , Pareto _______________ Pareto (Pareto Front)____________________ Pareto _____________",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:40",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm (EDA) to optimize an additively decomposed function (ADF) with constraints, how should practitioners factorize the probability distribution P(X) to generate new individuals, specifically defining the sets d_i, b_i, and c_i, and what is the significance of the running intersection property in this factorization?",
      "topics": [
        "optimization"
      ],
      "answer": "To factorize the probability distribution P(X) in an EDA for an ADF, first define \\$d_{i}=\\bigcup_{j=1}^{i} S_{j}\\$, \\$b_{i}=S_{i} \\backslash d_{i-1}\\$, and \\$c_{i}=S_{i} \\cap d_{i-1}\\$, where \\$S_i\\$ represents the \\$i\\$th variable set and \\$d_0 = \\phi\\$. This yields the factorization \\$P(X)=\\prod_{i=1}^{l} P(x_{b_{i}} \\mid x_{c_{i}})\\$. The running intersection property, requiring that \\$b_{i} \\neq \\phi, \\forall i=1, \\cdots l; d_{l}=X\\$ and \\$\\forall i \\geq 2, \\exists j<i\\$ such that \\$c_{i} \\subseteq S_{j}\\$, ensures the factorization is exact. While satisfying this property is generally desirable, the algorithm can still function effectively even if it's violated, though the factorization may then become inexact.",
      "chunk_id": 13302,
      "paper_id": "History information based optimization of additively decomposed function with constraints",
      "paper_title": "History information based optimization of additively decomposed function with constraints",
      "paper_year": "2004",
      "chunk_content": "The constraint problem we discuss here is defined as the following:  \n$$\n\\begin{aligned}\n& \\max f(X)=\\sum_{i} f_{i}\\left(S_{i}\\right) \\\\\n& \\text { s.t. } C_{i}\\left(S_{i}\\right)\n\\end{aligned}\n$$  \nwhere $X=\\left\\{x_{1}, \\cdots, x_{n}\\right\\}$ and the value of the $i$ th variable belongs to the set $\\left\\{x_{i, 1}, \\cdots, x_{i, n_{i}}\\right\\} . C_{i}\\left(S_{i}\\right)$ stands for the $i$ th constraint function (it may be equality or inequality) and the variable set $S_{i} \\subseteq X(i=1, \\cdots, l)$. The function $f(x)$ is called additively decomposed function (ADF). This class of functions is of great theoretical and practical importance. Optimization of an arbitrary function in this space is NP complete.  \nEvolutionary computation (EC) is widely used for constraint optimization [1]. This method is loosely based on the mechanics of artificial selection and genetic recombination. Two crucial factors of the EC success, a proper growth and mixing of good building blocks, are often not achieved [2]. The problem of building block disruption is often referred to as the linkage problem [3]. Various attempts to prevent the disruption of important partial solutions have been done. One way to generate new individuals is to use the information extracted from the entire set of promising solutions. A general scheme of the algorithms based  \non this principle is called the estimation of distribution algorithm (EDA) 4 . The main problems of EDA are how to estimate the distribution and how to get new individuals by this distribution. EDA is used successfully not only for unconstrained optimization but also for constrained optimization [5].  \nAlthough EDA is used successfully in real application, it also has the shortcoming of large population size. One of the reasons is that EDA only uses the information of the selected population and does not use any information of the population before selection. In this paper a history information based algorithm is proposed to solve additively decomposed function with constraints. We called this new algorithm as HCFA (History information based Constraint Factorization Algorithm). The main advantage of HCFA is that it can get good results with small population size. It can always produce feasible solutions if the individuals of the initial population are all feasible by using a factorization of the distribution of selected points. It can handle not only linear constraints but also nonlinear constraints. The paper is organized as follows. Section 2 gives the frame of the algorithm. In section 3, some important topics, including initialization and feasibility are discussed. Some numerical results are given in section 4 to show the efficiency of the algorithm.\nTo solve the problem, we must get a factorization of the probability of distribution at first. For convenience, just suppose $X=\\bigcup_{i=1}^{l} S_{i}$. Define  \n$$\nd_{i}=\\bigcup_{j=1}^{i} S_{j}, b_{i}=S_{i} \\backslash d_{i-1}, c_{i}=S_{i} \\cap d_{i-1}\n$$  \nSet $d_{0}=\\phi$ and then we get the factorization as  \n$$\nP(X)=\\prod_{i=1}^{l} P\\left(x_{b_{i}} \\mid x_{c_{i}}\\right)\n$$  \nLet's see an example. Suppose $X=\\left\\{x_{1}, x_{2}, x_{3}\\right\\}, x_{i} \\in\\{0,1\\}$ and the constraint functions are:  \n$$\n\\begin{aligned}\n& x_{1}+x_{2} \\leq 1 \\\\\n& x_{2}+x_{3} \\leq 1\n\\end{aligned}\n$$  \nThen we have  \n$$\nS_{1}=\\left\\{x_{1}, x_{2}\\right\\}, S_{2}=\\left\\{x_{2}, x_{3}\\right\\}\n$$  \nSo the factorization is  \n$$\nP(X)=P\\left(x_{1}, x_{2}\\right) P\\left(x_{3} \\mid x_{2}\\right)\n$$  \nIf  \n$$\n\\begin{gathered}\nb_{i} \\neq \\phi, \\forall i=1, \\cdots l ; d_{l}=X \\\\\n\\forall i \\geq 2, \\exists j<i \\text { such that } c_{i} \\subseteq S_{j}\n\\end{gathered}\n$$  \nwe say the factorization satisfy the running intersection property. At this condition, FORMULA_21 really holds [6].  \nIf the running intersection property is violated the factorization might not be exact. But we will show the running intersection property is not necessary by the numerical examples.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:43",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the UMDA algorithm discussed, under what mathematical conditions related to population size does the algorithm converge to the global optimal solution?",
      "topics": [
        "genetic"
      ],
      "answer": "The UMDA algorithm is described as converging to the global optimal solution when the population size, denoted as K, is sufficiently large. Specifically, K should be approximately equal to the square root of the total number of candidate solutions. If there are a total of $\\prod_{i=1}^{N} M_{i}$ candidate solutions, where $M_{i}$ represents the number of possible values for gen $G_{i}$, then K should be approximately equal to the square root of $\\prod_{i=1}^{N} M_{i}$ to ensure convergence to the global optimum.",
      "chunk_id": 4858,
      "paper_id": "Global Optimal Selection of Web Composite Services Based on UMDA",
      "paper_title": "Global Optimal Selection of Web Composite Services Based on UMDA",
      "paper_year": "2012",
      "chunk_content": "In the first step, the population size K should be determined. According to the research between the learning parameter and problem of the UMDA by Shapiro[14], only when the population size is huge enough, the UMDA algorithm can converge to the global optimal solution. The tests of the practical problems show that the population size should be the square root of the amount of the candidate solution. If there are total $\\prod_{i=1}^{N} M_{i}$ candidate solutions of service selection, in order to make the  \nalgorithm converge to the global optimal solution, K should be approximately equal the square root of it.  \nIn the second step, the initial probability of every possible value of every gen $G_{i}$ should be determined. If users don't have any preference about certain service in the candidate $S e t_{i}$, the chance of every service is the same. In that case, if the service in $S e t_{i}$ is chosen, the chance of every possible value of $G_{i}$ is the same, and it will be showed as follow:  \n$$\nP\\left(G_{i}=j\\right)=\\frac{1}{M_{i}}, j=1 \\sim M_{i}\n$$  \nIf the users have certain preference, and could give the probability of every candidate, the initial probability of every possible value comes from users. But in the practice, although the users have the preference about some services, the users can't give the exact probability of every candidate service, especially when the amount of the candidate services is huge. The local optimal selection algorithm is used to calculate the QoS of every candidate service and the sum of QoS of every candidate service, and the probability of every candidate service will be calculated by certain formula.  \n$$\nP\\left(G_{i}=j\\right)=\\frac{Q S_{i j}}{\\sum_{j=1}^{M_{i}} Q S_{i j}}, j=1 \\sim M_{i}\n$$  \nIn the third step, in every candidate service $S e t_{i}$, according to the probability of every candidate service, roulette algorithm is used K times for sampling to get the initial population.\nIt is applicable that the fitness function is the same with the object function, which means when the constraint conditions are satisfied, and the composite QoS of composite services influenced by the engine is taken into account, the formula is:  \n$$\nf(c w s)=\\sum_{k=1}^{t} \\omega_{k} \\times Q f_{k}(c w s)\n$$  \nBecause the amount of the composite schemes is too huge to calculate all the QoS of the possible composite services, $\\omega_{k}$ is given directly by the users, not by the objective data, which is different from the method of the local optimal selection algorithm.\nThe selection mechanism is the foundation of the probability updating. Numbers of the distribution relations inherited from the old generation population by the new  \ngeneration population are called selection pressure, which depends on selection mechanism. In the case that the proper selection mechanism is chosen, the selection pressure will keep population diversity and increase the possibility of the global optimal converging. It can also guarantee the high amount of the optimal entities during the evolution, and the algorithm converges fast. Similar with the genetic algorithm, the selection mechanisms of the EDA include sorting algorithm, roulette algorithm, tournament selection algorithm, and random traversal sampling algorithm.  \nThe paper uses the sorting algorithm. First, the QoS of the composite services of every entity of the population is calculated, and those unsatisfied with the constraint condition will be discarded. Then, after calculating the fitness values of the left entities by the fitness function, the fitness values will be sorted from maximum to minimum, and the excellent ones with high fitness value will be selected according to certain rate. In order to keep the population diversity, the rate should be around FORMULA_56.\nAccording to values of the gens of the selected optimal entities, the frequencies of the values of every gen are calculated. The probabilities of values of every gen are updated by the value calculated as the frequencies divided by total amount of the optimal entities. According to the new probabilities, every gen will be sampled K times by the roulette algorithm, and there will be K new entities then, which will form a new generation population.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:45",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of sEDA compare to $\\mathrm{UMDA}_{c}$ and $\\mathrm{EMNA}_{\\text {global }}$ when considering artificial test functions and real-world problems like the CiaS problem?",
      "topics": [
        "EDAs"
      ],
      "answer": "sEDA demonstrates significantly better performance than $\\mathrm{UMDA}_{c}$ and $\\mathrm{EMNA}_{\\text {global }}$ in most cases when evaluated on artificial test functions and real-world problems such as the CiaS problem. This improved performance is attributed to better selection of variables for covariance modeling. Additionally, sEDA provides insights into variable dependency and importance without exhibiting ill-posed covariance matrices during modeling.",
      "chunk_id": 5291,
      "paper_id": "Variable Screening for Reduced Dependency Modelling in Gaussian-based Continuous Estimation of Distribution Algorithms",
      "paper_title": "Variable Screening for Reduced Dependency Modelling in Gaussian-based Continuous Estimation of Distribution Algorithms",
      "paper_year": "2012",
      "chunk_content": "This paper analysed classical EDAs over continuous variables in terms of dependency of variables and modelling and presented numerical issues as well as common difficulties w.r.t. performance of the model. Using different techniques and theoretical analysis, we have proposed a Gaussian based continuous EDA, called sEDA, a mechanism to control the amount of covariance parameters estimated within the Gaussian model, which clearly gives an idea about the number of dependent variables and important of these variables in a problem. A simple  \nimplementation of this framework, sEDA, has been experimentally compared with $\\mathrm{UMDA}_{c}$ and $\\mathrm{EMNA}_{\\text {global }}$. While considering artificial test functions and real world problems (CiaS problem), sEDA showed significantly better performance in most of the cases. Most of the results are better primarily due to better selection of variables for covariance modelling. The role of FORMULA_187 is significant if we can know the nature of variables in a problem. The main advantage of sEDA is not only finding a good solution with less number of population, but also gives an idea of variable dependency and importance of the problem. Moreover, it doesn't show ill posed covariance matrix while modelling.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:47",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model within the Pittsburgh-style Learning Classifier System (LCS) described, specifically detailing the interaction between the rule-wise and rule set-wise levels?",
      "topics": [
        "crossover",
        "Estimation of Distribution Algorithms",
        "Pittsburgh-style Learning Classifier Systems"
      ],
      "answer": "The Pittsburgh-style LCS with EDA operates with two levels: rule-wise and rule set-wise. At the rule-wise level, single rules are produced by sampling Bayesian networks. These networks characterize global statistical information extracted from promising single rules. The sampled rules are then assembled to form rule sets for prediction. At the rule set-wise level, the process resembles a classic Genetic Algorithm (GA) cycle. A key step is the crossover operator, which recombines classifiers using rule-wise uniform crossover to maintain the semantics of rules within each classifier. This two-level approach allows for both exploration of individual rules and exploitation of complete rule sets.",
      "chunk_id": 5022,
      "paper_id": "Effective search for Pittsburgh learning classifier systems via estimation of distribution algorithms",
      "paper_title": "Effective search for Pittsburgh learning classifier systems via estimation of distribution algorithms",
      "paper_year": "2012",
      "chunk_content": "The proposed algorithm is described in detail in this section. The basic procedure of Pittsburgh-style LCSs is listed in Algorithm 1. As discussed in Section 2.1, each individual (i.e., classifier) is represented as a rule set to encode an entire solution, in which the number of rules are not identical to each other. (In the remainder of this paper, the terms individual and classifier are used interchangeably.) Therefore, there is no cooperation among individuals and only competition is performed in the typical cycle of GAs. The main peculiarity of our method lies in lines 6 and 7 in Algorithm 1, in which evolution and evaluation of classifiers are performed at two levels based on BOA. One level, called rule-wise level, deals with rules in classifiers. And the other, called rule set-wise level, handles rule sets (i.e., classifiers). Fig. 2 shows the framework of our method. The main steps at the two levels are represented above and below the dashed line, respectively. In the remainder of this section, we first represent the design of classifiers in our method, then the evaluation and evolution of classifiers at the two levels will be discussed, respectively.  \nAlgorithm 1. Basic procedure of Pittsburgh-style LCSs  \n  \n[IMAGE2]  \nFig. 2. In the proposed method, classifiers are recombined at two levels. The main steps at the rule-wise level are represented above the dashed line, where single rules contained in classifiers are produced by sampling Bayesian networks that characterize the global statistical information extracted from the current promising single rules in the search space, and then single rules are assembled together to form the rule sets in order to do prediction. The procedures at the rule set-wise level are depicted below the dashed line, which are similar to the classic GA cycle. The main peculiarity lies in the crossover operator, in which classifiers are recombined by rule-wise uniform crossover operators to keep the semantics of rules in each classifier.",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:49",
      "generation_style": "implementation_focused"
    },
    {
      "question": "According to the performance analysis, on what types of functions does the pPOEMS algorithm outperform the Cauchy EDA, and what is a limitation of Cauchy EDA's performance?",
      "topics": [
        "search"
      ],
      "answer": "The pPOEMS algorithm outperforms Cauchy EDA on separable functions. It also performs better on multimodal and weak-structure functions. However, Cauchy EDA shows weaker performance on multimodal functions, and restarting the algorithm does not significantly improve this.",
      "chunk_id": 7500,
      "paper_id": "Comparison of cauchy EDA and pPOEMS algorithms on the BBOB noiseless testbed",
      "paper_title": "Comparison of Cauchy EDA and pPOEMS algorithms on the BBOB Noiseless Testbed",
      "paper_year": "2010",
      "chunk_content": "In lower dimensions, Cauchy EDA is often orders of magnitude faster than pPOEMS. With increasing dimensionality this gap reduces, and the speed of both algorithms becomes almost equal (e.g. for 20D versions of sphere and ellipsoid functions). It may be anticipated that for larger dimensions pPOEMS would overtake the Cauchy EDA.  \nLooking at Fig. 4, it can be stated that pPOEMS beats CauchyEDA clearly on separable functions. It is better also for multimodal and weak-structure functions, but neither algorithm is really successful on these (especially in 20D). Cauchy EDA is a clear winner for ill-conditioned functions and for moderate functions in lower dimensions.\nThe time requirements of Cauchy EDA are taken from [7]. The multistart algorithm was run with the maximal number of evaluations set to FORMULA_57, the basic algorithm was restarted for at least 30 seconds. These experiments have been conducted on Intel Core 2 CPU, T5600, 1.83 GHz, 1 GB RAM with Windows XP SP3 in MATLAB R2007b for Cauchy EDA and on Intel Pentium-M 1400 MHz with Windows XP SP3 using the implementation in C for pPOEMS. The comparison of the average time demands per function evaluation are shown in Table 2.  \nThe differences in the average time needed for function evaluation are caused by the fact that CauchyEDA was implemented in MATLAB while pPOEMS in C. The MATLAB implementation becomes more efficient for larger populations.\nCauchy EDA and POEMS algorithm with a pool of candidate prototypes were compared using the BBOB 2010 methodology. The results confirm that pPOEMS searches much\nbroader neighborhood than Cauchy EDA. The pPOEMS algorithm is able to solve certain percentage of multimodal functions, while the performace of Cauchy EDA is for them rather weak (and the restarting does not help much).  \nThe pPOEMS algorithm is rather slow (compared to Cauchy EDA and other algorithms taking part in BBOB 2009) which showed up especially on unimodal functions. The pPOEMS greatly suffers from the fact that the individual actions in the improving sequence operate over axis-parallel directions. For non-separable functions, this renders the crossover operator used in the inner EA of POEMS rather useless since the individual actions are correlated. To incorporate a method that would decorrelate the actions between the individual inner-EA launches remains as future work.\nPetr Posik is supported by the Grant Agency of the Czech Republic with the grant no. 102/08/P094 entitled \"Machine learning methods for solution construction in evolutionary algorithms\". Jiri Kubalik is supported by the Ministry of Education, Youth and Sport of the Czech Republic with the grant No. MSM6840770012 entitled \"Transdisciplinary Research in Biomedical Engineering II\".",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:51",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for energy management strategies in PHEVs, contrasting rule-based, optimization-based, and learning-based methods?",
      "topics": [
        "search"
      ],
      "answer": "The primary purpose is to efficiently manage power distribution between propulsive sources in PHEVs, acknowledging the limitations of traditional methods. Rule-based strategies, while robust and fast, lack optimality. Optimization-based strategies, such as dynamic programming (DP) and equivalent consumption minimization strategy (ECMS), struggle with real-time application due to computational cost or dependence on accurate future driving condition prediction. Learning-based strategies, including those using neural networks (NNs) and deep Q-networks, aim to overcome these limitations by estimating parameters like the equivalence factor or predicting vehicle speeds using recurrent neural networks (RNNs) and long short-term memory (LSTM).",
      "chunk_id": 2937,
      "paper_id": "Online_Ecological_Energy_Management_for_Plug-In_HEVs_Using_Optimal_SOC_Prediction_and_Stochastic_Optimization",
      "paper_title": "Online Ecological Energy Management for Plug-In HEVs Using Optimal SOC Prediction and Stochastic Optimization",
      "paper_year": "2024",
      "chunk_content": "PLUG-IN hybrid electric vehicles (PHEVs) provide high energy efficiency owing to two or more propulsive sources and large battery capacities. The energy efficiency of PHEVs primarily depends on the power distribution between the propulsive sources, which is determined by the energy management strategy. Therefore, an energy management strategy that is appropriate for the driving conditions and characteristics of drivetrains is essential. Energy management strategies in  \n[^0]PHEVs are broadly divided into two categories based on the method of distributing power demand to propulsive sources: rule- and optimization-based strategies.  \nRule-based strategies control the power distribution using rules determined by human expertise [1], fuzzy logic [2], [3], genetic algorithms [4], and deep learning [5]. Generally, these strategies are robust, easy to implement, and sufficiently fast to allow real-time management; however, their optimality is limited under diverse driving conditions.  \nOptimization-based strategies are further divided into global and real-time optimization strategies. Global optimization strategies provide a globally optimal management solution using optimization algorithms, such as dynamic programming (DP) [6], [7], [8], with full knowledge of the driving conditions, which can be obtained via a global positioning system (GPS), intelligent transportation system (ITS), and communications [9], [10], [11]. However, the long computational time required to optimize the entire driving cycle hinders their real-time applications essential for coping with dynamic changes in traffic conditions. Generally, real-time optimization strategies optimize energy consumption over part of the driving cycle rather than the entire driving cycle for a faster computation, resulting in locally optimal performance. A common approach to real-time optimization is the equivalent consumption minimization strategy (ECMS), which minimizes the instantaneous sum of fuel and electric energy consumption weighted by an equivalence factor [12], [13], [14]. The Pontryagin's minimum principle (PMP) is another approach, which converts the power distribution problem into an instantaneous optimization based on specific assumptions [15], [16]. However, its optimality largely depends on the equivalence factor in the ECMS or the costate in the PMP, and it is difficult to determine the best equivalence factor or costate in real time, as they vary with the future driving condition.  \nRecently, learning-based strategies have been explored to overcome the aforementioned limitations, which are categorized into two groups. One group uses machine-learning or deep-learning algorithms for estimating the parameters or variables needed to optimize the energy management. The optimal battery current and equivalence factor in the ECMS were estimated from traffic data using neural networks (NNs) [7] and deep Q-networks [17]. Vehicle speeds were predicted using artificial NNs [18], recurrent neural networks (RNNs) and long short-term memory (LSTM) [19], Markov chains and  \n[^0]:    Manuscript received 24 March 2023; revised 6 December 2023 and 23 January 2024; accepted 18 March 2024. Date of publication 4 April 2024; date of current version 29 August 2024. This work was supported by the Basic Science Research Program through the National Research Foundation of Korea under Grant NRF-2019R1F1A1058029. The Associate Editor for this article was R. Arghandeh.  \nThe author is with the Department of Electronics Convergence Engineering, Kwangwoon University, Seoul 01897, South Korea (e-mail: lhs@kw.ac.kr).\nDigital Object Identifier 10.1109/TITS.2024.3379991",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:53",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of incorporating Hamming distance, as used in an EDA for consumption-loan planning, restrain the quantitative change in a solution structure during the EDA's processes?",
      "topics": [
        "genetic"
      ],
      "answer": "The EDA using Hamming distance restrains the quantitative change in a solution structure on the processes of EDA. This approach is employed to avoid convergence on a local solution within the consumption-loan planning problem, which involves maximizing a household's utility function consisting of consumption variables and loan variables under budget limitations. The Hamming distance, within the EDA, serves to control and limit the extent to which the solution changes from one iteration to the next, thereby promoting exploration of the solution space and reducing the likelihood of premature convergence to suboptimal solutions.",
      "chunk_id": 8382,
      "paper_id": "EDA with Hamming Distance for Consumption-Loan Planning in Experimental Economics",
      "paper_title": "EDA with Hamming Distance for Consumption-Loan Planning in Experimental Economics",
      "paper_year": "2019",
      "chunk_content": "Yukiko OritoHiroshima UniversityHiroshima, Japanorito@hiroshima-u.ac.jp\nFor the consumption-loan planning in the experimental economics, this paper proposes the EDA (Estimation of Distribution Algorithm) using Hamming distance in order to avoid convergence on a local solution. The EDA with Hamming distance restrains the quantitative change in a solution structure on the processes of EDA.\n- Theory of computation FORMULA_0 Evolutionary algorithms;\nEDA, Hamming distance, consumption-loan planning\nYukiko Orito and Tomoko Kashima. 2019. EDA with Hamming Distance for Consumption-Loan Planning in Experimental Economics. In Genetic and Evolutionary Computation Conference Companion (GECCO '19 Companion), July 13-17, 2019, Prague, Czech Republic. ACM, New York, NY, USA, 2 pages.\nhttps://doi.org/10.1145/3319619.3326788\nConsumption-loan planning is the combinatorial optimization problem which maximizes the household's utility function consisting of two kinds of decision variables, consumption variables and loan variables, under budget limitation. Izawa and Mardyla [1] designed the consumption-loan planning including various and complicated consumption items and loans as a real world application. They conducted the real effort experiment and then clarified the consumption and borrowing behaviors of subjects through the experiment. Orito et al. [2] optimized this consumption-loan planning by using the EDA. They analyzed the differences between the solutions obtained by the EDA and the behaviors obtained by the subjects on the experiment. However, some of solutions obtained by their EDA were the local solutions, not the global optimal solution. In order to improve this problem, we expand their EDA so that the quantitative change in a solution structure may be restrained.  \n[^0]",
      "question_type": "algorithmic mechanism",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:56:55",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "In which practical scenarios does the N-gram GP outperform the linear GP when solving Polynomial problems of varying degrees?",
      "topics": [
        "comparison"
      ],
      "answer": "The N-gram GP outperforms the linear GP on more difficult Polynomial problems, specifically those with a higher degree 'd'. While linear GP performs marginally better for small 'd', its performance degrades rapidly as 'd' increases. N-gram GP exhibits superior scalability, maintaining higher performance and a more graceful performance degradation as 'd' increases, making it more suitable for problems of size d=11 or larger.",
      "chunk_id": 5828,
      "paper_id": "A linear estimation-of-distribution GP system",
      "paper_title": "A linear estimation-of-distribution GP system",
      "paper_year": "2008",
      "chunk_content": "Fig. 1(a) shows a comparison of the success rate obtained by the hill climber, the Ngram GP and the linear GP on Polynomial problems of degrees from 5 to 12, when using the PlusTimesSwapR1R2 primitive set. It is apparent how the use of a small set of suitable primitives makes the problem solvable for all techniques tested. Unsurprisingly, the simple hill-climber does well on the relatively easy instances, but its performance is unsatisfactory for $d$ bigger than 9 or 10 . On the contrary, the performance of the linear GP never really drops to unacceptable levels. Furthermore, both linear GP and the hill-climber do marginally better than the N -gram GP for small $d$. On the more difficult problems, however, N-gram GP shows much better performance. Furthermore, its performance drops more slowly than the other techniques as $d$ increases, suggesting better scalability on these problems.  \nAs illustrated in Fig. 1(b), the use of a larger-than-necessary primitive set (AllOpsSwapR1R2) makes the problem harder, because the size of the search space increases enormously without a corresponding increase in the size of the solution space. In these conditions, a searcher would need more time and resources to identify solutions. However, in this work, all problems, searchers and primitive sets are compared using the same number of fitness evaluations, leading to generally poorer performance. Despite this general trend, all observations we made for Fig. 1(a) appear to be valid for Fig. 1(b) as well. In particular the N-gram GP system still shows superior scalability and higher performance on the harder problems.  \nFinally, let us consider the Lawn-Mower problem. Again the simple hill-climber is the weakest of all searchers. Linear GP is marginally superior to N-gram GP for small problem sizes. However, its performance rapidly degrades, becoming unacceptable for  \n[IMAGE0]  \nFig. 1. Success rate of hill climber, N-gram GP and linear GP on Polynomial problems of degrees from 5 to 12, when using the PlusTimesSwapR1R2 primitive set (a) and the AllOpsSwapR1R2 primitive set (b). Parameters are as detailed in Table 2.\nproblems of size $d=11$ or larger. Conversely, N-gram GP's performance degrades much more gracefully, leading it to being still able to solve problems of size $d=12$ in about one third of runs.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:56:57",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the networked control system, how does the relationship between the time delay $\\tau$ and the sampling period $h$ impact control performance, specifically when $\\tau$ is expressed as $\\tau = 5h + 20$, where the time delay $\\tau$ is 320 ms and the sampling period $h$ is 60 ms?",
      "topics": [
        "control"
      ],
      "answer": "The expression $\\tau = 5h + 20$, with $\\tau$ representing the time delay (320 ms) and $h$ representing the sampling period (60 ms), illustrates that the time delay is a few times the sampling period plus a time within a sampling period. The text suggests that if the time delay is excessively long relative to the sampling period, then it can lead to poor control performance if the sampling period is not small. Making the sampling period small is more suitable in this scenario.",
      "chunk_id": 4484,
      "paper_id": "Research on Gain Scheduling Controller of the Networked Control System with Long Delay",
      "paper_title": "Research on Gain Scheduling Controller of the Networked Control System with Long Delay",
      "paper_year": "2015",
      "chunk_content": "In order to make the research close to the reality, the round-trip-delay of the network between Tsinghua University and Yahoo is measured by sending and receiving data packet every five seconds from Tsinghua side. The Fig. 1 shows the continuous ten thousand times of time delay on the network between Tsinghua and Yahoo. The test date is September 7th, 2010. Yahoo server's IP address is 66.94.230.34.  \n[^0]:    Manuscript received July 1, 2013; revised March 4, 2014; accepted May 29, 2014. Recommended by Associate Editor Yingmin Jia under the direction of Editor-in-Chief Young-Hoon Joo.  \nThe work was supported in part by the National Basic Research Program of China (973 Program) under Grant 2012CB821206, by the National Natural Science Foundation of China under Grant 61004021, 61174069, and by the Beijing Natural Science Foundation under Grant 4122037.  \nJian-Qiu Deng is with Naval Aeronautical and Astronautical University, Qingdao, China (e-mail: djq06@mails.tsinghua.edu.cn).  \nHong-Bo Li and Zeng-Qi Sun are with the Department of Computer Science and Technology, Tsinghua University, Beijing, China (e-mails: hb-li04@mails.tsinghua.edu.cn, szq-dcs@tsinghua. edu.cn).  \nCui Hao is with Beijing Information Science and Technology University, Beijing, China (e-mail: haocui0433234@163.com).  Corresponding author.  \n[IMAGE0]  \nFig. 1. Continuous ten thousand times of time delay on the network between Tsinghua and Yahoo.  \nThe sensor and the actuator are time driven. The controller is event driven. The results in Fig. 1 shows that time delay is varying in a small range near the average time delay in a certain period of time, and it is so long that we can't make them in one sampling period because of the poor control performance. It is more suitable to make the sampling period small, so the time delay is a few times of sampling period plus a time within a sampling period (i.e., the time delay $\\tau$ is 320 ms , and the sampling period $h$ is 60 ms . So, the time delay is $\\tau$ $=5 h+20)$.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:56:59",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does Restricted Boltzmann Machine-based Estimation of Distribution Algorithm (REDA) model the probability distribution of a visible unit, specifically addressing the marginal costs and energy function?",
      "topics": [
        "genetic"
      ],
      "answer": "REDA models the probability distribution of a visible unit, \\(v_i\\), using the formula \\(Pr(v_i=1) = \\frac{P(v_i^{*})+avg(P(v_i))}{P(v_i^{*})+P(v_i^{-})+r_i * avg(P(v_i))}\\), where \\(P(v_i^{*}) = \\sum_{h=1}^{m} e^{-E(v_i=1, h)}\\) is the marginal cost when \\(v_i=1\\), \\(P(v_i^{-}) = \\sum_{h=1}^{m} e^{-E(v_i=0, h)}\\) is the marginal cost when \\(v_i=0\\), and \\(E(v, h) = -\\sum_{i} \\sum_{j} v_{i} h_{j} w_{i j} - \\sum_{i} v_{i} b_{i} - \\sum_{j} h_{j} b_{j}\\) is the energy function. Here, \\(w_{ij}\\) represents the weight connecting visible unit \\(i\\) and hidden unit \\(j\\), \\(b_i\\) is the bias for the visible unit \\(i\\), and \\(b_j\\) is the bias for the hidden unit \\(j\\).",
      "chunk_id": 5351,
      "paper_id": "A hybrid adaptive evolutionary algorithm in the domination-based and decomposition-based frameworks of multi-objective optimization",
      "paper_title": "A Hybrid Adaptive Evolutionary Algorithm in the Domination-based and Decomposition-based Frameworks of Multi-objective Optimization",
      "paper_year": "2012",
      "chunk_content": "Instead of using genetic operators, EDAs employ the probability distribution of the parent solutions to predict the favorable movements of the search processes. More specifically, EDAs construct a probabilistic model of the promising solutions and subsequently generate the children solutions by sampling the constructed model. Any probabilistic modeling approach can be used in EDAs. Some approaches that have been implemented in multi-objective EDAs (MOEDAs) are decision tree [18], local principle  \nBegin  \n1. Input: Define initial step size $\\sigma_{0}$.\nFor $j=1: L S$ (Number of solutions undergoing local search)\n2. Initial solution: Select a solution $x^{j}$ from the selection pool.\n3. Reproduction: Create $L$ local neighbors $r^{j}, i \\in(1,2, \\ldots, L)$ by\nperturbing $x^{j}$ using normal mutation $N\\left(0, \\sigma^{2}\\right)$.\n4. Evaluation: Calculate the objective values of $r^{j}, F\\left(r^{j}\\right)$.\n5. Direction: Estimate the global gradient direction as follows.  \n$$\n\\hat{v}=\\frac{\\sum_{i=1}^{n}\\left(v\\left(x^{j}\\right)+r\\left(x^{j}\\right)\\right)\\left|x^{j}-x^{j}\\right|}{\\left|\\left|\\sum_{i=1}^{n}\\left|v\\left(x^{j}\\right)+r\\left(x^{j}\\right)\\right| x^{j}-x^{j}\\right|\\right|}\n$$  \n6. Create an offspring:  \n$$\ny=x^{j}-\\sigma_{1} \\hat{v}\n$$  \n7. Update mutation step size $\\sigma_{t+1}$ :  \n$$\n\\sigma_{t+1}=\\left\\{\\begin{array}{ll}\n\\sigma_{t} x & \\text { if } F(y)<F\\left(x^{j}\\right) \\\\\n\\sigma_{t} / \\varepsilon & \\text { otherwise }\n\\end{array}, \\varepsilon=1.0\\right.\n$$  \n8. Update solution: if $F(y)<F\\left(x^{j}\\right)$\nthen $x^{j}=y$\n9. Output: Output $x^{j}$.  \nEnd for $j$\nEnd  \nFig. 1. Pseudo code of an evolutionary gradient search algorithm\ncomponent analysis [8], Bayesian network [19], Parzen estimator [7], and restricted Boltzmann machine (RBM) [9]. This paper will only consider an MOEDA that uses RBM (REDA) as its modeling approach.  \nRBM is an energy-based binary stochastic neural network. The network consists of two layers of neurons. They are a visible layer (denoted as $v_{i}$ where $i=1, \\ldots, n$ ) and a hidden layer (denoted as $h_{j}$ where $j=1, \\ldots, H$ ) where $n$ is the number of visible neurons or decision variables and $H$ is the number of hidden neurons. The process flow of REDA consists of three main steps, including the training, modeling and sampling steps. Firstly, the RBM is trained using the contrastive divergence training method [20]. Then, the probability distribution of a visible unit is constructed as follows.  \n$$\n\\begin{gathered}\n\\operatorname{Pr}(v)=\\frac{\\sum_{h} \\exp (-E(v, h))}{\\sum_{x, y} \\exp (-E(x, y))} \\\\\n\\operatorname{Pr}\\left(v_{i}=1\\right)=\\frac{P\\left(v_{i}^{*}\\right)+a v g\\left(P\\left(v_{i}\\right)\\right)}{P\\left(v_{i}^{*}\\right)+P\\left(v_{i}^{-}\\right)+r_{i} * a v g\\left(P\\left(v_{i}\\right)\\right)} \\\\\nE(v, h)=-\\sum_{i} \\sum_{j} v_{i} h_{j} w_{i j}-\\sum_{i} v_{i} b_{i}-\\sum_{j} h_{j} b_{j}\n\\end{gathered}\n$$  \nwhere $\\operatorname{Pr}(v)$ is the probability distribution of a visible unit, $P\\left(v_{i}^{*}\\right)=\\sum_{h=1}^{m} e^{-E\\left(v_{i}=1, h\\right)}$ is the marginal cost of $v_{i}$ when $v_{i}=1, P\\left(v_{i}^{-}\\right)=\\sum_{h=1}^{m} e^{-E\\left(v_{i}=0, h\\right)}$ is the marginal cost of $v_{i}$ when $v_{i}=0, a v g\\left(P\\left(v_{i}\\right)\\right)$ is the average marginal cost of $v_{i}$, $r_{i}$ is the number of cardinalities that $v_{i}$ may take, $E$ is the energy function of the network, $w_{i j}$ is the weight that connecting visible unit $i$ and hidden unit $j, b_{i}$ is the bias for the visible unit $i$ and $b_{j}$ is the bias for the hidden unit FORMULA_47. After\nconstructing the probabilistic model, a child solution is created by sampling the probabilistic model using the simple sampling mechanism [9].",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:02",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model when applied to a permutation-based problem, as described in the text?",
      "topics": [
        "algorithm"
      ],
      "answer": "The text describes using an Estimation of Distribution Algorithm (EDA) with the generalized Mallows distribution to solve a permutation-based problem, specifically school bus routing. The steps involve using the generalized Mallows distribution to model the probability distribution over a set of school bus routes. A mutation operator is then used to improve the estimation of the central permutation, which is a parameter of the Mallows distribution. The algorithm iteratively refines the Mallows distribution based on the performance of candidate solutions, guiding the search towards better bus routes.",
      "chunk_id": 7041,
      "paper_id": "An estimation of distribution algorithm coupled with the generalized Mallows distribution for a school bus routing problem with bus stop selection",
      "paper_title": "An estimation of distribution algorithm coupled with the generalized Mallows distribution for a school bus routing problem with bus stop selection",
      "paper_year": "2017",
      "chunk_content": "Revista Iberoamericana de Automatica e Informatica industrial 14 (2017) 288-298\nRicardo Perez-Rodriguez ${ }^{\\mathrm{a}, *}$, Arturo Hernandez-Aguirre ${ }^{\\mathrm{b}}$${ }^{a}$ CONACYT - Centro de Investigacion en Matematicas CIMAT, A.C. Fray Bartolome de las Casas 314, Barrio la Estacion, C.P. 20259, Aguascalientes, Ags. Mexico.${ }^{\\text {b }}$ Centro de Investigacion en Matematicas CIMAT, A.C. Callejon de Jalisco s/n, Mineral de Valenciana, C.P. 36240, Guanajuato, Gto, Mexico.\nAunque los algoritmos de estimacion de distribuciones fueron originalmente disenados para resolver problemas con dominio de valores reales o enteros, en esta contribucion se utilizan para la resolucion de un problema basado en permutaciones. El ruteo de autobuses escolares con seleccion de paradas es resuelto utilizando la distribucion generalizada de Mallows como un intento para describir y obtener una distribucion de probabilidad explicita sobre un conjunto de rutas de autobuses escolares. Ademas, un operador de mutacion es considerado para mejorar la estimacion de la permutacion central, un parametro de la distribucion de Mallows. Diferentes y diversas instancias sirvieron como parametro de entrada y prueba para mostrar que problemas basados en permutaciones tales como el ruteo de autobuses escolares con seleccion de paradas pueden ser resueltos por medio de un modelo de probabilidad, y mejorar la estimacion de la permutacion central ayuda al desempeno del algoritmo.\nAlgoritmo de estimacion de distribuciones, distribucion de Mallows, problema de ruteo de vehiculos, problema de ruteo de autobuses escolares.",
      "question_type": "steps",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:04",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific procedures can be employed to assess the effectiveness of the EDACC algorithm in refining solutions with high diversity but potentially low initial accuracy?",
      "topics": [
        "search"
      ],
      "answer": "The EDACC algorithm can integrate an efficient local search method in the final procedure of generating the best solution when the current solution is guaranteed to converge. Specifically, the Powell method, a derivative-free optimization technique using bi-directional search along each search vector, can be applied to refine solutions. This is suitable for large-scale optimization problems with high diversity but low accuracy, which is a characteristic of EDA.",
      "chunk_id": 11279,
      "paper_id": "An Estimation of Distribution Algorithm for Large-Scale Optimization with Cooperative Co-evolution and Local Search",
      "paper_title": "An Estimation of Distribution Algorithm for Large-Scale Optimization with Cooperative Co-evolution and Local Search",
      "paper_year": "2018",
      "chunk_content": "One important factor of EDA offspring generation is the way we select individuals and decision variables for probabilistic distribution model simulation. The problem of selecting individuals can be solved by original EDA like PBILc, while the selection of decision variables is still required developed in EDA algorithm. CC framework gives us a new insight for selecting subproblems in the original problem and DG offers a great grouping strategy for CC framework.  \nTaking all these factors into consideration, we propose a new generating offspring method in EDA under integrating CC framework and DG grouping strategy. In population updating procedure, EDACC doesn't take all decision variables in each selected individuals for the offspring generation. According to the decision variable division result using DG grouping method, we generate new offspring for each decision variable in one group together, while different decision variable groups are updated separately.  \nWe denote that $x_{i j}$ stands for the $j^{t h}$ decision variables in $i^{t h}$ individual. In offspring generation, for $K$ selected individuals like $\\left(x_{1}, x_{2}, \\ldots, x_{K}\\right)$, each individual contains $M$ decision variables and the decision variables only required for probabilistic model parameters updating are those variables in the same subgroup generated by DG strategy. Since DG strategy can reallocate interacting decision variables into the same subgroup, it's necessary to generate offspring one group by one group for EDA offspring generating integrating CC framework. The interaction among population and the characteristic of EDA is suitable for CC framework and DG strategy in solving a large-scale optimization problem by a divide-and-conquer method.\nSome previous researches $[18,22]$ in EDA have shown that original EDA may be poor at finding a high accuracy solution due to its offspring generating strategy. In EDACC, since the promising solution area can be found approximately, an efficient local search method can be used in the final procedure of generating the best solution when the current solution can be guaranteed converged. Powell method [8] is a classic optimization method without derivatives. It uses bi-directional search along each search vector and ensures efficiency during its searching. This characteristic is suitable for some method that solving large-scale optimization problems with high diversity but low accuracy like EDA. The total EDACC method is presented as Algorithm 4.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:05",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the Univariate Marginal Distribution Algorithm (UMDA) when applied to the Travelling Salesman Problem (TSP) using permutation encoding, and what key assumption does it make about the problem's variables?",
      "topics": [
        "mutation"
      ],
      "answer": "The Univariate Marginal Distribution Algorithm (UMDA), when applied to the TSP with permutation encoding, aims to learn a probability distribution over the space of permutations to guide the search for optimal routes. Specifically, it calculates a matrix of probabilities, \\(p_i(x_i)\\), representing the probability of each city \\(x_i\\) appearing at each position \\(i\\) in a route. A core assumption of UMDA is that the variables (city positions) are independent, allowing the probability of a sample \\(x\\) to be calculated as the product of the marginal probabilities: \\(P(x) = \\prod_{i=1}^{n} p_{i}(x_{i})\\), where \\(n\\) is the number of cities.",
      "chunk_id": 1992,
      "paper_id": "A roadmap for solving optimization problems with estimation of distribution algorithms",
      "paper_title": "A roadmap for solving optimization problems with estimation of distribution algorithms",
      "paper_year": "2022",
      "chunk_content": "the Travelling Salesman Problem. Let us consider, with illustrative purposes, one of the most recurrent combinatorial optimization problems in the literature: the Travelling Salesman Problem (TSP) (Goldberg and Lingle 1985). The TSP is the problem of finding the route to go over $n$ different cities visiting each city only once and returning to the city of departure. The goal is to find the route that minimizes the time, cost or any other similar criteria associated to it. By considering the most simple case of the\nproblem, the symmetric TSP, ${ }^{2}$ the solution space $\\Omega_{S}$ is composed of the set of all possible routes being $\\left|\\Omega_{S}\\right|=\\frac{(n-1)!}{2}$. We can think of this set as the different Hamiltonian cycles on a complete graph where cities are vertices and edges each have a weight associated that describes the cost of going from one city to another.  \nAccording to the literature on the TSP, depending on the approach used to solve it, different encodings have been considered to codify the solutions. A classical encoding is that which codifies routes as permutations of $n$ cities. ${ }^{3}$ Under this encoding, given any route $\\sigma$ (permutation of cities), $\\sigma(i)=j$ represents that the $j^{\\text {th }}$ city is visited between the visits to the $\\sigma(i-1)^{t h}$ and $\\sigma(i+1)^{t h}$ cities. For instance, in a TSP of $n=4$ cities, the permutation $\\sigma=3241$ describes the route that from city 3 , then goes through 2, 4 and 1, and returns back to 3 . Assuming the permutation encoding, the codification space $\\Omega$ consists of the group of all permutations of size $n$ :  \n$$\n\\Omega=\\mathbb{S}_{n}\n$$  \nand it is composed of $n$ ! permutations. Under this encoding, any $\\sigma \\in \\Omega$ corresponds to a unique route in $\\Omega_{S}$, unfortunately, for any route $x \\in \\Omega_{S}$ there are $2 n$ different permutations. Following the example above, the permutation $\\sigma^{\\prime}=1324$ describes the same route as $\\sigma$, as the starting city can be any of the $n$ possible ones. In other words, this encoding is redundant. Note that under this encoding, the third property of the desired and enumerated above does not hold.  \nLet us accept the previous codification, then a suitable choice of the probability model can be that proposed by the Univariate Marginal Distribution Algorithm (UMDA) (Muhlenbein and Paass 1996) which assumes that the variables of the problem are independent. In the case of the TSP, an application of this EDA calculates a matrix of probabilities that describes the probability of any integer (city) in $\\{1,2, \\ldots, n\\}$ appearing at each position. Then, the sample space onto which the probability distribution is defined is  \n$$\nS=\\{1, \\ldots, n\\}^{n}\n$$  \nThe computation of the probability matrix is carried out by computing the number of times each city appears at each position across the selected solutions in the population divided by the number of individuals. Then, the probability of any sample $x \\in S$ is calculated as  \n[^0]\n[^0]:    ${ }^{2}$ In this TSP variant, the cost involved of travelling between cities $i$ and $j$ is equal in either direction.\n${ }^{3}$ A permutation is understood as a bijection $\\sigma$ of the set of natural numbers $\\{1, \\ldots, n\\}$ onto itself.  \n$P(x)=\\prod_{i=1}^{n} p_{i}\\left(x_{i}\\right)$",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:07",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of comparing against traditional detection methods like the maximum, centroid, and polynomial fitting methods demonstrate EDA's effectiveness in handling distorted spectra?",
      "topics": [
        "performance"
      ],
      "answer": "The effectiveness of the proposed EDA method in handling distorted spectra is demonstrated by benchmarking it against traditional detection methods such as the maximum, centroid, and polynomial fitting methods. By showing that the EDA method performs better than these traditional approaches, it highlights the EDA's ability to effectively process and interpret data from Fiber Bragg Grating (FBG) sensors even when the spectra are distorted, which simulates aging effects through high-low temperature cycling.",
      "chunk_id": 2704,
      "paper_id": "Distortion Tolerant Method for Fiber Bragg Grating Sensor Network Using Estimation of Distribution Algorithm and Convolutional Neural Network",
      "paper_title": "Distortion Tolerant Method for Fiber Bragg Grating Sensor Network Using Estimation of Distribution Algorithm and Convolutional Neural Network",
      "paper_year": "2024",
      "chunk_content": "For the load localization experiment, similar to experimental methodology in the study [28], we used the finite element analysis software Abaqus to simulate the force distribution on an aluminum plate under various load conditions and recorded the sensing data, load sizes, load point positions, and the layout of multiple strain FBG sensors arranged on the plate's surface. This initial dataset represented the sensing data collected by the FBG sensor network under normal operating conditions.  \nTo simulate network node failure conditions, we replaced the sensing data from undistorted FBGs with the distorted and aged FBG sensing data, ensuring that the degree of spectral distortion corresponded to the strain size. This allowed us to construct new datasets representing different numbers and positions of failed FBG nodes within the network.  \nThe remainder of this section is organized as follows. In Section IV-B, the localization model was trained and tested using wavelength data from properly functioning FBGs. Section IV-C explored the model's resilience by swapping a single failed FBG with each of the other eight in the network, assessing the impact of the sensor's position. In Section IV-D, we further tested our model's robustness against FBGs with varying degrees of spectral distortion, simulating aging effects through high-low temperature cycling. In Section IV-E, we assessed the localization system's robustness by incrementally increasing the number of failed FBG sensors from one to five. Section IV-F compared the proposed EDA method against traditional detection methods like the maximum, centroid, and polynomial fitting methods, demonstrating EDA's effectiveness in handling distorted spectra. Section IV-G benchmarked the CNN's performance with other sophisticated machine learning and deep learning techniques, including BP neural networks,  \n[IMAGE8]  \nFig. 7. Distribution of FBG sensors and external load points.\n[IMAGE9]  \nFig. 8. Waveform samples detected by the nine FBGs.  \nSVR, ELM, and advanced architectures like [29] and [30], ResNet-18 [31], [32], VGG-16 [33], [34], and EfficientNetV2 [35], affirming the proposed method's superior localization performance.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:09",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm like BioHEL, what techniques can improve performance, and how are they configured?",
      "topics": [
        "performance"
      ],
      "answer": "To improve the performance of the BioHEL system, practitioners can use techniques such as incremental learning with alternating strata (ILAS) windowing, where only a portion of training examples are used to evaluate rule fitness. An ensemble learning scheme can also be used, where BioHEL runs multiple times with different random seeds, and each run votes on example membership. A default class policy can be implemented to group examples into a class to make the rule set more compact. The tradeoff between accuracy and coverage is controlled by the Coverage Ratio (CR) parameter. The coverage term is a function of the number of examples matched by a rule, up to a threshold parameterized by the Coverage Breakpoint (CB).",
      "chunk_id": 196,
      "paper_id": "Improving the performance of the BioHEL learning classifier system",
      "paper_title": "Improving the performance of the BioHEL learning classifier system",
      "paper_year": "2013",
      "chunk_content": "$\\operatorname{TL}(R)=\\frac{\\sum_{i=1}^{n \\text { Atr }}\\left(1-\\operatorname{Size}\\left(R_{i}\\right)\\right) / \\operatorname{Size}\\left(D_{i}\\right)}{\\# A t t r}$\nwhere \\#Attr is the number of the relevant attributes, Size $\\left(R_{i}\\right)$ is the width of the interval for ith attribute in the rule $R$ and Size $\\left(D_{i}\\right)$ is the width of the feasible range for ith attribute.  \nEL, on the other hand, is formulated as:\n$\\operatorname{EL}(R)=2-\\operatorname{ACC}(R)-\\operatorname{COV}(R)$\nwhere $\\operatorname{ACC}(R)$ represents the accuracy of the rule $R$, defined as the number of examples correctly classified among all the examples that are covered by the rule. And COV $(R)$ stands for the coverage of the rule $R$ defined as the number of examples matched by the rule divided by the current number of total training examples. The tradeoff between $\\operatorname{ACC}(R)$ and $\\operatorname{COV}(R)$ is controlled by a parameter called the Coverage Ratio (CR). Meanwhile, the coverage term is a function of the number of examples that are matched by the rule $R$, matched $(R)$. COV $(R)$ grows linearly to matched $(R)$ until it reaches a threshold which is parameterized by a threshold termed as the Coverage Breakpoint (CB). After reaching the CB, COV (R) grows at a slower rate.  \nTechniques which are introduced to improve the performance of the BioHEL system also include: (1) incremental learning with alternating strata (ILAS) windowing scheme in which a portion of, rather than all, training examples are used to evaluate the fitness of each rule. (2) ensemble learning scheme in which the BioHEL run multiple times with different random seeds. Each run cast a vote on the membership of an example which is eventually  \n[IMAGE10]  \nFig. 8. The pearson correlation coeffiecent between accuracy and coverage for each attribute of datasets with respectively 3, 5, 7 and 10 attributes.\nassigned the label of the class winning the majority of votes. (3) default class policy which allows examples to be grouped into a certain class in order to make the ultimate rule set more compact.\nThe checkerboard dataset contains 992 data points from two classes on $X-Y$ plane, with 496 for each class, as shown by Fig. 1. Fig. 2 displays the checkerboard pattern successfully recognized by the BioHEL using the parameter setting in Table 1. The BioHEL achieved a 10 -fold cross-validation accuracy of $97.17 \\%$.  \nIn order to examine BioHEL's ability of identifying signification attributes, the checkerboard datasets were added, incrementally, 1 to 18 dimensions of Gaussian noises, resulting in 18 synthetic datasets. Each noisy attribute, as well as the original two, has roughly the same mean of 1.50 . The standard deviations of the noises are also at the same level of around 0.14 , while they are around 0.28 for the original two attributes.  \nTen-fold cross validation accuracies of LIBSVM (Chang \\& Lin, 2001), NaiveBayes (NB) and C4.5 on the checkerboard datasets were reported in Table 2 and depicted by Fig. 3. For LIBSVM, the following Gaussian Radial Basis Function (RBF) was used:\nFORMULA_30\nFrom Fig. 3, it can be seen that both NaiveBayes and C4.5 were unable to perform well while the performance of both the BioHEL and LIBSVM degraded as the number of noises grows.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:11",
      "generation_style": "practical_application"
    },
    {
      "question": "Considering the task scheduling approach for satellite observation described, where priority dispatch is applied to create a schedule and the objective function is defined as CSTS, how does the term 'Duration' impact the overall value of CSTS, and what mathematical relationship ensures that targets with durations exceeding a threshold are appropriately rewarded within the CSTS calculation?",
      "topics": [
        "scheduling"
      ],
      "answer": "In the context of task scheduling for satellite observation, the 'Duration' term, specifically Duration$_{b o m a i}^{j}$ which equals Duration$_{b e t t a r i a t}^{i}$, rewards cases where the actual observation duration is longer than a threshold duration. This reward is mathematically incorporated within the CSTS objective function: CSTS = $\\sum_{i=1}^{n}[w_{i} \\alpha_{i}(\\sum_{j=1}^{n_{i}} \\text { Duration }_{b o m a i}^{j})-w_{p}(1-\\alpha_{i})]$. The term $\\sum_{j=1}^{n_{i}} \\text { Duration }_{b o m a i}^{j}$ represents the sum of durations for recurring observations of target $i$. Therefore, a larger 'Duration' directly increases the value of the CSTS objective function, weighted by $w_{i}$ (the priority weight for target $i$) and $\\alpha_{i}$ (an indicator variable being either 0 or 1). This incentivizes the scheduler to select observation times that maximize the duration of coverage for high-priority targets, effectively rewarding observations exceeding the specified threshold.",
      "chunk_id": 4247,
      "paper_id": "Reconfiguration of satellite orbit for cooperative observation using variable-size multi-objective differential evolution",
      "paper_title": "Reconfiguration of satellite orbit for cooperative observation using variable-size multi-objective differential evolution",
      "paper_year": "2015",
      "chunk_content": "$A R T=\\frac{\\sum_{i=1}^{K} \\sum_{j=1}^{m^{i}}\\left(t_{s}^{i, j}-t_{s}^{i, j}\\right)}{\\sum_{i=1}^{K} m^{i}}$\n(2) Total coverage time (TCT)  \nTCT measures the amount of time during which the targets are covered. For target $i$ at time $t$, if $\\eta_{i}^{t} \\leq \\eta^{\\max }$, then $t$ is marked as the start time of coverage window, $w_{s}$. At $t=t+\\Delta t$, the position of a satellite is updated from the ground track and the computation is repeated until the target is out of FOV, and the corresponding time is marked as the end time of coverage window, $w_{e}$. Accumulating $p^{i}$ coverage windows yields the TCT for $K$ satellites:\n$T C T=\\sum_{i=1}^{K} \\sum_{j=1}^{p^{i}}\\left(w_{s}^{i, j}-w_{s}^{i, j}\\right)$\n[IMAGE2]  \nFig. 3. Illustration of (a) interceptor trailing target and (b) interceptor leading target.\n(3) Coverage statistics based on task scheduling (CSTS)  \nIn some cases, it is desirable that the reconfiguration satisfies more than one mission requirement, such as requirement that the higher priority targets should be observed for longer period, that observation time must be at least equal to the threshold observation time, or that each target can be observed at least once. The computation of this coverage metric needs to employ task scheduling (Vallado, 2007). Task scheduling is defined as \"creating a schedule which selects exact start and stop observation time for each target based on $\\left[w_{s}^{i, j}, w_{s}^{i, j}\\right]$ \". In this study, priority dispatch (Vallado, 2007) is applied to create the schedule and then the objective function is defined as:\n$C S T S=\\sum_{i=1}^{n}\\left[w_{i} \\alpha_{i}\\left(\\sum_{j=1}^{n_{i}} \\text { Duration }_{b o m a i}^{j}\\right)-w_{p}\\left(1-\\alpha_{i}\\right)\\right]$\nwhere $n$ is the number of original targets, and $n_{i}$ is the number of the recurring observations of target $i ; w_{i}=$ [(largestPriority - smallestPriority + 1)/target ${ }_{i}$ Priority] is the priority weight for target $i$; Duration $_{\\text {bomar }}^{j}=\\text { Duration }_{b e t t a r i a t}^{i}$ Duration $_{\\text {bostrod }}$ rewards the cases where the actual duration is longer than the threshold observation duration. A penalty term, $w_{p}\\left(1-\\alpha_{i}\\right)$, aims to guarantee each target can be observed at least once; the penalty weight is $w_{p}$ creates a high cost for the targets which are not on the schedule $\\left(\\alpha_{i}=0, \\alpha_{i} \\in\\{0.1\\}\\right)$.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:14",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "For the sig-cGA, how does the probability of a false significance detection relate to the number of trials, $k$, when there is no bias in selection at position $i$?",
      "topics": [
        "selection"
      ],
      "answer": "For the sig-cGA, when there is no bias in selection at position $i$, the probability that $\\tau_{i}$ changes in an iteration (detecting a false significance) is at most $n^{-\\varepsilon / 3} \\log_{2} k$, where $n$ is a parameter, $\\varepsilon \\geq 1$, and $k$ represents the number of trials.",
      "chunk_id": 10972,
      "paper_id": "Significance-based Estimation-of-Distribution Algorithms",
      "paper_title": "Significance-based Estimation-of-Distribution Algorithms",
      "paper_year": "2018",
      "chunk_content": "$$\n\\operatorname{sig}\\left(\\frac{1}{2}, H\\right)= \\begin{cases}\\text { up } & \\text { if } \\exists m \\in \\mathbb{N}:\\|H\\left[2^{m}\\right]\\|_{1} \\geq \\frac{2^{m}}{n}+s\\left(\\varepsilon, \\frac{2^{m}}{n}\\right) \\\\ \\text { down } & \\text { if } \\exists m \\in \\mathbb{N}:\\|H\\left[2^{m}\\right]\\|_{0} \\geq \\frac{2^{m}}{2}+s\\left(\\varepsilon, \\frac{2^{m}}{2}\\right) \\\\ \\text { stay } & \\text { else }\\end{cases}\n$$  \n$\\operatorname{sig}\\left(1-\\frac{1}{n}, H\\right)= \\begin{cases}\\text { down } & \\text { if } \\exists m \\in \\mathbb{N}:\\|H\\left[2^{m}\\right]\\|_{0} \\geq \\frac{2^{m}}{n}+s\\left(\\varepsilon, \\frac{2^{m}}{n}\\right) \\\\ \\text { stay } & \\text { else }\\end{cases}$\n$\\operatorname{sig}\\left(\\frac{1}{n}, H\\right)=\\left\\{\\begin{array}{ll}\\text { up } & \\text { if } \\exists m \\in \\mathbb{N}:\\|H\\left[2^{m}\\right]\\|_{1} \\geq \\frac{2^{m}}{n}+s\\left(\\varepsilon, \\frac{2^{m}}{n}\\right), \\\\ \\text { stay } & \\text { else. }\\end{array}\\right.$\nWe stop at the first (minimum) length $2^{m}$ that yields a significance. Thus, we check a history $H$ in each iteration at most $\\log _{2}|H|$ times.  \nWe now prove that the probability of detecting a significance at a position when there is no bias in selection (i.e., a false significance) is small. We use this lemma in our proofs in order to argue that no false significances are detected with high probability.  \nLemma 3.1. For the sig-cGA (Alg. 1), let $\\varepsilon \\geq 1$. Consider a position $i \\in[n]$ of the sig-cGA and an iteration such that the distribution $X$ of 1 s of $H_{i}$ follows a binomial distribution with $k$ trials and success probability $\\tau_{i}$, i.e., there is no bias in selection at position $i$. Then the probability that $\\tau_{i}$ changes in this iteration is at most $n^{-e / 3} \\log _{2} k$.  \nProof. In order for $\\tau_{i}$ to change, the number of 0 s or 1 s in $X$ needs to deviate significantly from the hypothesis, which follows the same distribution as $X$ by assumption. We are going to use Theorem 2.1 in order to show that, in such a scenario, $X$ will deviate significantly from its expected value only with a probability of at most $n^{-\\varepsilon / 3} \\log _{2} k$ for any number of trials at most $k$.  \nLet $\\tau_{i}^{\\prime}=\\min \\left\\{\\tau_{i}, 1-\\tau_{i}\\right\\}$. Note that, in order for $\\tau_{i}$ to change, a significance of values sampled with probability $\\tau_{i}^{\\prime}$ needs to be sampled. That is, for $\\tau_{i}=1 / 2$, either a significant amount of 1 s or 0 s needs to occur; for $\\tau_{i}=1-1 / n$, a significant amount of 0 s needs to occur; and, for $\\tau_{i}=1 / n$, a significant amount of 1 s needs to occur. Further, let $X^{\\prime}$ denote the number of values we are looking for a significance within $k^{\\prime} \\leq k$ trials. That is, if $\\tau_{i}=1 / 2, X^{\\prime}$ is either the number of 1 s or 0 s ; if $\\tau_{i}=1-1 / n, X^{\\prime}$ is the number of 0 s ; and if $\\tau_{i}=1 / n, X^{\\prime}$ is the number of 1 s .  \nGiven the definition of $\\tau_{i}^{\\prime}$, we see that $E\\left[X^{\\prime}\\right]=k^{\\prime} \\tau_{i}^{\\prime}$ and $\\operatorname{Var}\\left[X^{\\prime}\\right]=k^{\\prime} \\tau_{i}\\left(1-\\tau_{i}\\right) \\leq k^{\\prime} \\tau_{i}^{\\prime}$. Since we want to apply Theorem 2.1, let $\\lambda=s\\left(\\varepsilon, E\\left[X^{\\prime}\\right]\\right)=s\\left(\\varepsilon, k^{\\prime} \\tau_{i}^{\\prime}\\right)$ and $\\sigma^{2}=\\operatorname{Var}\\left[X^{\\prime}\\right]$.  \nFirst, consider the case that $\\lambda=s\\left(\\varepsilon, k^{\\prime} \\tau_{i}^{\\prime}\\right)=\\varepsilon \\ln n$, i.e., that $\\left(k^{\\prime} \\tau_{i}^{\\prime} \\ln n\\right)^{1 / 2} \\leq \\ln n$, which is equivalent to $k^{\\prime} \\leq\\left(1 / \\tau_{i}^{\\prime}\\right) \\ln n$. Note that $\\lambda^{2} / \\sigma^{2} \\geq \\varepsilon^{2} \\ln n \\geq \\ln n$, as $\\varepsilon \\geq 1$. Thus, $\\min \\left\\{\\lambda^{2} / \\sigma^{2}, \\lambda\\right\\} \\geq \\varepsilon \\ln n$.  \nNow consider the case $\\lambda=s\\left(\\varepsilon, k^{\\prime} \\tau_{i}^{\\prime}\\right)=\\varepsilon\\left(k^{\\prime} \\tau_{i}^{\\prime} \\ln n\\right)^{1 / 2}$, i.e., that $\\left(k^{\\prime} \\tau_{i}^{\\prime} \\ln n\\right)^{1 / 2} \\geq \\ln n$, which is equivalent to $k^{\\prime} \\geq\\left(1 / \\tau_{i}^{\\prime}\\right) \\ln n$. We see that $\\lambda \\geq \\varepsilon \\ln n$ and $\\lambda^{2} / \\sigma^{2} \\geq \\varepsilon^{2} \\ln n$. Hence, as before, we get $\\min \\left\\{\\lambda^{2} / \\sigma^{2}, \\lambda\\right\\} \\geq \\varepsilon \\ln n$.  \nCombining both cases and applying Theorem 2.1, we get  \n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left[X^{\\prime} \\geq k^{\\prime} \\tau_{i}^{\\prime}+s\\left(\\varepsilon, k^{\\prime} \\tau_{i}^{\\prime}\\right)\\right]=\\operatorname{Pr}\\left[X^{\\prime} \\geq E\\left[X^{\\prime}\\right]+\\lambda\\right] & \\leq e^{-\\frac{1}{2} \\min \\left\\{\\frac{\\lambda^{2}}{\\sigma^{2}}, \\lambda\\right\\}} \\\\\n& \\leq e^{-\\frac{\\varepsilon}{2} \\ln n}=n^{-\\frac{\\varepsilon}{3}}\n\\end{aligned}\n$$",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:16",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to model the constraints related to capacity and order acceptance, specifically focusing on the implementation of equations for `d_{n}^{+}` and `d_{n}^{-}`?",
      "topics": [
        "planning"
      ],
      "answer": "To implement the EDA, the code should model the constraints for capacity expansion (`d_{n}^{+}`) and leftover capacity (`d_{n}^{-}`). The equation `d_{n}^{+}=\\sum_{i} \\sum_{j} \\sum_{j} e_{i j n t} q_{i} F_{i j|k| t n} \\forall n` should be implemented by iterating through all orders `i`, jobs `j`, and production time periods `k` to sum the capacity required (`e_{i j n t} q_{i}`) only if the order `i` is accepted to produce by process `j` in production time period `k` of process `n` (indicated by `F_{i j k t n} = 1`). Similarly, `d_{n}^{-}=\\left(\\sum_{i} \\sum_{k}^{k-1} C T P_{k n t}\\right) - \\sum_{i} \\sum_{i} \\sum_{j} \\sum_{k}^{k-1} e_{i j n} q_{i} F_{i j k t n} \\forall n` is implemented by calculating the difference between the total unallocated capacity (`CTP_{k n t}`) and the capacity required by accepted orders, considering the binary variable `F_{i j k t n}`. These equations should be implemented to accurately model the capacity constraints within the EDA.",
      "chunk_id": 462,
      "paper_id": "Overtime capacity expansion in order acceptance with node based estimation of distribution algorithms",
      "paper_title": "Overtime Capacity Expansion in Order Acceptance with Node Based Estimation of Distribution Algorithms",
      "paper_year": "2014",
      "chunk_content": "(3) Decision parameters\n$F_{i j k t n}=1$, if at production planning period $t$, order $i$ was accepted to produce by process $j$ in production time period $k$ of process $n$ $=0$, otherwise\n$R_{i}=1$, if the order $i$ is accepted\n$=0$, otherwise\nOne of the classic problems in the multi-processes manufacturing that produces variety of products is that the production lines need to expand the capacities $d_{n t}^{+} \\mathrm{while}$ there remains a lot of leftover capacities $d_{n t}^{-}$. To avoid this problem, firms have to make clear that the being accepted orders do not disrupt each other's time and materials. Generally, each order $i$ has different product, quantity $q_{i}$, profit $p_{i}$ and due date $D_{i}$. The order acceptance decision making system has to determine that the order $i$ should be produced at which production resource $k$, on which period $t$. As well as, job $j$ of the accepted order $i$, the require capacity $e_{i j n} q_{i}$ at process $n$, should not be larger than the amount of unallocated capacity $\\sum_{k} \\sum_{t} C T P_{k n t}$. The cost of expanded capacities $d_{n t}^{+} \\quad$ and leftover capacities $d_{n t}^{-}$are transformed into wage $g_{n}$. The cost of leftover capacities can be calculated from the common operational wages while the cost of expanded capacities can be calculated from the OT wages. In order to calculate the costs, $\\alpha_{1 n}$ and $\\alpha_{2 n}$ are used to represent the cost rate of the wage $g_{n}(\\alpha=$ $\\left.\\left(d_{n t}{ }^{\\prime} \\mathrm{s} \\operatorname{cost}\\right) / g_{n}\\right)$.  \nThe key objectives of this problem are (i) to maximize the gross profit and (ii) to minimize the costs of leftover and extended capacities. In order to achieve the first objective, the order acceptance decision and expand capacity decision are taking into account to find out that which unallocated capacity $C T P_{k n t}$ that each process $n$ has left, which orders should be accepted and how much capacity to be expanded. To archive the second objective, the model keep balancing capacity usage in-between production process $n$ based on production costs. Therefore, the model can help manufacturers to select and sequence the set of profitable orders using as much working capacity $C T P_{k n t}$, as well as less OT working time $d_{n t}^{+} \\quad$ as possible. The model thus can be defined as follows:\nMaximize $Z=\\sum_{i} p_{i} R_{i}-\\left(\\sum_{n} \\alpha_{1 n} d_{n}^{+}+\\alpha_{2 n} d_{n}^{-}\\right) g_{n}$\ns.t.  \n$$\n\\begin{aligned}\n& \\sum_{i} \\sum_{j} e_{i j n} q_{i} \\times R_{i} \\leq \\sum_{k} \\sum_{t} C T P_{k n t} \\quad \\forall n \\\\\n& d_{n}^{+}=\\sum_{i} \\sum_{j} \\sum_{j} e_{i j n t} q_{i} F_{i j|k| t n} \\quad \\forall n \\\\\n& d_{n}^{-}=\\left(\\sum_{i} \\sum_{k}^{k-1} C T P_{k n t}\\right) \\\\\n& -\\sum_{i} \\sum_{i} \\sum_{j} \\sum_{k}^{k-1} e_{i j n} q_{i} F_{i j k t n} \\quad \\forall n \\\\\n& f_{i j k n t} \\geq e_{i k t n} \\quad \\forall i, j, k, n, t \\\\\n& f_{i j k n t} \\leq e_{i j n} q_{i} F_{i j k t n} \\quad \\forall i, j, k, n, t \\\\\n& \\sum_{n} t F_{i j j k n t} \\leq D_{i} R_{i} \\quad \\forall i, k, t \\\\\n& \\sum_{k} \\sum_{t=1}^{t-1} f_{i(j-1) k n t}+\\sum_{k} f_{i(j-1) k n t} \\\\\n& \\geq e_{i(j-1) n} q_{i} F_{i j k t n} \\quad \\forall i, j \\backslash\\{1\\}, k, n, t \\\\\n& R_{i k}=\\{0,1\\} \\quad \\forall i, k \\\\\n& F_{i j k n t}=\\{0,1\\} \\quad \\forall i, j, k, n, t \\\\\n& f_{i j k n t} \\geq 0 \\quad \\forall i, j, k, n, t\n\\end{aligned}\n$$  \n[IMAGE_1]  \nFig. 2. Calculation the amount of surplus and stretch capacity",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:18",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output be measured using the criteria of the number of probabilistic models ($L$) in the context of Rastrigin-1.0, Schwefel, Ridge, and Rosenbrock-Chain functions, specifically focusing on the number of global optima discovered and the average number of evaluations required to discover them?",
      "topics": [
        "design"
      ],
      "answer": "The quality of the EDA's output, when varying the number of probabilistic models ($L$), can be assessed by observing the number of times the global optimum is discovered across multiple trials (specifically 20 trials, as outlined), and by measuring the average number of evaluations needed to find the global optimum. Higher performance in multi-peak functions is associated with larger values of $L$, while single-peak functions tend to perform better with smaller $L$ values. The total search points ($L \\times C$) are fixed, and the impact of $L$ is evaluated across Rastrigin-1.0, Schwefel, Ridge, and Rosenbrock-Chain functions.",
      "chunk_id": 11425,
      "paper_id": "Real-coded Estimation of Distribution Algorithm by Using Probabilistic Models with Multiple Learning Rates",
      "paper_title": "Real-coded Estimation of Distribution Algorithm by Using Probabilistic Models with Multiple Learning Rates",
      "paper_year": "2011",
      "chunk_content": "Table 6 shows the parameters that yielded the best performance. First, we discuss the maximum and minimum learning rates $\\left(\\beta_{1}\\right.$ and $\\left.\\beta_{L}\\right)$. In Rastrigin-1.0 and Schwefel functions do not have dependency between design variables where the values of $\\beta_{1}$ and $\\beta_{L}$ are close. On the other hand, in Ridge and Rosenbrock-Chain functions have dependency between design variables where those are 10.0 and 12.5 times different. When the values of $\\beta_{1}$ and $\\beta_{L}$ are close, the convergence speeds of all populations are rapid because each population is similar. However, the population does not cause the initial convergence in a multi-peak function and the global optimum can be discovered. This is because multiple probabilistic models are estimated for one design variable. When the values of $\\beta_{1}$ and $\\beta_{L}$ are markedly different, the diversity of the population is maintained because the convergence speed of each population is different. In functions with a strong dependency, RMM can search effectively because the search with maintenance of population diversity is important.  \nNext, we focus on the number of probabilistic models $(L)$. To determine the effects of the value of $L$, all the search points $(L \\times C)$ are fixed as 120 and the value of $L=4,6,8,10$ is changed. Other parameters are as shown in Table 6. The target test functions are Rastrigin-1.0, Schwefel, Ridge and Rosenbrock-Chain. The other experiment  \nTable 6: The best parameters of RMM  \nTable 7: Number of probabilistic models and search capability  \nTable 8: The best 10 performance parameters in single-peak functions  \nenvironments are the same as Section 4. The results are shown in Table 7. The upper row shows that the number of discovered the global optimum in 20 trials and the lower row shows that the average of the evaluations when the global optimum was discovered. Table 7 indicates that the performance is high in multi-peak functions with a large value of $L$ and in single-peak functions with a small value of $L$. The larger the value of FORMULA_84 is, the higher the probability of searching for a different area is. Thus, it is easy to discover the optimum point because the probability of population convergence in the suboptimal solution is small.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:21",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs regarding the adaptive crossover and mutation probabilities?",
      "topics": [
        "search"
      ],
      "answer": "The primary objective is to enhance the evolution speed and individual diversities by adaptively adjusting the crossover probability, \\(Pc\\), and mutation probability, \\(Pm\\), based on the fitness of individuals relative to the population's average fitness, \\(f_{\\text{avg}}\\), and maximum fitness, \\(f_{\\max }\\). Specifically, if an individual's fitness, \\(f\\), is worse than the average, its crossover and mutation probabilities are decreased.",
      "chunk_id": 3856,
      "paper_id": "Manufacturing rescheduling after crisis or disaster-caused supply chain disruption",
      "paper_title": "Manufacturing rescheduling after crisis or disaster-caused supply chain disruption",
      "paper_year": "2023",
      "chunk_content": "The purpose of the first stage is to obtain a high-quality population as the initial population for the second stage. The steps of the first stage are as follows:  \n1. Define parameters:  \n- population size, $P s$;\n- maximum iteration, iter $_{\\max }$;\n- the minimum crossover probability, $P c_{\\text {min }}$;\n- the maximum crossover probability, $P c_{\\max }$;\n- the minimum mutation probability, $P m_{\\min }$;\n- the maximum mutation probability, $P m_{\\max }$.\nSet starting time $T=0$. Encode and initialize population.  \n2. Calculate the fitness of the individuals within in the population. Use the roulette-wheel selection method to select the parents. The selection probability of the $y$ th individual, $P_{y}$, is calculated using the following function:\n$P_{y}=\\frac{f_{y}}{\\sum_{j=1}^{N} f_{y}}$,\nwhere $f_{y}$ denotes the fitness of the $y$ th individual.\n3. Conduct the adaptive crossover operation based on the following crossover probability: $P c$.  \n$$\nP c=\\left\\{\\begin{array}{ll}\nP c_{\\max }-\\frac{\\left(P c_{\\max }-P c_{\\min } \\forall f-f_{\\text {avg. }}\\right)}{f_{\\max }-f_{\\text {avg. }}}, & f \\geq f_{\\text {avg. }} \\\\\nP c_{\\max }, & \\text { otherwise }\n\\end{array}\\right.\n$$  \nwhere $f, f_{\\max }, f_{\\text {avg. }}$ denote the larger fitness of the two individuals being crossovered, the maximum fitness of the entire population, and the average fitness of the entire population, respectively.\n4. Conduct the adaptive mutation operation based on the following mutation probability $P m$.  \n$$\nP m= \\begin{cases}P m_{\\max }-\\frac{\\left(P m_{\\max }-P m_{\\min } \\times f-f_{\\text {avg. }}\\right)}{f_{\\max }-f_{\\text {avg. }}}, & f \\geq f_{\\text {avg. }} \\\\ P m_{\\max }, & \\text { otherwise }\\end{cases}\n$$  \n5. Update $t=t+1$. If FORMULA_135, return to Step 2; otherwise, exit first stage.  \nIn Step 3, the adaptive crossover probability is defined to accelerate evolution speed and increase individual diversities. This approach is adopted from Wang and Tang (2011). After the two chromosomes performed a crossover operation, if the larger fitness is greater than or equal to the population's average fitness (indicating a worse individual), its crossover probability decreases; otherwise, it remains unchanged.\nIn the second stage of the proposed algorithm, we search to discover whether better individuals exist. The final population from the first stage is used as the initial population for the second stage. In this section, we first introduce the algorithms used in the process; we then summarize the second stage at the end of this section.",
      "question_type": "evaluation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:23",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of modularization, which aims to maximize cohesion and minimize coupling between software modules, relate to the broader goal of software architecture recovery?",
      "topics": [
        "search"
      ],
      "answer": "Modularization algorithms, as applied in software architecture recovery, utilize cohesion and coupling criteria to partition a software system into meaningful subsystems. Cohesion indicates the coherence of a module, while coupling represents the degree of interaction between modules. The goal is to maximize connection/similarity within modules and minimize relationships between modules, using an Artifact Dependency Graph (ADG) as input. The ADG represents components such as classes, methods, functions, or files, and dependencies like calling dependencies or comment similarities. Therefore, modularization serves as a reverse engineering technique to understand the software's architecture by identifying understandable subsystems based on these cohesion and coupling criteria.",
      "chunk_id": 8218,
      "paper_id": "Multi-objective search-based software modularization- structural and non-structural features",
      "paper_title": "Multi-objective search-based software modularization: structural and non-structural features",
      "paper_year": "2019",
      "chunk_content": "Today, all large organizations are dependent on software systems. Adapting to the new requirements is one of the basic principles of these organizations. Therefore, to handle these requirements, it is necessary to keep the related software system up-to-date. During the maintenance process, to rejuvenate the application for newer needs, the  \n[^0]software architecture deviates from its original architecture, while these modifications are not well documented. Without up-to-date documentation, in the process of software maintenance, software engineers spend considerable time to understand the code of the software system, which indicates the importance of the program's understanding. For example, a study (see Pfleeger 2001; Pigoski 1996) reports that from 40 to $60 \\%$ of the maintenance activity is spent on studying the program to understand it. Understanding a program is possible from design features, such as software architecture. The architecture of a software system represents the components and connections between them. Software modularization techniques are used to extract the software architecture from the source code, aiming to understand and maintenance of the software. Modularization has been used in two different areas in software engineering in the literature: software architecture recovery and refactoring. The purpose of the software architecture recovery is to use modularization  \n[^0]:    Communicated by V. Loia.\nHabib Izadkhah\nizadkhah@tabrizu.ac.ir\nNafiseh Sadat Jalali\nnafisejalali1989@yahoo.com\nShahriar Lotfi\nshahriarlotfi@tabrizu.ac.ir\n1 Department of Computer Science, Faculty of Mathematical Sciences, University of Tabriz, Tabriz, Iran  \ntechniques to partition a software system from the source code into meaningful and understandable subsystems. This helps to understand the software in the process of reverse engineering software. Refactoring also utilizes modularization, but with different goals. Refactoring approaches support big-bang re-modularization (meaning those taking a system as an input and providing it as output, as a completely new system with a new modularization). Some papers that use modularization to refactor the source code are (Bavota et al. 2012; Candela et al. 2016; Mkaouer et al. 2015). This paper aims to present modularization approaches to support software architecture recovery, not software refactoring.  \nArtifact Dependency Graph (ADG) is the input of modularization algorithms. In a software, depending on the type of software, any component such as class, method, function, or file can be considered as an artifact. Also, calling dependency or similarity between comments and etc. can be used as a dependency between artifacts.  \nTo be a reasonable structure of software systems, artifacts placed within the same module should have the maximum connection/similarity to each other and artifacts in different modules should have the minimum relationship. Hence, most modularization methods use cohesion and coupling criteria to modularize a software system. Cohesion indicates the coherence of a module and coupling is the degree of interaction between modules. Candela et al. (2016) in an excellent paper named \"Using Cohesion and Coupling for Software re-modularization: Is It Enough?\". It was concluded that these criteria alone are not enough and other criteria are needed. Note that, they did not argue about what criteria are needed. In this paper, we aim at answering the following research questions:\n(1) Which features in the source code can lead to modularization which is closer to the modularization created by the domain expert?\n(2) Does a multi-objective fitness function that takes into account structural and non-structural features can improve modularization quality?\n(3) Is the estimation of distribution-based algorithm able to produce higher-quality modularization compared with other search-based modularization algorithms?",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:25",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for Procedural Content Generation (EDAPCG) to generate game levels with specific playstyles, how should practitioners adjust the coefficients to shift the evolutionary process towards optimizing for different level characteristics, such as linearity versus density?",
      "topics": [
        "optimization"
      ],
      "answer": "To shift the EDAPCG's evolutionary process, practitioners should adjust the coefficients in the objective function to prioritize specific metrics. For example, to decrease linearity and increase density and pattern-oriented metrics for an explorer-type level, the coefficients can be tuned to favor jumps and coins, potentially at the expense of discarding certain design elements like PIPE or STAIR. The evaluation of the final output is crucial to determine if the target playstyle is achieved, informing manual fine-tuning of these coefficients. Experiments with coefficient settings such as 0.1, 0.3, 0.4, 0.1, 0.1 can be used to explore different leniency values and generate harder levels, influencing the balance between linearity, leniency, density, and pattern-oriented metrics.",
      "chunk_id": 2215,
      "paper_id": "Using estimation of distribution algorithm for procedural content generation in video games",
      "paper_title": "Using estimation of distribution algorithm for procedural content generation in video games",
      "paper_year": "2022",
      "chunk_content": "In Figs. 12, 13 and 14 provided in this section, three representative generations are sampled from the EDAPCG's evolutionary process using different sets of coefficients to inquire about its workings. These sampled levels are the elite individuals from the 100th, 200th and 300th generations, with the latter being the final output of the level generation system. In addition, metric values for each level and fitness score are also included. It is worth mentioning that the showcased levels are not the comprehensive representatives of EDAPCG's expressive range, and are included for facilitating descriptive and visual discussion.  \nAs can be seen in Fig. 12, the proposed coefficients tend to guide the evolutionary process towards optimizing the linearity metric over others. The justification for this design is the inherent ability of EDAPCG in producing patterns from the original game, which in turn increases the density and provides varied levels of leniency (usually high), allowing to shift focus to generate less linear levels. In Fig. 12, from top to bottom, a gradual shift towards less linearity can be observed. Interestingly, the middle level in Fig. 12 displays a rare and less lenient level compared to overall results, with several PIPEPIRANHA and long gaps towards the end, thus it can be deduced that EDAPCG has the capacity to produce more variations of leniency, dependent on fine tuning the system using coefficients and probabilistic model's sampling agenda. This notion is explored through more experiments, which are included later in this section.  \nFigure 13, showcases sample levels in which EDAPCG manages to generate an output with balanced optimization of all the metrics. Specifically, notice the  \n[IMAGE13]\n(a) ERA visualization (x-axis linearity, y-axis leniency) with grammar weights set to achieve lower leniency (speeder/explorer) in various coefficient settings and pre-defined 300 evolutionary generations\n[IMAGE14]\n(b) explorer (above) speeder (below) sample levels with experimental coefficients $0.1,0.3,0.4,0.1,0.1$, metric values and fitness score  \nFig. 15 Leniency experiments-a ERA visualization, b sample levels\nlesser linear level is replaced by more density and pattern-oriented individual in 200th generation, giving way for a final output that satisfies all the metrics in a relatively balanced manner. By visual observation, the final output of this sample process is a speeder playstyle level, emphasizing on coins, jumps and sporadic enemies, whereas the previous level is more similar to an explorer type, with more enemy count and variation, powerup DE and less linearity. The evaluation for correct assigning of the final output of EDAPCG to target playstyles is included in designing of the system and informs the manually fine-tuning of different parameters for later runs.  \nIn standard setting, the EDAPCG's goal is to increase the density and patternoriented metrics. The justification of this coefficient configuration can be visually deduced from Fig. 10-the original levels' expressive range. As can be seen in Fig. 14, the evolutionary process gradually moves towards more linear structure, while preserving density. However, from visual comparison between 200 and 300th elite individuals, some patterns and DE are discarded through the process (i.e. PIPE, STAIR), which may be due to EDAPCG's main priority to generate explorer type level, favoring jumps and coins to previously mentioned DE.  \nUpon further experiments in exploring more leniency values using the current system design, EDAPCG proves to be capable of achieving lower values (generating harder levels). The results of these additional experiments can be seen in Fig. 15. A new set of coefficients is introduced for this purpose. This objective function",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:27",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding Estimation of Distribution Algorithms (EDAs), what phenomenon, common in machine learning and potentially impacting EDAs, is described as adapting so well to the given data that noise is encoded, and how is it typically detected?",
      "topics": [
        "search"
      ],
      "answer": "The phenomenon described is overfitting. In the context of machine learning and EDAs, overfitting occurs when a learning algorithm adapts so well to the given data that noise or particularities of the specific sample are also encoded by the learned model. Overfitting can be observed by cross-validating against a validation set which is independent of the set used for learning. Specifically, monitoring the loss function on the validation data; an increase in this loss function after an initial decrease indicates overfitting.",
      "chunk_id": 6186,
      "paper_id": "Does overfitting affect performance in estimation of distribution algorithms",
      "paper_title": "Does overfitting affect performance in estimation of distribution algorithms",
      "paper_year": "2006",
      "chunk_content": "Hao WuSchool of Computer Science The University of Manchester Manchester, M13 9PL, UKTel: +441612756205 wuh@cs.man.ac.uk\nEstimation of Distribution Algorithms (EDAs) are a class of evolutionary algorithms that use machine learning techniques to solve optimization problems. Machine learning is used to learn probabilistic models of the selected population. This model is then used to generate next population via sampling. An important phenomenon in machine learning from data is called overfitting. This occurs when the model is overly adapted to the specifics of the training data so well that even noise is encoded. The purpose of this paper is to investigate whether overfitting happens in EDAs, and to discover its consequences. What is found is: overfitting does occur in EDAs; overfitting correlates to EDAs performance; reduction of overfitting using early stopping can improve EDAs performance.\n1.2.8 [Artificial Intelligence]: Problem Solving, Control Methods, and Search\nAlgorithms\nOverfitting, Estimation of Distribution Algorithms, Bayesian Optimization Algorithm, Random 3-SAT\nEstimation of Distribution Algorithms (EDAs) [1] are a class of evolutionary algorithms that use machine learning techniques to solve optimization problems. They generally build probabilistic graphical model based on good solutions found so far and use the constructed models to guide the further search.  \nOne of the most important phenomena in machine learning from data is overfitting. In this, the learning algorithm adapts so well to the given data, that noise or particularities of the specific sample are also encoded by the learned model. It results in reduced performance when the task is the generalization to unseen data, as well as producing an overly complex model which may consume unnecessary learning time and computational resources.  \nOverfitting can be observed by cross-validating against a  \nCopyright is held by the author/owner(s).\nGECCO'08, July 8-12, 2006, Seattle, Washington, USA.\nACM 1-59593-186-4/06/0007.\nvalidation set which is independent of the set used for learning. In general, learning involves reducing some loss function. During learning, the loss function evaluated on the training data is reduced as the model fits the training data better and better. However, when the loss function is computed on validation, it often starts to decrease, but after a time starts to increase again, as shown in Figure 1. When the loss function on the validation data starts to increases, it indicates that the learner is fitting the specifics of the training data only, and is overfitting.  \nStandard methods for building probability models from data use regularization methods to avoid overfitting. This is done by adding a penalty term to the loss function, such as the Bayesian information criterion (BIC), which penalizes overly complex models, or by integrating over the parameters. Regularization does not fully avoid overfitting in small samples, as Section 3 shows. Since EDAs use machine learning techniques to construct model, is overfitting also important in EDAs? As far as we know, this question has not been investigated. Since the goal of EDAs is optimization not generalization to unseen data, perhaps it is understandable that it has not been considered. On the other hand, recent work has shown that EDAs do need some regularization to avoid being overly influenced by noise [2]. The goal of this paper is to determine whether overfitting is important in EDAs.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:28",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What are the key differences in how traditional AVS and AAVS adjust the Probability Distribution Ellipsoid (PDE) within the context of a Gaussian Estimation of Distribution Algorithm (GEDA), and how does this affect solution generation?",
      "topics": [
        "design"
      ],
      "answer": "Traditional Adaptive Variance Scaling (AVS) increases variances along all eigendirections, potentially enlarging the exploration range of GEDA without aligning with the fitness improvement direction. In contrast, Anisotropic Adaptive Variance Scaling (AAVS) independently tunes variances based on detection results along each eigendirection, increasing variance primarily along directions where slopes (fitness improvement directions) are detected. This reshaping of the PDE by AAVS results in more solutions being generated along the fitness improvement direction, enhancing search efficiency, whereas traditional AVS may generate solutions along less promising directions.",
      "chunk_id": 11060,
      "paper_id": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_title": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_year": "2018",
      "chunk_content": "```  \nAlgorithm 2 lists the pseudocode of AAVS, where three remarks need to be highlighted. First, AAVS tunes all the variances independently and adaptively according to the detection results along corresponding eigendirections. This is also the reason why we name it anisotropic adaptive variance scaling. Second, a single run of AAVS does not change the eigendirections of $\\overline{\\boldsymbol{C}}$, but running AAVS in successive generations can reshape PDE such that the major axis of PDE would gradually become consistent with the fitness improvement direction. The main reason lies in that slopes provide the main fitness improvement directions, AAVS enlarges the axes along slopes, and the new sampled solutions around these axes are more likely to be selected to estimate the new covariance matrix, which further makes this kind of axes approach to the fitness improvement directions. As a result, the search efficiency of GEDA can be substantially increased. Finally, the excellent performance of AAVS is obtained at the cost of sampling two additional solutions for detecting the local landscape along each eigendirection. Nevertheless, the additional sampling quantity is acceptable compared with the general setting of population size in multivariate GEDA.  \n[IMAGE3]  \nFig. 2. PDE and the generated solutions: (a) current PDE, (b) PDE tuned by traditional AVS and (c) PDE tuned by AAVS.  \nTo demonstrate the effectiveness of AAVS in adjusting PDE, a schematic experiment is designed. Suppose GEDA is employed to minimize a two dimensional function $f(\\boldsymbol{x})=x_{0}^{2}+x_{1}^{2}$ and the search range is set to $[0,8] \\times[0,8]$. Fig. 2(a) shows the contour map of this test function, together with the PDE of the current Gaussian distribution and the solutions generated by it. It is clear that the fitness landscape along the direction $x_{0}=x_{1}$ is a slope, the one along the direction $x_{0}=-x_{1}$ is a valley, and the current PDE is illshaped. After applying the traditional AVS and the new proposed AAVS, the resulting PDEs and the new solutions generated by them are shown in Fig. 2(b) and Fig. 2(c). It can be seen from Fig. 2(b) that when traditional AVS are employed, variances along both directions are increased. As a result, the exploration range of GEDA is enlarged, but most solutions are generated along the direction $x_{0}=-x_{1}$ since the PDE is still ill-shaped. When AAVS is applied as shown in Fig. 2(c), only the variance along the direction $x_{0}=x_{1}$ is increased since a slope can be detected along this direction. As a result, PDE is reshaped to a certain extent and more solutions are generated along the fitness improvement direction.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:31",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the compact Genetic Algorithm (cGA) as an Estimation of Distribution Algorithm (EDA) for optimization problems, what data structure is crucial for representing the underlying uncertainty of the problem, and how is this structure used to simulate the evolutionary process?",
      "topics": [
        "genetic"
      ],
      "answer": "In the compact Genetic Algorithm (cGA), a probability distribution is used as the key data structure to represent the underlying uncertainty of the problem. This distribution, which automatically captures the uncertainty, is then simulated to drive the evolutionary process of the algorithm. By sampling from this probability distribution, new candidate solutions are generated, effectively mimicking the population evolution seen in traditional genetic algorithms but without explicitly maintaining a population.",
      "chunk_id": 6613,
      "paper_id": "Real options approach to evaluating genetic algorithms",
      "paper_title": "Real options approach to evaluating genetic algorithms",
      "paper_year": "2009",
      "chunk_content": "The optimal stopping problem is an important class of a stochastic control problem that arises in economics and finance, such as finding optimal exercise rules for financial options. Fortunately, there are similarities in the problem of finding an optimal stopping time in genetic algorithms and finding optimal exercise rules for financial options. The concept behind this technique is that finding an optimal stopping time of the algorithm can be viewed as deciding when to exercise a call option. Note that a call option is the right to buy an asset at a certain price. In this case, exercising a call option is analogous to stopping an algorithm, or buying an asset, same as quitting an algorithm, ignores all future possibilities. To explore this approach, Rimcharoen et al. [42] proposed finding an optimal stopping time in the compact genetic algorithm. Using the compact genetic algorithm, a special class of genetic algorithms, the underlying uncertainty can be viewed as a probability distribution. This distribution automatically captures the underlying uncertainty of the problem, which can be simulated to obtain an evolutionary process of the algorithm. This forms a basis in using the real options valuation in order to determine when it is worth stopping the algorithm. The extensions of this work which improved solution's quality on the deceptive problem were published in [40,41].  \nIn this paper, the analysis and evaluation of univariate EDAs are presented as an example. They include the population-based incremental learning (PBIL) [6], the univariate marginal distribution algorithm (UMDA) [30], and the compact genetic algorithm (cGA) [19]. The different behaviors among these algorithms are also discussed. Although they belong to the same class, they have their own characteristic in searching for solution, which can be specified by their optimal stopping policies.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:33",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the distance between the MIM (Mutual Information Matrix) and the approximated bipartite graph, represented by \\(HH^T\\), minimized in the context of this Estimation of Distribution Algorithm?",
      "topics": [
        "proof"
      ],
      "answer": "The distance between the MIM and \\(HH^T\\) is minimized using a symmetric non-negative matrix factorization (SNMF) approach. Specifically, the divergence distance \\(DD(X, Y) = \\sum_{ij}(x_{ij} \\log \\frac{x_{ij}}{y_{ij}} - x_{ij} + y_{ij})\\) between the two adjacency matrices is minimized using a gradient descent method, where \\(X\\) and \\(Y\\) represent the matrices being compared.",
      "chunk_id": 598,
      "paper_id": "Estimation of distribution algorithm using factor graph and Markov blanket canonical factorization",
      "paper_title": "Estimation of Distribution Algorithm using Factor Graph and Markov Blanket Canonical Factorization",
      "paper_year": "2014",
      "chunk_content": "Let $K(V, U, F)$ be the bipartite graph, where $V=\\left\\{v_{i}\\right\\}_{i=1}^{n}$ is a collection of variables and $U=\\left\\{u_{p}\\right\\}_{p=1}^{m}$ is a set of factor nodes ( $V$ and $U$ are disjoint sets) and $F$ contains all the edges connecting $V$ and $U$. Let $B=\\left\\{b_{i p}\\right\\}$ denote the $n * m$ adjacency matrix with $b_{i p} \\geq 0$ being the weight for edge $\\left[v_{i}, u_{p}\\right]$. To factorize the MIM and finding the corresponding bipartite graph, we use the similarity relation between $v_{i}$ and $v_{j}$ in the bipartite graph $K$ presented in [14].\n$\\operatorname{mim}_{i j}=\\sum_{p=1}^{m} \\frac{b_{i p} b_{j p}}{\\lambda_{p}}=\\left(B \\Lambda^{-1} B^{T}\\right)_{i j}, \\quad \\Lambda=\\operatorname{diag}\\left(\\lambda_{1}, \\ldots, \\lambda_{m}\\right)$\nWhere $\\lambda_{p}=\\sum_{i=1}^{n} b_{i p}$ is the degree of vertex $u_{p} \\in U$.\nThe above equation can be analyzed based on the random walks on graphs. $e_{i j}$ is proportional to the stationary probability of transition between $v_{i}$ and $v_{j}, p\\left(v_{i}, v_{j}\\right)$. All the paths between vertices in $V$, must go through vertices in $U$ in the factor graph, therefore:  \n$$\n\\begin{aligned}\np\\left(v_{i}, v_{j}\\right)=p\\left(v_{i}\\right) p\\left(v_{j} \\mid v_{i}\\right) & =d_{i} \\sum_{p} p\\left(u_{p} \\mid v_{i}\\right) p\\left(v_{j} \\mid u_{p}\\right) \\\\\n& =\\sum_{p} \\frac{p\\left(v_{i}, u_{p}\\right) p\\left(u_{p}, v_{j}\\right)}{\\lambda_{p}}\n\\end{aligned}\n$$  \nwhere $d_{i}=p\\left(v_{i}\\right)$ is the degree of $v_{i}$. When $b_{i p}=p\\left(v_{i}, u_{p}\\right)$, equation (5) and equation (6) are the same. $p\\left(u_{p} \\mid v_{i}\\right)=\\frac{b_{i} p}{d_{i}}$ is the conditional probability of transitions from $v_{i}$ to $u_{p}$ and indicates how likely variable $i$ belongs to factor nodes p.  \nBased on equation (5), the bipartite graph can be approximated by minimizing the distance $\\left(M I M, B \\Lambda^{-1} B^{T}\\right)$. To\nmake the problem easy we use $H=B \\Lambda^{-1 / 2}$, then we have  \n$$\n\\min _{H \\in \\Re_{n}^{n+m}} \\operatorname{distance}\\left(M I M, H H^{T}\\right), \\quad \\text { s.t. } h_{i p} \\geq 1\n$$  \nThis problem is a symmetric non-negative matrix factorization (SNMF) [15]. There are different numerical methods to find the local minima of this problem. Here we use the gradient descent method to minimize the divergence distance between the two adjacency matrices (equation (8)).  \n$$\nD D(X, Y)=\\sum_{i j}\\left(x_{i j} \\log \\frac{x_{i j}}{y_{i j}}-x_{i j}+y_{i j}\\right)\n$$  \nTheorem 4.1 The distance is non-increasing under the following update rule  \n$$\n\\tilde{h_{i p}}=\\frac{h_{i p}}{\\sum_{j} \\tilde{h}_{j p}} \\sum_{j} \\frac{\\operatorname{mim}_{i j}}{\\left(H H^{T}\\right)_{i j}} h_{j p}\n$$  \nThe distance is invariant under the update rule if and only if $H$ is at stationary point of the distance [16].  \nAfter $H$ is calculated, $B$ can be calculated using $B=H \\Lambda^{1 / 2}$ and $\\Lambda=\\operatorname{diag}\\left(\\lambda_{1}, \\ldots, \\lambda_{m}\\right)$ where $\\lambda_{p}=\\sum_{i=1}^{n} h_{i p}$.\nProof of the convergence of the algorithm is available in [16]. We later use $\\lambda_{p}$ as the degree for factor node $p$. In order to provide an algorithmic scheme look at the following pseudo-code:",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:35",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs using Q-learning, and how does it address limitations of traditional genetic algorithms?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective of the Q-learning-based Estimation of Distribution Algorithm is to enhance the probability model of adaptive updates through agent and group interaction, overcoming limitations in solving complex optimization problems. By introducing Q-learning into evolutionary computation, the algorithm aims to avoid the blindness caused by chromosomal recombination and random mutation inherent in traditional genetic algorithms, thereby improving search efficiency and providing a faster, more reliable solution.",
      "chunk_id": 11428,
      "paper_id": "The Research of Q Learning-Based Estimation of Distribution Algorithm",
      "paper_title": "The Research of Q Learning-Based Estimation of Distribution Algorithm",
      "paper_year": "2011",
      "chunk_content": "Hu yugangInformation DepartmentChangzhou Textile Garment InstituteChangzhou chinaHuyugang80@163.com\nThis paper focuses on the theory of estimation of distribution algorithms. First, elaborated the idea of estimation of distribution algorithms, And then for the limitations of solving complex optimization problems,proposed Q Learning-Based Estimation of Distribution Algorithm. The Q learning algorithm is introduced into evolutionary computation, through the Agent and group interaction, to achieve a probability model of adaptive updates. Test functions using six classical comparative experiment, the results show that the algorithm performance is stable, running time is short, with a strong global search ability, is an efficient solving algorithm for function optimization problems.  \nKeywords- Estimation of Distribution Algorithm, Q Learning, Evolutionary Search\nIn order to overcome the genetic algorithm because of chromosomal rearrangements lead to the chain problem, people ask if you can not use the crossover and mutation operations, but by the optimal solution set from the extracted information, and then use this information to generate new solutions of the probability distribution, which Chain Linkage Leaning. The probability model using constructive thinking into the evolution of computing the theoretical basis for estimation of distribution algorithms.  \nThe concept of estimation of distribution algorithm first proposed in 1996, and after the year 2000 has been developing rapidly. It will build into the probability model and the sampling process of evolution to replace the traditional crossover and mutation. As is the use of probabilistic models to guide the search process, to avoid the blindness caused by chromosomal recombination and random, Thus effectively improving the efficiency of search, Fast, reliable solution to many of the traditional genetic algorithm optimization problem difficult to solve.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:36",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the Gaussian model used as the probability model for generating new solutions, specifically concerning the calculation of the mean $\\mu_{j}$ and standard deviation $\\sigma_{j}$?",
      "topics": [
        "performance"
      ],
      "answer": "The Gaussian model employed in the Estimation of Distribution Algorithm calculates the probability of a new solution $\\theta_{i, j}^{(l+1)}$ using the formula $f\\left(\\theta_{i, j}^{(l+1)}\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{j}} e^{-\\left(\\left(\\theta_{i, j}^{(l+1)}-\\mu_{j}\\right)^{2}\\right) / 2 \\sigma_{j}^{2}}$. Here, $\\mu_{j}$ represents the mean of the $j$th parameter across the $R$ selected solutions from the previous generation $l$, computed as $\\mu_{j}=\\frac{1}{R} \\sum_{i=1}^{R} \\theta_{i, j}^{(l)}$. The standard deviation $\\sigma_{j}$ for the $j$th parameter is calculated as $\\sigma_{j}=\\frac{1}{R} \\sum_{i=1}^{R}\\left(\\theta_{i, j}^{(l)}-\\mu_{j}\\right)$, reflecting the dispersion of the selected solutions around the mean. These parameters, $\\mu_{j}$ and $\\sigma_{j}$, are used to define the Gaussian distribution from which new candidate solutions are sampled.",
      "chunk_id": 8077,
      "paper_id": "Improved Renyi Entropy Benchmark for Performance Assessment of Common Cascade Control System",
      "paper_title": "Improved Renyi Entropy Benchmark for Performance Assessment of Common Cascade Control System",
      "paper_year": "2019",
      "chunk_content": "In order to illustrated the effectiveness of the proposed method, the system in section 1 is used based on the MATLAB platform. In all following experiments, the parameters in improved EDA were set to $N=80, R=200$. The Gaussian model is used as the probability model for the new solutions. It is expressed as,  \n$$\n\\left\\{\\begin{array}{l}\nf\\left(\\theta_{i, j}^{(l+1)}\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{j}} e^{-\\left(\\left(\\theta_{i, j}^{(l+1)}-\\mu_{j}\\right)^{2}\\right) / 2 \\sigma_{j}^{2}} \\quad i=1,2, \\ldots, N \\\\\n\\mu_{j}=\\frac{1}{R} \\sum_{i=1}^{R} \\theta_{i, j}^{(l)} \\quad \\sigma_{j}=\\frac{1}{R} \\sum_{i=1}^{R}\\left(\\theta_{i, j}^{(l)}-\\mu_{j}\\right)\n\\end{array}\\right.\n$$  \nwhere the $\\theta_{i, j}^{(l)}$ is the $j$ th parameter of the parameter vector $\\theta_{i}^{(l)}$. The terminated condition is set as $\\left|H_{2}^{(l)}-H_{2}^{(l-1)}\\right| \\leq 0.001$.  \nTo fully explain the accuracy of the simulation, we choose four sets of experiments,\nTo verify the accuracy of the improved EDA algorithm, the disturbances $a_{1}$ of the above table-1 are compared with the actual value and estimated value based on the least square(LS) algorithm. The results are shown in Fig.4.\nIt can be seen from the four figures that the EDA algorithm performs better than LS algorithm for both Gaussian disturbances and non-Gaussian disturbances. The main reason is that the least square algorithm cannot reflect the statistical characteristics of the whole system, so the result of LS algorithm has large deviation.\nTo simulate the mean shift of the system output, a zero offset of amplitude 1 is added to the system output of the third experiment. The output plot is shown in Fig.5,\nTo illustrate the performance of system output, the intervals are chosen as triple the standard deviation which is shown as the horizontal lines in the Fig-5. The output intervals of 4 experiments are $0.8831,0.8092,0.6503,0.7353$. The following table-2 shows the theoretical values and estimated values of MVC benchmark, minimum entropy benchmark (the method which is proposed in literature [15]) and the improved Renyi entropy benchmark which is proposed in this paper.\nFrom the table we can find that the theoretical value of both minimum entropy and improved Renyi entropy is very close to estimated value. It illustrates the effectiveness of improved EDA algorithm. Moreover, compared with other two benchmark, the improved Renyi entropy is more accurate to reflect the mean shift. It reflect the fluctuation of the system output. However, the MVC benchmark and pure minimum entropy benchmark are slow to the fluctuation of output. Thus we can say that the improved entropy benchmark has better robust, accuracy and consistency for non-Gaussian system. The improved EDA algorithm perform well in estimating the parameter space and disturbances.\nIn this paper, the routinely MVC method is reviewed and its defects are illustrated by using the experiment in section 1. The shortcomings of traditional Renyi entropy is illustrated in Section 2. Considering the characteristic of entropy, the improved benchmark based on the mean offset and improved Renyi entropy is proposed. From the simulations in section 4, the improved Renyi entropy can reflect the current performance of a non-Gaussian system with mean shift well. A serious of experiments with mixture disturbances validated the accuracy, robust and consistency of the improved Renyi entropy benchmark. It lays the theoretical foundation for practical engineering. But there still some problems, such as the efficiency of the EDA algorithm is poor. The next step is to improved the efficiency of the proposed method.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:39",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the EDA named Bayesian Optimization Algorithm (BOA) within a single iteration?",
      "topics": [
        "genetic"
      ],
      "answer": "A single iteration of the Bayesian Optimization Algorithm (BOA) involves constructing a Bayesian Network (BN) as a model of promising solutions after selection. New candidate solutions are then generated by sampling the constructed Bayesian network. Finally, new solutions are incorporated into the population, eliminating some old candidate solutions, and the next iteration is executed unless a termination criterion is met.",
      "chunk_id": 6588,
      "paper_id": "Theoretical and Empirical Analysis of a GPU Based Parallel Bayesian Optimization Algorithm",
      "paper_title": "Theoretical and Empirical Analysis of a GPU based Parallel Bayesian Optimization Algorithm",
      "paper_year": "2009",
      "chunk_content": "Bayesian Optimization Algorithm (BOA)[1] belongs to a class of algorithms known as Estimation of Distribution Algorithms (EDAs)[6]. EDAs are an outgrowth of Genetic Algorithms (GAs). Conventional GAs maintain a population of probable solutions and then they apply genetic operators like selection, mutation, and crossover to find the next population. This process continues until the algorithm finds an acceptable solution. EDAs replace the crossover step of conventional GAs with variation. In variation some kind of statistical inference from the existing population is used to construct the next population. In the case of BOA, variation starts by constructing a Bayesian Network (BN) [2] as a model of promising solutions after selection. New candidate solutions are then generated by sampling the constructed Bayesian network. Finally, new solutions are incorporated into the population, eliminating some old candidate solutions, and the next iteration is executed unless a termination criterion is met. Figure 1 shows the important steps in a single iteration of BOA.  \nBOA employs BN to encode the problem structure. Construction of BN is a computation-intensive task and according to Jiri et al. [8] takes more than $95 \\%$ of the total execution time. Parallel implementation of BOA (pBOA) is often used to reduce the total execution time. Almost all the parallel implementations of BOA suggested in the last decade were\ndesigned for clusters or MPPs. However, in this decade other architectures like multicores and Graphical Processing Units (GPUs) are competing as an affordable and energy efficient alternatives to conventional parallel computing paradigms. Such architectures are becoming more and more common and their importance cannot be ignored anymore.  \nGPU is a highly parallel multithreaded and manycore processor originally designed for computer graphics. With the addition of programmable stages and higher precision arithmetic, GPUs are now commonly used for applications that were traditionally handled by a CPU. The use of GPU for nongraphics applications is known as General Purpose processing using GPU or GPGPU in short. GPUs are designed such that more transistors are devoted to data processing rather than data caching and flow control, making GPUs less general purpose than CPUs. However, a carefully designed algorithm on GPU can achieve unprecedented speedups. Compute Unified Device Architecture (CUDA) [4] programming model by nVidia is very well suited to expose the parallel capabilities of GPUs through industry standard programming languages like C.  \nThe main motivation behind this paper is to harness the computational power of modern day GPUs to reduce the total execution time for solving complex combinatorial optimization problems using BOA without compromising the output fidelity. Utilizing memory bandwidth and massive data parallelism in an efficient way are the major design constraints. Although nVidia's Tesla C1060 is capable of 933 GFLOPs/s of processing performance and has a memory bandwidth of 102 $\\mathrm{GB} / \\mathrm{s}$, reaching peak performance or near peak performance is not an easy task. The objective of this research is to have a GPU compatible pBOA, where the algorithm is designed to take maximum advantage of the GPU processing power and memory bandwidth. The primary contribution of this research is the modification in the conventional pBOA algorithm to make it suitable for GPU architecture. By writing this paper, we also want to encourage more research in the area of EDAs over modern parallel architectures. We believe that such architectures will become more and more common in the coming years, making similar implementations inevitable in the very near future. We have not only designed and implemented the proposed algorithm, but in the results section (Sect. V) we empirically demonstrate the speedups achieved by solving different well known optimization problems. This  \n[IMAGE_0]  \nFig. 1. Bayesian Optimization Algorithm (BOA).\npaper is an extension of earlier work done by Asim et al. [7].",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:40",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Cellular Compact Genetic Algorithm (CCGA) discussed, how does the number of nodes in the CCGA network relate to its speed and scalability when implemented on an FPGA, specifically concerning the 'one max' problem and the F1 and F2 functions?",
      "topics": [
        "design"
      ],
      "answer": "The CCGA's speed is stated to be independent of the number of nodes in the network, indicating scalability on FPGA hardware. The text specifies that the CCGA delivers at least two times speed up over a normal compact GA in 'OneMax', F1, and F2 test cases. The CCGA and Cooperative Compact GA (CoCGA) implementations used two nodes, each with 32-bit probability vectors, while the compact GA had only one node with a single 32-bit probability vector. The FPGA resource usage remains compatible with other compact GA implementations, even when scaling up to four nodes, suggesting that the CCGA can address the scalability issue of genetic algorithms with problem size by increasing network size.",
      "chunk_id": 5543,
      "paper_id": "FPGA Implementation of a Cellular Compact Genetic Algorithm",
      "paper_title": "FPGA implementation of a cellular compact genetic algorithm",
      "paper_year": "2008",
      "chunk_content": "We implemented the CCGA with two neighbors in Virtex5 LX50 device. The code was design and coded in  \nsynthesizable Verilog HDL. ModelSim Version 6.2 was used for simulation. Xilinx ISE 9.1 was used for FPGA implementation. For our initial tests of the implementation, \"one max\" problem with 32-bit was used to verify the operation of the CCGA. The simulation result of \"one-max\" is shown in Fig. 5. The hardware was also tested with F1 and F2 functions as follows:  \n$$\n\\begin{aligned}\n& F 1(x)=\\sum_{i=1}^{3} x_{i} \\quad \\text { when }-5.12<x<5.12 \\\\\n& F 2(x)=100\\left(x_{1}^{2}-\\left(x_{1}^{2}-x_{2}\\right)^{2}+\\left(1-x_{1}\\right)^{2}\\right. \\\\\n& \\text { when }-2.048<x_{i}<2.048\n\\end{aligned}\n$$  \nIn Fig. 5, Fig. 6 and Fig. 7, the simulation results show the comparison between normal compact GA, the cooperative GA and cellular compact GA for OneMax, F1, and F2 functions. The CCGA and CoCGA contain two nodes; each has 32-bit probability vectors while CGA has only one node with one 32-bit probability vector. The performance of CCGA outperforms the normal CGA in term of speed and quality of the search results. CCGA provides at least two times speed up over normal compact GA in Onemax, F1 and F2 test cases as shown in Table 1. In addition, the CCGA provides the compatible speed up to the cooperative compact GA.  \nTable 2 shows the FPGA implementation of one node and when CCGA is scaled up to four nodes. From Table 2, the speed of the CCGA is not related to the number of the nodes which demonstrates that CCGA can be scaled up to a problem size in FPGA hardware. The comparison of FPGA resources is shown in Table 2. CCGA occupies the same amount of FPGA resources as others CGA. However, it's more practical to FPGA implementation since it has uniform cell type.  \nThe comparison in term of speed and hardware resources to others compact GA implementation is shown in Table 3. CCGA delivers the same speed and requires the compatible hardware resources.\n[IMAGE2]  \nFigure 5. 32-bit \"OneMax\" simulation results\n[IMAGE3]  \nFigure 6. F1 simulation results\n[IMAGE4]  \nGenerations (machine cycles)\nFigure 7. F2 simulation results  \nTABLE 1 Comparison of the speed up  \nTABLE 2\nFPGA HARDWARE RESOURCE Xilinx VIRTEX-5 LX50  \nTABLE 3 COMPARISON OF FPGA RESOURCES\nIn this paper, the CCGA is presented. The results provide initial evidence that CCGA can outperform the normal compact GA and can provide compatible results to the CoCGA with more applicable to FPGA implementation due to unified cell type. The CCGA delivers a more search performance with the adaptive probability vector recombination. For intrinsic evolvable or adaptive hardware, the CCGA can be used for a hardware GA for real-time evolution and adaptation with increased quality of search results. In addition, CCGA can address a scalability issue of genetic algorithm with problem size since CCGA can scale up with problem size by increasing network size as shown in Table 1.",
      "question_type": "evaluation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:43",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "In the FSS-EBNA algorithm, how does the method for controlling the uncertainty of the evaluation function impact computational cost, specifically concerning the number of 10-fold cross-validations performed?",
      "topics": [
        "heuristic"
      ],
      "answer": "The FSS-EBNA algorithm uses a heuristic to control the uncertainty of the evaluation function, which is based on repeated 10-fold cross-validation. If the standard deviation of the accuracy estimate is above 1%, another 10-fold cross-validation is executed. This process repeats, up to a maximum of five times, until the standard deviation drops below 1%. Consequently, the computational cost, measured by the number of 10-fold cross-validations, varies inversely with dataset size; smaller datasets may undergo multiple cross-validations, while larger datasets might only require a single cross-validation.",
      "chunk_id": 6089,
      "paper_id": "Feature subset selection by Bayesian networks  a comparison with genetic and sequential algorithms",
      "paper_title": "Feature subset selection by Bayesian networks:: a comparison with genetic and sequential algorithms",
      "paper_year": "2001",
      "chunk_content": "Once the FSS problem and EBNA algorithm are presented, we will use the search engine provided by EBNA to solve the FSS problem, resulting in the FSS-EBNA algorithm. In the next lines we will briefly describe its basic components (see [25] for more details).  \nParametrizing the FSS task as an optimization problem, it consists on selecting, for a training set characterized by $d$ features, the subset of features which maximizes the accuracy of a certain classifier on further test instances. Thus, the cardinality of the search space is $2^{d}$. Using an intuitive notation to represent each individual (there are $d$ bits in each individual, each bit indicating whether a feature is present (1) or absent (0)), we can see in Fig. 3 an overview of the application of the EBNA search engine to the FSS problem. In each generation of the search, the induced BN will factorize the probability distribution of selected individuals. The BN will be formed by $d$ nodes, each one representing one feature of the domain.  \nThe determination of a minimum population size to reliably estimate the parameters of a BN is not an easy task [17]. This difficulty is higher for real world problems where the true real probability distribution is not known. In this way, taking the dimensionality of our problems into account, we consider that a population size of 1000 individuals is enough to reliably estimate the BN parameters.  \nA wrapper approach will be used to calculate the evaluation function value of each proposed individual or feature subset. The value of the evaluation function of a feature subset found by the EBNA search technique, once the supervised classifier is fixed, will be calculated by an accuracy estimation on training data.  \n[IMAGE0]  \nFig. 3. FSS-EBNA method.\nThe accuracy estimation, seen as a random variable, has an intrinsic uncertainty. A 10 -fold cross-validation multiple times, combined with a heuristic proposed by Kohavi and John [30], will be used to control the intrinsic uncertainty of the evaluation function. The heuristic works as follows:  \n- if the standard deviation of the accuracy estimate is above $1 \\%$, another 10 -fold cross-validation is executed;\n- this is repeated until the standard deviation drops below FORMULA_106, a maximum of five times.\nIn this way, small datasets will be cross-validated many times. However, larger ones possibly once. Although FSS-EBNA is independent from the specific supervised classifier used within its wrapper approach, in our set of experiments we will use the well-known Naive-Bayes (NB), [10] supervised classifier. It is a simple and fast classifier which uses the Bayes rule to predict the class for each test instance, assuming that features are independent to each other given the class. Due to its simplicity and fast induction, it is commonly used on Data Mining tasks of high dimensionality [30,41]. The probability for discrete features is estimated from data using maximum likelihood estimation and",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:45",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the GA mentioned for solving the RCPSP, based on the description?",
      "topics": [
        "search"
      ],
      "answer": "When implementing the Genetic Algorithm (GA) for the Resource-Constrained Project Scheduling Problem (RCPSP), the code should incorporate a gene to decide either Forward or Backward Schedule Generation Scheme (SGS), or to decide Parallel SGS or Serial SGS, as mentioned for adaptive GA. This gene will influence the schedule generation process within the GA's evolutionary loop.",
      "chunk_id": 5117,
      "paper_id": "A hybrid estimation of distribution algorithm for solving the resource-constrained project scheduling problem",
      "paper_title": "A hybrid estimation of distribution algorithm for solving the resource-constrained project scheduling problem",
      "paper_year": "2012",
      "chunk_content": "With the development of computer technology and computational intelligence, meta-heuristics, such as genetic algorithm (GA), simulated annealing (SA), tabu search (TS), particle swarm optimization (PSO), scatter search (SS), have been developed for solving the RCPSP. In GA, Hartmann (1998) proposed a permutation based GA, which adopted regret-based sampling method and priority rule to produce initial population; Alcaraz and Maroto (2001) presented an activity list based GA in which a gene was  \n[^0]:    * Corresponding author. Tel.: +86 10 62783125; fax: +86 10 62786911.  \nE-mail address: wangling@tsinghua.edu.cn (L. Wang).  \nadded to decide Forward or Backward schedule generation scheme (SGS) to be used. Later, Hartmann (2002) proposed an adaptive GA, in which a gene was adopted to decide parallel SGS or serial SGS to be used. In SA, Boctor (1996) proposed an active list based SA to solve the RCPSP, where serial SGS was used to generate schedule and insert operation was employed as local search; Cho and Kim (1997) introduced a random key based SA, where some activities were delayed on purpose to expand search space; Bouleimen and Lecocq (2003) proposed a global shift operation-based SA, which adopted multiple cooling chains with different initial solution. In TS, Klein (2000) proposed a Forward-Backward tabu search to solve the time-varying RCPSP, where active list and serial SGS were adopted; Artigues, Michelon, and Reusser (2003) introduced an insert based TS, where the abandoned solutions were inserted based on a flow network model; Nonobe and Ibaraki (2001) adopted TS to solve the RCPSP, where shift moves and a specific neighborhood reduction mechanism were developed to improve the standard TS. In PSO, Zhang, Li, Li, and Huang (2005) proposed both permuta-tion-based particle swarm optimization and priority-based PSO for solving the RCPSP. In SS, Debels, De Reyck, Leus, and Vanhoucke (2006) developed a hybrid SS to solve the RCPSP, in which electromagnetism heuristic and Forward/Backward shift of individual activities were adopted to enhance the SS.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:46",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the workspace reachability, represented as \\(\\Theta(\\mathcal{D}, \\mathcal{S})\\), quantified in the context of evaluating the continuum robot design optimization?",
      "topics": [
        "optimization"
      ],
      "answer": "The workspace reachability \\(\\Theta(\\mathcal{D}, \\mathcal{S})\\) is calculated as the ratio of the number of target points reached by the robot \\(N_{\\text {reached }}\\) to the total number of target points in the workspace \\(N_{\\text {target }}\\). A target point \\(p_{j}\\) is considered reachable if the distance between the target point and the robot's end-effector position \\(\\vec{r}_{e}\\), given design variables \\(\\mathcal{D}\\) and state variables \\(\\mathcal{S}_{j}\\), is within a tolerance \\(\\epsilon\\), as defined by the condition \\(\\left\\|p_{j}-\\vec{r}_{e}\\left(\\mathcal{D}, \\mathcal{S}_{j}\\right)\\right\\| \\leq \\epsilon\\).",
      "chunk_id": 9280,
      "paper_id": "Optimal Design of Continuum Robots With Reachability Constraints",
      "paper_title": "Optimal Design of Continuum Robots With Reachability Constraints",
      "paper_year": "2021",
      "chunk_content": "The design of a multi-joint continuum robot is defined as the following optimization problem.  \n$$\n\\begin{aligned}\n\\min _{\\mathcal{D}} & f(\\mathcal{D}) \\\\\n\\text { s.t. } & d_{i, l b} \\leq x_{i} \\leq d_{i, n b} \\quad \\forall x_{i} \\in \\mathcal{D} \\\\\n& \\boldsymbol{\\Theta}(\\mathcal{D}, \\mathcal{S}) \\geq \\alpha\n\\end{aligned}\n$$  \nHere, $\\mathcal{D}$ represents a set of design variables $x_{i}$, such as the dimensions of a robot, and $\\mathcal{S}$ denotes a set of state variables that define the configuration of a robot, such as each joint's radius of curvature and angle. For the objective function $f(\\mathcal{D})$, the current work considers two different types - the total length of the robot and the minimum actuator torque required to reach a given workspace. Each design variable $x_{i}$ has lower and upper  \nbounds, $d_{i, l h}$ and $d_{i, u b}$, respectively, indicating the limits on robot dimensions. Finally, $\\Theta(\\mathcal{D}, \\mathcal{S})$ computes the percentage of the workspace that can be reached by a robot, and this value must be greater than the threshold $\\alpha$.  \nIn order to compute $\\Theta(\\mathcal{D}, \\mathcal{S})$, a given workspace is discretized into a set of target points in the 3D space. Then, its value can be calculated by  \n$$\n\\Theta(\\mathcal{D}, \\mathcal{S})=\\frac{N_{\\text {reached }}}{N_{\\text {target }}}\n$$  \nwhere $N_{\\text {target }}$ represents the number of target points in the workspace and $N_{\\text {reached }}$ is the number of such points that can be reached by a robot. $N_{\\text {reached }}$ is determined based on  \n$$\n\\left\\|p_{j}-\\vec{r}_{e}\\left(\\mathcal{D}, \\mathcal{S}_{j}\\right)\\right\\| \\leq \\epsilon \\quad \\text { for } j=1, \\ldots, m\n$$  \nin which $p_{j}$ is each of the $m$ target points considered and $\\vec{r}_{e}\\left(\\mathcal{D}, \\mathcal{S}_{j}\\right)$ computes the corresponding position of the robot's end-effector as shown later. $\\epsilon$ is the tolerance allowed.\nFirst presented is the formulation of kinematics used to perform a reachability analysis, followed by the optimization method using an estimation of distribution algorithm.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:49",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs employing Forward-Backward Iteration (FBI) in conjunction with the permutation-based local search (PBLS) strategy, and how does the choice between Activity List (AL) and Early Activity List (EAL) representations affect the computational time within the FBI procedure?",
      "topics": [
        "control"
      ],
      "answer": "The algorithmic approach aims to enhance the exploitation ability of EDAs for the Resource-Constrained Project Scheduling Problem (RCPSP) by integrating a permutation-based local search (PBLS) controlled by a threshold Pper, which explores the neighborhood of an individual without breaking precedence feasibility. The Forward-Backward Iteration (FBI) iteratively applies Serial Generation Scheme (SGS) in forward and backward directions to improve the makespan. When using FBI, adopting the EAL representation reduces computational time compared to using only AL, specifically reducing the computational time to approximately two-thirds due to differences in the number of calculating, sorting ($O(n \\log n)$), and scheduling ($O(n^{2})$) operations required within each iteration, where 'n' relates to problem size.",
      "chunk_id": 5122,
      "paper_id": "A hybrid estimation of distribution algorithm for solving the resource-constrained project scheduling problem",
      "paper_title": "A hybrid estimation of distribution algorithm for solving the resource-constrained project scheduling problem",
      "paper_year": "2012",
      "chunk_content": "To enhance the exploitation ability, a permutation-based local search strategy PBLS controlled by a threshold Pper is proposed to explore the neighborhood of an individual. This operator is a variation of SWAP operator, but the PBLS does not break the precedence feasibility of the EAL if it is precedence feasible before performing local search. The procedure of PBLS is described in Fig. 5.\nForward-Backward iteration (FBI) is an effective technique for the RCPSP (Li \\& Willis, 1992). Basically, the procedure iteratively employs SGS to Forward and Backward schedule until there is no further improvement to the makespan of the project. The activity finish times of a Forward schedule determine the activity priorities for the next Backward schedule. Similarly, the activity start times of a Backward schedule determine the activity priorities for the Forward schedule. The FBI can be easily incorporated into many algorithms for the RCPSP to improve the solution quality. In Fig. 6(a), a single iteration step is used to illustrate procedure of the FBI.  \n  \nFig. 5. Procedure of the PBLS.  \nTo reduce the makespan of Fig. 2, the FBI is used by shifting each activity to the right as much as possible in decreasing order of activity end times. For example, Activity 9 and Activity 7 cannot be scheduled later. Activity 8 can be right shifted to start at time 15 . Activity 6 can be shifted two time units and start at time 10. Since the right shift of Activity 8 has made some additional resources available, Activity 1 can be shifted three time units to start at time 9. Activity 2, Activity 3 and Activity 5 can be shifted two time units. Finally, Activity 4 is shifted to time 14. In this way, we obtain a schedule with a makespan of 16 units. Further improvements of the schedule are possible by shifting activities as much as possible to the left. This process reduces the makespan by one further time unit, as illustrated at the bottom of Fig. 6(a).  \nIf the EAL is adopted, two sort operations and two schedule operations are needed in a single iteration of FBI as shown in Fig. 6(b). However, if only AL is adopted, two calculating operations, two sort operations, and three schedule operations are needed in a single iteration of FBI as shown in Fig. 6(c).  \nSince the time complexity of quick sort is $O(n \\log n)$, the time complexity of serial SGS is $O\\left(n^{2}\\right)$, and the time complexity of computing $F T$ (ST) according to $S T(F T)$ is FORMULA_51, the computational time of the FBI with EAL will be about two third of the computational time of the FBI with AL.",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:51",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, how does the algorithmic mechanism of Bayesian evolutionary algorithms (BEAs) differ from a fully Bayesian approach, particularly concerning the use of maximum a posteriori probability (MAP)?",
      "topics": [
        "optimization"
      ],
      "answer": "Bayesian evolutionary algorithms (BEAs) formulate optimization as a probabilistic process of finding an individual with the maximum a posteriori probability (MAP). However, BEAs, despite their name, operate in a frequentist setting. This means they find an optimum point estimate of the parameters and plug this estimate into the formula for the distribution of a data point. A Bayesian approach, in contrast, would use the posterior predictive distribution to do predictive inference, returning a distribution over possible points instead of a fixed point as a prediction. Also, another method estimates the sample distribution with a graphical learning model using Helmholtz machines, making the optimization a sequential probabilistic process of finding the parameters with the maximum likelihood estimation (MLE) in a frequentist setting.",
      "chunk_id": 10267,
      "paper_id": "Language model based interactive estimation of distribution algorithm",
      "paper_title": "Language model based interactive estimation of distribution algorithm",
      "paper_year": "2020",
      "chunk_content": "EDAs [35,36] macroscopically reveal a large amount of information about the population by building an explicit probabilistic model of promising candidate solutions. Then, the offspring population is generated by sampling from a probabilistic model [3740]. Several methods of building and sampling from the distribution of the population have been proposed, including methods based on dependent chains/trees, factorization, neural trees, Bayesian networks, and genetic programming [37].  \nSince EDAs are a novel evolutionary optimization paradigm based on genetic algorithms and statistical learning, it is quite natural to integrate a Bayesian learning framework into EDAs. However, little research on this has been reported and researchers preferred taking the Bayesian network to decompose problems [37,39,41-43]. In [44], Zhang proposed Bayesian evolutionary algorithms (BEAs) in which optimization was formulated as a probabilistic process of finding an individual with the maximum a posteriori probability (MAP). Even with the name that looks like a method belonging to Bayesian statistics, BEAs are frequentist since prediction in frequentist statistics often involves finding an optimum point estimate of the parameters and then plugging this estimate into the formula for the distribution of a data point, whereas Bayesian theory calls for the use of the posterior predictive distribution to do predictive inference, i.e. instead of a fixed point as a prediction, a distribution over possible points is returned. In [43], Zhang and Shin proposed a method that estimates the sample distribution with a graphical learning model: the Helmholtz machines. Essentially, this method makes the optimization a sequential probabilistic process of finding the parameters with the maximum likelihood estimation (MLE). Both of the methods above addressed the probabilistic process in a frequentist setting instead of a Bayesian setting, in which a distribution rather than an estimated value could be generated.  \nWith the Bayesian setting, uncertainty and more information over values of the target variable can be expressed using a probability distribution. However, little research on the fusion of the Bayesian learning framework and interactive estimation of distribution algorithms (IEDAs) has been performed.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:53",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to optimize energy management in Plug-in Hybrid Electric Buses, how should practitioners discretize the engine power to reformulate the cost function, and what constraints must be considered during this discretization?",
      "topics": [
        "optimization"
      ],
      "answer": "Practitioners should discretize the engine power into $M$ levels, indexed by $j$, to reformulate the cost function. The cost function becomes a minimization problem involving the sum of $h(k+i, j) P_{c}(j) / \\eta_{c}(j)$ over $i$ from 1 to $N_p$ and $j$ from 1 to $M$, where $P_{c}(j)$ represents the $j$th discretized power level and $\\eta_{c}(j)$ is the corresponding engine efficiency. The variable $h(k+i, j)$ is a binary variable indicating whether the $j$th power level is selected at time step $k+i$. The constraints are that the sum of $h(k+i, j)$ over all $j$ must equal 1 for all $i$, $h(k+i, j)$ must be either 0 or 1, and Equations (19) and (21) must be satisfied. The size of the population is denoted by $L$, and the population is represented by a matrix $\\mathbf{M}$ of size $L \\times N_p$, where $N_p$ is the length of the prediction horizon.",
      "chunk_id": 1483,
      "paper_id": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_title": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_year": "2022",
      "chunk_content": "The aforementioned MPC problem exhibits a high dimensionality, strong nonlinearity, and uncertain nature. Compared with common typical methods, such as the shooting method and sequential quadratic programming, the EDA as a population-based and iterative algorithm is very powerful in solving such a PHEB energy management problem, which exhibits the outstanding ability of global search and faster convergence.  \nEDA can reproduce a new population using statistical information extracted from search experience instead of traditional evolutionary operators. In the search space, a probability model of the most promising solutions is constructed. Then, the new individuals can be generated from the aforementioned model, and this process is called sampling. Based on new individuals, a new probability model is estimated and reconstructed, which describes the distribution of the most promising solutions. Hence, the population can evolve toward the optimal solutions by repeating the above-mentioned steps. The EDA flowchart is also presented in Fig. 6.  \nTo apply the EDA algorithm in the optimization problem of energy management for PHEBs, the cost function should be  \nTABLE III\nRePRESENTATION OF THE POPULATION MATRIX M  \nreformulated by discretizing the engine power as follows:  \n$$\n\\begin{aligned}\nJ= & \\min \\sum_{i=1}^{N_{p}} \\sum_{j=1}^{M} h(k+i, j) P_{c}(j) / \\eta_{c}(j) \\\\\n& +\\gamma\\left[S O C\\left(k+N_{p}\\right)-S O C_{r}\\left(k+N_{p}\\right)\\right] \\\\\n\\text { s.t. } & \\sum_{j=1}^{M} h(k+i, j)=1 \\quad \\forall j \\\\\n& h(k+i, j)=\\{0,1\\} \\quad \\forall i, j \\\\\n& \\text { Eq. (19) and (21) }\n\\end{aligned}\n$$  \nwhere $M$ is the number of discretized power levels, $j$ is the index of the power level, $P_{c}(j)$ is the $j$ th discretized power level for the engine, and $\\eta_{c}(j)$ is the associated efficiency for the engine. Once the engine power is determined, the fuel consumption can also be calculated in (1). In this optimization problem, each individual consisting of an engine power sequence is a candidate solution, whose vector size is the length of the predictive horizon. Here, the Gaussian distribution is selected as a probabilistic model to characterize the candidate solutions. Assuming the size of the population is $L$, the population can be expressed as a matrix $\\mathbf{M}=\\left(m_{i j}\\right)_{L \\times N_{p}}$, whose representation is listed in Table III. Taking Individual1 as an example, the engine power level at the second time step of the horizon is 0 kW , which implies that the engine is shut off and only the battery pack can supply power.  \nFor each element of every individual in the population, the Gaussian probabilistic distribution can be formulated as follows:  \n$$\n\\begin{aligned}\ng(m, u, \\sigma) & =\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(m-u)^{2}}{2 \\sigma^{2}}}, u=m_{i j} \\\\\n\\sigma & =\\frac{\\rho_{1}}{\\sqrt{L-1}} \\sqrt{\\sum_{l=1}^{L}\\left(m_{l j}-m_{i j}\\right)^{2}}\n\\end{aligned}\n$$  \nwhere $\\rho_{1}$ is a constant. Here, the number of Gaussian functions is $L \\times N_{p}$. The mean and standard deviation values of each Gaussian function are different.  \nSubsequently, each individual is substituted into the cost function to obtain the cost value. According to the cost value in ascending order, the priority vector $\\mathbf{R}=\\left[r_{1}, r_{2}, \\cdots, r_{h}, \\cdots, r_{L}\\right]^{\\mathrm{T}}$ is generated. For example, $r_{l}=1$ when the $l$ th individual has the minimum value of the cost function. Then, the weight of each\nindividual can be calculated by the following expression:  \n$$\n\\omega_{i}=\\frac{1}{\\rho_{2} L \\sqrt{2 \\pi}} e^{-\\frac{\\left(r_{i}-r_{l}\\right)^{2}}{2 \\rho_{2} L)^{2}}}, i=1, \\cdots, L\n$$  \nwhere $\\omega_{i}$ is the weight for the $i$ th individual and $\\rho_{2}$ is a constant. For the dominant individual, its weight has a larger value.  \nTo generate the new individual, the Gaussian distribution for the $j$ th element of the new individual should be selected from the group of Gaussian probabilistic distributions expressed in (24). The corresponding selection probability can be defined as follows:  \nFORMULA_130",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:57:55",
      "generation_style": "practical_application"
    },
    {
      "question": "Considering the modularity quality function, $Q$, used in community detection, how does Property 2, which states that the value of $Q$ increases monotonically with $f(i)$, relate to the overall optimization process, where $f(i)$ is defined as the difference between the actual number of connections within a community and the expected number of connections in a randomly connected community?",
      "topics": [
        "proof"
      ],
      "answer": "Property 2 implies that as the local community structure, measured by $f(i)$, improves for individual nodes $i$ within the network $N(V, E)$, the global modularity $Q$ is guaranteed to increase. Specifically, if a node $i$ is moved from community $r(i)$ to $r(j)$, creating a new community structure $C'$, and the change in $f(i)$ for nodes in the affected communities ($c_{r(i)}' \\cup c_{r(j)}$) is positive, then the overall $Q$ value will increase. This monotonic relationship suggests that a local optimization strategy that iteratively improves $f(i)$ for individual nodes can effectively guide the algorithm towards a community structure with higher modularity, although it doesn't guarantee finding the global optimum.",
      "chunk_id": 10838,
      "paper_id": "The Improved Estimation of Distribution Algorithms for Community Detection",
      "paper_title": "The Improved Estimation of Distribution Algorithms for Community Detection",
      "paper_year": "2018",
      "chunk_content": "The design of the $Q$ function is based on the observation that as the network community structure becomes more obvious, the difference between it and random networks increases ${ }^{[7-11]}$. The specific details of the $Q$ function are described as follows.\nAssume that we are given the undirected and unweighted network $N(V, E)$, the vertex set of $V$, and the set of edges of $E$, where $V$ is clustered (divided) into a number of communities. If we suppose that $R(i)$ are the community tags of node $i$, and the set $\\operatorname{Cr}(i)$ is the community node set that $i$ belongs to, then the $Q$ function is expressed as  \n$$\nQ=\\frac{1}{2 m} \\sum_{i, j}\\left(\\left(A_{i j}-\\frac{k_{i} k_{j}}{2 m}\\right) \\times \\delta(r(i), r(j))\\right)\n$$  \nwhere the adjacency matrix of the network is $A=\\left(A_{i j}\\right)_{n \\times n}$, $\\delta(u, v)=\\left\\{\\begin{array}{ll}1 & u=v \\\\ 0 & u \\neq v\\end{array}\\right.$, the degree of node $i$ is $k_{i}$, and the total number of edges is m .  \nThe $Q$ function is the difference between the number of edges in the actual network within the community and a completely randomly connected community with the expected number.  \nIn the following section, we start from the local viewpoint to analyze the $Q$ function; thus, we simplify equation (1) as follows:  \n$$\n\\left\\{\\begin{array}{l}\nQ=\\frac{1}{2 m} \\sum_{v} f(i) \\\\\nf(i)=\\sum_{i \\neq v_{i j}}\\left(A_{i j}-\\frac{k_{i} k_{j}}{2 m}\\right)\n\\end{array}\\right.\n$$  \nThe $Q$ function can be expressed by the function $f(i)$ of all nodes. Obviously, $f(i)$ can be understood as follows: the difference between the actual number of connections within the community and the expected number of connections in a randomly connected community. Thus, from the local viewpoint, $f(i)$ can measure the community structure of the network. The following discussion considers the related properties of $f(i)$.  \nProperty 1: For any $i$ that belongs to $V, f(i)$ is only related to the community to which node $i$ belongs.  \nProof: For $f(i)=\\sum_{j \\neq v_{i j}}\\left(A_{i j}-\\frac{k_{j} k_{j}}{2 m}\\right)$, this formula is the sum of $j$, which is apparently only related to the nodes.  \nProperty 2: The value of $Q$ function increases monotonically with $f(i)$.  \nProof: Assume that the network $N=(V, E), C=\\left\\{c_{r}(i)\\right.$, $\\left.c_{(i j)}, \\ldots, c_{(i q)}\\right\\}$ is a community division. $c_{r(i)}$ contains the nodes labelled with $r(i)$. For any $i$ that belongs to $V$, the community label is $r(i)$, and the corresponding community is $c_{r(i)}$. Suppose that only the community label of $i$ changes from $r(i)$ to $r(j)(r(i) \\neq r(j))$, whereas the other nodes do not change, which forms a new community structure $\\mathrm{C}^{\\prime}$. Thus, $C^{\\prime}$ contains $c_{r(i)}^{\\prime}=c_{r(i)} /\\{i\\}$ and $c_{r(j)}^{\\prime}=c_{r(j)} \\cup\\{i\\}$. By combining function $f$ in formula (2), the definition of the $Q$ function, and Property 1 , the $f$ function value will be the corresponding changes, i.e. the set $c=c_{r(i)} \\cup c_{r(j)}, c^{\\prime}=c_{r(i)}^{\\prime} \\cup c_{r(j)}^{\\prime}$. Of course, we have $c=c^{\\prime}=c_{r(i)}^{\\prime} \\cup c_{r(j)} \\cup\\{i\\}$; hence, we can discuss the changes in the value of function $f$ in $c$.  \n1) For any s in $c_{r(i)}^{\\prime}$, there is:  \n$$\n\\Delta f_{s}=\\sum_{i \\neq v_{i j}}\\left(A_{i i}-\\frac{k_{i} k_{j}}{2 m}\\right)-\\sum_{i \\neq v_{i j}}\\left(A_{i i}-\\frac{k_{i} k_{j}}{2 m}\\right)\n$$",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:57:58",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the encoding of vertices affect the convergence of the described EDA approach for community detection?",
      "topics": [
        "convergence"
      ],
      "answer": "Encoding all vertices into a single particle results in a long particle length, which slows down convergence. To improve convergence, the described EDA encodes only the number of communities and the center of each community, rather than encoding every vertex. This reduces the particle length and avoids complex operations needed to eliminate alone vertices.",
      "chunk_id": 958,
      "paper_id": "PSO-Based Community Detection in Complex Networks",
      "paper_title": "An EDA-based Community Detection in Complex Networks",
      "paper_year": "2014",
      "chunk_content": "In order to determine the structure of a network, the vertices should be clustered and each cluster is a community. The choice of an efficient representation for\nnetwork structure is one of the most important issues in the optimizing process. If all vertices are encoded into a particle, the length of the particle is too long for quick convergence. In addition, complexly operation should be done at the end of the algorithm to eliminate the alone vertices. Therefore, only the number of communities and the center of each community are encoded. The structure of the particle includes two parts are as follows:\n[IMAGE5]  \nFigure 6. Structure of a particle.\nWhere flag $_{i}$ indicates whether or not the $i$-th center is valid in the result, their values are between 0 and 1 . If flag $_{i}<0.5$, the $i$-th center is not included in the result partition. Otherwise the $i$-th center is valid. In such a way, the number of valid flag $_{i}$ represents the number of communities.\ncenter, is the $i$-th community center corresponding to flag $_{i}$. If flag $_{i}$ is valid, center $_{i}$ is valid too. Otherwise, center $_{i}$ is not used when computing partition result. Since the components of $t_{i}$ in (2) are interrelated and $t_{i 1}$ represents the feature of $i$-th vertex best in $t_{i j}(j=1$, $2, \\cdots, r)$, only the first dimension of the cluster center is encoded. Suppose $a=\\min \\left(t_{11}, t_{21}, \\cdots, t_{r 1}\\right)$ and $b=\\max \\left(t_{11}\\right.$, $\\left.t_{21}, \\cdots, t_{r 1}\\right)$, then center $_{i} \\in[a, b]$.  \nEach particle in the swarm expresses a partition of vertices in the network. When transforming a particle into a factual network partition, the $j$-th node within which $t_{j 1}$ is closest to the valid center $t_{i}$ among all $t_{j i j}(p=1,2, \\cdots, s)$ is a valid center of communities. After all centers are determined, the spectral method weighted distances from nodes to all centers are computed and each node is divided to the community with the smallest weighted distance. The process is described as follows:  \n1) Compute the number of valid flag $_{i}$, let $n=$ $\\sum_{i=1}^{n-1} \\operatorname{round}\\left(\\right.$ flag $\\left._{i}\\right)$.\n2) If $n<2, n=2$, find $p$ and $q$ where flag $_{p}$ and flag $_{q}$ are no less than other flag $_{i}(i \\in[1, r+1])$, make flag $_{p}=1-0.5 \\times \\operatorname{rand}(0,1)$, flag $_{p}=1-0.5 \\times \\operatorname{rand}(0,1)$.\n3) For each flag $_{i}>0.5$, find $t_{j 1} \\in T$ where $t_{j 1}$ is closest to center $_{i}$. Make $\\left[t_{j 1}, t_{j 2}, \\cdots, t_{j(n-1)}\\right]$ one valid center of the communities.\n4) Combine centers to one if they have the same value. If the modified $n=1$, then set $n=2$ and select $t_{j \\cdot 1}$ where $t_{j \\cdot 1}$ is furthest from the original center $t_{j 1}$. Replace the combined center, with $t_{j \\cdot 1}$ and set $\\left[t_{j \\cdot 1}, t_{j \\cdot 2}\\right.$, $\\left.\\cdots, t_{j \\cdot(n-1)}\\right]$ the second center.  \n5) Compute spectral method weighted distance from all vertices to centers by (1); where $m$ is set to $n$. Divide nodes to communities with the smallest distance to their centers.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:57:59",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model to optimize truck scheduling in underground mines, considering the objective functions of minimizing total shift transportation distance and the total waiting time of transport trucks?",
      "topics": [
        "search"
      ],
      "answer": "The algorithmic steps involve using an improved estimation of distribution algorithm to solve the truck scheduling model. This results in the optimal ore blending and scheduling schemes. The algorithm considers reducing transportation costs and increasing transportation efficiencies, while also accounting for truck meeting situations in the ramp section. The algorithm's performance is evaluated by comparing it with a genetic algorithm, particle swarm optimization algorithm, and immune algorithm, focusing on convergence speed and the search for the optimal solution.",
      "chunk_id": 3111,
      "paper_id": "Scheduling optimization of underground mine trackless transportation based on improved estimation of distribution algorithm",
      "paper_title": "Scheduling optimization of underground mine trackless transportation based on improved estimation of distribution algorithm",
      "paper_year": "2024",
      "chunk_content": "Ning $\\mathrm{Li}^{\\mathrm{a}, \\mathrm{b},{ }^{*}}$, Yahui $\\mathrm{Wu}^{\\mathrm{b}}$, Haiwang $\\mathrm{Ye}^{\\mathrm{a}, \\mathrm{b}}$, Liguan Wang ${ }^{\\mathrm{c}}$, Qizhou Wang ${ }^{\\mathrm{a}, \\mathrm{b}}$, Mingtao Jia ${ }^{\\mathrm{c}}$${ }^{a}$ Hubei Key Laboratory of Mineral Resources Processing and Environment, Wuhan University of Technology, Wuhan, Hubei 430070, China${ }^{\\mathrm{b}}$ School of Resource and Environment Engineering, Wuhan University of Technology, Wuhan, Hubei 430070, ChinaFORMULA_8 School of Resource and Safety Engineering, Central South University, Changsha, Hunan 410083, China\nKeywords:\nUnderground mine\nTrackless transportation\nEstimation of distribution algorithm\nO re blending scheme\nScheduling optimization  \nA B STR ACT  \nThe trend in underground mine development is trackless transportation, and the scheduling optimization of underground mine trackless transportation is a current research hotspot. This paper proposes a truck scheduling optimization method for underground mine trackless transportation based on an improved estimation of distribution algorithm to address the truck scheduling problem in the underground mine trackless transportation process. The transportation process of transport trucks in underground mines is analyzed. The dispatching model of transport trucks in underground mines is constructed based on the requirements of reducing transportation costs and increasing transportation efficiencies, taking into account the truck meeting situation in the ramp section and minimizing the total shift transportation distance and the total waiting time of transport trucks as the objective functions. The improved estimation of distribution algorithm is used to solve the truck scheduling model, resulting in the optimal ore blending and scheduling schemes. The comparative analysis employs a genetic algorithm, particle swarm optimization algorithm, and immune algorithm. The results demonstrate that, compared to other algorithms, the improved estimation of distribution algorithm proposed in this paper has superior performance in terms of convergence speed and the search for the optimal solution. The total number of transportation tasks associated with the optimal ore allocation scheme is at least 82 , and the waiting time associated with the optimal scheduling scheme is reduced to 7.5 min . The operation time chart of transport trucks calculated by the optimal dispatching scheme can clearly depict the location of each transport truck at any time during a shift's working time, which has significant guiding significance for the actual truck transportation in the mine.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:01",
      "generation_style": "implementation_focused"
    },
    {
      "question": "When evaluating the EDA-SoHC algorithm for solving distributed asymmetric CSPs, what specific performance indicators are considered, and how are they statistically compared to other algorithms?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The EDA-SoHC algorithm's performance is evaluated based on the Success Rate (SR) and the number of Cycles required to solve the distributed asymmetric CSPs. The statistical correlation between these metrics for the GSoHC variants (using distributed restricted forms uniform crossover and modified two-point crossover) and the EDA-SoHC (with epsilon=0.125) is analyzed. Performance comparisons involve assessing whether the differences in the number of cycles between EDA-SoHC and other algorithms like SoHC, GSoHC, and ESoHC are statistically significant, particularly for easier instances of the problem.",
      "chunk_id": 6301,
      "paper_id": "A Comparison of Evolutionary Protocols for Solving Distributed Constraint Satisfaction Problems",
      "paper_title": "A comparison of evolutionary protocols for solving distributed constraint satisfaction problems",
      "paper_year": "2006",
      "chunk_content": "The applied evolutionary operators, known as crossover and mutation, on randomly generated distributed asymmetric CSPs are studied in the work presented in this paper. The SoHCs, GSoHCs, EDA-SoHC and ESoHC are described and a series of experimental results and comparisons are presented. In particular, GSoHCs using distributed restricted forms uniform crossover, and modified two-point crossover, are studied with respect to SR, Cycles and their statistical correlation to the EDA-SoHC $(\\varepsilon=0.125)$.  \nFrom experimental results and a series of comparisons, we can draw the following conclusions:\nIn general, we note that SoHC performs noticeably worse than all the other algorithms, save for the easiest instances when $\\mathrm{p} 2=0.03$.\nGenerally speaking, GSoHCmtpx has better performance than GSoHCupx due to the fact that it takes more genes from the best dCS.  \nThe GSoHCs and ESoHC have better performance than the simple SoHC. The EDA-SoHC protocol performs roughly on par with ESoHC under most conditions. Further, the differences between the number of cycles for EDA-SoHC and for the other algorithms are generally not statistically significant, except for the easier instances ( FORMULA_194 and 0.04 ). In general, we attribute the success of the EDA-SoHC to its application of selection pressure through taking genetic material from the above average members of the population. At the same time, the algorithm preserves a level of population diversity by granting the opportunity for a child to obtain attributes from any of the above-average individuals (not merely the best).  \nComparing the results between GSoHC, ESoHC, and EDA-SoHC suggests that the variation of the above-average dCS's plays the most important role in the genetic and evolutionary SoHC search. The specific type of operator creating this variation is only of secondary importance [32]. Our future work will be devoted to discovering a form of recombination that is has a performance equal to or better than the distributed restricted uniform mutation operator and the EDA-SoHC.",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:03",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in feature subset selection, particularly when dealing with large feature sets or computationally intensive algorithms like PSVM?",
      "topics": [
        "genetic"
      ],
      "answer": "The primary purpose is to provide a scalable and efficient method for feature subset selection by tuning EDA parameters such as P, E, and I to discover a relevant subset of S features. This approach aims to address the computational infeasibility of methods like SBE when feature sets are large or algorithms like PSVM are time-demanding, offering a considerable speedup without sacrificing efficiency.",
      "chunk_id": 13226,
      "paper_id": "Fast feature selection using a simple estimation of distribution algorithm  a case study on splice site prediction",
      "paper_title": "Fast feature selection using a simple estimation of distribution algorithm: a case study on splice site prediction",
      "paper_year": "2003",
      "chunk_content": "set and gradually decreases the number of features until a set of $S$ features remains. For both holdout sets it is observed that the EDA-approach provides a considerable speedup. The increase in speed depends on a number of things like e.g. complexity of the algorithm, size of the constrained subset and the holdout set. Whereas the increase in speed is not so much in the case of NBM on an unbalanced holdout set and a subset of 150 features, the speedup for the PSVM on the unbalanced holdout set for a fixed number of 40 features is about a factor 10 .  \nThese results support the view that the use of EDAs for feature selection provides a very practical approach when feature sets get larger or when very time-demanding algorithms (like e.g. PSVM) are used. In these cases the use of SBE becomes computationally infeasible and by tuning the EDA-parameters $P, E$ and $I$, a relevant subset of $S$ features can be discovered.\nGenetic Algorithms (GAs) have been frequently used for feature subset selection in small scale (less than 100 features) domains (Kudo and Sklansky, 2000; Siedelecky and Sklansky, 1988; Vafaie and De Jong, 1993). The use of  \nEDA's for feature subset selection was pioneered by Inza et al. (1999) and the use of EDA's for FSS in large scale domains was reported to yield good results (Larranaga and Lozano, 2001). Cantu-Paz (2002) compared several EDA's with the simple GA for small scale domains (at most 35 features) using a Naive Bayes classifier, and concluded that the complicated dependency learning EDA's are not significantly better than the simple compact GA. It has to be pointed out that the EDA-UMDA approach is very similar to the compact GA (Harik et al., 1998) or to a GA with uniform crossover.\nRecently, the technique of feature distributional clustering was combined with Support Vector Machines for text categorization (Bekkerman et al., 2001). This method performs feature selection by distributional clustering of words via the information bottleneck method (Tishby et al., 1999) and can be considered a sophisticated filter method.\nAn extensive overview of splice site recognition, including new methods like Support Vector Machines can be found in Sonnenburg (2002), while a more general overview and a comparison of gene and splice site prediction is discussed in Mathe et al. (2002) and Zhang (2002).\nThe results displayed in this paper are showing that feature subset selection by estimation of distribution algorithms is able to select highly relevant features for splice site prediction. We presented a method that is scalable to larger feature sets and, when applied with a constraint on the size of the feature subset, provides a considerable gain in speed. This was obtained at no expense on efficiency, on the contrary. The method can be used for any optimisation problem where the feature set is sufficiently large, like e.g. gene selection in microarray datasets. Future research on splice site prediction will include position-independent information, possibly also structural information to achieve better results. Other future directions we would like to explore are the combination of EDAs with other classification systems, and the development of faster estimation algorithms for multiple dependencies.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:04",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of evaluating classification performance, what statistical property of the Area Under the Curve (AUC) connects it to ranking probabilities and how is this property computationally leveraged?",
      "topics": [
        "algorithm"
      ],
      "answer": "The Area Under the Curve (AUC) has a statistical property where it is equivalent to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance. This property is leveraged computationally through the concordance index, or $c$-index. The $c$-index is computed by creating all possible pairs of observations where one element has $c_{j}=1$ and the other has $c_{j}=0$. The $c$-index then represents the proportion of times the observation with $c_{j}=1$ has the higher of the two probabilities, with ties resolved by coin tossing. Without ties, the $c$-index is equivalent to the AUC and the Mann-Whitney $U$ statistic.",
      "chunk_id": 5930,
      "paper_id": "Optimizing logistic regression coefficients for discrimination and calibration using estimation of distribution algorithms",
      "paper_title": "Optimizing logistic regression coefficients for discrimination and calibration using estimation of distribution algorithms",
      "paper_year": "2008",
      "chunk_content": "The ROC curve is commonly summarized by the area under the curve (AUC) (Hilden 1991; Bradley 1997). AUC ranges from 0 to 1 , where perfect discrimination between both classes corresponds to an area of 1 (a horizontal line through the point $(1,1))$ and random classification corresponds to an area of 0.5 (the identity line).  \nThere are many ways to compute the AUC (Fawcett 2003). We can use the trapezoidal rule after connecting the ROC curve points by straight lines (Horton et al. 2004), which is a poor computational strategy, known to underestimate the AUC if the number of points is limited (Hanley and McNeil 1982). AUC has an important statistical property: it is equivalent to the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance. Thus, an intuitive way to proceed is by computing the concordance index or $c$-index, as follows. Let us create all the possible pairs of observations such that its first element has $c_{j}=1$ and the second element has $c_{j}=0$. Then, the $c$-index is the proportion of the time that the observation with $c_{j}=1$ has the higher of the two probabilities, with ties resolved by tossing an unbiased coin (Harrell et al. 1996; Hanley and McNeil 1982). Without ties, the $c$-index is the AUC and is equivalent to  \nthe Mann-Whitney $U$ statistic, which is another form of the Wilcoxon rank-sum test (Hajek et al. 1999). Under limited information-like having only a single point of the ROC curve-approximations to the AUC can be computed (van den Hout 2003). Other approximations, both parametric and non-parametric, have been proposed in the large literature on the subject, see a review in Lasko et al. (2005).",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:06",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an algorithm to solve instances with 100 tasks ($|V|=100$) derived from the literature, and given that the instance set is divided according to characteristics such as order strength (OS), structure of the precedence graph, and the operation time of the tasks, how should practitioners configure the algorithm to handle instances with varying order strengths, specifically OS values of 0.2 and 0.6, while excluding instances with OS values of 0.9?",
      "topics": [
        "analysis"
      ],
      "answer": "To handle instances with varying order strengths, the algorithm should be configured to process instances with OS values of 0.2 and 0.6. Instances with an OS of 0.9 should be excluded from the analysis because they are over-constrained and, thus, easier to solve. The algorithm should also account for the structure of the precedence graph (block, chain, and mixed) and the operation time of the tasks (bottom, middle, and bimodal) as described in the literature.",
      "chunk_id": 11105,
      "paper_id": "Modelling and solving a cost-oriented resource-constrained multi-model assembly line balancing problem",
      "paper_title": "Modelling and solving a cost-oriented resource-constrained multi-model assembly line balancing problem",
      "paper_year": "2018",
      "chunk_content": "The Hoffmann heuristic described in Section 3 was coded in C, compiled using gcc 4.4.7 and run on a 32-core 2.0 GHz Intel Xeon with 128-gigabytes RAM, running the Linux operating system. The 32 cores are not used in the code and were only used to perform the resolution of 32 different instances simultaneously. Therefore, the code can be considered to have been executed in a single processor machine. Note that the application is not memory intensive (the memory consumption in each execution stood below 100 Mb ).  \nIn order to investigate the performance of the proposed algorithm when compared with previous approaches, a computational experiment with instances derived from the literature was conducted. The description of these instances is provided below and the results of the experiments are reported in Section 4.2. A separate section is devoted to the study of the real case found in the apparel industry, see Section 4.3. Additionally, and in order to compare the solutions found with a bound on the optimal solution, the lower bound described in Appendix 1 was also implemented. This bound was selected as it is the state-of-the-art lower bound for the SALBP (see Pereira 2015). The implementation uses the IBM ILOG CPLEX library version 12.6.2 to solve both the mathematical formulations of the relaxation and the pricing subproblems.  \nAn instance set derived from instances found in the literature was constructed in order to consider the effect of the additional features of the C-R-MMALBP. The set proposed in Otto, Otto, and Scholl (2013) was chosen because it contains harder instances than the classical instance set, see further discussion in Otto, Otto, and Scholl (2013). Moreover, the set follows a structured approach that enables the analysis of the effect of the different characteristics for the solution approach. The SALBP set is divided according to four characteristics, see Otto, Otto, and Scholl (2013) for further details:  \nNumber of tasks in the instance. Following the suggestions given in Otto, Otto, and Scholl (2013), as well as the results reported in Pereira (2015), the large instance set was selected. Consequently, those instances with 100 tasks are considered, $|V|=100$.\nOrder strength, OS, of the instance (the ratio between the number and the total possible number of predecessors). Instances with low, 0.2 , and high, 0.6 , OS are selected. Instances with very high, $O S=0.9$, were left out since they were over constrained and, thus, easier to solve.\nStructure of the precedence graph. Instances with block (tasks with multiple predecessors), chain (featuring long series of tasks with one predecessor and successor) and mixed (combining both structures) are considered.\nThe operation time of the tasks. Three types of operation times are considered: bottom (task time follows a normal distribution with mean equal to 0.1 times the cycle time), middle (normal distribution with mean equal to 0.5 times the cycle time) and bimodal (bimodal combining the previous distributions).  \nThe instance set described in Otto, Otto, and Scholl (2013) contains 525 instances per instance size, which are divided in subgroups of 25 instances with common characteristics, OS, structure, and operation times. For each combination of characteristics considered in this study, five instances were selected from each subgroup, summing up a total of 90 instances.  \nIn addition to these characteristics, the instances include four factors relevant to the C-R-MMALBP:",
      "question_type": "parameter selection and configuration guidance",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:08",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EoDCP algorithm, which is proposed to reduce complexity and computational time, what is the trade-off observed when using the Max N-Min L heuristic for the German network with k={3,4,5,6} in terms of power consumption compared to EoDCP?",
      "topics": [
        "heuristic"
      ],
      "answer": "The Max N-Min L heuristic, when used for the German network with k values of 3, 4, 5, and 6, results in a power consumption increase of 15%, 17%, 19% and FORMULA_49, respectively, compared to the EoDCP algorithm. This indicates that while the Max N-Min L heuristic is faster, it wastes more power compared to the more complex EoDCP.",
      "chunk_id": 8726,
      "paper_id": "Power Aware Data Center Placement in WDM Optical Networks",
      "paper_title": "Power Aware Data Center Placement in WDM Optical Networks",
      "paper_year": "2021",
      "chunk_content": "Fig. 6 shows the power saving [\\%] using traffic grooming approach for Random and German network respec-  \n[IMAGE2]  \nFig. 3: The (a) 20 Node Random (b) 17 Node German Topology\n[IMAGE3]  \nFig. 4: The (a) Random and (b) German Network DC Placement Analysis\n[IMAGE4]  \nFig. 5: The (a) Random and (b) German Network Power Consumption Analysis (Grooming vs No Grooming)  \n[IMAGE5]  \nFig. 6: Power Saving \\% using Traffic Grooming\ntively. Trends in Fig. 6 show that as the node-to-node traffic increases, there is a significant increase in the power saving. For example, for the 20 -nodes Random network and the 17-node German network with high traffic demand of 10000 Gbps per node, there is roughly a $13 \\%$ and $16 \\%$ power saving using traffic grooming technique.\nThis work shows that the data traffic can be managed to minimize power consumption with the placement of DCs on suitable nodes or locations. The ESDCP algorithm provides an optimal lower bound in small size topologies. However, it becomes un-tractable for realistic network sizes. Hence, an iterative probabilistic optimization approach EoDCP is proposed to reduce complexity and computational time. Furthermore, the results of Max N-Min L heuristic for German network and $k=\\{3,4,5,6\\}$ shows that placing DCs in accordance with maximum node degree and minimum average length wastes $15 \\%, 17 \\%, 19 \\%$ and FORMULA_49 respectively more power in comparison with ESDCP and EoDCP. Similar trend hold for the Random network too. Thus, a very fast and simple heuristic provides performance very close to those of more complex and time consuming solutions. Finally, electronic traffic grooming is shown to further reduce power consumption.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:10",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantages do the NSGA-II-A and NSGA-II-B variants offer in dynamic environments compared to the First-Order Difference Model-Based MOEA/D (MOEA/D-FD) regarding population adaptation?",
      "topics": [
        "optimization"
      ],
      "answer": "NSGA-II-A adapts to dynamic problems with severe changes by replacing a small portion of the population with random solutions, while NSGA-II-B uses mutated solutions of existing individuals, making it suitable for problems with small changes. MOEA/D-FD, on the other hand, predicts the location of the new population using a first-order difference model based on historical information and evenly distributed individuals selected from the previous population. Thus, NSGA-II-A and NSGA-II-B offer different adaptive strategies based on the severity of environmental changes compared to MOEA/D-FD's predictive approach.",
      "chunk_id": 10163,
      "paper_id": "Novel Prediction Strategies for Dynamic Multiobjective Optimization",
      "paper_title": "Novel Prediction Strategies for Dynamic Multiobjective Optimization",
      "paper_year": "2020",
      "chunk_content": "$$\n\\mathrm{MHV}=\\frac{\\sum_{t \\in T} \\mathrm{HV}_{t}}{|T|}\n$$\n\nC. Compared Algorithms\n\nIn order to validate the performance of our proposed method, several existing approaches are selected as the comparison algorithms. A brief description of these algorithms and their parameter settings is given as follows.\n\n1) Population Prediction Strategy (PPS): The main idea of PPS is dividing the optimal solutions into two parts: 1) population center and 2) manifold. An AR model is adopted to predict the next population center based on a time series of history population centers. Similarly, history manifolds are also used to predict the new manifold. Then, a new population will be generated based on the predicted population center and manifold [34].\n2) Dynamic Version of NSGA-II (DNSGA-II): DNSGA-II is a dynamic version of NSGA-II by making some changes to the original NSGA-II. Two versions are available: 1) NSGA-II-A and 2) NSGA-II-B. The former is formed by replacing a small portion of the population with random solutions, and it is suitable for solving dynamic problems with severe changes. The latter is similar to the former except that the replacement uses mutated solutions of existing individuals, and works well in solving problems with small changes. Both of them are used in this paper [7].\n3) First-Order Difference Model-Based MOEA/D: Firstorder difference model-based MOEA/D (MOEA/D-FD) [5] utilizes history information to predict the location of the new POS after a change is detected. The new population is composed of two kinds of solutions: 1) the old solutions and 2) the predicted ones. The movement of population centroid defines a predicted direction. To make the new population diversified, evenly distributed individuals selected from the previous population are used in the prediction.\n\nD. Parameter Settings\n\nThe parameters of the MOEAs considered in the experiment were referenced from their original papers. Some key parameters in these algorithms were set as follows.\n\n1) Population Size: The population size $(N)$ in all the algorithms was set to 100 . Around 1000 points were uniformly sampled from the true POF for computing the performance metrics in both bi- and three-objective cases.\n2) Other Parameters: All the parameters in the compared algorithms used the same settings as in their original studies.\na) Parameters in PBDMO: The second sampling strategy obtains $N_{1} N_{2}$ sampling points from $L_{1}+\\{0.2,0.4,0.6,0.8\\} *\\left(U_{1}-L_{1}\\right)$, and the size of SubPop ${ }_{3}$ was set to $0.3 N$.\n3) Stopping Criterion and the Number of Executions: Each algorithm terminates after a prespecified number of generations and should cover all possible changes. To minimize the effect of static optimization, we gave 50 generations for each algorithm before the first change occurs. The total number of generations was set to $3 n_{t} \\tau_{t}+50$, which ensures there are $3 n_{t}$ changes during the evolution. Additionally, each algorithm was executed 20 independent times on each test instance.\n4) Change Detection: For all the algorithms, a maximum number of $10 \\%$ population members are re-evaluated for change detection.\n\nE. Experimental Results\n\nTo study the impact of the change frequency on algorithms' ability in dynamic environments, the severity of change $\\left(n_{t}\\right)$ was fixed to 10 , and the frequency of change FORMULA_160 was set to 5 , 10 , and 20 , respectively. The statistical results are presented in Tables I-III, where the best values obtained by one of the five algorithms are highlighted in bold face.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:12",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What programming techniques are suggested to optimize the EDA's computational time when used within a Model Predictive Control (MPC) framework for energy management in Plug-in Hybrid Electric Buses (PHEBs)?",
      "topics": [
        "search"
      ],
      "answer": "To minimize computational time, the EDA should be selected with global search capabilities. This enables it to efficiently guide the evolution towards the optimal solution by leveraging the statistical information of each individual. The text suggests that a more accurate short-term velocity prediction, achieved through methods like a self-updating Markov chain model, serves as a basis for energy management, thereby reducing the search space for the EDA and leading to faster convergence. The text shows a reduction in computational time from 421s to 289s by using the proposed strategy.",
      "chunk_id": 1488,
      "paper_id": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_title": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_year": "2022",
      "chunk_content": "[IMAGE19]  \nFig. 14. RMSE and standard deviation of the velocity forecast results.  \nTABLE VI\nEVALUATION RESULTS OF ALGORITHMIC PERFORMANCE  \namong these methods. Compared to the ECMS strategy, the proposed strategy allows the distribution of the engine working points to be more reasonable. Therefore, sound fuel economy is achieved by the proposed strategy.\nTo evaluate the algorithmic performance, the traditional MPC is selected to make a comparison with the proposed strategy. In the traditional MPC, velocity forecasting is realized by using the Markov chain model without self-update, and the shooting method is selected to obtain the candidate solutions. When the WVCITY cycle was repeated four times, the RMSE and standard deviation of the velocity forecast results are shown in Fig. 14. It is observed that as the prediction horizon increases from 5 to 15 s , the RMSE in the Markov chain model without self-update grows from 1.914 to $7.136 \\mathrm{~km} / \\mathrm{h}$, whereas the RMSE of the velocity forecast with the self-update mechanism only grows from 1.302 to $6.236 \\mathrm{~km} / \\mathrm{h}$. The standard deviations for these two forecasting methods in the 5 s forecasting situation are relatively small, approximately 0.51 and 0.29 , respectively. As the horizon increases, the prediction results become less precise for both methods. This is because under the Markov chain model, the causal link between predicted and current velocities is ambiguous, especially in the larger predictive horizon. Regardless, the proposed strategy obtains better prediction accuracy than the traditional MPC in the same horizon through the recursive mechanism.  \nThe evaluation results between traditional MPC and the proposed strategy are summarized in Table VI. The total cost of the traditional MPC is 37.47 CNY over the $4 \\times$ WVCITY cycle, whereas the total cost of the proposed strategy is reduced by $4.93 \\%$ in comparison with that of traditional MPC. More importantly, the computational time that each method takes to obtain the optimal solution is critical, especially if targeting a real-time application where computational resources on board  \n[IMAGE20]  \nFig. 15. Framework of the HIL test bench.  \nTABLE VII\nTECHNICAL DESCRIPTION OF THE MODULES  \nare limited. The computational time of traditional MPC is 421 s over the testing cycle, while the value of the proposed strategy is only up to 289 s . It can be noted that the elapsed time with the proposed strategy is shorter than that of traditional MPC, whose reduction is up to FORMULA_157. The reasons for these achievements can be summarized as follows: first, more accurate short-term velocity prediction is the basis of the energy management of PHEBs based on MPC, and second, the EDA algorithm with global search capability is selected as the solver to guide the evolution toward the optimal solution by making full use of the statistical information of each individual. To summarize, the proposed strategy with the shorter computational time requirement exhibits outstanding fuel savings ability.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:14",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output be measured using the criteria of average accuracy when applied to feature subset selection?",
      "topics": [
        "search"
      ],
      "answer": "The quality of the EDA's output in feature subset selection can be measured by assessing the average accuracy results obtained for various classifiers. For example, the FSS-TREE algorithm, which is based on the EDA model, was evaluated by comparing its average accuracy against several other feature subset selection techniques.",
      "chunk_id": 11919,
      "paper_id": "Application of L-EDA in metabonomics data handling- global metabolite profiling and potential biomarker discovery of epithelial ovarian cancer prognosis",
      "paper_title": "Application of L-EDA in metabonomics data handling: global metabolite profiling and potential biomarker discovery of epithelial ovarian cancer prognosis",
      "paper_year": "2011",
      "chunk_content": "Estimation of distribution algorithms (EDAs) are a novel class of evolutionary algorithms and suitable for optimization. A most salient feature of EDAs is that they maintain a probabilistic model during the iterative search process (Larranaga and Lozano 2002). The probabilistic model is modified in each iteration using a certain strategy and directs the search in next iteration in turn. The iterative search terminates when a termination condition is satisfied. EDAs have been successfully applied in solving bioinformatics problems (Saeys et al. 2003, 2007; Inza et al. 2001; Santana et al. 2007, 2008). Compared with traditional greedy methods, EDAs are more efficient in relevant feature subset selection for splice site prediction. Meanwhile the results got from EDA methods were comparable or even better (Saeys et al. 2003). A new randomized algorithm based on the EDA model, FSS-TREE, obtained the best average accuracy results for various classifiers among several compared feature subset selection techniques (Inza et al. 2001). In other studies, different variants of EDAs have been used for protein structure prediction in\nsimplified models, and their use as a simulation tool for the analysis of the protein folding process was proposed (Santana et al. 2008). Besides, three different EDAs were applied to protein design by minimization of contact potentials (Santana et al. 2007).  \nEpithelium ovarian cancer (EOC) is the leading cause of death in gynecological cancer (Brown et al. 2002), and serous tumors are the most widespread forms of ovarian cancer (Williams et al. 2007). EOC can usually be diagnosed at the advanced stage, because only few symptoms of EOC can be noticed at the early stage. Moreover, EOC is likely to be recurrent after treatment, which leads to low survival rate (less than 30\\%) (Brown et al. 2002). Till now, biomarkers for EOC early diagnosis and prognosis have not been well developed. Cancer antigen 125 (CA125) is the commonly used biomarker for EOC diagnosis and prognosis (Jacobs and Menon 2004). However, levels of CA125 are also elevated in other cancers (Bast et al. 1998) and gynecological inflammations (An et al. 2006). Therefore, development of new sensitive and specific biomarkers for EOC early diagnosis or prognosis is quite necessary. Metabonomics (Odunsi et al. 2005; Guan et al. 2009; Denkert et al. 2006) and proteomics (Petricoin et al. 2002) have been used to study EOC to find potential biomarkers. The performance of pattern recognition methods including linear discriminant analysis, quadratic discriminant analysis, FORMULA_27-nearest neighbor classifier, bagging and boosting classification trees, support vector machine, and random forest were compared for the classification of ovarian cancer and control serum samples based on MS spectra (Wu et al. 2003).  \nIn this study, an improved EDA method (L-EDA) was proposed and introduced to metabonomics study for mining specific different variables in potential EOC prognosis biomarker discovery. Sera from healthy, EOC, non-recurrent EOC and recurrent EOC were analyzed based on LCMS platform. Specific variables reflecting the differences of EOC prognosis were selected by the L-EDA method, and visualized on PCA model. Furthermore, the specific metabolites from L-EDA filtered data were selected as potential biomarkers for EOC prognosis.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:15",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for managing PHEV charging in a municipal parking deck, considering real-world operational constraints?",
      "topics": [
        "design"
      ],
      "answer": "The primary objective is to design a sophisticated controller that regulates multiple loads from a cluster of PHEVs while accommodating real-world constraints such as communication and infrastructure variations, differences in arrival and departure times, and the number of PHEVs. The algorithm should be robust to uncertainty, make decisions in real-time with limited communication bandwidth, and seamlessly integrate with existing utilities, potentially using approaches like particle swarm optimization (PSO) to optimally allocate power.",
      "chunk_id": 5168,
      "paper_id": "Performance Evaluation of an EDA-Based Large-Scale Plug-In Hybrid Electric Vehicle Charging Algorithm",
      "paper_title": "Performance Evaluation of an EDA-Based Large-Scale Plug-In Hybrid Electric Vehicle Charging Algorithm",
      "paper_year": "2012",
      "chunk_content": "ECONOMIC AND environmental incentives, as well as advances in technology, are reshaping the traditional view of power systems. Plug-in hybrid electric vehicles (PHEVs) have received increasing attention because of their low pollution emissions and high fuel economy. Ultimately, PHEVs will shift energy demands from crude oil to electricity for the personal transportation sector [1]. By drawing on and supplying power to the power grid, electric vehicles could displace the use of petroleum. This would reduce pollution and alleviate  \n[^0]security issues related to oil extraction, importation, and combustion. Along with the utilization of grid power, PHEVs also have the potential to transfer power to the grid to alleviate peak power demand and provide ancillary services to the grid [2].  \nThe U.S. Department of Energy projects that approximately 1 million PHEVs will be on the road by 2015 and 425000 PHEVs will be sold in 2015 alone. At this penetration rate, PHEVs would account for $2.5 \\%$ of all new vehicle sales in 2015 [3]. The Electric Power Research Institute (EPRI) projects that $62 \\%$ of the entire U.S. vehicle fleet will consist of PHEVs by 2050 using a moderate penetration scenario [4]. Accordingly, there is a growing need to address the implications of this technology on the power grid. Large numbers of PHEVs have the potential to threaten the stability of the power system. For example, the aggregated load in a municipal parking deck needs to be managed very carefully in order to avoid interruption when several thousand PHEVs are introduced into the system over a short period of time (e.g., during the early morning hours when people arrive at work). Moreover, due to variations in the needs of the PHEVs parked in the deck at any given time, the demand pattern will also have a significant impact on the electricity market.  \nIn order to maximize customer satisfaction and minimize disturbances to the grid, a sophisticated controller will need to be designed in order to regulate multiple loads from a cluster of PHEVs appropriately. This controller must take into consideration real-world constraints (i.e., communication and infrastructure variations among individual vehicles). The controller must also accommodate for differences in arrival and departure times, as well as the number of PHEVs in the parking deck. The algorithm should also be robust to uncertainty, be capable of making decisions in real-time with limited communication bandwidth, and work seamlessly with existing utilities.  \nA theoretical system of a PHEV municipal parking deck has been studied in [5]-[7]. The initial algorithms have been implemented in Matlab/Simulink and Labview. In [8], the authors analyzed the optimal performance of the proposed charging algorithms under certain operating conditions and various types of battery models. A particle swarm optimization (PSO) based control algorithm was put forward in [9] to optimally allocate power to PHEVs at a municipal parking deck. In [10], the authors evaluated the impact of the large penetration of PHEVs under various charging scenarios.  \nThis paper addresses the performance evaluation of different control strategies in real-world PHEV parking deck operating conditions under various energy constraints. This paper first simulates the parking deck scenarios (e.g., plug-in time, initial",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:17",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of Restricted Boltzmann Machines (RBM) model variable distributions using a hidden layer, and what specific steps are involved in training the probabilities of the joint configuration over the hidden and visible units to achieve thermal equilibrium?",
      "topics": [
        "heuristic"
      ],
      "answer": "Within RBM-EDA, the Restricted Boltzmann Machine employs a hidden layer to model variable distributions. The algorithm trains the probabilities of the joint configuration over the hidden and visible units in the network until the distribution over the global state reaches a certain level of thermal equilibrium. This training process involves adjusting the network energy function to create a probability model. Specifically, the network consists of hidden and visible units, and the probabilities associated with their joint configurations are iteratively updated until the entire network achieves thermal equilibrium, which then allows the construction of the probability model.",
      "chunk_id": 11963,
      "paper_id": "Multi-objective Estimation of Distribution Algorithm based on Voronoi and local search",
      "paper_title": "Multi-objective Estimation of Distribution algorithm based on Voronoi and Local search",
      "paper_year": "2016",
      "chunk_content": "The estimation of distribution algorithms performance is naturally depends on statistical modeling and sampling method. There is a good wealth of literature on probability modeling in estimation of distribution algorithms.\nBayesian network is one of these probability models, which could consider the dependency between variables and use to learn parameters relationship and problem structure. These networks approximate the conditional probability. Each node and connection in these networks relate to the conditional probability. Some of the multi-objective estimation of distribution algorithms that use Bayesian networks includes BMOA, mohBOA, DTMEDA, DP-MrBOA, [1-4]. MBN-EDA is a new modeling method in multi-objective estimation of distribution algorithm that uses multi dimensions Bayesian networks (MBN) to learn a common model of aims and variables. This model not only, like other estimation of distribution algorithms, considers the variables relationship, but also could consider the goals relationship [5].\nRestricted Boltzmann machine is another statistical model that uses a hidden layer to model its variables distributions. This network includes hidden and visible units. The probabilities of the joint configuration over the hidden and visible units in network are trained until that distribution over the global state achieves a certain level of thermal equilibrium. Then, probability model is made by using network energy function. In RBM-EDA, Restricted Boltzmann machine model is introduced as the estimation of distribution algorithm in the multi-objective optimization filed [6]. In [7], EDA based on RBM combined with PSO for multi-objective optimization in noisy environment.\nVEDA [8] and mohBOA ignore the regularity in making probability models. Since the probability modeling technics check widespread under special discipline and regularity in statistical\nlearning fields, thus it is possible to use discipline in designing estimation of distribution algorithms in continues multi-objective algorithms. In RM-MEDA, the regularity feature of continues multi-objective optimization problems use as a base for an estimation of distribution algorithm in facing variables relationship. RM-MEDA, model promised area in search space by a probability model that its gravity center is a piece continuous manifold. Local PCA algorithm uses to make this model [9].\nSome methods combine the estimation of distribution algorithm with other heuristic search methods in order to increase the performance. The work presented in [10] is a combination of EDA and particle swarm algorithms. Gao et al. present an algorithm that combine EDA based on univariate distribution with particle swarm optimization (PSO) algorithm [11]. In [12], the combination of EDA and particle swarm optimization algorithm presented to control reservoir flood. This algorithm divides the population to some sub-population and makes the probability model for each of them. Based on the probability model, each sub-population reproduces new members with the estimation of distribution and particle swarm optimization algorithm. In [13], use univariate Gaussian model to estimate the solutions distributions. Some parameters of this model have the learning ability. In this method an EDA with comparative learning rate combine with chaos disorder search method.\nWhile most of the multi-objective estimation of distribution algorithms are based on Pareto front, there are some study in other multi-objective optimization frame. In [14] the main idea is that any information from solutions near the weight vector should be helpful. Thus, making a probability model from all neighborhood solutions may have more efficient information than crossover operator [15]. In [16-19] cited some of estimation of distribution algorithm based on decomposition method. Shim et al. use a selection method based on decomposition in a combination of EDA based on univariate distribution and some local search methods [20]. In some of EDA a combination of some of probability models are used [21]. However, existing models could not reflect the problem completely. when the amount of variables and components increase, the optimization results become invalid [22]. Additionally, when consider all the relations between variables the computing cost increase.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:19",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to solve the flexible job-shop scheduling problem, what specific considerations are needed?",
      "topics": [
        "heuristic"
      ],
      "answer": "When implementing an Estimation of Distribution Algorithm (EDA) for the flexible job-shop scheduling problem (FJSP), one must address both the routing sub-problem (assigning each operation to a machine) and the scheduling sub-problem (sequencing operations on machines). A bi-population based EDA (BEDA) can be used, as it was presented as a method to solve the FJSP.",
      "chunk_id": 241,
      "paper_id": "An effective estimation of distribution algorithm for the flexible job-shop scheduling problem with fuzzy processing time",
      "paper_title": "An effective estimation of distribution algorithm for the flexible job-shop scheduling problem with fuzzy processing time",
      "paper_year": "2013",
      "chunk_content": "The flexible job-shop scheduling problem (FJSP) is an extension of the classical job-shop scheduling problem (JSP) for the flexible manufacturing systems, which is very close to the real manufacturing situation. In the FJSP, some machines can perform more than one type of operations. The FJSP consists of two sub-problems: the routing sub-problem that assigns each operation to a machine among a set of capable machines, and the scheduling sub-problem that sequences the assigned operations on all the machines to obtain a feasible schedule. The FJSP is more difficult to solve than the classical JSP since it needs to determine the assignment of operations to the related machines.  \nThe first work to address the FJSP was by Bruker and Schlie (1990), where a polynomial algorithm was presented for the problem with only two jobs and identical machines. Later, Brandimarte (1993) presented a hybrid tabu search (TS) algorithm with some existing dispatching rules. Dauzere-Peres and Paulli (1997) also presented a TS algorithm based on an integrated approach, which was improved by two developed neighbourhood functions (Mastrolilli and Gambardella 2000) in terms of computational time and solution quality. Gao, Sun, and Gen (2008) designed a genetic algorithm (GA) hybridising with variable neighbourhood search (VNS), and Pezzella, Morganti, and Ciaschetti (2008) developed a GA integrating different strategies. Besides, Amiri et al. (2010) developed a VNS algorithm based on six neighbourhood structures, Yazdani, Amiri, and Zandieh (2010) developed a parallel VNS algorithm, and Xing et al. (2010) developed a knowledge-based ant colony optimisation algorithm. Recently, a bi-population based estimation of distribution algorithm (BEDA) (Wang et al. 2012c) and a novel artificial bee colony (ABC) algorithm (Wang et al. 2012d) were presented to solve the FJSP. As for the multi-objective flexible job-shop scheduling (MFJSP), relevant algorithms include heuristic algorithm (Wang, Zhou, and Xi 2008), GA (Frutos, Olivera, and Tohme 2010; Wang et al. 2010), genetic programming (Tay and Ho 2008), TS algorithm (Li, Pan, and Liang 2010), particle swarm optimisation (PSO) (Xia and Wu 2005; Moslehi and Mahnam 2011), and ABC algorithm (Li, Pan, and Gao 2011; Wang et al. 2012a).",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:20",
      "generation_style": "practical_application"
    },
    {
      "question": "The mean inverted generational distance (MIGD) is used to measure the convergence and diversity of solutions. How is MIGD mathematically defined in terms of the inverted generational distance (IGD) and what do the variables in the IGD calculation represent?",
      "topics": [
        "optimization"
      ],
      "answer": "MIGD is calculated as the average of the IGD values over a set of discrete time points, represented as MIGD = (∑_{t ∈ T} IGD(POF_{t}^{*}, POF_{t}^{ob})) / |T|, where T is the set of discrete time points and |T| is the total number of changes in a run. The IGD is computed as IGD(POF_{t}^{*}, POF_{t}^{ob}) = (∑_{g ∈ POF_{t}^{*}} d(g, POF_{t}^{ob})) / |POF_{t}^{*}|, where POF_{t}^{*} is a set of uniformly distributed solutions in the true Pareto optimal front (POF) at time t, POF_{t}^{ob} is the POF approximation at time t, d(g, POF_{t}^{ob}) refers to the minimum Euclidean distance between a point g in POF_{t}^{*} and the points in POF_{t}^{ob}, and |POF_{t}^{*}| is the number of solutions in POF_{t}^{*}.",
      "chunk_id": 10162,
      "paper_id": "Novel Prediction Strategies for Dynamic Multiobjective Optimization",
      "paper_title": "Novel Prediction Strategies for Dynamic Multiobjective Optimization",
      "paper_year": "2020",
      "chunk_content": "IV. EXPERIMENTAL STUDY\n\nA. Test Instances\n\nThe performance of the proposed approach is examined on a recently proposed DF test suite [15], which has nine bi-objective and five tri-objective benchmark functions with diverse properties, such as variable linkage, disconnectivity, irregular POF shapes, and time-dependent geometries. The DF test suite consists of functions taken from other test suites, e.g., FDA [8], dMOP [10], ZJZ [33], and JY [13]. The time instance $t$ used in the test suite is given as $t=\\left(1 / n_{t}\\right)\\left\\lfloor\\left(\\tau / \\tau_{t}\\right)\\right\\rfloor$, where $n_{t}$, $\\tau$, and $\\tau_{t}$ are the severity of change, the number of iterations, and the frequency of change, respectively. The dimension $(D)$ of benchmark functions is set to 10 . The definition of these test instances can be found in [15].\n\nB. Performance Indicators\n\nPerformance indicators play an important role in assessing the performance of algorithms. In this paper, we adopts the following three performance indicators.\n\n1) Mean Inverted Generational Distance: The mean inverted generational distance (MIGD), a widely adopted measure [30], [32], [34], is mainly employed to measure the convergence and diversity of solutions obtained by an algorithm. Suppose that $\\mathrm{POF}_{t}^{*}$ is a set of uniformly distributed solutions in the true POF and $\\mathrm{POF}_{t}^{o b}$ is a POF approximation, at time $t$, IGD can be calculated as\n\n$$\n\\operatorname{IGD}\\left(\\mathrm{POF}_{t}^{*}, \\mathrm{POF}_{t}^{o b}\\right)=\\frac{\\sum_{g \\in \\mathrm{POF}_{t}^{*}} d\\left(g, \\mathrm{POF}_{t}^{o b}\\right)}{\\left|\\mathrm{POF}_{t}^{*}\\right|}\n$$\n\nwhere $d\\left(g, \\mathrm{POF}_{t}^{o b}\\right)$ refers to the minimum Euclidian distance between $g$ and the points in $\\mathrm{POF}_{t}^{o b}$, and $\\left|\\mathrm{POF}_{t}^{*}\\right|$ is the number of solutions in $\\mathrm{POF}_{t}^{*}$. Then, the MIGD can be computed as\n\n$$\n\\mathrm{MIGD}=\\frac{\\sum_{t \\in T} \\mathrm{IGD}\\left(\\mathrm{POF}_{t}^{*}, \\mathrm{POF}_{t}^{o b}\\right)}{|T|}\n$$\n\nwhere $T$ is a set of discrete time points and $|T|$ is the total number of changes in a run.\n\n2) Mean Schott's Spacing Metric: The Schott's spacing (SP) metric [10], [21], [25] aims to evaluate the distribution of $\\mathrm{POF}_{t}^{o b}$. The following gives the expression formula:\n\n$$\n\\mathrm{SP}\\left(\\mathrm{POF}_{t}^{o b}\\right)=\\sqrt{\\frac{1}{\\left|\\mathrm{POF}_{t}^{o b}\\right|-1}\\left(\\sum_{i=1}^{\\left|\\mathrm{POF}_{t}^{o b}\\right|}\\left(D_{i}-\\bar{D}\\right)\\right)}\n$$\n\nwhere $D_{i}$ is the Euclidean distance between the $i$ th point in $\\mathrm{POF}_{t}^{o b}$ and its nearest point in $\\mathrm{POF}_{t}^{o b} . \\bar{D}$ represents the average value of $D_{i}$. The mean Schott's spacing metric (MSP) can be defined as follows:\n\n$$\n\\mathrm{MSP}=\\frac{\\sum_{t \\in T} \\mathrm{SP}\\left(\\mathrm{POF}_{t}^{o b}\\right)}{|T|}\n$$\n\n3) Hypervolume Metric: Hypervolume (HV) [34] is a widely used indicator in multiobjective optimization. The calculation of HV requires a reference point, which is usually defined as a vector dominated by any points in the true POF. A larger HV value indicates a better approximation. HV is defined as follows:\n\n$$\n\\mathrm{HV}_{t}=\\mathrm{HV}\\left(\\mathrm{POF}_{t}^{o b}\\right)\n$$\n\nwhere $\\mathrm{HV}\\left(\\mathrm{POF}_{t}^{o b}\\right)$ refers to the HV [27] of set $\\mathrm{POF}_{t}^{o b}$. The reference point for the computation of HV is $\\left(z_{j}+0.5, j=\\right.$ $1, \\ldots, m)$, where $z_{j}$ is the maximum value of the $j$ th objective of true POF. The mean HV (MHV) can be calculated as follows:\n\n$$\n\\mathrm{MHV}=\\frac{\\sum_{t \\in T} \\mathrm{HV}_{t}}{|T|}\n$$\n\nC. Compared Algorithms\n\nIn order to validate the performance of our proposed method, several existing approaches are selected as the comparison algorithms. A brief description of these algorithms and their parameter settings is given as follows.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:22",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the MMHCEDA algorithm compare to the BOA and EBNA algorithms, specifically in the context of evolutionary optimization?",
      "topics": [
        "search"
      ],
      "answer": "The comparison of the MMHCEDA with the algorithms BOA and EBNA suggests that MMHCEDA is a competitive evolutionary optimization algorithm. The text indicates that MMHCEDA scales well with high efficiency of data, making it potentially suitable for large dimension problems from Data Mining, Pattern Recognition, and Artificial Intelligence fields.",
      "chunk_id": 10659,
      "paper_id": "Evaluating the Max-Min Hill-Climbing Estimation of Distribution Algorithm on B-Functions",
      "paper_title": "Evaluating the Max-Min Hill-Climbing Estimation of Distribution Algorithm on B-Functions",
      "paper_year": "2018",
      "chunk_content": "The evaluated algorithm is based in recent advances in the area of learning of Bayesian networks from data. In particular, the algorithm scales well with high efficiency of data. We have wondered to what extent these features could mean a significant impulse with regard to the quality of the EDAs and their capacities to attack real world problems of large dimensions mainly problems from Data Mining, Pattern Recognition, and Artificial Intelligence fields. Indeed, the comparison of the MMHCEDA with the algorithms $B O A$ and $E B N A$ allows us to conclude that it is a competitive evolutionary optimization algorithm. Keeping in mind the nature of the chosen test functions, we conjecture that similar results will be obtained with many other classes of problems. The research reported here is just a first promising step and thus we continue working in this direction. We are currently developing a parallel version of the algorithm. Another line that we are already approaching is the creation of more efficient models of the learning type used in this report and consequently of new EDAs based on them.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:24",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model described, and what correction operator is applied during the optimization process?",
      "topics": [
        "optimization"
      ],
      "answer": "The EDA model involves these steps: (1) Initialize a population of size N randomly. (2) Evaluate the fitness of each individual based on \\(K_{eff}\\), maximum permissible reactor power, channel power, channel power peaking factor, bundle power, and shutdown system worth. (3) Decide to continue for new generation calculations or terminate. (4) Select M individuals (where M < N) based on a termination selection method. (5) Calculate the Probability Distribution Function (PDF) using selected M individuals using the formula \\(PDF(t+1) = PDF(t) \\cdot (1-\\alpha) + \\alpha \\frac{1}{M} \\sum_{m=1}^{M} X_{m}(t)\\), where \\(\\alpha\\) is a constant between [0,1] and X is a binary matrix representation of the loading pattern. (6) Generate a new population of size N using the new PDF. (7) Apply a correction operator that randomly changes the fuel type if any fuel type exceeds its specified value. (8) Evaluate the fitness of the new N individuals as in step 2. (9) Repeat from step 3.",
      "chunk_id": 11877,
      "paper_id": "Optimization of depleted uranium loading in fresh core of large sized Indian PHWR by evolutionary algorithm",
      "paper_title": "Optimization of depleted uranium loading in fresh core of large sized Indian PHWR by evolutionary algorithm",
      "paper_year": "2011",
      "chunk_content": "In all, four types of DU loadings (cases A-D) described in Section 2 were separately optimized using the EDA algorithm. The properties of optimum DU configuration obtained in each of the four cases are shown in Table 1.  \nIt is seen that the configurations corresponding to cases A-C can give $100 \\% \\mathrm{FP}$ with sufficient excess reactivity, while keeping bundle power, channel power and CPPF within limits. The worth of 28 rods of SDS\\#1 is also adequate. In case D, the CPPF is somewhat higher than the prescribed limit and hence it is not accepted.  \n1. Initialize the population (Size=N) randomly.\n2. Evaluate the fitness of each individual based on their $\\mathrm{K}_{\\text {eff }}$, maximum permissible reactor power, channel power, channel power peaking factor, bundle power and the worth in shutdown system as obtained by diffusion code DOLP using Eq.(1) in section 2.1.\n3. Either continue for new generation calculations or terminate the execution.\n4. Select $\\mathrm{M}<\\mathrm{N}$ candidates based on termination selection method (the best fit M individuals among total N individuals).\n5. Calculate Probability Distribution Function (PDF) using selected M individuals. At any generation (t) the PDF has been estimated as given below for each location.  \n$$\nP D F(t+1)=P D F(t) \\cdot(1-\\alpha)+\\alpha \\frac{1}{M} \\sum_{m=1}^{M} X_{m}(t)\n$$  \nWhere $\\alpha$ is constant between $[0,1] . \\mathrm{X}$ is binary matrix representation of loading pattern.\n6. Generate new population (Size=N) using this new probability distribution function (PDF).\n7. A correction operator is applied. The fuel type which is more in number than the specified value is randomly changed into other type.\n8. The fitness of new N individuals is found out as in step 2 .\n9. Go to step 3 .  \nFig. 2. Pseudo EDA model used for optimization.  \nTable 1\nThe 700 MWe core properties for different type of loading.\nTable 1 gives maximum power and safety parameters in the fresh core. It is necessary that the power level and constraints are satisfactory at later times also. To further study suitability of DU loadings, time dependent burnup simulation was carried out for all the four cases up to the pre-fuelling period. A time-step of 2.5 FPD (full power days) was used. The change in excess reactivity with FPD is shown in Fig. 3 for all the four cases. It is seen that excess reactivity becomes zero after about 116 FPD, which marks beginning of refuelling. The variation of CPPF with time is shown in Fig. 4 for all the four cases. The CPPF varies in narrow range for case A (DU at 7th location). The ROP detectors are calibrated with CPPF regularly. Case A permits more operating margin (lower CPPF) before the ROP trip as well as better safety (less variation in CPPF). Hence, the DU configuration in case A are considered as a better choice.\n[IMAGE1]  \nFig. 3. Variation in excess reactivity.\n[IMAGE2]  \nFig. 4. Variation in channel power peaking factor.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:26",
      "generation_style": "implementation_focused"
    },
    {
      "question": "Within the decomposition framework described, how is the fitness of a solution for each subproblem determined using the Tchebycheff approach?",
      "topics": [
        "search"
      ],
      "answer": "The fitness value of the $j$th subproblem, denoted as $g t(x | \\lambda^{j}, z^{*})$, is calculated using the formula $gt(x | \\lambda^{j}, z^{*})=\\max _{1 \\leq i \\leq j}\\left{\\lambda_{i}^{j} | F_{i}(x)-z_{i}^{*} |\\right\\}$, where $\\lambda^{j}$ represents a set of evenly distributed weight vectors, $z^{*}$ is the reference point, and $F_{i}(x)$ represents the objective values.",
      "chunk_id": 5470,
      "paper_id": "A Hybrid Estimation of Distribution Algorithm with Decomposition for Solving the Multiobjective Multiple Traveling Salesman Problem",
      "paper_title": "A Hybrid Estimation of Distribution Algorithm with Decomposition for Solving the Multiobjective Multiple Traveling Salesman Problem",
      "paper_year": "2012",
      "chunk_content": "The proposed algorithm, consisting of four main mechanisms (chromosome representation, decomposition, modeling, and local search metaheuristics), is presented in this section. The proposed decomposition framework is a modified version of the multiobjective evolutionary algorithm with decomposition (MOEAD) [13]. In this implementation, one-chromosome representation [4] is utilized to represent the order of the cities to be traveled by $m$ salesmen. This scheme introduces $m-1$ pseudocities (integer values $\\leq 1$ ) to the chromosome. These pseudocities represent the same initial city where all the salesmen will start their routes. Therefore, each chromosome may consist of $n+m-1$ genes.  \nThe representation with nine cities and three salesmen is illustrated in Fig. 5. The sequence of travel is as follows. The first salesman starts from the initial city 1 then visits cities 5, 7 , and 9 in that order. The second salesman again starts from the initial city then visits cities 4 and 3 in that order. The third salesman visits cities 2,6 , and 8 in that order.  \nIn the decomposition framework, the fitness assigned to each solution can be based on any classical aggregation approach.  \nFor the implementation, the Tchebycheff approach [45] is used and the decomposition framework is described according to this approach. A set of evenly distributed weight vectors $\\lambda^{1}, \\ldots, \\lambda^{S}$ and the reference point $z^{*}$ are generated, where $S$ is the number of subproblems. The algorithm decomposes the population into $S$ scalar optimization subproblems according to the Tchebycheff formulation and the fitness value of the $j$ th subproblem is defined as  \n$$\ng t\\left(x \\mid \\lambda^{j}, z^{*}\\right)=\\max _{1 \\leq i \\leq j}\\left\\{\\lambda_{i}^{j} \\mid F_{i}(x)-z_{i}^{*} \\mid\\right\\}\n$$  \nThe pseudocode of the proposed algorithm can be found in Fig. 6. In step 1, the $Q$ neighbors that are nearest, in terms of Euclidean distance, to each weight vector are determined. Therefore, subproblem $i$ has $Q$ neighbors denoted as $B(i)=$ $\\left\\{i_{1}, \\ldots, i_{Q}\\right\\}$. Then, initial chromosomes in the form as indicated in Fig. 5 are, randomly, generated. Objective values $F_{1}(x), \\ldots, F_{p}(x)$ are calculated based on the formulation in Section III, and the reference point FORMULA_116 is set to the minimum objective value of the initial population.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:28",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs using the scoring function of Ko and Kim (2014), and how is it integrated with Bayesian Discrimination?",
      "topics": [
        "optimization"
      ],
      "answer": "The scoring function of Ko and Kim (2014) aims to evaluate the dependency between pairs of nodes, specifically assessing causal relationships using conditional probabilities $\\mathrm{P}(X_{2} | X_{1})$ and $\\mathrm{P}(X_{1} | X_{2})$. This approach constructs a causal score table, and the method uses Bayesian Discrimination (BD) to evaluate candidate structures during Estimation of Distribution Algorithm (EDA)-based structure learning, limiting the scoring function's application to causality evaluation between nodes.",
      "chunk_id": 11152,
      "paper_id": "Experimental comparisons with respect to the usage of the promising relations in EDA-based causal discovery",
      "paper_title": "Experimental comparisons with respect to the usage of the promising relations in EDA-based causal discovery",
      "paper_year": "2018",
      "chunk_content": "- $R_{2}$ is a score of $\\mathrm{P}($ not start the car|not enough fuel); this has a high probability.\n- $C_{1}$ is a score of $\\mathrm{P}($ not start the car|fuel); this has a low probability.\n- $C_{2}$ is a score of $\\mathrm{P}($ start the car|not enough fuel); this has a low probability.  \nThe scoring function of Ko and Kim (2014) evaluates the dependency between a pair of two nodes which is used as a basis for the differentiation between the likelihood equivalence. Relations between two nodes, $\\{$ Node1, Node2\\}, are evaluated from $\\mathrm{P}\\left(X_{2} \\mid X_{1}\\right)$ and $\\mathrm{P}\\left(X_{1} \\mid X_{2}\\right)$ instead of $\\mathrm{P}\\left(X_{1}\\right) \\mathrm{P}\\left(X_{2} \\mid X_{1}\\right)$ and $\\mathrm{P}\\left(X_{1}\\right) \\mathrm{P}\\left(X_{1} \\mid X_{2}\\right)$; notes that $\\mathrm{P}\\left(X_{1}\\right) \\mathrm{P}\\left(X_{2} \\mid X_{1}\\right)=\\mathrm{P}\\left(X_{1}, X_{2}\\right)=$ $\\mathrm{P}\\left(X_{1}\\right) \\mathrm{P}\\left(X_{1} \\mid X_{2}\\right)$. Based on this approach, the proposed method evaluates causalities between all pairs of nodes, $\\mathrm{P}\\left(X_{i} \\mid X_{j}\\right)$, and then, constructs an $n$ by $n$ causal score table. In this paper, we have limited the boundary of the usage of the scoring function of Ko and Kim to evaluate causalities between nodes. BD is used to evaluate candidate structures during EDA based structure learning.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:30",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of integrating an EDA with a Genetic Algorithm (GA) aim to improve the mode assignment aspect of the Multi-Mode Resource Constrained Project Scheduling Problem (MRCPSP), given that the crossover operator of a standard GA is considered limited in learning the interrelations between problem parameters?",
      "topics": [
        "analysis"
      ],
      "answer": "The integration of an EDA with a GA for the MRCPSP aims to enhance the GA's mode assignment capabilities. The text suggests that a standard GA's crossover operator has limitations in learning the interrelations between problem parameters. The EDA is intended to improve upon this by more effectively handling the mode assignment aspect, where each activity $i$ must be performed in a mode $k$ selected from a set of possible modes $\\left[1, m_{i}\\right]$, where $m_{i}$ is the number of possible modes of $i$. The goal is to select one mode of execution for each activity such that the makespan, or $f t_{\\alpha}$, is minimized while adhering to resource and precedence constraints.",
      "chunk_id": 12675,
      "paper_id": "BPGA-EDA for the multi-mode resource constrained project scheduling problem",
      "paper_title": "BPGA-EDA for the Multi-Mode Resource Constrained Project Scheduling Problem",
      "paper_year": "2016",
      "chunk_content": "Generally, local search methods have been applied to the mode assignment sub-problem questioning the suitability of the GA for this aspect of the MRCPSP. The crossover operator of the GA is limited in its ability to learn the interrelations between problem parameters [12]. We aim to improve the GA by applying EDA to the mode assignment aspect of the problem.  \nThe rest of the paper is structured as follows. In Section 2, we present a background to our study. Here, we formulate the problem, present a brief review of GA configuration choices and motivation for a hybrid approach. In Section 3, we present our proposed solution approach. Section 4 presents the experimental configurations and parameter settings while results and analysis are described in Section 5. Section 6 presents our conclusions and suggests directions for future research.\nThe MRCPSP can be formerly defined as follows: A project consists of a set of $n$ activities. Every activity $i$ is labeled from $1, \\ldots, n$. Activity $i, i \\in[2, n]$ has a set of predecessors $\\operatorname{Pred}_{i}$ which suggests that activity $i$ cannot be performed until every predecessor $h, h \\in \\operatorname{Pred}_{i}$ has been completed. Activity $i$ must be performed in a mode $k \\in\\left[1, m_{i}\\right]$, where $m_{i}$ is the number of possible modes of $i$. Given that there are $A$ renewable resources, each renewable resource $r$, $r \\in[1,|A|]$ is available per period of time. The maximum per period availability of $r$ is denoted by $\\alpha \\max _{r}$. Apart from renewable resources, there are also $B$ non-renewable resources that cannot be renewed but available for the entire project duration. The overall availability of the non-renewable resource $l, l \\in[1,|B|]$ is denoted by $\\beta \\max _{l}$. Each mode of execution $k$ of an activity $i$ is composed of an integer vector of renewable resources $\\left(\\alpha_{i, k, 1}, \\ldots, \\alpha_{i, k,|A|}\\right)$, an integer vector of non-renewable resources $\\left(\\beta_{i, k, 1}, \\ldots, \\beta_{i, k,|B|}\\right)$ and the associated duration/execution time $t_{i, k}$.  \nThe aim of the MRCPSP is to select exactly one mode of execution for each activity subject to resource and precedence constraints. This is such that makespan is minimised. We formulate the MRCPSP as follow.  \nMinimise $f t_{\\alpha}$ subject to:  \n$$\n\\forall i \\in[1, n], s t_{i} \\geq f t_{h} \\forall h \\in \\operatorname{Pred}_{i}\n$$  \nLet $C_{p}$ be the set of activities being executed during time period $[\\mathrm{p}-1, \\mathrm{p}]$, then  \n$$\n\\begin{aligned}\n\\sum_{i \\in C_{p}} \\alpha_{i, k_{i}, r} & \\leq \\alpha \\max _{r} \\forall r, r \\in[1,|A|], \\forall p \\\\\n\\sum_{i=1}^{n} \\beta_{i, k_{i}, l} & \\leq \\beta \\max _{l} \\forall l, l \\in[1,|B|]\n\\end{aligned}\n$$  \nWe denote the start and finish times of activity $i$ by $s t_{i}$ and $f t_{i}$ respectively. The precedence constraint is presented in (1) while the renewable and non-renewable resource constraints are respectively presented in (2) and (3). In (2) and (3), $k_{i}$ is the allocated mode of $i$ and can only be one of the predefined modes of $i$. Also, $\\alpha_{i, k_{i}, r}$ and $\\beta_{i, k_{i}, l}$ are respectively the amount of renewable resource $r$ and non-renewable resource $l$ required by activity $i$ performed in mode FORMULA_41.",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:33",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the EDA named Probabilistic Principal Component Analysis (PPCA) to calculate the posterior distribution of latent variables z given observed data x, assuming an isotropic Gaussian noise model?",
      "topics": [
        "optimization"
      ],
      "answer": "To calculate the posterior distribution p(z|x) in PPCA with isotropic Gaussian noise, first define the covariance matrix as Σ = WWᵀ + σ²I, where W is the weight matrix, σ² is the noise variance, and I is the identity matrix. Then, calculate C = WᵀW + σ²I. The posterior distribution is then given by p(z|x) = (2π)^(-q/2) |σ⁻²C|^(1/2) * exp[-1/2 {z - C⁻¹Wᵀ(x - μ)}ᵀ (σ⁻²C) {z - C⁻¹Wᵀ(x - μ)}], where μ is the mean of the observed data x and q is the dimensionality of the latent variable z. The mean of this distribution, C⁻¹Wᵀ(x - μ), can be used to predict z for a given x.",
      "chunk_id": 6123,
      "paper_id": "Continuous Estimation of Distribution Algorithms with Probabilistic Principal",
      "paper_title": "Continuous estimation of distribution algorithms with probabilistic principal component analysis",
      "paper_year": "2001",
      "chunk_content": "For the isotropic Gaussian noise model $\\epsilon \\sim N\\left(0, \\sigma^{2} \\mathbf{I}\\right)$, equation (3) implies that $\\mathbf{z}$ conditional probability distribution over $\\mathbf{x}$-space is given by $\\mathbf{x} \\mid \\mathbf{z} \\sim N\\left(\\mathbf{W} \\mathbf{z}+\\boldsymbol{\\mu}, \\sigma^{2} \\mathbf{I}\\right)$, i.e,  \n$$\np(\\mathbf{x} \\mid \\mathbf{z})=\\left(2 \\pi \\sigma^{2}\\right)^{-d / 2} \\exp \\left\\{-\\frac{\\|\\mathbf{x}-\\mathbf{W} \\mathbf{z}-\\boldsymbol{\\mu}\\|^{2}}{2 \\sigma^{2}}\\right\\}\n$$  \nWith the marginal distribution of the latent variables $\\mathbf{z} \\sim$ $N(0, \\mathbf{I})$ defined by  \n$$\np(\\mathbf{z})=(2 \\pi)^{-q / 2} \\exp \\left\\{-\\frac{1}{2} \\mathbf{z}^{\\mathrm{T}} \\mathbf{z}\\right\\}\n$$  \nthe marginal distribution for the observed data $\\mathbf{x}$ is obtained by integrating out the latent variables as follows:  \n$$\n\\begin{aligned}\n& p(\\mathbf{x})=\\int p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) d \\mathbf{z} \\\\\n& =(2 \\pi)^{-d / 2}|\\boldsymbol{\\Sigma}|^{-1 / 2} \\exp \\left\\{-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right\\}\n\\end{aligned}\n$$  \nwhere the covariance is specified by $\\boldsymbol{\\Sigma}=\\mathbf{W} \\mathbf{W}^{\\mathrm{T}}+\\sigma^{2} \\mathbf{I}$ and this implies $\\mathbf{x} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$.  \nThe posterior distribution of $\\mathbf{z}$ is easily obtained by standard methods and it also turns out to be normal. That is, $\\mathbf{z} \\mid \\mathbf{x} \\sim N\\left(\\mathbf{W}^{\\mathrm{T}} \\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}),\\left(\\sigma^{-2} \\mathbf{W}^{\\mathrm{T}} \\mathbf{W}+\\mathbf{I}\\right)^{-1}\\right)$. Thus the posterior distribution of the latent variables $\\mathbf{z}$ given the observed $\\mathbf{x}$ can be calculated:  \n$$\n\\begin{aligned}\np(\\mathbf{z} \\mid \\mathbf{x})= & (2 \\pi)^{-q / 2}\\left|\\sigma^{-2} \\mathbf{C}\\right|^{1 / 2} \\\\\n& \\times \\exp \\left[-\\frac{1}{2}\\left\\{\\mathbf{z}-\\mathbf{C}^{-1} \\mathbf{W}^{\\mathrm{T}}(\\mathbf{x}-\\boldsymbol{\\mu})\\right\\}^{\\mathrm{T}}\\left(\\sigma^{-2} \\mathbf{C}\\right)\\right. \\\\\n& \\left.\\left\\{\\mathbf{z}-\\mathbf{C}^{-1} \\mathbf{W}^{\\mathrm{T}}(\\mathbf{x}-\\boldsymbol{\\mu})\\right\\}\\right]\n\\end{aligned}\n$$  \nwhere $\\mathbf{C}=\\mathbf{W}^{\\mathrm{T}} \\mathbf{W}+\\sigma^{2} \\mathbf{I}$. The mean of this distribution might then be used to predict $\\mathbf{z}$ for a given $\\mathbf{x}$ and the precision of the predictions would be given by the elements of the covariance matrix.  \nAlthough there is no closed form analytic solution for $\\mathbf{W}$ and $\\sigma$, the parameters for this model can be obtained by iterative procedure, e.g. by using expectation-maximization (EM) algorithms which will be explained in the next section.\nIn the continuous optimization problems, candidate solutions are usually represented as real vectors. PPCA can explain the relationship between each component of promising solution vectors with the latent variables. The procedures used in PPCA to obtain the values of the variables and to generate new instances with those values are described in this section.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:35",
      "generation_style": "practical_application"
    },
    {
      "question": "For the EDA-DQN algorithm discussed, how does the parameter $\\mu$ of the softmax strategy in action selection influence the algorithm's ability to avoid local optima and maintain knowledge-based strategies, and what observed trend justifies the selection of $\\mu = 1.9$?",
      "topics": [
        "comparison"
      ],
      "answer": "In the EDA-DQN algorithm, the parameter $\\mu$ in the softmax strategy balances exploration and exploitation. A large $\\mu$ favors actions with the highest Q-value, potentially leading to entrapment in local optima. Conversely, a small $\\mu$ promotes random action selection, which can diminish the effectiveness of knowledge-based strategies. Based on empirical observation, setting $\\mu$ to 1.9 yields the best performance, as indicated by achieving optimal Hypervolume (HV) and Inverted Generational Distance (IGD) values. The Hypervolume (HV) is calculated using the Lebesgue measure, denoted as $\\lambda(\\bullet)$, applied to the union of the hypervolumes $v_i$ of non-dominated solutions $p_i$ in the non-dominated set $NS$, expressed as $H V=\\lambda\\left(\\cup_{i=1}^{N S} v_{i}\\right)$. The Inverted Generational Distance (IGD) is calculated as $I G D=\\frac{1}{n} \\sum_{j \\in P F *}\\left(\\min _{i \\in N S}|j-i|\\right)$, where $PF*$ is the true Pareto front, and $|j-i|$ represents the Euclidean distance between solution $j$ from $PF*$ and solution $i$ from $NS$.",
      "chunk_id": 3419,
      "paper_id": "Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem",
      "paper_title": "Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem",
      "paper_year": "2023",
      "chunk_content": "In this study, to evaluate the performance of the proposed algorithm and other comparison algorithms, HV and inverted generational distance (IGD) are employed.  \nIn HV calculation, the two objectives were normalized as (56):  \n$$\nf_{i}^{\\prime}=f_{i} / f_{i, \\max }\n$$  \nwhere $f_{i}^{\\prime}$ is the $i$ th normalized objective value, $f_{i}$ is the $i$ th objective value, and $f_{i, \\max }$ is the maximum value in the $i$ th objective values.  \nThe reference point in HV is set as $(3,3)$. The HV is calculated as follows:  \n$$\nH V=\\lambda\\left(\\cup_{i=1}^{N S} v_{i}\\right)\n$$  \nTABLE III\nCOMPARISON RESULTS WITH EFFICIENT ALGORITHMS  \nwhere $\\lambda(\\bullet)$ is the Lebesgue measure, $N S$ is non-dominated set, and $v_{i}$ is the HV of the non-dominated solution $p_{i}$.  \nIGD is calculated as follows:  \n$$\nI G D=\\frac{1}{n} \\sum_{j \\in P F *}\\left(\\min _{i \\in N S}|j-i|\\right)\n$$  \nwhere $P F *$ is the true Pareto front, and $|j-i|$ is the Euclidean distance between solution $j$ from $P F *$ and solution $i$ from $N S$.  \nAccording to the definitions of HV and IGD, it can be found that the solution with bigger HV or smaller IGD means a better result.  \nFor the comparison of criteria values from different algorithms, the relative percentage increase (RPI) is utilized, which is calculated as follows.  \n$$\nR P I=\\frac{\\left|f_{c}-f_{\\min }\\right|}{f_{\\min }} \\times 100\n$$  \nIn (59), $f_{c}$ is the average criteria value obtained by the corresponding algorithm, and $f_{\\min }$ is the best average criteria value in all algorithms.  \nTABLE IV\nCOMPARISON RESULTS WITH THE EXACT CPLEX SOLVER\nFor the optimization of EDA-DQN, the most influential factor is the $\\mu$ of the softmax strategy in action selection. Specifically, large $\\mu$ tends to select the action with the highest $Q$ value but can  \nbe easily trapped in local optima, whereas small $\\mu$ tends to select the action more randomly but loses information of knowledgebased strategies. As a result, we only calibrated the parameter $\\mu$ to improve algorithm performance. In parameter calibration, the third group instances are used, where each instance was run for 20 repeats, and the average HV and IGD values were collected.  \nFig. 12(a) and (b) show the HV and IGD trends for various $\\mu$ values from 1.0 to 2.0 , respectively. According to the trends, when $\\mu$ is 1.9 , both the HV and IGD values achieve the best performance. As a result, FORMULA_397 is set to 1.9 for all following experiments.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:38",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What are the key differences between the Equi-width histogram (EWH) model, the Equi-height histogram (EHH) model, and the Cluster-based histogram (CBH) model in the context of Estimation of Distribution Algorithms (EDAs)?",
      "topics": [
        "search"
      ],
      "answer": "In EDAs, the Equi-width histogram (EWH) model divides the data into bins of equal width, while the Equi-height histogram (EHH) model creates bins such that each bin contains the same probability mass. The Cluster-based histogram (CBH) model partitions the points into M clusters in each dimension.",
      "chunk_id": 4575,
      "paper_id": "An Estimation of Distribution Algorithm With Cheap and Expensive Local Search Methods",
      "paper_title": "An Estimation of Distribution Algorithm With Cheap and Expensive Local Search Methods",
      "paper_year": "2015",
      "chunk_content": "Input:  \n1) $N$ : population size.\n2) $F E$ : maximum number of FE.\n3) $M$ : number of bins used in the VWH model.\n4) $P_{b}$ : percentage of best solutions used for local search.\n5) $P_{c}$ : probability to use the location information.\n6) $\\theta$ : Convergence threshold.  \nOutput: best solution and its objective value.\n1 pop $\\leftarrow$ initialize().\n/ initialize population /\n/ set evaluation count /\nfor $i \\leftarrow 1$ to $N$ do\n$y^{i} \\leftarrow$ sample $(P(X))$.\n$k \\leftarrow$ randomselect $\\left\\{2,3, \\ldots,\\left\\lfloor P_{b} N\\right\\rfloor-1\\right\\}$.\nfor $j \\leftarrow 1$ to $n$ do\nif $\\operatorname{rand}()<P_{c}$ then\n$y_{j}^{i} \\leftarrow$ cheapls $\\left(\\left(x_{j}^{k-1}, f^{k-1}\\right),\\left(x_{j}^{k}, f^{k}\\right),\\left(x_{j}^{k+1}, f^{k+1}\\right)\\right)$.\nend\n$y_{j}^{i} \\leftarrow\\left\\{\\begin{array}{l}0.5\\left(x_{j}^{i}+a_{j}\\right) \\text { if } y_{j}^{i}<a_{j} \\\\ y_{j}^{i} \\quad \\text { if } a_{j} \\leq y_{j}^{i} \\leq b_{j} . \\\\ 0.5\\left(x_{j}^{i}+b_{j}\\right) \\text { if } y_{j}^{i}>b_{j}\\end{array}\\right.$\nend\nend\npop $\\leftarrow$ select $\\left(\\left\\{x^{1}, x^{2}, \\ldots, x^{N}\\right\\} \\cup\\left\\{y^{1}, y^{2}, \\ldots, y^{N}\\right\\}\\right)$.\n$f e \\leftarrow f e+N$.\n$t \\leftarrow \\frac{f e}{N}$.\nif converge $\\left(\\theta, t, t_{a}\\right)$ then\npop $\\leftarrow$ sort(pop, 'ascend').\n$k \\leftarrow$ randomselect $\\left\\{1,2, \\ldots,\\left\\lfloor P_{b} N\\right\\rfloor\\right\\} . \\quad / *$ select a solution for expensive local search $* /$\n$\\left\\{x^{*}, f l\\right\\} \\leftarrow$ expensive $\\_l s\\left(x^{k},\\lfloor 0.5(F E-f e)\\rfloor\\right)$.\n$f e \\leftarrow f e+f l$.\n$t_{e} \\leftarrow \\frac{f e}{N}$.\n$/ *$ set generation count after expensive local search $* /$\nif $f\\left(x^{*}\\right)<f\\left(x^{k}\\right)$ then\n$x^{k} \\leftarrow x^{*}$.\n/ replace the old solution /\nend\nend\n31 return $x^{*}=\\arg \\min _{y \\in \\operatorname{pop}} f(y)$ and $f\\left(x^{*}\\right)$.\nwhere $x=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$ denotes a random variable vector and $P_{i}\\left(x_{i}\\right)$ is the marginal probability function of $x_{i}$.  \nFor a UMDA with a histogram marginal model, the histogram of $x_{i}$ consists of some bins. Let $M$ denote the number of bins. The $m$ th bin can be described by a tuple $<a_{i, m-1}, a_{i, m}, P_{i, m}>$, where $a_{i, m-1}$ and $a_{i, m}$ are the boundaries of the bin and $P_{i, m}$ denotes the probability that $x_{i}$ is from the interval $\\left[a_{i, m-1}, a_{i, m}\\right)$.  \nIn sampling $P_{i}\\left(x_{i}\\right)$, a bin is firstly selected with the probability $P_{i, m}, m=1, \\ldots, M$. A component $x_{i}$ is then uniformly sampled from $\\left[a_{i, m-1}, a_{m}\\right)$.  \nThree types of histogram marginal models are often used for modeling the population distribution in EDAs [43], [44].  \n1) Equi-width histogram (EWH) model, in which each bin has the same width.\n2) Equi-height histogram (EHH) model, in which each bin has the same probability.\n3) Cluster-based histogram (CBH) model, in which the points are partitioned into $M$ clusters in each dimension. Fig. 1(a)-(c) illustrates the basic ideas of EWH, EHH, and CBH, respectively, in the case of $M=4$.\n4) VWH Model: A major shortcoming of the above three models is that they are unable to reach high-precision optimal  \n[IMAGE0]",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:39",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the PMBGNP-RL algorithm, what data structures are required to represent the probabilistic model, and how are they used during the algorithm's execution?",
      "topics": [
        "selection"
      ],
      "answer": "The PMBGNP-RL algorithm's probabilistic model, denoted as $P$, is represented by a set of connection probabilities $P(b_{i}, j)$. Here, $P(b_{i}, j)$ represents the probability of a connection from branch $b_{i}$ of node $i$ to node $j$. This model can be implemented using a table or matrix, where rows represent the branches of nodes and columns represent the nodes. During execution, these probabilities are used in conjunction with Sarsa-learning to guide the node transitions within the graph-based chromosome structure, effectively determining the next node to visit based on the current state (branch) and the learned connection probabilities. The state-action pairs generated during node transitions are used to update the state-action tables efficiently, given the fixed number of branches and nodes in the GNP structure.",
      "chunk_id": 11591,
      "paper_id": "A novel estimation of distribution algorithm using graph-based chromosome representation and reinforcement learning",
      "paper_title": "A Novel Estimation of Distribution Algorithm Using Graph-based Chromosome Representation and Reinforcement Learning",
      "paper_year": "2011",
      "chunk_content": "The model construction of PMBGNP-RL is inspired by most of the classical EDA, which directly studies its graphbased chromosome structure. However, one should note that the traditional PMBGA estimates the probabilistic model by the probabilities of 0 's or 1 's in each gene loci, while PMBGP by the probabilities of functions in each node. On the other hand, the proposed algorithm estimates the probabilities of connections between the nodes. It is due to the characteristics of GNP, that is, the number of nodes and the functions of each node are predefined and fixed in GNP individuals to evolve compact programs. Moreover, the start node is not considered in our probabilistic model since its connection to the next node is predefined and fixed. The probabilistic model $P$ of PMBGNP-RL is composed of a set of probabilities $P\\left(b_{i}, j\\right)$, where $P\\left(b_{i}, j\\right)$ represents the connection probability from branch $b_{i}$ of node $i$ to node $j$. Fig. 2 shows an example of the probabilistic model. For each branch in the graph structure, the probabilities to connect to the next node is calculated to represent the probabilistic model.  \n1) Definitions: Before applying RL in the proposed algorithm, we need to give the following definitions w.r.t. RL  \nDefinition 1: Episode The task is executed by following the sequences of the node transitions in PMBGNP-RL individuals, which can be viewed as the episodes of RL. Each PMBGNPRL individual generates one episode of RL.  \nDefinition 2: State A state is defined as a branch of a node in PMBGNP-RL individual. Therefore, the set of states refers  \n[^0]\n[^0]:    ${ }^{1}$ IFLTE $(a, b, c, d)$ function means that if $(a<b)$ then $c$ else $d$, which is widely used for robot control.  \n[IMAGE2]  \nFig. 3. An example of PMBGNP-RL runs.\nto the set of branches of PMBGNP-RL individual, which is predefined and fixed.  \nDefinition 3: Action An action is defined as a node in PMBGNP-RL individual.  \nFig. 3 shows an example of PMBGNP-RL runs. The agent of each individual is controlled by following the node transitions of PMBGNP-RL to solve one task, i.e., node $1 \\rightarrow 2 \\rightarrow 5 \\rightarrow 3$. The branch of each node is selected based on its function, i.e., node 2 selects its second branch based on $\\operatorname{IFLTE}(a, b, c, d)$ function. The agent observes its environment to decide an action, i.e., to select a node to transit. Concretely speaking, an activated branch corresponds to the current state, and the selection of the next node in the branch corresponds to an action. Since the number of branches and nodes are predefined, fixed and not so large in GNP structure, PMBGNP-RL can generate and maintain the state-action FORMULA_47 tables efficiently.\n2) Sarsa-Learning: Fig. 4 shows the general form of an episode generated by the node transitions of PMBGNP-RL and the factorized state-action pairs in each time step.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:41",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measures are proposed to quantify the performance of the EDA variants PMBGNP, PMBGNP-AC, and PBILc, and how are these measures used to compare their effectiveness?",
      "topics": [
        "search"
      ],
      "answer": "The performance of the EDA variants is statistically analyzed using a one-tailed, paired t-test. This t-test is used to determine if PMBGNP-AC statistically outperforms GNP and Sarsa across all problem sizes ($S_{\\max } \\in\\{100,200,300,400,500\\}$), and whether it outperforms PMBGNP and PBILc in specific problem instances. Statistical superiority, based on the t-test results, indicates the relative effectiveness of each algorithm.",
      "chunk_id": 5140,
      "paper_id": "A continuous estimation of distribution algorithm by evolving graph structures using reinforcement learning",
      "paper_title": "A Continuous Estimation of Distribution Algorithm by Evolving Graph Structures Using Reinforcement Learning",
      "paper_year": "2012",
      "chunk_content": "Five simulations of $S_{\\max } \\in\\{100,200,300,400,500\\}$ are carried out to testify the effectiveness and scalability of the proposed algorithm. The simulation results are the average over 30 independent runs.  \n1) Fitness results: The detailed fitness values and curves of the compared methods are shown in Table III and Fig. 5. Each value of Table III indicates the average fitness with standard deviation, where the bold ones denote the best results of the problems. We perform the analysis of different methods as follows:  \nGNP: In most cases of the five problems, GNP performs worse results than the variants of PMBGNP, and only outperforms Sarsa. This is due to the lack of evolution ability by standard genetic operators, i.e., crossover and mutation. The results show that such genetic operators cause GNP achieve worse evolution ability than that of EDA based PMBGNP.  \nPMBGNP: PMBGNP achieves better performance than that of Sarsa and GNP. However, it has worse performance than PMBGNP-AC. This is due to the loss of the solution precision by discretization. On the other hand, PMBGNP actually obtains very stable performances among five problems (has the  \n[^0]\n[^0]:    ${ }^{2}$ Start node is not taken into account in this case.  \n[IMAGE5]  \nFig. 5. Fitness curves in five wall-following problems.  \nTABLE III\nThe fitness results $\\bullet$ VER 30 INDEPENDENT RUNS.  \nFig. 6. Average fitness evaluation for five wall-following problems.\nsmallest standard deviation), which is because of the balance of exploitation and exploration by Boltzmann distribution [4].  \nPBILc: In this method, only the information of three individuals (the best two and the worst one) are used to update the pdf of Gaussian distribution [15]. It might cause that the search space is explored in a too restricted region and slow speed. Therefore, this method can ensure quite good performance in\nsimple problems $\\left(S_{\\max }=100,200\\right)$, however, obtain poor results when the problem size increases $\\left(S_{\\max }=500\\right)$.  \nSarsa: Discretization causes that Sarsa has to update a huge size of $Q$ table (consists of $256 \\times 25$ state-action pairs in each time step). This might cause the slow learning speed of Sarsa. Therefore, Sarsa can only work well in simple problems among five simulation results. However, with the increase of the problem size, it cannot find the optimal solution.  \nPMBGNP-AC: The simulation results confirm the effectiveness and scalability of PMBGNP-AC. It ensures the best results among all the five problems. Although in a certain respect it is more volatile than PMBGNP (larger standard deviation), we can still say that PMBGNP-AC works quite well in directly handling the continuous variables.  \nFig. 6 plots the average number of fitness evaluations to solve the wall-following problems. Results confirm the higher evolution ability of PMBGNP-AC over the other methods.\n2) Statistical analysis: In order to further analyze the simulation results, we display the statistical analysis of different methods by t-test (one-tailed, paired). Table IV details the t-test results. This shows that PMBGNP-AC statistically outperforms GNP and Sarsa among all the problems, and outperforms PMBGNP and PBILc in some problems. Particularly, in the case of the largest problem size FORMULA_193, PMBGNP-AC is statistically superior than the other methods.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:43",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs within the Island Hybrid Evolutionary Algorithm (IHEA)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The IHEA framework uses an EDA alongside PSO and FEP on different islands to increase population diversity and reduce premature convergence by allowing them to explore different areas of the search space. The EDA is intended for exploring new promising areas, while PSO acts as a fast local search, and FEP functions as a mutation operator, with migration facilitating information sharing.",
      "chunk_id": 5700,
      "paper_id": "An Island Based Hybrid Evolutionary Algorithm for Optimization",
      "paper_title": "An Island Based Hybrid Evolutionary Algorithm for Optimization",
      "paper_year": "2008",
      "chunk_content": "The main idea of IHEA is that migration of individuals among different islands can increase diversity of each island, so it can reduce the probability of premature convergence. In IHEA, there are three subpopulation residing in three different islands, which use PSO, FEP and EDA algorithms respectively to search global optima in the whole shared search space. Since different islands use different evolutionary techniques, they probably follow different search directions in the whole shared search space, that is they explore different area in the whole search space. However, they are not independent to search, they exchange their own updated information periodically between each other by migration of promising individuals. The information sharing mechanism is helpful to search unexplored space where probably global optima is.  \nPSO in IHEA can be regarded as a fast local search operator for exploitation, EDA is used for exploring new promising area in the whole search space. FEP can be taken as mutation operator because of its long jump capability. The cooperative search among the three islands is helpful for them to explore new promising areas. It greatly reduces the probability of premature convergence, hence the global search capability is improved.  \nThe migration topology of IHEA is described in Fig. 1. The main framework of IHEA is as follows:  \nStep 1. Initialize the three population, set $k=1$.\nStep 2. Use PSO, EDA and FEP to optimize each population.\nStep 3. Compare the best individual of each population, if the best individual of population $p$ is better than the best of the other two population, migrate individuals of population $p$ to the other two population whose fitness is better than those individuals of the other two population.\nStep 4. Stop if stop criterion is true; otherwise, $k=k+1$ and goto Step 2.  \nTable 1. Details of the test functions, where $n$ and $f_{\\text {min }}$ are the dimension and the minimum value of a function respectively and FORMULA_70\nTable 2. Population size of the three islands in IHEA algorithm\nAnother big issue in IHEA is the population resource allocation among different islands. As we know, different problems may have totally different landscapes, such as the number of local or global optima, the difference among local optima, the location of local or global optima, and so on. Different problems may need different algorithms to solve it. This can be observed from the result presented in Section 4.2. Hence, we should allocate different population resources on different islands. For example, we can allocate the most population resources to the island that is more effective than other algorithms to solve the problem.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:45",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the UMDA (Univariate Marginal Distribution Algorithm) leverage the Chernoff bound to estimate the probability of promising individuals, and what role does the parameter 'delta' play in this estimation?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "UMDA",
        "Chernoff bound",
        "probability estimation"
      ],
      "answer": "The UMDA, as described in the chunk, uses the Chernoff bound to estimate the probability that the marginal probability \\(p_{t, 1}(1)\\) is lower bounded. Specifically, when \\(p_{t-1,1}(1) \\leq \\frac{M}{N(1-\\delta)}\\), the Chernoff bound is applied to obtain the inequality \\(\\mathbb{P}\\left(M p_{t, 1}(1) \\geq(1-\\delta) p_{t-1,1}(1) N \\mid p_{t-1,1}(1) \\leq \\frac{M}{N(1-\\delta)}\\right) > 1-e^{-\\frac{p_{t-1,1}(1) N}{2} \\delta^{2}}\\). This inequality indicates the probability that \\(M p_{t, 1}(1)\\) is greater than or equal to \\((1-\\delta) p_{t-1,1}(1) N\\), given the condition that \\(p_{t-1,1}(1)\\) is less than or equal to \\(\\frac{M}{N(1-\\delta)}\\). The parameter '\\(delta\\)' controls the deviation from the expected value, influencing the tightness of the bound. A smaller '\\(delta\\)' results in a tighter bound, increasing the probability that \\(p_{t, 1}(1)\\) is close to \\(p_{t-1,1}(1)\\). The chunk also states that \\(N = \\omega(n^2 \\log n)\\), implying \\(N\\) is super-polynomially large in \\(n\\), making the probability superpolynomially close to 1.",
      "chunk_id": 7451,
      "paper_id": "Analysis of Computational Time of Simple Estimation of Distribution Algorithms",
      "paper_title": "Analysis of Computational Time of Simple Estimation of Distribution Algorithms",
      "paper_year": "2010",
      "chunk_content": "With $\\hat{\\mathbf{P}}_{0}\\left(\\mathbf{x}^{*}\\right)=\\left(\\frac{1}{2}, \\ldots, \\frac{1}{2}\\right)$, we have  \n$$\n\\hat{\\mathbf{P}}_{t}\\left(\\mathbf{x}^{*}\\right)=\\gamma_{t}^{t-T_{i-1}}\\left(\\hat{\\mathbf{P}}_{T_{i-1}}\\left(\\mathbf{x}^{*}\\right)\\right)\n$$  \nwhere $T_{i-1}<t \\leq T_{i}(i=1, \\ldots, n)$. Since $\\left\\{\\gamma_{t}\\right\\}_{t=1}^{n}$ derandomizes the whole optimization process, $\\left\\{T_{i}\\right\\}_{i=1}^{n}$ in the above equation are no longer random variables. For the sake of clarity, we rewrite the above equation as  \n$$\n\\hat{\\mathbf{P}}_{t}\\left(\\mathbf{x}^{*}\\right)=\\gamma_{t}^{t-\\bar{T}_{i-1}}\\left(\\hat{\\mathbf{P}}_{\\bar{T}_{i-1}}\\left(\\mathbf{x}^{*}\\right)\\right)\n$$  \nwhere $\\bar{T}_{i-1}<t \\leq \\bar{T}_{i}(i=1, \\ldots, n)$. As we will show immediately, $\\bar{T}_{i}(1 \\leq i \\leq n)$ is an upper bound of the random variable $T_{i}$ with some probability. Since $T_{n} \\geq \\tau$, our task finally becomes calculating the $\\bar{T}_{n}$ and the probability that $\\bar{T}_{n}$ holds as an upper bound of $T_{n}$.  \nNow we present the proof in detail. First, we estimate $\\bar{T}_{1}$ and $T_{1}$ for the UMDA, which is the first stage of our analysis. Consider the 1-promising individuals. Note that the first bits of the 1-promising individuals are 1's. The sampling procedure of the UMDA can be considered as a large number of events resulting in either 0 or 1 . Hence, when $p_{t-1,1}(1) \\leq \\frac{M}{N(1-\\delta)}$, for the sampling procedure of the UMDA, by noting Lemma 5, we can apply Chernoff bounds to obtain the following:  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(M p_{t, 1}(1) \\geq(1-\\delta) p_{t-1,1}(1) N \\mid p_{t-1,1}(1) \\leq \\frac{M}{N(1-\\delta)}\\right) \\\\\n& \\quad>1-e^{-\\frac{p_{t-1,1}(1) N}{2} \\delta^{2}}\n\\end{aligned}\n$$  \nwhere $N=\\omega\\left(n^{2} \\log n\\right)$, thus the probability above is superpolynomially close to 1 , i.e., an overwhelming probability. An  \n[^0]\n[^0]:    ${ }^{5}$ The notation \" [ ]\" can be interpreted as follows: given $a>1,[a]=1$; given $a \\in(0,1),[a]=a$. For the sake of brevity, we will omit this notation but implicitly restrict the value of a probability not to exceed 1 in the following parts of the paper.\n${ }^{6}$ When there is no selection pressure, the proportion of alleles in a population with finite genes will fluctuate due to the errors brought by random sampling. For more details, one can refer to [6], [41].  \nTABLE III\nCalculation of Probability That $p_{0,1}(1)$ Is Lower Bounded by $\\bar{p}_{0,1}(1)$  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(p_{0,1}(1) \\geq \\bar{p}_{0,1}(1) \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& =\\sum_{\\forall t^{\\prime}<t \\leqslant q_{t^{\\prime}} \\in\\left\\{0, \\frac{1}{M}, \\frac{1}{M}, \\ldots, 1\\right\\}} \\mathbb{P}\\left(p_{0,1}(1) \\geq G^{r} p_{0,1}(1), p_{t-1,1}(1)=a_{t-1}, \\cdots, p_{1,1}(1)=a_{1} \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& >\\mathbb{P}\\left(p_{0,1}(1) \\geq G p_{t-1,1}(1), \\cdots, p_{1,1}(1) \\geq G p_{0,1}(1) \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& =\\mathbb{P}\\left(p_{t-1,1}(1) \\geq G p_{t-2,1}(1), \\cdots, p_{1,1}(1) \\geq G p_{0,1}(1) \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& \\mathbb{P}\\left(p_{0,1}(1) \\geq G p_{t-1,1}(1) \\mid p_{t-1,1}(1) \\geq G p_{t-2,1}(1), \\cdots, p_{1,1}(1) \\geq G p_{0,1}(1), p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& =\\mathbb{P}\\left(p_{1,1}(1) \\geq G p_{0,1}(1) \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& \\prod_{k=2}^{r} \\mathbb{P}\\left(p_{k, 1}(1) \\geq G p_{k-1,1}(1) \\mid p_{k-1,1}(1) \\geq G p_{k-2,1}(1), \\cdots, p_{1,1}(1) \\geq G p_{0,1}(1), p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& =\\mathbb{P}\\left(p_{1,1}(1) \\geq G p_{0,1}(1) \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& \\prod_{k=2}^{r} \\mathbb{P}\\left(p_{k, 1}(1) \\geq G p_{k-1,1}(1) \\mid p_{k-1,1}(1) \\geq \\bar{p}_{k-1,1}(1)=G^{k-1} \\bar{p}_{0,1}(1)\\right) \\\\\n& >\\prod_{k=1}^{r}\\left(1-e^{-\\bar{p}_{k-1,1}(1) N \\bar{p}^{2} / 2}\\right)>\\prod_{k=1}^{r}\\left(1-e^{-G^{k-1} \\bar{p}_{0,1}(1) N \\bar{p}^{2} / 2}\\right)>\\left(1-e^{-\\bar{p}_{0,1}(1) N \\bar{p}^{2} / 2}\\right)^{\\prime}\n\\end{aligned}\n$$  \nTABLE IV\nCalculation of Probability That $T_{1}$ Is Upper Bounded by $\\bar{T}_{1}$  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(T_{1} \\leq \\bar{T}_{1} \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right) \\\\\n& >\\mathbb{P}\\left(p_{T_{1}-1,1}(1) \\geq \\frac{M}{N(1-\\delta)} \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right)\\left(1-e^{-\\frac{\\bar{p}_{0,1}(1) N}{2} \\bar{p}^{2}}\\right) \\\\\n& >\\mathbb{P}\\left(p_{T_{1}-1,1}(1) \\geq \\bar{p}_{T_{1}-1,1}(1)=G^{T_{1}-1} p_{0,1}(1)>\\frac{M}{N(1-\\delta)} \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right)\\left(1-e^{-\\frac{\\bar{p}_{0,1}(1) N}{2} \\bar{p}^{2}}\\right) \\\\\n& >\\mathbb{P}\\left(p_{T_{1}-1,1}(1) \\geq \\bar{p}_{T_{1}-1,1}(1) \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1), \\bar{p}_{T_{1}-1,1}(1)>\\frac{M}{N(1-\\delta)}\\right) \\\\\n& \\mathbb{P}\\left(\\bar{p}_{T_{1}-1,1}(1)>\\frac{M}{N(1-\\delta)} \\mid p_{0,1}(1)=\\bar{p}_{0,1}(1)\\right)\\left(1-e^{-\\frac{\\bar{p}_{0,1}(1) N}{2} \\bar{p}^{2}}\\right)\n\\end{aligned}\n$$  \nTABLE V\nBOUNDING $N_{i, j}^{(s)}\\left(x_{j}^{*}\\right)$ From Below With an OVERwhelming Probability  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(N_{i, j}^{(s)}\\left(x_{j}^{*}\\right)>\\left(1-\\eta^{\\prime}\\right) \\frac{(1-\\eta) p_{t-1, j}\\left(x_{j}^{*}\\right) N}{N} M \\mid N_{i, j}\\left(x_{j}^{*}\\right) \\geq\\left(1-\\left(\\frac{1}{n}\\right)^{1+\\frac{n}{2}}\\right) p_{t-1, j}\\left(x_{j}^{*}\\right) N, p_{t-1, j}\\left(x_{j}\\right)\\right) \\\\\n& =\\mathbb{P}\\left(\\frac{(1-\\eta) p_{t-1, j}\\left(x_{j}^{*}\\right) N}{N} M-N_{i, j}^{(s)}\\left(x_{j}^{*}\\right)<\\eta^{\\prime} \\frac{(1-\\eta) p_{t-1, j}\\left(x_{j}^{*}\\right) N}{N} M \\mid N_{i, j}\\left(x_{j}^{*}\\right) \\geq\\left(1-\\left(\\frac{1}{n}\\right)^{1+\\frac{n}{2}}\\right) p_{t-1, j}\\left(x_{j}^{*}\\right) N, p_{t-1, j}\\left(x_{j}^{*}\\right)\\right) \\\\\n& >1-2 e^{-2(1-\\eta)^{2} p_{t-1, j}^{2}\\left(x_{j}^{*}\\right) \\eta^{\\prime 2} M}\n\\end{aligned}\n$$  \nTABLE VI\nCalculation of the Joint Probability That $T_{1}$ Is Bounded Above by $\\hat{T}_{2}$  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(T_{2} \\leq \\hat{T}_{2}, T_{1} \\leq \\hat{T}_{1}, p_{\\hat{T}_{1}, 2}(1) \\geq \\hat{p}_{\\hat{T}_{1}, 2}(1)>\\frac{1}{e} \\mid p_{0,1}(1)=\\hat{p}_{0,1}(1), p_{0,2}(1)=\\hat{p}_{0,2}(1)\\right) \\\\\n& >\\mathbb{P}\\left(p_{\\hat{T}_{2}-1,2}(1) \\geq \\frac{M}{N(1-\\delta)} \\mid p_{0,1}(1)=\\hat{p}_{0,1}(1), p_{0,2}(1)=\\hat{p}_{0,2}(1), T_{1} \\leq \\hat{T}_{1}, p_{\\hat{T}_{1}, 2}(1) \\geq \\hat{p}_{\\hat{T}_{1}, 2}(1)>\\frac{1}{e}\\right) \\\\\n& \\quad\\left(1-e^{-\\frac{\\left(p h^{2}\\right) p_{0}(0,0)}{2 e}}\\right)^{\\hat{T}_{1}}\\left(1-n^{-\\left(1-\\left(\\frac{1}{n}\\right)^{1+\\frac{e}{2}}\\right)^{2} e(1)}\\right)^{2 \\hat{T}_{1}}\\left(1-e^{-\\frac{\\hat{p}_{\\hat{T}_{1}, 2}(1) N}{2} e}\\right) \\\\\n& >\\mathbb{P}\\left(p_{\\hat{T}_{2}-1,2}(1) \\geq \\hat{p}_{\\hat{T}_{2}-1,2}(1)=G^{\\hat{T}_{2}-\\hat{T}_{1}-1} p_{\\hat{T}_{1}, 2}(1)>\\frac{M}{N(1-\\delta)} \\mid p_{\\hat{T}_{1}, 1}(1)=1, p_{\\hat{T}_{1}, 2}(1) \\geq \\hat{p}_{\\hat{T}_{1}, 2}(1)>\\frac{1}{e}\\right) \\\\\n& \\quad\\left(1-e^{-\\frac{\\left(p h^{2}\\right) p_{0}(0,0)}{2 e}}\\right)^{\\hat{T}_{1}}\\left(1-n^{-\\left(1-\\left(\\frac{1}{n}\\right)^{1+\\frac{e}{2}}\\right)^{2} e(1)}\\right)^{2 \\hat{T}_{1}}\\left(1-e^{-\\frac{\\left(p_{\\hat{T}_{1}, 2}(1) N}{2} e}\\right)} \\\\\n& >\\mathbb{P}\\left(p_{\\hat{T}_{2}-1,2}(1) \\geq \\hat{p}_{\\hat{T}_{2}-1,2}(1) \\mid p_{\\hat{T}_{1}, 1}(1)=1, p_{\\hat{T}_{1}, 2}(1) \\geq \\hat{p}_{\\hat{T}_{1}, 2}(1)>\\frac{1}{e}, \\hat{p}_{\\hat{T}_{2}-1,2}(1)>\\frac{M}{N(1-\\delta)}\\right) \\\\\n& \\mathbb{P}\\left(\\hat{p}_{\\hat{T}_{2}-1,2}(1)>\\frac{M}{N(1-\\delta)} \\mid p_{\\hat{T}_{1}, 1}(1)=1, p_{\\hat{T}_{1}, 2}(1) \\geq \\hat{p}_{\\hat{T}_{1}, 2}(1)>\\frac{1}{e}\\right) \\\\\n& \\quad\\left(1-e^{-\\frac{\\left(p h^{2}\\right) p_{0}(0,0)}{2 e}}\\right)^{\\hat{T}_{1}}\\left(1-n^{-\\left(1-\\left(\\frac{1}{n}\\right)^{1+\\frac{e}{2}}\\right)^{2} e(1)}\\right)^{2 \\hat{T}_{1}}\\left(1-e^{-\\frac{\\left(p h^{2}\\right) p_{0}(0,0)}{2} e}\\right)\n\\end{aligned}\n$$  \nTABLE VII\nBounding $N_{t, q}^{(i)}(x_{q}^{*})$ From Above With an Overwhelming Probability  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(N_{t, q}^{(i)}(x_{q}^{*})<\\left(1+\\eta^{\\prime}\\right)^{\\frac{(1+\\eta) p_{t-1, q}\\left(x_{q}^{*}\\right) N}{N}} M \\mid N_{t, q}\\left(x_{q}^{*}\\right) \\leq\\left(1+\\left(\\frac{1}{n}\\right)^{1+\\frac{e}{2}}\\right) p_{t-1, q}\\left(x_{q}^{*}\\right) N, p_{t-1, q}\\left(x_{q}^{*}\\right)\\right) \\\\\n= & \\mathbb{P}\\left(N_{t, q}^{(i)}\\left(x_{q}^{*}\\right)-\\frac{(1+\\eta) p_{t-1, q}\\left(x_{q}^{*}\\right) N}{N} M<\\eta^{\\prime} \\frac{(1+\\eta) p_{t-1, q}\\left(x_{q}^{*}\\right) N}{N} M \\mid N_{t, q}\\left(x_{q}^{*}\\right) \\leq\\left(1+\\left(\\frac{1}{n}\\right)^{1+\\frac{e}{2}}\\right) p_{t-1, q}\\left(x_{q}^{*}\\right) N, p_{t-1, q}\\left(x_{q}^{*}\\right)\\right) \\\\\n> & 1-e^{-2(1+\\eta)^{2} p_{t-1, q}^{2}\\left(x_{q}^{*}\\right) N^{2} M}\n\\end{aligned}\n$$  \nequivalent form of the equation above is  \n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(p_{t, 1}(1) \\geq(1-\\delta) \\frac{\\hat{p}_{t-1,1}(1) N}{M} \\mid p_{t-1,1}(1) \\leq \\frac{M}{N(1-\\delta)}\\right) \\\\\n& >1-e^{-\\frac{\\left(p_{t-1,1}(1) N}{2} \\delta^{2}}}\n\\end{aligned}\n$$  \nwhich demonstrates with an overwhelming probability the marginal probability $p_{t, 1}(1)$ is lower bounded by $G p_{t-1,1}(1)=$ $(1-\\delta) \\frac{\\hat{p}_{t-1,1}(1) N}{M}$. Furthermore, given $\\hat{p}_{t, 1}(1)=G^{t} \\hat{p}_{0,1}(1)$ and FORMULA_331, we can obtain the inequality in Table III.",
      "question_type": "algorithmic mechanism",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:49",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the Cellular Compact Genetic Algorithm (CCGA) when used to evolve weights and biases for a Block-Based Neural Network (BBNN) solving the XOR problem, focusing on the chromosome structure and fitness evaluation?",
      "topics": [
        "fitness"
      ],
      "answer": "To implement the CCGA for evolving a $2 \\times 1$ BBNN to solve the XOR problem, each CCGA node uses a 102-bit chromosome. This chromosome is structured to support ten outputs, with each output utilizing 10 bits. These 10 bits are allocated as follows: 7 bits for representing weights and 3 bits for representing biases for one BBNN node, and 2 bits for four configuration types. The fitness of each chromosome is calculated using the formula $F i t n o s z=\\frac{1}{\\frac{1+e}{1-e}}$, where 'e' represents the error. The error 'e' is computed as $e=\\frac{1}{N \\cdot n_{n}} \\sum_{j=1}^{N} \\sum_{k=1}^{N} e_{j k}^{k}$, where N is the number of training data points, and $n_n$ is the number of outputs. The individual error $e_{jk}$ is calculated as the difference between the desired output $d_{jk}$ and the actual output $y_{jk}(x)$. The training is considered achieved when the fitness reaches a value of 0.998, as demonstrated with 18-bit precision fixed-point arithmetic.",
      "chunk_id": 5967,
      "paper_id": "FPGA Implementation of a Cellular Univariate Estimation of Distribution Algorithm and Block-Based Neural Network as an Evolvable Hardware",
      "paper_title": "FPGA Implementation of a Cellular Univariate Estimation of Distribution Algorithm and Block-Based Neural Network as an Evolvable Hardware",
      "paper_year": "2008",
      "chunk_content": "To demonstrate the capability of integration between BBNN and CCGA, we implemented a $2 \\times 1$ BBNN network which has three BBNN nodes and evolving the weights with three nodes of CCGA to solve the XOR problem with two inputs, x 1 and x 2 , and one output, y 1 . The \"off\" is when x or y has value $<0.0625$ and $>0.9375$ when \"on\". Each CCGA has 102-bit which supports ten outputs; each has 10 -bit, for seven weights and three biases for one BBNN node and two bits for four configuration types. In Fig 15 shows the block  \ndiagram of BBNN and CCGA to solve the XOR problem. The error calculation block computes using following equations:  \n$$\n\\begin{gathered}\nF i t n o s z=\\frac{1}{\\frac{1+e}{1+e}} \\\\\ne=\\frac{1}{N \\cdot n_{n}} \\sum_{j=1}^{N} \\sum_{k=1}^{N} e_{j k}^{k} \\\\\ne_{j k}=d_{j k}-y_{j k}(x)\n\\end{gathered}\n$$  \nWhere, N and $\\mathrm{n}_{\\mathrm{n}}$ are number of training data and output. $\\mathrm{d}_{\\mathrm{jk}}$ and $\\mathrm{y}_{\\mathrm{jk}}$ are desired and actual output respectively.  \nFig. 17 shows the hardware simulation results of training of the XOR problem. For one training pattern, the BBNN takes 60 clock cycles while CCGA takes only 3 clock cycles. At 549 epoch, the training was achieved with fitness 0.998 using 18-bit precision fixed point arithmetic. The number of bit in neural network has an impact on the performance of the hardware [26]. Fig. 16 shows a configuration of three BBNN Blocks that give the best fitness.\n[IMAGE9]  \nFig.13. F1 simulation results\n[IMAGE10]  \nFig.14. F2 simulation results  \nTABLE I\nFPGA Hardware Resource Xilinx Virtex-5 LX50  \n[IMAGE11]  \nFig.15. Block diagram of BBNN and CCGA for XOR\nIn this paper, an approach to training BBNN in hardware using the cellular compact genetic algorithm which is a kind of EDAs is presented. We propose the cellular compact GA and the layer-based architecture for integration between the block-based neural network and cellular genetic algorithm in hardware. With the layer-based architecture, evolvable hardware based-on the integration between BBNN and CCGA is feasible and effective since both have array.like architecture. This approach provides a solution for  \nscalability of genetic algorithm since CCGA can scale up to the size of the BBNN by adding more CCGA nodes without sacrifice the speed in term of clock period and cycles. The XOR problem was used as an example of the approach. It has been implemented in hardware and can classify the data successfully. The more difficult classification problems can be solved in real-time with this kind of evolvable hardware. We believe that the more hardware resource in future FPGA will create more applications of the block-based neural network and the cellular compact GA for real world problems.\n[IMAGE12]  \nFig.16. a structure of XOR that has fitness value of 0.998\n[IMAGE13]  \nFig.17. Fitness value in training process of XOR",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:52",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the eEDA discussed for scheduling problems with precedence constraints, how does restricting the search space to only 'legal permutations' of job processing orders contribute to reducing computational cost?",
      "topics": [
        "design"
      ],
      "answer": "The eEDA focuses on 'legal permutations,' where job $i$ is placed before job $j$ if job $i$ is a precedent of job $j$. These legal permutations form a 'dominant set of schedules' containing at least one optimal schedule. By considering only these legal permutations, the eEDA reduces the search space, leading to savings in computational cost, as it avoids exploring infeasible solutions that violate the precedence constraints.",
      "chunk_id": 11971,
      "paper_id": "An effective estimation of distribution algorithm for solving uniform parallel machine scheduling problem with precedence constraints",
      "paper_title": "An Effective Estimation of Distribution Algorithm for Solving Uniform Parallel Machine Scheduling Problem with Precedence Constraints",
      "paper_year": "2016",
      "chunk_content": "In the eEDA, a job processing order permutation $\\pi$ is used to represent a solution, where $\\pi_{i}$ represents the $i$-th job to be scheduled.  \nIn order to generate the feasible solutions in accordance with the precedence constraints, job $i$ is placed before job $j$ in the permutation if job $i$ is the precedent of job $j$. These permutations that do not violate the precedence constraints are defined legal ones. The legal permutations consist of a dominant set of schedules, which contain at least one optimal schedule [14]. It guarantees that the encoding mechanism can cover the best solution. Therefore, the eEDA is designed to generate legal permutations. In addition, by considering the legal permutations only, it can reduce the search space and save computational cost.  \nThe eEDA maps the solutions into the detail schedules by using the earliest finish time formulation (EFT). For each solution, the jobs in the permutation are assigned to the  \nmachine based on the EFT until all the jobs are scheduled. To explain the decoding mechanism, a problem with 2 machines and 4 jobs is used as an example. Suppose $s_{1}=2, s_{2}=3$, and $p_{i}=1$ $(j=1,2,3,4)$. The precedence constraints between jobs are $2 \\rightarrow 3$, $2 \\rightarrow 4$ and $3 \\rightarrow 4$.  \nWithout loss of generality, a legal processing permutation $(1,2,3,4)$ is considered. Let $C_{j i}$ denote the completion time of job $j$ on machine $i$. Job 1 is scheduled first according to the permutation. Since $p_{11}=2 \\times 1=2$ and $p_{12}=3 \\times 1=3$, thus $C_{11}=2$ and $C_{12}=3$. Because $C_{11}<C_{12}$, job 1 is scheduled on machine 1 according to the EFT. Then, job 2 is considered. There is no precedence constraint between job 1 and job 2 , and $C_{22}=p_{22}=3$ $<C_{21}=C_{11}+p_{21}=2+2=4$, so job 2 is scheduled on machine 2 . Since there exists precedence constraint between job 2 and job 3 , job 3 cannot start until job 2 finishes its processing. The completion time of job 3 on different machines can be calculated as $C_{31}=C_{2}+p_{31}=3+2=5$ and $C_{32}=C_{2}+p_{32}=3+3=6$. Job 3 is scheduled to machine 1 , since $C_{31}<C_{32}$. And job 4 is assigned to machine 1 because $C_{41}<C_{42}$. Therefore, the Gantt chart of the corresponding schedule is illustrated in Fig. 1.\n[IMAGE_0]  \nFig. 1. Corresponding Gantt chart of the solution",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:58:54",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of IA-EDA compare to IA-RiEDA, specifically regarding the refinement operator's impact on the Traveling Salesman Problem (TSP) solution, considering that IA-RiEDA uses a random insertion method?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "EDAs",
        "IA-EDA",
        "IA-RiEDA",
        "Traveling Salesman Problem",
        "TSP",
        "refinement operator",
        "greedy search",
        "random insertion",
        "UMDA",
        "PBIL"
      ],
      "answer": "IA-EDA employs a 'greedy search' method within its refinement operator, as defined in equation (6), to guide antibodies towards feasible TSP solutions by utilizing distance knowledge. In contrast, IA-RiEDA replaces this 'greedy search' with a random insertion method, where unvisited cities are inserted into the location of repeated cities with uniform probability. The comparison aims to evaluate the effect of the 'greedy search' approach versus the random insertion approach on search performance. IA-RiEDA has two variants, IA-RiUMDA and IA-RiPBIL, which use UMDA and PBIL respectively.",
      "chunk_id": 11988,
      "paper_id": "Immune algorithm combined with estimation of distribution for traveling salesman problem. IEEJ",
      "paper_title": "Immune Algorithm Combined with Estimation of Distribution for Traveling Salesman Problem",
      "paper_year": "2016",
      "chunk_content": "Operator The proposed refinement operator plays an important role in the search process of the algorithm, not only enabling the antibodies sampled by EDA to be feasible but also effectively utilizing the distance knowledge of TSP by a local 'greedy search' method shown in Eq. (6). To give more insights into the influence of the refinement operator, we also employed two other competitors: one is a variant of IA-EDA wherein the refinement operator is modified by using a random insertion method, and called IA-RiEDA for short; while the other is a simpler hybrid algorithm (called IA-R), which only makes use of the refinement operator in IA.  \nTo be more specific, the random insertion method of the refinement operator used in IA-RiEDA can be described as follows. In all infeasible antibodies sampled by EDA, each unvisited city will be inserted into the location of the repeated city randomly. To realize this, we use a uniformly generated number to replace the probability generated by (6). Consequently, two kinds of IARiEDA are conducted, namely IA-RiUMDA and IA-RiPBIL, by using UMDA and PBIL, respectively. Through the comparison between IA-EDA and IA-RiEDA, we expect to find out the effects of the 'greedy search' manner derived from (6) over that of the newly established random insertion refinement operator on the search performance.  \nOn the other hand, IA-R is used for finding out the influence of the refinement operator on IA, and further for inferring which component (the refinement operator or EDA) is more effective when combined with IA. As the refinement operator in Algorithm 1 is initially proposed for refining infeasible antibodies sampled by EDA, it is revised in IA-R since all solutions generated by IA are feasible. IA-R only needs to perform the refinement operator as a local search operator rather than a refinement technique. Thus, in the experiment, we modify Algorithm 1 as in the following. First, randomly select a position $i(i=1,2, \\ldots, N)$ in the antibody  \n[IMAGE3]  \nTable V. Experimental results of IA, IA-R, and the two variants of IA-RiEDA, i.e. IA-RiUMDA and IA-RiPBIL\ngenerated by IA, and then select another position $j$ according to the following probability:  \n$$\np_{j}=\\frac{d^{\\prime}\\left(\\pi_{i}, \\pi_{j}\\right)}{\\sum_{k=1}^{N}\\left(d^{\\prime}\\left(\\pi_{i}, \\pi_{k}\\right)\\right)}\n$$  \nwhere $d^{\\prime}\\left(\\pi_{i}, \\pi_{j}\\right)=1 / d\\left(\\pi_{i}, \\pi_{j}\\right),(j=1,2, \\ldots, N$ and $j \\neq i)$ is the reciprocal of the distance between city $\\pi_{i}$ and city $\\pi_{j}$. According to (9), the gene position that is nearer to the preselected gene position has a higher probability to be selected, thus also exhibiting the same 'greedy search' manner as in Algorithm 1. For an antibody $\\pi=\\left\\{\\pi_{1}, \\pi_{2}, \\ldots, \\pi_{N}\\right\\}$ generated by IA, the refinement operator used in IA-R can be illustrated as follows:  \n$$\n\\begin{aligned}\n& \\pi_{1} \\rightarrow \\pi_{2} \\ldots \\rightarrow \\pi_{\\mathbf{i}} \\rightarrow \\pi_{i+1} \\ldots \\rightarrow \\pi_{\\mathbf{j}} \\rightarrow \\pi_{j+1} \\ldots \\rightarrow \\pi_{N} \\\\\n& \\quad \\Downarrow \\\\\n& \\pi_{1} \\rightarrow \\pi_{2} \\ldots \\rightarrow \\pi_{\\mathbf{i}} \\rightarrow \\pi_{\\mathbf{j}} \\rightarrow \\pi_{i+1} \\ldots \\rightarrow \\pi_{j+1} \\ldots \\rightarrow \\pi_{N}\n\\end{aligned}\n$$",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:58:56",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model when it is combined with Differential Evolution (DE) to solve the Transmission Expansion Planning (TEP) problem, considering that the EDA inherits the 'whole information for individuals'?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms",
        "Differential Evolution",
        "Transmission Expansion Planning"
      ],
      "answer": "While the precise steps of the hybrid EDA/DE algorithm are not fully detailed, the text suggests that the EDA component leverages 'whole information for individuals,' implying a probabilistic model is built from the population. Therefore, the EDA steps likely involve: 1) Population Initialization (potentially using a random or heuristic approach). 2) Model Building: Constructing a probabilistic model (e.g., Gaussian network, Bayesian network) from the current population. This model captures the dependencies between variables. 3) Sampling: Generating new candidate solutions by sampling from the constructed probabilistic model. 4) Selection: Evaluating the candidate solutions and selecting the best ones to update the population. The selected individuals are then used by the DE component, which likely involves: 1) Mutation: Creating mutant vectors by perturbing existing solutions. 2) Crossover: Combining the mutant vectors with the current population to generate trial vectors. 3) Selection: Choosing the best trial vectors to replace the corresponding individuals in the population. The hybrid approach uses the DE's search ability and the EDA's global information to efficiently solve the TEP model.",
      "chunk_id": 4563,
      "paper_id": "Transmission Expansion Planning Based on Hybrid EDADE Algorithm Considering Wind Power Penetration",
      "paper_title": "Transmission Expansion Planning Based on Hybrid EDA/DE Algorithm Considering Wind Power Penetration",
      "paper_year": "2015",
      "chunk_content": "Algorithm, Transmission Expansion Planning, Wind Power Penetration\nTransmission expansion planning (TEP) occupies an important place in the electric power system planning, and its crucial mission is to expand the transmission grid according to the load forecasting and generation development. Then the future grid can meet the power transport demand, ensuring the safety and economy as well as reliability of the target electric power grid. With the rapid development of wind power industry and rising injection for the grid, the fluctuant and intermittent output of wind plants has been a crucial challenge[1]. Recently, researches on TEP model coordinated with wind power penetration are mainly focused on objective functions, constraints and approaches for TEP solving. The economic benefit is still an important objective for TEP model to be concerned with, mainly including the investment cost, operation maintenance cost, social welfare, environmental benefit as well as power outage cost. Ref. [2] adds the cost of  \nDehua Zheng, IEEE MemberState Wind Power Engineering Technology Research CenterGoldwind Beijing Etechwin Electric CO. LTDBeijing, ChinaZHENGDEHUA01@hotmail.com  \nload shedding up to the objective function by the help of penalty coefficient, while Ref. [3] adds the cost of dummy generators in a similar way to deal with the violating of power balance. And With the reformation of electric power market, congestion cost is concerned to ensure the economical transport of electric power [4]. Recently, Ref. [5] runs a transmission and generation planning program and Ref. [6] has concerned about the cost of reactive power equipments, running a TEP associated with reactive power planning.  \nAs the reliability of the transmission grid is not ignorable, generally $\\mathrm{N}-1$ criterion is applied to test the target transmission grid. As a deterministic criterion, $\\mathrm{N}-1$ test mainly pays close attention to big probability events. Since some the above events may cause less loss, planning programs with $100 \\%$ satisfactory for $\\mathrm{N}-1$ criterion may result in high construction cost. Risk is defined as the product of the probability and consequence, not only the big probability events are concerned, but also the small probability events with grave consequences are reflected. Therefore, risk index is more suitable for TEP [7-9].  \nThe TEP model possesses multi-objective, high dimension, non-convex solutions, complicated constrains and nonlinearity, as it concerns about multi factors. In order to solve the TEP model efficiently and obtain the global optimum, EDA and DE is combined to be a new hybrid algorithm [10-12], inhering the prominent searching ability of DE and the whole information for individuals of EDA.  \nWhen the wind power injects at multi locations in a weak power grid with high penetration level, the difference among the locations has a serious impact on the safety, operation cost and risk value of the weak power grid. In addition, the adopt capacity for wind power is effected as well, while the location optimization is rarely referred in existing researches. In order to make up the deficiency, a TEP coordinated with locations for wind power injection optimization is proposed in this paper. And it is a non-linear model with complicate constrains.  \nThis paper is organized as following: the model of TEP associated with the optimal position for wind power penetration is formulated in Section II, the proposed solving approach as bybrid is introduced in Section III, case study and conclusion are given in Section IV and Section V respectively.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:58:59",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model in comparison to MTWPS and GA?",
      "topics": [
        "performance"
      ],
      "answer": "The effectiveness of the EDA model is evaluated using aRPV (average Relative Percentage Value), bRPV (best Relative Percentage Value), and running time. Lower aRPV and bRPV values, along with shorter running times, generally indicate better performance. The optimal values for aRPV and bRPV are identified in the comparison.",
      "chunk_id": 3500,
      "paper_id": "A Deadlock-Free Hybrid Estimation of Distribution Algorithm for Cooperative Multi-UAV Task Assignment With Temporally Coupled Constraints",
      "paper_title": "A Deadlock-Free Hybrid Estimation of Distribution Algorithm for Cooperative Multi-UAV Task Assignment With Temporally Coupled Constraints",
      "paper_year": "2023",
      "chunk_content": "The proposed DHEDA is compared with MTWPS, GA, and EDA and the CMTAP instances described in Section IVA are used in the comparison.  \nThe comparison results are shown in Table VII, where the performances of the four algorithms vary markedly in terms of aRPV, bRPV, and running time; the optimal values are bolded in black. Fig. 8 plots a set of comparison results and shows that DHEDA obtains the best bRPV and aRPV in nearly all instances, and only in a few cases does MTWPS perform the best.  \nFig. 8(c) shows the running time of all algorithms. For small-type instances, deadlocks arise with a low probability, and the GA has the shortest running time due to its simplicity. For large-scale instances, the proportion of deadlock solutions increases, as shown in the experiments in Section IV-B; thus, if the graph-based TPG or NDM is used, it takes a lot of time to resolve deadlocks. Thus, GA (using TPG) and MTWPS (using NDM) take much more time than EDA and DHEDA, which use the proposed PDAM to amend deadlocks. Although DHEDA takes marginally more time than EDA, DHEDA always obtains a better solution because DHEDA uses a dedicated local exploitation method to improve the solution quality, but EDA does not. In general, adding a small additional time cost to achieve\n[IMAGE_7]  \nFig. 8. Plots for GA (use TPG), MTWPS (use NDM), EDA, DHEDA. (a) Variance plot of RPV. (b) Line chart of bRPV. (c) Variance plot of running time.\na better solution is worthwhile. Therefore, we conclude that DHEDA outperforms existing methods when solving CMTAP, particularly for large instances.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:00",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for low-carbon production project scheduling?",
      "topics": [
        "scheduling"
      ],
      "answer": "The primary objective is to simultaneously minimize carbon emissions and project makespan using a Pareto-based Estimation of Distribution Algorithm (PBEDA). This involves encoding solutions as activity-mode lists, building a hybrid probability model to represent the solution space's distribution, and employing two Pareto archives to store non-dominated solutions and solutions for updating the probability model, respectively. The PBEDA samples and updates the hybrid probability model to generate new individuals in promising search areas, and the Taguchi method is used to study parameter setting effects, ultimately aiming to provide a Pareto set that helps project managers trade-off between carbon emissions and makespan.",
      "chunk_id": 4392,
      "paper_id": "Reduction of carbon emissions and project makespan by a Pareto-based estimation of distribution algorithm",
      "paper_title": "Reduction of carbon emissions and project makespan by a Pareto-based estimation of distribution algorithm",
      "paper_year": "2015",
      "chunk_content": "Huan-yu Zheng, Ling Wang*Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Automation, Tsinghua University, Beijing 100084, China\nArticle history: Received 28 March 2014 Accepted 6 December 2014 Available online 15 December 2014  \nKeywords:\nLow-carbon production\nProject scheduling\nEstimation of distribution algorithm\nProbability model\nMulti-objective optimization\nDue to the increasing concerns about global warming, low-carbon production has been a hot topic around the world. In this paper, carbon emissions reduction and project makespan minimization are considered simultaneously. To formulate the problem, a multi-objective multi-mode resourceconstrained project scheduling model with makespan and carbon emissions criteria is given. To solve the problem, a Pareto-based estimation of distribution algorithm (PBEDA) is proposed. Specifically, an activity-mode list is used to encode the individual of the population; a hybrid probability model is built to describe the probability distribution of the solution space; and two Pareto archives are adopted to store the explored non-dominated solutions and the solutions for updating the probability model, respectively. New individuals are generated in the promising search areas by sampling and updating the hybrid probability model. Besides, Taguchi method of design of experiments is adopted to study the effect of parameter setting. Finally, numerical results and the comparisons to other algorithms are provided to show the effectiveness of the PBEDA in terms of quantity and quality of the obtained solutions. The Pareto set derived by the PBEDA can be helpful for project manager to recognize the relationship between carbon emissions and makespan so as to properly trade-off the two criteria according to certain preference.\n(c) 2014 Elsevier B.V. All rights reserved.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:02",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of Voronoi partitioning, specifically the discrete Voronoi diagram, leverage both selected and unselected individuals to guide the search process, and what is the role of the geometric distribution in determining mesh selection probability?",
      "topics": [
        "search",
        "Estimation of Distribution Algorithms",
        "Voronoi partitioning",
        "geometric distribution"
      ],
      "answer": "The discrete Voronoi diagram partitions the search space into small grids, each containing at most one member. Ranks are assigned to these grids based on the ranks of nearby members, with grids near multiple members receiving worse ranks. Grids with the same rank form a Voronoi mesh, and each mesh is assigned a selection probability. This approach uses information from both selected and unselected individuals. The probability is calculated using a geometric distribution, defined as P = P_G(1 - P_G)^(r-1), where P_G is a number in [0, 1], set to 0.8, and r is the rank of the mesh. This probability then guides the selection of meshes for further exploration, ensuring that even meshes associated with lower-ranked individuals have a chance to contribute to the search process.",
      "chunk_id": 11964,
      "paper_id": "Multi-objective Estimation of Distribution Algorithm based on Voronoi and local search",
      "paper_title": "Multi-objective Estimation of Distribution algorithm based on Voronoi and Local search",
      "paper_year": "2016",
      "chunk_content": "One of the reasons that could increase problem complexity is increase in data dimension. There are different methods to reduce problem complexity like correlation, the principal component analysis, linear programming and etc. Due to simplicity and performance of the principal component analysis, at first in the proposed method this procedure used to reduce the data dimension and variables transfer to coordinate system with fewer dimensions. In new coordination system problem solved and finally data return to the first coordinate system.\nPrincipal component analysis is a statistical method that is frequently used to evaluate a group of correlated variables. Uses an orthogonal linear transformation to takes data to a new coordinate system and can be used to reduce the data dimension. Select fewer factors as the principal components from primary factors, by delete some unimportant information. The first extracted principal component, consider the most scattering over all data. That means the first component correlate at least to some of variables. The second extracted component has two important features, first this component consider the most set of data that are not compute by the first component, second it has no correlation to the first component. In other words, ignore the pervious component, pass the first to the final components, each component explain less variance. It means that always the first principal component explains the greatest amount of variance and the final components explain the least amount of variance, thus by ignoring the final components not lose many information.\nVoronoi partitioning has several advantages. Voronoi diagram has the ability to adapt the problem structure. Cover all the search space. Although unselected individual have low rank, but they may include well information, therefore, ignoring them may lose part of information. By partitioning, all individuals (selected and unselected) information could use to lead the search. After transferring the variables to new system, partition the search space by Voronoi diagram.\nThe discrete Voronoi diagram presented in [8] is used for simplicity. At first, all the search space divided to small grid, in which at most a member is existed in each grid. Then allocate the member rank to the related grid. The next step is to allocate the rank to the neighbors, till all the grids have rank. When a grid places near some members, it achieves the worse rank. All the grids with the same rank form a Voronoi mesh. Therefore, each mesh has its own rank. This rank use to calculate that mesh selection probability. To calculate individual rank, non-dominated sorting algorithm used [24] and for calculate probability geometric distribution is used.\nMathematically, the geometric distribution is calculated as (1).\n$\\mathrm{P}=\\mathrm{P}_{\\mathrm{G}}\\left(1-\\mathrm{P}_{\\mathrm{G}}\\right)^{\\mathrm{r}-1}$\nIn (1) $\\mathrm{P}_{\\mathrm{G}}$ is a number in $[0,1]$ and r is the related rank. In this paper $\\mathrm{P}_{\\mathrm{G}}=0.8$.",
      "question_type": "algorithmic",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:04",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "In which practical scenarios does the DT-MEDA model outperform NSGA-II, considering the number of generations and performance metrics?",
      "topics": [
        "performance"
      ],
      "answer": "DT-MEDA demonstrates better convergence, as measured by the metric $\\gamma$, on problems ZDT4 and FON compared to NSGA-II when the number of generations is relatively low (e.g., 250). When the maximum number of generations is increased to 500, DT-MEDA also converges better on ZDT6. Regarding the diversity metric $\\Delta$, DT-MEDA achieves a better spread of non-dominated solutions on OSY with fewer generations, and on ZDT4, ZDT6, and OSY after 500 generations.",
      "chunk_id": 6444,
      "paper_id": "A Decision-Tree-Based Multi-objective Estimation of Distribution Algorithm",
      "paper_title": "A Decision-tree-based Multi-objective Estimation of Distribution Algorithm",
      "paper_year": "2007",
      "chunk_content": "Four benchmark biobjective problems ZDT4, ZDT6, FON and OSY from [13] are used to test the performance of DT-MEDA.\nThe results are from 30 independent runs of the two algorithms. Each experiment starts from a randomly generated population. Table 1 shows the mean and variance of the convergence metric $\\gamma$ obtained by DTMEDA and NSGA-II on the four test problems. For brevity, $\\gamma(\\mathrm{M})$ is used to denote this metric of the nondominated sets obtained by DT-MEDA and $\\gamma(\\mathrm{N})$ denotes that of NSGA-II. $\\Delta(\\mathrm{M})$ stands for the diversity metric of non-dominated sets obtained by DT-MEDA, $\\Delta(\\mathrm{N})$ denotes that of NSGA-II.  \nTable 1. Mean and variance of\nTable 2 shows the mean and variance of the diversity metric $\\Delta$ obtained by DT-MEDA and NSGA-II on the four test problems  \nTable 2. Mean and variance of $\\Delta$\nFrom table 1 and table 2, we can see that DT-MEDA performs better on all ZDT4 and FON while NSGA-II shows better on ZDT6 and OSY in terms of convergence metric $\\gamma$. With regard to diversity metric\n$\\Delta$, DT-MEDA gets better spread of non-dominated solutions only on OSY.  \nWe perform additional experiments by increasing the number of maximum generation to 500 with other parameters fixed. Table 3 and table 4 show the convergence and diversity metric respectively.  \nTable 3. Mean and variance of\nTable 4. Mean and variance of $\\Delta$\nIt can be seen that DT-MEDA converge better in ZDT4, ZDT6 and FON after 500 generations. The variance in 30 runs is very small (less than 1e-6) except in OSY. DT-MEDA gets better spread of non-dominated solutions on ZDT4, ZDT6 and OSY. The results reveal that DT-MEDA converges slower than NSGA-II. But it can approximate the true Pareto-optimal front very closely after a relative more generation.  \nThe non-dominated solutions obtained in a certain run on ZDT4 and ZDT6 are shown in figures 1 and 2. There are axial translations for clarity in these two figures. It can be seen that the four obtained sets are very close to the known Pareto front. The two obtained by DT-MEDA are more evenly scattered.  \n[IMAGE0]  \nFigure 1. Non-dominated solutions on ZDT4\n[IMAGE1]  \nFigure 2. Non-dominated solutions on ZDT6\nDT-MEDA needs more CPU-time cost than NSGAII. For a single run on Pentium-4-2.66GHz PC with 512 M memories, the time cost is given in the following table for ZDT4 and OSY  \nTable 5. Time cost of NSGA-II and DT-MEDA\nIn the above table, 250 and 500 are the generations, and the other digits are the time cost in seconds. Although DT-MEDA is more time consuming, this shortcoming can be negligible in engineering applications where the CPU time is mainly consumed by function evaluations.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:06",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the combination of Variable Neighborhood Search (VNS) and Estimation of Distribution Algorithms (EDAs), how are the different approaches classified, and what is the underlying philosophy of the first group of combined algorithms?",
      "topics": [
        "search"
      ],
      "answer": "The different ways of combining VNS and EDAs are classified into three groups. The first group consists of combinations where the philosophy underlying VNS is embedded in EDAs. This involves considering different neighborhood spaces such as points, populations, or probability distributions to create instantiations for the approaches in this group. The second group utilizes probabilistic models or machine learning paradigms to exploit the 'good and bad shakes' of randomly generated solutions within a reduced VNS. The last group contains algorithms that alternate between VNS and EDAs.",
      "chunk_id": 5593,
      "paper_id": "Combining variable neighborhood search and estimation of distribution algorithms in the protein side chain placement problem",
      "paper_title": "Combining variable neighborhood search and estimation of distribution algorithms in the protein side chain placement problem",
      "paper_year": "2008",
      "chunk_content": "Roberto Santana $\\cdot$ Pedro Larranaga $\\cdot$Jose A. Lozano  \nReceived: 7 April 2006 / Revised: 28 September 2006 / Accepted: 12 January 2007 /\nPublished online: 23 October 2007\n(c) Springer Science+Business Media, LLC 2007\nThe aim of this work is to introduce several proposals for combining two metaheuristics: variable neighborhood search (VNS) and estimation of distribution algorithms (EDAs). Although each of these metaheuristics has been previously hybridized in several ways, this paper constitutes the first attempt to combine both optimization methods.  \nThe different ways of combining VNS and EDAs will be classified into three groups. In the first group, we will consider combinations where the philosophy underlying VNS is embedded in EDAs. Considering different neighborhood spaces (points, populations or probability distributions), we will obtain instantiations for the approaches in this group. The second group of algorithms is obtained when probabilistic models (or any other machine learning paradigm) are used in order to exploit the good and bad shakes of the randomly generated solutions in a reduced variable neighborhood search. The last group of algorithms contains the results of alternating VNS and EDAs.  \nAn application of the first approach is presented in the protein side chain placement problem. The results obtained show the superiority of the hybrid algorithm in comparison with EDAs and VNS.  \nKeywords VNS $\\cdot$ EDAs $\\cdot$ UMDA $\\cdot$ Protein folding $\\cdot$ Rotamers $\\cdot$ Protein side chain placement  \n[^0]\n[^0]:    R. Santana ( $\\boxtimes) \\cdot$ P. Larranaga FORMULA_8 J.A. Lozano  \nIntelligent Systems Group, Department of Computer Science and Artificial Intelligence, University of the Basque Country, Paseo Manuel de Lardizabal 1, 20080, San Sebastian-Donostia, Spain\ne-mail: rsantana@si.edu\nP. Larranaga\ne-mail: pedro.larranaga@ehu.es\nJ.A. Lozano\ne-mail: ja.lozano@ehu.es  \nWhen a known hard optimization problem has to be solved and no clue about the characteristics of the search space is available, a repertoire of optimization methods is usually tried in the hope that the best method for the problem is identified. In these situations, metaheuristics are one of the most employed optimization approaches. Even if there are a variety of such metaheuristics, sometimes the results obtained by each algorithm separately are not satisfactory. One alternative in such cases is the combination of those metaheuristics that have proven to be the best contenders, or that benefit from different search strategies. The study of possible ways to combine metaheuristics is therefore an important topic in optimization (Kovacevic et al. 1999; Brimberg et al. 2000; Andreatta and Ribeiro 2002; Rodriguez et al. 2003).",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:08",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the approach used in MOEA/D to repair infeasible solutions in the multi-objective knapsack problem compare to the method used in MOGLS, specifically concerning the criteria for item removal?",
      "topics": [
        "metrics"
      ],
      "answer": "Both MOEA/D and MOGLS employ a greedy repair method to address infeasible solutions in the 0/1 multi-objective knapsack problem. This repair strategy iteratively removes items until the solution becomes feasible, prioritizing the removal of items with heavy weights and small profits. The chunk states that both algorithms use the 'same instances and the same greedy repair method'. Thus, the criteria for item removal (heavy weights and small profits) are identical in both MOEA/D and MOGLS.",
      "chunk_id": 4269,
      "paper_id": "Scale adaptive reproduction operator for decomposition based estimation of distribution algorithm",
      "paper_title": "Scale Adaptive Reproduction Operator for Decomposition based Estimation of Distribution Algorithm",
      "paper_year": "2015",
      "chunk_content": "The algorithm is tested on the $0 / 1$ multi-objective knapsack problem. This section presents the test problem, evaluation setup, performance metrics and comparison results with MOEA/D. At last, the main parameter $s$ of the proposed operator is studied.\nThe classical $0 / 1$ knapsack problem is a well-known combinatorial optimization problem [34]. It can be extended for an arbitrary number of knapsacks. Given $n$ items and $m$ knapsacks. Each item has a weight and a profit while each knapsack has a capacity. Select items and place them into every knapsacks. The objective is to maximize the sum of the values of each knapsack under the condition that the sum of the weights must be less than the knapsack's capacity. The formalize definition of $0 / 1$ multi-objective knapsack problem is as follows.  \n$$\n\\left\\{\\begin{array}{ll}\n\\max & \\mathbf{F}(\\mathbf{x})=\\left(f_{1}(\\mathbf{x}), f_{2}(\\mathbf{x}), \\ldots, f_{m}(\\mathbf{x})\\right)^{\\mathrm{T}} \\\\\n& f_{i}(\\mathbf{x})=\\sum_{j=1}^{n} p_{i j} x_{i}, i=1,2, \\ldots, m \\\\\n\\text { subject to } & \\sum_{j=1}^{n} w_{i j} x_{j} \\leq c_{i}, i=1,2, \\ldots, m\n\\end{array}\\right.\n$$  \nwhere $p_{i j}$ and $w_{i j}$ are the profit and the weight of $j$ th item according to $i$ th knapsack respectively. The $c_{i}$ is the capacity of $i$ th knapsack. A solution, $\\mathbf{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)^{\\mathrm{T}}, x_{j} \\in\\{0,1\\}$ for all $j \\in(1,2, \\ldots n)$, is a binary vector where $x_{j}=1$ if the $j$ th item is selected and $x_{j}=0$ otherwise. If a solution is not feasible, it should be repaired by some repair method. In this paper, we used the same instances and the same greedy repair method which have been used in MOGLS[35] and MOEA/D [6]. The main idea of this repair method is that the item with the heavy weights and small profits is more likely to be removed. It repairs the solution by removing the item one by one until the solution is feasible [6]. Nine instances ( 3 objectives $\\times 3$ sizes) are used to test the algorithms. An\ninstance is denoted as $\\mathrm{KN}-n-m$ where $n$ is the number of items and $m$ is the number of objectives. For example, instance that has bi-objectives and 500 items is denoted as KN-500-2.",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:10",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the local search strategy based on Differential Evolution (DE), as described for optimizing parameters?",
      "topics": [
        "search"
      ],
      "answer": "The local search strategy based on DE involves two primary steps: Mutation and Crossover. The Mutation step uses two strategies to generate mutant individuals, \\(v_{i, j}^{g}\\) and \\(c_{i, j}^{g}\\), based on equations \\(v_{i, j}^{g}=x_{i 1, j}^{g}+F\\left(x_{i, j}^{g}-\\left(x_{i 2, j}^{g}+x_{i 3, j}^{g}\\right) / 2\\right)\\) and \\(c_{i, j}^{g}=\\left(x_{i 1, j}^{g}+x_{i 2, j}^{g}\\right) / 2+\\zeta_{i, j}^{g}\\left(x_{\\text {best }, j}^{g}-x_{i 3, j}^{g}\\right)\\), where \\(x_{i, j}^{g}\\) represents the \\(i\\)th individual of the \\(j\\)th dimension in the \\(g\\)th iteration, \\(F\\) is a mutation factor, and \\(\\zeta_{i, j}^{g}\\) is a random number. The Crossover step then generates a trial individual \\(u_{i, j}^{g}\\) using \\(u_{i, j}^{g}=\\left\\{\\begin{array}{l}v_{i, j}^{g} \\quad \\text { if }\\left(\\operatorname{rand}_{i, j}^{g} \\leq C R\\right) \\\\c_{i, j}^{g} \\quad \\text { otherwise }\\end{array}\\right.\\), where \\(\\operatorname{rand}_{i, j}^{g}\\) is a random number and \\(C R\\) is the crossover probability.",
      "chunk_id": 12728,
      "paper_id": "An Operation Optimization Method Based on Improved EDA for BOF End-point Control",
      "paper_title": "An Operation Optimization Method Based on Improved EDA for BOF End-point Control",
      "paper_year": "2016",
      "chunk_content": "Due to the lack relationship of UMDA $_{\\mathrm{C}}$ between variables, and the marginal probability distributions of sampling individuals are considered as the joint probability distribution of the new population, thus the premature convergence of UMDA $_{\\mathrm{C}}$ often appears in the search process, and leads to the poor search ability of global optimal solution, the population often obtains the local optimal solution. In order to enhance the diversity of population, many researchers [26]-[27] have studied intensively on the variance control based on Gaussian model.  \nAiming at the above characteristic of variance, this paper develops the strategy based on the variable scale variance. According to the search way of UMDA $_{\\mathrm{C}}$, the variable scale  \nvariance can be divided into three stages. In the first stage, the scale variance has a wide range of searching, and the current estimated variance based on Gaussian model will be amplified. The smaller variance search is used for the second stage. To approach the global optimum rapidly, the third stage is designed with a tiny search variance. The formula of proposed strategy is introduced as follows:  \n$$\n\\sigma_{i}= \\begin{cases}\\operatorname{rand}(0.1,1) & \\text { if }\\left(\\sigma_{i}<10^{-2}\\right) \\quad \\text { First stage } \\\\ \\operatorname{rand}(0.01,1) & \\text { if }\\left(\\sigma_{i}<10^{-4}\\right) \\quad \\text { Second stage } \\\\ \\operatorname{rand}(0.001,1) & \\text { if }\\left(\\sigma_{i}<10^{-6}\\right) \\quad \\text { Third stage }\\end{cases}\n$$  \nFor different search, the variable scale variance provides with randomness, so as to enhance the diversity of UMDAc.\nDue to the powerful search capability of differential evolution (DE) [4], this paper extracts the nutrition from the version of DE/rand/1 [28], so as to find the optimized parameters of LSSVM. Through crossover, mutation and selection between the individuals, the optimum approximate objective function value can be obtained, the sampling procedure can be converged fast.  \nThe main steps of local search strategy based on DE are summarized as follows:  \nStep1: Mutation: To keep the diversity of population, two kinds of newly proposed mutation strategies based on DE/rand/1 are proposed for exploitation. These mutation strategies are used to encourage generating new individuals. In the $g$ th iteration of population, $x_{i, j}^{g}$ represents the $i$ th individual of the $j$ th dimension, $i=1, \\ldots, N P . X_{\\text {Best }}{ }^{g}{ }_{j}$ is the best individual of the $j$ th dimension. In addition, $F$ and $\\zeta_{i, j}^{g}$ are the given mutation factor and the random number from the range $(0,1)$, respectively. $r 1, r 2$, and $r 3$ are different integers randomly selected from the range $[1, N P]$, and they are different from the base index $i$. On the basic of above, $v_{i, j}^{g}$ is regarded as the one of mutant individuals, $c_{i, j}^{g}$ is considered as the other one, they are presented as (11), (12), respectively.  \n$$\n\\begin{gathered}\nv_{i, j}^{g}=x_{i 1, j}^{g}+F\\left(x_{i, j}^{g}-\\left(x_{i 2, j}^{g}+x_{i 3, j}^{g}\\right) / 2\\right) \\\\\nc_{i, j}^{g}=\\left(x_{i 1, j}^{g}+x_{i 2, j}^{g}\\right) / 2+\\zeta_{i, j}^{g}\\left(x_{\\text {best }, j}^{g}-x_{i 3, j}^{g}\\right)\n\\end{gathered}\n$$  \nStep2: Crossover: Generate a trial individual $u_{i, j}^{g}$ through the crossover operation as follows:  \n$$\nu_{i, j}^{g}=\\left\\{\\begin{array}{l}\nv_{i, j}^{g} \\quad \\text { if }\\left(\\operatorname{rand}_{i, j}^{g} \\leq C R\\right) \\\\\nc_{i, j}^{g} \\quad \\text { otherwise }\n\\end{array}\\right.\n$$  \nwhere $r a n d_{i, j}^{g}$ and $C R$ are the random number and the given crossover probability from the range FORMULA_70, respectively.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:13",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What procedure is implemented in MEDA/D-MK to avoid repeatedly sampling the same permutation in the neighborhood during the generation of new solutions?",
      "topics": [
        "control",
        "diversity",
        "sampling"
      ],
      "answer": "A validation procedure is performed to avoid sampling the same permutation many times in the neighborhood, which can be detrimental to diversity. If a sampled solution $\\sigma_{s}^{k}$ is already present in $B(k)$, the algorithm discards $\\sigma_{s}^{k}$ and attempts to sample a new one until a solution $\\sigma_{s}^{k} \\notin B(k)$ is found, or a maximum number of trials ($T$) is reached. If $T$ is reached, the algorithm maintains the last sampled solution.",
      "chunk_id": 7002,
      "paper_id": "Multiobjective decomposition-based Mallows Models estimation of distribution algorithm. A case of study for permutation flowshop scheduling problem",
      "paper_title": "Multiobjective decomposition-based Mallows Models estimation of distribution algorithm. A case of study for permutation flowshop scheduling problem",
      "paper_year": "2017",
      "chunk_content": "(a) A single insert-based movement is applied to $\\sigma_{s}^{k}$ with a low probability.\n(b) A validation procedure is performed to avoid that the same permutation appears many times in the neighborhood, which is detrimental for diversity. So, if the sampled solution $\\sigma_{s}^{k} \\in B(k)$ then, the algorithm discards $\\sigma_{s}^{k}$, and tries to sample a new one until it samples a solution $\\sigma_{s}^{k} \\notin B(k)$ or reaches a maximum number of trials $(T)$. If $T$ is reached, the algorithm maintains the last sampled solution anyway.\n4. Update Pop: The new sampled solution is used to update Pop. The update procedure follows the scheme described in the general framework.  \n[IMAGE1]  \nFig. 2. Two-point crossover and insert mutation operators.\n5. Shaking procedure: To lead the algorithm to escape from local optima and control the diversity of the population, MEDA/D-MK is improved with a controlled shaking procedure that can be performed at any subproblem $k$. The procedure works as follows: If $\\sigma^{k}$ has not been enhanced (updated) after a predefined number of generations (count ${ }^{k}$ ), $\\sigma^{k}$ is updated by receiving $n_{\\text {sh }}$ random insert-based movements, even if it computes a worse $F\\left(\\sigma^{k}\\right)$. Then, the count for a new perturbation in the subproblem $k$ is reset to 0 .  \nMoreover, the $E P$ is updated as described in the general framework.\nRegarding the input parameters, besides those summarized in Table 1, the MEDA/D-MK for MopFSP includes: 1) the factor $\\alpha$ for the adapted Weighted Sum and Tchebycheff, 2) the maximum number of consecutive generations without an improvement in the subproblem $k$ before executing the shaking procedure (count ${ }^{k}$ ), and 3) the number of random insertbased movements ( FORMULA_238 ) to perturb the solution.\nThe aim of the experimental studies is to evaluate the performance of MEDA/D-MK for MoPFSP compared to the state-of-the-art approaches. In this analysis, we: (i) evaluate if, within the MOEA/D framework, using the Mallows Model is preferable to genetic operators, and (ii) check if our approach is competitive compared to the state-of-the-art results reported by the scientific community.",
      "question_type": "algorithm detail",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:15",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when applied to hydrologic model parameter calibration, and how does it achieve this compared to traditional Genetic Algorithms?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to guide the search for optimal parameters by building and sampling probabilistic distributions of promising candidate solutions, thereby increasing the probability of generating solutions with better fitness values. Unlike Genetic Algorithms that rely on crossover and mutation operators, the Estimation of Distribution Algorithm avoids these, aiming to more efficiently locate the region of the global optimum or its accurate approximation. The performance of the EDA is evaluated using metrics such as efficiency (average best objective function value), variability (standard deviation and box plot), reliability (empirical cumulative distribution function), and accuracy (Nash-Sutcliffe efficiency coefficient and overall volume error) when compared to algorithms like the Multistart Local Metric Stochastic Radial Basis Function algorithm and the Shuffled Complex Evolution algorithm.",
      "chunk_id": 12252,
      "paper_id": "Evaluation of Estimation of Distribution Algorithm to Calibrate Computationally Intensive Hydrologic Model",
      "paper_title": "Evaluation of Estimation of Distribution Algorithm to Calibrate Computationally Intensive Hydrologic Model",
      "paper_year": "2016",
      "chunk_content": "Zejun Li ${ }^{1}$; Pan Liu ${ }^{2}$; Chao Deng ${ }^{3}$; Shenglian Guo ${ }^{4}$; Ping He ${ }^{5}$; and Caijun Wang, Ph.D. ${ }^{6}$\nThe estimation of distribution algorithm (EDA) is a new evolutionary algorithm developed as an alternative to the traditional genetic algorithm (GA). The EDA guides the search by avoiding the crossover and mutation operators of the GA in favor of building and sampling probabilistic distributions of promising candidate solutions. By increasing the probability of generating solutions with better fitness values, the EDA locates the region of the global optimum or its accurate approximation. In this study, EDA was used to calibrate the parameters of the soil and water assessment tool hydrologic model for the Xunhe River Basin in China. The EDA was compared with three other algorithms: (1) the Multistart Local Metric Stochastic Radial Basis Function algorithm (a surrogate optimization method), (2) the Shuffled Complex Evolution algorithm, and (3) the GA. Four metrics are presented to assess the performance of the algorithms: (1) efficiency in terms of the average best objective function value in a limited number of function evaluations, (2) variability in terms of standard deviation and the box plot, (3) reliability in terms of the empirical cumulative distribution function, and (4) accuracy in terms of the Nash-Sutcliffe efficiency coefficient and overall volume error. Results indicated that the EDA is more efficient and could provide more accurate solutions with a relatively high probability, at least for this case study. DOI: 10.1061/(ASCE)HE.1943-5584.0001350. (c) 2016 American Society of Civil Engineers.  \nAuthor keywords: Estimation of distribution algorithm; Hydrologic model; Parameter calibration.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:17",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of Probabilistic Building Increasing Learning (PBIL) utilize the Generator Function (GF) to evolve a population of chromosomes?",
      "topics": [
        "planning"
      ],
      "answer": "PBIL, an EDA strategy, uses a Generator Function (GF) containing probabilities \\(p_{i}\\), where \\(p_{i}\\) represents the probability that the \\(i^{\\text {th }}\\) bit of an \\(n\\)-bit chromosome is 0. For a population with \\(m\\) chromosomes, \\(p_{i}\\) is calculated as the proportion of 0 bits in the \\(i^{\\text {th }}\\) bit position to the total number of bits in that position (\\(m\\)). For example, given chromosomes \\{010, 100, 111, 101\\}, the GF contains \\(p_{1}=0.25\\), \\(p_{2}=0.5\\), and \\(p_{3}=0.5\\). To generate a new population, each new chromosome has 0 assigned to its \\(1^{\\text {st }}\\), \\(2^{\\text {nd }}\\), and \\(3^{\\text {rd }}\\) bit with probabilities 0.25, 0.5, and 0.5 respectively. The GF reflects knowledge from past generations to guide the generation of good chromosomes, refining this knowledge as the population evolves.",
      "chunk_id": 5553,
      "paper_id": "QoS-based service provision schemes and plan durability in service composition",
      "paper_title": "QoS-based service provision schemes and plan durability in service composition",
      "paper_year": "2008",
      "chunk_content": "$$\nD_{p}(g)=\\frac{S_{p}}{n}\n$$  \nwhere $S_{p}$ is the number of service instances involved in partnership schemes, and $n$ is the total number of service instances in $g$.  \n- $w_{i}$ indicates the weight (i.e. importance) the user gives to each component of $F(g)$.  \nWhen a satisfactory solution is not yet found, there are several strategies for EDA to generate a new generation of population. We use the one called Probabilistic Building Increasing Learning (PBIL) to generate chromosomes for the new generation by using Generator Function (GF). A GF contains probabilities $p_{i}$, i.e. $\\left\\{p_{1}, \\ldots, p_{n}\\right\\}$, where $p_{i}$ is the probability that the $i^{\\text {th }}$ bit of an $n$-bit chromosome is 0 . For a given population with $m$ chromosomes, $p_{i}$ is the proportion of the number of 0 bits found in the $i^{\\text {th }}$ bit position to the total number of bits in the $i^{\\text {th }}$ bit position (i.e. $m$ ). For example, given a population with four chromosomes $\\{010,100,111,101\\}$, the GF contains $p_{1}=0.25, p_{2}=0.5$, and $p_{3}=0.5$. To generate a new generation of population, each new chromosome in the new population would have 0 (zero) assigned to its $1^{\\text {st }}, 2^{\\text {nd }}$, and $3^{\\text {rd }}$ bit with the probabilities $0.25,0.5$, and 0.5 respectively. In this manner, GF reflects knowledge from the past which guides how to generate good chromosomes. This knowledge would be refined as the population evolves from one generation to the next.\nIn the fitness function above, rating and partnership coupling components contribute to durability of the generated plan. Since rating concerns QoS fluctuation while partnership coupling signifies a potential that a single service change may affect the plan to a larger extent, putting weights on them will indicate to EDA to find an optimised  \nplan with good rating and low partnership coupling. That is, when it is less likely for the plan to require change, the plan is durable and can be reused.  \nAt execution time, service instances, and hence the business process flow, may suffer from performance degradation and cannot deliver service quality as planned. The flow should be prepared to survive in unstable operational environment by considering performance deviation at planning time. We can simulate the situation by injecting QoS deviation to service instances and letting the EDA process makes a plan out of those instances (see Section 6.2).",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:19",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm on the spiral dataset, what parameter settings are recommended for the binary rotation gate and the rate of mean and standard deviation shift, and over how many generations should the algorithm evolve?",
      "topics": [
        "selection"
      ],
      "answer": "When applying an Estimation of Distribution Algorithm to the spiral dataset, the learning rate for the binary rotation gate should be set to $\\theta = \\pi / 50$. The rate of the mean and standard deviation shift should be configured with $\\theta_{\\mu} = 0.1$ and $\\theta_{\\sigma} = 0.1$, respectively. The algorithm should then be allowed to evolve over a total of 400 generations.",
      "chunk_id": 6709,
      "paper_id": "Integrated feature and parameter optimization for an evolving spiking neural network  Exploring heterogeneous probabilistic models",
      "paper_title": "Integrated feature and parameter optimization for an evolving spiking neural network: Exploring heterogeneous probabilistic models",
      "paper_year": "2009",
      "chunk_content": "For the combined optimization method we chose a population structure of ten individuals organized in a single group, which is globally synchronized every generation. This setting was reported to be generally superior for a number of different benchmark problems (Defoin-Platel et al., 2009). In the case of the spiral dataset the learning rate for the binary rotation gate was set to $\\theta=\\pi / 50$. For the rate of the mean and standard deviation shift we chose $\\theta_{\\mu}=0.1$ and $\\theta_{\\sigma}=0.1$ respectively. The algorithm was allowed to evolve over a total number of 400 generations. Due to its larger problem size 1000 generations were computed for the hypercube problem, using once more $\\theta=\\pi / 50$ for the binary learning rate and $\\theta_{\\mu}=0.1$ and $\\theta_{\\sigma}=0.05$ for the continuous update operator.  \nIn order to allow a fair comparison between the classification methods used in this study, one has to decide for an appropriate parameter configurations for each classifier. In contrast to the other classifiers, NBC does not require the tuning of any parameters. To setup the MLP we have experimented on a subset of the datasets containing the relevant features only. By changing the number of hidden neurons, the learning rate, and the momentum term a satisfying configuration, in terms of classification accuracy, was experimentally obtained by systematic trial and error. The results of the parameter study for the MLP on the spiral dataset are presented in Fig. 4. The finally chosen setting is based on a tradeoff between computational cost and classification accuracy. The additional cost of more hidden neurons is not worth the slight increase of accuracy reported in Fig. 4. Using 10-fold crossvalidation the chosen configuration of MLP achieved a satisfying accuracy of 0.849 (standard deviation 0.0634) on the spiral dataset containing the two relevant features only. When applied to the full dataset using all 20 features, the same configuration resulted in an accuracy of $0.611(0.0608)$. Thus, appropriate feature selection does improve the performance of MLP, which is the key principle exploited in the wrapper approach. Finding an appropriate setting for the spiral problem appeared to be more difficult, in contrast to the other benchmark. For the latter problem changes in the configuration did not seem to impact the performance of the classifier too much. Thus we decided to use the same parameter setting for both problems. The common error back-propagation learning algorithm was used to train the network, connection weights were initialized with small uniform random numbers in the range $[-0.25,0.25]$.  \nMost of the parameters of QiSNN are optimized during the evolutionary process. For each class $l \\in L$ three parameters exist: The modulation factor $m_{l}$, the similarity threshold $s_{l}$, and\n[IMAGE3]  \nFig. 4. The figure shows the accuracy levels achieved by 32 different configurations of a multi-layer perceptron on the two-spiral dataset. Each point represents the average of the accuracies obtained in a 10 -fold cross-validation experiment, error bars indicate the standard deviation. All configurations use neurons with sigmoid transfer functions, trained in 500 epochs. The lower curve (green triangles) represents the accuracy of the MLP when all 20 features are included in the dataset, the upper curve (black squares) the accuracy when only the relevant features are used. The circles (red) indicate the finally chosen configuration for the experiments performed in this study, which is a satisfying compromise between computational cost and classification quality.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:21",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the BUMDA algorithm, how is the Boltzmann distribution approximated to reduce computational effort, and what mathematical measure is minimized to maintain the relationship between the Boltzmann distribution and its approximation?",
      "topics": [
        "convergence"
      ],
      "answer": "The Boltzmann distribution, $P(x)$, is approximated by a normal distribution, $Q(x)$, represented as a Gaussian distribution, to reduce computational effort. The relationship between the Boltzmann distribution and the normal distribution is maintained by minimizing the Kullback-Leibler divergence (KLD), denoted as $K_{Q, P} = \\int_{x} Q_{x} \\log \\frac{Q_{x}}{P_{a}} \\mathrm{d} x$, where $P(x)$ is named $P_{a}$ and $Q(x, \\mu, \\nu)$ is named $Q_{x}$. Minimizing this divergence preserves the essence of the Boltzmann distribution while using a lower computational effort. The mean, $\\mu$, and variance, $\\nu$, of the Gaussian distribution are then computed using equations \\mu = \\sum_{x_{i}} w(x_{t}) x_{t}, where $w(x_{t}) = \\frac{g(x_{t})}{\\sum_{x_{i}} g(x_{t})}$, and $\\nu = \\sum_{x_{i}} w'(x_{t})(x_{t} - \\mu)^{2}$, where $w'(x_{t}) = \\frac{g(x_{t})}{\\sum_{x_{i}} g(x_{t})+1}$, respectively, to define the normal distribution approximation.",
      "chunk_id": 473,
      "paper_id": "Design and Optimization of Heat-Integrated Distillation Column Schemes through a New Robust Methodology Coupled with a Boltzmann-Based Estimation of Distribution Algorithm",
      "paper_title": "Design and Optimization of Heat-Integrated Distillation Column Schemes through a New Robust Methodology Coupled with a Boltzmann-Based Estimation of Distribution Algorithm",
      "paper_year": "2014",
      "chunk_content": "2.1. Fundamentals of the BUMDA Algorithm. The BUMDA is an algorithm belonging to the estimation of distribution algorithms (EDAs). These algorithms were derived from the genetic algorithms. The main difference among them is the method of generating the population. In genetic algorithms, each population is obtained using factors of mutation and crossing on the individuals with the best aptitude. In EDAs, a probability distribution is used to sample new candidate individuals. Thus, the probability distribution will determine which individuals must be considered to produce the next generation. For instance, for a problem of maximization, there will be a high probability of sampling individuals with the highest fitness function, and each new population is obtained employing these individuals. Therefore, all new individuals will be found around the maximum of the function. Otherwise, if the fitness function of the problem represents a minimization, the probability of sampling will be high on the region with the lowest values of the fitness function. Therefore, the new  \npopulation will meet the characteristics of the individuals with lowest fitness function.  \nWith the aim of effectively guiding the convergence toward the optimum value, the BUMDA algorithm is supported by two key items: (1) the Boltzmann distribution and (2) the application of a truncation method of population on the best individuals.\n2.2. Boltzmann Distribution. On one hand, the goal of the Boltzmann distribution is getting a continuous approximation to the fitness function $(g(x))$ through the probability model $(P(x))$ presented in eq 1. This means that the distribution is able to adapt to the function's shape and distinguish every optimum present on it.  \nBoltzmann distribution includes the fitness function, the parameter $\\beta$, and the parameter of normalization $Z$. In the original context of the Boltzmann distribution, $\\beta$ is defined by the inverse product between the Boltzmann's constant $(k)$ and the temperature $(T), 1 /(k T)$; nevertheless, for EDAs, this parameter has a direct relationship with the selection pressure and the variance. Besides, the $Z$ parameter is evaluated by the summation of the exponential function of the numerator, on the whole search domain, as it is indicated by eq 2 .  \n$$\n\\begin{aligned}\n& P(x)=\\frac{\\exp [\\beta g(x)]}{Z} \\\\\n& P\\left(x_{t}\\right)=\\frac{\\exp \\left[\\beta g\\left(x_{t}\\right)\\right]}{\\sum_{x} \\exp [\\beta g(x)]}\n\\end{aligned}\n$$  \nBoltzmann distribution involves using an infinite population in order to explore the complete search space of the function, but it does not represent an efficient way to carry out the exploration. Thus, the Bolzmann distribution has been approached by a normal distribution, $Q(x)$, represented by a Gaussian distribution, whose form is shown in eq 3. This distribution is properly defined as a function of the mean $(\\mu)$ and variance $(\\nu)$ of the population; the relationship with the Boltzmann distribution is determined by the Kullback-Leibler divergence (KLD). This divergence represents the distance or deviation between the Boltzmann and the normal distribution, such as it is observed in eq 4. Consequently, the minimization of KLD is achieved between the distributions in order to preserve the Boltzmann distribution essence using a low computational effort. Through the minimization and under several considerations along the mathematical treatment, were obtained the functions to evaluate both the mean and the variance of the population, which preserve the corresponding interrelation between both distributions. Thus, these variables will be computed and used to evaluate the normal distribution employed as the approximation. The corresponding expressions are represented by eq 5 and eq 6 , respectively.  \n$$\n\\begin{aligned}\nQ(x) & =\\prod_{i=1}^{n} Q_{x_{i}}(x) \\quad \\text { where } \\\\\nQ_{x}(x) & =Q_{x}\\left(x_{t}, \\mu_{t}, \\nu_{t}\\right)=\\frac{\\exp \\left[-\\left(x_{t}-\\mu_{t}\\right)^{2} / 2 \\nu_{t}\\right]}{\\left(2 \\pi \\nu_{t}\\right)^{1 / 2}} \\\\\nK_{Q, P} & =\\int_{x} Q_{x} \\log \\frac{Q_{x}}{P_{a}} \\mathrm{~d} x \\quad \\begin{array}{l}\n\\text { naming } P(x)=P_{a} \\\\\n\\text { and } Q(x, \\mu, \\nu)=Q_{x}\n\\end{array} \\\\\n\\mu & =\\sum_{x_{i}} w\\left(x_{t}\\right) x_{t} \\text { defining } w\\left(x_{t}\\right)=\\frac{g\\left(x_{t}\\right)}{\\sum_{x_{i}} g\\left(x_{t}\\right)} \\\\\n\\nu & =\\sum_{x_{i}} w^{\\prime}\\left(x_{t}\\right)\\left(x_{t}-\\mu\\right)^{2} \\text { considering } w^{\\prime}\\left(x_{t}\\right)=\\frac{g\\left(x_{t}\\right)}{\\sum_{x_{i}} g\\left(x_{t}\\right)+1}\n\\end{aligned}\n$$  \nWhere $x_{i}$ represents each individual selected.\n2.3. Truncation Method. As can be seen in Figure 5 (for the case of a maximization problem), by means of truncation of",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:24",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the OptGC EDA model compare to the VV control method in terms of reactive power usage and voltage violation percentage under maximum load conditions?",
      "topics": [
        "control"
      ],
      "answer": "Under maximum load conditions, the OptGC EDA model uses significantly less reactive power than the VV control method. Specifically, VV uses 5.9 times more reactive power than OptGC. However, VV achieves a slightly better voltage control with voltage violations occurring $0.1 \\%$ of the time, while OptGC experiences voltage violations $0.2 \\%$ of the time. This demonstrates a trade-off where OptGC minimizes reactive power usage at the expense of slightly increased voltage violations compared to VV.",
      "chunk_id": 9540,
      "paper_id": "EDA-based optimized global control for PV inverters in distribution grids",
      "paper_title": "EDA-based optimized global control for PV inverters in distribution grids",
      "paper_year": "2021",
      "chunk_content": "Although high demand periods are less problematic in PV integration studies, due to the disconnection of the OLTC at the substation and the capacitors banks, the largest voltage violations in our study occur under maximum load conditions.  \nThe results for the maximum load scenarios with clear, partly cloudy and overcast conditions are shown in Figures 11-13, respectively. The structure and colour code of the figures are the same as for minimum load results.  \nOptGC outperforms every other alternative in terms of reactive power use (except for the PF0.98 control on the overcast day) with a percentage of bad voltage values of $0.2 \\%$. Since PF0.98 uses reactive power as a function of the actual PV power delivered, it is expected that on days with low irradiance, PF0.98 will use little reactive power. But PF0.98 fails to maintain the voltages within the allowed range; violations occur $21 \\%$ of the time. VVwD+VW and VVwD are close in terms of reactive power usage and voltage stability, but inferior to OptGC. VVwD+VW and VVwD use $46 \\%$ and $47 \\%$ more reactive power than OptGC, respectively; while the percentages of time outside the voltage limits are $2 \\%$ for both. For VV control, the amount of reactive power is 5.9 times higher than OptGC and voltages are violated $0.1 \\%$ of the time. VV is the only control that achieves better voltage control than OptGC, but at the cost of a disproportionate amount of reactive power.  \nAs expected, the curtailed energy in maximum load scenarios is considerably lower than in the minimum load scenarios (up to $10,433 \\mathrm{kWh}$ ), with maximum values below $2,000 \\mathrm{kWh}$. OptGC again outperforms all the methods that make use of power curtailment-except for PF0.98 on the overcast day. Again, there is a slight residual active power curtailment on the overcast day that can be explained by the algorithm as an approximator.  \nPractically all local control strategies violate the lower voltage limits as observed in the violin plots in Figures 11-13. The severe undervoltage situations experienced in maximum load scenarios are explained by the modifications made to the test feeder (explained in Section 5), primarily the removal of shunt capacitors. OptGC yields a high density of voltage magnitudes close to the lower limit. Since the objective function does not reward voltages being a safe distance away from the lower limit, small variations in the load can force voltage violations which occur $0.2 \\%$ of the time. There is a tradeoff between minimizing power used for control and the proximity of voltages to the limit.  \nPV systems located at the end of the feeder use more reactive power compensation and power curtailment. For OptGC, the\n[IMAGE14]  \nFIGURE 14 Percentage of time with voltage violations (out of voltage limits) split by scenario (each colour represents one scenario). Red colours represent the high load scenarios, where most of the voltage violations take place\n[IMAGE_15]  \nFIGURE 15 Total active power curtailment, reactive and apparent energy used for control in all scenarios\nparticipation of PV systems in the control is unbalanced, with systems in phases 2 and 3 suffering more power curtailment, and systems in phases 1 and 3 using more reactive power compensation. This unbalanced nature of global controllers is due to their ability to inject or absorb reactive power in one phase to avoid voltage violations in the other phases.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:25",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned, what data structures are required when employing the extended compact genetic algorithm (ECGA) with the split-on-demand (SoD) discretization method for real-parameter optimization problems?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms",
        "data structures"
      ],
      "answer": "When using ECGA with SoD for real-parameter optimization, the primary data structure involves representing real-valued variables using an adaptive discretization encoding scheme. Specifically, SoD encodes individuals of real values into integer codes. This integer representation is then used within the ECGA framework, which typically operates on bit strings. The implementation needs to maintain a mapping between the real-valued variables and their corresponding integer representations generated by SoD, allowing ECGA to effectively process continuous problems.",
      "chunk_id": 7317,
      "paper_id": "Enabling the Extended Compact Genetic Algorithm for Real-Parameter Optimization by Using Adaptive Discretization",
      "paper_title": "Enabling the Extended Compact Genetic Algorithm for Real-Parameter Optimization by Using Adaptive Discretization",
      "paper_year": "2010",
      "chunk_content": "Estimation of distribution algorithm, EDA, ECGA, split-on-demand, SoD, real-parameter optimization, economic dispatch, valve point effect.\nGenetic algorithms are widely applied on many real-world optimization problems. According to the theory of design decomposition (Goldberg, 2002), key components in the GA success include identifying, reproducing, and exchanging solution structures. Recombination, one of the main GA operators, mixes the promising subsolutions, called building blocks (BBs), and creates new solutions. Genetic algorithms therefore work very well on those problems that can be decomposed into subproblems. However, problem-independent recombination operators with fixed chromosome representations  \n[^0]\n[^0]:    *To whom correspondence should be addressed.  \noften break building blocks and result in ineffective mixing. When traditional genetic algorithms meet complex solution structures composed of groups of related genes, they often fail to appropriately identify and exchange building blocks to create good final solutions (Goldberg et al., 1989).  \nIn order to mix genes effectively, Larranaga and Lozano (2001) and Pelikan et al. (2002) proposed evolutionary algorithms based on probabilistic models. In such schemes, the offspring population is generated according to the estimated probabilistic model of the selected individuals instead of using regular recombination and mutation operators. The probabilistic model is expected to reflect the problem structure, and better performance can be achieved via exploring and exploiting the relationship among genes. These evolutionary algorithms are called estimation of distribution algorithms (EDAs) or probabilistic model building genetic algorithms (PMBGAs; Larranaga and Lozano, 2001; Pelikan et al., 2002).  \nIn EDAs, decision variables are often coded with binary codes. It is computationally expensive to find high accuracy solutions in solving continuous problems for EDAs combined with elementary discretization methods (Tsutsui et al., 2001; Pelikan et al., 2003). Moreover, many real-world engineering problems are real-parameter optimization problems, such as structural optimization. In the literature, several attempts to apply EDAs to problems in the continuous domain have been made, including continuous population-based incremental learning with Gaussian distribution (Sebag and Ducoulombier, 1998), a real-coded variant of population-based incremental learning with interval updating (Servet et al., 1997), Bayesian evolutionary algorithms for continuous function optimization (Shin and Zhang, 2001), and the real-coded Bayesian optimization algorithm (Ahn et al., 2004).  \nHowever, these approaches require the knowledge of and are clearly specialized for the modified algorithms. In order to provide a good, general interface between problems of continuous variables and algorithms for discrete variables, we propose a framework that enables the EDAs designed for handling bit strings to tackle realvalued optimization problems. Particularly, we develop a new, adaptive discretization encoding scheme that can be easily integrated into EDAs or other algorithms for discrete variables, and we use the extended compact genetic algorithm (ECGA; Harik, 1999) as an example in the present work.  \nIn the next section, we will give a background of this study, including a brief introduction of ECGA and two well-known discretization methods: the fixed-height histogram (FHH) and the fixed-width histogram (FWH). Section 3 proposes split-ondemand (SoD) and describes in detail how SoD encodes individuals of real values into integer codes. In Section 4, we use SoD to enable ECGA to handle real-valued variables. The numerical experiments on benchmark functions are presented in Section 5, including the comparisons with the elementary discretization techniques and other optimization methods in evolutionary computation. The proposed framework is also adopted to tackle the economic dispatch problem in Section 6. Finally, Section 7 concludes this work.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:27",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific characteristics of the Cauchy distribution are leveraged in certain Estimation of Distribution Algorithms (EDAs) to address premature convergence, and how are Gaussian distribution parameters utilized in conjunction with it?",
      "topics": [
        "evolutionary"
      ],
      "answer": "Some EDAs employ the Cauchy distribution to prevent premature convergence. Because the moments of an \\(n\\)-dimensional variable with a multivariate Cauchy distribution are undefined, the mean vector and covariance matrix are computed as if the distribution were Gaussian. When sampling new solutions, the scaling factor of the Cauchy distribution is used to generate isotropically distributed new solutions.",
      "chunk_id": 5389,
      "paper_id": "A review on probabilistic graphical models in evolutionary computation",
      "paper_title": "A review on probabilistic graphical models in evolutionary computation",
      "paper_year": "2012",
      "chunk_content": "An extended version of IDEA (Bosman and Thierens 2001) uses a mixture of normal distributions over clusters of solutions, obtained by applying a clustering algorithm before learning mixture components. rBOA (Ahn et al. 2004) first learns a GBN to obtain a decomposition of the problem variables into smaller subproblems. Then, a separate mixture of GBNs is learnt for each of the subproblems by clustering the solutions in that subproblem. In BGMMEDA (Li et al. 2006), instead of clustering the samples, a boosting technique is applied to estimate a Gaussian mixture model.  \nMB-GNG (Marti et al. 2011) adopts growing neural gas, a specific single-layer neural network, to determine the location of the components of the mixture of Gaussian distributions. This model learning algorithm is sensitive to, and therefore does  \nnot neglect, outliers and is able to automatically adapt its topology while decreasing the accumulated error of the network nodes. The multi-model EDA framework (Weise et al. 2011) extends these mixture methods by applying traditional EA recombination operators to the individual models learnt for each of the clusters in order to improve search space exploration.  \nRM-MEDA (Zhang et al. 2008) learns a piece-wise continuous manifold for multiobjective optimization using the local principle component analysis algorithm. Each model component consists of a hyper-rectangle with a Gaussian noise.\nPosik $(2008,2009$ a) proposed the use of Cauchy distribution for the purpose of preventing premature convergence. Since the moments of an $n$-dimensional variable with multivariate Cauchy distribution are not defined, the mean vector and covariance matrix of a Gaussian distribution are computed instead. For sampling new solutions, the scaling factor of the Cauchy distribution is used to obtain isotropically distributed new solutions.  \nMore recently some EDAs have employed copula theory to relax the Gaussian assumption for the variables. Copula-based EDAs (CEDAs) (Salinas-Gutierrez et al. 2009; Wang et al. 2009; Wang and Zeng 2010; Cuesta-Infante et al. 2010) use the copula function for estimating the joint probability distribution of the variables according to Sklar's theorem. The copula function only uses the marginal univariate probabilities to compute the joint probability distribution. This reduces the computational complexity of model learning. Two-dimensional elliptical copulas as well as Archimedean and empirical copulas and their extensions to higher dimensions are studied in the literature. These copula functions will serve as the problem dependency structure when sampling new solutions from the learnt model. In each generation the algorithm selects or constructs a copula function after estimating the univariate marginal distributions and then, generates new samples according to the copula distribution.  \nCMA-ES (Hansen 2006) incorporates model estimation into evolutionary strategies which mainly deal with continuous domain optimization. The algorithm learns an MND as its probabilistic model to generate new solutions. The probabilistic model estimated in each generation is a combination of information collected over several generations, taking into account the path that the optimizer has traversed in the search space. Instead of estimating a new probabilistic model in each generation, the algorithm adapts the model during evolution. Thus, the algorithm is able to use smaller population sizes for optimization by spanning model learning over several generations. Because of such an adaptation strategy, some researchers do not completely consider this algorithm as an EDA (Posik 2009b). It is worth to note that similar techniques have been proposed for improving the efficiency of EDAs in optimization (Pelikan et al. 2008; Bosman et al. 2008).",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:29",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs using Differential Evolution (DE) with mutation, crossover, and selection operators, and how does NMBDE adapt these operators?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The purpose is to iteratively update a population of solutions using mutation, crossover, and selection. The standard DE uses these operators on floating-point encoded vectors. NMBDE, which uses binary coding, adapts these operators by incorporating a new probability estimation operator to handle the bit string representation, since the standard mutation operator generates real-coded vectors. NMBDE still uses the mutation, crossover, and selection operators.",
      "chunk_id": 4963,
      "paper_id": "A novel modified binary differential evolution algorithm and its applications",
      "paper_title": "A novel modified binary differential evolution algorithm and its applications",
      "paper_year": "2012",
      "chunk_content": "The population of the standard DE consists of a group of floating-point encoded vectors randomly initialized in the continuous space. Three evolutionary operators, i.e., the mutation operator, the crossover operator and the selection operator are commonly used for DE to update the population. In the evolutionary process, the mutation operator and crossover operator are used to generate the new trail individual, and the selection\noperator chooses the better one between the target individual and its trial alternative for the next generation by comparing their fitness values.  \nMutation: There are several mutation schemes in DE, and \"DE/ rand/I\" as Eq. (1) is the most popular one.\n$u_{i j}^{t+1}=x_{t, j}^{t}+F \\otimes\\left(x_{t, j}^{t}-x_{t, j}^{t}\\right)$\nIn Eq. (1), $u_{i j}$ is the element of the mutant individual $u_{i} ; F$ is the scaling factor which is a positive constant; $t$ is the index of generation; $x_{t, j}, x_{t, j}$ and $x_{t, j}$ are three bits of the randomly chosen individuals with index $r_{1} \\neq r_{2} \\neq r_{3} \\neq i$.  \nCrossover: The trial individual $v_{i}$ is generated by crossing the target individual $x_{i}$ with its mutant counterpart $u_{i}$. The widely used binomial crossover is defined as the following equation:\n$v_{i j}^{t+1}= \\begin{cases}u_{i j}^{t+1}, & \\text { if }(\\text { rand } j \\leq C R) \\text { or }(j=\\text { rand }(i)) \\\\ x_{i j}^{t}, & \\text { otherwise }\\end{cases}$\nwhere $v_{i j}$ is the element of the trial individual $v_{i}$ and $C R$ is the crossover probability ranged in $(0,1)$. The randj are a stochastic number uniformly distributed within $(0,1)$; rand $(i)$ are a random integer within $1,2, \\ldots, N$ where $N$ is the length of individual; $j$ is the index of the dimensionality with $j=1,2, \\ldots, N$.  \nSelection: The selection operator is defined as the following equation:\n$x_{i}^{t+1}= \\begin{cases}v_{i}^{t+1}, & \\text { if } f\\left(v_{i}^{t+1}\\right)<f\\left(v_{i}^{t}\\right) \\\\ x_{i}^{t}, & \\text { otherwise }\\end{cases}$\nAs shown in Eq. (3), the trial individual $v_{i}$ replaces the target individual $x_{i}$ if its fitness value is better. Otherwise, the target individual is reserved in the next generation. Therefore, the population is updated according to these three operators.\nNMBDE adopts the binary coding scheme and each individual is represented by a bit string denoted as $p x_{i}=p x_{0} \\cdot\\left|p x_{i j} \\in 0,1\\right.$; $i=1,2, \\ldots, N P: j=1,2, \\ldots, N$, where $N P$ is the population size and $N$ is the dimensionality of solution. NMBDE reserves the updating formulas of the standard DE, including the mutation operator, the crossover operator and the selection operator. Since the standard mutant operator generates real-coded vectors not bit strings, a new probability estimation operator is proposed to tackle this problem in NMBDE, into which the mutant operator is integrated.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:31",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the calculation and interpretation of the hypervolume $I_{H}$ as it is used to compare the performance of IRM-MEDA, RM-MEDA, NINA, and NSGA-II?",
      "topics": [
        "selection"
      ],
      "answer": "The hypervolume $I_{H}$ measures the performance related to the diversity and extent of nondominated solutions. In the context described, a higher $I_{H}$ value indicates a larger objective space dominated by a technique. The reference point for calculating $I_{H}$ is formed by combining the maximum value of each objective search across all optimization runs; specifically, the reference points are set to $2.9 \\times 10^{4}, 9.0 \\times 10^{4}$ and $10 \\times 10^{4}, 750$ for test system 1 and system 2, respectively. For comparative purposes, the $I_{H}$ is normalized to the interval $[0,1]$. Based on the average $I_{H}$ values obtained over ten runs, IRM-MEDA demonstrates a larger objective space than RM-MEDA, NINA and NSGA-II, while NSGA-II performs the worst according to this indicator.",
      "chunk_id": 4765,
      "paper_id": "An improved multiobjective estimation of distribution algorithm for environmental economic dispatch of hydrothermal power systems",
      "paper_title": "An improved multiobjective estimation of distribution algorithm for environmental economic dispatch of hydrothermal power systems",
      "paper_year": "2015",
      "chunk_content": "First, hypervolume $I_{H}$ is adopted to measure the performance of the diversity and extent of the nondominated solutions. The Paretooptimal fronts with the maximum $I_{H}$ obtained by each technique out of ten runs are presented in Figs. 5-10. The Pareto-optimal fronts of IRM-MEDA has been compared with RM-MEDA, NINA, NSGA-II, It is clear that all the attained Pareto-optimal fronts have good diversity characteristic of nondominated solutions. This indicates the EED of HPS problem can be efficiently solved by these techniques.  \nThe selection of reference point selection for each test system has a significant impact on the $I_{H}$ value. In our experiment, the joint reference point is formed by combining the maximum value of each objectives search in all the optimization runs. In detail, we set $2.9 \\times 10^{4}, 9.0 \\times 10^{4}$ and $10 \\times 10^{4}, 750$ as the reference point for the test system 1 and system 2 respectively. For the simplicity of the comparative study, we normalize the $I_{H}$ to the interval $[0,1]$.  \nFor further studying the extent characteristic of these techniques, the average value of $I_{H}$ over ten different optimization runs\n[IMAGE1]  \nFig. 4. The average $I_{H}$ values of system 2 under the different settings of the proportional coefficient.  \n[IMAGE2]  \nFig. 5. Pareto-optimal fronts of test system 1 with the maximum $I_{H}$ value obtained by IRM-MEDA and RM-MEDA.\n[IMAGE3]  \nFig. 6. Pareto-optimal fronts of test system 1 with the maximum $I_{H}$ value obtained by IRM-MEDA and NSGA-II.\n[IMAGE4]  \nFig. 7. Pareto-optimal fronts of test system 1 with the maximum $I_{H}$ value obtained by IRM-MEDA and NNIA.\n[IMAGE5]  \nFig. 8. Pareto-optimal fronts of test system 2 with the maximum $I_{H}$ value obtained by IRM-MEDA and RM-MEDA.\n[IMAGE6]  \nFig. 9. Pareto-optimal fronts of test system 2 with the value obtained by IRM-MEDA and NINA.\n[IMAGE7]  \nFig. 10. Pareto-optimal fronts of test system 2 with the value obtained by IRMMEDA and NSGA-II.  \nTable 1\nThe average $I_{H}$ value obtained by each technique in ten runs of test system 1 .\nTable 2\nThe average $I_{H}$ value obtained by each technique in ten runs of test system 2 .\n[IMAGE8]  \nFig. 11. Box plot of the $I_{H}$ values obtained by IRM-MEDA, RM-MEDA, NNIA and NSGA-II of test system 1.\nis listed in Tables 1 and 2. The box plot of this measure value is also given in Figs. 11 and 12.  \nIt can be learned from Tables 1 and 2 that the objective space size dominated by IRM-MEDA is larger than other techniques for both test system 1 and test system 2. And NSGA-II performs worst in this indictor.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:33",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "In which practical scenarios does the hybrid Q-EDA model, utilizing the LRAV rule for job encoding, outperform standalone QGA and GA when applied to flowshop scheduling problems?",
      "topics": [
        "genetic"
      ],
      "answer": "The hybrid Q-EDA model, employing the LRAV rule, demonstrates superior performance compared to standalone QGA and GA, particularly in medium-sized flowshop scheduling problems where the number of jobs (n) is between 5 and 20, and the number of machines (m) is between 5 and 10. This advantage is evident in achieving lower average percentage relative deviation (APRD) values, indicating solutions closer to the optimal or best-known values. Furthermore, the hybrid Q-EDA exhibits faster convergence, reaching optimal or near-optimal solutions within fewer iterations, as illustrated by the fitness function's progression against the number of iterations.",
      "chunk_id": 967,
      "paper_id": "An estimation of distribution algorithm (EDA) variant with QGA for Flowshop scheduling problem",
      "paper_title": "An Estimation of Distribution Algorithm (EDA) Variant with QGA for Flowshop Scheduling Problem",
      "paper_year": "2014",
      "chunk_content": "To evaluate the performance of the proposed Q-EDA algorithm, extensive numerical simulations have been carried out on standard benchmarks ${ }^{[15]}$. The percentage relative deviation (PRD) of a best solution value Xi found by an algorithm from the optimal solution or the best known value Xbest can be calculated as $A R P D=\\frac{\\sum_{i=1}^{n}\\left(\\frac{\\left(X_{i}-X_{\\text {best }}\\right) \\cdot 100}{X_{\\text {best }}}\\right)}{n}$, where R is the replication of each algorithm for a particular instances and in this study $\\mathrm{R}=10$ has been considered. The APRD is the average PRD values for a set of instances. The algorithms were coded in MATLAB programming language. All experiments were run on a desktop PC with Intel Pentium IV, Windows XP, 2 GHz processor and 1 GB memory. In this article medium size problems has been tested up to i.e. $\\mathrm{n}=5,10,20 \\mathrm{~m}=5,10$. Comparison has also made between the best known results of $\\mathrm{NEH}^{[2]}, \\mathrm{GA}^{[3]}$, a similar EDA as developed in study of ${ }^{[13]}$, QGA ${ }^{[14]}$ and proposed Q-EDA.  \nIn our proposed algorithm, a maximum population size of 40 has been considered. The length of Q-bit will equal to the number of jobs because we are using LRAV rule for encoding of jobs instead of random keys. QGA and EDA together has produced better results as compare to the results produced stand alone. The hybrid QEDA in their standard  \nformat has shown better performance as compared to their contemporary approaches. In fig.2, ave. percentage deviation in terms makespan is shown. While in fig.3, the fitness function shown against number of iterations. Both figures are showing the performance of proposed algorithm which is better than others. In table. $2 \\& 3$, numerical results from simulations are shown for different benchmarks i.e. Carl......Car8 and Taillard. The results are compared previous published algorithms like NEH, GA and hybrid format like QGA. The comparison has shown the capability and effectiveness of proposed algorithm in terms of solution quality, convergence and computationally efficient.\n[IMAGE_0]  \nFigure 2: Comparison between Results and Fitness Functions of GA, QGA and Hybrid Q-EDA  \nTable 1 Comparison of simulation results for Carlier Instances  \nTable 2: Ave. results of different instances for GA, QGA and Q-EDA\nIn this paper we have investigated the behavior of standard versions of evolutionary algorithms. All these evolutionary algorithms have been implemented in their standard form. The QGA and EDA has probabilistic in nature and they can exploit and explore search space and keep directed themselves towards promising solution space. The results have shown that it can be improved more if we used their hybrid forms like Hybrid Quantum Genetic Algorithm  \n(HQGA) and integrated with mixed variants of EDA along with the job encoding in terms of angles. This kind of job encoding can reduce the complexity of algorithm and also requires less computation time and effort. The improvement of Q-EDA has validated that if it implemented on large size problems along with hybrid form of QGA, it can produced more better results. Furthermore, if standard versions of other meta-heuristics are integrated instead adding other strategies, they still be able produce better results and remain efficient.",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:35",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the genetic algorithm (GA) as a heuristic algorithm for estimating parameters in solar cell models, what general mathematical challenges arise from the non-linearity of the current and voltage characteristics, and how might this impact the algorithm's ability to find satisfactory results?",
      "topics": [
        "genetic"
      ],
      "answer": "The non-linearity of the current and voltage characteristics in solar cell models presents a challenge for the genetic algorithm (GA). The presence of non-linearity can lead to unsatisfactory results when using heuristic algorithms to estimate the PV single diode model, double diode model and fuel cell model. This is because the mathematical models may not accurately predict the voltage, current, and power values due to variations in temperature levels.",
      "chunk_id": 9044,
      "paper_id": "Optimal model parameter estimation of solar and fuel cells using improved estimation of distribution algorithm",
      "paper_title": "Optimal model parameter estimation of solar and fuel cells using improved estimation of distribution algorithm",
      "paper_year": "2021",
      "chunk_content": "The keyphrase 'Green Energy Technology' attracted many world-wide scientists, researchers to develop/create electricity and fuel from the natural resources without pollution. Stringent environmental legislation and energy incentives were introduced around the world to encourage development and use of renewable energy resources, such as wind, solar energy, fuel cell, wave as well as other energy resources, to meet demands for sustainable energy production and to sustain environment [1]. Fuel cells and solar panels attracted a lot of attraction among multiple techniques to produce effective and clean electricity [2]. One of the most common fuel cell with many preferred properties, such as low working temperature, low noise, zero emission, increased lifespan, high power density, is a Polymer Electrolyte Membrane (PEM) [3,4].  \n[^0]For ion exchange purpose, proton is used for conduction; hence polymer electrolyte membrane fuel cell is also called as proton exchange membrane fuel cell. The solar cell (photovoltaic cell) transforms light energy into electric energy. Photovoltaic (PV) effect is called the method of transforming light energy to electrical energy [5]. The datasheets of solar cell provided by the manufacturer lacks several essential parameters required in mathematical modelling of the device [6]. Moreover the current and the voltage characteristics are highly nonlinear [7]. The accurate measurement of model parameters is of key importance in the modeling of PV systems $[8,9,10]$.  \nVarious analytical and optimization strategies are employed to estimate solar cell and fuel cell model parameters. Analytical model uses mathematical equations and the equations are solved to estimate the model parameters, based on the data sheet provided by the manufacturer. Since there is much variation in temperature levels, the mathematical models are not able to predict the accurate voltage, current and power values. This problem has been solved using the meta-heuristic algorithms (MHAs) during the past years. The existence of non-linearity in the problem brought unsatisfactory results. Different heuristic algorithms used to estimate the PV single diode model, double diode model and fuel cell model are genetic algorithm (GA), particle swarm optimization (PSO), differential evolution (DE), artificial bee colony (ABC), Global-best Harmony Search algorithm (GHS), Regenerate genetic algorithm (GHA), teaching-learning based optimization (TLBO),  \n[^1]\n[^0]:     Corresponding author at: Department of EEE, Karunya Institute of Technology and Sciences, Coimbatore 641114, India.\nE-mail addresses: benin@karunya.edu (B. Pratap Chandran), immanuel@karunya.edu (A. Immanuel Selvakumar), shinelet@ gmail.com (G. Shine Let), sathiyan@ karunya.edu (S. Paul Sathiyan).\nPeer review under responsibility of Ain Shams University.  \n[^1]:    https://doi.org/10.1016/j.asej.2020.07.034\n2090-4479/_ 2020 The Authors. Published by Elsevier B.V. on behalf of Faculty of Engineering, Ain Shams University.\nThis is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:37",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Considering the population encoding strategy for the QiSNN framework, how does the number of receptive fields affect the resolution for distinguishing between different input variables when using 20 receptive fields for spiral data versus five receptive fields for a hypercube?",
      "topics": [
        "search"
      ],
      "answer": "The number of receptive fields in the population encoding affects the resolution for distinguishing between different input variables. Using 20 receptive fields for the spiral data provides a higher resolution compared to using only five receptive fields for the hypercube data. This difference in resolution impacts the ability of the QiSNN framework to accurately classify samples in the testing dataset, which is determined by the ratio between correctly classified samples and the total number of testing samples after shuffling and dividing the dataset using a 0.75 ratio.",
      "chunk_id": 6710,
      "paper_id": "Integrated feature and parameter optimization for an evolving spiking neural network  Exploring heterogeneous probabilistic models",
      "paper_title": "Integrated feature and parameter optimization for an evolving spiking neural network: Exploring heterogeneous probabilistic models",
      "paper_year": "2009",
      "chunk_content": "the proportion factor $c_{l}$. Since both problems contain two classes, six parameters are involved in the QiSNN framework used here. In terms of the population encoding we found especially that the number of receptive fields needs careful consideration, since it affects the resolution for distinguishing between different input variables. After some preliminary experiments we decided for 20 receptive fields in case of the spiral data and five receptive fields for the hypercube. The Gaussian centers were uniformly distributed over the search interval and the variance was set to $\\beta=1.5$.  \nIn order to guarantee statistical relevance, 30 independent runs for each investigated classification method were performed. In every generation all samples of the dataset were randomly shuffled and divided into training and testing samples, according to a ratio of 0.75 . For the computation of the classification error we determined the ratio between correctly classified samples and the total number of testing samples.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:39",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model for the Agent Routing Problem in Multi-Point Dynamic Task (ARP-MPDT), and how are the probability models updated based on the selected individuals?",
      "topics": [
        "selection"
      ],
      "answer": "The EDA model execution for ARP-MPDT involves the following steps: 1) Initialize a population of solutions; 2) Calculate the fitness value of each individual and select individuals with better fitness into a dominant group; 3) Update the probability model using the dominant group as samples; 4) Sample the probability model to generate new solutions; 5) Check the termination condition. The probability models, specifically NHM and EHM, are updated using a proportion of individuals selected by truncation sorting from the new population. The initial $G_{\\text {NHM }}$ is related to the state growth index of each task and initialized as $G_{\\text {NHM }}=\\left[G_{\\text {NHM }}(i, j)\\right]_{\\text {min }}=\\left[\\begin{array}{cccc}\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\ \\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n}\\end{array}\\right]$.",
      "chunk_id": 11312,
      "paper_id": "A Multi-Model Estimation of Distribution Algorithm for Agent Routing Problem in Multi-Point Dynamic Task",
      "paper_title": "A Multi-model Estimation of Distribution Algorithm for Agent Routing Problem in Multi-point Dynamic Task",
      "paper_year": "2018",
      "chunk_content": "According to the aforementioned assumptions, because the agent is not allowed to go to other task points before completing its current task, the feasible solution of ARP-MPDT can be expressed by the access sequence of task points. In the following, the coding scheme will be explained by an example including 6 task points:  \nThe access sequence of all task points is denoted as follows:  \n$$\n\\mathbf{z}=\\{1,2,4,6,3,5\\}\n$$  \nThe value of each variable in $T$ can be calculated according to the following formulas:  \n$$\n\\begin{aligned}\n& t_{z(1)}^{r}=0 \\\\\n& t_{z(i)}^{l}=t_{z(i)}^{r}+\\Delta t_{z(i)} \\\\\n& t_{z(i+1)}^{r}=t_{z(i)}^{l}+\\frac{D_{z(i), z(i+1)}}{V}\n\\end{aligned}\n$$  \nIn this way, the value of the objective function can be calculated for each solution encoded by an access sequence of all task points.\nEDA describes the distribution information of the superior solutions of the problem by establishing probability models ${ }^{[9]}$, and the probability model is sampled to get a new generation of population. EDA relies on the loop of probabilistic modeling and sampling to discover the best solutions. The basic algorithm procedure is shown as the following ${ }^{[10]}$ :\nStep 1: Initialize a population of solutions(individuals);\nStep 2: Calculate fitness value of every individual, and select some individuals which has better fitness value into the dominant group;\nStep 3: Use the dominant group as samples to update the probability model;\nStep 4: Sample the probability model to generate new solutions;\nStep 5: Judge the termination condition. If the termination condition is satisfied, the algorithm stops and the result is output; otherwise, go to step 2.\nA graph for ARP-MPDT can be built by taking the task points as nodes and using the distance between any two points as the weight of the arc connecting them. It is obvious that the quality of solutions to ARP-MPDT relies on both the states of nodes and the weights of arcs in the graph. In this sense, neither NHM nor EHM can solely adapt to ARP-MPDT in general cases.  \nWhen the execution time takes up most of the total time, the agent's traveling time is not a primary element. It is better to solve the ARP-MPDT with EDA employing NHM, because the execution time mainly depends on the property of task points(nodes). On the other hand, if the traveling time takes up most of the total time, it is better to solve the ARP-MPDT with EDA employing EHM. Both NHM and EHM are adopted in the proposed algorithm. However, it is hard to determine which probability model to use without any prior knowledge. A coefficient is designed to adjust dynamically the selection proportion of NHM to EHM in generating new individuals.  \nBecause of the difference between the two models based on NHM or EHM, the sampling strategies and the updating strategies of probability models are also different. A certain proportion of the individuals in new population will be selected as samples by truncation sorting to update both EHM and NHM.  \nThe flowchart of the proposed algorithm for ARP-MPDT is illustrated in Fig.1and the notations are explained as Table1.  \nTable 1: Notations of the proposed algorithm\n1) Initialization  \nIn this paper, the initial $G_{\\text {NHM }}$ is related to the state growth index of each task. It can be initialized as follows:  \n$$\nG_{\\text {NHM }}=\\left[G_{\\text {NHM }}(i, j)\\right]_{\\text {min }}=\\left[\\begin{array}{cccc}\n\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\\n\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n}\n\\end{array}\\right]\n$$  \n[IMAGE0]  \nFig.1: Flowchart of the proposed algorithm",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:41",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is a candidate analog circuit topology encoded for processing by the Estimation of Distribution Algorithm (EDA) within the search space?",
      "topics": [
        "search"
      ],
      "answer": "The topology of an analog RLC circuit is encoded using a binary characteristic vector 'c' of length '3n_adm', where 'n_adm' represents the number of admittances. Each bit in the vector 'c' corresponds to an edge of the complete multigraph G_c, indicating whether the corresponding edge (and thus the corresponding component) is included in the subgraph G_s, which represents the circuit topology.",
      "chunk_id": 4518,
      "paper_id": "Design of Passive Analog Electronic Circuits using Hybrid Modified UMDA Algorithm",
      "paper_title": "Design of Passive Analog Electronic Circuits using Hybrid Modified UMDA Algorithm",
      "paper_year": "2015",
      "chunk_content": "The used encoding method is based on the idea of fully connected admittance network. For chosen number of the nodes the fully connected admittance network is formed by connecting the admittances between all combinations of the nodes of the network. The number of the admittances of the fully connected admittance network with $n_{n}$ nodes can be calculated according to (3)  \n$$\nn_{\\text {adm }}=\\binom{n_{n}}{2}=\\frac{n_{n}!}{2!\\left(n_{n}-2\\right)!}\n$$  \nEvery single admittance of the fully connected admittance network can be replaced by resistor, capacitor, inductor or their parallel combination. Therefore the largest circuit which can be for chosen number of the nodes $n_{n}$ obtained is the circuit where every single admittance of the fully connected admittance network is replaced by parallel combination of resistor, capacitor and inductor. In this paper such circuit is denoted as expanded fully connected admittance network and includes $3 n_{\\text {adm }}$ components. Example of the expanded fully connected admittance network is presented in Fig. 10.\n[IMAGE7]  \nFig. 10. Expanded fully connected admittance network $N_{c}\\left(n_{c}=\\right.$ 4) [1].  \nThe expanded fully connected admittance network can be represented using complete multigraph with three multiple edges at the most [10]. Complete multigraph $G_{c}$ corresponding to expanded fully connected admittance network  \n$N_{c}$ is presented in Fig. 11. Nodes $n_{0}$ to $n_{3}$ of network $N_{c}$ correspond to vertices $v_{0}$ to $v_{3}$ of complete multigraph $G_{c}$. Branches of network $N_{c}$ correspond to edges of complete multigraph $G_{c}$. For example edges $e_{5}(1), e_{5}(2), e_{5}(3)$ (on complete multigraph $G_{c}$ ) correspond to components $L_{5}, R_{5}, C_{5}$ (in network $N_{c}$ ) respectively. Then the problem of searching of the topology of the analog RLC circuits can be defined as searching of subgraph $G_{s}$ on complete multigraph $G_{c}[10]$.\n[IMAGE8]  \nFig. 11. Complete multigraph $G_{c}$ representing expanded fully connected admittance network $N_{c}[1]$.  \nSubgraph $G_{s}$ can be encoded using binary characteristic vector $c$ of length $3 n_{\\text {adm }}$. Every single bit of characteristic vector $c$ represents including or not including of the corresponding edge of the complete multigraph $G_{c}$ in subgraph $G_{s}$. For example complete multigraph $G_{c}$ is encoded using characteristic vector $c$ of length 18 bits where $c(i)=1$ for $i \\in\\{1,2, \\ldots, 18\\}$. Example of subgraph $G_{s}$, corresponding analog circuit and its characteristic vector $c$ are presented in Fig. 12.\n[IMAGE9]  \nFig. 12. a) Example of subgraph $G_{s}$ b) analog circuit corresponding to $G_{s}$ c) characteristic vector $c$ of $G_{s}[1]$.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:44",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the EDA-GA hybrid algorithm compared to standard EDA and GA approaches in the context of task scheduling?",
      "topics": [
        "crossover"
      ],
      "answer": "The EDA-GA hybrid algorithm demonstrates a reduction in task completion time, improved load balancing as measured by higher $DBL$ values, and a higher fitness value ($GValue$) compared to standard EDA and GA. This is attributed to the probability model's ability to find feasible solutions and the crossover and mutation operations preventing the algorithm from converging to a local optimum.",
      "chunk_id": 8246,
      "paper_id": "An EDA-GA Hybrid Algorithm for Multi-Objective Task Scheduling in Cloud Computing",
      "paper_title": "An EDA-GA Hybrid Algorithm for Multi-Objective Task Scheduling in Cloud Computing",
      "paper_year": "2019",
      "chunk_content": "1) EXPERIMENT 1  \nTo verify the superiority of the proposed EDA-GA hybrid algorithm, we compare it with EDA and GA using the same\n[IMAGE4]  \nFIGURE 5. The influence trend of $p$.\n[IMAGE5]  \nFIGURE 6. The influence trend of $\\lambda$.\nparameter settings as described in the previous section. The experimental testing is performed in three different instances:  \nInstance 1: A few small tasks along with many large tasks;\nInstance 2: A few large tasks along with many small tasks;\nInstance 3: The sizes of tasks are randomly determined.\nWe choose 1000 as the number of tasks and 10 as the number of virtual machines. These values are fixed throughout the three instances. The results and analysis focus on three aspects: task completion time, load balancing degree and fitness value.\nA. Test of the task completion time: CompleteTime  \nAs shown in Figs. 7 - 9, EDA-GA performs better in each instance in terms of task completion time. In the three instances, EDA-GA has an average reduction of $3.2 \\%$ and $15.1 \\%$ compared to EDA and GA, respectively.\nB. Test of the load balancing: $D B L$  \nThe results in Figs. 10 - 12 show that EDA-GA has higher $D B L$ values than the other two algorithms. Compared with EDA and GA, EDA-GA has an average increase of $7.6 \\%$ and $11.7 \\%$, which means that EDA-GA has advantages in terms of load balancing.\nC. Test of the fitness value: GValue  \nAs shown in Figs. 13 - 15, the fitness value of EDA-GA is the highest among the three algorithms, and it is $5.4 \\%$ and  \n[IMAGE6]  \nFIGURE 7. CompleteTime of instance 1.\n[IMAGE7]  \nFIGURE 8. CompleteTime of instance 2.\n[IMAGE8]  \nFIGURE 9. CompleteTime of instance 3.\n9.1\\% higher than the other two algorithms. This result is more in line with the goal of this paper, which is to find a trade-off between reducing task completion time and improving load balancing ability.\n[IMAGE9]  \nFIGURE 10. DBL of instance 1.\n[IMAGE10]  \nFIGURE 11. DBL of instance 2.\n[IMAGE11]  \nFIGURE 12. DBL of instance 3.  \nIn conclusion, the experimental results show that the EDA-GA hybrid algorithm has a lower task completion time, more balanced load and higher fitness value than the other two algorithms under different instances. The reason mainly lies in the fact that the sampling mechanism and probability  \n[IMAGE12]  \nFIGURE 13. GValue of instance 1.\n[IMAGE13]  \nFIGURE 14. GValue of instance 2.\n[IMAGE14]  \nFIGURE 15. GValue of instance 3.\nmodel contribute to finding feasible and excellent solutions quickly. Moreover, the crossover and mutation operations expand the range of the solutions to prevent the algorithm from falling into a local optimum. Based on the above",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:46",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the Markov Network Estimation of Distribution Algorithm (MN-EDA) using Kikuchi approximations differ from that of Bayesian network based EDAs in estimating the distribution of selected solutions?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Kikuchi approximation",
        "Markov Network Estimation of Distribution Algorithm",
        "Bayesian networks",
        "Gibbs Sampling",
        "probability approximation"
      ],
      "answer": "The Markov Network Estimation of Distribution Algorithm (MN-EDA) employs Kikuchi approximations to estimate the distribution, whereas Bayesian network based EDAs use traditional methods of probability approximation. MN-EDA also uses Gibbs Sampling (GS) to generate new points. The key difference lies in the class of factorizations that can be obtained, with MN-EDA aiming to learn a more general class of probability factorizations by combining the Kikuchi approximation, a probability approximation procedure, with a novel approach for finding graph decompositions, potentially allowing MN-EDA to outperform other EDAs, especially in the optimization of functions with strong interactions among their variables.",
      "chunk_id": 12969,
      "paper_id": "Estimation of Distribution Algorithms with Kikuchi Approximations",
      "paper_title": "Estimation of distribution algorithms with Kikuchi approximations",
      "paper_year": "2005",
      "chunk_content": "Roberto Santanarsantana@si.ehu.esInstitute of Cybernetics, Mathematics, and Physics,Calle 15, e/ C y D, Vedado, Cp-10400, Havana, Cuba\nThe question of finding feasible ways for estimating probability distributions is one of the main challenges for Estimation of Distribution Algorithms (EDAs). To estimate the distribution of the selected solutions, EDAs use factorizations constructed according to graphical models. The class of factorizations that can be obtained from these probability models is highly constrained. Expanding the class of factorizations that could be employed for probability approximation is a necessary step for the conception of more robust EDAs. In this paper we introduce a method for learning a more general class of probability factorizations. The method combines a reformulation of a probability approximation procedure known in statistical physics as the Kikuchi approximation of energy, with a novel approach for finding graph decompositions. We present the Markov Network Estimation of Distribution Algorithm (MN-EDA), an EDA that uses Kikuchi approximations to estimate the distribution, and Gibbs Sampling (GS) to generate new points. A systematic empirical evaluation of MN-EDA is done in comparison with different Bayesian network based EDAs. From our experiments we conclude that the algorithm can outperform other EDAs that use traditional methods of probability approximation in the optimization of functions with strong interactions among their variables.",
      "question_type": "relationship",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:48",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within a multi-objective optimization framework, how should practitioners select cluster leaders using the nearest-neighbor heuristic?",
      "topics": [
        "optimization"
      ],
      "answer": "To select $k-m$ cluster leaders, the first leader is chosen as the solution with the maximum value for a randomly chosen objective. For remaining solutions, the nearest-neighbor distance is computed to the first leader, and the most distant solution becomes the next leader. Distances for remaining solutions are updated; if the distance to the new leader is smaller than the stored nearest-neighbor distance, the stored distance is updated. This is repeated until all $k-m$ leaders are selected.",
      "chunk_id": 727,
      "paper_id": "A novel population-based multi-objective CMA-ES and the impact of different constraint handling techniques",
      "paper_title": "A Novel Population-based Multi-Objective CMA-ES and the Impact of Different Constraint Handling Techniques",
      "paper_year": "2014",
      "chunk_content": "A general framework for extending population-based algorithms from single- to multi-objective optimization was introduced in [6]. An overview of the multi-objective optimization framework is depicted in Figure 1. Next, a description of each step of the framework is given.\n[IMAGE0]  \nFigure 1: Flowchart of the multi-objective optimization framework.\nGiven a population of size $n,\\lfloor\\tau n\\rfloor\\left(\\tau \\in\\left[\\frac{1}{n}, 1\\right]\\right)$ solutions with the lowest domination ranks are selected. From the rank that crosses the boundary of $\\lfloor\\tau n\\rfloor$ solutions a subset must be chosen. For this, the same nearest-neighbor heuristic is used as for selecting cluster leaders (see below).\nA nearest-neighbor heuristic is used to select $k-m$ cluster leaders, that are spread as well as possible, from the selection set. The first leader is chosen as a solution with a maximum value for a randomly chosen objective. For all  \nremaining solutions, the nearest-neighbor distance is computed to the first leader and the most distant solution is chosen as the next leader. The distances for the remaining solutions are updated by checking whether the distance to the new leader is smaller than the currently stored nearestneighbor distance. This procedure is repeated until all the necessary cluster leaders are selected.  \nNext, the distance from each solution in the selection set to the cluster leaders is computed. These leaders serve as initial cluster centroids in the subsequent application of the $k$-means clustering algorithm. After running $k$-means clustering, for each cluster, the $c$ closest solutions are to the final cluster centroid assigned to it, ensuring that each cluster consists of exactly $c$ solutions.  \nBecause the final assignment is done independently for each cluster, some solutions may be assigned to multiple clusters whereas other solutions may not be assigned at all. The probability of this happening can be reduced by increasing the probability that the clusters will overlap by setting $c>\\frac{1}{k}\\lfloor\\tau n\\rfloor$. Specifically, we use $c=\\frac{k}{k}\\lfloor\\tau n\\rfloor$ as proposed in [6], resulting in substantial expected overlap between neighboring clusters. This increases the expected density in the usual void between the boundaries of clusters in the objective space, thereby increasing the probability of finding a good, uniform spread of solutions faster.  \nTo ensure that spatial separation of the search bias is obtained in the objective space, clustering is performed on the basis of objective values. Specifically, the distances are based on normalized objective values to remove the influence of differently scaled objectives. To this end, first the minimum $f_{i}^{\\min }$ and maximum $f_{i}^{\\max }$ values for each objective $i$ are computed from all selected solutions. A point in objective space $f(\\boldsymbol{x})$ is then scaled linearly to the observed ranges, i.e. FORMULA_42.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:49",
      "generation_style": "practical_application"
    },
    {
      "question": "How does the described Bayesian Optimization Algorithm (BOA) address the challenge of potentially poor initial population distributions, and what is the trade-off between solution quality and computational cost in this approach?",
      "topics": [
        "design"
      ],
      "answer": "The described BOA addresses the challenge of poor initial population distributions by suggesting an increase in population size to improve the distribution of good solutions. However, this approach presents a trade-off because it increases the computational cost, specifically the time required for evaluating all individuals in the population and offspring. The algorithm also introduces mutation to explore the search space beyond the distribution of good solutions, aiming to avoid being trapped in local optima. This mutation step is similar to that used in Genetic Algorithms (GA), Population Based Incremental Learning (PBIL), and Compact Genetic Algorithm (CGA).",
      "chunk_id": 5409,
      "paper_id": "Modified Bayesian optimization algorithm for EMC complex system design",
      "paper_title": "Modified Bayesian Optimization Algorithm for EMC Complex System Design",
      "paper_year": "2012",
      "chunk_content": "Once the structure and parameters of BN have been learned, new offspring will be generated by sampling the learned network. The procedure proceeds in two steps: ordering nodes and sampling variable according to the order.  \nIn the first step, an order of nodes, where each node is preceded by it parents, is computed. The purpose of this order is to generate variable in a certain sequence so that the value of parents of one node are generated prior to the generation of the node itself. The second step samples all variables according to the computed ordering. Following the ancestral ordering, given values of parents of a variable, the distribution of this variable is computed by the corresponding conditional probability, and new value is generated according to this distribution.\nAs described above, BOA performance greatly depends on distribution of current good solutions. However, initial population for BOA is randomly generated; there would be some cases when all best solutions would not provide good enough distribution about problem, thus the algorithm hardly converges. To overcome this difficulty, one possibility is to increase the population size; therefore it will increase the quality of distribution of good solution. However, this solution will be time consuming, i.e. evaluating all population and offspring. In this paper, we propose a new approach by adding mutation to traditional BOA.  \nBy adding mutation, some individual will be used to discover space out of distribution of good ones; therefore, the algorithm will avoid being trapped at local optimum. This is similar to Genetic Algorithms (GA) [5], Population Based Incremental Learning (PBIL) [6], and Compact Genetic Algorithm (CGA) [7], which use mutation as one of most important operator for exploring problem space. However, in proposed algorithm, we use Bayesian Network to represent probability model and generate new offspring. Moreover, we work with variable vector, which is more preferred for realvariable problem as microwave, instead of probability vector as PBIL and CGA. In our work, we implement BOA with tournament selection and individual mutation for design microwave filters.\nIn this paper, we present result of modified BOA for Onemax problem as mathematical test function and then apply  \nfor filter synthesis. For all test problems, 30 independent runs are performed and the results showed here are averaged values.\nOnemax problem is defined as sum of bits in the input binary string. The optimal solution of Onemax is the string of all ones.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:51",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the expected runtime of classical EAs compare to the UMDA when optimizing the DeceptiveLeadingBlocks (DLB) problem, based on the provided information?",
      "topics": [
        "genetic"
      ],
      "answer": "Classical EAs are stated to optimize the DeceptiveLeadingBlocks (DLB) problem in O(n^3) expected runtime. The UMDA, under parameter settings that avoid genetic drift, can optimize DLB with high probability in a specified number of fitness evaluations represented by FORMULA_76, although the exact expression for FORMULA_76 is not provided.",
      "chunk_id": 3915,
      "paper_id": "The Competing Genes Evolutionary Algorithm Avoiding Genetic Drift Through Competition Local Search and Majority Voting",
      "paper_title": "The Competing Genes Evolutionary Algorithm: Avoiding Genetic Drift Through Competition, Local Search, and Majority Voting",
      "paper_year": "2023",
      "chunk_content": "1) OneMax: The generalized $\\operatorname{OneMax}_{z}(x)$ function, for some fixed target string $z \\in\\{0,1\\}^{n}$, tests the performance of an EA as a hill climber [25] by assigning to $x$ the number of positions where $x$ and $z$ agree. Formally  \n$$\n\\operatorname{OneMax}_{z}(x)=\\left|\\left\\{i \\in[n] \\mid x_{i}=z_{i}\\right\\}\\right|\n$$  \nONEMAX is a member of the class of generalized MONOTONE functions.  \nDefinition 1: A function $f:\\{0,1\\}^{n} \\rightarrow \\mathbb{R}$ is monotone with respect to $z \\in\\{0,1\\}^{n}$ if for all $x, y \\in\\{0,1\\}^{n}$ where $\\left\\{i \\in[n] \\mid x_{i}=z_{i}\\right\\} \\subset\\left\\{i \\in[n] \\mid y_{i}=z_{i}\\right\\}$, then $f(x)<f(y)$.\n2) LeadingOnes: The generalized LEADINGONES function tests the ability of an EA to cope with dependencies among variables [25] by applying a permutation $\\sigma$ to both $x$ and a target string $z$ and counting the number of positions where the rearrangements agree until the first disagreement. Formally  \n$$\n\\begin{aligned}\n& \\text { LEADINGONES }_{z, \\sigma}(x) \\\\\n& \\quad=\\max \\left\\{i \\in\\{0, \\ldots, n\\} \\mid \\forall j \\in[i]: x_{\\sigma(j)}=z_{\\sigma(j)}\\right\\}\n\\end{aligned}\n$$  \nFor our analysis, we consider the instance of generalized LEADINGONES with the identity permutation and an all-ones target string. This instance counts the number of ones until the first zero in a bit string. The performance of the cgEA on this instance generalizes to the whole class because the cgEA is unbiased as it neither discriminates between the positions nor differentiates between the bits 1 and 0 . The instance we analyze is  \n$$\n\\operatorname{LEADINGONES}(x)=\\sum_{i=1}^{n} \\prod_{j=1}^{i} x_{j}\n$$  \nDoerr and Krejca [23] summarized the expected runtime of various EAs on the OneMax and LeadingOnes functions. They note that many of the algorithms have an expected runtime of $\\Theta(n \\ln n)$ on OneMax and $\\mathrm{O}\\left(n^{2}\\right)$ on LEADINGONES for optimal parameter settings.\n3) DeceptiveLeadingBlocks: Lehre and Nguyen [11] introduced the DeceptiveLeadingBlocks (DLB) problem as a deceptive version of LEADINGONES to study the behavior of the UMDA in the presence of deception and epistasis. The function takes in a bitstring $x \\in\\{0,1\\}^{n}$, where $n$ is an even positive integer, and pairs $x_{2 i-1}$ and $x_{2 i}$ for all $i \\in[n / 2]$ to form $n / 2$ blocks. The active block is the leftmost block whose value is not 11 . Suppose this is the $(k+1)$ th block numbered from the left, then the fitness of $x$ is $n$ if there is no active block, $2 k+1$ if the active block's value is 00 , and $2 k$ if 01 or 10. The function deceives an algorithm to prefer the locally optimal value of 00 for the active block even though the global optimum is the all-ones string. A formal definition of DLB is  \n$$\n\\operatorname{DLB}(x)= \\begin{cases}n, & \\text { if } \\phi(x)=\\frac{n}{2} \\\\ 2 \\phi(x)+1, & \\text { if } x_{2 \\phi(x)+1}+x_{2 \\phi(x)+2}=0 \\\\ 2 \\phi(x), & \\text { if } x_{2 \\phi(x)+1}+x_{2 \\phi(x)+2}=1\\end{cases}\n$$  \nwhere  \n$$\n\\phi(x)=\\sum_{i=1}^{\\frac{n}{2}} \\prod_{j=1}^{2 i} x_{j}\n$$  \nis the number of leading 11 s . Classical EAs optimize DLB in $\\mathrm{O}\\left(n^{3}\\right)$ expected runtime [11]. Doerr and Krejca [10] proved that the UMDA can optimize DLB with high probability in FORMULA_76 fitness evaluations if its parameters are in the regime that avoids genetic drift.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:53",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing the community detection algorithm using the CS objective function, what programming consideration should be given to the parameter 'r', and how does its value affect the algorithm's behavior on the Girvan-Newman benchmark?",
      "topics": [
        "benchmarks"
      ],
      "answer": "When implementing the community detection algorithm with the CS objective function, the 'r' parameter in the community score needs careful consideration. Increasing the value of 'r' will cause the algorithm to favor a larger number of communities. On the Girvan-Newman data set, which contains only four communities, a higher 'r' value can lead to unsatisfactory results because the algorithm will tend to increase the number of communities beyond the ground truth.",
      "chunk_id": 934,
      "paper_id": "An EDA-based Community Detection in Complex Networks",
      "paper_title": "An EDA-based Community Detection in Complex Networks",
      "paper_year": "2014",
      "chunk_content": "We use Girvan-Newman[12] and LFR[14] data set in order to assess our approach. Girvan-Newman(GN) data set contains  \n[^0]\n[^0]:    ${ }^{1}$ http://snap.stanford.edu/snap/index.html  \n128 nodes that fall into four communities, and each community contains 32 nodes and the expected degree of each node is 16 . Because of the easiness of the GN benchmark, we also use LFR benchmark that uses power law distributions of degree and community size. We generate undirected and unweighted LFR benchmark graphs without overlapping communities. The parameters of the LFR graphs are set as follows. The number of nodes $N=1000$, the average degree of nodes $k=20$, the maximum degree of nodes $\\max k=50$, the minus exponent for the degree sequence $t_{1}=2$ and the minus exponent for community size distribution $t_{2}=1$. We should determine a parameter named Mixing Coefficient $(\\mu)$ for generating these data sets. This parameter specifies the proportion of the number of links of a node to other communities and the degree of the node. The larger the mixing coefficient the more difficult to detect communities on the GN or LFR benchmarks.  \nFig. 4 shows the results of the algorithms on the GN data set. Our approach with Q objective function (Ours-Q) is better than the others when $\\mu \\leq 0.5$. Our approach with CS objective function (Ours-CS) does not show satisfactory results. The quality of Our-CS is sensitive to the $r$ parameter of the community score. By increasing the value of $r$, the algorithm will tend to increase the number of communities, while there are only four communities on GN data set. The effect of $r$ parameter is studied in [15].  \nAs can be seen in Fig. 5, our algorithms have better NMI than CNM algorithm on the LFR data set. Since the number of communities is high (more than thirty), Ours-CS has satisfactory results.\nWe use American Football, Political Books and Dolphins data sets. The American Football data set contains the games between some colleges, as compiled by Girvan and Newman. The communities of the nodes indicate to which conferences they belong [12]. This network contains 115 nodes and 616 links in 12 communities. On the political books data set, nodes represent 105 books about US politics sold by the online bookseller Amazon.com. The Links represent frequent copurchasing of the books by the same buyers. Nodes are divided into 3 communities that indicate whether books are liberal, neutral, or conservative. These divisions were assigned separately by Mark Newman [16]. The last real data set is Dolphins that contains a social network of frequent associations between 62 dolphins as compiled by Lusseau et al [17]. The nodes are divided into 2 communities.  \nFig. 6 shows the results of applying different algorithms to detect communities on three real data sets. Ours-Q is better than other algorithms on Dolphins and Political Books and is very close to the best algorithm (here GN) on American Football data set. Except Football data set, Ours-CS does not gain satisfactory NMI on other two data sets. Since the $r$ parameter in the community score objective function is set to 1.5 , again Ours-CS has a tendency to increase the number of communities. On the Football data set, which includes 12 communities Ours-CS has an excellent result and on the Political Book with three communities and on the Dolphins with two communities, Ours-CS does not have satisfactory results.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 11:59:55",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How are the probabilistic amplitudes, represented by \\(\\alpha\\) and \\(\\beta\\) in the Q-bit string of a Quantum Estimation Algorithm (QEA), mathematically constrained to ensure a valid quantum state?",
      "topics": [
        "optimization"
      ],
      "answer": "In a QEA, the probabilistic amplitudes \\(\\alpha_{i}\\) and \\(\\beta_{i}\\) within a Q-bit string representing a Q-gene must satisfy the condition \\(|\\alpha_{i}|^{2}+|\\beta_{i}|^{2}=1\\) for all \\(i\\) from 1 to \\(m\\), where \\(m\\) is the length of the Q-bit string. This constraint ensures that the sum of the probabilities of finding the Q-bit in state \"0\" (represented by \\(\\alpha\\)) and state \"1\" (represented by \\(\\beta\\)) equals 1, thus maintaining a valid probabilistic quantum state.",
      "chunk_id": 368,
      "paper_id": "A hybrid Quantum Estimation of Distribution Algorithm (Q-EDA) for Flow-Shop Scheduling",
      "paper_title": "A Hybrid Quantum Estimation of Distribution Algorithm (Q-EDA) for Flow-Shop Scheduling",
      "paper_year": "2013",
      "chunk_content": "The fundamental QEA was developed by the Han \\& Kim [35] almost a decade ago. They have successfully integrated and implemented the quantum-computational mechanism for a variety of combinatorial optimization problems i.e. Knapsack problem and other numerical optimization problems. The QGA has also implemented successfully in other engineering areas like electrical power system for steady state performance of control variables [6, 7]. The QEA had proved its robustness, efficiency and extremely flexible and easily integrated with other contemporary approaches like GA, PSO, and VNS etc. The first attempt to implement QEA for scheduling was made by Wang [8-10]. His initial results and shown the excellent leading edge over other EA approaches in terms of its small size of population, parallelism and better encounter with local optima trapping issue. Furthermore, QEA can explore and exploit the search space for global optima in incredible short span of time as compared to EA approaches.\nThe representation of QEA has based on a novel Q-bit gene, which is governed by the probabilistic rules. A Q-bit or Qgene can be found in state \" 1 \" or \" 0 \", or in superposition of both sates. A Q-bit or a Q-gene can be represented as Q-bit string of length $m$ as follow;  \n$$\nq=\\left[\\begin{array}{lll}\n\\alpha_{1} & \\alpha_{2} \\ldots \\alpha_{m} \\\\\n\\beta_{1} & \\beta_{2} \\ldots \\beta_{m}\n\\end{array}\\right]\n$$  \nWhere $\\alpha$ and $\\beta$ are complex numbers with specific probabilistic amplitude which satisfies the following condition,  \n$$\n\\left|\\alpha_{i}\\right|^{2}+\\left|\\beta_{i}\\right|^{2}=1, \\quad i=1,2, \\ldots \\ldots \\ldots \\ldots . m\n$$  \nIf, for example Q-bit system contains only two pairs of amplitudes as follows,  \n$$\nq=\\left[\\begin{array}{cc}\n-1 / \\sqrt{2} & 1 / 2 \\\\\n1 / \\sqrt{2} & \\sqrt{3 / 2}\n\\end{array}\\right]\n$$  \nThen the sates can be have the following probabilistic amplitudes like:  \n$$\n-\\frac{1}{2 \\sqrt{2}}|00\\rangle+\\frac{\\sqrt{3}}{2 \\sqrt{2}}|01\\rangle+\\frac{1}{2 \\sqrt{2}}|10\\rangle-\\frac{\\sqrt{3}}{2 \\sqrt{2}}|01\\rangle\n$$  \nThe above equation has representation of different states in terms of probabilities. Only two Q-bit systems can hold the information of four states like $|01\\rangle,|01\\rangle,|00\\rangle,|11\\rangle$ and have $1 / 8,3 / 8,1 / 8,3 / 8$ probabilities respectively. While in binary system minimum four strings would be required as (00), (01), (10), (11). As stated earlier, QEA has strong parallelism characteristic, which enable it to explore solution space while showing better convergence properties as compared to other E.A's. For problem solutions, the Q-bit has to be converted in binary with some suitable method and then converted Q-bit in binary can be used to solve the problem. The backbone operation of QEA is the updating of Quantum population comprised on Q-bits, which are initialized with constant value in beginning of algorithm. The following equation represents the operation rotation gate which dictates the updating of quantum population.  \n$$\n\\left[\\begin{array}{l}\n\\alpha_{i} \\\\\n\\beta_{i}\n\\end{array}\\right]=U\\left(\\theta_{i}\\right)\\left[\\begin{array}{l}\n\\alpha_{i} \\\\\n\\beta_{i}\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n\\cos (\\theta) & -\\sin \\left(\\theta_{i}\\right) \\\\\n1 / \\sqrt{2} & \\cos \\left(\\theta_{i}\\right)\n\\end{array}\\right]\\left[\\begin{array}{l}\n\\alpha_{i} \\\\\n\\beta_{i}\n\\end{array}\\right]\n$$  \nWhere $\\alpha^{\\prime}$ and $\\beta^{\\prime}$ are updated Q-bits of new population. Where $\\theta_{i}=s\\left(\\alpha_{i}, \\beta_{i}\\right) \\Delta \\theta_{i}$ represents the value of rotation angle and $s\\left(\\alpha_{i}\\right.$, $\\left.\\beta_{i}\\right)$ denotes rotation direction. The value of rotation angle plays an important role and has a very significant impact on the convergence of algorithm. Commonly, larger angles caused premature convergence and couldn't find optimal solution.\nThe main body of QEA is comprised on different parts named Initialization, Observation (conversion of Q-bit string to Binary string), evaluation and updating if Q-bit system. The descriptive procedure of QEA and EDA has shown below:",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 11:59:57",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically contrasting the proposed Markov-EDA with MIMIC?",
      "topics": [
        "mutation"
      ],
      "answer": "The primary objective is to implement a Markov-EDA that models the configuration of a variable \\(z^{n+1}\\) based on the preceding variable's configuration, as formalized in equation (7). This Markov-EDA, without variable permutation, differs from MIMIC, which focuses on identifying the optimal variable permutation to minimize pairwise entropy relative to the true distribution, despite both belonging to a chain topology.",
      "chunk_id": 10849,
      "paper_id": "An improved estimation of distribution algorithm for cloud computing resource scheduling",
      "paper_title": "An Improved Estimation of Distribution Algorithm for Cloud Computing Resource Scheduling",
      "paper_year": "2018",
      "chunk_content": "In this section, we elaborate the MCEDA proposed to tackle the problem investigated.\nThis paper adopts a 1-order Markov-EDA [12], [16] in which the configuration of the variable $z^{n+1}$ depends on the configuration of the previous variable, which can be formulized as equation (7). Note that, our proposed MCEDA without variables permutation is different from mutual information maximing input clustering (MIMIC) [18] whose main  \nAlgorithm 1 General Framework for EDAs  \n  \nidea is to choose the optimal permutation to produce the lowest pairwise entropy with respect to the true distribution, although, both of them belong to a chain topology. The pseudo code of the Markov-EDA is shown in Algorithm 1.  \nFORMULA_29",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 11:59:58",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, how does the algorithmic mechanism of migrating promising solutions in the many-tasking estimation distribution algorithm (MaT-EDA) leverage the optimal correspondence assisted affine transformation (OCAT) to alleviate the population demand on individual tasks?",
      "topics": [
        "optimization"
      ],
      "answer": "The many-tasking estimation distribution algorithm (MaT-EDA) addresses the population demand issue in conventional EDAs by explicitly migrating promising solutions from other tasks to the current task using the optimal correspondence assisted affine transformation (OCAT). OCAT is used to achieve proper intertask alignment by locating the optimal correspondences between training samples. This allows MaT-EDA to transfer solutions for distribution modeling among composite tasks, reducing the need for a large population on each task and facilitating more evolution generations to locate better solutions.",
      "chunk_id": 3425,
      "paper_id": "Aligning heterogeneous optimization problems with optimal correspondence assisted affine transformation for evolutionary multi-tasking",
      "paper_title": "Aligning heterogeneous optimization problems with optimal correspondence assisted affine transformation for evolutionary multi-tasking",
      "paper_year": "2023",
      "chunk_content": "In fact, the pairwise-learning-based intertask alignment problem is quite similar to the point set registration one [33-35], which also requires to search for the correct correspondences between two point sets and then conduct a space geometry transformation to register them. Inspired by the influential registration algorithm iterative closest point (ICP) [33], this proposes a novel pairwise-learning-based intertask alignment algorithm named optimal correspondence assisted affine transformation (OCAT). OCAT describes the relationship between any two involved tasks using affine transformation. It first constructs a mathematical model for the intertask alignment problem, and then theoretically deduces the model solution by iteratively rebuilding the correspondences between the transformed samples and deriving the new alignment affine transformation. Accordingly, the correspondences that enable the affine transformation to achieve maximum intertask alignment can be located finally. OCAT notices that for the given samples and their correspondences, there are generally infinite affine alignment transformations, but some of them may dramatically impair the knowledge contained in the task during the alignment process. Purposefully, it imposes a constraint on the transformation parameters according to the task domain space sizes and then derives a closed-form solution of affine transformation, ensuring a smooth knowledge transfer.  \nThis study finally develops an explicit many-tasking estimation distribution algorithm (MaT-EDA) by integrating OCAT with EDA. As model-based EAs, EDAs show impressive convergence speed over other EAs by using statistical learning methods to estimate the distribution of promising solutions [36-38]. However, conventional EDAs usually require a large population to supply enough samples for distribution modeling, which sharply limits their performance. On the other hand, a many-tasking optimization problem generally involves more than ten tasks. The population demand of each task can be alleviated by transferring the solutions for distribution modeling among the composite tasks. Following this idea, MaT-EDA explicitly migrates some  \nTable 1\nA list of the abbreviations in this paper.\npromising solutions from the other tasks to the current one through OCAT and then estimates the distribution model accordingly. As a result, it only requires a small-scale population on each task, facilitating more evolution generations to locate better solutions.  \nTo evaluate the effectiveness of OCAT and MaT-EDA, comprehensive simulation tests have been conducted on several multitasking and many-tasking optimization benchmark suites. The results indicate that OCAT can significantly enhance EMTO and also performs superior over some state-of-the-art intertask alignment algorithms. Moreover, MaT-EDA achieves very competitive many-tasking optimization performance. In summary, the main contributions of this study are as follows:\n(1) A novel method to locate the optimal correspondences between training samples is developed. It can help the pairwise-learning-based methods achieve proper intertask alignment.\n(2) A new derivation method for affine transformation is proposed. It generates an affine alignment transformation with small influence on the knowledge contained in the tasks during the alignment process.\n(3) An explicit many-tasking optimization framework is designed. It enables EDA to effectively solve many-tasking optimization problems effectively.\n(4) Empirical studies were conducted to investigate the performance of OCAT and MaT-EDA. A thorough analysis of the empirical results is also presented.  \nThe remainder of this paper proceeds as follows: Section 2 reviews the related works. Section 3 describes the proposed algorithm in detail. Section 4 reports experimental settings and results. Finally, Section 5 concludes this paper and discusses some future research directions. Table 1 lists all the abbreviations and their full names in this paper.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:00",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using the EDAspy Python package, how can practitioners access the code?",
      "topics": [
        "optimization"
      ],
      "answer": "Practitioners can access the code for implementing an Estimation of Distribution Algorithm by visiting the GitHub repository at https://github.com/ VicentePerezSoloviev/EDAspy. The package can also be downloaded from Pypi.",
      "chunk_id": 9525,
      "paper_id": "Quantum-Inspired Estimation Of Distribution Algorithm To Solve The Travelling Salesman Problem",
      "paper_title": "Quantum-Inspired Estimation Of Distribution Algorithm To Solve The Travelling Salesman Problem",
      "paper_year": "2021",
      "chunk_content": "The code will be uploaded to EDAspy Python package. The package can be found at https://github.com/ VicentePerezSoloviev/EDAspy and downloaded from Pypi.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:01",
      "generation_style": "practical_application"
    },
    {
      "question": "How does the Estimation of Distribution Algorithm (EDA), specifically the BUMDA mentioned, determine the \"optimal design\" of the four-bar linkage mechanism, and what mathematical property of the objective function guarantees that the resulting design minimizes the distance to the desired path?",
      "topics": [
        "design"
      ],
      "answer": "The Estimation of Distribution Algorithm (EDA) determines the \"optimal design\" by proposing configurations with different lengths and reference positions of the four-bar linkage mechanisms. The algorithm measures the distance between points in the actual path and points in the desired path for each configuration. The objective function value is defined as the sum of these distances. The EDA, specifically the BUMDA, aims to minimize this objective function. The mathematical property that guarantees the resulting design minimizes the distance to the desired path is the fact that the algorithm converges towards a configuration where the sum of distances, which is the objective function value, is minimized. The optimal design produces the minimum distance to the desired path, due to the minimization process inherent in the EDA's optimization strategy.",
      "chunk_id": 8904,
      "paper_id": "Automated Dimensional Synthesis of a Portable Sky Scanner for Measuring Light Pollution",
      "paper_title": "Automated Dimensional Synthesis of a Portable Sky Scanner for Measuring Light Pollution",
      "paper_year": "2021",
      "chunk_content": "Alejandra RiosIPN ESIME-TicomanCiudad de Mexico, Mexicoarioss1000@alumno.ipn.mx  \nEusebio E. HernandezIPN ESIME-TicomanCiudad de Mexico, Mexicoeuhernandezm@ipn.mx  \nHector LampharCONACYT-CENTROGEO ACQueretaro, Mexicohsolano@centrogeo.edu.mxS. Ivvan ValdezCONACYT-CENTROGEO ACQueretaro, Mexicosvaldez@centrogeo.edu.mx\nLight pollution is often measured by a photometric sensor network distributed in the area of interest. However, photometric sensors usually have a narrow view angle, making difficult to perform measurements at low elevation angles. Furthermore, short-term variations are not significant; hence, a low-cost solution is to displace a portable device, able to scan the sky in a range of azimuth and zenith angles, to different locations of interest. The device should be designed with the aim of characterizing the emission function from ground based light sources, which is decreasing in intensity with respect to the zenith. In this manuscript, we propose to find the dimensions of a fourbar linkage mechanism that best fits the scanning task via an optimization problem, solved with an estimation of distribution algorithm. The optimization algorithm proposes configurations with different lengths and reference positions of four-bar linkage mechanisms; then, it measures the distance between points in the actual path and points in the desired path for each configuration. The objective function value is the sum of such distances; thus, the optimal design produces the minimum distance to the desired path. This proposal for automated design reduces the working time and experience requirements of a human designer, and trial-and-error design intends, by determining adequate dimensions for the mechatronic system. A CAD model and a simulation demonstrate the design feasibility and the high accuracy of the resulting device.  \nIndex Terms-Dimensional synthesis, Optimization, BUMDA, Four-bar linkage mechanism, Automated design",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:04",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the global best position tracking in Particle Swarm Optimization (PSO) compare to tracking the best position among topological neighbors, in terms of guiding particle movement?",
      "topics": [
        "search"
      ],
      "answer": "In Particle Swarm Optimization (PSO), the velocity update equation \\(\\mathbf{v}_{\\mathbf{i}}(\\mathbf{t}+\\mathbf{1})=\\mathbf{v}_{\\mathbf{i}}(\\mathbf{t})+c_{1} \\phi_{1}\\left(\\mathbf{p}_{\\mathbf{i}}(\\mathbf{t})-\\mathbf{x}_{\\mathbf{i}}(\\mathbf{t})\\right)+c_{2} \\phi_{2}\\left(\\mathbf{p}_{\\mathbf{g}}(\\mathbf{t})-\\mathbf{x}_{\\mathbf{i}}(\\mathbf{t})\\right)\\) uses \\(\\mathbf{p}_{\\mathbf{g}}\\), the global best position among all particles, to influence a particle's new velocity. An alternative version of PSO uses the best position among a particle's topological neighbors instead of the global best, which changes how \\(\\mathbf{v}_{\\mathbf{i}}\\) is updated and thus how the particle's position \\(\\mathbf{x}_{\\mathbf{i}}\\) changes at each time step \\(t\\).",
      "chunk_id": 6368,
      "paper_id": "Estimation of distribution algorithm for optimization of neural networks for intrusion detection system",
      "paper_title": "Estimation of distribution algorithm for optimization of neural networks for intrusion detection system",
      "paper_year": "2006",
      "chunk_content": "The Particle Swarm Optimization (PSO) conducts searches using a population of particles which correspond to individuals in evolutionary algorithm (EA). A population of particles is randomly generated initially. Each particle represents a potential solution and has a position represented by a position vector $\\mathbf{x}_{\\mathbf{i}}$. A swarm of particles moves through the problem space, with the moving velocity of each particle represented by a velocity vector $\\mathbf{v}_{\\mathbf{i}}$. At each time step, a function $f_{i}$ representing a quality measure is calculated by using $\\mathbf{x}_{\\mathbf{i}}$ as input. Each particle keeps track of its own best position, which is associated with the best fitness it has achieved so far in a vector $\\mathbf{p}_{\\mathbf{i}}$. Furthermore, the best position among all the particles obtained so far in the population is kept track of as $\\mathbf{p}_{\\mathbf{g}}$. In addition to this global version, another version of PSO keeps track of the best position among all the topological neighbors of a particle. At each time step $t$, by using the individual best position, $\\mathbf{p}_{\\mathbf{i}}$, and the global best position, $\\mathbf{p}_{\\mathbf{g}}(\\mathbf{t})$, a new velocity for particle $i$ is updated by  \n$$\n\\mathbf{v}_{\\mathbf{i}}(\\mathbf{t}+\\mathbf{1})=\\mathbf{v}_{\\mathbf{i}}(\\mathbf{t})+c_{1} \\phi_{1}\\left(\\mathbf{p}_{\\mathbf{i}}(\\mathbf{t})-\\mathbf{x}_{\\mathbf{i}}(\\mathbf{t})\\right)+c_{2} \\phi_{2}\\left(\\mathbf{p}_{\\mathbf{g}}(\\mathbf{t})-\\mathbf{x}_{\\mathbf{i}}(\\mathbf{t})\\right)\n$$  \nwhere $c_{1}$ and $c_{2}$ are positive constant and $\\phi_{1}$ and $\\phi_{2}$ are uniformly distributed random number in $[0,1]$. The term $\\mathbf{v}_{\\mathbf{i}}$ is limited to the range of $\\pm \\mathbf{v}_{\\text {max }}$. If the velocity violates this limit, it is set to its proper limit. Changing velocity this way enables the particle $i$ to search around its individual best position, $\\mathbf{p}_{\\mathbf{i}}$, and global best position, $\\mathbf{p}_{\\mathbf{g}}$. Based on the updated velocities, each particle changes its position according to the following equation:  \n$$\n\\mathbf{x}_{\\mathbf{i}}(\\mathbf{t}+\\mathbf{1})=\\mathbf{x}_{\\mathbf{i}}(\\mathbf{t})+\\mathbf{v}_{\\mathbf{i}}(\\mathbf{t}+\\mathbf{1})\n$$  \nA neural network classifier trained by PSO algorithm with flexible bipolar sigmoid activation functions at hidden layer were constructed for the breastcancer data set. The issue of coding is similar with the one used in EDA-NN discussed above.  \nThe simple loop of the proposed training algorithm for neural network is as follows.  \nS1 Initialization. Initial population is generated randomly. The learning parameters $c_{1}$ and $c_{2}$ in PSO should be assigned in advance.\nS2 Evaluation. The objective function value is calculated for each particle.\nS3 Modification of search point. The current search point of each particle is changed using Eqn.(2) and Eqn.(1).\nS4 if maximum number of generations is reached or no better parameter vector is found for a significantly long time ( 100 steps), then stop, otherwise goto step S2;",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:06",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description to implement parallel LINC (pLINC) on a parallel architecture using Message Passing Interface (MPI)?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "parallel LINC",
        "Message Passing Interface",
        "parallel computing"
      ],
      "answer": "To implement parallel LINC (pLINC) on a parallel architecture using MPI, the code should be structured to parallelize the calculation of the nonlinearity condition for each pair of loci. The master processor distributes an initial population to the other processors. Each processor independently calculates the nonlinearity condition for its assigned subset of loci pairs. After the calculations, the results are communicated back to the master processor. Since communication is minimized to initial population distribution and result collection, the code should prioritize efficient, independent parallel computation to optimize performance.",
      "chunk_id": 13263,
      "paper_id": "Empirical investigations on parallelized linkage indentification",
      "paper_title": "Empirical investigations on parallelized linkage indentification",
      "paper_year": "2004",
      "chunk_content": "In order to compare the parallel LINC (pLINC) and the Distributed BOA (DBOA), numerical experiments comparing the number of fitness evaluations are not considered appropriate because they differ in their major source of computational overheads. The computational overheads of pLINC come from $O\\left(l^{2}\\right)$ fitness evaluations and those of DBOA come from $O\\left(l^{3}\\right)$ network construction that does not need fitness evaluations. To compare overall computational overheads, we need to observe those for fitness evaluations and for network construction in actual situations. Therefore, we perform experiments on an actual parallel  \narchitecture. In the following experiments, we employ a parallel computer SGI Onix 300 consisting of MIPS R14000/600MHz $\\times 32$ CPUs with 16GB shared memory connected via NUMAflex ${ }^{T M}$ high-speed network. For communications among processors, Message Passing Interface (MPI) is employed.  \nWe employ an one-max function and the sum of $k$-bit trap functions defined as follows as our test functions.  \n$$\nf(s)=\\sum_{i=1}^{L} f_{i}\\left(u_{i}\\right)\n$$  \nwhere $f_{i}$ is a $k$-bit trap sub-function defined as follows:  \n$$\nf_{i}\\left(u_{i}\\right)=\\left\\{\\begin{array}{cc}\nk-u_{i}-1 & \\text { if } 0 \\leq u_{i} \\leq k-1 \\\\\nk & \\text { if } u_{i}=k\n\\end{array}\\right.\n$$  \nwhere $u_{i}$ is the number of 1 's occurrence in a $k$-bit substring $s_{i}\\left(s=s_{1} s_{2} \\cdots s_{L}\\right)$.\nWe employ one-max, 3 -bit trap, and 5 -bit trap functions in the following experiments in order to control difficulty of the test problems. The string length of the problems is fixed to $l=105(L=35$ for the 3 -bit trap function and $L=21$ for the 5 -bit trap function). We observe time to obtain optimal solutions changing the number of processors $P=1,2,4,8,16$. Population size and other parameters of the algorithms are optimized for each experiment in order to minimize the time to obtain optimal solutions, and we perform 20 experiments and plot their average in the following figures.\nFigure 3 shows a comparison of speedups by pLINC and DBOA for the 5-bit trap test function. In the figure, the x -axis shows the number of processors employed and the y -axis is the speedup factor $S=T_{s} / T_{p}$ where $T_{s}$ is execution time for a serial processor (when $P=1$ ) and $T_{p}$ is that for the parallel machine.  \nThis illustrates pLINC achieves better results compared to DBOA in the speedup factors. This is because parallel calculation of nonlinearity condition for each pair of loci is highly independent and communication is necessary only when the master processor distributes an initial population and collects the results. On the other hand, parallel network construction in DBOA needs more frequent communications among processors during its search for an optimal network that minimizes the BD metric. This figure shows that pLINC is more preferable than DBOA in parallel computing environment for this problem. We have obtained similar results for one-max and 3-bit trap test functions. Since comparisons only by speedup factors are not enough to compare parallel algorithms - an inefficient algorithm by serial processing may achieve high speedup factors because its $T_{s}$ is large, we perform comparisons for time to obtain optimal solutions in the following.  \n[IMAGE_2]  \nFig. 3. Comparison of speedups between pLINC and DBOA.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:09",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when applied to the shifted test problems, and what statistical procedure is used to obtain the reported results?",
      "topics": [
        "selection"
      ],
      "answer": "The effectiveness of the EDA model is evaluated by its ability to find the minimum value of the shifted elliptic, shifted Rastrigin, shifted Ackley, shifted 1.2 Schwefel, and shifted Rosenbrock problems, where the minimum for all problems is f(X)=0. The reported results are obtained from 31 independent runs, using parameters such as a population size of 100, a maximum of 1,000 generations, a maximum of 100,000 function evaluations, a maximum of 5 parents in a copula, a selection of 30 individuals, a problem size of 10 variables, and an alpha value for estimation of univariate distributions ranging from 0.01 to 0.1 with increments of 0.01.",
      "chunk_id": 5013,
      "paper_id": "An EDA based on Bayesian networks constructed with Archimedean copulas",
      "paper_title": "An EDA Based on Bayesian Networks Constructed with Archimedean Copulas",
      "paper_year": "2012",
      "chunk_content": "Five of the problems found in [32] were selected. Such functions present diverse characteristics, and are frequently used in the specialized literature. Such problems are and their characteristics are:  \n1) Shifted elliptic problem: unimodal, separable.\n2) Shifted Rastrigin problem: multimodal, separable.\n3) Shifted Ackley problem: multimodal, separable.\n4) Shifted 1.2 Schwefel problem: unimodal, nonseparable.  \n[IMAGE0]  \nFigure 1. Construction of graph structure\n5) Shifted Rosenbrock problem: multimodal, nonseparable.\nThe minimum for all problems is $f(X)=0$. The reported results were obtained from 31 independent runs, with the following parameters:  \n- Population size: 100.\n- Maximum number of generations: 1,000.\n- Maximum number of function evaluations: 100,000.\n- Maximum number of parents in a copula: 5.\n- Selection: 30 individuals.\n- Problem size: 10 variables for all problems.\n- $\\alpha$ for estimation of univariate distributions: from 0.01 to 0.1 , with increments of 0.01 .\nThe results are shown in Table II. Experiments with higher dimensionalities are currently under way.  \nThe obtained results show that the approach based on multivariate Archimedean copulas is promising, even competitive with other evolutionary algorithms not based on statistical modeling.\nThis work proposes the use of several type of copulas, adaptively selected during the process. This can increase the precision of reflecting the nature of relations between variables in the problem at hand.  \nAdditionally, the use of Archimedean copulas can provide means for decreasing the computational cost associated with the estimation of the parameters of multivariate copulas.  \nThe use of an incremental rule for estimating the parameters of marginal distributions is very important in this approach, because it promotes exploration and maintains diversity, otherwise quickly lost during the process.  \nSome preliminary results are presented in this paper, with only 10 variables. Experiments with higher dimensionalities (up to 100) are currently under way. They require a considerable amount of time and space in the respective report, so they are planned for a future publication.  \nAs a future work related with the estimation of marginals, is the self-adaptation of the $\\alpha$ value, eliminating the necessity of fine tuning or dynamic rules.  \nAnother future work is related with negative correlations, currently discarded because of the probabilistic model. However, the contribute important information which can be incorporated to the model.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:10",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the Bayesian Network algorithmic approach detailed for EDAs when modeling relationships between features?",
      "topics": [
        "algorithm"
      ],
      "answer": "The Bayesian Network approach models causal relationships between features using a Directed Acyclic Graph (DAG) and a set of parameters. The DAG represents features as vertices and their relationships as directed edges, where each edge is associated with a parameter modeling the conditional probability \\(Pr(V_j | V_i)\\), representing the influence of a parent variable \\(V_i\\) on a child variable \\(V_j\\). The joint probability distribution is then decomposed into the product of conditional distributions of each variable given its parents, \\(P(V_{i}=v_{i} | \\mathbf{Pa}(V_{i}))\\).",
      "chunk_id": 3138,
      "paper_id": "Bayesian Network-Based Multi-objective Estimation of Distribution Algorithm for Feature Selection Tailored to Regression Problems",
      "paper_title": "Bayesian Network-Based Multi-objective Estimation of Distribution Algorithm for Feature Selection Tailored to Regression Problems",
      "paper_year": "2024",
      "chunk_content": "A Bayesian Network (BN) [13] is a probabilistic graphical model which provides a robust general approach especially suited to modeling complex non-deterministic systems. A BN models the causal relationships between the features of a model. It consists of a Directed Acyclic Graph (DAG) $\\mathcal{G}$ [13], and a set of parameters $\\Theta$, defining the strength and the shape of the relationships between features. To use a BN, one must define the graph $\\mathcal{G}$ and then calculate its parameters $\\Theta$. Defining the graph $\\mathcal{G}$ is a task that can be done by learning through data or by consulting human experts in a specific field [13].\n$\\mathcal{G}$ consists of a set of vertices $\\mathcal{V}$ and a set of directed edges $\\mathcal{E}$. The vertices in $\\mathcal{V}$ represent the features whose relationship is modeled by the BN, and the edges in $\\mathcal{E}$ represent the relationships between the features. A directed edge from $V_{i}$ to $V_{j}$ where $V_{i}, V_{j} \\in \\mathcal{V}$ is symbolically represented by the tuple $\\left(V_{i}, V_{j}\\right) \\in \\mathcal{E}$ or graphically represented as $V_{i} \\rightarrow V_{j}$. The directed edge $\\left(V_{i}, V_{j}\\right) \\in \\mathcal{E}$ indicates that $V_{i}$ is the parent of $V_{j}$ and that $V_{j}$ is the child of $V_{i}$. A BN models a parentchild relationship as the parent variable causing the child variable. Therefore, the directed edge $\\left(V_{i}, V_{j}\\right)$ in a BN means that the parent variable $V_{i}$ causes the child variable $V_{j}$. Additionally, every directed edge $\\left(V_{i}, V_{j}\\right) \\in \\mathcal{E}$ has a parameter $\\theta_{i, j} \\in \\Theta$. The parameter $\\theta_{i, j}$ associated with this edge is a matrix modeling $\\operatorname{Pr}\\left(V_{j} \\mid V_{i}\\right)$ (the conditional probability of $V_{j}$ given $V_{i}$ ). If $V_{i}, V_{j}$ can take on $\\left|V_{i}\\right|,\\left|V_{j}\\right|$ different values respectively, then this matrix $\\theta_{i, j}$ will have $\\left|V_{i}\\right| \\times\\left|V_{j}\\right|$ different entries.  \nFinally, a BN assumes that the joint probability distribution of the variables $P\\left(V_{1}=v_{1}, V_{2}=v_{2}, \\ldots, V_{n}=v_{n}\\right)$, defined in Eq. (1), can be decomposed as the product of the conditional distribution of the variables given the value of their parents $P\\left(V_{i}=v_{i} \\mid \\mathbf{P a}\\left(V_{i}\\right)\\right)$.  \n$$\nP\\left(V_{1}=v_{1}, V_{2}=v_{2}, \\ldots, V_{n}=v_{n}\\right)=\\prod_{i=1}^{n} P\\left(V_{i}=v_{i} \\mid \\mathbf{P a}\\left(V_{i}\\right)\\right)\n$$",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:12",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the `Popstats` variable in the PF-ESL memetic algorithm contribute to the diversification phase?",
      "topics": [
        "initialization"
      ],
      "answer": "In the PF-ESL memetic algorithm, `Popstats` records the statistics on edge states within the population `P`. Specifically, `Popstats(i)` calculates the ratio of solutions in the population that \"cut\" edge `i`, represented as (number of solutions in the population that cut edge `i`) / (number of solutions in the population). This statistic informs the hybrid reconstruction procedure, a part of the diversification phase, by providing information about which edges are frequently cut. The `Policyflag` variable, which randomly chooses a value from the range (0,1), determines whether PathRelinking or EDA procedure is used to construct a new solution. If `Policyflag` is less than the constant value `ζ` and there are at least one pair of linkable solutions, PathRelinking is activated, choosing a linkable solution pair (Sⱼ, Sₘ) which have largest difference. The information from `Popstats` thus influences the selection of edges to modify during the diversification phase, promoting exploration of different regions of the search space.",
      "chunk_id": 1558,
      "paper_id": "A memetic based on-state for max-cut",
      "paper_title": "A memetic based on-state for max-cut",
      "paper_year": "2022",
      "chunk_content": "Our PF-ESL memetic algorithm follows the two-phase (intensification and diversification) framework mentioned above. It is composed of four components: population initialization, the hybrid reconstruction procedure, the Tabu search procedure, and the population-updating operator. The Tabu search procedure corresponds to the intensification phase, the hybrid reconstruction procedure and the populationupdating operator form the diversification phase. At first, the first component initializes the population for the rest of the algorithm. The other three components then form a key repeated process alternating between intensification phase (the third component) and the diversification phase (the second and the fourth component): at each iteration of the repeated process, the hybrid reconstruction procedure generates a promising initial solution based on the population (diversification phase), which is further optimized by the Tabu search procedure (intensification phase); the population-updating operator then uses the result of the Tabu search procedure to update the population (diversification phase).  \nThe variables involved in the algorithm are described as follows:\n$P$ : the population.\n$p$ : the size of the population.\n$\\zeta$ : a constant value prescribes the possibility of using Pathrelinking to construct a new solution from the population at each iteration.  \nPolicyflag: A temporary variable, its value is generated from range $(0,1)$ at each iteration randomly. It is used to compare with $\\zeta$ to determine whether to use PathRelinking or EDA procedure to construct a new solution.  \nPopstats: the statistics on edge states, it records the ratio of each edge that being \"cut\" within the population, i.e., Popstats(i) $=$ (number of solutions in the population that cut edge $i$ ) / (number of solutions in the population).  \nAlgorithm 1: PF-ESL memetic algorithm.\nInput: the size of the population $(p)$; the number of vertices $n$; the $n \\times$ $n$ matrix of edge weights.\nOutput: the best solution ever found.\n1: /Lines 2-7 initialize the population (Population initialization, component 1), section $2.2 * /$\n2: $P=\\left\\{S_{1}, \\ldots, S_{p}\\right\\} \\leftarrow$ randomly generate $p$ initial solutions as the population $/ *$ section $2.2 * /$\n3: for $i$ in $\\{1, \\ldots, p\\}$ do\n4: $\\quad S_{i} \\leftarrow$ TabuSearch $\\left(S_{i}\\right) / *$ Tabu Search procedure, section $2.4 * /$\n5: end for\n6: Popstats $\\leftarrow$ Calculate the statistics on edge states over the population $/ *$ section $2.2 * /$\n7: Mark each solution pair $\\left(S_{i}, S_{j}\\right)(i \\neq j, i, j \\in[1, p])$ as linkable $/ *$ section $2.2 * /$\n8: /Lines 9-24 form the key repeated process (component $2-4$ )/\n9: repeat\n10: /Lines 11-21 belong to the hybrid reconstruction procedure (component 2), section $2.3 * /$\n11: $\\quad$ Policyflag $\\leftarrow$ randomly chooses a value from $(0,1)$\n12: if Policyflag $<\\zeta$ and there are at least one pair of linkable solutions then\n13: / the path relinking operator is activated/\n14: Choose a linkable solution pair $\\left(S_{j}, S_{m}\\right)$ which have largest difference\n15: $\\quad S_{0} \\leftarrow$ PathRelinking $\\left(S_{j}, S_{m}\\right) / *$ Section FORMULA_110",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:15",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm (EDA) to solve the Hybrid Flowshop Scheduling problem with Unrelated Parallel Machines (HFS-UPM), how should practitioners represent the problem's constraints, specifically considering that there are 'n' jobs, 's' stages, and 'M' sets of unrelated parallel machines at each stage?",
      "topics": [
        "scheduling"
      ],
      "answer": "When applying an EDA to the HFS-UPM scheduling problem, practitioners must encode the constraints within the EDA's probabilistic model. Since there are 'n' jobs to be processed on 's' stages, and 'M' represents the sets of unrelated parallel machines at each stage (\\( \\mathbf{M}=\\{\\mathbf{M}_{1}, \\mathbf{M}_{2}, \\ldots, \\mathbf{M}_{j}, \\ldots, \\mathbf{M}_{s} \\mid j \\in \\mathbf{S}\\} \\) ), the EDA should model the probability distribution over possible machine assignments at each stage for each job, ensuring that each job is processed by exactly one machine at every stage. The EDA implementation needs to ensure that preemption is not allowed and the makespan, defined as the maximum completion time of all jobs at the final stage 's', is minimized.",
      "chunk_id": 9308,
      "paper_id": "An improved gravitational search algorithm to the hybrid flowshop with unrelated parallel machines scheduling problem",
      "paper_title": "An improved gravitational search algorithm to the hybrid flowshop with unrelated parallel machines scheduling problem",
      "paper_year": "2021",
      "chunk_content": "Our description of the HFS-UPM scheduling problem is written in the similar way as Cui and Gu's work (Cui and Gu 2015) for the HFS-IPM model. Givens and assumptions are as below.  \n[IMAGE0]  \nFigure 1. Description of HFS-UPM.\n(1) A set of $n$ jobs $\\mathbf{J}, \\mathbf{J}=\\{1,2, \\ldots, i, \\ldots, n\\}$;\n(2) A set of $s$ stages $\\mathbf{S}, \\mathbf{S}=\\{1,2, \\ldots, j, \\ldots, s\\}$;\n(3) $s$ sets $\\mathbf{M}, \\mathbf{M}=\\left\\{\\mathbf{M}_{1}, \\mathbf{M}_{2}, \\ldots, \\mathbf{M}_{j}, \\ldots, \\mathbf{M}_{s} \\mid j \\in \\mathbf{S}\\right\\}$, and $\\mathbf{M}_{j}=\\left\\{1,2, \\ldots, k, \\ldots, m_{j} \\mid m_{j} \\geq 1, j \\in \\mathbf{S}\\right\\}$ is one set of unrelated parallel machines at the stage $j$ and the processing time for each machine is irrelevant.\n(4) One or more machines exist at each stage, and at least one stage $j$ must have more than one machine;\n(5) All machines are available at all the time without breakdown;\n(6) A machine can process at most one job at a time and a job can be processed by at most one machine at a time;\n(7) The setup, release, and transportation times of all jobs are negligible;\n(8) Preemption is not allowed and the intermediate buffer capacities between two successive stages are unlimited.  \nThere are $n$ jobs to be processed on $s$ stages. Every job has to visit all of the stages in the same order from stage 1 through stage $s$ and is processed by exactly one machine at every stage. The HFS-UPM scheduling problem is to allocate a machine at each stage for each job and determine the sequence of jobs on each machine so as to minimise the makespan, which is the maximum completion time of all jobs at the final stage $s$. The brief description of the HFS-UPM is shown in Figure 1. Please see Cui and Gu's work (Page 250; Cui and Gu 2015) for a similar simple explanation FORMULA_24 of the problem.",
      "question_type": "challenge",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:17",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed for solving the Steiner tree problem, what general performance characteristics are indicated regarding the influence of network scale on the algorithm's performance?",
      "topics": [
        "search"
      ],
      "answer": "The EDA-based Steiner minimal tree algorithm exhibits a performance that is 'not much influenced by network scale.' This suggests that the algorithm's search and converging speed is relatively stable even when applied to 'largescale topology'.",
      "chunk_id": 239,
      "paper_id": "An Estimation of Distribution Algorithm for Steiner Tree Problem",
      "paper_title": "An Estimation of Distribution Algorithm for Steiner Tree Problem",
      "paper_year": "2013",
      "chunk_content": "The paper proposed an optimizing Steiner minimal tree algorithm based on EDAs. The algorithm adopted the thought of tree shape change via learning from the probabilistic model to solve Steiner tree problem. This algorithm can be used for undirected Steiner tree. Simulation results show that the results are almost the same as the best one, and this algorithm has better performance in searching and converging speed. It can also be seen that the performance of the algorithm is not much influenced by network scale, indicating that it is more applicable to largescale topology and provides a better choice for the Steiner problem.\nThe study is supported by National Natural Science Foundation of China (NSFC No. 60773101), Natural Science Foundation of Shandong Province (Grant No. ZR2011FM021), and Science and Technology Development Program of Jinan (Grant No.201102010), The National Innovating and Enterprising Projects for College Students of china, 2013",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:18",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "According to the details in the chunk, what advantages does IRM-MEDA have over RM-MEDA in terms of IGD-metric and search speed when the maximal number of function evaluations is reduced?",
      "topics": [
        "search"
      ],
      "answer": "IRM-MEDA exhibits a stronger local search capability than RM-MEDA due to its local learning mechanism, leading to increased search speed. When the maximal number of function evaluations is reduced, RM-MEDA's performance degenerates rapidly, as indicated by the total IGD-metric on functions F1-F9. In contrast, IRM-MEDA maintains a good property and surpasses RM-MEDA on all problems except for F4, demonstrating that IRM-MEDA can find solutions faster.",
      "chunk_id": 1245,
      "paper_id": "Improved RM-MEDA with local learning",
      "paper_title": "Improved RM-MEDA with local learning",
      "paper_year": "2014",
      "chunk_content": "The local learning gives IRM-MEDA stronger ability of local search than RM-MEDA. It will increase its search speed and make it faster to find the solution of problems. To farther show  \nFig. 7 The total IGD-metric of RM-MEDA and IRM-MEDA on F1-F9\n[IMAGE19]  \nRM-MEDA (half): RM-MEDA with half of the the maximal number of function evaluations\nIRM-MEDA (half): IRM-MEDA with half of the the maximal number of function evaluations\n[IMAGE20]  \nNumber of Function Evaluations $\\left(\\times 10^{4}\\right)$\n(a) Convergence curve of F1\n[IMAGE21]  \nNumber of Function Evaluations $\\left(\\times 10^{4}\\right)$\n(d) Convergence curve of F4\n[IMAGE22]\n(g) Convergence curve of F7\n[IMAGE23]  \nNumber of Function Evaluations $\\left(\\times 10^{4}\\right)$\n(b) Convergence curve of F2\n[IMAGE24]  \nNumber of Function Evaluations $\\left(\\times 10^{4}\\right)$\n(e) Convergence curve of F5\n[IMAGE25]\n(h) Convergence curve of F8\n[IMAGE26]  \nNumber of Function Evaluations $\\left(\\times 10^{5}\\right)$\n(c) Convergence curve of F3\n[IMAGE27]  \nNumber of Function Evaluations $\\left(\\times 10^{4}\\right)$\n(f) Convergence curve of F6\n[IMAGE28]  \nFig. 8 The average IGD-Metric of the final nondominated solutions in 20 runs versus the number of function evaluations on F1-F9  \ndisplay the advantages of IRM-MEDA, we reduce the maximal number of function evaluations to half of its primitive value and keep others parameters unchanged. Table 3 shows the new result and form it IRM-MEDA shows an enough advantage than RM-MEDA. It is obvious that IRM-MEDA have greatly surpassed RM-MEDA on all problems except for F4.  \nFigure 7 shows the total IGD-metric of RM-MEDA and IRM-MEDA on F1-F9. From this figure, the performance of RM-MEDA degenerated very fast when reduce the maximal number of function evaluations. But IRM-MEDA still maintains a good property. It just illustrate that the Local Learning we proposed is powerful and IRM-MEDA can search the solution faster than RM-MEDA.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:20",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model described for selecting dandelions into the next generation, based on the provided selection strategy?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The selection strategy, as outlined in Algorithm 3, involves these steps: First, generate N dandelions randomly in the search space to form the initial population. Second, each dandelion generates normal seeds using Algorithm 1. Third, mutation seeds are generated by the BD component, implemented via Algorithm 2. Finally, select N dandelions for the subsequent generation by evaluating all dandelions, normal seeds, and mutation seeds, choosing the best individuals based on the fitness function f(x). Specifically, if a dandelion is the best dandelion x_B, the selection considers the fitness values of the dandelion itself f(x_i(t)), its normal seeds f(s_ik), and its mutation seeds f(m_j), selecting the argument that minimizes the fitness. Otherwise, for non-best dandelions, the selection considers only the fitness values of the dandelion itself f(x_i(t)) and its normal seeds f(s_ik).",
      "chunk_id": 1854,
      "paper_id": "Competition-Driven Dandelion Algorithms With Historical Information Feedback",
      "paper_title": "Competition-Driven Dandelion Algorithms With Historical Information Feedback",
      "paper_year": "2022",
      "chunk_content": "In this article, in order to implement a fair competition, we design a new selection strategy based on a greedy strategy. Its core idea is that a dandelion and its own seeds are considered as a single population and greedily select the best individual in the population into the next generation  \n$$\n\\mathbf{x}_{i}(t+1)=\\left\\{\\begin{array}{ll}\n\\arg \\min \\left\\{f\\left(\\mathbf{x}_{i}(t)\\right), f\\left(\\mathbf{s}_{i k}\\right), f\\left(\\mathbf{m}_{j}\\right)\\right\\}, & \\mathbf{x}_{i}=\\mathbf{x}_{B} \\\\\n\\arg \\min \\left\\{f\\left(\\mathbf{x}_{i}(t)\\right), f\\left(\\mathbf{s}_{i k}\\right)\\right\\}, & \\text { otherwise }\n\\end{array}\\right.\n$$  \nwhere $f\\left(\\mathbf{s}_{i k}\\right)$ is the fitness values of normal seeds generated by the $i$ th dandelion, and $f\\left(\\mathbf{m}_{j}\\right)$ is the fitness values of mutation seeds generated by BD.  \nAlgorithm 3 summarizes the framework of DA. Therein, $N$ dandelions are generated randomly in search space as initial population (line 1), and then each dandelion generates its normal seeds by Algorithm 1 (line 4), while BD is selected to generate the mutation seeds by Algorithm 2 (line 5). Finally, selecting $N$ dandelions into the next generation from all dandelions (dandelions, normal seeds and mutation seeds) via a selection strategy. BD is returned when the termination condition is satisfied.\nIn this section, we introduce the proposed algorithms in detail. First, a novel competition mechanism is designed, and then three historical information feedback models are proposed",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:22",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the approximated Pareto fronts, and what statistical test is applied to analyze the results?",
      "topics": [
        "search"
      ],
      "answer": "The $\\mathrm{HV}^{-}$ indicator and the IGD metric are used to evaluate the approximated Pareto fronts. The Mann-Whitney-Wilcoxon test with $\\alpha=5 \\%$ is applied for the statistical analysis of the results.",
      "chunk_id": 9399,
      "paper_id": "Analysis of Bayesian Network Learning Techniques for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm a case study on MNK Landscape",
      "paper_title": "Analysis of Bayesian Network Learning Techniques for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm: a case study on MNK Landscape",
      "paper_year": "2021",
      "chunk_content": "Tables 2 and 3 present the respective $\\mathrm{HV}^{-}$indicator and IGD metric to the approximated Pareto fronts provided by the two populations $P F_{s}$ and $P F_{s n}$. The values are averaged over the results of 30 executions of each algorithm. The Mann-WhitneyWilcoxon test with $\\alpha=5 \\%$ is applied for the statistical analysis of the results. Values of $P F_{s}$ and $P F_{s n}$ for each algorithm and instance with background in light blue have no statistically significant differences. The values in bold correspond to the best values for the paiwise comparison between $P F_{s}$ and $P F_{s n}$ for each HMOBEDA variant.  \n[IMAGE11]  \n[IMAGE12]\nMohamed El Yafrani\nmey@mp.aau.dk\nMyriam Delgado\nmyriamdelg@utfpr.edu.br\nRicardo Luders\nluders@utfpr.edu.br\nRoberto Santana\nroberto.santana@ehu.es\nHugo V. Siqueira\nhugosiqueira@utfpr.edu.br\nHuseyin G. Akcay\ngokhanakcay@gmail.com  \nBelaid Ahiod\nahiod@fsr.ac.ma\n1 Federal University of Technology - Parana (UTFPR), Curitiba, Brazil\n2 Operations Research Group, Aalborg University (AAU), Aalborg, Denmark\n3 University of the Basque Country (UPV/EHU), San Sebastian, Spain\n4 Akdeniz University (AKU), Antalya, Turkey\n5 Mohammed V University in Rabat, Rabat, Morocco",
      "question_type": "evaluation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:24",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for Resource-Constrained Project Scheduling (RCSP) when using a time-based-robust measure (TRM)?",
      "topics": [
        "scheduling"
      ],
      "answer": "The primary objective is to improve the robustness of schedules by considering not only the total slack time ($s_j$) of activities but also the number of immediate successors ($NSucc_j$) and the resource requirements ($r_{jk}$) of each activity, effectively minimizing the impact of delays on the overall schedule, where the TRM is calculated as $\\sum_{j=1}^{N} s_{j} N S u c c_{j} \\sum_{k=1}^{K} r_{j k}$.",
      "chunk_id": 8187,
      "paper_id": "A hybrid multi-objective EDA for robust resource constraint project scheduling with uncertainty",
      "paper_title": "A hybrid multi-objective EDA for robust resource constraint project scheduling with uncertainty",
      "paper_year": "2019",
      "chunk_content": "In job shop environment, the robustness is often defined as the difference between expected value (e.g., makespan) and realized one (Jensen, 2001). In RCSP, except the duration of project, the resource usage is also need to take into consider. For example, the deviation of the starting time of each activity in the realized schedule and the expected one is to be minimized, or minimize the resource flow network for the problems with unrestricted resource availability (Herroelen \\& Leus, 2004).  \nWe proposed two kinds of robust measures for RCSP: time-basedrobust and resource-based-robust.\n(a) Time-based-robust measure (TRM): In order to measure the robustness on the time, one popular way is slack-based. Two types of slack are widely used in the scheduling literature: total slack and free slack. Total slack is the difference between the earliest start time and latest start time of an activity, while free slack is the amount of time that an activity can be delayed without delaying the start of the next activity.  \nIn Fig. 2, it shows one example of total slack time in project scheduling environment. There are 5 activities, and the yellow area is the slack time period for activity A2 while the red area is for activity A3. In previous studies, most of them thought the slack time for A2 and A3 are equal, because the lengths of time period are same. However, from the view of resource allocation in RCSP, A3 requires more amount of resource than A2, in other words, if A3 delayed, more resources should be\n[IMAGE1]  \nFig. 2. An illustrative example of slack time.  \n[IMAGE2]  \nFig. 3. Amount of successors and conflict resource.\nheld by it and impact to the system is larger than delay of A2. Meanwhile, from the view of successors, activity A2 has more successors than A3, and the impact of delay of A2 is larger than A3.  \nAs a result, conventional slack-based approach only focus on the length of slack time period to evaluate the robustness of one schedule, but ignoring considering the affect by different amount of resource. As shown in Fig. 3, it shows two typical conditions of slack time. In Fig. 3(a), two activities with red color and blue color have the same time periods of slack time, but for red one, it has more successors than blue one, in other words, if the red one delayed, more operations will be affected. So the amount of successors should be taken into consider together with slack time.  \nIn Fig. 3(b), the red one and blue one have the same slack time, but red one requires more resources than the blue one, if red one delayed, more resources are required and hold by it. In other words, the higher amount of conflict with a shared resource, the bigger impact to the schedule system. As a result, the required resource of each operation has to be well considered also.  \nIn this study, for RCSP, we proposed one new slack-based robust measure which includes amount of successors and resource requirement of activity. These together show the ability to absorb the uncertainty, while keeping the expected makespan.\n$T R M: \\sum_{j=1}^{N} s_{j} N S u c c_{j} \\sum_{k=1}^{K} r_{j k}$\nwhere $s_{j}$ is the total slack time, $N S u c c_{j}$ represents the number of immediate successors of activity $j$, and $r_{j k}$ is the resource requirements for activity $j$.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:25",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms (EDAs) used for software test data generation, how does the algorithmic mechanism of updating the 'set' of best inputs for each branch relate to the overall search process, and what impact does this have on the EDA's population seeding strategy?",
      "topics": [
        "optimization"
      ],
      "answer": "The system keeps a 'set' with the best inputs found so far for each code branch, where the quality of an input set is the average objective function value of the elements in the set. During each EDA iteration, each individual (input) is evaluated not only for the objective branch but also with regard to every other uncovered branch. If an individual improves the quality of the branch's set, the worst input in the set is replaced. If the branch had previously been treated but uncovered, its state is marked as untreated. This increased quality of the set results in a promising population seed, making the branch a new candidate objective in the selection step. This mechanism dynamically updates the initial population of the EDA based on the best inputs found across all branches, influencing the EDA's exploration of the search space and potentially leading to faster convergence toward covering the objective branch.",
      "chunk_id": 6041,
      "paper_id": "DYNAMIC SEARCH SPACE TRANSFORMATIONS FOR SOFTWARE TEST DATA GENERATION",
      "paper_title": "Dynamic search space transformations for software test data generation",
      "paper_year": "2008",
      "chunk_content": "In a SBSTDG approach following the scheme in Figure 2, the coverage of a branch may result in a highly difficult task, as the space defined by the inputs and the objective function is usually large and complex.  \nMost of the efforts to address this issue have concentrated on the objective function and the optimization technique. Attempts on the former relate to the concepts in Section 3.2, while, on the other hand, a clear case concerning the techniques is the general confrontation of local with global optimization procedures.  \nSurprisingly, so far little attention has been paid to the selection of an appropriate search space. This is an interesting matter, as focusing the search on a promising region could simplify the problem, while making an inadequate choice an optimal solution may not even exist.  \nAn alternative facing this question is suggested in Harman et al. (2002a). Here, a dependence analysis is applied to the variables in the source code to identify the input parameters that cannot affect the coverage of a given branch. This way, a number of problem variables can be eliminated and the search space, reduced.  \nThe present paper describes two approaches for the search space selection issue that follow the same line. Both extend the method explained in Sagarna and Lozano (2005a), so this work is outlined next.\nThe system developed by Sagarna and Lozano conforms to the general scheme in Figure 2. Each code branch is associated with three possible states: covered, treated but uncovered, or untreated. Initially, all the branches are in the untreated state. After tackling the optimization problem of a branch, if the optimum was reached, the branch is marked as covered. Otherwise, its state is marked as treated but uncovered.  \nThe stopping criterion of the scheme is full coverage achievement (all branches in the covered state) or unsuccessful treatment of every unexercised objective branch (treated but uncovered state).  \nAdditionally, the input sets strategy discussed in Section 3.3 is applied. That is, for each branch, a set with the best inputs found so far is kept at every moment during the process. The quality of an input set is taken as the average objective function value of the elements in the set. Thus, the objective selection step consists of choosing the branch with the highest quality set.  \nThe optimization step seeks inputs covering the objective branch through an EDA. An individual in the EDA is a bit string representing an input and the initial population is composed of the inputs in the set of the branch.  \nFigure 4 illustrates a schema of the whole process. At each iteration, a branch, together with its set of best inputs, is selected as the objective, and its coverage is sought through an EDA.  \nIn the EDA, each individual (input) is evaluated not only for the objective branch, but with regard to every other uncovered branch. This way, if the individual improves the quality of the set of the branch, then the worst input in the set is replaced by the one represented by the individual. In this case, the quality of the set has been increased, so it may result in  \n[IMAGE_1]  \nFigure 4. Schema of the basic approach.\na promising population seed. Hence, if the branch had previously been treated, its state is marked as untreated and becomes a new candidate objective in the selection step.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:28",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners substitute crossover and mutation operators, given its advantage over traditional evolutionary algorithms?",
      "topics": [
        "evolutionary"
      ],
      "answer": "When using an Estimation of Distribution Algorithm, the crossover and mutation operators typically found in Genetic Algorithms are replaced by an estimation process. This substitution is a key characteristic of EDAs that distinguishes them from traditional evolutionary algorithms.",
      "chunk_id": 6461,
      "paper_id": "Ambient Cardiac Expert A Cardiac Patient Monitoring System using Genetic and Clinical Knowledge Fusion",
      "paper_title": "Ambient cardiac expert: A cardiac patient monitoring system using genetic and clinical knowledge fusion",
      "paper_year": "2007",
      "chunk_content": "Figure 4: Gaussian EDA Algorithm to Compute Weights  \nThe choice of EDA algorithm is made due to its better performance for different optimization problem over traditional evolutionary algorithm e.g. Genetic Algorithms [12]. It has advantage over traditional evolutionary algorithms in a way that both crossover and mutation operators are substituted by estimation process.\nTo test ACE system clinical data, generated by following four different groups was used:  \n1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\nThe data had 120 samples from healthy persons while there were 102 samples from different patients. Each sample comprised of 13 clinical parameters shown in Table 1. Genetic data on the other hand had much larger attributes (54,676 genes) while much lower number of samples for both normal and idiopathic heart failure samples. The data is downloaded from CardioGenomics project by Harvard University\n\"http://cardiogenomics.med.harvard.edu/groups/proj1/pages /download_Hs-idiopathic.html\"and was generated using Affymetrics HgU133 Plus 2.0 arrays and contains 12 samples each for normal and heart failure patients.  \nTo provide real-time sensor network environment parameters to ACE, we developed a device to emulate the body area network - that includes sensors attached to a patient, the sensors in the environment and a gateway node. The device, named Virtual Patient (VP), comprises of an Atmel AtMega 128 8bit RISC based micro controller. The Device features a 2 line by 16 character standard alpha numeric LCD display. The VP also includes 1 Promi ESD blue tooth module. The Blue tooth module presents as an AT compatible modem and is controlled via a series of AT commands in ASCII. The blue tooth module has its own blue tooth stack and can perform discovery as well as be discovered. When connected to a peer device this module provides blue tooth serial services and appears as a COM port.  \nThe next level of emulation is at the home network, which comprises the intermediate nodes in the network and the network server (SNS). In the experimental testbed, we used an HP iPAQ 6915 series PDA for this purpose, which has Microsoft Windows Mobile 5.0 for Pocket PC Phone Edition and GSM/GPRS/EDGE WLAN 802.11b, Bluetooth 1.2, integrated high sensitivity GPS receiver with HP iPAQ Quick GPS connection utility and IrDA. Rest of the framework components include the hospital network that has the diagnosis facilities and the physician's terminal. We used a Toshiba Tecra series notebook with Intel Core Solo 1.66 GHz T1300 Processor with 1.5 GB RAM, IEEE 802.11b, Bluetooth and USB interfaces to run ACE.  \nThe VP was setup to use Bluetooth channel to communicate with the intermediate node (PDA), while WIFI was used between the PDA and the Genome \\& Network Server (notebook).  \nTable 1: Clinical Data Attributes\nWith the above mentioned devices in place, the software components of the framework were written and deployed in respective devices. The DNA microarray and the corresponding clinical data of 31 normal and diseased patients each were obtained and the Genome server on the notebook was trained. The ACE was programmed in C and MATLAB to diagnose the disease based on the DNA and clinical data and produce a DNA-Risk Factor (in the range of 1-100) depicting the level of a cardiac risk.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:29",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Evolutionary Algorithm with Structure Mutation (EA/SM) discussed, how do the runtime performances compare when the repair-assisted restart process is replaced with a greedy restart process, specifically in terms of the Rtime (runtime of restart process) and overall runtime?",
      "topics": [
        "search"
      ],
      "answer": "When the new repair-assisted restart process in EA/SM is replaced with a greedy restart process, resulting in the EA/SM/GR variant, the Rtime is observed to be $8.5\\%-34.6\\%$ more than that of EA/SM. Furthermore, the overall runtimes are $3.3\\%-15.8\\%$ longer than that of EA/SM, despite the greedy restart process itself being slightly faster than the new repair-assisted restart process. These comparisons are based on experiments conducted on the MBBP benchmark.",
      "chunk_id": 4191,
      "paper_id": "A New Evolutionary Algorithm with Structure Mutation for the Maximum Balanced Biclique Problem",
      "paper_title": "A New Evolutionary Algorithm with Structure Mutation for the Maximum Balanced Biclique Problem",
      "paper_year": "2015",
      "chunk_content": "In EA/SM, the structure mutation is proposed to improve the exploration capability of the algorithm during the local search process to escape from local optima, while the new repair-assisted restart process is introduced to make full use of the statistical information extracted from the good solutions during the local search process with probability model. A very natural question is whether the proposed SM operator and the new repair-assisted restart process have any positive contribution to the performance of the algorithm. To answer this question, the performance of EA/SM are compared with three other EAs.  \n1) Evolutionary algorithm with greedy restart (EA/GR), which has the same framework as EA/SM, but no SM and repair operator is adopted. EA/GR adopts the same restart process as that present in [17].\n2) Evolutionary algorithm with the new repair-assisted restart (EA/RR), which has the same framework as  \nEA/SM, and the new repair-assisted restart process is adopted after local search process, but no SM is adopted.\n3) Evolutionary algorithm with structure mutation and greedy restart (EA/SM/GR), which has the same framework as EA/SM, and the SM is adopted in local search process, but no repair operator is adopted. EA/SM/GR adopts the same restart process as that present in [17]. All the parameters of EA/GR, EA/RR, and EA/SM/GR are set as the same as EA/SM. The three algorithms are run independently for 30 times on each benchmark graph.\nTable II provides the experiment results of the four algorithms on the MBBP (statistical test results will be presented in a separate table). It can be seen that the performance of ER/GR is much weaker than those of other EAs. EA/GR even cannot obtain a biclique as large as that got by the heuristic algorithm [9] in most case, so the values of Ftime are unfilled in Table II. In particular, it is observed that the restart process in EA/GR is invoked more frequently (2.5-4.2 times) than EA/SM to help algorithm jump out of the local optima, which results in much longer runtimes. It can also be observed in Table II that the performances of both EA/RR and EA/SM/GR are weaker than that of EA/SM, while they both outperform the heuristic algorithm significantly.  \nTABLE II\nExperiment Results of EA/GR, EA/RR, and EA/SM/GR on the MBBP (Statistical Test Results are Presented in Table IV)  \nWithout of SM, the performance of EA/RR can be summarized as follows: 1) the values of Ftime are $2-3.8$ times more than that of EA/SM; 2) the values of Rtime are 2.2-3.4 times more than that of EA/SM; and 3) the runtimes are $13.6 \\%-24.7 \\%$ longer than that of EA/SM. Making use of greedy restart process [17] in place of the proposed new repair-assisted restart process, the performance of EA/SM/GR can be summarized as follows: 1) the values of Rtime are $8.5 \\%-34.6 \\%$ more than that of EA/SM and 2) the runtimes are $3.3 \\%-15.8 \\%$ longer than that of EA/SM, although the greedy restart process itself is slightly faster than the new repair-assisted restart process.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:31",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "According to the details in the chunk, what advantages does the Guided Hopfield Evolutionary Algorithm (GHEA), which combines a Hopfield net with EDA and local search, have in comparison to state-of-the-art approaches for the maximum clique problem (MCP)?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Heuristic Search",
        "Hopfield Networks",
        "Maximum Clique Problem"
      ],
      "answer": "The Guided Hopfield Evolutionary Algorithm (GHEA) utilizes a specific repair process to enhance the quality of the Hopfield intermediate state, and perturbation based on EDA probability to generate new initial states for Hopfield. This combination allows GHEA to escape from local minima efficiently and search wider domains, resulting in it outperforming state-of-the-art approaches on some maximum clique problem (MCP) instances of varying difficulty.",
      "chunk_id": 1231,
      "paper_id": "A guided Hopfield evolutionary algorithm with local search for maximum clique problem",
      "paper_title": "A Guided Hopfield Evolutionary Algorithm with Local Search for Maximum Clique Problem",
      "paper_year": "2014",
      "chunk_content": "In this paper, we have presented a hybrid algorithm, named GHEA, based on Hopfield net combined with EDA and local\nsearch for the maximum clique problem. According to the characteristic of continuous Hopfield net, the algorithm utilizes a specific repair process to efficiently enhance the quality of Hopfield intermediate state. Simultaneously, the perturbation based on the idea of EDA probability can generate a new initial situation for Hopfield to guide for heuristic searching. Our algorithm can escape from local minima efficiently and search wider domains. We have tested our algorithm on a set of MCP instances of different difficulties, outperforming the state-of-the-art approach to some extent on MCP.",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:33",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model described, based on Algorithm 1?",
      "topics": [
        "selection"
      ],
      "answer": "The EDA model execution involves these steps: (1) Initialize by randomly generating M individuals to create an initial population D{0}. (2) Iteratively perform the following: (a) Select N individuals from the previous population D{l-1} to form D{l-1}^{s} using a selection method. N is less than or equal to M. (b) Estimate the joint probability distribution p{l}(x) based on the selected individuals D{l-1}^{s}. (c) Sample M new individuals from the probability distribution p{l}(x) to create the new population D{l}. (3) Repeat step (2) until a specified stop criterion is met.",
      "chunk_id": 13243,
      "paper_id": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_title": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_year": "2004",
      "chunk_content": "We study the suitability of EDAs as a non-deterministic search procedure for the HP model. A main difference between EDAs and GAs is that the former constructs an explicit probability model of the solutions selected. This model can capture, by means of probabilistic dependencies, relevant interactions among the variables of the problem. The model can be conveniently used to generate new promising solutions. The main scheme of the EDA approach is shown in algorithm 1. Although the introduction of EDAs is relatively new, there already exists a number of succesful applications of EDAs in computational biology [2, 18 .  \nEDAs differ in the type of models that they use and the corresponding factorizations of the probability that these models determine. For the protein folding problem, we define a probability model that assumes that proteins adjacent in the sequence are related in their lattice positions. The probability model then encodes the dependencies between the move of a residue and the moves of the previous residues in the sequence. This information is used in the generation of solutions.  \nLet $p(\\mathbf{x})$ be the probability distribution of random variable $\\mathbf{X}$. Our probability model considers that the configuration of variable $X_{i}$ depends on the configuration of the previous $k$ variables, where $k \\geq 0$ is a parameter of the model. $p(\\mathbf{x})$ can be factorized as follows:  \n$$\np(\\mathbf{x})=p\\left(x_{1}, \\ldots, x_{k+1}\\right) \\prod_{i=k+2}^{n} p\\left(x_{i} \\mid x_{i-1}, x_{i-2}, \\ldots, x_{i-k}\\right)\n$$  \nThe learning phase of our EDA will only comprise a parametric learning of the parameters in contrast to some state-of-the-art EDAs that make structural  \n```\nAlgorithm 1: Main scheme of the EDA approach\n\\(1 \\quad D{0} \\leftarrow\\) Generate \\(M\\) individuals (the initial population) randomly\n\\(2 l=1\\)\ndo \\(\\{\\)\n\\(D{l-1}^{s} \\leftarrow\\) Select \\(N \\leq M\\) individuals from \\(D{l-1}\\) according to a selection method\n\\(p{l}(\\boldsymbol{x})=p\\left(\\boldsymbol{x} \\mid D{l-1}^{s}\\right) \\leftarrow\\) Estimate the joint probability of selected individuals\n\\(D{l} \\leftarrow\\) Sample \\(M\\) individuals (the new population) from \\(p{l}(\\boldsymbol{x})\\)\n\\} until A stop criterion is met",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:35",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the data mining algorithms for intrusion detection?",
      "topics": [
        "search"
      ],
      "answer": "The effectiveness of data mining algorithms for intrusion detection can be evaluated based on their ability to identify deviations from normal usage behavior patterns (anomaly intrusion detection) and to detect well-defined patterns of attacks (misuse intrusion detection).",
      "chunk_id": 6365,
      "paper_id": "Estimation of distribution algorithm for optimization of neural networks for intrusion detection system",
      "paper_title": "Estimation of distribution algorithm for optimization of neural networks for intrusion detection system",
      "paper_year": "2006",
      "chunk_content": "Attacks on the nation's computer infrastructures are becoming an increasingly serious problem. Computer security is defined as the protection of computing systems against threats to confidentiality, integrity, and availability [1]. Confidentiality (or secrecy) means that information is disclosed only according to policy, integrity means that information is not destroyed or corrupted and that the system performs correctly, availability means that system services are available when they are needed. Computing system refers to computers, computer networks, and the information they handle. Security threats come from different sources such as natural forces (such as flood), accidents (such as fire), failure of services (such as power) and people known as intruders. There are two types of intruders: the external intruders who are unauthorized users of the machines they attack, and internal intruders, who have permission to access the system with some restrictions. The traditional prevention techniques such as user authentication, data encryption, avoiding programming errors and firewalls are  \nused as the first line of defense for computer security. If a password is weak and is compromised, user authentication cannot prevent unauthorized use, firewalls are vulnerable to errors in configuration and ambiguous or undefined security policies. They are generally unable to protect against malicious mobile code, insider attacks and unsecured modems. Programming errors cannot be avoided as the complexity of the system and application software is changing rapidly leaving behind some exploitable weaknesses. Intrusion detection is therefore required as an additional wall for protecting systems. Intrusion detection is useful not only in detecting successful intrusions, but also provides important information for timely countermeasures. Intrusion detection is classified into two types: misuse intrusion detection and anomaly intrusion detection. Misuse intrusion detection uses well-defined patterns of the attack that exploit weaknesses in system and application software to identify the intrusions. Anomaly intrusion detection identifies deviations from the normal usage behavior patterns to identify the intrusion.  \nWe have two options to secure the system completely, either prevent the threats and vulnerabilities which come from flaws in the operating system as well as in the application programs or detect them and take some action to prevent them in future and also repair the damage. It is impossible in practice, and even if possible, extremely difficult and expensive, to write a completely secure system. Transition to such a system for use in the entire world would be an equally difficult task. Cryptographic methods can be compromised if the passwords and keys are stolen. No matter how secure a system is, it is vulnerable to insiders who abuse their privileges. There is an inverse relationship between the level of access control and efficiency. More access controls make a system less user-friendly and more likely of not being used. An Intrusion Detection system is a program (or set of programs) that analyzes what happens or has happened during an execution and tries to find indications that the computer has been misused. An Intrusion detection system does not eliminate the use of preventive mechanism but it works as the last defensive mechanism in securing the system. Data mining approaches are a relatively new technique for intrusion detection. There are a wide variety of data mining algorithms drawn from the fields of statistics, pattern recognition, machine learning, and databases. Previous research of data mining approaches for intrusion detection model identified several types of algorithms as useful techniques. Classification is one of the data mining algorithms, which have been investigated as a useful technique for intrusion detection models.  \nVarious intelligent paradigms namely Neural Networks [2], Support Vector Machine [3, Neuro-Fuzzy systems [4, Linear Genetic Programming [5, Flexible Neural Tree [6] 7] [8, ensemble of intelligent paradigms [22] 23] and Decision Trees [10] have been used for intrusion detection. Various data mining techniques have been applied to intrusion detection because it has the advantage of discovering useful knowledge that describes a user's or program's behavior from large audit data sets.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:36",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of using Relative Position Indexing (RPI) within the described Universal Island-based Metaheuristic Algorithm (UIMA) in conjunction with Differential Evolution (DE)?",
      "topics": [
        "search"
      ],
      "answer": "The primary objective of employing Relative Position Indexing (RPI) is to map integer-coded solutions from the UIMA framework to real-coded solutions compatible with the Differential Evolution (DE) algorithm. This mapping, defined by the relationship $RPI_{inx} = IC_{inx} / MAX_{IC}$, where $RPI_{inx}$ is the RPI index, $IC_{inx}$ is the integer-coded index, and $MAX_{IC}$ is the maximum integer-coded value, enables DE to operate on solutions generated by UIMA, which initially uses an integer-coded representation. Furthermore, the island-based metaheuristic algorithm uses parameters such as frequency of migration, number of immigrants, immigrant selection and individual removal to perform migration in island-based metaheuristic algorithms.",
      "chunk_id": 9767,
      "paper_id": "Berth scheduling at marine container terminals A universal island-based metaheuristic approach",
      "paper_title": "Berth scheduling at marine container terminals A universal island-based metaheuristic approach",
      "paper_year": "2020",
      "chunk_content": "```  \nFigure 10.\ninfeasibility. The fitness value of each trial vector is calculated in step 6 . After that, the selection operator is applied to the target vectors and the trial vectors to establish a new DE sub-population for the next iteration of UIMA (step 7). The DE sub-population, selected for the next iteration of UIMA, is updated by applying the elitism strategy in step 8. In step 9, the solutions with the real-coded representation, used by DE, are mapped back to the solutions with the integer-coded representation. In step 10, the DE sub-population is returned to UIMA.  \nSince the DE algorithm conducts operations with the real-coded solutions, the solutions, provided by UIMA that have the integer-coded representation, should be mapped to the solutions with the real-coded representation. In this study, Relative Position Indexing (RPI) will be used to map the integer-coded solutions into the realcoded solutions for the DE algorithm (Lichtblau, 2002). In Figure 11, the integer-coded vectors are mapped into the real-coded vectors using the RPI-format based on the following relationship: $R P I_{\\text {inx }}=I C_{\\text {inx }} / M A X_{I C}$, where: $R P I_{\\text {inx }}$ is the index of the vessel or the berthing position in the RPI-format; $I C_{\\text {inx }}$ is the integer-coded index of the vessel or the berthing position; and $M A X_{I C}$ is the maximum value of the integer-coded vector for the vessels or the berthing positions. In the presented example, the RPI value for vessel \" 7 \" was estimated as $7 / 7=1.00$ (\" 7 \" is the maximum value of the integer-coded vector, representing the arriving vessels), while the RPI value for berthing position \" 1 \" was estimated as $1 / 2=0.50$ (\" 2 \" is the maximum value of the integer-coded vector, representing the available berthing positions). For a detailed description of typical mutation, crossover, and selection operators, which were adopted within the DE algorithm, this study refers to Arabani et al. (2011).  \n5.2 The major parameters of universal island-based algorithm  \nIn addition to typical algorithmic parameters, which are used within the population-based metaheuristic algorithms that were adopted to search the UIMA islands, there are four other parameters/procedures, required to perform migration in island-based metaheuristic algorithms. One of the most important parameters is the frequency of migration, which determines how often the islands exchange the solutions between each other. The frequency of migration directly impacts performance of island-based metaheuristic algorithms (Alba and Tomassini, 2002). Moreover, there are three other UIMA parameters/procedures that should be properly set, including the following (Eiben and Smith, 2003):\n(1) the number of immigrants;\n(2) the individuals, which should migrate (i.e., immigrant selection); and\n(3) the individuals, which must be removed on the destination island to make enough room for the migrating individuals.  \nA detailed description of the strategies adopted for the aforementioned parameters is provided in Sections 5.2.1-5.2.4 of the manuscript.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:38",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of assembly line balancing, what is the key algorithmic difference in handling constraints between mixed-model assembly lines that use a weighted average of task times, as seen in the approach mentioned using Yagmahan (2011), versus those that consider a separate constraint for each model, like the method found in Bukchin and Rabinowitch (2006)?",
      "topics": [
        "constraints"
      ],
      "answer": "The algorithmic difference lies in how cumulative cycle time constraints for different products are addressed. Some mixed-model assembly line balancing methods, such as those described using Yagmahan (2011), use a weighted average of task times for all models to represent the constraint. In contrast, other methods, such as those described using Bukchin and Rabinowitch (2006), use a separate constraint for each model. Thus, the former aggregates the constraints, while the latter maintains individual constraints for each model.",
      "chunk_id": 11089,
      "paper_id": "Modelling and solving a cost-oriented resource-constrained multi-model assembly line balancing problem",
      "paper_title": "Modelling and solving a cost-oriented resource-constrained multi-model assembly line balancing problem",
      "paper_year": "2018",
      "chunk_content": "The literature covers two basic approaches on assembly lines with multiple models, mixed-model and multi-model assembly line balancing, see Dolgui and Battaia (2013). The main difference between a mixed-model and a multi-model line lies in the variability among the manufactured units. In a mixed-model assembly line, a single product with multiple variations (models) is assembled. While the variability among the models needs to be taken into account during line balancing, the models are scheduled in a specific order to minimise possible work overload. A classical example corresponds to an automotive assembly line in which different models (e.g. with/without sun roof) of the same car are produced. In a multi-model assembly line, differences among models are more significant and force the line to rely on batch production. An example corresponds to the line investigated in the case study, in which different garments are manufactured in a single line. In this case, line balancing takes into account distinct but similar assembly operations.  \nThe literature has mostly focused on mixed-model assembly lines (Bock 2008; Bukchin and Rabinowitch 2006; Emde, Boysen, and Scholl 2010; Kimms 2000; Yagmahan 2011, among others). These studies can be divided according to the method used to tackle the cumulative (cycle time) constraints of different products. Some methods consider a weighted average of the task times for all of the models (Yagmahan 2011) while others consider a separate constraint for each model (Bukchin and Rabinowitch 2006). Note that other approaches are possible (Bock 2008; Emde, Boysen, and Scholl 2010).  \nStudies on multi-model assembly lines are less usual, and they tend to address the disturbances caused by product changeover, like set-up times (Scholl, Boysen, and Fliedner 2008), or the buffers required for smooth operations (Chakravarty and Shtub 1985).  \nIn this work, the model considers batched production, and thus the multi-model nature of the problem is represented as cumulative constraints like in the mixed-model problem found in Bukchin and Rabinowitch (2006). Note that line balancing problems with multiple cumulative constraints have been studied in the literature, both in abstract terms (Scholl, Fliedner, and Boysen 2010) and in specific applications (Bautista and Pereira 2011).",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:40",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within the MaT-EDA framework, what specific steps are involved in measuring the similarity between task populations, and how does this similarity measurement influence the selection of assisted tasks?",
      "topics": [
        "evolutionary"
      ],
      "answer": "Within MaT-EDA, the similarity between task populations is measured using the Kullback--Leibler divergence. This divergence quantifies the difference between the probability distributions of individuals in different task populations. The intertask similarity, as quantified by the Kullback--Leibler divergence, is then synthetically considered alongside accumulated transfer rewards when assigning the assisted task. This means that tasks with lower Kullback--Leibler divergence (indicating higher similarity) are more likely to be selected as assisted tasks, promoting positive transfer between tasks.",
      "chunk_id": 3430,
      "paper_id": "Aligning heterogeneous optimization problems with optimal correspondence assisted affine transformation for evolutionary multi-tasking",
      "paper_title": "Aligning heterogeneous optimization problems with optimal correspondence assisted affine transformation for evolutionary multi-tasking",
      "paper_year": "2023",
      "chunk_content": "With the deepening of the research on EMTO, there are some emerging studies developed for many-tasking optimization problems. The main challenge in many-tasking optimization is that only a minority of composite tasks are similar [18]. The preliminary studies identify an appropriate assisted task for the current target one according to the historical performance. For example, Liaw and Ting [44] selected the task that gains the most frequent positive transfer on the target one as the next assisted task. Thanh et al. [45] employed the multi-armed bandit technique and chose the assisted task based on the reward feedback of the action. Although these methods have achieved some successes in solving many-tasking optimization problems, they ignore the intertask similarity and thus may cause negative transfer.  \nChen et al. alleviated this issue by proposing an archive-based many-tasking differential evolution (MaTDE) algorithm [18]. It first measures the similarity between the task populations according to the Kullback--Leibler divergence and then synthetically considers the intertask similarity and the accumulated transfer rewards when assigning the assisted task. Liang et al. developed an evolutionary many-task optimization algorithm based on a multi-source knowledge transfer mechanism (EMaTO-MKT) [19], which first adaptively calculates the probability of knowledge transfer on the target task according to its current evolution trend. When the knowledge transfer is triggered, EMaTO-MKT selects multiple assisted tasks using the maximum mean discrepancy measure and generates the offspring by sampling from the distribution model estimated based on the individuals from the target task and the assisted ones. More recently, Jiang et al. [46] tried to measure the intertask similarity from the perspectives of the fitness shape and the global optimal domain. Then based on the type of intertask similarity, they further configured the most\nsuitable knowledge transfer strategy for the involved tasks. By this means, the developed bi-objective knowledge transfer (BoKT) framework achieves impressive many-tasking optimization performance.  \nDespite the differences among the above algorithms, they possess the same motivation of decreasing the probability of negative transfer in many-tasking optimization. On the other hand, the intertask alignment methods can smoothly alleviate the negative transfer issue. It is thus promising to exploit the intertask alignment method to enhance the many-tasking optimization. With this consideration in mind, this study develops the many-tasking optimization algorithm MaT-EDA with the help of the proposed OCAT method.\nIn this section, we successively elaborate on the proposed OCAT and MaT-EDA methods. The general framework of OCAT is first detailed in Section 3.1, where the location of the optimal correspondences between training samples is provided. Next, the new derivation method of affine transformation is presented in Section 3.2. Then the overall implementation of OCAT and its time complexity analysis are given in Section 3.3. Finally, the whole process of MaT-EDA is described in Section 3.4.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:43",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Estimation of Distribution Algorithm (EDA) applied to power system reliability assessment, how does the algorithm reduce the sample space before evaluating system states, and what is the impact on convergence when assessing the Expected Energy Not Supplied (EENS) value?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "convergence",
        "sample space reduction",
        "reliability assessment",
        "EENS"
      ],
      "answer": "The Estimation of Distribution Algorithm (EDA) reduces the sample space by initially removing states with low failure modes that are unlikely to lead to a loss of load. Specifically, in one instance, 6,872,362 samples were removed where the total load was supplied. This reduction allows for convergence of the EENS value with significantly fewer samples; for instance, convergence was achieved with 898,763 samples, representing approximately 13% of the total available samples. The number of optimal power flow iterations required was 3500.",
      "chunk_id": 1983,
      "paper_id": "Reliability evaluation of a composite power system in the presence of renewable generations",
      "paper_title": "Reliability evaluation of a composite power system in the presence of renewable generations",
      "paper_year": "2022",
      "chunk_content": "Case 4: In this case, along with the integrating states and applying the precise uncertainty modeling for RES, the EDA algorithm has been adopted and applies to Case 3. Since the number of system modes in Case 3 was 100 and also the states of system equipment must be included, the number of required samples and the evaluation time will be unreasonable. In Case 3, the number of samples was 10 million and the time needed to evaluate the reliability was 5560 s . Here, the EDA algorithm has been used to assess the reliability indices. In this algorithm, before assessing the system states, many states with low failure modes that will not lead to loss of load are eliminated. Therefore, the remaining sample size will be significantly reduced. After this reduction, fewer samples can estimate the total probabilistic space of the problem.  \nIf the load duration curve were considered instead of the fixed load\nTable 7\nResults of the reliability evaluation in Case 3.  \n[IMAGE9]  \nFig. 9. Duration curve of wind and photovoltaic production.  \nTable 8\nResults of the reliability evaluation in Case 4.  \nTable 9\nResults of the reliability evaluation in Case 5.  \n(peak load), a large number of states would be omitted from the evaluation cycle. In other words, if in an interval of the load duration curve where the total load is much less than the installed capacity without renewable sources, the evaluation of the 100 modes of renewables will not be required. However, in this paper, the reliability assessment has been performed by considering the peak load for the whole year.  \nMoreover, at intervals where wind and photovoltaic output power levels are high, many possible network states are excluded from the reliability assessment because the load will be supplied. Therefore, in this case, $6,872,362$ samples are first removed from the samples' space of Case 3, and as a result, the remaining samples often lead to load interruption. The convergence of the EENS value with 898,763 samples has been obtained. In fact, the percentage of evaluated samples to the total number of available samples is about $13 \\%$, which has significantly reduced the time in comparison with the previous case. The number of optimal power flow iterations, in this case, is 3500 times. The simulation results of Case 4 are provided in Table 8.  \nThe results of Table 8 indicate the high computational efficiency of Case 4, while the reliability indices are not much different from the results of Case 3. Thus, the high efficiency of the EDA algorithm for improving computational efficiency with high accuracy is confirmed.  \nCase 5: In this case study, two WFs are removed from the test system, and only the PV units are considered as renewable resources. The integrating states and applying the precise uncertainty modeling for RES, the idea of the virtual generators and the EDA algorithm have been implemented for the reliability evaluation. Before evaluating the system states, a large number of states with the low possibility of failure, which certainly does not lead to loss of load, are eliminated and therefore, the samples size is significantly reduced. The reliability indices and computation time of this case are presented in Table 9.  \nThe results of Table 9 demonstrate that the reliability of PV units is higher than wind resources. Hence, the contribution of generation failure events in the reliability indices has decreased by $15 \\%$ compared to the previous case. Here, similar to Case $4,6,872,362$ samples in which total load is supplied, are initially removed from the probabilistic space.\n[IMAGE10]  \nFig. 10. Comparison of PLC index in five case studies.\n[IMAGE_11]",
      "question_type": "relationship",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:45",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the WEDA algorithm compare to classical unsupervised algorithms, specifically in terms of CPU cost and accuracy, according to the provided information?",
      "topics": [
        "performance"
      ],
      "answer": "WEDA generally requires fewer iterations to reach the same accuracy as classical unsupervised algorithms, often achieving comparable accuracy with just one internal iteration. While WEDA's global discretization method initially incurs a CPU cost, it can outperform classical approaches without necessarily requiring a high CPU cost, as only a few iterations are often needed to match or exceed their accuracies.",
      "chunk_id": 6438,
      "paper_id": "Wrapper discretization by means of estimation of distribution algorithms",
      "paper_title": "Wrapper discretization by means of estimation of distribution algorithms",
      "paper_year": "2007",
      "chunk_content": "Table 4\nSummary of the estimated predictive accuracy. Supervised approaches compared with WEDA\nWe can conclude that WEDA seems to perform better than classical unsupervised algorithms but can be less competitive than supervised approaches when the number of intervals is very high. This performance improvement is related to the use of classifier accuracy information and the global way of accomplishing discretization. But this global way of performing discretization leads to a cost in CPU that will be detailed next.  \nThe cost in CPU is the most critical aspect in our approach. In order to assess this, Figs 11 and 12 are presented. In these figures we can see the accuracy evolution over time in all datasets. The accuracy evolution showed is the average accuracy obtained in all executions performed by WEDA.  \nSeveral conclusions can be extracted from these figures. The first one is that the accuracy evolution shows that in most cases WEDA requires only one internal iteration to reach the same accuracy as some classical approaches. And with 15 iterations WEDA reaches the same accuracy as all classical approaches in all datasets, excluding those cases where WEDA is inferior. General behaviour of WEDA indicates that the cost in CPU does not need to be necessarily high to outperform classical approaches as few iterations are required to reach the same accuracies.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:47",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing a higher-order Markov chain model for level generation, as described, what programming considerations are critical for managing the probability distribution, especially given the exponential growth in data requirements?",
      "topics": [
        "search"
      ],
      "answer": "A key consideration is memory management due to the exponential growth of data needed for estimating the probability distribution in higher-order Markov chain modeling. Efficient data structures like sparse matrices or hash tables should be used to store the dependency matrices. Furthermore, techniques like pruning less probable transitions or using dimensionality reduction methods can mitigate the memory requirements. The trade-off between memory usage and the accuracy of the generated content's statistical properties needs to be carefully evaluated during implementation.",
      "chunk_id": 2200,
      "paper_id": "Using estimation of distribution algorithm for procedural content generation in video games",
      "paper_title": "Using estimation of distribution algorithm for procedural content generation in video games",
      "paper_year": "2022",
      "chunk_content": "The idea of probabilistic modeling has been explored in the context of PCG for games in several studies including quality diversity and machine learning based approaches. While not necessarily in the scope of current study, these are essentially helpful in positioning the proposed method amongst the current body of work.  \nQuality Diversity (QD) algorithms are designed to provide a set of diverse solutions with defined quality from the behaviour space of the evolutionary population rather than focusing on finding a single global optimum in the latter space [37]. These approaches have been successfully applied to the domain of digital games with MAP-Elites (short for Multi-dimensional Archive of Phenotypic ElitesME). Fontaine et al. [8] use the probabilistic modeling functionalities of Covariance Matrix Adaptation: Evolution Strategy (CMA-ES) to increase the performance of ME in searching the latent space of trained generative adversarial networks and extract interesting levels close to the work of a human. The proposed CMAME method efficiently performs maximal exploration of distorted behaviour space. However, in comparison in two domains, CMA-ES finds better individuals, but converges consistently.  \nSnodgrass et al. [38] use higher-order Markov chains to model two dimensional maps and learn statistical patterns contained in high quality human authored levels using different dependency matrices. In turn, the model is used to generate new content that exhibits the same statistical properties, with experimental validation and evaluation steps. The main challenge of this approach is in the amount of data needed to effectively estimate the probability distribution, which grows exponentially in higher-order Markov chain modeling. The main advantage of this approach is that it needs no hard-coded rules or constraints and operates solely on learned dependencies, generates diverse sets of maps, and shows good generalization in similar games. However, this method fails to replicate the overall structure of the maps, and lacks several vital DE. In the follow-up study, Snodgrass et al. [39] use three specific higher-order Markov models and turn to machine learning to exploit such models, while generalizing the resulting map generation to other games. This study highlights the performance of higher-order Markov chain models in building structural probabilistic models, which show fast sampling time favorable for online content generation, diverse sets of generated maps with mixed results that polarize the performance on two extremes of playable and aesthetically pleasing levels in  \nSMB game, compared to levels that are unplayable and unable to \"capture longrange dependencies or global attributes\" in the games Kid Icarus and Loderunner.  \nIn a similar category as the above, Guzdial et al. [40] derive probabilistic graphical models from the gameplay videos that effectively capture the level design style of the original game. In this system, an unsupervised learning technique is used to learn the geometric sprite data from level chunks categorized from the gameplay videos as input. Using unsupervised learning to infer the accurate tile placements from human-authored original levels, along with the \"level plan\" component, contributes to this method's effectiveness in capturing the semantic meaning of the level components.  \nFrom another perspective, Gonzalez-Duque et al. [41] use Bayesian optimization for the task of fast dynamic difficulty adjustment. Their system is a combination of two components, i.e. Gaussian process regression as a probabilistic regression model and an acquisition function. In detail, the system maintains a probabilistic regression model of the player, updates it based on the gameplay data and identifies the best level (using a modified acquisition function) in terms of difficulty that is suitable for the player's skill level. This method needs only a few iterations in gathering player data dynamically and adjusting the difficulty, and thus works fast with low mean error at the expense of high variance, which in overall outperforms all the baseline methods.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:48",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What constitutes a lower bound on the runtime of the compact Genetic Algorithm (cGA) with a hypothetical population size \\(\\mu\\) when applied to a function \\(\\mathcal{F}:\\{0,1\\}^{n} \\rightarrow \\mathbb{R}\\) possessing a unique global optimum?",
      "topics": [
        "search"
      ],
      "answer": "With probability \\(1-\\exp (-\\Omega(n))\\), the cGA with hypothetical population size \\(\\mu\\) has a runtime of at least \\(\\min \\left\\{\\frac{\\mu}{4}, \\exp (\\Theta(n))\\right\\}\\) on any function \\(\\mathcal{F}:\\{0,1\\}^{n} \\rightarrow \\mathbb{R}\\) with a unique global optimum. This also holds true for functions with a sufficiently small exponential number of optima.",
      "chunk_id": 9058,
      "paper_id": "The Runtime of the Compact Genetic Algorithm on Jump Functions",
      "paper_title": "The Runtime of the Compact Genetic Algorithm on Jump Functions",
      "paper_year": "2021",
      "chunk_content": "```  \nFor the case with frequency boundaries, the well-behaved frequency assumption is equivalent to $\\left(1-\\frac{2}{n}\\right)$ being an even multiple of the update step size $\\frac{1}{\\mu}$. In this case, $n_{\\mu}=\\left(1-\\frac{2}{n}\\right) \\mu \\in 2 \\mathbb{N}$ and the set of frequencies that can occur is  \n$$\nF:=F_{\\mu}:=\\left\\{\\left.\\frac{1}{n}+\\frac{i}{\\mu} \\right\\rvert\\, i \\in\\left[0 \\ldots n_{\\mu}\\right]\\right\\}\n$$  \nThis assumption was made, e.g., in the papers [35] (see the last paragraph of Section II.C) and [55] (see the paragraph following Lemma 2.1) as well as in the proof of Theorem 2 in [64].  \nA trivial lower bound: We finish this subsection on the cGA with the following very elementary remark, which shows that the cGA with hypothetical population size $\\mu$ with probability $1-\\exp (-\\Omega(n))$ has a runtime of at least $\\min \\left\\{\\frac{\\mu}{4}, \\exp (\\Theta(n))\\right\\}$ on any $\\mathcal{F}:\\{0,1\\}^{n} \\rightarrow \\mathbb{R}$ with a unique global optimum (and also on all functions with a sufficiently small exponential number of optima). This shows, in particular, that the cGA with the parameter value $\\mu=\\exp (\\Omega(k))$ used to optimize jump functions with gap size $k \\in \\omega(\\log n) \\cap o(n)$ in time $\\exp (O(k))$ in [43] cannot have a runtime better than exponential in $k$.  \nLemma 1 Let $\\alpha, \\beta \\geq 0$ be constants such that $\\alpha \\beta<\\frac{4}{3}$. Let $\\mathcal{F}:\\{0,1\\}^{n} \\rightarrow \\mathbb{R}$ have at most $\\alpha^{n}$ optima. The probability that the cGA generates an optimum of $\\mathcal{F}$ in $T=\\min \\left\\{\\frac{\\mu}{4}, \\beta^{n}\\right\\}$ iterations is at most $2\\left(\\alpha \\beta \\frac{3}{4}\\right)^{n}=\\exp (-\\Omega(n))$.  \nProof By the definition of the cGA, the frequency vector $f$ used in iteration $t=1,2,3, \\ldots$ satisfies $f \\in\\left[\\frac{1}{2}-\\frac{t-1}{\\mu}, \\frac{1}{2}+\\frac{t-1}{\\mu}\\right]^{n}$. Consequently, the probability that a fixed one of the two search points which are generated in this iteration is a fixed solution, is at most $\\left(\\frac{1}{2}+\\frac{t-1}{\\mu}\\right)^{n}$. For $t \\leq \\frac{\\mu}{4}$, this is at most $\\left(\\frac{3}{4}\\right)^{n}$. Hence by a simple union bound (over time and the global optima), the probability that an optimum is generated in the first $T=\\min \\left\\{\\frac{\\mu}{4}, \\beta^{n}\\right\\}$ iterations, is at most FORMULA_155.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:50",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the specific EDA discussed concerning the weighting factor '$\\alpha$' and population size 'N'?",
      "topics": [
        "performance"
      ],
      "answer": "The weighting factor '$\\alpha$' in the EDA controls the percentage of solutions updated based on the best candidate solutions, and a smaller value promotes a more diverse search but slows convergence. Increasing the population size 'N' can improve optimization but requires significantly more simulations; therefore, the number of generations is often reduced to manage computational cost.",
      "chunk_id": 3164,
      "paper_id": "Initial core loading pattern optimization studies using estimation of distribution algorithm for VVER type cores",
      "paper_title": "Initial core loading pattern optimization studies using estimation of distribution algorithm for VVER type cores",
      "paper_year": "2023",
      "chunk_content": "c) Weighting Factor ' $a$ '. This provides the percentage of solutions which will be updated based on best candidate LPs of previous generation.  \nThe value of $\\mathrm{N}, \\mathrm{M}$ and $\\alpha$ has been different for different problems. And it is usually required to do a few simulations to evaluate the best values of these parameters. Therefore, the study has been started first for optimizing initial parameters for EDA.  \nInitially, based on literature review (Jiang et al., 2006, Mishra et al., 2009), small value of $\\alpha=0.05$ has been chosen. The value of N was considered to be 120 and M is fixed as $20 \\%$ of N. However, it was observed that even after 300 generations the convergence was not achieved. And there appears to scope of better optimized LP. It is to be noted that the DF matrix will be modified with each generation. If the DF matrix reaches a state, where, for all fuel locations, one element out of 5 reaches a value of 1 then all the LPs generated will be same. Therefore, there will not be any benefit in going for more generations as no new LPs will generated and the same is defined as meaning convergence. Therefore, higher population size of 240 and 600 were chosen. But if computations are done for same number of generations (300), the number of simulations become very high. For example, in case of $\\mathrm{N}=$ 120 and total generations considered is 300 this means total number of simulations is $36,000(120 \\times 300)$. However, for $\\mathrm{N}=240$ or 600 , for same number of generations will require $72,000 \\& 180,000$ simulations. Therefore, cases for $\\mathrm{N}=240$ and 600 have been restricted to lesser generations of $\\sim 150$ and 100 respectively. For understanding the performance of EDA with these parameters, the average value of best 15 candidates of each generation is plotted in Fig. 7. It is to be noted that usually, multiple simulations for same case are done and average value of the best one among all these multiple solutions is plotted. However, to reduce simulations, we have avoided multiple simulations for same case. But instead of best solution, we have considered the average of best 15 solutions in each generation. This has resulted in providing a good picture of performance of algorithm without requirement of multiple runs for same case. It can be observed that, the smaller value of $\\alpha$ makes the algorithm search in different areas of search space (more diverse search). But it makes the algorithm slow to reach for a converged value. As $\\mathrm{N}=240 \\& 600$ cases have been done with lesser number of  \n[IMAGE6]  \nFig. 7. OF Vs Generation number for case I, I-a \\& I-b ( $\\mathrm{N}=120$, alpha $=0.05$, FORMULA_71 ).",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:52",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of an economic/environment load dispatch problem, what mathematical principles govern the multi-objective optimization model that considers social welfare, minimum emission, and maximum efficiency, specifically relating to the interplay between the generator bid function \\(G_i\\), consumer bid function \\(C_i\\), and the curtailment on generation \\(C_i\\)?",
      "topics": [
        "control"
      ],
      "answer": "The multi-objective optimization model aims to maximize \\(\\Sigma C_{i}(D_{i}) - \\Sigma G_{i}(P_{i}, C_{i}, L_{i})\\), which represents the ISO benefit where \\(D_i\\) is the demand of the consumer, \\(G_i\\) is the generator bid function, \\(C_i\\) is the consumer bid function, \\(P_i\\) is the power generated, \\(C_i\\) is the curtailment on generation, and \\(L\\) represents limit violation. Simultaneously, it minimizes \\(\\Sigma E m_{i}(P_{i})\\), the sum of emission functions \\(E m_i\\) of each generator, and maximizes \\(\\Sigma \\eta_{i}(P_{i})\\), the sum of the efficiencies \\(\\eta_i\\) of each generator at its operating point. The balance between these objectives is controlled by coefficients \\(\\alpha, \\beta, \\gamma\\), and \\(\\delta\\), allowing the ISO to prioritize objectives and control curtailment.",
      "chunk_id": 12529,
      "paper_id": "A Solution to Economic Dispatch Problem Using Heuristic based Optimisation Under Pool Market with Elastic Demand and Efficient Generation",
      "paper_title": "A Solution to Economic Dispatch Problem Using Heuristic based Optimisation Under Pool Market with Elastic Demand and Efficient Generation",
      "paper_year": "2016",
      "chunk_content": "The economic/environment load dispatch finds the optimal combination of the power generating schedules satisfying the demand such that the individual generators operate in/near their most efficient regions, emissions are at their lowest, and that the system runs at the minimum cost.  \nThe essential constraints considered in the model are; Equation (2), the power balance constraint where power produced by generators is consumed by customers. Equation (3), the power limit constraints i.e. the generators operate  \nwithin their specified range and equation (4), a limit to the maximum allowed curtailment given by the $C^{\\max }$ [1].  \nList of Constraints:  \n$$\n\\begin{gathered}\n\\Sigma G_{i}=\\Sigma D_{i} \\\\\nP_{i}{ }^{\\min }<G_{i}<P_{i}^{\\max } \\\\\n\\Sigma C<C^{\\max }\n\\end{gathered}\n$$  \n$C^{\\max }=\\Sigma$ (maximum limit of requested demand) $-\\Sigma$ (minimum limit of requested demand).  \nThe concept entails curtailment on both generators and consumers and does not concern the revenue loss suffered by the GENCOs, TRANSCOs and DISCOMs. It is tested on a 3 generator 2 load system. Generators in the system are assumed to be diesel in nature.  \nThe success of market dictated utility operation requires the bids to reflect the true costs of generation and demand bids [8]. Therefore the assumed generating cost function is of the form given in equation (5).  \n$$\n\\begin{gathered}\nG_{i}=a P_{i}^{2}+b P_{i}+c+P e n_{i} \\\\\nP e n_{i}=F\\left(C_{i}, L_{i}\\right)\n\\end{gathered}\n$$  \nF is the penalty function as decided by the ISO as in equation (6). The consumer benefit function is represented in equation (7).  \n$$\nC_{i}=p D_{i}^{2}+q D_{i}+r\n$$  \nThe emissions function given in equation (8) is also assumed to be a quadratic[16].  \n$$\nE m_{i}=I P_{i}^{2}+m P_{i}+n\n$$  \nThe coefficients of the equations (5), (7) and (8) are given in Tables I and II. Both minimization of emission as well as reduction of fuel cost is required for the optimal production of power. This economic/environmental dispatch problem deals with competing objectives such that some reasonable trade off between the two objectives is made. [2] [15].  \nThe multi-objective optimization model considers the following objectives (1) Social Welfare with desired operating conditions given by equation (9) [1], (2) Minimum Emission given by equation (10) and (3) Maximum efficiency in equation (11). The efficiency of the generator is taken from individual generator's efficiency vs. load curve to identify the high efficiency regions.  \n$$\n\\text { ISO benefit }=\\Sigma C_{i}\\left(D_{i}\\right)-\\Sigma G_{i}\\left(P_{i}, C_{i}, L_{i}\\right)\n$$  \nWhere: $D_{i}=$ Demand of Consumer\n$G_{i}$ : Generator bid function of $i^{\\text {th }}$ generator\n$C_{i}$ : Consumer bid function of the $i^{\\text {th }}$ consumer\n$P_{i}$ : Power Generated by $i^{\\text {th }}$ generator\n$C_{i}$ : The Curtailment On generation\n$L:$ Limit violation  \n$$\nA=\\operatorname{Min}\\left(\\Sigma E m_{i}\\left(P_{i}\\right)\\right)\n$$  \nWhere: $E m_{i}=$ Emission function of $i^{\\text {th }}$ generator  \n$$\nB=\\operatorname{Max}\\left(\\Sigma \\eta_{i}\\left(P_{i}\\right)\\right)\n$$  \n$\\eta_{i}=$ efficiency of $i^{\\text {th }}$ generator at its operating point\nThe model is tuneable and ISO is at liberty to decide the priority of the schedules as in equation (12) and therefore can alter the coefficients of the augmented objective function i.e. $\\alpha, \\beta$, and $\\gamma$ to alter the focus of the algorithm among the objectives and $\\delta$ to control amount of curtailment and thereby to control his economic losses born out of curtailment.  \nFORMULA_44  \nTABLE I. COEFFICIENT OF GENERATOR AND CONSUMER BID FUNCTIONS[8]  \nTABLE II. COEFFICIENTS OF EMISSION FUNCTION [2]",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:00:55",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm with an adaptive univariate model, how should practitioners utilize Algorithm ProbMod to compute the probability \\(p(x_i; t)\\) for the \\(i\\)-th component \\(x_i\\) at generation \\(t\\), and what considerations are necessary when setting the parameter \\(\\epsilon\\)?",
      "topics": [
        "search"
      ],
      "answer": "To compute the probability \\(p(x_i; t)\\) using Algorithm ProbMod, first determine \\(\\ell_{i}^{\\min}\\) and \\(\\ell_{i}^{\\max}\\) as the minimum and maximum values of the \\(i\\)-th dimension within the selected population \\(\\mathcal{P}^{s}(t)\\). Then, assign a small probability to the intervals \\([\\ell_{i}^{\\min} - \\epsilon, \\ell_{i}^{\\min}]\\) and \\([\\ell_{i}^{\\max}, \\ell_{i}^{\\max} + \\epsilon]\\), and a larger probability to the interval \\([\\ell_{i}^{\\min}, \\ell_{i}^{\\max}]\\). The parameter \\(\\epsilon\\), a small positive real number, expands the search space to moderate premature convergence. When setting \\(\\epsilon\\), practitioners must balance exploration and convergence; a larger \\(\\epsilon\\) promotes exploration but may slow convergence, while a smaller \\(\\epsilon\\) accelerates convergence but risks premature convergence.",
      "chunk_id": 7309,
      "paper_id": "A novel memetic algorithm for constrained optimization",
      "paper_title": "A Novel Memetic Algorithm for Constrained Optimization",
      "paper_year": "2010",
      "chunk_content": "Existing EDAs for real variables can be classified with respect to the probability model $p(x ; t)$. In those EDAs, the assumed probability models include a Gaussian distribution [18], a Gaussian mixture [39], and a histogram [40][41]. In this paper, we propose to construct an adaptive univariate model. This model is assumed to be fully factorized over the variables, i.e. $p(x ; t)=\\prod_{i=1}^{n} p\\left(x_{i} ; t\\right)$. Moreover, we propose to adaptively shrink the search space in order to increase the exploration speed of the EDA.  \nSuppose that at generation $t$, the selected population consists of $\\mathcal{P}^{s}(t)=\\left\\{x^{1}(t), x^{2}(t), \\cdots, x^{K}(t)\\right\\}$ where $K$ is the size of the selected population. For the $i$-th dimension, $p\\left(x_{i} ; t\\right)$ is computed as described in Algorithm ProbMod.  \nOne can imagine that along with the evolution procedure, the search space will be adaptively shrink. This can increase the evolution search speed, but will inevitably cause premature convergence problems. To moderate this problem, in the adaptive univariate model, we use a predefined small positive real number $\\epsilon$ to expand the search space at each dimension. Moreover, the premature convergence problem can also be moderated by using a multiple sampling strategy.  \nTo our best knowledge, in almost all EDAs, the sampled offspring size is usually less than, or equal to, the population size. However, it is well known that to accurately characterize $p(x ; t)$, a large sampling size is needed. Therefore,\nInput: The selection population $\\mathcal{P}^{s}(t)$\nOutput: The probability $p\\left(x_{i} ; t\\right)$ for the $i$-th component $x_{i}$.  \n1. Find $\\ell_{i}^{\\min }\\left(\\ell_{i}^{\\max }\\right)=\\min (\\max )\\left\\{x_{i}^{k}(t), 1 \\leq k \\leq K\\right\\}$;\n2. Assign a small probability to the intervals $\\left[\\ell_{i}^{\\min }\\right.$ $-\\left.\\epsilon, \\ell_{i}^{\\min }\\right]$ and $\\left[\\ell_{i}^{\\max }, \\ell_{i}^{\\max }+\\epsilon\\right]$, and a big probability to $\\left[\\ell_{i}^{\\min }, \\ell_{i}^{\\max }\\right]$.",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:00:57",
      "generation_style": "practical_application"
    },
    {
      "question": "What are the two stopping conditions for the EDA-LGD, CMA-ES, and xNES algorithms described, and what are their specific thresholds?",
      "topics": [
        "search"
      ],
      "answer": "The three algorithms, EDA-LGD, CMA-ES, and xNES, stop when either the maximum number of function evaluations is reached, specifically \\(10^4 \\times d\\), where \\(d\\) represents the dimension of the problem, or when the target error is smaller than \\(10^{-8}\\).",
      "chunk_id": 926,
      "paper_id": "A New EDA by a Gradient-Driven Density",
      "paper_title": "A New EDA by a Gradient-Driven Density",
      "paper_year": "2014",
      "chunk_content": "This section contrasts the proposed EDA against two known Evolutionary Algorithms based on multivariate densities: CMA-ES [3] and xNES [2]. Each algorithm runs in 10 benchmark problems, see Table 1 In order to make a fair comparison, the code was downloaded from authors homepage and 50 runs were performed. Also, the initial center of densities was chosen randomly in the search domain with an initial variance according to the domain ( $1 / 3$ of this). The three algorithms only have two stopping conditions: maximum number of evaluations of function is reached $\\left(10^{4} \\times d\\right)$, or target error smaller than $10^{-8}$,  \n1: $t \\leftarrow 0, \\beta \\leftarrow 0.5, N \\leftarrow\\left\\lceil 4+\\left(1+d^{0.7}\\right)\\right], M \\leftarrow 2 *\\lfloor\\log (d)\\rfloor+1, r \\leftarrow d+1$\n2: $\\operatorname{POb}_{t} \\leftarrow \\mathcal{U}$ (Domain), compute $\\mathcal{F}\\left(\\boldsymbol{x}^{(i)}\\right)$, find the $\\boldsymbol{x}^{\\text {best }} \\quad \\triangleright$ First population\n3: $P_{\\text {best }} \\leftarrow$ Best $r+2$ individuals from $\\operatorname{POb}_{t} \\quad \\triangleright$ Historical best population\n4: while (Stop condition is not reached) do\n5: $\\quad$ Gradient estimate $G\\left(\\boldsymbol{x}^{\\text {best }}\\right)=\\widehat{\\nabla \\mathcal{F}}\\left(\\boldsymbol{x}^{\\text {best }}\\right)$ with neighborhood $\\left\\{P_{\\text {best }} \\backslash \\boldsymbol{x}^{\\text {best }}\\right\\}$\n6: $\\quad$ Normalized vector $\\boldsymbol{x}_{G}^{\\text {best }}$ by (9) or negative for minimization\n7: $\\quad$ Empirical estimation of $\\widehat{\\boldsymbol{\\mu}}$ and $\\widehat{\\boldsymbol{\\Sigma}}$. Initial covariance $\\boldsymbol{\\Sigma}_{0}=\\operatorname{diag}(\\operatorname{diag}(\\widehat{\\boldsymbol{\\Sigma}}))$\n8: $\\quad$ Parameters $\\boldsymbol{\\mu}_{g}$ and $\\boldsymbol{\\Sigma}_{g}$ by definition 4. Parameters $\\boldsymbol{\\mu}^{\\text {new }}$ and $\\boldsymbol{\\Sigma}^{\\text {new }}$ by (15)\n9: $\\quad \\circ \\mathcal{S} \\leftarrow$ Simulate $M$ individuals from $\\mathcal{N}\\left(\\boldsymbol{x} ; \\boldsymbol{\\mu}^{\\text {new }}, \\boldsymbol{\\Sigma}^{\\text {new }}\\right)$\n10: $\\quad \\circ \\mathcal{S} \\leftarrow \\operatorname{Reinsertion}(\\mathcal{S}) \\quad \\triangleright$ if-outside-domain\n11: $\\quad$ Fitness values $\\mathcal{F}(\\mathcal{S})$\n12: $\\quad \\circ \\operatorname{POb}_{t+1} \\leftarrow$ Best individuals among $\\left\\{\\operatorname{POb}_{t}, \\mathcal{S}\\right\\}$\n13: $\\quad$ Find the $\\boldsymbol{x}_{t+1}^{\\text {best }}$ of $\\operatorname{POb}_{t+1}$\n14: if $\\boldsymbol{x}_{t+1}^{\\text {best }}$ has better fitness value than $\\boldsymbol{x}^{\\text {best }}$ then\n15: $\\quad \\boldsymbol{x}^{\\text {best }} \\leftarrow \\boldsymbol{x}_{t+1}^{\\text {best }}$ and $\\boldsymbol{x}_{t+1}^{\\text {best }}$ replaces the worst individual in $P_{\\text {best }}$\n16: end if\n17: $\\quad \\circ M_{\\text {sur }} \\leftarrow$ Number of survivors from $\\mathcal{S}$ into $\\operatorname{POb}_{t+1}$\n18: if $\\frac{M_{\\text {sur }}}{M}>1 / 2$ then\n19: $\\quad \\beta \\leftarrow \\beta+0.05$; if $\\beta>1$ then $\\beta=1 \\quad \\triangleright$ Exploration\n20: else\n21: $\\quad \\beta \\leftarrow \\beta-0.05$; if $\\beta<0$ then $\\beta=0 \\quad \\triangleright$ Exploitation\n22: end if\n23: $\\quad t \\leftarrow t+1$\n24: end while\nFig. 2. Pseudocode of the EDA led by a Gradient-driven Density (EDA-LGD)\nTable 1. Benchmark problems [2] [5]. The minimum fitness value of all problems is 0 , except for $\\mathcal{F}_{4}, \\mathcal{F}_{6}$ and $\\mathcal{F}_{10}$ where $\\mathcal{F}_{4}^{*}=2, \\mathcal{F}_{6}^{*}=-10$ and FORMULA_193.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:00:59",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How do the Iterative Distribution Generation (IGD) values of RM-MEDA compare to DES-RM-MEDA, and what algorithmic difference is suggested to explain this performance?",
      "topics": [
        "design"
      ],
      "answer": "Based on the statistical results of the IGD values, DES-RM-MEDA achieves better performance than RM-MEDA on the tested instances. The improved performance is attributed to the Differential Evolution based Sampling (DES) scheme's ability to generate more diverse points compared to the Latin square design method when sampling new solutions in the latent space.",
      "chunk_id": 12512,
      "paper_id": "Sampling in Latent Space for a Mulitiobjective Estimation of Distribution Algorithm",
      "paper_title": "Sampling in Latent Space for a Mulitiobjective Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "This paper proposed a differential evolution based sampling (DES) scheme to generate points in the latent space. The basic idea is to project the parent solutions into the latent space, use a DE mutation operator to generate new points in the latent space based on the projected points, and finally map the points back to the decision space added with the Gaussian noise  \nTABLE I\nStatistical results of the IGD values of the final populations obtained by RM-MEDA and DES-RM-MEDA on the 10 test instances over 30 runs.  \nFORMULA_154 The bolder ones mean better.\nto generate offspring solutions. The DES scheme is applied in RM-MEDA. A preliminary study has indicated that the DES scheme outperforms the Latin square design method on sampling new solutions. The reason might be that DES can generate more diverse points than the Latin square design.  \nThe preliminary study in this paper has shown the possibility to do reproduction in the latent space, which has much lower dimension than the decision space. There still needs much work to investigate the latent space sampling strategy, and possible directions include: (a) trying other reproduction operators in the latent space, and (b) applying the DES scheme to other MOEAs.\nThis work is supported by China National Instrumentation Program under Grant No.2012YQ180132, the National Natural Science Foundation of China under Grant No.61273313, and the Science and Technology Commission of Shanghai Municipality under Grant No.14DZ2260800.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:00",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EA/G-IR approach for MWDS, specifically detailing how the population is updated and modified throughout the generations?",
      "topics": [
        "fitness"
      ],
      "answer": "The EA/G-IR approach begins by initializing a population, denoted as \\(pop(g)\\), of \\(N{r}\\) solutions, where \\(N{r}\\) is divisible by 4. A probability vector \\(p\\) is initialized for all nodes using Algorithm 2. The algorithm selects the best \\(N{r}/2\\) solutions from \\(pop(g)\\) to form a parent set, parent\\((g)\\), and updates the probability vector \\(p\\) using Algorithm 3. The GM operator is applied \\(N{r}/2\\) times on the best solution \\(b{v}\\) in parent\\((g)\\) to generate \\(N{r}/2\\) new solutions. A repair operator and an improvement operator are applied to each newly generated solution. The new population \\(pop(g+1)\\) is formed by combining the \\(N{r}/2\\) newly generated solutions with the best \\(N{r}/2\\) solutions from parent\\((g)\\). If all solutions in the population are identical, \\(pop(g)\\) is reinitialized, and the algorithm returns to updating the probability vector \\(p\\). Otherwise, the algorithm iterates from the selection of parent solutions.",
      "chunk_id": 4618,
      "paper_id": "A hybrid evolutionary algorithm with guided mutation for minimum weight dominating set",
      "paper_title": "A hybrid evolutionary algorithm with guided mutation for minimum weight dominating set",
      "paper_year": "2015",
      "chunk_content": "Algorithm 7: EA/G-IR Approach for MWDS\n1 At generation \\(g \\leftarrow 0\\), an initial population \\(p o p(g)\\) consisting of \\(N{r}\\) solutions \\(\\left(N{r}\\right.\\) should be divisible by 4) are generated in a manner described in Section 5.2;\n2 Initialize the probability vector \\(p\\) for all nodes using Algorithm 2;\n3 Select best \\(\\frac{N{r}}{2}\\) solutions from \\(\\operatorname{pop}(g)\\) to form a parent set parent \\((g)\\), and then\nupdate the probability vector \\(p\\) using Algorithm 3;\n4 Apply the GM operator \\(\\frac{N{r}}{2}\\) times on the best solution \\(b{v}\\) in parent \\((g)\\) in order to\ngenerate \\(\\frac{N{r}}{2}\\) new solutions. A repair operator is applied to each generated\nsolution, if necessary, and then an improvement operator is applied to each\ngenerated solution to improve the solution fitness. Add all \\(\\frac{N{r}}{2}\\) newly generated\nsolutions along with best \\(\\frac{N_{r}}{2}\\) parent \\((g)\\) solutions to form \\(\\operatorname{pop}(g+1) \\text {. If the }\\) stopping condition is met, return the dominating set with the minimum weight found so far ;\n\\(g \\leftarrow g+1 ;\\)\n6 If all solutions are identical, then reinitialize \\(\\operatorname{pop}(g)\\), and go to step 2 ;\n7 Go to step 3 ;\n```",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:03",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of mass spectrometry data preprocessing, what statistical measure is used to determine if a candidate peak meets the required signal-to-noise ratio (SNR) threshold?",
      "topics": [
        "comparison"
      ],
      "answer": "The peak's SNR is computed as the ratio between the point's height and the median absolute deviation (MAD) in the intensity window under consideration. A candidate peak must have an SNR higher than or equal to 3 within its associated intensity window to be considered valid.",
      "chunk_id": 11850,
      "paper_id": "Peakbin Selection in Mass Spectrometry Data Using a Consensus Approach with Estimation of Distribution Algorithms",
      "paper_title": "Peakbin Selection in Mass Spectrometry Data Using a Consensus Approach with Estimation of Distribution Algorithms",
      "paper_year": "2011",
      "chunk_content": "Within the MS domain, the preprocessing stage is an elementary and critical part of the design analysis protocol (DAP [17]). The DAP stage converts the data from its raw, initial form into a compact and homogeneous matrix forming the input for subsequent methods, such as machine learning or pattern recognition techniques. Thus, the main  \n[^0]objective of the preprocessing task is to clean the data and detect the true signals in the noisy spectra.  \nMS data pose similar problems to most classical signal processing problems. Additionally, since the sample composition is often unknown or overly complex, the original signal decomposition is unknown. There have been attempts to mathematically model the true signal in a MS experiment but with limited or no success. The most accepted formulation is shown in Equation 1:  \n$$\nf(t)=B(t)+N \\cdot S(t)+\\varepsilon(t)\n$$  \nThe first term $f(t)$ is the observed signal. $B(t)$ is a visually identifiable additive baseline component, and $S(t)$ is the expected true signal, which is modified by a normalization factor $N$. The last element $\\varepsilon(t)$ is an unknown noise component that groups the remaining variations.  \nAlthough there is no standard preprocessing pipeline for MS data, the most accepted dataflow core stages are: baseline removal or correction, interspectra normalization, signal noise reduction or smoothing, peak detection, and finally peak alignment. Since there is no standard preprocessing pipeline, we have reviewed the state-of-the-art methods and decided which are the most suited to our data domain. In the cases where selected methods have been modified or augmented, we include a brief description of the changes.  \nIn order to remove the low-range noise, we propose the use of the top-hat filter operator [18], [19] as the baseline correction method. A normalization task converts all the spectra signals to the same intensity ranges, so a fair comparison can be made among them. The use of local estimators over $m / z$ windows with rescaling to the median value of the total ion count (TIC) is suggested for this aim [20]. The next processing step consists of smoothing the signal wave from the input signal to avoid the low signal fluctuations. The most common signal smoothing technique is wavelet denoising proposed by [12], [21], and implemented in the Cromwell package. ${ }^{2}$  \nThe following task comprises the identification of peaks in the signal, or peak detection. This detection is individually applied to each separate spectrum, and then, a list of candidate peaks is retrieved for each spectrum. The peak detection algorithm proposed in [22] is borrowed as the starting point. To make the detection more restrictive, we have included two constraints into the algorithm: 1) the signal value of a candidate peak must be higher than a sensitivity threshold, and 2) a candidate peak must have an SNR higher than or equal to 3 within its associated intensity window [23]. The peak SNR is computed as the ratio between the point's height and the median absolute deviation (MAD) in the window under consideration, as suggested in [24].  \nLastly, the peak assembly or alignment tries to match similar peaks detected across all spectra. There is no definite order in which this and the former (peak detection) tasks should be performed: peak alignment followed by peak detection [12] or vice versa [25]. To overcome signal shifts and potentially isotopic formations or very close compounds, we propose to assemble peakbins of different widths. Our preprocessing pipeline uses the Pearson linear  \n[^1]\n[^0]:    1. See supplementary content page, which can be found at http:// www.sc.ehu.es/cowbayes/members/ruben/ms.  \n2. http://bioinformatics.mdanderson.org/cromwell.html.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:04",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs that incorporates an insert-neighborhood-based local search?",
      "topics": [
        "control"
      ],
      "answer": "The primary purpose is to refine solutions generated within the Estimation of Distribution Algorithm by applying a local search with a probability of $pls$. This local search utilizes an insert-neighborhood strategy to improve solutions, while avoiding more complex algorithms like taboo search or simulated annealing to maintain simplicity and reduce the number of parameters.",
      "chunk_id": 8531,
      "paper_id": "Migrating Birds Optimization for Lot-streaming flow shop scheduling problem",
      "paper_title": "Migrating Birds Optimization for Lot-streaming flow shop scheduling problem",
      "paper_year": "2019",
      "chunk_content": "In this work, the purpose of the local search is to generate a better solution from the neighborhood of a given solution. We adopt an insert-neighborhood-based local search [14], which has been regarded as superior to the swap or exchange neighborhood. Furthermore, we try to present a simple algorithm with few parameters, so some relative algorithms such as taboo search and simulated annealing algorithm are not applied. In this paper, we apply the local search to the solutions generated in subsection 4.3 with a small probability of $p l s$ (parameter $p l s$ controls whether the solution undergoes the local search or not). That is, a uniform random number $r$ is generated from 0 and 1 , if $r=p l s$, the solution will employ the local search. Otherwise, the solution does not perform the local search.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:06",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of constructing a probabilistic model to estimate the probability distribution of promising solutions fundamentally differ from simply aiming for a perfect representation of the current best solutions in the population?",
      "topics": [
        "selection"
      ],
      "answer": "EDAs, unlike other metaheuristic methods, explicitly construct a probabilistic model to capture the distribution of promising solutions. This model-building process in EDAs doesn't seek a perfect representation of the current top solutions, but rather aims for a more general distribution that captures the functionality of chosen solutions, making them superior to other candidates. The process starts with an initial population generated from a uniform distribution and selected based on a selection factor $P_m$, as shown in Algorithm 1. For example, the top $60\\%$ of the population is selected. The distinction lies in creating a model that generalizes beyond the current best to enable efficient sampling of new, potentially better solutions in subsequent generations, rather than merely replicating the characteristics of the existing elite population. This model is iteratively refined until a maximum number of iterations, denoted as Miter, is reached, using a fitness function $f$ to evaluate solutions $\\boldsymbol{X}$.",
      "chunk_id": 8552,
      "paper_id": "Estimation of Distribution Algorithm Based on Levy Flight for Solving the Set-Union Knapsack Problem",
      "paper_title": "Estimation of Distribution Algorithm Based on Levy Flight for Solving the Set-Union Knapsack Problem",
      "paper_year": "2019",
      "chunk_content": "EDAs are EAs that are stochastic optimization algorithms. They explore the space of potential solutions by using the constructed explicit probabilistic model to find the most promising solution. In EDAs, there is no traditional crossover or mutation. Usually, EDAs start with the initial population that is generated based on a uniform distribution in the  \nsolution space. Then, the population is evaluated using the fitness function, and the population is sorted according to the fitness function. For example, from the sorted population, when we use $60 \\%$ as the selection operator, the subset of the top $60 \\%$ best solutions is selected. The probabilistic model is constructed using the selected solution method in order to estimate the probability distribution of the solution. Once a probabilistic model has been established, some new solutions can be sampled based on this probabilistic model and a new population can be generated. Until the termination conditions are met, we repeat this process, and each iteration is usually called a generation of the EDAs. The basic procedure of EDAs is shown in Algorithm 1. Here, $N P$ is the population size, $\\boldsymbol{X}$ is the $n$-dimensional vector, Miter is the maximum number of iterations, $P_{m}$ is the selection factor, $\\boldsymbol{B}$ is the optimal solution, and the function $f$ is the fitness value.  \n  \nAn important step in distinguishing EDAs from many other metaheuristic methods is the construction of the model and the attempt to capture the probability distribution of a promising solution. This task is not trivial because the goal is not a perfect representation of a promising solution for the population, but rather a more general distribution that captures the functionality of the chosen solution and makes it better than any other candidate. In addition, we must ensure that models are efficiently built and sampled.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:08",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners perform the modeling-based reproduction step in RM-MEDA?",
      "topics": [
        "selection"
      ],
      "answer": "In RM-MEDA, modeling-based reproduction involves first partitioning the population P(t) into K disjoint clusters using the Local PCA algorithm. Then, a probability model is built for each cluster. Finally, N new solutions are sampled from these models to form Q(t).",
      "chunk_id": 1237,
      "paper_id": "Improved RM-MEDA with local learning",
      "paper_title": "Improved RM-MEDA with local learning",
      "paper_year": "2014",
      "chunk_content": "We hope that the solution set in decision space in a MOEA for Eq. (1) will approximate the PS as close as possible and at the same time, can locate around the PS. Figure 1 illustrates the distribution of solutions in the decision space in a successful MOEA. So the solution in the population can be supposed as an independent observation of a random vector $\\xi \\in R^{n}$ whose central is the PS. As indicated in the theoretical basic, the PS of MOEA for Eq. (1) is an $(m-1)$-dimensional piecewise continuous manifold, therefore $\\xi$ can be described by\n$\\xi=\\xi+\\varepsilon$\nwhere $\\xi$ is uniformly distributed over the manifold, and $\\varepsilon$ is an n-dimensional zero-mean noise vector.  \nAccording to the regularity of the Pareto set discussed above, RM-MEDA builds the probability model. In the procedure of the modeling-based reproduction, the population $P(t)$ is first partitioned into K disjoint clusters by Local PCA algorithm (Kambhatla and Leen 1997). And then a model for Eq. (5) is built for each cluster. Finally new solutions are sampled from these models. Figure 2 shows the procedure of RM-MEDA and the detail of each steps can be further studied in Zhang et al. (2008). In the following figure, $N$\n[IMAGE0]  \nFig. 1 The solutions distribution in the decision space in a successful MOEA  \nProcedure 1:\nStep1 Initialize: Initialize the population $P(t)$ and evaluate $P(t), \\mathrm{t}=0$.\nStep2 Modeling-based Reproduction:\ni). Learn the distribution of the solutions in $P(t)$ and build the probability model.\nii). Sample $N$ individuals from the probability model and merge them into $Q(t)$.  \nStep3 Evaluation: Evaluate $Q(t)$.\nStep4 Selection: Select $N$ solutions from $P(t) \\cup Q(t)$ to create $P(t+1)$ by NDS-Selection method, $\\mathrm{t}=\\mathrm{t}+1$.\nStep5 Stopping Condition: If the stop condition is satisfied, then output the Pareto solutions from $P(t+1)$, otherwise go to Step2.  \nFig. 2 The procedure of RM-MEDA  \n```\nProcedure 2:\nStep1 Initialize: Initialize the population \\(P(t)\\) and evaluate \\(P(t), \\mathrm{t}=0\\).\nStep2 Sort: Sort \\(P(t)\\) with the fast nondominated sorting approach [9].\nStep3 Local Learning Reproduction:\ni). Select an elitist individual \\(X\\) from \\(P(t)\\) with tournament selection [50].\nii). If \\(X\\) is a Pareto solution, then set the length coefficient as \\(r\\), else set the length coefficient as \\(2 r\\).\niii). Sample an individual solution from \\(B r\\) randomly and merge it into \\(Q(t)\\).\niv). Return to i) until \\(\\theta \\times N\\) solutions are generated by local learning.\nStep4 Modeling-based Reproduction: Sample \\((1-\\theta) \\times N\\) individuals by modeling-based reproduction and\nmerge them to \\(Q(t)\\).\nStep5 Evaluation: Evaluate \\(Q(t)\\).\nStep6 Selection: Select \\(N\\) solutions from \\(P(t) \\cup Q(t)\\) to create \\(P(t+1)\\) by NDS-Selection method, \\(\\mathrm{t}=\\mathrm{t}+1\\).\nStep7 Stopping Condition: If the stop condition is satisfied, then output the Pareto solutions from \\(P(t+1)\\),\notherwise go to Step3.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:10",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the deployment of UmBSs (UAV-mounted base stations), how does increasing the transmission bandwidth $\\mathcal{B}_{i}$, where $\\mathcal{B}_{i}$ can be 25, 50, or 75 Mbps, affect both the number of UmBSs required and the percentage of MUs (mobile users) served, considering that the transmission bandwidth is directly related to $\\Re_{i}$?",
      "topics": [
        "analysis"
      ],
      "answer": "Increasing the transmission bandwidth $\\mathcal{B}_{i}$ of the UmBSs leads to a decrease in the number of UmBSs required. However, it also results in a significant reduction in the percentage of MUs served. This trade-off occurs because the transmission bandwidth of the UmBS is directly related to $\\Re_{i}$, and an increase in $\\mathcal{B}_{i}$ increases the value of $\\Re_{i}$, thus increasing the value of $\\phi$ and $\\psi$. Due to the random distribution of MUs, there aren't many places where UmBSs can be deployed to meet the higher values of $\\phi$. When the service area becomes crowded, the difference between the percentage of MUs covered by UmBS with low transmission bandwidth and those covered by high transmission bandwidth becomes smaller. Deploying UmBSs with larger bandwidth is beneficial in terms of the number of UmBSs required, but it is detrimental in terms of the percentage of MUs served, potentially not meeting the predefined threshold of MUs served.",
      "chunk_id": 3250,
      "paper_id": "FRAT a fuzzy rule based adaptive technique for intelligent placement of UAV-mounted base station",
      "paper_title": "FRAT: a fuzzy rule based adaptive technique for intelligent placement of UAV-mounted base station",
      "paper_year": "2023",
      "chunk_content": "```  \n$\\mathcal{B}_{i}=\\{25,50,75\\}$ where values are in Mbps. Figure 2 illustrates how the number of UmBSs required and the percentage of MUs served get affected when the number of MUs seeking network service varies from 40 to 200 with each set of bandwidth. Here, we fix the value of $h_{i}=120 \\mathrm{~m}$ and $\\zeta=20$. As shown in Fig. 2, the number of UmBSs required to serve different sets of MUs decreases with the increase in the UmBS bandwidth. However, it can also be noticed that there is a significant reduction in the percentage of MUs served. The reason behind this is that the transmission bandwidth of the UmBS is directly related to the $\\Re_{i}$ so an increase in the bandwidth increases the value of $\\Re_{i}$ thus increasing the value of $\\phi$ and $\\psi$ too. Due to the random distribution of MUs in the service area, there aren't many places where UmBSs can be deployed to meet the higher values of $\\phi$. However, it is important to notice that when the service area becomes crowded, the difference between the percentage of MUs covered by UmBS with low transmission bandwidth and those covered by high transmission bandwidth becomes smaller. Figure 3 illustrates the number of UmBSs with different bandwidths required to serve 120 MUs when the $h_{i}$ varies from 40 to  \n200 m . As shown in Fig. 3, with the deployment of UmBS at lower altitudes, we can serve a greater percentage of MUs with a smaller number of UmBSs with all values of bandwidth. This is because the lower height of the UmBS\n[IMAGE2]  \nFig. 2 Analysis of required UmBSs and percentage of MU serve as a function of bandwidth with varying number of MUs with $\\zeta=20, h_{i}=120 m$  \n[IMAGE3]  \nFig. 3 Analysis of required UmBSs and percentage of MU serve as a function of bandwidth with varying height of UmBS with $\\zeta=20, \\mathcal{K}=120$\nleads to higher values of received SINR at MU. Figure 4 plots the number of UmBS required and the percentage of MUs served when the $\\phi$ varies from 10 to $90 \\%$. From Fig. 4, it can be seen that the deployment of UmBSs with larger bandwidth is beneficial in terms of the number of UmBSs required, but it is detrimental in terms of the percentage of MUs served. A large portion of MUs remains unserved. The percentage of MU served does not meet the predefined threshold of MUs served. Meanwhile, from Fig. 4, it is also important to note that, even though the use of UmBS with less bandwidth means more UmBSs are needed, it is good in terms of MUs served.\n[IMAGE4]  \nFig. 4 Analysis of required UmBSs and percentage of MU serve as a function of bandwidth with varying minimum MU coverage with $h_{i}=120 \\mathrm{~m}, \\mathcal{K}=120$\n[IMAGE5]  \nFig. 5 Number of UmBSs required and percentage of MU serve with varying number of MUs with FORMULA_188",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:12",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What algorithmic trade-off exists between GMDEDA and HGMDEDA concerning the Generalized Mallows Distribution (GMD) when scaling to a larger number of vertices in the school bus routing problem?",
      "topics": [
        "algorithm"
      ],
      "answer": "The text suggests that while both GMDEDA and HGMDEDA leverage the Generalized Mallows Distribution to estimate the probability of bus stop $i$ being chosen at sequence position $j$, GMDEDA's performance may degrade when constructing larger sequences (i.e., more vertices) without hybridization. This implies a trade-off where HGMDEDA, presumably through its hybridization, mitigates the limitations of GMDEDA in larger problem instances, suggesting GMD alone becomes a disadvantage as the number of vertices increases.",
      "chunk_id": 7059,
      "paper_id": "An estimation of distribution algorithm coupled with the generalized Mallows distribution for a school bus routing problem with bus stop selection",
      "paper_title": "An estimation of distribution algorithm coupled with the generalized Mallows distribution for a school bus routing problem with bus stop selection",
      "paper_year": "2017",
      "chunk_content": "Basados en los resultados descritos en la seccion previa no es necesario reparar las soluciones como otros algoritmos que se han utilizado para problemas de optimizacion basados en permutaciones. El GA y el UMDA emplean operadores especificos para mantener la diversidad en el progreso evolutivo. Estos operadores son utiles en problemas de optimizacion basados en permutaciones, pero no son capaces de construir una distribucion de probabilidad explicita en el dominio de las rutas de transporte escolar. Podemos considerar que una ventaja del GMDEDA y del HGMDEDA es que toman en consideracion la GMD para resolver esta situacion. Gracias al uso de la GMD es posible estimar la probabilidad de que la parada $i$ sea elegida en la posicion $j$ de la secuencia; sin embargo, para construir secuencias mas amplias, i.e., mayor numero de vertices, la GMD sin hibridacion podria ser una desventaja.  \nAunque los algoritmos utilizados en esta investigacion no son capaces de manejar entradas invalidas o inesperadas, y el metodo propuesto se encuentra actualmente en la fase de prototipo para los usuarios, se espera que los profesionales y/o academicos encuentren el EDA beneficioso para sus escuelas cuando este listo para su utilizacion debido a que el EDA puede ser modificado con el fin de obtener un modulo para los usuarios en entornos escolares.  \nLos trabajos de investigacion futura deben considerar un modulo para usuarios, y deben incluir el tiempo computacional y aspectos economicos. Los tiempos de calculo y los costos no fueron considerados en esta investigacion debido a que el algoritmo propuesto se encuentra actualmente en la fase de  \nprototipo. Por ultimo, esta investigacion se centra solamente en las instancias de Schittekat et al., (2013). Sin embargo, el numero de paradas de autobus parece variar significativamente en multiples entornos escolares. La asignacion dinamica de la correcta parada de autobus a la posicion correcta en la secuencia tambien afecta el valor de aptitud, y esto sigue siendo un tema para futuras investigaciones. Ademas, esta investigacion debe ampliarse para tener en cuenta otros factores de retraso, tales como el transito, ausentismos en los conductores, y otros cambios que pueden abordarse mediante el desarrollo de una version dinamica del EDA y asi regular el flujo vehicular de los autobuses basados en simulaciones partiendo de la investigacion de Aquino et al., (2009).  \nLa investigacion a futuro puede tratar con una extension del EDA que utilice modelos de probabilidad de orden superior para representar las interacciones mas complejas o las relaciones entre las variables del problema enunciado. Se requieren modulos eficaces para usuarios especificos en las escuelas, y aprender acerca de los modelos probabilisticos seria util para mejorar el modelado del problema mencionado. Por ultimo, la literatura aun no considera la interaccion que existe entre las paradas de autobus con otros temas de planeacion relacionados, por medio de un modelo de probabilidad, y valdria la pena proporcionar un enfoque diferente, que integre las decisiones sobre estos temas de planeacion con el fin de reducir al minimo la distancia total recorrida.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:14",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the NAGEDA model described, specifically concerning the update and repair of the covariance matrix?",
      "topics": [
        "search"
      ],
      "answer": "The NAGEDA algorithm involves the following steps related to the covariance matrix: First, the algorithm computes maximum likelihood estimates for the mean vector $\\vec{\\mu}$ and the covariance matrix $\\boldsymbol{\\Sigma}$ using the current population. Then, a repair technique is applied to $\\boldsymbol{\\Sigma}$ where eigenvalues below $10^{-100}$ are replaced with $10^{-100}$. The matrix $\\boldsymbol{\\Sigma}$ is then rebuilt. Subsequently, the initial matrix $\\mathbf{C}$ is computed via singular value decomposition of $\\boldsymbol{\\Sigma}$. Finally, the natural gradient is computed to update the parameters $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}$.",
      "chunk_id": 4751,
      "paper_id": "An Estimation of Distribution Algorithm based on the Natural Gradient and the Boltzmann Distribution",
      "paper_title": "An Estimation of Distribution Algorithm based on the Natural Gradient and the Boltzmann Distribution",
      "paper_year": "2015",
      "chunk_content": "Initial parameters: $\\vec{\\mu}=[0,0]^{\\top}$ and $\\boldsymbol{\\Sigma}=\\mathbf{I}$.\nFigure 2 shows the results of this experiment. Once again Figures 2-(b) and 2-(c) show similar behaviour; both are focusing the Gaussian distribution on a smaller area around the global optimum. On the other hand, the parameter $\\beta=1 / 10$ encourages the increment of the spread of the Boltzmann density. As a consequence, in Figure 2-(a) the multivariate Gaussian distribution covers a bigger area according to the step size. This behaviour might be very useful to avoid being trapped in local optimum locations.  \nThe previous experiments suggest that our proposal is capable of managing the exploration and exploitation phases. Note that, it is a desirable attribute to build effective evolutionary algorithms and maintain the diversity of the population [8] [16]. The next section is dedicated to building an Estimation of Distribution Algorithm (EDA) based on the natural gradient developed through the previous sections.\nThe Estimation of Distribution Algorithms (EDAs) fit a multivariate density function on regions near optimum locations; so that any new sample might be near the global optimum. However, it is well-known that the EDA approach might reduces the spread of population too early [13]. The EDA presented below deals with similar issues by effectively using the gathered information through the optimisation process. In addition, some of the ideas presented here can be applied in the general EDA context.  \nThis section introduces our proposal named Natural Gradient based Estimation of Distribution Algorithm (NAGEDA), see Figure 3. The algorithm exploits the developed updating rules for the parameters $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}=\\mathbf{C C}^{\\top}$. The central idea consists in the computation of a search distribution capable of predicting the location of optimum regions. Here, the Natural Gradient estimator developed in sections 3 and 4 plays an important role.  \nThe NAGEDA starts with a random population, which is utilised to compute the fitness values $\\mathcal{F}\\left(\\vec{x}_{i}\\right)$ and the energy values $\\mathcal{G}\\left(\\vec{x}_{i}\\right)$. Note that Eq. (20) is a valid formula to find the maximum values of the fitness function $\\mathcal{F}(\\vec{x})$. But, the minimization problems should be attained via $\\mathcal{F}(\\vec{x})=$  \n$-\\mathcal{F}(\\vec{x})$. Then, the whole set of individuals $\\mathcal{P}^{(t)}$ is used to compute the maximum likelihood estimates $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}$. Additionally, a repair technique is applied to the estimate $\\boldsymbol{\\Sigma}$, line 7. This technique replaces the eigenvalues below $10^{-100}$ by setting the minimum value to $10^{-100}$; as a consequence the matrix $\\boldsymbol{\\Sigma}$ is built again. Next, the initial matrix $\\mathbf{C}$ is computed via a singular value decomposition of $\\boldsymbol{\\Sigma}$. It allows for the estimate of the vectors $\\vec{z}_{i}$; note that $\\vec{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. Hence, the proposed natural gradient is computed to update the parameters $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}$, line 10 . Next, new individuals are simulated from the updated multivariate Gaussian density. Since the set $\\mathcal{P}_{S}^{(t)}$ could have better individuals than the actual population, the next population $\\mathcal{P}^{(t+1)}$ is chosen by $\\mathcal{P}^{(t)} \\cup \\mathcal{P}_{S}^{(t)}$. This step adds the necessary selective pressure to maintain the improvement of the population. This algorithm only needs to update the variables $\\beta$ and $\\eta$, but an auto-adaptive rule is added for this purpose, lines 16-24.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:16",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when benchmarked against IUMDA and MUMDA on the moving peaks benchmark (MPB)?",
      "topics": [
        "fitness"
      ],
      "answer": "The primary metric used to evaluate the effectiveness of the EDA model is the average error, which represents the averages of the error of the best solution on each generation over all independent runs. The moving peaks benchmark (MPB) is used, and the best of generation fitness is recorded every generation across 50 independent runs. The total population size N is fixed at 40 individuals, and the UMDA parameter α is set to 0.5 for all experiments. Performance is compared across different change severities denoted by 's'.",
      "chunk_id": 5922,
      "paper_id": "An Improved Estimation of Distribution Algorithm in Dynamic Environments",
      "paper_title": "An Improved Estimation of Distribution Algorithm in Dynamic Environments",
      "paper_year": "2008",
      "chunk_content": "In order to test the performance of the proposed algorithm, we use the publicly available moving peaks benchmark(MPB)[4-5]. The function is formulated as follows:\n$F(x, t)=\\max _{i=1, \\cdots 10} \\frac{H_{i}(t)}{1+W_{i}(t) \\sum_{j=1}^{5}\\left(x_{j}-X_{j}(t)\\right)^{2}}$\nwhere $H_{i}(t)=H_{i}(t-1)+k_{0} \\sigma, \\quad W_{i}(t)=W_{i}(t-1)+k_{0} \\sigma$,\n$\\sigma \\in N(0,1) \\quad, \\quad X(t)=X(t-1)+\\omega_{i}(t)$,\n$\\omega_{i}(t)=\\frac{s}{|r+\\omega_{i}(t-1)|}\\left((1-\\lambda) r+\\lambda \\omega_{i}(t-1)\\right)$.\nThe moving peak function consists of a number of peaks $X(t)$, of varying heights $H_{i}(t)$ and widths $W_{i}(t)$, moving by a fixed shift length $s$ in random directions. The peaks change position every $\\tau$ generation by a distance of $s=1$ in a random direction. These parameter settings are summarized in Table 1.  \nTable 1 Standard settings for the moving peaks benchmark  \nExperiments were carried out to compare the performance of the proposed algorithm, IUMDA and MUMDA on the test environments constructed above. IUMDA is UMDA with random immigrants[9], and MUMDA is hyper mutation based UMDA[10], in which hyper mutation is selected to increase the diversity when the problem is changed.  \nFor each experiment of combining different algorithm and test problems, 50 independent runs were executed with the same set of random seeds. For each run of different algorithm on each problem, the best of generation fitness was recorded every generation. And for\neach run of an algorithm on a dynamic problem, 500 generations are allowed.  \nIn order to compare performance of different algorithms, the total population size $N$ was fixed at 40 individuals. The parameter of UMDA $\\alpha=0.5$ was used for all experiments. And the average errors which are the averages of the error of the best solution on each generation over all run are located in figures. The simulation results on different change severities $s$ are shown in Fig.1-3 (the solid line represent the improved UMDA, the dotted line represent the IUMDA, and the dash-dot line represent the MUMDA ).\n[IMAGE0]  \nFig. 1 Experimental results on MPB  \n$$\n(p=10, \\tau=25, s=1)\n$$  \n[IMAGE1]  \nFig. 2 Experimental results on MPB  \n$$\n(p=10, \\tau=30, s=2)\n$$  \n[IMAGE2]  \nFig. 3 Experimental results on MPB  \nFORMULA_80  \nFrom the simulation results, the following considerations can be drawn.\n(1) First, generally, the improved UMDA outperforms IUMDA and MUMDA in the same environment. One straight forward approach to make EAs more suitable for dynamic environments is to increase the diversity of the population after a change.\n(2) The proposed algorithm increases the diversity by generating the new individuals with combing transfer model. Thus the proposed algorithm makes useful of the current and history information of the optimal solutions to increase the diversity by guide fashion. The new individuals are close to or in the promising region. So the time to track the optimum for the proposed algorithm is shorter than other algorithm.\n(3) By using improved UMDA, the optimum solution is achieved in dynamic environments. Dynamic optimum problem field is extended by using EDAs.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:18",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when applied to the Multidimensional Knapsack Problem (MKP), and what specific mechanisms are integrated into the proposed hybrid EDA (HEDA) to address the problem's characteristics?",
      "topics": [
        "design"
      ],
      "answer": "The primary objective is to develop a hybrid EDA (HEDA) tailored for solving the MKP, given the limited prior research on applying standard EDAs to this problem. The HEDA incorporates a probability model, an updating mechanism for this model, and an initialization strategy based on specific knowledge of the MKP. Furthermore, it investigates the influence of parameter settings and the importance of a repair operator to ensure feasibility within the knapsack constraints defined by \\$\\sum_{j=1}^{n} r_{i j} x_{j} \\leq b_{i}\\$, where \\$r_{ij}\\$ represents the weight of item \\$j\\$ for constraint \\$i\\$ and \\$b_i\\$ is the capacity of constraint \\$i\\$.",
      "chunk_id": 5338,
      "paper_id": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_title": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_year": "2012",
      "chunk_content": "So far the EDA has been applied to a variety of academic and engineering optimization problems, such as feature selection, cancer classification, quadratic assignment problem, machinery structure design, nurse rostering, and etc (Zhou \\& Sun, 2007). However, to the best of our knowledge, there is almost no research work about the EDA for solving the MKP except the relaxed complemental EDA for the MKP (Yang, Ouyang, \\& Quan, 2007). In this paper, we take the characteristic of the MKP to propose a hybrid EDA (HEDA) for solving the MKP. A probability model is built and an updating mechanism is proposed. In addition, a mechanism of  \n[^0]:     Corresponding author. Tel.: +86 10 62783125; fax: +86 10 62786911.  \nE-mail address: wangling@tsinghua.edu.cn (L. Wang).  \ninitializing the probabilistic model is proposed based on the specific knowledge of the MKP in the framework of the EDA. Moreover, the influence of parameter setting and the importance of repair operator are both investigated. Finally, we use a set of benchmark instances to test the performances of the HEDA and to compare it with some existing methods to further demonstrate the effectiveness of the HEDA.  \nThe remainder of the paper is organized as follows: In Section 2, the MKP is formulated. In Section 3, the basic EDA is introduced briefly. Then, the hybrid EDA for the MKP is proposed in Section 4. The influences of parameter setting and repair operator are investigated in Section 5, and computational results and comparisons are also provided. Finally we end the paper with some conclusions in Section 6.\nThe multidimensional knapsack problem can be formulated as follows:  \nMaximize $\\sum_{j=1}^{n} p_{j} x_{j}$\nSubject to $\\sum_{j=1}^{n} r_{i j} x_{j} \\leq b_{i}, \\quad i=1,2, \\ldots, m$,\n$x_{j} \\in\\{0,1\\}, \\quad j=1,2, \\ldots, n$\nwhere $n$ is the number of items, and $m$ is the number of knapsack constraints with capacities $b_{i}(i=1,2, \\ldots, m)$, associated weights $r_{i j}$ and profits $p_{j}$.  \nThe objective is to find a subset of items that yields a maximum profit without exceeding the resource capacities. Without loss of generality, it can be assumed that all the data $r_{i j}, b_{i}$ and $p_{j}$ are non-negative integers and $r_{i j} \\leqslant b_{i}, \\sum_{j=1}^{n} r_{i j}>b_{i}$ for all $i=1,2, \\ldots, m$ and $j=1,2, \\ldots, n$.\n[IMAGE_0]  \nFig. 1. The general framework of the EDA.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:20",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of HMOBEDA differ from traditional EDA-based approaches, specifically regarding the probabilistic graphic model (PGM)?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm (HMOBEDA) differs from traditional EDA-based approaches because its probabilistic graphic model (PGM) provides the joint probability of decision variables, objectives, and configuration parameters of an embedded local search. Traditional EDA-based approaches do not explicitly model the joint probability in this manner, especially concerning the configuration parameters of a local search.",
      "chunk_id": 7030,
      "paper_id": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_title": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_year": "2017",
      "chunk_content": "Marcella S. R. Martins,Myriam Delgado and Ricardo LudersFederal University of Technology - ParanaEmail: \\{marcella,myriamdelg,luders\\}@utfpr.edu.brRoberto SantanaUniversity of the Basque CountryEmail: roberto.santana@ehu.esRichard A. Goncalvesand Carolina P. de AlmeidaMidwest State University of ParanaEmail: \\{richard,carol\\}@unicentro.br\nMetaheuristics that explore the decision variables space to construct probabilistic modeling from promising solutions, like estimation of distribution algorithms (EDAs), are becoming very popular in the context of Multi-objective Evolutionary Algorithms (MOEAs). The probabilistic model used in EDAs captures certain statistics of problem variables and their interdependencies. Moreover, the incorporation of local search methods tends to achieve synergy of MOEAs' operators and local heuristics aiming to improve the performance. In this work, we aim to scrutinize the probabilistic graphic model (PGM) presented in Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm (HMOBEDA), which is based on a Bayesian network. Different from traditional EDA-based approaches, the PGM of HMOBEDA provides the joint probability of decision variables, objectives, and configuration parameters of an embedded local search. HMOBEDA has shown to be very competitive on instances of Multi-Objective Knapsack Problem (MOKP), outperforming state-of-the-art approaches. Two variants of HMOBEDA are proposed in this paper using different sample methods. We aim to compare the learnt structure in terms of the probabilistic Pareto Front approximation produced at the end of evolution. Results on instances of MOKP with 2 to 8 objectives show that both proposed variants outperform the original approach, providing not only the best values for hypervolume and inverted generational distance indicators, but also a higher diversity in the solution set.  \nKeywords-Multi-objective optimization; estimation of distribution algorithms; automatic algorithm configuration;",
      "question_type": "algorithmic",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:22",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to reduce the amino acid alphabet, what specific implementation steps are required for the extended compact genetic algorithm (EcGA) to reduce a 20-letter alphabet?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The extended compact genetic algorithm (EcGA) can be used to reduce the 20-letter amino acid (AA) alphabet into a lower cardinality alphabet. The reduced alphabet can then be used in a genetics-based machine learning technique to induce rules for protein structure prediction features. An example result showed that it is possible to reduce the alphabet size from twenty to three letters.",
      "chunk_id": 5955,
      "paper_id": "A review of estimation of distribution algorithms in bioinformatics",
      "paper_title": "A review of estimation of distribution algorithms in bioinformatics",
      "paper_year": "2008",
      "chunk_content": "The alphabet reduction problem is addressed in [57] using the extended compact genetic algorithm (EcGA) [69]. The problem is to reduce the 20 -letter amino acid (AA) alphabet into a lower cardinality alphabet. A genet-ics-based machine learning technique uses the reduced alphabet to induce rules for protein structure prediction features. The results showed that it is possible to reduce the size of the alphabet used for prediction from twenty to just three letters resulting in more compact rules.  \nResults of using EDAs and the HP model to simulate the protein folding process are presented in [64]. Some of the features exhibited by the EDA model that mimics the behaviour of the protein folding process are investigated. The features considered include the correlation between the EDA success rate and the contact order of the protein models, and the relationship between the generation convergence of EDAs for the HP model and the contact order of the optimal solution. Other issues analyzed are the differences in the rate of formation of native contacts during EDA evolution, and how these differences are associated with the contact separation of the protein instance.\nThroughout this paper, we reviewed the state-of-the-art of EDA applications in bioinformatics. As soon as researchers realized the need to apply a randomized, populationbased, heuristic search, EDAs emerged as a natural alternative to commonly used genetic algorithms. Since the pos-  \nsible solution space is huge for most of the addressed problems, researchers have made use of efficient EDA implementations.  \nA group of interesting papers demonstrate the efficiency and the competitive accuracy of this novel search paradigm in a set of challenging NP-hard genomic and proteomic bioinformatic tasks. As the number of EDA application papers in bioinformatics is modest and the number and variety of problems is constantly growing, there is room for new EDA applications in the field.  \nAn interesting opportunity for future research is the adaptation and application of multivariate EDA models that can efficiently deal with the huge dimensionality of current bioinformatic problems. Going further than simple univariate models, bio-experts could explicitly inspect the probabilistic relationships among problem variables for each generation of the evolutionary process. This would create opportunities for improved accuracy. These probabilistic relationships induced from the evolutionary model are an attractive way of proposing novel biological hypotheses to be further tested by bio-experts.\nThe authors declare that they have no competing interests.\nRA, II, and PL conceived of the manuscript. II, YS, JLF, RB, VR and CB participated in writing the genomics section. The proteomics section was designed and written by RS and JAL. The introduction to EDAs was carried out by RA, RS and YS. RA was in charge of the writing and coordination process. II, YVP and PL helped to write and correct the manuscript draft. All authors read and approved the final manuscript.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:24",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the discrete-event simulator algorithm described, how are the times between failures ($TBF_{ki}$) and times to repair ($TTR_{ki}$) for machine $M_{ki}$ mathematically modeled, and what distribution governs their generation within the simulation?",
      "topics": [
        "scheduling"
      ],
      "answer": "Within the discrete-event simulator algorithm, both the time between failure ($TBF_{ki}$) and the time to repair ($TTR_{ki}$) for a given machine $M_{ki}$ in factory $k$ are modeled as random variables following an exponential distribution. Specifically, in Algorithm I, Step 4, $TBF_{ki}$ is set to a random number drawn from an exponential distribution with a mean equal to the mean time between failures ($MTBF_{ki}$), expressed as $TBF_{ki} = \\exp(MTBF_{ki})$. Similarly, in Algorithm II, Step 1, $TTR_{ki}$ is set to a random number drawn from an exponential distribution with a mean equal to the mean time to repair ($MTTR_{ki}$), expressed as $TTR_{ki} = \\exp(MTTR_{ki})$.",
      "chunk_id": 12590,
      "paper_id": "A fuzzy logic-based hybrid estimation of distribution algorithm for distributed permutation flowshop scheduling problems under machine breakdown",
      "paper_title": "A fuzzy logic-based hybrid estimation of distribution algorithm for distributed permutation flowshop scheduling problems under machine breakdown",
      "paper_year": "2016",
      "chunk_content": "To evaluate the population under machine breakdown, a discrete-event simulator is applied to provide the estimations of expected makespan. In this simulator, the eventdriven policy and right-shift schedule repair are adopted to deal with machine breakdown, that is, rescheduling is executed when machine breakdown occurs and the remaining operations are therefore postponed by the downtime. The discrete-event simulator under machine breakdown is detailed as follow, in which both times between failures and repair times for the machines are assumed of exponential distributions.  \nNotation:\n$n$ : $\\quad$ a counter, the number of simulation replications\n$N_{\\text {sim }}: \\quad$ maximum simulation replications\n$M_{k i}: \\quad$ machine $i$ in factory $k$\n$M T B F_{k i}: \\quad$ mean time between failure of $M_{k i}$\n$T B F_{k i}: \\quad$ time between failure of $M_{k i}$\n$M T T R_{k i}: \\quad$ mean time to repair of $M_{k i}$\n$T T R_{k i}: \\quad$ time to repair of $M_{k i}$\n$B L_{k i}: \\quad$ breakdown level of $M_{k i}$\n$A P T_{k i}: \\quad$ accumulated processing time of $M_{k i}$\n$S M_{n}: \\quad$ simulated makespan in the $n^{\\text {th }}$ simulation replication\n$S M_{\\text {avg }}: \\quad$ average simulated makespan  \nAlgorithm I: The discrete-event simulator algorithm\nStep 1: $\\quad$ Generate the $M T T R_{k i}$ and $B L_{k i}$ for each machine $M_{k i}$;\nStep 2: $\\quad$ Compute the $M T B F_{k i}$ for each machine $M_{k i}$ using $M T B F_{k i}=M T T R_{k i} / B L_{k i}-M T T R_{k i}$\nStep 3: $\\quad$ Initialise $n=0$ and set the maximum simulation replications $N_{\\text {sim }}$;\nStep 4: $\\quad$ For each machine $M_{k i}$, let $A P T_{k i}=0$ and set $T B F_{k i}$ to a random number following the exponential distribution with mean $M T B F_{k i}$, that is, $T B F_{k i}=$ $\\exp \\left(M T B F_{k i}\\right)$\nStep 5: Determine the jobs on each machine according to ECT rule;\nStep 6: $\\quad$ For each machine $M_{k i}$, identify the first unprocessed job and add its processing time to $A P T_{k i}$;\nStep 7: If $A P T_{k i} \\geqslant T B F_{k i}$, run the machine breakdown algorithm. Otherwise, repeat from Step 6 until all the jobs allocated to a machine have been completed;\nStep 8: $\\quad$ Compute the simulated makespan $M_{s i m}^{\\alpha}$, which is the maximum of job completion times in distributed factories;\nStep 9: If $n \\geqslant N_{\\text {sim }}$, return $S M_{\\text {avg }}=\\sum_{n=1}^{N_{\\text {sim }}} S M_{n} / N_{\\text {sim }}$; otherwise, set $n=n+1$ and go to Step 4.  \nAlgorithm II: The machine breakdown algorithm\nStep 1: $\\quad$ For the breakdown machine $M_{k i}$, set $T T R_{k i}$ to a random number following the exponential distribution with mean $M T T R_{k i}$, that is $T T R_{k i}=\\exp$ $\\left(M T T R_{k i}\\right)$\nStep 2: $\\quad$ For unprocessed jobs on the breakdown machine $M_{k i}$, compute their completion times, which are the sums of $T T R_{k i}$ and their planned completion times;\nStep 3: $\\quad$ Let $A P T_{k i}=0$ and set $T B F_{k i}$ to a random number following the exponential distribution with mean $M T B F_{k i}$, that is, $T B F_{k i}=\\exp \\left(M T B F_{k i}\\right)$.",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:26",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the EDALS algorithm compare to the iMeme-net algorithm on GN extended benchmark networks, specifically regarding the mixing parameter $\\mu$ and the Normalized Mutual Information (NMI)?",
      "topics": [
        "convergence"
      ],
      "answer": "On GN extended benchmark networks, the EDALS algorithm demonstrates superior detection capability as the mixing parameter $\\mu$ increases from 0.05 to 0.5, as measured by the average maximum NMI. In contrast, the iMeme-net algorithm is unable to detect the true community structure for any value of the mixing parameter $\\mu$ within that range.",
      "chunk_id": 12314,
      "paper_id": "Estimation of Distribution Algorithm with Local Sampling Strategy for Community Detection in Complex Networks",
      "paper_title": "Estimation of Distribution Algorithm with Local Sampling Strategy for Community Detection in Complex Networks",
      "paper_year": "2016",
      "chunk_content": "The GN extended benchmark network contains four communities with 128 vertices, and each community has 32 nodes. The average degree of node is 16 , and the mixing parameter $\\mu$ determines the percentage of connections between communities to the total connections. When the express $\\mu<0.5$ is true, the network has a clear group structure. On the other hand, when the express $\\mu>0.5$ is true, the community structure is vague, and it is difficult to detect its structure.  \nExperiments on GN extended networks were carried out to test the performance of our algorithm. FN, TGA, Infomap, FTQ, and iMeme-net and the proposed algorithms were tested on 10 GN extended networks with the mixing parameter $\\mu$ distributing from 0.05 to 0.5 . Figure 2 shows the average maximum NMI and $\\mu$ values obtained by different methods when the parameter $\\mu$ increasing from 0.05 to 0.5 at 0.05 intervals.  \nAs shown in Fig. 2, the superiority of the proposed algorithm EDALS is demonstrated. EDALS shows its excellent detection capability when the community structure becomes increasingly obscure with the change in the parameter $\\mu$. The algorithm iMeme-net cannot detect the real community structure in any mixing parameter $\\mu$. The algorithms FN, TGA, Infomap, FTQ, and the proposed algorithm can acquire the true community structure when the parameter $\\mu \\leq 0.15$. With the increase in the parameter $\\mu$, the community structure of the complex network becomes fuzzy and it becomes difficult to detect the true structure of the community. Informap and FN first show their weakness. The detection capability of Informap decreases rapidly from $\\mu=0.15$ to 0.3 and the performance of FN decreases gradually from $\\mu=0.1$ to 0.5 . When $\\mu>0.3$, the algorithms TGA and FTQ show their limitation in detecting the community structure. By comparing these results for selected algorithms and EDALS performed on GN extended benchmark networks, the algorithm EDALS shows its superiority. From our view point, the designed definition takes the topology of the community structure into consideration, which allows the algorithm to detect a more obscure structure\n[IMAGE1]  \nFig. 2. (Color online) Average maximum NMI over 30 runs on GN extended benchmark networks.\n[IMAGE2]  \nFig. 3. (Color online) Average maximum NMI with EDALS over 30 runs on GN extended benchmark networks.\nthan the others with a suitable tuning parameter value in the objective functions.  \nMore experiments are discussed in detail to illustrate the performance of the proposed algorithm. In our objective function, $\\lambda$ is a tuning parameter. If the $\\lambda$ is bigger, the more the number of the communities will be detected generally.  \nFigure 3 shows the simulation results executed by the algorithm EDALS over 30 runs under different mixing parameters $\\mu$ on GN extended benchmark networks. As seen from Fig. 3, the algorithm EDALS can be used to detect the community structure under the condition that the value of the parameter $\\mu$ is less than 0.35 . When the parameter $\\lambda$ is greater than 0.7 , the algorithm EDALS can obtain good results.  \nTo discuss the convergence of the nature-inspired algorithms (the proposed algorithm, TGA, and iMeme-net algorithm), the GN extended benchmark network FORMULA_212 was chosen to illustrate the convergence procedure.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:28",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for optimizing the Local Linear Wavelet Neural Network (LLWNN), what programming considerations should be taken into account when initializing and updating the scale parameters ($a_i$), translation parameters ($b_i$), and local linear model parameters ($\\omega_{i0}, \\omega_{i1}, ..., \\omega_{in}$)?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Local Linear Wavelet Neural Network",
        "Parameter Initialization",
        "Optimization"
      ],
      "answer": "When implementing the EDA for the LLWNN, the scale ($a_i$) and translation ($b_i$) parameters, along with the local linear model parameters ($\\omega_{i0}, \\omega_{i1}, ..., \\omega_{in}$), must be initialized randomly. The EDA then iteratively updates these parameters to optimize the network's performance. A developer needs to ensure that the EDA implementation correctly handles the tensor product of n single wavelet basis functions, $\\psi(x)=\\prod_{i=1}^{n} \\psi(x_{i})$, when calculating the wavelet activation function. Efficient matrix operations should be used to compute the linear model $v_{i} = \\omega_{i0} + \\omega_{i1}x_1 + ... + \\omega_{in}x_n$ for each unit, as this is a key component of the LLWNN's output $y = \\sum_{i=1}^{M}(\\omega_{i0} + \\omega_{i1}x_1 + ... + \\omega_{in}x_n)\\Psi_{i}(x)$.",
      "chunk_id": 12934,
      "paper_id": "Stock index modeling using EDA based Local Linear Wavelet Neural Network",
      "paper_title": "Stock index modeling using EDA based Local Linear Wavelet Neural Network",
      "paper_year": "2005",
      "chunk_content": "In terms of wavelet transformation theory, wavelets in the following form  \n$$\n\\begin{gathered}\n\\Psi=\\left\\{\\Psi_{i}=\\left|\\mathbf{a}_{i}\\right|^{\\frac{1}{2}} \\phi\\left(\\frac{\\mathrm{x}-\\mathrm{b}_{\\mathrm{i}}}{\\mathrm{a}_{\\mathrm{i}}}\\right): \\mathrm{a}_{\\mathrm{i}}, \\mathrm{~b}_{\\mathrm{i}} \\in \\mathrm{R}^{\\mathrm{n}}, \\mathrm{i} \\in \\mathrm{Z}\\right\\} \\\\\n\\mathrm{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) \\\\\n\\mathrm{a}_{\\mathrm{i}}=\\left(a_{i 1}, a_{i 2}, \\ldots, a_{i n}\\right) \\\\\n\\mathrm{b}_{\\mathrm{i}}=\\left(b_{i 1}, b_{i 2}, \\ldots, b_{i n}\\right)\n\\end{gathered}\n$$  \nare a family of functions generated from one single function $\\psi(x)$ by the operation of dilation and translation. $\\psi(x)$,  \nwhich is localized in both the time space and the frequency space, is called a mother wavelet and the parameters $a_{i}$ and $\\mathrm{b}_{i}$ are named the scale and translation parameters, respectively. The x represents inputs to the WNN model.  \nIn the standard form of wavelet neural network, the output of a WNN is given by  \n$$\nf(x)=\\sum_{i=1}^{M} \\omega_{i} \\Psi(x)=\\sum_{i=1}^{M} \\omega_{i}\\left|a_{i}\\right|^{-\\frac{i}{2}} \\psi\\left(\\frac{x-b_{i}}{a_{i}}\\right)\n$$  \nwhere $\\psi_{i}$ is the wavelet activation function of $i$ th unit of the $\\omega_{i}$ is the weight connecting the $i$ th unit of the hidden layer to the output layer unit. Note that for the $n$-dimensional input space, the multivariate wavelet basis function can be calculated by the tensor product of $n$ single wavelet basis functions as follows  \n$$\n\\psi(x)=\\prod_{i=1}^{n} \\psi\\left(x_{i}\\right)\n$$  \nObviously, the localization of the $i$ th units of the hidden layer is determined by the scale parameter $a_{i}$ and the translation parameter $b_{i}$. According to the previous researches, the two parameters can either be predetermined based upon the wavelet transformation theory or be determined by a training algorithm. Note that the above wavelet neural network is a kind of basis function neural network in the sense of that the wavelets consists of the basis functions.  \nNote that an intrinsic feature of the basis function networks is the localized activation of the hidden layer units, so that the connection weights associated with the units can be viewed as locally accurate piecewise constant models whose validity for a given input is indicated by the activation functions. Compared to the multilayer perceptron neural network, this local capacity provides some advantages such as the learning efficiency and the structure transparency. However, the problem of basis function networks is also led by it. Due to the crudeness of the local approximation, a large number of basis function units have to be employed to approximate a given system. A shortcoming of the wavelet neural network is that for higher dimensional problems many hidden layer units are needed.  \nIn order to take advantage of the local capacity of the wavelet basis functions while not having too many hidden units, here we propose an alternative type of wavelet neural network. The architecture of the proposed LLWNN [8] is shown in Fig.1. Its output in the output layer is given by  \n$$\ny=\\sum_{i=1}^{M}\\left(\\omega_{i 0}+\\omega_{i 1} x_{1}+\\ldots+\\omega_{i n} x_{n} \\Psi_{i}(x)\\right.\n$$  \n$$\n=\\sum_{i=1}^{M}\\left(\\omega_{i 0}+\\omega_{i 1} x_{1}+\\ldots+\\omega_{i n} x_{n}\\right)\\left|a_{i}\\right|^{-\\frac{i}{2}} \\psi\\left(\\frac{x-b_{i}}{a_{i}}\\right)\n$$  \nwhere $x=\\left[x_{1}, x_{2}, \\ldots, x_{n}\\right]$. Instead of the straightforward weight $\\omega_{i}$ (piecewise constant model), a linear model  \n$$\nv_{i}=\\omega_{i 0}+\\omega_{i 1} x_{1}+\\ldots+\\omega_{i n} x_{n}\n$$  \nis introduced. The activities of the linear models $v_{i}(i=1,2, \\ldots M)$ are determined by the associated locally active wavelet functions $\\psi_{i}(x)(i=1,2, \\ldots M)$, thus $v_{i}$ is only locally significant. The motivations for introducing the local linear models into a WNN are as follows: (1) Local linear models have been studied in some neurofuzzy systems and shown good performances [18], [19]; and (2) Local linear models should provide a more parsimonious interpolation in high-dimension spaces when modeling samples are sparse.  \nThe scale and translation parameters and local linear model parameters are randomly initialized at the beginning and are optimized by a EDA discussed in the following section.\n[IMAGE_0]  \nFig. 1. A local linear wavelet neural network",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:31",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach is outlined to assess the EDA in comparison to existing algorithms for the semiconductor final testing scheduling problem (SFTSP)?",
      "topics": [
        "analysis"
      ],
      "answer": "The EDA's performance is assessed by comparing it against the wcGA, bvGA, and CEDA algorithms using a set of simulation instances of the SFTSP. These instances are available at the Decision Analysis Lab website http://dalab.ie.nthu.edu.tw/newsencontent.php?id=0. The algorithm is implemented in C and executed on a 2.3 GHz Intel Core i5 processor.",
      "chunk_id": 4717,
      "paper_id": "A hybrid estimation of distribution algorithm for the semiconductor final testing scheduling problem",
      "paper_title": "A hybrid estimation of distribution algorithm for the semiconductor final testing scheduling problem",
      "paper_year": "2015",
      "chunk_content": "For each generation of the designed HEDA, its computational complexity can be roughly analyzed as follow.  \nFor the updating process, first it is with the computational complexity $O(P \\log P)$ by using the quick sorting method to select the best $S P$ individuals from population; then, it is with the complexity $O\\left(T_{o} \\times S P+T_{o} \\times n\\right)$ to update all the $T_{o} \\times n$ elements of $A_{1}$ by the operator sequence vectors and with the computational complexity $O\\left(T_{o} \\times S P+T_{o} \\times m\\right)$ to update $A_{2}$ by the machine assignment vectors. Thus, the computational complexity for updating process is $O\\left[T_{o}(S P+m+n)+\\right.$ $P \\log P]$.  \nFor the sampling process, it generates a certain gene is by the roulette strategy via sampling $A_{1}$ and $A_{2}$ to obtain a new individual. It is with the complexity $O\\left(T_{o} \\times n\\right)$ and $O\\left(T_{o} \\times m\\right)$ to generate an certain operation sequence vector and machine assignment vector, respectively. Thus, the computational complexity for generating $P$ individuals is $O\\left[P T_{o}(m+n)\\right]$.  \nFrom the above analysis, it can be concluded that the complexity of the proposed EDA is not large and the algorithm may have the potential capability to solve the SFTSP efficiently.\nAs for the evolutionary algorithms to solve the SFTSP, the wcGA (Wu and Chien 2008), the bvGA (Wu et al. 2012) and the CEDA (Hao et al. 2013) are three typical existing algorithms. In the literature, a set of simulation instances of the SFTSP (available at the Decision Analysis Lab website http://dalab.ie.nthu.edu.tw/newsencontent. php?id=0) was used for numerical testing. Thus, we also use these instances to carry out numerical simulations for testing and comparing the performance of the proposed HEDA with  \nTable 3 Parameters of the instances\nTable 4 Combinations of parameter values\nTable 5 Orthogonal array and RV values\nthe existing algorithms. The parameters of the instances are provided in Table 3. The algorithm is coded in C and run on a 2.3 GHz Intel Core i5 processor.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:33",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of incorporating an Estimation of Distribution Algorithm (EDA) within the universal island-based metaheuristic algorithm (UIMA) for berth scheduling?",
      "topics": [
        "search"
      ],
      "answer": "The Estimation of Distribution Algorithm (EDA) is integrated as one of the four distinct population-based metaheuristics within the UIMA framework. Its purpose is to diversify the search process across the islands by leveraging different operators compared to algorithms like evolutionary algorithm (EA), particle swarm optimization (PSO), and differential evolution (DE), ultimately facilitating the discovery of superior solutions for the berth scheduling problem.",
      "chunk_id": 9747,
      "paper_id": "Berth scheduling at marine container terminals A universal island-based metaheuristic approach",
      "paper_title": "Berth scheduling at marine container terminals A universal island-based metaheuristic approach",
      "paper_year": "2020",
      "chunk_content": "Masoud KavoosiFlorida A\\&M University-Florida State University College of Engineering, Tallahassee, Florida, USAMaxim A. DulebenetsDepartment of Civil and Environmental Engineering, Florida A\\&M UniversityFlorida State University College of Engineering, Tallahassee, Florida, USA  \nOlumide Abioye, Junayed Pasha, Oluwatosin Theophilus, Hui Wang and Raphael KampmannFlorida A\\&M University-Florida State University College of Engineering, Tallahassee, Florida, USA, andMarko MikijeljevicUniversity of Montenegro, Podgorica, Montenegro\nPurpose - Marine transportation has been faced with an increasing demand for containerized cargo during the past decade. Marine container terminals (MCTs), as the facilities for connecting seaborne and inland transportation, are expected to handle the increasing amount of containers, delivered by vessels. Berth scheduling plays an important role for the total throughput of MCTs as well as the overall effectiveness of the MCT operations. This study aims to propose a novel island-based metaheuristic algorithm to solve the berth scheduling problem and minimize the total cost of serving the arriving vessels at the MCT.  \nDesign/methodology/approach - A universal island-based metaheuristic algorithm (UIMA) was proposed in this study, aiming to solve the spatially constrained berth scheduling problem. The UIMA population was divided into four sub-populations (i.e. islands). Unlike the canonical island-based algorithms that execute the same metaheuristic on each island, four different population-based metaheuristics are adopted within the developed algorithm to search the islands, including the following: evolutionary algorithm (EA), particle swarm optimization (PSO), estimation of distribution algorithm (EDA) and differential evolution (DE). The adopted population-based metaheuristic algorithms rely on different operators, which facilitate the search process for superior solutions on the UIMA islands.\nFindings - The conducted numerical experiments demonstrated that the developed UIMA algorithm returned near-optimal solutions for the small-size problem instances. As for the large-size problem instances, UIMA was found to be superior to the EA, PSO, EDA and DE algorithms, which were executed in isolation, in terms of the obtained objective function values at termination. Furthermore, the developed UIMA algorithm outperformed various single-solution-based metaheuristic algorithms (including variable neighborhood  \n[^0]\n[^0]:    Maritime Business Review Vol. 5 No. 1, 2020 pp. 30-66\nEmerald Publishing Limited 2397-5757\nDOI 10.1108/MABR-06-2019-0022  \n[^1]\n[^0]:    (C) Pacific Star Group Education Foundation. Licensed re-use rights only.  \nThis work has been partially supported by the National Science Foundation grant CMMI1901109. The opinions, findings and conclusions, expressed in this publication, are those of the authors and do not necessarily reflect the views of the National Science Foundation.  \nsearch, tabu search and simulated annealing) in terms of the solution quality. The maximum UIMA",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:34",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of MCEDA differ from MOEA/D in generating new solutions, and what role does the 'normalize' function play in MCEDA's robustness?",
      "topics": [
        "termination"
      ],
      "answer": "MCEDA and MOEA/D differ in their solution generation methods. MOEA/D uses operators of differential evaluation, while MCEDA generates new solutions through a clustering and modeling procedure. Specifically, MCEDA utilizes 'generateClusters' on a set of non-dominated solutions 'Ps_t' to produce clusters 'C_t', then applies 'modeling' using 'm(C_t)' and 'n', where 'm' is the number of objectives and 'n' is the number of variables. The 'normalize' function, applied to the population 'P_t' (resulting in 'Pn_t') and potentially before line 21 in Algorithm 2 (though omitted for conciseness), enhances robustness by preventing excessively large or small objective function values from misleading the selection process and avoiding values that exceed the computer's capacity. 'normalize' is also applied to the initial population 'P_0' and to the population within the subproblems context.",
      "chunk_id": 8170,
      "paper_id": "MCEDA- A novel many-objective optimization approach based on model and clustering",
      "paper_title": "MCEDA: A novel many-objective optimization approach based on model and clustering",
      "paper_year": "2019",
      "chunk_content": "The reason why the normalization is used here is to make the algorithm more robust, i.e. 1) to avoid the too large or to small value of the objective function misleads the direction of the selection 2) and to avoid the too large value exceeds the scope the computer can hold. It would be better to add the normalization operator before line 21 in Algorithm 2 as well. However, thinking about the small amount of the new generated solutions and to make the algorithm more concise, the normalization operator is not added before line 21 in Algorithm 2.  \nThe main difference between MCEDA and MOEA/D is the way to generate new solutions. While MOEA/D uses operators of the differential evaluation, MCEDA generate new solutions by clustering and modeling procedure.\nInput: $P_{t}$ : the problem; $N$ : the size of population and weight vectors; $m$ : the number of the objectives; $n$ : the number of the variables of the problem; MaxRSS: the max RSS in k means; MaxIterations: the max iterations in k means;\n$1 P_{0} \\leftarrow$ initializePopulation( $N$ );\n$2 P_{0} \\leftarrow$ evaluatePopulation $\\left(P_{0}\\right)$;\n3 Update evaluation number;\n$4 z^{*} \\leftarrow$ initializeldealPoint();\n$5 P_{0} \\leftarrow$ normalize( $\\left.P_{0}\\right)$;\n$6 \\lambda \\leftarrow$ generateWeight $(N)$;\n$7 N b \\leftarrow$ initialNeighborhood $(\\lambda)$;\n8 while termination criteria not satisfied do randomly permutate subproblem;\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25 return subproblems do\nId $\\leftarrow$ subproblemId;\n$N t \\leftarrow$ RandomlyChooseNeighborType();\n$P n_{t} \\leftarrow$ normalize( $\\left.P_{t}, z_{t}^{*}\\right)$;\n$P s_{t} \\leftarrow$ nonDominatedSelect( $\\left.P n_{t}\\right)$;\n$C_{t} \\leftarrow$ generateClusters( $\\left.P s_{t}, m\\right.$, MaxIterations, MaxRSS);\n$Q_{t} \\leftarrow$ modeling $\\left(C_{t}, m\\left(C_{t}\\right), n\\right)$;\n$Q c_{t} \\leftarrow$ crossover $\\left(Q_{t}, I d\\right)$;\n$Q c m_{t} \\leftarrow$ mutate $\\left(Q c_{t}\\right)$;\n$Q c m_{t} \\leftarrow$ evaluatePopulation $\\left(Q c m_{t}\\right)$;\nUpdate evaluation number;\nQcms $_{t} \\leftarrow$ nonDominatedSelect $\\left(Q c m_{t}\\right)$;\nforeach solution in Qcms, do\n$z_{t+1}^{*} \\leftarrow$ updateldealPoint(solution);\n$P_{t+1} \\leftarrow$\nupdatePopulation $\\left(P_{t}\\right.$, solution, Id, Nt, FORMULA_97;\n// see Algorithm 3;\n26 return",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:37",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to solve the multi-carpooling problem, how should practitioners update the carpooling probabilistic matrix to optimize solutions, especially when the matrix is not the identity matrix?",
      "topics": [
        "search"
      ],
      "answer": "When the carpooling probabilistic matrix in the Estimation of Distribution Algorithm is not the identity matrix FORMULA_11, the multi-carpooling problem should be augmented with an intermediate stage for ridesharing among drivers. This involves a series of incremental updates to the carpooling probabilistic matrix based on promising carpooling solutions found during the stochastic optimization process. Additionally, a virtual vehicle, representing a generalized profile of vehicles with arbitrary starting and ending points, should be introduced to facilitate this intermediate ridesharing stage.",
      "chunk_id": 12428,
      "paper_id": "An Augmented Estimation of Distribution Algorithm for Multi-Carpooling Problem with Time Window",
      "paper_title": "An Augmented Estimation of Distribution Algorithm For Multi-Carpooling Problem With Time Window",
      "paper_year": "2016",
      "chunk_content": "The multi-carpooling problem is a NP sub-problem of Pickup and Delivery Problem which goal is to minimize the riding distances and thus alleviate urban traffic jams and the transportation pressure ${ }^{[1,2]}$. Meanwhile it subjects to the constraints of multi-variables including: location points of dynamic ridesharing, time windows for pickup and dropping, riding routes, passenger capacities, travel speed and etc. The implementation of the carpooling problem is to seek compromised multi-routes that are preferred by all qualified riders; however, stochastic disturbances of travel time make it hard to actionable merging the routes for all riders. Yan proposed a stochastic carpooling model formulated as an integer multiple commodity network flow problem; however, the model could be difficult to find optimal solutions especially with large problem sizes ${ }^{[3]}$. A more conventional approach is to use vehicle routing problem with hard time window to eliminate the uncertainty ${ }^{[4,5]}$. In addition, the multi-carpooling model is implemented in the multi-vehicle environment with distributed parallel computing ${ }^{[6-9]}$. The distributed computing for multi-carpooling is of high time and space complexity, hence, the temporal-spatial complexity results in the solving difficulties within a reasonable period of time. In order to reduce the complexity, $\\operatorname{Pan}^{[4]}$ proposed a time difference insertion heuristics algorithm, $\\operatorname{Shao}^{[9]}$ proposed a clustering heuristic algorithm based on matching degree, and $\\operatorname{Xiao}^{[10]}$  \nThis work was supported by the Natural Science Foundation of China under contact (61233007), the National High Technology Research and Development Program of China (863 Program: 2011AA040101, 2012AA041102-03, 2011AA040103), Foundation of Chinese Academy of Sciences under contract (XDA06020500, XDA06021100, XDA06020602).\nCorresponding author: yang.wang.cn@ieee.org\nused the fuzzy clustering and fuzzy recognition theory to study the carpooling problem. Though their heuristic algorithms are efficient, yet these models were simplified by a certain level of abstraction, the risk remains that the model would not represent reality sufficiently. As for the model-free method, service models ${ }^{[6-8]}$ are proposed as a data-driven approach considering GPS data sets, context information, and measurement based on the MapReduce model. Besides, genetic algorithm ${ }^{[5,11]}$ and ant colony algorithm ${ }^{[12]}$ are also be used to solve the carpooling problems in cloud computing.  \nFor more efficient computing and effective solutions, an estimation of distribution algorithm (sometimes called probabilistic model-building genetic algorithm) is proposed as a stochastic optimization method to solve the optimum with a carpooling probabilistic matrix of promising carpooling solutions. The optimization consists of a series of incremental updates of the carpooling probabilistic matrix. If the carpooling probabilistic matrix is not the identity matrix FORMULA_11, the multicarpooling problem is augmented with an intermediate stage for ridesharing among drivers. In addition, a notion of the virtual vehicle is introduced as a generalized profile of vehicles permitting arbitrary starting and ending points for drivers.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:38",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of quay crane scheduling, how does the required time, \\(t_{ij}\\), for a quay crane to move between container bays \\(i\\) and \\(j\\) relate to the time, \\(\\hat{t}\\), required to move between adjacent bays, and what is the significance of \\(l_i\\) and \\(l_j\\) in this calculation?",
      "topics": [
        "scheduling"
      ],
      "answer": "The required time for a quay crane to move between container bays \\(i\\) and \\(j\\), denoted as \\(t_{ij}\\), is calculated as \\(t_{ij} = \\hat{t} |l_i - l_j|\\), where \\(\\hat{t}\\) represents the time required for the quay crane to move between two adjacent bays. The terms \\(l_i\\) and \\(l_j\\) represent the bay positions of container bays \\(i\\) and \\(j\\), respectively. Therefore, \\(|l_i - l_j|\\) calculates the absolute difference in bay positions, and multiplying this difference by \\(\\hat{t}\\) gives the total time required for the quay crane to move between bays \\(i\\) and \\(j\\).",
      "chunk_id": 11745,
      "paper_id": "Estimation of Distribution Algorithm for the Quay Crane Scheduling Problem",
      "paper_title": "Estimation of Distribution Algorithm for the Quay Crane Scheduling Problem",
      "paper_year": "2011",
      "chunk_content": "Every quay crane $q$ has a ready time, $r^{q}$, that specifies its earliest possible activity. The initial and final bay positions of the quay crane $q$ are denoted as $l_{0}^{q}, l_{T}^{q} \\in Z^{+}$, respectively. The required time for a quay crane to move itself between two adjacent bays is $\\hat{t}$. The required time for a quay crane to move itself between the container bays $i$ and $j$ is $t_{i j}=\\hat{t}\\left|l_{i}-l_{j}\\right|$ (so, $t_{0 j}^{q}=\\hat{t}\\left|l_{q}^{0}-l_{j}\\right|$ and $t_{i T}^{q}=\\hat{t}\\left|l_{i}-l_{q}^{T}\\right|$ is the time required by the quay crane $q$ to move from its initial position to the bay $j$ and from the bay $i$ to its final position). Quay cranes can be moved along the length of the container vessel by means of a pair of rails, so that they cannot cross each other and must keep a safety distance $\\delta$ (measured in container bay units).  \nThere are tasks that need to be done before other ones because they are placed within the same container bay. For example, unloading tasks on the deck must be carried out before unloading tasks in the hold. Let $\\Phi$ be the set of task pairs within the same container bay for which exists a precedence relationship. On the other hand, $\\Psi$ is the set of task pairs that cannot be processed simultaneously. That is,  \n$$\n\\begin{aligned}\n& \\Phi=\\{(i, j): i \\text { has to be completed before the starting of } j\\} \\\\\n& \\Psi=\\{(i, j): i \\text { and } j \\text { cannot be done simultaneously }\\}\n\\end{aligned}\n$$  \nNote that $\\Phi \\subseteq \\Psi$.\nThe objective of the QCSP is to determine the completition times $c_{i}$ of all tasks $i \\in \\bar{\\Omega}$ so that the completition time of the last task $T\\left(c_{T}\\right)$ is minimized; that is, minimizing the makespan.  \nFigure 13.1 shows an instance of the QCSP with $n=8$ tasks, $m=2$ quay cranes, $l_{0}^{1}=2, l_{0}^{2}=5, r^{1}=r^{2}=0, \\hat{t}=1$ and $\\delta=1$. Processing times and the location of the tasks on the bays are shown in Table 13.1. Additionally,  \n$$\n\\begin{aligned}\n\\Phi & =\\{(1,2),(5,6),(5,7),(6,7)\\} \\\\\n\\Psi & =\\{(1,2),(3,4),(5,6),(5,7),(6,7)\\}\n\\end{aligned}\n$$  \n[IMAGE0]  \nFig. 13.1 Example of an instance of the Quay Crane Scheduling Problem  \nTable 13.1 Input data of the example instance  \nIn this work, the search space is limited to unidirectional schedules. A scheduling is denominated unidirectional if the quay cranes have the same sense of moving and this is not changed after the initial positioning (see [1]). The best unidirectional scheduling may be not the optimal scheduling but, usually, it has high quality. On the other hand, without loss of generality, a lexicographic order of the tasks is assumed. That is, tasks are ordered according to their bay position along the container vessel. Figure 13.2 depicts a unidirectional scheduling for the previous instance, where tasks $1,2,3,5,6$ and 7 are done by the quay crane 1 and tasks 4 and 8 are done by the quay crane 2 . After the initial positioning of the quay crane 1 on the bay 1 and the quay crane 2 on the bay 4 , both quay cranes move unidirectionally from left to right. Note that tasks within the container vessel are sequenced according to the lexicographic order. The lexicographic order indicates that tasks are ordered from left to right and, within each bay, in order of precedence.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:40",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the iterative dynamic programming (IDP) algorithm's approach to optimization compare to deterministic dynamic programming (DDP) in terms of computational efficiency, specifically concerning processor memory usage?",
      "topics": [
        "control"
      ],
      "answer": "The IDP algorithm, described as a numerical method, aims to reduce calculation time and achieve a quasi-optimal solution compared to the optimal solutions provided by deterministic dynamic programming (DDP). IDP achieves this efficiency by adjusting the grid size of state and control variables in each iteration to minimize the demands on processor memory. The stage cost function, denoted as h1 =  $\\dot{m}_{l}(x_{k}, u_{1})+\\omega_{1} \\frac{P_{t o s}}{Q_{h v}}$, includes a weight on electric energy consumption, $\\omega_{1}$, which is iteratively recalculated to approximate a target value. While DDP provides optimal solutions with smaller state and control variables, IDP saves computational time, albeit with a quasi-optimal result, through dynamic grid size adjustment.",
      "chunk_id": 10292,
      "paper_id": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
      "paper_title": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
      "paper_year": "2020",
      "chunk_content": "[IMAGE6]  \nFig. 5. General analysis results in energy consumption plan. (a) Predicted velocity profile in two travel routes. (b) Energy consumption comparison by different methods. (c) Engine torque by different methods in whole travel route. (d) Motor torque by different methods in whole travel route.\n$m$ ); and the threshold values of hidden and output layer are $\\theta_{f}$ and $\\phi_{k}$. The training process of the three-layer BP-NN are described as follows:  \nStep 1: Initialize the number of nodes in the input layer, hidden layer, and output layer; their corresponding weights as well as the threshold values of hidden and output layer.\nStep 2: Input the training data to proceed the forward propagation, and obtain the output from the nodes in output layer, as:  \n$$\n\\left\\{\\begin{array}{l}\nu_{j}=\\sum_{i} v_{k i} y_{j}+\\phi_{k} \\\\\ny_{j}=f\\left(u_{j}\\right) \\\\\nx_{k}=\\sum_{j} v_{k j} y_{j}+\\theta_{j} \\\\\no_{i}=f\\left(x_{k}\\right)\n\\end{array}\\right.\n$$  \nStep 3: Calculate the error $\\psi_{i}$ between the output $o_{i}$ of the forward propagation and real output $t_{i}$ of the trained data, as:\n$\\psi_{i}=\\left(o_{i}-t_{i}\\right) t_{i}\\left(1-o_{i}\\right)$  \nStep 4: Proceed the backward propagation with $\\psi_{i}$, and calculated the error signal $\\sigma_{f}$ caused by nodes in the hidden layer, as:\n$\\sigma_{i}=\\left(\\sum_{k} \\psi_{i} v_{k i}\\right) y_{i}\\left(1-y_{i}\\right)$  \nStep 5: Adjust the weight and threshold values by:  \n$$\n\\left\\{\\begin{array}{l}\nv_{k i}^{\\prime}=v_{k j}+\\tau \\psi_{i} y_{j} \\\\\n\\omega_{j i}^{\\prime}=\\omega_{j i}+\\tau \\psi_{i} x_{i} \\\\\n\\theta_{j}^{\\prime}=\\theta_{j}+\\tau \\psi_{j} \\\\\n\\phi_{k}^{\\prime}=\\phi_{k}+\\tau \\psi_{k}\n\\end{array}\\right.\n$$  \nwhere ris the learning rate.\nStep 6: Repeat steps 1 to 6 and calculate the mean square error between the output of the BP-NN and real value by:\n$E=\\frac{1}{2 N} \\sum_{k=1}^{N} \\sum_{k=1}^{N}\\left(o_{k}-t_{k}\\right)^{2}$\nThe training process will be repeated untilEis lower than the pre-set value. The data for training the specific BP-NN is prepared offline by IDP [52] based on the collected driving cycle data. The length of each driving cycle, gathered in real route segment with different driving conditions, is 1500 m . The velocity profiles of partial chosen driving cycles are shown in Fig. 4(b). The IDP algorithm, as a numerical method, can save the calculation time while attain the quasi-optimal effect, compared with the optimal solutions provided by the deterministic DP  \nTable 2\nExperimental setup.\n(DDP) with smaller amount of state and control variables. In each iteration, the grid size of state and control variable will be adjusted to endeavour the lowest request on processor memory [45]. To constrain the electric energy, the stage cost function in IDP to calculate the cost-to-go values of each discrete state can be expressed as:\n$h_{1}=\\dot{m}_{l}\\left(x_{k}, u_{1}\\right)+\\omega_{1} \\frac{P_{t o s}}{Q_{h v}}$\nwhere $\\omega_{1}$ denotes the weight on electric energy consumption, and can be calculated as:  \n$$\n\\begin{aligned}\n& \\omega_{1} q+1\\left(=\\omega_{1} q\\right)+\\operatorname{sign} E_{c_{-} \\text {rest }} q\\left(-E_{c_{-} \\text {target }} q\\right)\\left(\\times \\delta E_{c_{-} \\text {rest }} q\\right) \\\\\n& \\quad-E_{c_{-} \\text {target }}(q))^{\\frac{1}{2}}\n\\end{aligned}\n$$  \nwhere $q$ is the iteration time, $E_{c_{-} \\text {rest }}$ is the real electric energy consumption in qth iteration, $E_{c_{-} \\text {target }}$ is the target electric energy consumption, and $\\delta$ is a constant parameter. In each iteration, $\\omega_{1}$ is recalculated according to the attained electric energy consumption, trying to approximate the target value. In the IDP based optimization, the inequality constraints are the same with that in EDA optimization. The offline generated battery SOC decreasing slopes, based on the velocity profiles displayed in Fig. 4 (b), is demonstrated in Fig. 4 (c).",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:43",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing an Estimation of Distribution Algorithm (EDA) for fuel channel loading optimization, and generating initial loading patterns based on a random number criterion (threshold 0.6), how would you structure the code to efficiently manage and update the population based on varying alpha values and population sizes?",
      "topics": [
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "To efficiently manage the EDA population, you would first generate random numbers for each fuel channel and assign cluster types based on the 0.6 threshold (type-1 if less than 0.6, type-2 otherwise). The code should then iterate through generations, evaluating the objective function for each individual in the population. For each generation, the code should update the distribution based on the selected individuals, considering the alpha value (0.05, 0.1, or 0.5) which influences the learning rate or the extent to which the distribution is updated towards the selected individuals. Code should track the best objective function value and generation number, allowing for comparison between different alpha values (e.g., observing the improvement from alpha 0.05 to 0.1 and then to 0.5) and population sizes (e.g., comparing a population size of 24 to 240) to optimize performance.",
      "chunk_id": 12741,
      "paper_id": "Performance of Estimation of distribution algorithm for initial core loading optimization of AHWR-LEU",
      "paper_title": "Performance of Estimation of distribution algorithm for initial core loading optimization of AHWR-LEU",
      "paper_year": "2016",
      "chunk_content": "The study of varying initial distribution function has been divided into two parts as described above.\nIn this case the loading patterns are generated by generating random number for each fuel channel and setting the criteria that if the random number generated is less than 0.6 , type-1 cluster will be loaded else type-2 cluster will be loaded. In this way the type-1 clusters will be $\\sim 60 \\%$ and type-2 clusters will be $\\sim 40 \\%$. Now three different values of population sizes have been considered.\nThe three values of $\\alpha$ considered are $0.05,0.1$ and 0.5 . The first case of population size of 24 and $\\alpha=0.05$ belongs to very small population size and very small ' $\\alpha$ '. The best value of objective function in 400 generations is 0.9870 . After increasing the value of $\\alpha$ to 0.1 , the best value of objective function in 400 generations improved to 0.98790 . By further increasing the value of $\\alpha$ to 0.5 , the best value of objective function in 150 generations improves marginally to 0.9965 . The variation of best value of objective func-\ntion with generation number for different values of $\\alpha$, is shown in Fig. 2. It is observed that there is very small or negligible improvement in optimized value of objective function by increasing $\\alpha$ from 0.05 to 0.5 .\nIn the second step, we tried the simulations considering higher population size of 240 in each generation. The three values of $\\alpha$ considered are $0.05,0.1$ and 0.5 . The first case of population size of 240 and $\\alpha=0.05$ belongs to moderate population size and very small ' $\\alpha$ '. The best value of objective function in $\\sim 130$ generations is 0.9954 . After increasing the value of $\\alpha$ to 0.1 , the best value of objective function in 130 generations improved to 1.0074 . By further increasing the value of $\\alpha$ to 0.5 , the best value of objective function in 150 generations improves marginally to 1.009530 . The variation of best value of objective function with generation number for different values of $\\alpha$, is shown in Fig. 3. On comparison with case-I(a), it is observed that there is significant improvement in optimized value of objective function. It is also observed that the very small value of FORMULA_91, the optimized value of objective function is poor (0.9954).",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:46",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metric is used to evaluate the best solution found so far during the execution of the algorithm?",
      "topics": [
        "genetic"
      ],
      "answer": "The best solution value found so far is evaluated using the variable Fbest. If Fbest is greater than the minimum function value of local minima \\(y^{i}\\), calculated as \\(\\min _{1 \\leq i \\leq J} f\\left(y^{i}\\right)\\), then Fbest is updated to this minimum value.",
      "chunk_id": 13328,
      "paper_id": "Hybrid estimation of distribution algorithm for global optimization",
      "paper_title": "Hybrid Estimation of Distribution Algorithm for Global Optimization",
      "paper_year": "2004",
      "chunk_content": "The framework of the proposed algorithm is as follows.\nStep 0. Parameter setting. Population size: $N$, the best solution value found so far: $F$ best $=\\infty$, the number of new solutions sampled from the probability model at each iteration: $K$, the maximal number of function evaluations in the simplex method: $S$, and the number of solutions undergoing UOBDQA at each iteration: $J . J<K$.  \nStep 1. Initialization. Generate $N$ solutions $\\tilde{x}^{1}, \\tilde{x}^{2}, \\ldots, \\tilde{x}^{N}$ from $D$, using the uniform design technique. Apply the simplex method with at most $S$ function evaluations to each solution $\\tilde{x}^{i}$ and obtain $\\tilde{x}^{i}(1 \\leq i \\leq N)$. Then let $x^{1}, x^{2}, \\ldots, x^{N}$ constitute the initial population.  \nStep 2. Reproduction. Build a probability model based on the statistical information extracted from some selected solutions in the current population. Sample $K$ new solutions $\\tilde{x}^{N+1}, \\ldots, \\tilde{x}^{N+K}$ from this model and then apply the simplex method with at most $S$ function evaluations to each solution $\\tilde{x}^{i}$ and obtain $x^{i}(N+1 \\leq i \\leq N+K)$.  \nStep 3. Comparison. Compare the function values of all $x^{i}(1 \\leq i \\leq N+K)$, order and relabel them such that  \n$$\nf\\left(x^{1}\\right) \\leq f\\left(x^{2}\\right) \\leq \\cdots \\leq f\\left(x^{N+K}\\right)\n$$  \nStep 4. Update of Fbest. Apply UOBDQA to $x^{i}(1 \\leq i \\leq J)$ and obtain $J$ local minima $y^{i}(1 \\leq i \\leq J)$. If Fbest $>\\min _{1 \\leq i \\leq J} f\\left(y^{i}\\right)$, set Fbest $=$ $\\min _{1 \\leq i \\leq J} f\\left(y^{i}\\right)$.  \nStep 5. Stopping condition. If the stopping condition is met, stop.\nStep 6. Update of the population. Let $x^{J+1}, \\ldots, x^{J+N}$ constitute new population. Go to Step 2.\nExperimental design techniques (Montgomery, 1997) such as orthogonal design and uniform design have been proposed to improve the performance of genetic algorithms (Leung and Wang, 2001; Zhang and Leung, 1999). The total number of orthogonal design points is often much more than $2^{n}$ while the number of uniform design points is relatively smaller. This is the reason why we use the uniform design in initialization (Step 1). The probability model built in reproduction (Step 2) step models the distribution of the best solutions in the current population. Therefore, sampling solutions from this model should fall in promising areas with high probability. In Step 3 (comparison), since all the solutions have undergone the incomplete simplex method with at most $S$ function value evaluations, the best ones, i.e. $x^{1}, x^{2}, \\ldots, x^{J}$ in Step 4, should be more likely to be close to the global optimum than other solutions. We apply UOBQDA only to these best solutions in Step 4. The details of the main ingredients of EDA/L are explained in the following.",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:49",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, and how does it aim to improve upon existing methods like BMDA, MIMIC, and COMIT?",
      "topics": [
        "optimization"
      ],
      "answer": "The SGMIEC algorithm aims to improve the performance of EDAs in discrete optimization problems by focusing on key genes that determine individual performance. Unlike BMDA, MIMIC, and COMIT, which can get trapped in local optima due to a lack of population diversity, SGMIEC employs a mutual information and entropy based cluster model and an incremental learning method with a resample scheme to identify and utilize these key genes, balancing convergence speed and population diversity. This allows SGMIEC to achieve superior convergent reliability and velocity compared to the other three methods.",
      "chunk_id": 11465,
      "paper_id": "Using selfish gene theory to construct mutual information and entropy based clusters for bivariate optimizations",
      "paper_title": "Using selfish gene theory to construct mutual information and entropy based clusters for bivariate optimizations",
      "paper_year": "2011",
      "chunk_content": "Finally, the convergence processes of BMDA, MIMIC, SGMIEC and COMIT are also tested and the results are  \n[IMAGE1]  \nFig. 1 Convergent reliability. a OneMax problem, b weighed One-Max problem, c four peaks problem, d trap problem, e satisfaction problem, $\\mathbf{f}$ deceptive-3 problem\nshown in Fig. 3. Although the convergence speed of SGMIEC is not always faster than BMDA, MIMIC and COMIT, it avoids getting trapped in local optima since it keeps the balance between a fast convergence and population diversity successfully. BMDA, MIMIC and COMIT often fail to solve the problems. After a quick\nconvergence, they plateau at a suboptimal level. A possible reason for this is that, the population becomes more and more homogeneous over time and the lack of diversity leads to models that are unable to break out from the sampling of more and more identical solutions.  \n[IMAGE2]  \nFig. 2 Convergent velocity. a OneMax problem, b weighed One-Max problem, c four peaks problem, d trap problem, e satisfaction problem, $\\mathbf{f}$ deceptive-3 problem  \n[IMAGE3]  \nFig. 3 Convergent process. a The 150-dimensional OneMax problem, b the 150-dimensional weighed One-Max problem, c the 50-dimensional four peaks problem, d the 50-dimensional trap problem, e the 50-dimensional satisfaction problem, f the 63-dimensional deceptive-3 problem\nIn this paper, we have proposed a selfish gene-based approach called SGMIEC to solve the discrete optimization problems. Based on the SG, we notice that the performance of individual is only decided by some key genes. That means if these key genes are decided, the performance of the individual can be identified. While the current EDAs  \nrequire much time in the statistic learning process as the relationships among the variables are too complicated, here we employ a mutual information and entropy based cluster model to test the impacts of the genes and an incremental learning method with resample scheme is also used in the mutual information cluster construction.  \nTo evaluate the performance of SGMIEC, we test six benchmark problems for a range of problem size ( $n=$ FORMULA_72 with step 10) and compare the results with what obtained by BMDA, COMIT and MIMIC. The experimental results presented here indicate that our SGMIEC is obviously superior than the other three methods in convergent reliability, convergent velocity as well as convergent results (solutions).  \nAcknowledgments This work was supported by the Research Project of Wuhan University under Grant 6082018.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:51",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the Iterated Local Search (ILS) algorithm as presented, how does the algorithmic mechanism governing the parameter `pp{\\text{cur}}` influence the search process, specifically in relation to the parameters `pp{\\mathrm{LB}}` and `pp{\\mathrm{UB}}`?",
      "topics": [
        "search"
      ],
      "answer": "Within the ILS algorithm, `pp{\\text{cur}}` is a parameter that appears to control some aspect of the perturbation applied to the current solution `Y^{\\text {cur }}`. The algorithm initializes `pp{\\text{cur}}` to `pp{\\mathrm{LB}}`, which represents a lower bound. The algorithm increases a counter `c{\\text {noimpr }}` if the local search doesn't improve the current best solution `Y^{\\text {bsf }}`. If `c{\\text {noimpr }}` exceeds `pp{\\text{cur}}`, the algorithm checks if `pp{\\text{cur}}` is less than `pp{\\mathrm{UB}}`, an upper bound. If it is, `pp{\\text{cur}}` is increased, and `c{\\text {noimpr }}` is reset. Otherwise, `pp{\\text{cur}}` is reset to `pp{\\mathrm{LB}}`. This mechanism suggests that `pp{\\text{cur}}` dynamically adjusts the perturbation strength based on the number of consecutive local search iterations without improvement, bounded by `pp{\\mathrm{LB}}` and `pp{\\mathrm{UB}}`.",
      "chunk_id": 1374,
      "paper_id": "Optimization Techniques and Formal Verification for the Software Design of Boolean Algebra Based Safety-Critical Systems",
      "paper_title": "Optimization Techniques and Formal Verification for the Software Design of Boolean Algebra Based Safety-Critical Systems",
      "paper_year": "2022",
      "chunk_content": "```\nAlgorithm 2: ILS.\n1: input: values for parameters \\(p p{\\mathrm{LB}}, p p{\\mathrm{UB}}, c{\\mathrm{lim}}\\)\n2: \\(Y^{\\text {cur }}=\\operatorname{GenerateInitialSolution()}\\)\n3: \\(Y^{\\text {cur }}=\\operatorname{LocalSearch}\\left(Y^{\\text {cur }}\\right)\\)\n4: \\(Y^{\\text {bsf }}=Y^{\\text {cur }}, c{\\text {noimpr }}=0, p p{\\text {cur }}=p p{\\mathrm{LB}}\\)\n5: while CPU time limit not reached do\n6: if \\(c{\\text {noimpr }}p p{\\mathrm{UB}}\\) then\n19: \\(\\quad p p{\\text {cur }}=p p{\\mathrm{LB}}, c{\\text {noimpr }}=c{\\text {noimpr }}+1\\)\n20: end if\n21: end if\n22: end while\n23: output: \\(Y^{\\text {bsf }}\\), the best solution found",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:01:53",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners handle outliers when using a Multivariate Cauchy distribution for optimization?",
      "topics": [
        "selection"
      ],
      "answer": "When using a Multivariate Cauchy distribution in an EDA, specifically in the sampling step as in MCEDA, be aware that the Expectation-Maximization (EM) algorithm, used to estimate the Cauchy's parameters, tends to disregard outliers. These outliers might represent good solutions close to an optimum. Therefore, it is important to consider using the Multivariate Cauchy distribution only in the sampling step (step 5 in Algorithm 1) to avoid discarding potentially valuable solutions during parameter estimation.",
      "chunk_id": 1201,
      "paper_id": "Multivariate Cauchy EDA Optimisation",
      "paper_title": "Multivariate Cauchy EDA Optimisation",
      "paper_year": "2014",
      "chunk_content": "The algorithms used in this paper for comparison are Multivariate Gaussian EDA (MGEDA), Multivariate Cauchy EDA (MCEDA) and Univariate Cauchy EDA (UCEDA). MGEDA takes on board the sample correlations between the variables of the selected individuals through a full covariance matrix, and MCEDA encodes pairwise dependencies among the search variables through its matrix valued parameter. UCEDA neglects dependences among the search variables. Algorithm 1 describes generic EDA algorithm.  \n1. Set $\\mathrm{t}:=0$. Generate M points randomly to give an initial population P . Do\n2. Evaluate fitness for all M points in P .\n3. Select some individuals $P^{\\text {sel }}$ from P .\n4. Estimate the statistics of $P^{\\text {sel }}$\n5. Use statistics in step (4) to sample new population $P^{\\text {new }}$.\n6. Set P to $P^{\\text {new }}$  \nUntil Termination criteria are met.\nAlgorithm 1. The Pseudocode of a simple EDA with Population size M.  \nThis algorithm is a typical EDA, which proceeds by initially generating a population of individuals and then evaluates their fitness to select the fittest ones based on their fitness using the truncation selection. For the MGEDA, we compute the maximum likelihood estimates (MLE) of the mean $(\\mu)$ and the covariance $(\\Sigma)$ of the fittest individuals and use these parameters to generate new ones by sampling from a multivariate Gaussian distribution with parameters $\\mu$ and $\\Sigma$. For MCEDA, we use the same estimates to sample from a Multivariate Cauchy distribution in step 5. In UCEDA, we use $\\mu$ and the diagonal elements of $\\Sigma$ to sample each from Univariate Cauchy. The new population is formed by replacing the old individuals by the new ones.\nThe philosophy in EDA is to estimate the density of the selected individuals so that when new individuals are sampled from the model, they will follow the same distribution. Fortunately, for Gaussian this works. Parameter estimation in Cauchy distributions was studied in statistics [3] where an Expectation and Maximization (EM) algorithm was developed to find the maximum likelihood estimate of a multivariate Cauchy distribution from a set of points, which we implemented for our study.\n[IMAGE1]  \nFig. 2. A plot showing the behavior of EDA when the search distribution is a Cauchy distribution  \nHowever, we found that when we estimate the Cauchy's parameter (Using EM), then the obtained model of the selected individuals (a Cauchy density) will disregard any outliers. This is of course what a robust density estimator is meant to do- however for optimization those outliers may be some rare and very good solutions that got close to an optimum. Fig 2 illustrates such an example.  \nAs you can see in fig. 2, which was a snap shot taken from an iteration of the experiments we conducted, two selected individuals are close to the optimum and as such are good individuals but they are outliers with respect to the density of the rest of the selected individuals. This is the reason why in algorithm 1, the Multivariate Cauchy distribution was used only in the sampling step.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:01:55",
      "generation_style": "practical_application"
    },
    {
      "question": "In the described Estimation of Distribution Algorithm (EDA) for a min-max problem, a probabilistic model $M_{G}$ is built for the lower-level (LL) solutions using multivariate normal densities. What are the specific parameters of the $d$-dimensional multivariate normal density function $F(x, \\mu, \\Sigma)$ used to factorize the joint probability density function (pdf), and how are these parameters estimated within the algorithm?",
      "topics": [
        "design",
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "The $d$-dimensional multivariate normal density function $F(x, \\mu, \\Sigma)$ used in the EDA is defined as $\\frac{1}{\\sqrt{|\\Sigma|(2 \\pi)^{d}}} \\mathrm{e}^{-1 / 2(x-\\mu) \\Sigma^{-1}(x-\\mu)^{\\prime}}$, where $x$ is the $d$-dimensional random vector representing the LL solution, $\\mu$ is the $d$-dimensional mean vector, and $\\Sigma$ is the $d x d$ covariance matrix. These two parameters, $\\mu$ and $\\Sigma$, are estimated from the best $n$Pop $/ 2$ individuals of the upper-level (UL) population, specifically from their stored lower-level best solutions $Y_{best} = \\arg \\max _{y \\in Y} f(X_{i}, y)$. This means that in each generation, statistical information about the LL solutions corresponding to the best UL individuals is extracted and used to update the parameters of the probabilistic model $M_{G}$.",
      "chunk_id": 8938,
      "paper_id": "Differential Evolution with Estimation of Distribution for Worst-Case Scenario Optimization",
      "paper_title": "Differential Evolution with Estimation of Distribution for Worst-Case Scenario Optimization",
      "paper_year": "2021",
      "chunk_content": "In the proposed algorithm, we keep the hierarchically nested formulation of a min-max problem, which solves asymmetrical problems. The design space (UL) decision variables are evolving with a DE. For the evaluation of each UL individual, first the scenario space (LL) problem is solved by the DE. This solution is then transferred to the upper level. To reduce the cost, we apply an estimation of distribution mechanism between the decision space search (UL) and the scenario space search (LL). In that way, we use a priori knowledge obtained during the optimization. To further reduce the FEs, we search only for solutions with good worst-case scenarios. If the objective function of a solution $X_{1}$ under any scenario is already worse in terms of worst-case performance of the best solution $X_{2}$ found so far, there is no need for further exploring $X_{1}$ over scenario space. Therefore, the mutant individual's performance is checked under the parent's worst-case scenario, and further explored only when it is better in terms of the fitness function. Figure 4 shows the general framework of the proposed approach. The main steps of the proposed algorithm for the UL:  \n1. Initialization: A population of size NPop is initialized according to the general DE procedure mentioned in the previous section, where the individuals are representing candidate solutions in the design space $X$.\n2. Evaluation: To evaluate the fitness function, we need to solve the problem in the scenario space. For a fixed candidate UL solution $X_{i}$, the LL DE is executed. More detailed steps are given in the next paragraphs. The LL DE returns the solution corresponding to the worst-case scenario for the specific $X_{i}$. For each individual, the corresponding best $Y_{b e s t}=\\arg \\max _{y \\in Y} f\\left(X_{i}, y\\right)$ solutions are stored, meaning the solution $y$ that for a fixed $x$ maximizes the objective function.\n3. Building: The individuals in the population $P(i)$ are sorted as the ascending of the UL fitness values. The best $n$ Pop $/ 2$ are selected. From the best $n$ Pop $/ 2$ individuals, we build the distribution to establish a probabilistic model $M_{G}$ for the LL solution. The $d$-dimensional multivariate normal densities to factorize the joint probability density function (pdf) are:  \n$$\nF(x, \\mu, \\Sigma)=\\frac{1}{\\sqrt{|\\Sigma|(2 \\pi)^{d}}} \\mathrm{e}^{-1 / 2(x-\\mu) \\Sigma^{-1}(x-\\mu)^{\\prime}}\n$$  \nwhere $x$ is the $d$-dimensional random vector, $\\mu$ is the $d$-dimensional mean vector and $\\Sigma$ is the $d x d$ covariance matrix. The two parameters are estimated from the best $n$ Pop $/ 2$ of the population, from the stored lower level best solutions. In that way, in each generation, we extract statistical information about the LL solutions of the  \nprevious UL population. The parameters are updated accordingly in each generation, following the general schema of an estimation of distribution algorithm.\n4. Evolution: Evolve UL with the steps of the standard DE of mutation, crossover, producing an offspring $U_{i, G}$.\n5. Selection: As mentioned above, the selection operation is a competition between each individual $X_{i, G}$ and its offspring $U_{i, G}$. The offspring will be evaluated in the scenario space and sent in LL only if $f\\left(U_{i, G}, Y_{i, G}\\right) \\leq f\\left(X_{i, G}, Y_{i, G}\\right)$, where $Y_{i, G}$ corresponds to the worst case vector of the parent individual FORMULA_89. In that way, a lot of unneeded LL optimization calls will be avoided, reducing FEs. If the offspring is evaluated in the scenario space, the selection procedure in Equation (6) is applied.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:01:58",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "While the text discusses various capacity management approaches in semiconductor manufacturing, it does not explicitly detail the mechanisms or performance characteristics of specific Estimation of Distribution Algorithms (EDAs). Can you provide a comparative evaluation question based solely on the text?",
      "topics": [
        "search"
      ],
      "answer": "The provided text focuses on capacity management strategies within semiconductor manufacturing, such as robust capacity strategies, new product allocation, and outsourcing. It does not contain information about specific Estimation of Distribution Algorithms (EDAs) or their relative performance, computational trade-offs, or advantages. Therefore, it is impossible to formulate a comparative evaluation question regarding EDAs based solely on this text.",
      "chunk_id": 907,
      "paper_id": "The cooperative estimation of distribution algorithm  a novel approach for semiconductor final test scheduling problems",
      "paper_title": "The cooperative estimation of distribution algorithm: a novel approach for semiconductor final test scheduling problems",
      "paper_year": "2014",
      "chunk_content": "High-tech industries, including those of semiconductor manufacturing, LEDs, solar cells, and TFT-LCDs, are highly dynamic. In particular, the challenges in planning semiconductor manufacturing can be characterized by a high capital expenditure in capacity investment, long capacity installation lead times, high obsolescence rates caused by rapid technology development, and high demand volatility (Chien 2007; Wu 2011). Because of advanced functions with a reduced average unit cost, semiconductor applications are continuously expanding and penetrating various market segments. Smart integrated circuits (ICs) are increasingly used in medical electronics, green energy, car electronics, computers, communication, and consumer electronics. To respond to the increasing demand and challenging cost-effective supply match, the PDCCCR strategic decision-making framework is proposed to model the interrelated decision elements of semiconductor manufacturing companies, including pricing strategies (P), demand forecast and demand fulfillment planning (D), capacity planning and capacity portfolio (C), capital expenditure (C), and cost structure (C), which affect the overall financial return (R) (Chien et al. 2010a; Chien and Kuo 2012). A critical success factor is to improve capital  \n[^0]:    X.-C. Hao  \nGraduate School of Information, Production and Systems, Waseda University, 2-7 Hibikino, Wakamatsu-ku, Kitakyushu, Fukuoka 808-0135, Japan\nJ.-Z. Wu ( FORMULA_5  \nDepartment of Business Administration, Soochow University, 56 Kueiyang Street, Section 1, Taipei 100, Taiwan, R.O.C\ne-mail: jzwu@scu.edu.tw\nC.-F. Chien  \nDepartment of Industrial Engineering and Engineering Management, National Tsing Hua University, 101, Section 2, Kuang-Fu Road, Hsinchu 30013, Taiwan, R.O.C\nM. Gen  \nDepartment of Research and Development, Fuzzy Logic Systems Institute (FLSI), 101, Section 2, Kuang-Fu Road, Hsinchu 30013, Taiwan, R.O.C\nM. Gen  \nFuzzy Logic Systems Institute (FLSI), Center of Iizuka Research and Development, 680-41 Oaza-Kawazu, Iizuka-shi, Fukuoka 820-0067, Japan  \neffectiveness through the management of capital expenditures (CapEx) under uncertainty (Chien et al. 2011a).  \nConventional approaches for capacity management include robust capacity strategies (Chien and Zheng 2012), new product allocation, intra-company inter- and intra-fab backup (Chien et al. 2011b), inter-company backup (Chien and Kuo 2012), outsourcing (Wu and Chien 2008a; Chien et al. 2010b; Wu et al. 2012a), collaborative design (Wu and Hsu 2009), and productivity enhancement (Chien et al. 2007a,b). Most approaches have been applied by semiconductor manufacturing companies to meet diverse and increasing demands (Shih et al. 2009). In addition to planning level enhancement, a number of efforts emphasized shop-floor-level scheduling.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:00",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model involving sampling from a distribution with covariance matrix C, as described, and what role do the matrices B and D play in this process?",
      "topics": [
        "optimization"
      ],
      "answer": "The process begins with applying an eigendecomposition to the covariance matrix \\$\\boldsymbol{C}\\$ to obtain \\$\\boldsymbol{C}=\\boldsymbol{B} \\boldsymbol{D}^{2} \\boldsymbol{B}^{T}\\$. Here, \\$\\boldsymbol{B}\\$ is an orthogonal matrix defining the coordinate system, and \\$\\boldsymbol{D}\\$ is a diagonal matrix scaling the dimensions of this coordinate system. A partial solution \\$\\boldsymbol{o}^{(g+1)}\\$ is then sampled using the formula \\$\\boldsymbol{o}^{(g+1)}=\\langle\\boldsymbol{x}\\rangle_{w}^{(g)}+\\sigma^{(g)} \\boldsymbol{B}^{(g)} \\boldsymbol{D}^{(g)} \\boldsymbol{z}^{(g+1)}\\$ where \\$\\boldsymbol{z}^{(g+1)}\\$ follows a normal distribution \\$\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})\\$.",
      "chunk_id": 9147,
      "paper_id": "Achieving Highly Scalable Evolutionary Real-Valued Optimization by Exploiting Partial Evaluations",
      "paper_title": "Achieving Highly Scalable Evolutionary Real-Valued Optimization by Exploiting Partial Evaluations",
      "paper_year": "2021",
      "chunk_content": "To sample from the distribution with covariance matrix $\\boldsymbol{C}$, an eigendecomposition is applied to find $\\boldsymbol{C}=\\boldsymbol{B} \\boldsymbol{D}^{2} \\boldsymbol{B}^{T}$, where $\\boldsymbol{B}$ is an orthogonal matrix that determines the coordinate system, and $\\boldsymbol{D}$ is a diagonal matrix that scales the dimensions of this coordinate system accordingly. For a sampling model $\\mathcal{M}_{j}$, a $\\left|\\mathcal{F}_{j}\\right|$-dimensional partial  \nA. Bouter, T. Alderliesten, P.A.N. Bosman\nsolution $\\boldsymbol{o}$ is sampled from $\\mathcal{N}\\left(\\boldsymbol{\\mu}, \\sigma^{2} \\boldsymbol{C}\\right)$ as follows:  \n$$\n\\boldsymbol{o}^{(g+1)}=\\langle\\boldsymbol{x}\\rangle_{w}^{(g)}+\\sigma^{(g)} \\boldsymbol{B}^{(g)} \\boldsymbol{D}^{(g)} \\boldsymbol{z}^{(g+1)}\n$$  \nwith $\\boldsymbol{z}^{(g+1)} \\sim \\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$.\nAs discussed in Section 6, the population has to be periodically reevaluated to avoid large numerical errors. However, reevaluating the population once every 50 generations, as is done in RV-GOMEA ${ }^{\\mathrm{A}}$, appeared insufficient in preliminary experiments to efficiently solve high-dimensional problems with RV-GOMEA ${ }^{\\mathrm{C}}$, because the numerical errors have too much of an influence on the optimization process. This can be seen in the convergence plots in Figure 1. Figure 1 shows runs of RV-GOMEA ${ }^{\\mathrm{C}}$ with three different settings for the number of generations after which the complete population is reevaluated. Note that all runs took fewer than 50 generations, so the population was never reevaluated for the setting with reevaluation every 50 generations. If the population is reevaluated every 50 generations, RV-GOMEA ${ }^{\\mathrm{C}}$ gets 'stuck' near the VTR, because each solution that appears to reach the VTR is reevaluated, but then turns out to be worse than the VTR due to numerical errors. This is the cause of a large inefficiency, most notably in highly-dimensional problems, and can even cause premature convergence. For RV-GOMEA ${ }^{\\mathrm{C}}$ we therefore choose to reevaluate the population every 10 generations, as this is a reasonable setting given the results in Figure 1.\n[IMAGE0]  \nFigure 1: Convergence plots of typical runs of RV-GOMEA ${ }^{\\mathrm{C}}$ on the 80960-dimensional sphere problem, with different settings for the number of generations after which the complete population is reevaluated.\nSimilar to the AMS applied to partial solutions in Section 7.1.2, AMS is applied to all variables of a fraction $0.5 \\tau$ of the population directly following GOM, with the purpose of moving solutions in the direction of generational improvement for all problem variables simultaneously. This application of AMS is only accepted when it leads to an improvement, or with a probability of $p^{\\text {acept }}$. AMS is applied as follows:  \n$$\n\\boldsymbol{x}^{5015}=\\boldsymbol{x}+\\delta^{5015}\\left(\\boldsymbol{\\mu}^{(g)}-\\boldsymbol{\\mu}^{(g-1)}\\right)\n$$  \nwhere $\\delta^{5015}=2$, and $\\boldsymbol{\\mu}_{j}^{(g)}$ is the mean vector of all variables in generation FORMULA_189.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:03",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is diversity measured within the Estimation of Distribution Algorithm (EDA) to determine when to trigger the restart step, and what action is taken during the restart?",
      "topics": [
        "convergence"
      ],
      "answer": "Diversity is measured by calculating the number of different vectors in the selected population divided by $N$, where $N$ represents the size of the selected population. If the diversity falls below a predefined threshold, a restart step is triggered. During the restart, all solutions in the population, except the best solution, are randomly modified with a given probability value, similar to mutation operators in Genetic Algorithms (GAs), but with a higher mutation probability.",
      "chunk_id": 13244,
      "paper_id": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_title": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_year": "2004",
      "chunk_content": "```  \nand parametric learning of the model. Therefore, the computational complexity of the algorithm is reduced, and it can be faster than sophisticated GAs that incorporate complex local search procedures. In addition to the probabilistic model, there are two particular features that characterize our EDA approach to the protein folding problem. The first one is the inclusion of a restart step in the EDA. The restart step tries to avoid early convergence of the population. The other feature added to our EDA is a method to ensure that all the vectors evaluated are valid (i.e. self-avoided) paths. We describe these two additions to the EDA scheme shown above in detail. It should also be noted that none of these changes use knowledge about the problem.  \nEvery time that the diversity of solutions in the population goes under a predefined threshold, all solutions except the best are randomly modified with a given probability value in the same way mutation operators are applied in GAs, but with a higher mutation probability. Diversity is measured by calculating the number of different vectors in the selected population divided by $N$. Restart tries to avoid the early convergence of the population.  \nIn the representation that we used, not all vectors correspond to self-avoiding sequences. Our search procedure organizes the search within the space of valid solutions. To enforce the validity of the solutions, we employ the backtracking method proposed in [3]. This method can be used in two different ways: as a generator procedure or as a repairing algorithm. In the first case, a solution is incrementally constructed in such a way that the self-avoidance constraint is fulfilled. At position $i$, the backtracking call is invoked only if self-avoidance cannot be fulfilled with any of the three possible assignments to FORMULA_30.  \nUsed as a repairing method, the algorithm inspects every sampled solution. It checks whether the current vector position assignments violates the self-avoidance constraint. If such is the case, another value is assigned to the position and tested. The order of the assignment of variables is random. If all the three possible values have been checked, and self-avoidance is not fulfilled yet, backtracking is invoked. Further details about the backtracking algorithm, originally proposed for the 3-D HP model, can be found in [3].  \nThe repairing procedure destroys some of the statistical dependencies generated from the model. However, the effect of this step is beneficial because solutions will be altered only if their current assignment violates the constraint.  \nThere exist EDAs that are able to generate solutions that consider the fulfillment of constraints at the generation step [13]. A similar approach could be applied to the protein folding problem. Nevertheless, this procedure has an additional computational cost because the fulfillment of the constraints must be checked at each step of the solution generation.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:04",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs using a $(\\mu, \\lambda)$ selection scheme on unimodal problems, and how do the equations presented define the evolution of the Gaussian model?",
      "topics": [
        "convergence"
      ],
      "answer": "The primary objective is to mathematically model the dynamics of a continuous Estimation of Distribution Algorithm (EDA) on unimodal problems by iteratively updating a Gaussian model. The equations define this evolution by first determining the truncation range $[-\\alpha, \\alpha]$ based on the selection pressure $\\tau$ using the equation $\\int_{-\\alpha}^{\\alpha} \\frac{1}{\\sqrt{2 \\pi \\delta_{i}^{2}}} e^{-\\frac{\\left(x-\\mu_{i}\\right)^{2}}{2 \\delta_{i}^{2}}} dx = \\tau$. Subsequently, the mean $\\mu_{i+1}$ and standard deviation $\\delta_{i+1}$ of the Gaussian model for the next generation are calculated from the selected individuals within this range using the equations $\\mu_{i+1}=\\frac{1}{\\tau} \\cdot \\int_{-\\alpha}^{\\alpha} x \\cdot \\frac{1}{\\sqrt{2 \\pi \\delta_{i}^{2}}} e^{-\\frac{\\left(x-\\mu_{i}\\right)^{2}}{2 \\delta_{i}^{2}}} dx$ and $\\delta_{i+1}^{2}=\\frac{1}{\\tau} \\cdot \\int_{-\\alpha}^{\\alpha}\\left(x-\\mu_{i+1}\\right)^{2} \\cdot \\frac{1}{\\sqrt{2 \\pi \\delta_{i}^{2}}} e^{-\\frac{\\left(x-\\mu_{i}\\right)^{2}}{2 \\delta_{i}^{2}}} dx$, effectively capturing the convergence behavior based solely on the unimodal and symmetric structure of the problem.",
      "chunk_id": 6311,
      "paper_id": "A mathematical modelling technique for the analysis of the dynamics of a simple continuous EDA",
      "paper_title": "A mathematical modelling technique for the analysis of the dynamics of a simple continuous EDA",
      "paper_year": "2006",
      "chunk_content": "[IMAGE0]  \nFig. 1. A typical one-dimensional unimodal problem.\nThe 1D unimodal problems considered in this section have a general shape like the quadratic function $\\mathrm{y}=\\mathrm{x}^{2}$ shown in Figure 1. The only assumption made is that each problem is symmetric with regard to its global minimum, which is placed at the origin without loss of generality (i.e., there are no upper and lower boundaries on the search space). For the EDA, an infinitely large population size is assumed throughout the paper, meaning that new individuals have exactly the same statistics as the Gaussian model from which they are sampled. It is also assumed that the initial population is generated from a Gaussian with mean $\\mu_{0}$ and standard deviation $\\delta_{0}$. During evolution, the Gaussian model will be evolved towards the origin with changing mean and standard deviation values. An illustration of the dynamics of the EDA is shown in Figure 2.\n[IMAGE1]  \nFig. 2. A demo of the dynamics of the EDA on the unimodal problem.  \nWith the $(\\mu, \\lambda)$ scheme, the Gaussian model constructed in the $\\mathrm{i}^{\\text {th }}$ generation is completely determined by selected individuals in the $\\mathrm{i}^{\\text {th }}$ population sampled from the Gaussian model built in the $(\\mathrm{i}-1)^{\\text {th }}$ generation. As a result, there is a simple recursive relationship among the models in different generations. Another important feature is that the selected individuals in any generation are restricted within a continuous range $[-\\alpha, \\alpha]$ as shown in Figure 1 with the value of $\\alpha$ depending on the model parameters as well as the selection pressure $\\tau(0<\\tau<1)$. This is because truncation selection applies a deterministic fitness threshold and only individuals strictly better than it are chosen.  \nThe specific value of $\\alpha$ in the $(\\mathrm{i}+1)^{\\text {th }}$ generation can be calculated by solving the following equation:  \n$$\n\\int_{-\\alpha}^{\\alpha} \\frac{1}{\\sqrt{2 \\pi \\delta_{i}^{2}}} e^{-\\frac{\\left(x-\\mu_{i}\\right)^{2}}{2 \\delta_{i}^{2}}} d x=\\tau\n$$  \nThe meaning of Eq. 1 is that the cumulative probability of the Gaussian distribution within $[-\\alpha, \\alpha]$ should be equal to $\\tau$, which is the portion of individuals to be selected. Although it may be difficult to come up with an analytical solution to Eq.1, it is easy to see that the value of the left hand side increases from zero monotonically as $\\alpha \\rightarrow+\\infty$, which makes it possible to use a simple line searching method to find the appropriate $\\alpha$ value at a desired accuracy level.  \nOnce the value of $\\alpha$ is available, the mean parameter $\\mu_{i+1}$ and standard deviation parameter $\\delta_{i+1}$ are determined by the statistics of the individuals within $[-\\alpha, \\alpha]$ :  \n$$\n\\begin{gathered}\n\\mu_{i+1}=\\frac{1}{\\tau} \\cdot \\int_{-\\alpha}^{\\alpha} x \\cdot \\frac{1}{\\sqrt{2 \\pi \\delta_{i}^{2}}} e^{-\\frac{\\left(x-\\mu_{i}\\right)^{2}}{2 \\delta_{i}^{2}}} d x \\\\\n\\delta_{i+1}^{2}=\\frac{1}{\\tau} \\cdot \\int_{-\\alpha}^{\\alpha}\\left(x-\\mu_{i+1}\\right)^{2} \\cdot \\frac{1}{\\sqrt{2 \\pi \\delta_{i}^{2}}} e^{-\\frac{\\left(x-\\mu_{i}\\right)^{2}}{2 \\delta_{i}^{2}}} d x\n\\end{gathered}\n$$  \nNow we have enough tools to describe the EDA's behaviour on unimodal problems. It should be pointed out that, in the above three equations, there is no utilization of any specific information of test functions. This shows that the convergence behaviour of the EDA in this situation is only dependent on the general structure of the problem (i.e., strictly unimodal, symmetric with regard to the origin).  \nIn the following, some case studies are presented to formally investigate the dynamics of the EDA with regard to various algorithm factors. Figures $3 \\& 4$ shows the standard deviations and the mean values of the EDA with $\\mu_{0}=-20$ and $\\tau=0.3$, where the three lines in each plot represent results with $\\delta_{0}=0.1,1.0$ and 5.0 respectively.  \nThere are a few interesting things that can be observed from this example:",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:07",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of incorporating local search with guided operators relate to the global statistical information typically utilized by EDAs?",
      "topics": [
        "selection"
      ],
      "answer": "EDAs typically extract global statistical information to build a probabilistic model representing the distribution of best solutions. However, they don't directly use the locations of the best individual solutions found so far. The local search with guided operators combines this global statistical information with the location information of solutions found so far. For example, in the 2-D HP model, guided operations are implemented under special conditions such as guaranteeing the validity of the individual by avoiding position collisions and attempting to place H's near the HCC and P's far from the HCC. This combination aims to generate offspring that fall in or close to promising areas characterized by the probabilistic model.",
      "chunk_id": 7610,
      "paper_id": "A Hybrid EDA for Protein Folding Based on HP Model. IEEJ",
      "paper_title": "A Hybrid EDA for Protein Folding Based on HP Model",
      "paper_year": "2010",
      "chunk_content": "An efficient EA should make use of both the local information of solutions found so far and the global information about the search space. The local information of solutions found so far can be helpful for exploitation, while the global information can guide the search for exploring promising areas. The search in EDAs is mainly based on the global information, but local search is an exploration method based on local information. Therefore, it is worthwhile investigating whether combining local search with EDA could improve the performance of the EDA.  \nLocal search with a set of guided operators is implemented in the proposed hybrid EDA. Some of these operations have been utilized as mutations in the previous GA and ant colony optimizations studies of protein folding [7]. But in this paper, we call them as 'guided operators', meaning that those operations are implemented only under some special conditions.  \nTaking the 2-D HP model as example, the special conditions are defined as follows: (i) The guided operation should grantee the validity of the individual, i.e. it cannot produce position collision in the lattice. If we want to change some residues to other positions in the lattice, the object positions must be empty. (ii) Guided operation should follow a basic principle that make H's as near as possible to the HCC and P's far away from the HCC according to the relative position in lattice, as shown in Fig. 3.  \nThe method of choosing individuals to implement local search is described as follows: In each iteration procedure of EDAs, use the composite fitness function (described by (3)) to sort the selection individuals. According the distribution of individuals' fitness, randomly select some individuals (the number is a certain percentage of the population) in each fitness domain to implement the local search with guided operators.  \nEDAs extract globally statistical information from the previous search and then build a probabilistic model for modeling the distribution of the best solutions visited in the search space. However, the information of the locations of the best individual solutions\n[IMAGE_2]  \nFig. 3. The guided operators for local search\nfound so far is not directly used for guiding further search. Local search with a guided operator generates offspring through a combination of global statistical information and the location information of solutions found so far. The resultant solution can (hopefully) fall in or close to a promising area, which is characterized by the probabilistic model.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:09",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm with distance-based exponential models, what general convergence behavior can practitioners expect based on theoretical models?",
      "topics": [
        "search"
      ],
      "answer": "Based on the presented theoretical model, in most cases, the Estimation of Distribution Algorithm using distance-based exponential models converges to the optimal solution.",
      "chunk_id": 7950,
      "paper_id": "A Mathematical Analysis of EDAs with Distance-based Exponential Models",
      "paper_title": "A Mathematical Analysis of EDAs with Distance-based Exponential Models",
      "paper_year": "2019",
      "chunk_content": "We have presented a mathematical model to study an EDA with infinite populations using discrete dynamical systems and distancebased exponential models. Several problems have been presented and studied, combining the formal results and some conjectures (based on some experiments). In general, the presented theoretical model has shown that in most cases it converges to the optimal solution.\nThis research has been partially supported by Spanish Ministry of Economy and Competitiveness MINECO through the Project I+D Excellence MTM2015-65317-P; by Spanish Ministry of Science and Innovation through the project TIN2016-78365-R and Severo Ochoa SEV-2017-0718; by the Basque Government through the BERC 2014-2017 and IT928-16 programs; and by the University of the Basque Country UPV/EHU through the projects PPG17/32 and GIU17/011. Imanol holds a grant from the Department of Education of the Basque Government.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:11",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of the Travel Managing Service (TMS) example, where composite services are evaluated based on availability ($q_{\\text {avail }}$) and response time ($q_{\\text {erime }}$), what mathematical formula is used to calculate the score of a composite service, and how does this scoring method reflect the preferences for availability and response time?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The score of a composite service is calculated using a weighted sum of the normalized values of availability and response time.  For example, for composition1 (airline1- insurance1- bankcard1- hotel1), the score is calculated as $0.5 *(\\frac{300-300}{300-100} + \\frac{180-100}{180-100} + \\frac{220-95}{220-95})+0.5(\\frac{0.85-0.85}{0.94-0.88} * \\frac{0.88-0.88}{0.94-0.88} )$.  The weights (0.5 in this case) represent the preferences for availability and response time, with the given example assuming equal preference. The normalization is performed by subtracting the minimum value from the actual value and dividing by the difference between the maximum and minimum values for each QoS parameter.  This formula is used to evaluate the utility of different composite services, allowing for the selection of the optimal composition based on the calculated scores.",
      "chunk_id": 8082,
      "paper_id": "A parallel refined probabilistic approach for QoS-aware service composition",
      "paper_title": "A parallel refined probabilistic approach for QoS-aware service composition",
      "paper_year": "2019",
      "chunk_content": "In this section, we present an illustrative example of a Travel Managing Service (TMS), where the goal is to help users to manage their travel plan using a composite service. Suppose that the workflow of the TMS includes five abstract services: Book Airline service (BAS), Buy Air Insurance service (BAIS), Accept Bank Card service (ABCS), Accept Credit Card service (ACCS) and Book Hotel service (BHS). In particular, the BAS and BAIS are composed using a parallel structure and the ABCS and ACCS are composed using a conditional structure. Meanwhile, each abstract service of TMS has three web services. The QoS of each web service is represented by a vector $Q_{T M S}=\\left\\{q_{\\text {avail }}, q_{\\text {erime }}\\right\\}$, where $q_{\\text {avail }}$ and $q_{\\text {erime }}$ represent availability and response time, respectively. The workflow of the TMS is shown in Fig. 1.  \nAssume that the global constraint 3 for availability and response time are 500 ms and $5 / 10$, respectively, and their preferences are the same. Upon receiving the requirement, the user would consist of both BAS and BAIS for a plane ticket. If airlai 4 service is selected, the insurance service is selected or currently. Similar workflow is executed when airline2 and airline3 are selected. Consequently, the ticket is payed. According to the mode of payment, the conc. to service is selected from ABCS or ACCS. In either case, the ticket is purchased. Then, the user would buyk the hotel. Apparently, there are multiple possible composite services, e.g., the composition1 (airline1- insurance1- bankcard1- hotel1) and composition2 (airline3- insurance3- creditcard1 - hotel1). These are alternative solutions because they satisfy user's functional requirement. According to the normalized values of the availability and response time, the score of a composite service can be computed to evaluate its utility. For composition1, we have $0.5 *\\left(\\frac{300-300}{300-100}\\right.$ $\\left.+ \\frac{180-100}{180-100}+\\frac{220-95}{220-95}\\right)+0.5\\left(\\frac{0.85-0.85}{0.94-0.88} * \\frac{0.88-0.88}{0.94-0.88} \\right) \\approx 1$, and for the composition2, the score is $0.5 *\\left(\\frac{300-300}{300-110}\\right.$ $\\left.+ \\frac{140-100}{140-100}+\\frac{220-95}{220-95}\\right)+0.5 *\\left(\\frac{0.89-0.89}{0.95-0.82} * \\frac{0.85-0.85}{0.91-0.85} * \\frac{0.8-0.8}{0.9-0.8}\\right)=\\frac{24}{19}$.\n[IMAGE_0]  \nFig. 1: Travel Managing Service (TMS)  \nThen, the optimal composition can be selected according to the scores.  \nWith the increase of web services, there are many services that have similar functionalities. For example, 170 APIs about hotel information can be located in programmableWeb.com. If a user has a complex requirement, the optimal solution may not be obtained in a limited time. Let's further assume that the airlinel service is canceled. Reactive approaches may map a new workflow to concrete services. For example, the compositions: airline2- insurance2- bankcard3- hotel3, airline2- insurance2- creditcard3- hotel3, are selected as alternative solutions. Due to limit alternative solutions, there might not exist an alternative composite service that could be optimal or near-optimal. In these cases, the mechanism of maintaining the diversity of compositions within the specified time could be used to provide more alternative compositions for the user. To implement this mechanism, the feature information of service composition needs to be captured and distinguished. Meanwhile, efficient and effective exploration of composition solutions is needed.",
      "question_type": "algorithm explanation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:13",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between the exact algorithms, heuristics/approximate algorithms, and meta-heuristics (specifically genetic algorithms and Tabu Search) for solving bin packing problems?",
      "topics": [
        "optimization"
      ],
      "answer": "The text describes exact algorithms that use a mathematical approach to reach an optimal solution for bin packing problems, but does not specify the computational trade-offs. Heuristics and approximate algorithms are presented as an alternative, and meta-heuristics like genetic algorithms and Tabu Search are mentioned as a third type of solution technique, but their computational trade-offs are not detailed beyond being different solution approaches.",
      "chunk_id": 132,
      "paper_id": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_title": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_year": "2013",
      "chunk_content": "The solution techniques in literature for bin packing problems can be classified into three groups. The first group contains algorithms that use mathematical approach and try to reach an exact optimal solution. Martello et al. 2] discussed the lower bound and presented an exact algorithm to pack items into a single bin. Hifi et al. 1 introduced a mixed-integer linear programming formulation (MILP1) for bin packing problem. Heuristics and approximate algorithms belong to the second type. Lim et al. 3] did a comprehensive review on the heuristics that is used for bin packing problem. Most of them are wall or layer-building of the traditional 3DBPP to pack a selected subset of items into a single bin pursuing least waste space. Meta-heuristics such as genetic algorithm belong to the third type. Lodi et al. [4 presented a general Tabu Search technique for the solution of two- and three-dimensional bin packing problems. Crainic et al. 5 presented a new tabu search-based two-level which separates the search for the optimal number of bins from the optimization of the accommodation of items within bins, resulting into a more flexible procedure than the existing ones. Wang et al. 6 presented a hybrid genetic algorithm and a new crossover method for 3DBPP.\nThe investigated problem comes from a real world application, where a transportation company tries to make full use of their various bins to pack the cartons which is almost all rectangular. Their goal is to minimize the sum of all the waste space in the bins that are used. Wasted space of a bin is denoted as the volume of the bin minus the sum of the volume of all cartons in the bin.\nThere are total $m$ cartons and $N$ boxes, all of which are rectangular. The length, width and height of carton $i$ are denoted as $l_{i}, w_{i}, h_{i}$, while the length, width and height of bin $i$ is denoted as $L_{i}, W_{i}, H_{i}$. All the cartons need to be packed into the bins under three constrains.\n(1) Each carton lies completely in the bin and does not penetrate the bin's boundary surface. (2) No two cartons in the same bin can overlap with each other. (3) Each carton has only six rotations. Let the length of the bin be Xaxis, the width of the bin be the Y-axis and the height of the bin be the Z-axis. Let $(l, w, h)$ means the carton is placed in the way that length of the carton is paralleled to X -axis, width is paralleled to Y -axis and height is paralleled to Z-axis. The six rotation is $(l, w, h),(l, h, w),(w, l, h),(w, h, l),(h, w, l),(h, l, w)$.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:15",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for gas lift allocation optimization, what data structures are required to represent the Gaussian Bayesian networks and Gaussian kernels used in the algorithm?",
      "topics": [
        "genetic"
      ],
      "answer": "The EDA implementation requires data structures to represent both Gaussian Bayesian networks and Gaussian kernels. For the Gaussian Bayesian network, a directed acyclic graph (DAG) structure is needed, where nodes represent gas-lift performance variables for wells, and edges represent probabilistic dependencies modeled as Gaussian distributions. Each node stores the mean and variance parameters of its conditional Gaussian distribution, given its parents. For Gaussian kernels, data structures are needed to store kernel parameters such as bandwidth and center locations, along with the well data points themselves, to estimate probability densities for gas injection rates and initiation parameters.",
      "chunk_id": 12513,
      "paper_id": "Development of a time-dependent economic method with start time consideration to optimise gas-lift allocation and scheduling",
      "paper_title": "Development of a time-dependent economic method with start time consideration to optimise gas-lift allocation and scheduling",
      "paper_year": "2016",
      "chunk_content": "S. Omid H. MiresmaeiliInstitute of Petroleum Engineering, University of Tehran, Tehran, IranEmail: omiresmaeili@alumni.ut.ac.irCorresponding author\nDepartment of Petroleum and Chemical Engineering, Sultan Qaboos University, Muscat, Oman\nEmail: pourafshary@squ.edu.om\nSchool of Chemical Engineering, University of Tehran, Tehran, Iran\nEmail: fjalali@ut.ac.ir\nThe gas lift allocation optimisation is an important operational problem. In this paper, we present a method to optimise the lift gas allocation profile and determine the best time to start the gas-lift operation for each well. To tackle the nonlinear optimisation, an estimation of distribution algorithm (EDA) is employed based on Gaussian Bayesian networks and Gaussian kernels and the results are compared with those obtained by particle swarm optimisation (PSO) and genetic algorithms (GAs). Gas-lift performance for all the wells along with estimated cumulative production data are correlated over time to develop a model to show the field production behaviour as a function of the gas injection rates and initiation parameters. The developed model is coupled with an economic model to maximise the net present value of the gas-lift process for the field. [Received: 7 September 2014; Accepted: 30 September 2015]  \nKeywords: gas-lift allocation; gas-lift start time; economic optimisation; Gaussian network; estimation of distribution algorithm; EDA.  \nReference to this paper should be made as follows: Miresmaeili, S.O.H., Pourafshary, P. and Farahani, F.J. (2016) 'Development of a time-dependent economic method with start time consideration to optimise gas-lift allocation and scheduling', Int. J. Oil, Gas and Coal Technology, Vol. 13, No. 1, pp.41-59.  \nBiographical notes: S. Omid H. Miresmaeili is currently a researcher in NIOC-IOR Research Institute in lieu of mandatory military service as Iran's National Elites Foundation member. He received his MSc in Petroleum Production and Drilling Engineering from the Institute of Petroleum Engineering, University of Tehran, Iran, in 2014. His research interests include artificial lift systems design and optimisation and application of artificial intelligence methods in modelling and optimisation of production systems.  \nPeyman Pourafshary received his PhD in Petroleum Engineering from University of Texas, Austin, in 2007. Currently, he works as an Assistant Professor in Department of Chemical and Petroleum Engineering at the Sultan Qaboos University, Oman. His research interests are in the fields of production engineering and production optimisation, well stimulation, formation damage and experimental studies and modelling of enhanced oil recovery methods. He has published more than 45 peer reviewed papers in these areas.  \nFarhang Jalali Farahani is currently Professor and faculty member at the University of Tehran. He received his PhD degree from University of Utah, in 1992, and his Master degree from Colorado State University, in 1988, USA. His field of interest is production optimisation in oil and gas industries. He has worked on many projects using high models and computational algorithms.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:18",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach is outlined to assess the EDA macro-parametric approach, specifically addressing its ability to handle feature modeling representation?",
      "topics": [
        "representation"
      ],
      "answer": "The macro-parametric approach's benchmarking focuses on its ability to exchange design intents among heterogeneous CAD systems. Evaluation would involve assessing its performance in mapping different terminologies with identical meanings but different syntax. A key aspect is determining if the mapping is performed syntactically or semantically, with semantic interoperability achieved through ontology-based extensions. The benchmark would also need to quantify the approach's limitations in exchanging singular features or sketches.",
      "chunk_id": 12801,
      "paper_id": "Quantitative optimization of interoperability during feature-based data exchange",
      "paper_title": "Quantitative optimization of interoperability during feature-based data exchange",
      "paper_year": "2016",
      "chunk_content": "The macro-parametric approach [22,23,38,46,54], inspired by the data recovery mechanism of database systems where log files are used for the recovery, is based on the macro information. The macro information is a neutral representation of the modeling commands sequence or modeling history, which is not unique either. Thus, the macro-parametric approach encounters the same problem as ISO-FBDE. The main advantage of the macro-parametric approach is its ability to exchange the design intents, but it cannot exchange singular feature or singular sketch among the heterogeneous CAD systems.  \nIn addition, similar studies have been performed for the parametric exchange of \"round shapes\" be-\ntween a mechanical CAD system and a ship CAD system [45,47]. This paper proposes a method to resolve the problem that occurs when exchanging data between two CAD systems of two different domains: featurebased CAD systems (mechanical CAD systems) and a non-feature-based CAD system (the AVEVA Marine system).  \nAlthough the macro-parametric approach enables the mapping among different terminologies with an identical meaning but different syntax, the mapping is performed syntactically, not semantically. To consider the semantic aspect, Seo et al. [68] extended this approach by developing an ontology based on the macroparametric approach to achieve semantic interoperability between feature-based CAD models. In addition, Samer et al. [1] proposed a method to share CAD models based on the construction of a common design features ontology, which also considered semantic interoperability of knowledge in feature-based CAD models.  \nThe universal product representation (UPR) [64-66] presented an improved centralized architecture that is a union of the data types supported by commercial CAD systems instead of their intersection. The contributions of the UPR method are shown in two aspects:  \n- Union of the data. When creating the neutral feature information, UPR uses a union of the data instead of attempting to find the unambiguous representation, which overcomes a major problem in ISO-FBDE and the macro-parametric approach.\n- Feature rewrite. UPR uses a geometric model when the data types cannot be exchanged using only the parametric information, which is a compromise mechanism to prevent the problem from occurring during the interoperability of a singular feature or singular sketch.  \nThe aforementioned studies (ISO-FBDE, macroparametric approach, UPR) focus on the representation of feature modeling, which is the most common issue in FBDE. Another important issue is how to retrieve the modeling process; no efficient method is available for this purpose. Li et al. [48,49] proposed a procedure recovery approach (PRA) method to attempt to resolve this problem; they presented a two-stage mechanism to recover the modeling process of a feature model in the source system and subsequently used the exchange procedure to simulate a human modeler to reconstruct the feature model in the receiving system.  \nThis paper attempts to resolve the problem of interoperability for a singular feature or singular sketch based on the theory of PRA. According to the geome-  \ntry of a singular feature or singular sketch in the source CAD heterogeneous system, the equivalence of geometry of a feature or sketch in the receiving CAD system can be automatically recovered. Com-pared with ISO-FBDE and the macro-parametric approach, this paper specifies the interoperability of a singular feature or singular sketch among heterogeneous CAD systems. Compared with UPR, this paper surpasses the geometry replacement method in which the singular features are replaced with geometry [64-66]. Under the premise of sufficiently high geometric fidelity, the exchanged model of the receiving CAD system can be parametrically edited.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:20",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for stochastic job-shop scheduling problems, specifically concerning makespan and tardiness?",
      "topics": [
        "genetic"
      ],
      "answer": "The primary objective is to minimize both the expected makespan ($C_{max}$) and the expected total tardiness in stochastic job-shop scheduling problems (S-JSP). This involves considering the probabilistic processing time of operations, where each operation $o_{ij}$ has an expected value $\\mathrm{E}[p_{ij}]$ and variance $v_{ij}$, and using techniques like evolutionary algorithms and ordinal optimization to find a schedule that balances these two conflicting objectives.",
      "chunk_id": 7017,
      "paper_id": "Effective multiobjective EDA for bi-criteria stochastic job-shop scheduling problem",
      "paper_title": "Effective multiobjective EDA for bi-criteria stochastic job-shop scheduling problem",
      "paper_year": "2017",
      "chunk_content": "Gholami and Zandieh (2009) integrated simulation into genetic algorithm to the dynamic scheduling of a flexible job-shop with the objectives of minimizing expected makespan and mean tardiness. Lei (2012) developed an efficient genetic algorithm to solve the problem of scheduling stochastic job shop subject to breakdown with minimizing the makespan. Horng et al. (2012) proposed an evolutionary algorithm ESOO as embedding evolutionary strategy (ES) in ordinal optimization (OO) to solve for a good enough schedule with the objective of minimizing the expected sum of storage expenses and tardiness penalties. Zhang et al. (2012) proposed a two-stage PSO algorithm for S-JSP with the objective of minimizing the expected total weighted tardiness. In the first-stage PSO, a performance estimate is used for quick evaluation of the solutions, and a local search procedure is embedded for accelerating the convergence to promising\nregions in the solution space. The second-stage PSO continues the search process, but applies a more accurate solution evaluation policy. Recently, Yang et al. (2014) developed hybrid evolutionary strategy in ordinal optimization (ESOO) which is embedded optimal computing budget allocation (OCBA) technique into the exploration stage of ESOO to optimize the performance evaluation process by controlling the allocation of simulation times. Lin et al. (2012) proposed a network modeling and evolutionary optimization for scheduling in manufacturing system. Also, Gen and Lin (2014) surveyed the recent multiobjective evolutionary algorithms for solving manufacturing scheduling problems.  \nIn this paper, we extend the approach proposed in the reference (Hao et al. 2013a, b) to improve performance in terms of convergent speed and optimization quality for solving S-JSP with probabilistic processing time to minimize the expected makespan and total tardiness lacking classification of them in Table 1. This approach will describe in detail in \"Effective multiobjectives estimation of distribution algorithm\" section.\nIn order to solve a job-shop scheduling problem in stochastic and static environments, it assumes that the probability  \ndistribution of the processing time is known in advance. The realized outcome of a random processing time of operation only gets to be known at the completion of the processing. In this paper, we use a pure integer programming model to transmute the processing times in terms of stochastic variable. The S-JSP can be formulated as an extended version of JSP. Difference to the conventional JSP, Each operation $o_{i j}$ is carried out under uncertain random disturbance with pregiven expected valued $\\mathrm{E}\\left[p_{i j}\\right]$ and variance $v_{i j}$ where $p_{i j}$ is the processing time of $o_{i j}$ on the machines. The distribution of the variance can be predicted from the experimental data such as normal distribution, uniform distribution and exponential distribution etc. Therefore, the processing time uncertainty can be constructed through the concept scenario $\\xi$ which corresponds to an assignment of reasonable processing time on $o_{i j}$.  \nThe stochastic expected value model of bi-criteria S-JSP may be formulated as follows: the makespan is the maximum completion time of jobs and objective is to find a schedule that minimizes the expected value of makespan $C_{\\max }$, the Eq. (1) and the expected total tardiness, the Eq. (2) conflicting each other.\nIndices:\n$i, k \\quad$ the index of jobs; $i, k=1 \\ldots J$\n$j, h \\quad$ the index of operations; $j, h=1 \\ldots N$\n$m \\quad$ the index of machines; $m=1 \\ldots M$",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:21",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs being applied to tune the parameters of a Particle Swarm Optimization (PSO) algorithm, how does the algorithmic mechanism of maintaining a multivariate histogram probabilistic model of PSO parameters within the EDA influence the PSO's search for optimal solutions?",
      "topics": [
        "evolutionary"
      ],
      "answer": "When an Estimation of Distribution Algorithm (EDA) is used to tune the parameters of a Particle Swarm Optimization (PSO) algorithm, the EDA maintains a multivariate histogram probabilistic model of the PSO parameters. In each generation, the PSO parameters are sampled from this EDA model. Subsequently, new particles, representing candidate solutions, are generated by the PSO operator using these sampled parameters. The performance of these sampled parameters, as reflected in the quality of the generated particles, is then used to update the EDA's probability model. This iterative process allows the EDA to guide the PSO's search by favoring parameter settings that have historically led to better particle performance, effectively evolving the PSO's parameters alongside the PSO's own search process in the original problem search space.",
      "chunk_id": 7283,
      "paper_id": "Parameter Evolution for a Particle Swarm Optimization Algorithm",
      "paper_title": "Parameter Evolution for a Particle Swarm Optimization Algorithm",
      "paper_year": "2010",
      "chunk_content": "The parameter tuning plays a key role in applying evolutionary algorithms (EAs) to real world applications [1]. The success of an EA depends not only on the algorithm itself but also on the problem to be solved. In algorithm design, we could tune the parameters either by repeated running or by analyzing the properties of benchmark probelems. However in applications, the characteristics of the problems maybe incomplete or the problems may not have closed forms, and the repeated experiments may be expensive. Thus the strategies for tuning parameters in algorithm design are no longer suitable in such cases. Furthermore, to achieve the best performance, the parameters of an algorithm may not be fixed throughout the run. For example, at the beginning stages, to get better diversity, the mutation probability might be high; while at the later stages, to achieve better convergence, the mutation probability needs to be low. To overcome the shortcomings of offline parameter tuning strategies, many research turn to set algorithm parameters adaptively online [2].  \nMost of widely adaptively parameter tuning methods could be classified into the following categories.  \n- Randomly selecting parameters: With this strategy, the users give a set of candidate parameter settings by guessing or using prior knowledge. The algorithm then randomly select a parameter setting from the given set 3. The initial parameter set is importance to the algorithm success.\n- Adaptively tuning by feedback: By this strategy, the parameters are adaptively adjusted by heuristic rules with take feedbacks from previous parameter changes [4. How to define the feedback is a key issue.\n- Encoding parameters into chromosomes: The parameters are incorporated into the chromosomes and evolve with decision variables [5]. There is not much additional work to implement this strategy. However, encoding the parameters increases the complexity of the EA search space and may slow down the search.\n- Parameter evolving: Cooperating with the main algorithm, another EA works on the parameters and its optimal solutions, i.e. the best parameters, are used in the main algorithm [6].  \nIn this paper, we follow the idea of parameter evolving strategy. An estimation of distribution algorithm (EDA) 77] 8 is applied to tune the parameters of a particle swarm optimization (PSO) 9] 10. In our approach, an EDA and a PSO evolve simultaneously. The EDA works on the PSO parameter space, while the PSO works on the original problem search space. In the running process, the EDA maintains a multivariate histogram probabilistic model of PSO parameters; and the PSO maintain a set of candidate solutions (particles). In each generation, the PSO parameters are firstly sampled from the EDA model; secondly, new particles are generated by the PSO operator; thirdly, the probability model is updated according to the performances of the sampled parameters.  \nThe rest of the paper is organized as follows. The next section introduces the background of our work, including the problems, the PSO model which are used in the paper, and a brief introduction of EDA. Section 3 presents the details of the proposed method. Section 4 describes and analyzes the experimental results. The final section concludes the paper and outlines future research work.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:23",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for antenna selection in massive MIMO systems, how should practitioners adapt the Cross Entropy (CE) optimization method, as applied in cooperative cognitive radio networks for multiple relay assignment and power allocation, to address the specific challenges of rapidly varying channel conditions and the need for low computational complexity?",
      "topics": [
        "evolutionary"
      ],
      "answer": "Practitioners can adapt the Cross Entropy (CE) optimization by first representing antenna selection as a probabilistic model, similar to its application in cooperative cognitive radio networks. The implementation involves iteratively updating a probability distribution over the possible antenna subsets. In each iteration, antenna subsets are sampled from the current probability distribution, and their spectral efficiency is evaluated. The probability distribution is then updated to favor antenna subsets that yield higher spectral efficiency. To manage rapidly varying channel conditions, the update frequency of the probability distribution should be adjusted based on the channel coherence time. For reducing computational complexity, techniques such as limiting the number of samples drawn in each iteration or employing a low-rank approximation of the probability distribution can be used. Furthermore, incorporating a Successive Interference Cancellation (SIC) based precoder for the selected antennas can help to reduce signal attenuation and mitigate path loss, improving overall system efficiency. This joint approach addresses both antenna selection and precoding in a computationally efficient manner.",
      "chunk_id": 8974,
      "paper_id": "Probabilistic distribution learning algorithm based transmit antenna selection and precoding for millimeter wave massive MIMO systems",
      "paper_title": "Probabilistic distribution learning algorithm based transmit antenna selection and precoding for millimeter wave massive MIMO systems",
      "paper_year": "2021",
      "chunk_content": "Although the multiplexing gain can be achieved with higher dimensions of massive MIMO architecture, the consequences are also faced in terms of computational complexity. Antenna selection can be an effective way to overcome the complexity issues of massive MIMO architecture. Spectral efficiency increases significantly with the number of antennas. However, the gain gets almost constant beyond a certain limit, resulting in reduction of hardware efficiency and increase in power consumption of the system. Authors in [13] have demonstrated that a subset of available antennas can achieve FORMULA_12 of ergodic rate achieved by full antennas. Ref. [14] demonstrates that in order to optimize the hardware, a selection procedure can be opted to choose the antennas experiencing good channel conditions. Authors proved that the advantage of multi-antenna diversity is not sacrificed using only the selected antennas, rather the system efficiency is increased. Exhaustive search (ES) algorithm is\nthe optimal way to choose the desired subset of available antennas. In ES scheme the algorithm iterates and evaluates all possible antenna combinations to select the desired combination that maximizes the spectral efficiency. However, such a scheme is computationally inefficient. An effective transmit antenna selection scheme is required to manage the frequently varying channel conditions for practical systems. Researchers have adopted minimum eigenvalue [15] and constrained cross entropy optimization (CCEO) [16] to choose the sub set of total available antennas. Inspired by the efficiency of evolutionary algorithms, authors in [17] and [18] have adopted binary version of particle swarm optimization (BPSO) algorithm for effective transmit and receive antenna selection. Reference [18] has applied the BPSO on user selection problem. For fully connected architecture, authors in [19] have performed joint antenna selection and precoding using sliding window index selection (SWIS) algorithm for antenna selection and adopting OMP algorithm for beamforming.  \nReferences [20] and [21] have performed joint transmit and receive antenna selection by adopting ant colony optimization and adaptive markov chain monte carlo algorithm respectively. [22] performs transmit antenna selection based on euclidean distance. In [23] survey article, the performance comparison of a transmit antenna selection system with different kinds of receiver architectures is discussed. Authors in [24] have investigated antenna selection methods for bidirectional full-duplex MIMO systems in which antennas at each node can be selected to either transmit or receive configuration. The user scheduling problem using the probabilistic model is discussed in [25]. In [26], for cooperative cognitive radio networks, authors have applied the cross entropy (CE) optimization for multiple relay assignment and power allocation. The resource management for D2D communication using the probabilistic algorithm is performed in [27]. In [28], for low resolution ADCs, authors have compared different beamforming (digital, analog and hybrid) architectures at receiver to study the spectral and energy efficiency tradeoff. This work extends the idea of the probabilistic model and applies the theory on the antenna selection problem aimed for partially connected massive MIMO architecture. Table 1 presents the summary of related work.  \nIn order to efficiently operate the massive MIMO systems in mmW regime, joint application of antenna selection and precoding to achieve optimal energy efficiency and combat path-loss is essential. Also since the channel conditions change rapidly, the proposed algorithm should be computationally efficient to manage the rapid changes. However, most of the existing literature does not present the joint solution for antenna selection and precoding. So motivated by this fact, to improve the system efficiency of a massive MIMO partially connected architecture, we have developed a low complexity solution for joint antenna selection and precod-  \nTable 1 Literature review summary  \ning. Firstly, antenna selection scheme based on probabilistic distribution learning is applied for transmit antenna selection, and secondly, precoder for selected antennas based on SIC algorithm is designed to reduce signal attenuation and mitigate path loss. Summarized below are the main contributions of this work.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:27",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of genetic algorithms and linkage learning, how is the matrix $H$ analyzed to assess the performance of the SNMF approach for learning linkage groups in decomposable problems?",
      "topics": [
        "performance"
      ],
      "answer": "The matrix $H$ is analyzed with an example through different generations to understand the performance of the SNMF approach in learning linkage groups within decomposable problems. This analysis is performed in subsection 5.1 to observe the examples learned by SNMF.",
      "chunk_id": 601,
      "paper_id": "Estimation of distribution algorithm using factor graph and Markov blanket canonical factorization",
      "paper_title": "Estimation of Distribution Algorithm using Factor Graph and Markov Blanket Canonical Factorization",
      "paper_year": "2014",
      "chunk_content": "In this section, we look closely at the SNMF approach by looking at the examples learned by this approach. In subsection 5.1, we see examples of SNMF performance for learning linkage groups in decomposable problems in the context of genetic algorithm and linkage learning. We analyze the matrix $H$ with an example through different generations. In the second subsection, algorithm 1 is used to find the linkage groups in problems with overlapping building blocks to\nsee if the approach is capable of finding the building blocks for additively decomposable problems with overlapping BBs or not. The next subsection is dedicated to the analysis of the effect of the max $F N$ parameter used in algorithm 1 on the performance of the algorithm.",
      "question_type": "evaluation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:28",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the Estimation of Distribution Algorithm (EDA) differ from the Genetic Algorithm (GA) in optimizing pilot patterns for sparse channel estimation, and what advantage does this difference provide?",
      "topics": [
        "genetic"
      ],
      "answer": "The EDA learns and samples the probability distribution of the best individuals in a population at each generation, whereas the GA operates through crossover and mutation. This key difference allows the EDA to introduce population diversity by sampling individuals from a probability distribution, making it less likely to become trapped in local minima and thus more robust than the GA. The pilot pattern optimized by EDA is shown to be more effective in exploiting channel sparsity than those obtained by the GA.",
      "chunk_id": 4384,
      "paper_id": "Pilot Pattern Optimization for Sparse Channel Estimation in OFDM Systems",
      "paper_title": "Pilot Pattern Optimization for Sparse Channel Estimation in OFDM Systems",
      "paper_year": "2015",
      "chunk_content": "CHANNEL estimation, which provides channel state information (CSI) for equalizing channel distortion and demodulating received signals, plays an important part in orthogonal frequency-division multiplexing (OFDM) systems. Comparing with conventional methods, compressive sensing (CS) based channel estimation is capable of exploiting the inherent sparse property of wireless channels, and providing the same CSI with much fewer pilots and high spectral efficiency [1].  \nIn CS-based sparse channel estimation, sparse CSI can be recovered with a high probability, when pilot tones are randomly selected from all OFDM subcarriers. This kind of pilot patterns, corresponding to the partial Fourier sensing matrix  \n[^0]whose rows are randomly selected from the standard Fourier matrix, is difficult to implement in practical systems due to its randomness. One may design an optimal pilot pattern to improve the CSI recovery probability by constructing its corresponding sensing matrix that better satisfies the restricted isometry property (RIP). However, there are no known efficient methods to evaluate whether a given matrix satisfies the RIP in polynomial time. An alternative scheme is to evaluate the mutual coherence of the sensing matrix, which is more strict but practically feasible than the RIP [2]. The smaller the mutual coherence is, the better the sensing matrix satisfies the RIP. One can exhaustively search all possible pilot patterns to find the optimal sensing matrix. However, this is computationally intractable under the given numbers of subcarriers and pilots used in practical OFDM systems. Welch gave a lower bound of mutual coherence in [3]. We may utilize various mathematical theories, e.g., the cyclic different set theory [4], to construct optimal matrices with the Welch bound. However, optimal matrices only exist when their rows and columns satisfy specific conditions, which are not the common cases in OFDM systems. Therefore, efficient methods to search for a suboptimal pilot pattern are highly desirable, when both the total subcarrier number and the pilot number are given.  \nTowards this end, pilot pattern optimization schemes based on random search [5], discrete stochastic approximation [6], [7], and cross-entropy optimization (CEO) [8], [9] have been proposed. However, these approaches are randomized search methods whose convergence time cannot be guaranteed. Moreover, the genetic algorithm (GA), an evolutionary algorithm in artificial intelligence, is employed in [10], [11] to accelerate the search of suboptimal pilot patterns. However, this method is likely to trap into local minima and hence less robust.  \nIn this letter, we propose a new pilot pattern optimization method based upon the estimation of distribution algorithm (EDA) [12] for sparse channel estimation in OFDM systems. The EDA is an evolutionary algorithm, which learns and samples the probability distribution of the best individuals of a population at each generation rather than operates the crossover and mutation in the GA. Hence, it can be regarded as a probability version of the GA. The EDA introduces the population diversity by sampling individuals from the probability distribution rather than producing one specific individual, and hence is unlikely to trap into local minima and more robust than the GA. Simulation results show that the pilot pattern optimized by EDA is more effective in exploiting channel sparsity than the ones obtained by random search, CEO and GA.  \nThe remainder of this letter is organized as follows. In Section II, the sparse channel estimation model and the pilot pattern optimization problem are formulated mathematically. Then, the EDA-based pilot pattern optimization method is proposed in Section III. Finally, simulation results are presented in Section IV for evaluating the performance of the proposed approach.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:30",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned in conjunction with Message Passing Algorithms (MPAs) for constrained optimization problems, what programming considerations should be taken regarding the representation of constraints involving a small number of variables?",
      "topics": [
        "optimization"
      ],
      "answer": "Constraints involving a small number of variables can be represented by factors within a factor graph. The implementation should include these factors in the graph, allowing the EDA to employ MPAs for sampling. This approach attempts to incorporate the constraints directly into the message-passing procedure, rather than relying on potentially disruptive repairing procedures that might compromise dependencies captured by the probabilistic models.",
      "chunk_id": 12582,
      "paper_id": "A review of message passing algorithms in estimation of distribution algorithms",
      "paper_title": "A review of message passing algorithms in estimation of distribution algorithms",
      "paper_year": "2016",
      "chunk_content": "The application of WP and SP can be used as a step previous to the application of the EDA. If the MPA does not converge, the information about the preferred states of the variables or the cavity bias can be used as a way to sample an initial population of solutions. Variables that have not received conflicting messages will be strongly biased to the values found by the MPA. Variables that have received conflicting messages would be sampled more uniformly.\n\nOne of the current limitations of EDAs is in dealing with constraints. Probabilistic models are in general not suitable to represent general constraints between the variables and repairing procedures tend to disrupt the dependencies that have been captured and sampled by the probabilistic models. Constraints that involve a small number of variables can be represented by factors that, once included in the factor graph, can be optimized using EDAs that employ MPAs for sampling in an attempt to incorporate the constraints to the message-passing procedure.\n\n6.7 Use of the topological features\n\nFor optimization problems for which the structure is known, it is usually possible to make a characterization of the problem based on topological features of the graph. It has been confirmed that some characteristics of the difficulty of a problem instance can also be captured by topological descriptors (Echegoyen 2012; Echegoyen et al. 2010b; Mooij 2005; Santana et al. 2008; Weiss 2000). In MPAs, the number and distribution of loops in the graph is a clear example of these topological characteristics (Weiss 2000). Loops can contribute to the arousal of frustration, although for this to happen the problem parameters have also a role to play. In EDAs, the influence of topological characteristics have also been investigated (Echegoyen 2012; Echegoyen et al. 2010b; Santana et al. 2008, 2012a). Furthermore, it has been confirmed that EDAs are able to capture structural properties of the optimization problem in the graphical structure of the probabilistic model (Brownlee et al. 2012; Echegoyen 2012; Echegoyen et al. 2008; Karshenas et al. 2011).\n\nOne open question is how to use the topological information of the problem to decide on the application of MPAs, EDAs, or any other possible combination of them. Analyzing whether problems defined on graph topologies for which MPAs have been theoretically proved to converge are equally solvable by EDAs is another interesting research topic. Results achieved for MPAs can provide some clues of the class of problems where EDAs are expected to be more successful. It is also an open question whether characterizations of the graphs in terms of topological measures can serve to predict the EDA behavior in these problems. Empirical analysis for the study of these measures on LBP have been conducted (Santana et al. 2008).\n\n6.8 Dealing with continuous, permutation-based, and mixed problems\n\nAlthough MPAs such as Gaussian BP have been proposed for continuous problems (Dolev et al. 2009; Malioutov et al. 2006), this type of MPAs have not been applied in EDAs. However, they represent an opportunity for continuous problems where EDAs usually require sophisticated mechanisms to avoid getting trapped in local optima. The application of EDAs to mixed problems, with continuous and discrete variables is also very limited by the complexity of the probabilistic models needed to represent these problem domains (Ocenasek and Schwarz 2002). MPAs such as EP (Minka 2001) show that in these models, inference methods based on MPAs are also possible.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:32",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measure is used to determine when to trigger adaptive variance scaling in the Estimation of Distribution Algorithm (EDA)?",
      "topics": [
        "search"
      ],
      "answer": "The ranked correlation coefficient, denoted as 'r', between the density and the fitness of selected solutions is used. Adaptive variance scaling is triggered when 'r' is at most a threshold value, denoted as '0corr', i.e., when '0corr ≤ r'. In maximization problems, the test is '0corr ≥ r'.",
      "chunk_id": 5574,
      "paper_id": "Matching inductive search bias and problem structure in continuous Estimation-of-distribution Algorithms",
      "paper_title": "Matching inductive search bias and problem structure in continuous Estimation-of-distribution Algorithms",
      "paper_year": "2008",
      "chunk_content": "We propose to base the test for triggering the use of adaptive variance scaling on the ranked correlation coefficient between density and fitness. We use ranked correlation because the most important aspect is that a larger density should be associated with a better fitness value whereas the exact form of the fitness landscape is less important. The results of using this correlation trigger for a slope and for a peak are illustrated in Fig. 4.  \nWe propose to have a threshold value $0^{\\text {corr }}$ such that if the value of the correlation coefficient $r$ between the density and the fitness of the selected solutions is at most the value of the threshold, i.e. $0^{\\text {corr }} \\leqslant r$, then the conventional maximum-likelihood estimate is used in the EDA. Otherwise, the estimate based on adaptive variance scaling is used. Note that in the case of maximization we should test for $0^{\\text {corr }} \\geqslant r$ instead. An experimental illustration of using adaptive variance scaling only when the correlation test was not passed is presented in Fig. 5. Indeed, adaptive variance scaling is now not always used, preventing the variance from becoming unnecessarily large and speeding up convergence.\nIn this section we present the results of experiments performed with the various EDAs based on the normal pdf as described earlier. For clarity, the base normal EDA that we use, employs the greedy building of a Bayesian factorization of the\nnormal pdf with maximum-likelihood estimates as initially introduced under the acronym IDEA (Bosman and Thierens, 2000). The experiments serve to indicate whether our closer analysis of the dynamics of continuous EDAs and their subsequent redesign indeed leads to more efficient continuous EDAs and hence supports our adjusted formulation of lessons and prerequisites for the design of EDAs. For comparison with other existing optimization techniques, we used the state-of-the art in evolutionstrategies research, i.e. the CMA-ES (Hansen et al., 2003; Kern et al., 2004). We further used six well-known numerical optimization problems. The dimensionality of these problems was varied to get a total of twelve problem instances to test the algorithms on.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:33",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the bi-population EDA (BEDA) algorithmic approach detailed for solving the no-idle permutation flow-shop scheduling problem (NIPFSP) with the total tardiness criterion?",
      "topics": [
        "search"
      ],
      "answer": "The primary objective of the bi-population EDA (BEDA) is to leverage two sub-populations, each generated by sampling from different probability models, to enhance search efficiency and maintain population diversity when solving the NIPFSP. Specifically, a global model, updated with a superior population, and a local probability model, updated with the best explored solution, are used in conjunction with an insertion operator to improve local exploitation ability. This approach aims to outperform traditional methods like discrete artificial bee colony (DABC) algorithms and genetic algorithms (GA) in addressing the NIPFSP with the total tardiness criterion.",
      "chunk_id": 4473,
      "paper_id": "A bi-population EDA for solving the no-idle permutation flow-shop scheduling problem with the total tardiness criterion",
      "paper_title": "A bi-population EDA for solving the no-idle permutation flow-shop scheduling problem with the total tardiness criterion",
      "paper_year": "2015",
      "chunk_content": "E-mail address: wangling@mail.tsinghua.edu.cn (L. Wang).  \n[IMAGE_1]  \nFig. 1. The general framework of the EDA.\nwere developed; Very recently, a discrete artificial bee colony (DABC) algorithm [22] were developed. Clearly, it is very important to develop new effective and efficient solution approaches for solving the NIPFSP with total tardiness criterion.  \nAs a population-based evolutionary algorithm, estimation of distribution algorithm (EDA) [23] has gained increasing attention during recent years. Instead of using crossover and mutation operators of genetic algorithm (GA), the EDA produces offspring implicitly by using a probability model according to the knowledge of the obtained solution space during the search process. The EDA is of good ability in global exploration and has been applied to solve some types of scheduling problems, including flow-shop scheduling [24], job-shop scheduling [25], nurse scheduling [26], and resource-constrained project scheduling [27]. However, to the best of our knowledge, there is no reported work about the EDA for solving the NIPFSP. Inspired by the success of the EDA in solving scheduling problems, we will develop an effective bi-population EDA (BEDA) in this paper to solve the NIPFSP with the total tardiness criterion. To solve the problem effectively, two sub-populations are generated by sampling different probability models, i.e., the global model updated with the superior population, and the local probability model updated with the best solution that has been explored. In such a way, the search efficiency can be enhanced and the diversity of the whole population can be maintained to some extent. In addition to the sampling process based on the probability models, the insertion operator is adopted to further improve the local exploitation ability. To reflect the influence of parameter setting, we carry out the study by using the Taguchi method of design-of-experiment (DOE) [28]. The effectiveness of the bi-population strategy and local search procedure is experimentally demonstrated, and the comparisons between the BEDA and the very recent DABC and GA [22] are also presented to show the effectiveness of the BEDA.  \nThe remainder of the paper is organized as follows: In Section 2, the NIPFSP is described. In Section 3, the BEDA for the NIPFSP is presented in details. In Section 4, the influence of parameter setting is investigated, and the numerical results and comparisons are provided. Finally, we end the paper with some conclusions and future work in Section 5.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:36",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what fundamental properties distinguish the Cauchy EDA from BIPOP-CMA-ES, leading to the observed performance differences?",
      "topics": [
        "optimization"
      ],
      "answer": "The results indicate that BIPOP-CMA-ES dominates the Cauchy EDA. The core distinction lies in the adaptation scheme. CMA-ES requires lower population sizes, resulting in faster execution and enabling more frequent algorithm restarts. For the functions tested, this suggests that having a fast local optimizer with the ability to restart it often is more effective than the approach used by the Cauchy EDA.",
      "chunk_id": 7354,
      "paper_id": "Comparison of cauchy EDA and BIPOP-CMA-ES algorithms on the BBOB noiseless testbed",
      "paper_title": "Comparison of Cauchy EDA and BIPOP-CMA-ES Algorithms on the BBOB Noiseless Testbed",
      "paper_year": "2010",
      "chunk_content": "The results indicate that BIPOP-CMA-ES clearly dominates the Cauchy EDA algorithm regardless of the particular optimization conditions. The adaptation scheme used in CMA-ES needs lower population sizes, is thus faster, and allows for more algorithm restarts. For the functions in the testbed, it seems to be better to have fast local optimizer with the possibility to restart it often.\nThe author is supported by the Grant Agency of the Czech Republic with the grant no. 102/08/P094 entitled \"Machine learning methods for solution construction in evolutionary algorithms\".",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:37",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners update the probabilistic model to incorporate experiential Transmission Expansion Planning (TEP) measures when line overloads occur?",
      "topics": [
        "evolutionary"
      ],
      "answer": "To update the probabilistic model in the EDA, practitioners should combine the formula for $p_{l+1}(x)$ which is $\\boldsymbol{p}_{l+1}(x)=(1-\\alpha) \\boldsymbol{p}_{l}(x)+a \\frac{1}{N} \\sum_{k=1}^{N} x_{k: k}^{j}+\\beta \\Delta \\boldsymbol{p}_{l}(x)$ with the additional probability increment vector $\\Delta p_{l}(x)$. Here, $\\beta$ is a constant in the interval $(0,1)$ representing the weight factor of the additional probability increment, and $\\Delta p_{l}(x)$ is calculated based on load shedding at nodes connected to overloaded lines. If two sides of the $i^{\\text {th }}$ line experience load shed as $e_{l}$ and $e_{k}$ and $\\Delta p_{l}(x_{i}) \\neq 0$, another line connected to node $k$ (excluding the $i^{\\text {th }}$ line) is selected to add the additional probability increment.",
      "chunk_id": 4567,
      "paper_id": "Transmission Expansion Planning Based on Hybrid EDADE Algorithm Considering Wind Power Penetration",
      "paper_title": "Transmission Expansion Planning Based on Hybrid EDA/DE Algorithm Considering Wind Power Penetration",
      "paper_year": "2015",
      "chunk_content": "As it can be known and defined from formula (11), $P_{l}\\left(x_{i}\\right)$ is the probability of obtaining a value of 1 in the $i^{\\text {th }}$ component of the population of individuals and its additional probability increment $\\Delta p_{l}\\left(x_{i}\\right)=0 . r_{j}(j=1,2, \\ldots, V)$ in formula (7) gives the load shed of each node after running economic dispatch, where $V$ is the number of nodes in the objective grid. Then the total load shed energy of each node in all scenarios can be obtained as $e_{f}$, as well as the total load shed energy of the whole grid as $E$. It is assumed that there are $m$ lines connected with node $j$, one of the lines is selected randomly to add the additional probability increment. It refers to formula (12).  \n$$\n\\Delta p_{l}\\left(x_{i}\\right)=\\frac{e_{f}}{E}\n$$  \nThere are still another situations. If the two sides of the $i^{\\text {th }}$ line occur load shed as $e_{l}$ and $e_{k}$ and the $\\Delta p_{l}\\left(x_{i}\\right) \\neq 0$, another line connected the node $k$ except the $i^{\\text {th }}$ line is selected to add the additional probability increment. When it comes to only one single line between the node $j$ and $k$, the greater additional probability is applied. The additional probability increment vector of the $l^{\\text {th }}$ generation is then obtained after running above process, as showed below. Plus, the initial additional probability increment vector is a 0 vector.  \n$$\n\\Delta p_{l}(x)=\\left(\\Delta p_{l}\\left(x_{1}\\right), \\Delta p_{l}\\left(x_{2}\\right), \\cdots, \\Delta p_{l}\\left(x_{l}\\right), \\cdots, \\Delta p_{l}\\left(x_{n}\\right)\\right)\n$$  \nThen the improved updating mechanism of probabilistic model in EDA is obtained combining formula (11) with (13).  \n$$\n\\boldsymbol{p}_{l+1}(x)=(1-\\alpha) \\boldsymbol{p}_{l}(x)+a \\frac{1}{N} \\sum_{k=1}^{N} x_{k: k}^{j}+\\beta \\Delta \\boldsymbol{p}_{l}(x)\n$$  \nwhere $\\beta$ is a constant in the interval $(0,1)$, and it is defined as weight factor of additional probability increment, decides the weight of additional probability increment in the offspring probabilistic model. The physical significance of $\\beta$ is how much the weight of the mentioned experiential TEP measure affects the offspring plans when the overload in some lines occurs in normal state.\nThere are mainly two strategies for the two above algorithms cooperating. One is that the evolutionary operation is added into the mutation and crossover of DE to obtain offspring; the other one is that EDA and DE solves the model in sequence as the hybrid process runs EDA firstly and skips to DE until sort of conditions. A simple skipping strategy is put up in this paper. Assuming the maximal iteration is IterMax, EDA is run at the first $\\omega$ IterMax times. Where $\\omega$ is a constant in the interval $(0,1)$, and it is defined as proportion weight coefficient of hybrid algorithm, deciding the proportion of EDA and DE taking in the process of the\nproposed hybrid algorithm. The flow chart of the hybrid EDA/DE algorithm is referred to Figure 3.\n[IMAGE_2]  \nFigure 3. The flow chart of hy bridEDA/DE algorithm",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:40",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, under what mathematical conditions does the performance of sEDA increase relative to UMDA${_c}$ and EMNA${_\\text{global}}$ on CiaS problems, specifically in terms of the problem size $n_{c}$ and the modelling of variable dependencies?",
      "topics": [
        "performance"
      ],
      "answer": "On CiaS problems, the performance of sEDA increases relative to UMDA${_c}$ as the problem size $n_{c}$ increases beyond 4, based on the performance ratio $d_{n} / f(x_{n})$. Here, $d_{n}$ represents the known global optimum and $f(x_{n})$ is the solution found by the algorithm. sEDA's increased performance is attributed to its efficient capture of the importance and dependency of variables, modelling covariance for only 30 percent of the variables.",
      "chunk_id": 5289,
      "paper_id": "Variable Screening for Reduced Dependency Modelling in Gaussian-based Continuous Estimation of Distribution Algorithms",
      "paper_title": "Variable Screening for Reduced Dependency Modelling in Gaussian-based Continuous Estimation of Distribution Algorithms",
      "paper_year": "2012",
      "chunk_content": "Schwefel function : For 10-D and 50-D Schwefel function, the performance of $\\mathrm{EMNA}_{\\text {global }}$ surpasses sEDA and UMDA ${ }_{c}$. We can increase the performance of sEDA by modifying the value of $\\eta$, since we know clearly from the definition of Schwefel function described in Table 4, that all the variables have interaction with each other. Further discussion is in sub-section 4.4.\n[22] discussed about the performance of UMDA ${ }_{c}$ and Nelder-Mead simplex algorithm in CiaS problems. Here we compare UMDA ${ }_{c}, \\mathrm{EMNA}_{\\text {global }}$ and sEDA with number of circles ranging from $2 \\ldots 20$, over a fixed number of function evaluations.  \nFigure 1 shows the performance of UMDA ${ }_{c}$,  \nTable 5. Solution quality comparison for 10-D problem. Bold font represents the best result.  \nU stands for UMDA ${ }_{c}$, E stands for $\\mathrm{EMNA}_{\\text {global }}$, s stands for sEDA. + sign, the value of $t$ test ( 2 tailed) $<0.05$, indicates statistically significant difference when compared with results of sEDA.\n- sign, the value of $t$ test ( 2 tailed) $>0.05$, indicates no statistically significant difference when compared with results of sEDA.\n( $n$ ), when the results are same.  \nTable 6. Solution quality comparison for 50-D problem. Bold font represents the best result.  \nU stands for UMDA ${ }_{c}$, E stands for $\\mathrm{EMNA}_{\\text {global }}$, s stands for sEDA. + sign, the value of $t$ test ( 2 tailed) $<0.05$, indicates statistically significant difference when compared with results of sEDA.\n- sign, the value of $t$ test ( 2 tailed) $>0.05$, indicates no statistically significant difference when compared with results of sEDA.\n$(n)$, when the results are same.  \n$\\mathrm{EMNA}_{\\text {global }}$ and sEDA on the CiaS problems. The xaxis denotes the problem size $\\left(n_{c}\\right)$ while the y -axis is a performance ratio given by $d_{n} / f\\left(x_{n}\\right)$, where $d_{n}$ is the known global optimum and $f\\left(x_{n}\\right)$ is the solution found by the algorithm. Figure 1 shows that the performance of UMDA ${ }_{c}$ is worst than $\\mathrm{EMNA}_{\\text {global }}$ and sEDA. But when sEDA is compared with $\\mathrm{EMNA}_{\\text {global }}$, we found out that up to $n_{c}=4$, the performance is some how  \n[IMAGE0]  \nFigure 1. Median Performance of UMDA ${ }_{c}$, EMNA $_{\\text {global }}$ and sEDA on CiaS problem.\nsimilar but when $n_{c}$ increases, the performance of sEDA also increases.  \nThe nature of variables in the CiaS problems is that some variables are equally important and some are dependent on each other. Here, out of the total number of variables only 30 percent of variables are selected for modelling covariance matrix by sEDA. By analysing the results, we can conclude that sEDA captures the importance and dependency of variables in this problem very efficiently.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:42",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of a hybrid Differential Evolution (DE) with Estimation of Distribution Algorithm (EDA), as presented by Fang et al. (2018) using a Gaussian probabilistic model-based operator for offspring generation, compare to a hybrid DE with EDA that employs random walk mutation to preserve population diversity, as described by Liao et al. (2019), with respect to balancing exploration and exploitation in the search space?",
      "topics": [
        "search",
        "Estimation of Distribution Algorithms",
        "Differential Evolution",
        "hybrid algorithms",
        "exploration vs exploitation"
      ],
      "answer": "Fang et al. (2018) utilize both crossover/mutation operators from DE and a Gaussian probabilistic model from EDA, aiming to leverage the strengths of both paradigms for offspring generation. This approach potentially focuses exploitation by refining solutions around the Gaussian model's mean. In contrast, Liao et al. (2019) use random walk mutation to maintain population diversity, which likely emphasizes exploration by introducing greater variability in the search. The trade-off is that the Gaussian model may lead to faster convergence but a higher risk of local optima, while random walk mutation may provide better global exploration at the cost of slower convergence.",
      "chunk_id": 4118,
      "paper_id": "A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning",
      "paper_title": "A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning",
      "paper_year": "2023",
      "chunk_content": "Another popular and promising means of improving performance is incorporating various intelligent optimization algorithms with the superiority of each algorithm (Shi et al., 2022). The collaboration between the EDA and DE is representative. (Liao et al., 2019) presents a hybrid DE with EDA by the random walk mutation to preserve the population diversity, and the EDA is employed to accelerate the convergence. (Fang et al., 2018) develops a novel algorithm, named the DE/GM, which utilizes both crossover/mutation operators from the DE and a Gaussian probabilistic model-based operator from the EDA for offspring generation. (Zhou and Tan, 2020) studies a discrete supermarket location problem that considers the utilization rate and capacity constraint of the\n[IMAGE0]  \nFig. 1. The main idea of KCACIL.  \n[IMAGE1]  \nFig. 2. The flow chart of KCACIL.\nsupermarkets by a self-adaptive EDA with a differential DE. In (Zhou and Tan, 2020), a hybrid DE with EDA using an ensemble model is studied to minimize the total weighted completion time for a reentrant hybrid flow shop scheduling problem.  \nThe performance of the algorithms is related to exploration and exploitation in the search space (Zhao et al., 2022a). Exploration finds the potential area where the optimal solution is located and involves searching over a large range. Exploitation focuses on the precise location and a refined search over a small area (Khishe, 2020). If the exploration is emphasized excessively, it improves the potential to find the optimal solution but ignores the accuracy of the generated solutions. In contrast, the candidate solutions are refined when only the exploitation is focused. However, the opportunity to seek high-quality solutions from the global area is abandoned, and the search falls into the local optimum. Exploration is vital during the early stage of the algorithms, and refined exploitation is paid more attention during the later evolution (Givi and Hubalovska, 2023). Hence, the trade-off between exploration and exploitation is essential to achieve promising effects. The design of a reasonable algorithm framework and efficient rules are indispensable and challenging (Karaduman et al., 2019).  \nDynamic adaptive adjustment of key parameters is beneficial for exploration and exploitation. (Liao et al., 2023a) presents a knowledge transfer-based adaptive DE that carries out parameter adaptation with niching level and knowledge transfer between two niching techniques to balance diversity and convergence. Reasonable individuals are selected for the transfer to overcome the deficiencies of crowding and speciation. (Huynh et al., 2021) implements the Q-learning DE, which integrates the Q-learning model into the DE to adaptively adjust the control parameters of the algorithm at each iteration for different search domains. (Wei et al., 2020) presents a PSO variant based on multiple adaptive strategies (MAPSO) with an adaptive strategy for the population size. (Liao et al., 2023b) develops a neighborhood information-based adaptive DE with a dynamic neighborhood size mechanism and a novel mutation strategy. (Xiong et al., 2023) develops an enhanced neighborhood-based\nspeciating DE with adaptive control parameters, an external archive, and a crowding relieving mechanism to solve multimodal optimization problems. The aforementioned research shows that parameter adaptation is helpful for exploration and exploitation and saves computational resources. However, multiple-parameter adaptive strategies combined with diverse mechanisms to fully achieve automatic configuration based on various stages is rare.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:45",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, when managing a large number of PHEVs/PEVs charging at a municipal parking station?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithm",
        "Smart Grid",
        "Plug-in Hybrid Electric Vehicles",
        "Plug-in Electric Vehicles"
      ],
      "answer": "The code should implement an Estimation of Distribution Algorithm to optimally manage a large number of PHEVs/PEVs charging. The implementation should focus on solving a large-scale optimization problem within a Smart Grid environment, specifically for a municipal parking station.",
      "chunk_id": 5491,
      "paper_id": "Computational intelligence-based energy management for a large-scale PHEV PEV enabled municipal parking deck",
      "paper_title": "Computational intelligence-based energy management for a large-scale PHEV/PEV enabled municipal parking deck",
      "paper_year": "2012",
      "chunk_content": "Wencong Su*, Mo-Yuen ChowDepartment of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27606, USA\nArticle history:\nReceived 29 June 2011\nReceived in revised form 5 November 2011\nAccepted 30 November 2011\nAvailable online 26 December 2011  \nKeywords:\nPlug-in Hybrid Electric Vehicle (PHEV)\nPlug-in Electric Vehicle (PEV)\nElectric Vehicle (EV)\nSmart Grid\nEstimation of Distribution Algorithm (EDA)\nParticle Swarm Optimization (PSO)\nThere is a growing need to address the potential problems caused by the emergence of Plug-in Hybrid Electric Vehicles (PHEVs) and Plug-in Electric Vehicles (PEVs) within the next 10 years. In the near future, a large number of PHEVs/PEVs in our society will add a large-scale energy load to our power grids, as well as add substantial energy resources that can be utilized. The large penetration of these vehicles into the marketplace poses a potential threat to the existing power grid. The existing parking infrastructure is not ready for the large penetration of plug-in vehicles and the high demand of electricity. Nowadays, the advanced computational intelligence methods can be applied to solve large-scale optimization problems in a Smart Grid environment. In this paper, authors propose and implement a suite of computational intelligence-based algorithms (e.g., Estimation of Distribution Algorithm, Particle Swarm Optimization) for optimally managing a large number of PHEVs/PEVs charging at a municipal parking station. Authors characterize the performance of the proposed methods using a Matlab simulation, and compare it with other optimization techniques.  \n(c) 2011 Elsevier Ltd. All rights reserved.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:46",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of the HIS algorithm, how is the diversity of a newly created population determined and what role does the 'target distribution' play in this process?",
      "topics": [
        "design"
      ],
      "answer": "In HIS, the diversity of a new population is determined by the target distribution, denoted as $(q_{1}(x), \\cdots, q_{L}(x))$, for each probabilistic model. The target distribution is designed to have a sequentially changing diversity. When a new probabilistic model is created, the number of selected search points is adjusted based on the diversity of the target model; a smaller diversity leads to fewer selected points, while a larger diversity results in more selected points.",
      "chunk_id": 11422,
      "paper_id": "Real-coded Estimation of Distribution Algorithm by Using Probabilistic Models with Multiple Learning Rates",
      "paper_title": "Real-coded Estimation of Distribution Algorithm by Using Probabilistic Models with Multiple Learning Rates",
      "paper_year": "2011",
      "chunk_content": "In general EDA, only one population and one probabilistic model are used. Therefore, if the population has been converged and the global optimum is outside the population range, it is difficult to find the global optimum. HIS[12] is another type of EDA that uses multiple populations $\\left(X_{1}, \\cdots, X_{L}\\right)$ and probabilistic models $\\left(p_{1}(x), \\cdots, p_{L}(x)\\right)$ with different diversities. HIS searches using all populations and probabilistic models, and is designed that some populations are converged and others are not. Thus, HIS performs not only to find good solutions quickly but also to avoid converging into the local optimum.  \nHIS has two main operators, which are performed repeatedly sampling and estimation. In sampling, all probabilistic models create search points independently (Fig. 1). In estimation, all the populations are merged into one pool from $X_{l}, X_{l+1}$ and $X_{l-1}$. Then, new probabilistic models are built from the good search points, which are selected from the merged pool (Fig. 2).  \nIn HIS, the diversity of the new created population has to be determined and the target distribution $\\left(q_{1}(x), \\cdots, q_{L}(x)\\right)$ of the probabilistic model should be settled for each model. The target distribution is designed as a model the diversity of which is changed sequentially. In HIS, when a new probabilistic model is created, the number of selected search points is not determined but the target distribution is fixed. Therefore, search points should be selected to build a new probabilistic model that has the target distribution. Thus, the number of selected points is small when the diversity of the target model is small, and conversely the number of selected points is large when the diversity of the target model is large.  \nThis section described several mechanisms of HIS. These mechanisms help HIS to control the diversity of populations. Therefore, HIS can search effectively.\nIn this section, RMM that uses multiple populations and probabilistic models similar to HIS is proposed. RMM refers to a probabilistic model and method for generating search points of PBILc[9]. PBILc uses a simple rule for updating the probabilistic model based on the normal distribution $\\left(N\\left(\\mu_{i}, \\sigma_{i}^{2}\\right)\\right.$, $i$ is a dimension number) in real-coded EDAs, and we feel that facilitates to investigate a effectiveness of using multiple probabilistic models.  \n1. Generate search points using uniform distribution in each population $\\left(X_{1}, \\cdots, X_{L}\\right)$.\n2. Calculate the function values of all search points in populations.\n3. Initialize average $\\left(\\mu_{i}\\right)$ and variance $\\left(\\sigma_{i}^{2}\\right)$ in each probabilistic model. The $\\mu_{i}$ is equal to the design variable of the best search point in the population. The $\\sigma_{i}^{2}$ is set as a squared size of $1 / 4$ of domain.\n4. do $\\{$  \nFor $l=1$ to $L$\n(1) Select good search points from $X_{l-1}, X_{l}, X_{l+1}$.\n(2) Update probabilistic model $p_{l}$ according to eq. 3,4 and learning rate $\\beta_{l}$.\n(3) Generate next population from probabilistic model $p_{l}$.\n(4) Replace population $X_{l}$ with the generated population.\n]until(stopping criterion reached)  \nFigure 3: Pseudo Code  \nThe proposed algorithm has a mechanism to alter the learning rate used for updating each probabilistic model to generate various populations. PBILc uses variance $\\left(\\sigma_{i}^{2}\\right)$ in a probabilistic model, and the value of variance can be controlled by the learning rate.",
      "question_type": "evaluation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:48",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "Based on the experimental results, what is the main conclusion regarding the trade-off between recognition accuracy and computational complexity when using the $\\mathrm{GEFE}_{\\mathrm{ML}}$ algorithm compared to the baseline method across different datasets?",
      "topics": [
        "complexity"
      ],
      "answer": "The $\\mathrm{GEFE}_{\\mathrm{ML}}$ algorithm demonstrates a trade-off where it can achieve comparable or slightly better recognition accuracy with a significant reduction (approximately 40% in Experiment II) in computational complexity compared to the baseline method. While the baseline may outperform $\\mathrm{GEFE}_{\\mathrm{ML}}$ in accuracy on some datasets like MORPH-500, $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text{ts}}$ (instances of $\\mathrm{GEFE}_{\\mathrm{ML}}$) offer a computationally less expensive alternative, especially when considering the normalized Manhattan Distance ($NMD$) for feature vector comparison and evaluating performance using Cumulative Match Characteristic (CMC) and Receiver Operator Characteristic (ROC) curves.",
      "chunk_id": 4922,
      "paper_id": "Genetic & Evolutionary Biometrics  Feature extraction from a Machine Learning perspective",
      "paper_title": "Genetic & Evolutionary Biometrics: Feature Extraction from a Machine Learning Perspective",
      "paper_year": "2012",
      "chunk_content": "In Experiment I, $\\mathrm{GEFE}_{\\mathrm{ML}}$ performed better than the baseline method in terms of average recognition accuracy and average computational complexity. In Experiment II, the average performance of $\\mathrm{GEFE}_{\\mathrm{ML}}$ did not outperform the baseline method in regards to accuracy; however $\\mathrm{GEFE}_{\\mathrm{ML}}$ had approximately a $40 \\%$ reduction in computational complexity.  \nThe Cumulative Match Characteristic (CMC) curves and the Receiver Operator Characteristic (ROC) curves provide further analysis of the performance of $\\mathrm{GEFE}_{\\mathrm{ML}}$. The ROC curves were created using the normalized Manhattan Distance formula, $N M D[8]$, shown in Equation 2, where $h_{i}$ and $h_{j}$ represent the two feature vectors being compared, $l$ represents the length of the feature vectors, and $z$ represents the $z^{\\text {th }}$ feature in a feature vector.  \n$$\nN M D\\left(h_{i}, h_{j}\\right)=\\sum_{i=0}^{j-1} \\frac{\\left|h_{i, z}-h_{j, z}\\right|}{\\max \\left(h_{i, z}-h_{j, z}\\right)}\n$$  \nThe generalizing performance of the best $\\mathrm{FE}^{*}$ and the best $\\mathrm{FE}^{\\text {ts }}$ were measured on FRGC-100 and MORPH-500 using CMC and ROC curves. We chose $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ from the $\\mathrm{GEFE}_{\\mathrm{ML}}$ that used a maximum of 1000 FE evaluations because it had the best average performance on FRGC-100 with respect to the $\\mathrm{GEFE}_{\\mathrm{ML}}$ instances.  \nFigure 7a shows the CMC curves of the baseline method, $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ (which appears as 'FEts') based on their performances on the first test set, FRGC-100. One can see that at Rank 1 and Rank 2, $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ outperform the baseline method. At Rank 3, all three methods perform equally; however, the performances of $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ are computationally less expensive.  \nIn Figure 7b, one can see that the ROC curves of the three methods are similar; however, the curve of $\\mathrm{FE}^{*}$ has a slight separation from the other two methods. Of the three methods, with respect to Figure 7b, $\\mathrm{FE}^{*}$ has the best performance.  \nFigure 8a provides the CMC curves of the performances of the three methods with respect to the second test set, MORPH-500. The baseline method outperforms $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ at each rank with a maximum accuracy of $64 \\%$ at Rank 10. The Rank 10 accuracies for $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ were $58.2 \\%$ and $55.8 \\%$. These results are encouraging when one considers that $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ were trained on only 100 subjects from a different database. This is also the case with the ROC curves shown in Figure 8b. The performances of the three methods are somewhat similar; however, the performances of $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ come at a fraction of the cost of the baseline method.\n[IMAGE9]  \nFigure 7a. CMC curve of Baseline, $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ on FRGC-100\n[IMAGE10]  \nFigure 7b. ROC curve of Baseline, $\\mathrm{FE}^{*}$ and $\\mathrm{FE}^{\\text {ts }}$ on FRGC-100  \n[IMAGE11]",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:50",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms (EDAs) applied to the Quadratic Assignment Problem (QAP), how does the algorithmic mechanism of using Mallows Models with Hamming distance based kernels contribute to solving this NP-hard problem?",
      "topics": [
        "genetic"
      ],
      "answer": "Estimation of Distribution Algorithms (EDAs) are used to solve permutation problems like the NP-hard Quadratic Assignment Problem (QAP) by introducing distance-based exponential models. Specifically, Mallows Models are employed, and the approach approximates the QAP with Hamming distance based kernels of these Mallows Models. This involves using the Hamming distance to measure the difference between permutations within the Mallows Model framework, which is then used to guide the search for better solutions to the QAP.",
      "chunk_id": 7875,
      "paper_id": "Approaching the quadratic assignment problem with kernels of mallows models under the hamming distance",
      "paper_title": "Approaching the Quadratic Assignment Problem with Kernels of Mallows Models under the Hamming Distance",
      "paper_year": "2019",
      "chunk_content": "Etor ArzaBCAM - Basque Center for Applied MathematicsBilbao, Spain - Basque Countryearza@bcamath.orgAritz PerezBCAM - Basque Center for Applied MathematicsBilbao, Spain - Basque Countryaperez@bcamath.org\nThe Quadratic Assignment Problem (QAP) is a specially challenging permutation-based np-hard combinatorial optimization problem, since instances of size $n>40$ are seldom solved using exact methods. In this sense, many approximate methods have been published to tackle this problem, including Estimation of Distribution Algorithms (EDAs). In particular, EDAs have been used to solve permutation problems by introducing distance based exponential models, such as the Mallows Models. In this paper we approximate the QAP with a Hamming distance based kernels of Mallows Models.\nBased on the benchmark instances, we have observed that our approach is competitive, reaching the best-known solution in $71 \\%$ of the tested instances, especially on large instances ( $n>125$ ), where it is able to outperform state of the art results in 43 out of 288 instances.\n- Mathematics of computing $\\rightarrow$ Combinatorial optimization; Evolutionary algorithms;\nEstimation of Distribution Algorithm, Quadratic Assignment Problem, Evolutionary Algorithm, Hamming distance\nEtor Arza, Josu Ceberio, Aritz Perez, and Ekhine Irurozki. 2019. Approaching the Quadratic Assignment Problem with Kernels of Mallows Models under the Hamming Distance. In Genetic and Evolutionary Computation Conference Companion (GECCO '19 Companion), July 13-17, 2019, Prague, Czech Republic. ACM, New York, NY, USA, 2 pages. https://doi.org/10.1145/ 3319619.3321976  \n[^0]",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:52",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using neighborhood search strategies, how should practitioners incorporate reference-based and tabu-based searches to optimize population performance?",
      "topics": [
        "performance"
      ],
      "answer": "To incorporate reference-based neighborhood search, select the optimal individual as the reference solution. During the search, randomly select two locations $i$ and $j$ (where $i<j$) and insert the jobs at positions $i$ and $j$ from the reference solution into the corresponding positions of the population individuals. If the new solution's performance is better, replace the original individual. For tabu-based search, add truncated individuals from the previous generation to a tabu table. Before neighborhood search, check if the candidate solution exists in the tabu table. If it does, skip the search; otherwise, randomly select either a swap or insertion operator for the neighborhood search.",
      "chunk_id": 3964,
      "paper_id": "An estimation of distribution algorithm with multiple intensification strategies for two-stage hybrid flow-shop scheduling problem with sequence-dependent setup time",
      "paper_title": "An estimation of distribution algorithm with multiple intensification strategies for two-stage hybrid flow-shop scheduling problem with sequence-dependent setup time",
      "paper_year": "2023",
      "chunk_content": "In the proposed algorithm, two neighborhood search strategies are used to further optimize the performance of the population. These two strategies are reference-based neighborhood search and tabu-based neighborhood search.\nIn this method, the optimal individual in the population is recommended as the reference solution. The process of neighborhood search is performed based on the reference solution. Two locations $i$ and $j$, where $(i<j)$, are selected during the search process. The jobs at positions $i$ and $j$ in the reference solution are inserted into $i$ and $j$ positions of the population individuals, respectively. Then, the neighborhood search solution is obtained. The new solution is compared to the original population individual. If the performance of the new  \nsolution is better than that of the original population individual, the original population individual is replaced by the corresponding neighborhood search solution.  \n  \n2. Tabu-based neighborhood search  \nIn the method, the truncated individuals of the population in the previous generation are added to the taboo table. The candidate solution is compared with the taboo table. If the candidate solution is included in the taboo table, the neighborhood search is not carried out. Otherwise, the neighborhood search is carried out. One strategy is randomly selected between swap and insertion operators for neighborhood search.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:02:54",
      "generation_style": "practical_application"
    },
    {
      "question": "How is the computational complexity of the Pareto-based Estimation of Distribution Algorithm (PBEDA) analyzed, specifically considering the activity list (AML) encoding scheme where $\\mathrm{AML}= [\\pi, \\lambda]$, with $\\pi$ representing the activity priority list and $\\lambda$ representing the mode list?",
      "topics": [
        "complexity"
      ],
      "answer": "The analysis of the computational complexity of the PBEDA considers the AML encoding scheme, where $\\pi = [\\pi_{1}, \\pi_{2}, \\ldots, \\pi_{j}]$ denotes the priority of activities and $\\lambda = [\\lambda_{1}, \\lambda_{2}, \\ldots, \\lambda_{j}]$ represents the execution mode of each activity, with $\\lambda_{j} \\in \\{1, 2, \\ldots, M_{j}\\}$. The serial schedule generation scheme is modified to build a schedule according to activities. Given an AML, activities are scheduled in the activity list order as early as possible, satisfying precedence constraints and the peak power load limit. The complexity analysis would need to account for the number of activities $j$, the number of modes $M_j$ for each activity, the serial schedule generation scheme's iterations $n$, the size of the set of scheduled activities $\\boldsymbol{S}_{\n}$, and the size of the decision set $\\boldsymbol{D}_{\n}$. The deviation from the peak power load limit at time $t$, denoted by $\\pi P_{t}$, along with the sets of activity's first and second part active at the schedule time, $\\boldsymbol{A}_{\\boldsymbol{1 t}}$ and FORMULA_64, respectively, also contribute to the overall computational cost. A detailed complexity analysis would involve quantifying the computational cost of each step in the modified serial schedule generation scheme as a function of these parameters.",
      "chunk_id": 4398,
      "paper_id": "Reduction of carbon emissions and project makespan by a Pareto-based estimation of distribution algorithm",
      "paper_title": "Reduction of carbon emissions and project makespan by a Pareto-based estimation of distribution algorithm",
      "paper_year": "2015",
      "chunk_content": "In this section, the encoding and decoding schemes, initialization, hybrid probability model, sampling mechanism, and updating mechanism will be presented sequentially. Then, the framework of the PBEDA will be given and the computational complexity will be analyzed.  \nTable 1\nPower requirements and corresponding durations of the example in Fig. 3.\n[IMAGE3]\nExperimental evaluation by Hartmann and Kolisch (2000) showed that metaheuristics using the activity list perform generally better than those adopting other representations. As the MOMRCPSP-Makespan-Carbon is a generalization of the RCPSP, the AML based encoding scheme is adopted in the PBEDA expecting to get good results. That is, $\\mathrm{AML}=[\\pi, \\lambda]$, where $\\pi=\\left[\\pi_{1}, \\pi_{2}, \\ldots, \\pi_{j}\\right]$ is the activity list, denoting the priority of activities; and $\\lambda=\\left[\\lambda_{1}, \\lambda_{2}, \\ldots, \\lambda_{j}\\right]$ is the mode list, where $\\lambda_{j} \\in\\left\\{1,2, \\ldots, M_{j}\\right\\}$, representing the execution mode of each activity.  \nNote that activities in this paper are different from the original form (see Section 2). The serial schedule generation scheme (Kolisch, 1996) (see Fig. A1 for pseudo code) is modified to build a schedule (a solution to an individual) according to activities in this paper. When an AML is given, the activities are scheduled in the activity list order as early as possible, satisfying the precedence constraints and peak power load limit. The pseudo code of the scheme is illustrated in Fig. 5, where $n$ is the iteration; $\\boldsymbol{S}_{\\boldsymbol{n}}$ denotes the set of scheduled activities; $\\boldsymbol{D}_{\\boldsymbol{n}}$ is the decision set, containing all schedulable activities; $\\pi P_{t}$ denotes the deviation from the peak power load limit at time $t ; \\boldsymbol{A}_{\\boldsymbol{1 t}}$ and FORMULA_64 represent sets of activity's first and second part active at the schedule time, respectively.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:02:57",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantage is gained by using the FLH-based solution-generate method, compared to representing a solution as a set $h$ and a factory assignment vector $s$, when applied to the Distributed Permutation Flowshop Scheduling Problem (DPFSP)?",
      "topics": [
        "search"
      ],
      "answer": "The FLH-based solution-generate method aims to efficiently generate feasible solutions $h$ from a given factory assignment vector $s$. This approach is intended to decrease the scale of the searching space, compared to directly representing a solution as a set $h$ (containing job permutation vectors for each factory) and a factory assignment vector $s$. The FLH method involves calculating the total processing time $T_{i}^{f}$ for each job $job_{i}^{f}$ assigned to factory $f$, sorting jobs based on $T_{i}^{f}$, and iteratively building a best partial sequence to minimize completion time, contrasting with directly defining job permutations.",
      "chunk_id": 12480,
      "paper_id": "A hybrid estimation of distribution algorithm for distributed permutation flowshop scheduling with flowline eligibility",
      "paper_title": "A Hybrid Estimation of Distribution Algorithm for Distributed Permutation Flowshop Scheduling with Flowline Eligibility",
      "paper_year": "2016",
      "chunk_content": "Solution representation is a key issue for every metaheuristic method. In the regular DPFSP, a set of $F$ lists or the two layer encoding based method is the most widely used representation. In the DPFSP with flowline eligibility constraint, we represent every feasible solution as a set $h$ as same as DPFSP and a factory assignment vector $s$, each list of $h$ contain a job permutation vector with the order in which jobs will be processed at each factory. This kind of representation is the most straightforward method, for instance, if there is a problem with 10 jobs ( $n=10$ ) and three factories $(F=3)$, and $M_{1}=\\{1,3\\}, M_{2}=\\{2\\}$, the sets of unavailable factories of the other jobs are empty. One feasible solution is :  \n$$\nh=\\left\\{\\begin{array}{c}\n10,4,2,8 \\\\\n1,9,6 \\\\\n5,3,7\n\\end{array}\\right.\n$$  \nand  \n$$\ns=\\{2,1,3,1,3,2,3,1,2,1\\}\n$$  \nIn order to execute the searching operator efficiently and decrease the scale of searching space, in this paper we proposed a novel solution-generate method, which makes it possible to generate a new feasible solution $h$ from a given factory assignment vector $s$. This novel method is based on a heuristic for total flow time minimization in permutation flow shops, which is first proposed by Framinan and Leisten (FLH) [15]. The details of FLH based solution-generate method will be described as follows:  \nStep 1: For each factory $f$, let  \n$$\nS^{f}=\\left\\{j o b_{i}^{f}, j o b_{i}^{f}, \\ldots, j o b_{i}^{f}\\right\\}\n$$  \nrepresents the set of jobs assigned to factory $f$ and is calculated from the factory assignment vector $s$;  \nStep 2: For job $j o b_{i}^{f}$ each set $S^{f}$, calculate the total processing time $T_{i}^{f}$ which is given by:  \n$$\nT_{i}^{f}=\\sum_{j=1}^{M} T_{i j}\n$$  \nthen sort all jobs of $S^{f}$ in ascending order of $T_{i}^{f}$;\nStep 3: Set $k=2$, Select the first two jobs from the sorted list and choose the better between the two feasible sequences as the best partial sequence so far.  \nStep 4: let $k=k+1$. Choose the $k$ th job from the sorted list and insert it into the $k$ possible positions of the temporary best partial sequence. The one with minimum completion time is selected as the best partial sequence obtained so far;  \nStep 5: If $k=n$, stop, let FORMULA_83 and go to Step 1; else, go to Step 4.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:02:59",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the SHEDA model, specifically focusing on how the probabilistic models are updated after the initialization and evaluation steps?",
      "topics": [
        "EDAs",
        "SHEDA",
        "probabilistic models",
        "MLDG",
        "OI strategy"
      ],
      "answer": "After initializing individuals using the OI strategy (Algorithm 1) and evaluating them, the SHEDA model performs the following steps to update the probabilistic models: First, the MLDG (Algorithm 3) is applied to generate synthetic individuals, and both original and synthetic individuals are stored in the archive. Then, the top $N_{b}$ individuals from the archive are selected to update the probabilistic models. This update involves computing $\\mu$ and FORMULA_113 for continuous variables using equations (2) and (3), and calculating the probabilities for discrete variables using equation (5).",
      "chunk_id": 3777,
      "paper_id": "Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks",
      "paper_title": "Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks",
      "paper_year": "2023",
      "chunk_content": "The pseudo code of the complete SHEDA is shown in Algorithm 4. After encoding the CNNs, the SHEDA mainly has the following five steps.  \nStep 1: SHEDA initializes individuals through OI strategy (Algorithm 1) and evaluates them by the training-based evaluation. Then the MLDG (Algorithm 3) is performed on these evaluated individuals to generate synthetic individuals. Both the original and generated individuals will be stored in the arch.  \nStep 2: The $N_{b}$ best individuals in the arch (including the generated synthetic individuals) are used to update the probabilistic models, i.e., to compute the $\\mu$ and FORMULA_113 for continuous variables [i.e.,(2) and(3)] and calculate the prob for discrete variables [i.e., (5)].",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:02",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of optimizing a group insurance portfolio using an Estimation of Distribution Algorithm (EDA), how is the objective function adjusted to penalize insured members who do not meet a minimum investment threshold, and what specific formula is used to calculate this penalty?",
      "topics": [
        "optimization"
      ],
      "answer": "To ensure a minimum investment amount, a penalty mechanism is applied to the objective function, denoted as \\(J^{\\prime}(X^{k}, \\beta^{k})\\). This adjusted objective function is calculated as \\(J^{\\prime}(X^{k}, \\beta^{k}) = J(X^{k}, \\beta^{k}) \\prod_{k=1}^{n} v_{k}\\), where \\(J(X^{k}, \\beta^{k})\\) is the original objective function and \\(v_{k}\\) is the penalty rate for the \\(k\\)th insured. The penalty rate \\(v_{k}\\) is determined by \\(v_{k} = 0.9 + \\frac{D_{k}}{D}\\) if \\(\\frac{D_{k}}{D} < 0.1\\), and \\(v_{k} = 1\\) if \\(\\frac{D_{k}}{D} \\geq 0.1\\). Here, \\(D_{k}\\) represents the total investment amount of the \\(k\\)th insured, and \\(D\\) is the total investment amount of the entire group. This penalty enforces that each insured invests at least 10% of the total investment amount.",
      "chunk_id": 2094,
      "paper_id": "A Coevolutionary Estimation of Distribution Algorithm for Group Insurance Portfolio",
      "paper_title": "A Coevolutionary Estimation of Distribution Algorithm for Group Insurance Portfolio",
      "paper_year": "2022",
      "chunk_content": "Similarly, denoted the death compensation rate of each endowment policy for the $k$ th insured at age $t$ with purchase at age $t_{1}$ as $\\eta_{2 i j}{ }^{k}\\left(t_{1}, t\\right)$, the death compensation $Z^{k}(t)$ is calculated by summing up all of the death compensations of endowment policies for the $k$ th insured, i.e.,  \n$$\nZ^{k}(t)=\\sum_{i=1}^{n_{1}} \\sum_{j=1}^{m_{i}} x_{i j} \\eta_{2 i j}^{k}\\left(t_{0}^{k}, t_{0}^{k}+t\\right)\n$$  \nAs for the disposable cash in hand $C(t)$ for the whole group, it is calculated by the sum of the balance at time $(t-1)$ and the disposable income for insurance investment of the whole group $I(t)$, and subtracts the medical expenses that are not covered by the selected hospitalization policy of each person. Denoted the medical expense for the diseases in the $s$ th group as $z_{s}, C(t)$ is calculated as  \n$$\n\\begin{aligned}\n& C(t)=\\left\\{\\begin{array}{cc}\nI_{1}, & \\text { if } t=0 \\\\\nC(t-1)+I(t)-\\sum_{k=1}^{n} \\\\\n\\times\\left(\\sum_{i=1}^{n_{1}} \\sum_{j=1}^{m_{i}} v_{i j}^{k}(t) x_{i j}^{k}\\right. \\\\\n\\left.-\\sum_{s=1}^{n_{2}-\\beta^{k}} p_{s}^{k}\\left(t+t_{0}^{k}\\right) z_{s}^{k}(t)\\right), & \\text { otherwise }\n\\end{array}\\right. \\\\\n& I(t)=\\sum_{k=1}^{n} I_{2}^{k}\\left(t+t_{0}^{k}\\right)\n\\end{aligned}\n$$  \nwhere $v_{i j}^{k}(t) \\in\\{0,1\\}$ is an indicator of whether or not the $k$ th member invests in each endowment policy. $p_{s}{ }^{k}(\\mathrm{t})$ is the probability that the $k$ th insured will suffer from the diseases in the $s$ th group. $I_{2}{ }^{k}(t)$ is the income of the $k$ th insured at age $t$.  \nBesides, each insured in the group should invest in a minimum amount of endowment policy to guarantee the basic need. Therefore, a penalty mechanism given in (17) is implemented to support this demand  \n$$\n\\begin{aligned}\n& J^{\\prime}\\left(X^{k}, \\beta^{k}\\right)=J\\left(X^{k}, \\beta^{k}\\right) \\prod_{k=1}^{n} v_{k} \\\\\n& v_{k}= \\begin{cases}0.9+\\frac{D_{k}}{D}, & \\text { if } \\frac{D_{k}}{D}<0.1 \\\\\n1, & \\text { if } \\frac{D_{k}}{D} \\geq 0.1\\end{cases}\n\\end{aligned}\n$$  \nHere, the minimum amount for each insured to invest is set to be $10 \\%$ of the whole investment amount. $v_{k}$ is the penalty rate. $D_{k}$ is the total investment amount of the $k$ th insured while $D$ is the total investment amount of the whole group. $J^{\\prime}\\left(X^{k}, \\beta^{k}\\right)$ is the final objective function, which we need to maximize.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:04",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of using Mixtures of Factor Analyzers (MFAs) within Estimation of Distribution Algorithms (EDAs) when optimizing functions such as Rosenbrock and Griewank?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective of using MFAs in continuous EDAs is to improve the estimation of density by creating clusters of similar individuals, which can be considered as sub-populations. This allows for a more accurate estimation of the distribution for each cluster, leading to better performance compared to single Factor Analyzers (FAs). By sampling new individuals from these distributions, the algorithm can more easily search for optimal solutions, particularly when the center points of some clusters are close to the optimal and the error covariance matrix has small diagonal elements.",
      "chunk_id": 13177,
      "paper_id": "Evolutionary optimization by distribution estimation with mixtures of factor Analyzers",
      "paper_title": "Evolutionary optimization by distribution estimation with. mixtures of factor Analyzers",
      "paper_year": "2002",
      "chunk_content": "To verify the quality of our method, we use the Rosenbrock and Griewank functions,  \n$$\n\\begin{aligned}\nf_{\\text {Rosenbrock }}(\\mathbf{x}) & =\\sum_{i=2}^{d}\\left[100\\left(x_{i}-x_{i-1}^{2}\\right)^{2}+\\left(1-x_{i-1}\\right)^{2}\\right] \\\\\nf_{\\text {Griewank }}(\\mathbf{x}) & =1+\\sum_{i=1}^{d} \\frac{x_{i}^{2}}{4000}-\\prod_{i=1}^{d} \\cos \\left(\\frac{x_{i}}{\\sqrt{i}}\\right)\n\\end{aligned}\n$$\nWe compare the results of MFAs with that of single FAs to show the effect of mixture model in the continuous EDAs with latent variables. The population size $N$ in all experiments was 1000 and the algorithm was stopped when the number of generation was 1000. Thus, all methods were given the same computational resource in the total number of function evaluations, i.e., $10^{6}$.  \nFigure 2 illustrate the impact of EDAs with MFAs on the seven dimensional Rosenbrock's function optimization, where the range of all the components of the individual is $-2.048 \\leq x_{i} \\leq 2.048$. Without regard to the dimension of latent variables, the MFAs $(M \\geq 2)$ achieve better performance than the single FAs $(M=1)$. In all experiments by MFA methods, we found the satisfiable solutions except the two mixture model cases. The best one was 0.000293 at the point  \n[^0]:    ${ }^{2}$ This termination condition is also from the Ghahramani's software  \n[IMAGE0]  \nFig. 2. Optimum values found in our experiments in terms of the number of mixtures and the dimension of the latent variables (minimum values among 10 runs for each setting).\n$\\mathbf{x}=(0.999750,0.999493,0.999283,0.999912,1.000168$, $1.000931,1.002600)$ when $M=20$ and $q=6$. This seems attributed to the fact that MFAs make the clusters of similar individuals which can be considered as sub-populations and appropriately estimate the density for each cluster. As the generation goes by, some of these clusters have the center points very close to the optimal and the diagonal elements of the error covariance matrix have small values. Therefore, we can search for the optimal solution easily by sampling new individuals from the corresponding distributions.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:06",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms, how does the algorithmic mechanism of iteratively learning a statistical model and subsequently sampling new solutions from that model contribute to the overall optimization process, particularly when integrated within a hybrid approach like Memetic Path Relinking (MemPR)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "Estimation of Distribution Algorithms (EDAs) function by iteratively learning a statistical model of good solutions. This learned model is then used for sampling new solutions. In Memetic Path Relinking (MemPR), which is a hybrid algorithm, this iterative learning and sampling process is integrated with memetic, evolutionary, and path relinking techniques. The statistical model learned by the EDA component guides the generation of new solutions within the population, influencing which areas of the search space are explored by the other operators in MemPR. The goal is to create a robust algorithm.",
      "chunk_id": 10895,
      "paper_id": "Analysing a Hybrid Model-Based Evolutionary Algorithm for a Hard Grouping Problem",
      "paper_title": "Analysing a Hybrid Model-Based Evolutionary Algorithm for a Hard Grouping Problem",
      "paper_year": "2018",
      "chunk_content": "Sebastian Raggi ${ }^{1(\\boxtimes)}$, Andreas Beham ${ }^{1,2}$, Stefan Wagner ${ }^{1}$, and Michael Affenzeller ${ }^{1,2}$${ }^{1}$ Heuristic and Evolutionary Algorithms Laboratory, University of Applied Sciences Upper Austria, Hagenberg, Softwarepark 11, 4232 Hagenberg, Austria sebastian.raggi@fh-hagenberg.at${ }^{2}$ Institute for Formal Models and Verification, Johannes Kepler University Linz, Altenberger Strasse 69, 4040 Linz, Austria\nWe present a new hybrid model-based algorithm called Memetic Path Relinking (MemPR). MemPR incorporates ideas of memetic, evolutionary, model-based algorithms and path relinking. It uses different operators that compete to fill a small population of high quality solutions. We present a new hard grouping problem derived from a real world transport lot building problem. In order to better understand the algorithm as well as the problem we analyse the impact of the different operators on solution quality and which operators perform best at which stage of optimisation. Finally we compare MemPR to other state-of-the-art algorithms and find that MemPR outperforms them on real-world problem instances.  \nKeywords: Hybrid algorithm $\\cdot$ Memetic algorithm\nEstimation of distribution algorithm $\\cdot$ Grouping problem\nMany modern optimisation algorithms are actually hybrids between different techniques. Memetic algorithms are the combination of population-based and trajectory based optimisation techniques. They have attracted a significant amount of research interest in recent years [1]. Memetic algorithms are especially successful at solving combinatorial optimisation problems [2]. Estimation of distribution algorithms are another class of algorithms that have been studied extensively [3]. They work by iteratively learning a statistical model of good solutions followed by the sampling of new solutions from that model. Path relinking (PR) was originally employed as an intensification strategy for tabu search [4]. It was also successfully used to explore paths between elite solutions in GRASP and scatter search FORMULA_8.  \nThe no free lunch theorem states that no algorithm can outperform all others on every problem [7]. The main idea behind the algorithm presented in this paper  \nis that by incorporating all of the previously mentioned approaches we can get a very robust algorithm that can tackle a wide variety of problem instances with different characteristics. An algorithm that treats problems as a black box and can solve them reasonable well is very valuable, especially when dealing with real-world problems.\nWhen optimising real-world problems it is very likely that the problem definition, i.e. constraints, objective, is going to be adapted over time. When presenting optimisation results of real world problems to practitioners it is very important that the presented solutions are at least local optima. Otherwise even very good results might be dismissed when a human can find, inspired by the presented solution, a very similar but better solution.  \nThe rest of this article is structured as follows. In Sect. 2 we describe the realworld transport lot building problem we want to solve. In Sect. 3 we describe our new memetic path relinking algorithm. In Sect. 4 we analyse how much the different operators contribute to the population and how this contributions change over time. Additionally we investigate the influence of the operators on the quality of solutions found. We compare our algorithm against four different algorithms on real-world problem instances in Sect. 5. Finally, there is a short discussion and outlook.",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:08",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for permutation-based problems using Random Keys (RK), how should practitioners configure a cooling scheme within RK-EDA to effectively balance exploration and exploitation of the search space?",
      "topics": [
        "search"
      ],
      "answer": "To implement RK-EDA, a novel RK-based EDA, for permutation problems, practitioners should incorporate a cooling scheme to control the variance in the probabilistic model. This cooling scheme is crucial for balancing exploration and exploitation. The specific details of the cooling scheme, such as the cooling rate or initial variance, are not provided, but the cooling scheme's purpose is to improve RK-EDA's performance on Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.",
      "chunk_id": 12297,
      "paper_id": "RK-EDA- A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_title": "RK-EDA: A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "Mayowa Ayodele ${ }^{(\\boxtimes)}$, John McCall, and Olivier Regnier-CoudertRobert Gordon University, Aberdeen, UK\\{m.m.ayodele,j.mccall, o.regnier-coudert\\}@rgu.ac.uk\nThe challenges of solving problems naturally represented as permutations by Estimation of Distribution Algorithms (EDAs) have been a recent focus of interest in the evolutionary computation community. One of the most common alternative representations for permutation based problems is the Random Key (RK), which enables the use of continuous approaches for this problem domain. However, the use of RK in EDAs have not produced competitive results to date and more recent research on permutation based EDAs have focused on creating superior algorithms with specially adapted representations. In this paper, we present RK-EDA; a novel RK based EDA that uses a cooling scheme to balance the exploration and exploitation of a search space by controlling the variance in its probabilistic model. Unlike the general performance of RK based EDAs, RK-EDA is actually competitive with the best EDAs on common permutation test problems: Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.  \nKeywords: Estimation of distribution algorithm $\\cdot$ Random key $\\cdot$ Permutation problems $\\cdot$ Cooling scheme FORMULA_4 Univariate model",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:10",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the IEDA discussed, how does the algorithm incorporate mutation to increase population diversity, and what is the termination criterion based on the number of iterations?",
      "topics": [
        "mutation",
        "termination criterion"
      ],
      "answer": "The IEDA incorporates mutation by applying crossover and mutation operations from IGA (presumably, a Genetic Algorithm) to all individuals in each generation. This is done to generate new individuals and increase the diversity of the population. The termination criterion is set as a maximum iteration, denoted as G, which is equal to 5 times n (G = 5 × n), where n is not further defined in this context.",
      "chunk_id": 11048,
      "paper_id": "Independent tasks scheduling in cloud computing via improved estimation of distribution algorithm",
      "paper_title": "Independent Tasks Scheduling in Cloud Computing via Improved Estimation of Distribution Algorithm",
      "paper_year": "2018",
      "chunk_content": "Finally, our sampling strategy in IEDA is divided into two parts: one is probabilistic sampling by PBIL probability model; on the other hand, in order to increase the diversity of population, the crossover and mutation operation of IGA are applied to all individuals of this generation to generate new individuals. Furthermore, an improved and novel elitism criterion is employed, which converts the worst individual wg in this generation to the best individual bg-1 in the last generation after sampling.\nAfter elaborating on the improvements of PBIL algorithm, our proposed IEDA is presented as Algorithm 1. Simultaneously, the population size of IEDA is set to $\\mathrm{N}=\\mathrm{n} \\times \\mathrm{m}$, and the maximum iteration $\\mathrm{G}=5 \\times \\mathrm{n}$ is seen as a termination criterion.  \nTABLE. 1 After elaborating on the improvements\nAs mentioned earlier, there is no state-of-the-art algorithm for solving the studied problem, so three different comparative approaches: EMM[4], MGA [5], and PBIL[7] are chosen to compare with our proposed IEDA from  \ntwo aspects: solution quality and convergence speed of all comparative algorithms. The CloudSim framework [9] was used to implement all comparative algorithms which are executed on the same conditions.\nIn this subsection, we will analyze the quality of the solution from two cases. Case1: the number of VMs is fixed, the number of cloudlets is ascending. We keep the number of VMs as 4 or 8 , and increase the number of cloudlets from 20 to 200. Case2: the number of cloudlets is fixed, the number of VMs is ascending. We keep the number of cloudlet as 100 or 200, and increase the number of VMs from 4 to 12 . The simulation data are randomly generated, in which the computing speed of the VMs and the size of the cloudlets come from the uniform distribution [100, 1000] and FORMULA_39, respectively.",
      "question_type": "algorithm mechanism",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:12",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Regarding the application of a Wilcoxon rank sum test to differentiate between easy and hard NK-landscape instances, how do the statistical differences in the clustering coefficient compare to those in the node participation coefficient?",
      "topics": [
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "The analysis using the Wilcoxon rank sum test ($\\alpha=0.05$) revealed two coincidences each for the clustering coefficient and the node participation coefficient. However, in each case, only one test of $N$ (where there is one coefficient for every node in the network) found significant differences. This suggests a similar low level of statistically significant difference between easy and hard instances when using these two network measures individually.",
      "chunk_id": 5016,
      "paper_id": "Evolving NK-complexity for evolutionary solvers",
      "paper_title": "Evolving NK-complexity for Evolutionary Solvers",
      "paper_year": "2012",
      "chunk_content": "The objective of the experiments is to investigate whether the network measures extracted from the evolved instances capture the differences between the sets of easy and hard instances. First, we compute for each instance a large set  \n[^0]\n[^0]:    ${ }^{1}$ We use the implementation by the author, available from http://medal.cs.umsl.edu/software.php  \nof network measures that serve as topological descriptors. Then, we apply a statistical test to each of the features to identify those that have a significantly different distribution between easy and hard instances. Table 1 describes the topological measures extracted from the NK-landscape structures. The computation of the number of structural and functional motifs was implemented using the brain connectivity toolbox [4].  \nTable 1: Topological measures extracted from the NK-landscape structures.  \nIn order to identify the set of significant features, we applied, for each feature, a statistical test to determine whether there exists significant difference between the easy and hard instances for the given feature. The statistical test of choice was the Wilcoxon rank sum test of equal medians and the parameter $\\alpha=0.05$ was fixed for all the statistical tests. The test outputs the p-value corresponding to the statistics and we use these values to further characterize the differences between the features.  \nTable 2 shows which of the network measures described in Table 1 were identified as significant for any combination of $N$ and $K$. When groups of features were considered, the table shows how many of the features in the group were detected as significant. It can be seen in Table 2 that out of all possible statistical tests only statistical differences between the sets of easy and hard instances are found only 26 times for 8 network measures. There are two coincidences for the clustering coefficient and the node participation coefficient respectively but in every case, only one test of $N$ (there is one coefficient for every node in the network) found significant differences. Therefore 2 tests out of $9(20+28+34)=738$ tests might be due to multiple testing.\nIn this paper we have introduced an empirical method  \nTable 2: Relevant features identified by the application of the statistical test.\nfor investigating some factors that could predict differences in the complexity of NK-landscape instances for EAs. Our method is based on the direct evolution of easy and hard instances using the success rate of an evolutionary algorithm to estimate the instance complexity. The evolutionary process guarantees that the evolved instance will be \"easier\" or \"harder\" than the initial instance. By applying evolution in the two directions of difficulty we can guarantee that the two final sets will differ in terms of complexity with respect to the original set, and more significantly, between them. The type of network measures extracted from the instances can be also applied to the structures of the graphical models for unveiling relevant information from the problem and allowing transfer learning between problem instances [5].\nThis work has been partially supported by the Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Government), TIN2010-14931 and Consolider Ingenio 2010 CSD 2007 - 00018 projects (Spanish Ministry of Science and Innovation) and COMBIOMED network in computational biomedicine (Carlos III Health Institute)",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:14",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the ML-MOEA, and how do the ML-MOEA/SOM and ML-MOEA/LLE variants differ within this framework?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The ML-MOEA algorithm consists of the following steps: 1) Randomly initialisation of the population; 2) Modelling the population using a manifold learning algorithm; 3) Extending and reproducing the population based on the manifold model; 4) Elite selection to choose the best individuals; 5) Termination check, either halting or returning to step 2 for further iterations. The ML-MOEA/SOM and ML-MOEA/LLE variants implement step 2, the manifold learning modelling, using different techniques. ML-MOEA/SOM uses self-organising maps (SOM) for manifold learning, while ML-MOEA/LLE employs locally linear embedding (LLE) for the same purpose. The remaining steps (initialisation, reproduction, selection, and termination) are identical across all three algorithms; the core difference lies in the specific manifold learning algorithm used to model the data in step 2.",
      "chunk_id": 4673,
      "paper_id": "A research overview of manifold-learning-based multiobjective evolutionary algorithm",
      "paper_title": "A research overview of manifold-learning-based multiobjective evolutionary algorithm",
      "paper_year": "2015",
      "chunk_content": "Wei Zhan, Chao Guo and Leiping XiongSchool of Computer Science,Yangtze University,Jingzhou, Hubei, ChinaEmail: zhanwei814@gmail.comEmail: 1442650559@qq.comEmail: 1074137926@qq.comCorresponding author\nManifold learning algorithm can find out the low-dimensional smooth manifold embedded in high-dimensional data. So, in this paper, the manifold learning algorithm is introduced into multiobjective optimisation algorithm for multiobjective optimisation problems (MOPs), and a manifold-learning-based multiobjective evolutionary algorithm (ML-MOEA) is proposed to overcome deficiency of the traditional evolutionary multi-objective optimisation algorithms (EMOAs) and model-based multi-objective optimisation algorithms (MOEAs) for reducing dimension of data and mining manifold in the decision space of MOPs, build accurate model, guide algorithm evolution and accelerate convergence. The steps of ML-MOEA is as follows: 1) randomly initialisation; 2) modelling via manifold learning algorithm; 3) extend and reproduction; 4) elite selection; 5) halt or go to step 2. Based on the framework of ML-MOEA, a ML-MOEA via self-organising maps (ML-MOEA/SOM) and a ML-MOEA via SOM locally linear embedding (ML-MOEA/LLE) is proposed, and comparison experiment of algorithm performance is done.  \nKeywords: manifold learning; multiobjective optimisation; evolutionary algorithm; model-based multiobjective estimation of distribution algorithm; research overview.  \nReference to this paper should be made as follows: Zhan, W., Guo, C. and Xiong, L. (2015) 'A research overview of manifold-learning-based multiobjective evolutionary algorithm', Int. J. Computing Science and Mathematics, Vol. 6, No. 3, pp.287-296.  \nBiographical notes: Wei Zhan received his BEng in Computer Science from Hubei Normal University, Huangshi, China, in 2001, and received his MEng and PhD degrees in Computer Science from China University of Geosciences (CUG), Wuhan, China, in 2006 and 2013, respectively. Currently, he is a faculty member with School of Computer Science, Yangtze University, Jingzhou, Hubei, China. His research interests include computer version (CV), multiobjective optimisation (MOP), intelligent computation and its applications.  \nChao Guo is an undergraduate student in School of Computer Science, Yangtze University, Jingzhou, Hubei, China.  \nLeiping Xiong is an undergraduate student in School of Computer Science, Yangtze University, Jingzhou, Hubei, China.  \nThis paper is a revised and expanded version of a paper entitled 'A hybrid\nmultiobjective evolutionary algorithm model-based on local linear embedding\n(LLE)' presented at International Workshop on Swarm Intelligent Systems\n(IWSIS2014), Nanchang, China, 6-8 June 2014.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:16",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach is outlined to assess the EDA, specifically Population Based Incremental Learning (PBIL), when applied to cancer chemotherapy optimization?",
      "topics": [
        "genetic"
      ],
      "answer": "The benchmarking approach involves comparing the performance of Population Based Incremental Learning (PBIL), an Estimation of Distribution Algorithm (EDA), against Genetic Algorithms (GAs) in finding effective chemotherapeutic treatments. The aim is to analyze and compare the performance of both algorithms to determine which approach to cancer chemotherapy optimization is more efficient.",
      "chunk_id": 6339,
      "paper_id": "Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms",
      "paper_title": "Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms",
      "paper_year": "2006",
      "chunk_content": "Andrei PetrovskiSchool of ComputingThe Robert Gordon UniversityAberdeen, UKap@comp.rgu.ac.uk  \nSiddhartha ShakyaSchool of ComputingThe Robert Gordon UniversityAberdeen, UKss@comp.rgu.ac.uk  \nJohn McCallSchool of ComputingThe Robert Gordon UniversityAberdeen, UKjm@comp.rgu.ac.uk\nThis paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.  \nWe compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.\nI.2.8 [Artificial Intelligence]: Problem Solving, Control Methods, and Search\n; G. 3 [Probability and statistics]: Probabilistic algorithms, Stochastic processes\n; J. 3 [Life and Medical Sciences]: Health\nAlgorithms, Performance, Theory",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:17",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for feature selection, and how does the \"fast estimation of distribution algorithm\" (FEDA) address the computational challenges associated with wrapper approaches?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective is to reduce the computational cost associated with wrapper approaches for feature selection in EDAs. The \"fast estimation of distribution algorithm\" (FEDA) addresses this by avoiding the evaluation of all new individuals using the actual fitness function. It employs Bayesian Networks to model probabilistic distributions and generate new individuals, and it extends these networks to approximate fitness values, thereby reducing the computational burden. Individual control strategy and model management are used to find informative individuals for updating the model.",
      "chunk_id": 13146,
      "paper_id": "Fitness approximation in estimation of distribution algorithms for feature selection",
      "paper_title": "Fitness approximation in estimation of distribution algorithms for feature selection",
      "paper_year": "2005",
      "chunk_content": "Haixia Chen ${ }^{1}$, Senmiao Yuan ${ }^{1}$, and Kai Jiang ${ }^{2}$${ }^{1}$ College of Computer Science and Technology, Jilin University, Changchun 130025, Chinahxchen2004@sohu.comFORMULA_4 The 45th Research Institute of CETC, Beijing 101601, Chinakjiang2004@sohu.com\nEstimation of distribution algorithms (EDAs) are popular and robust algorithms that combine two technical disciplines of soft computing methodologies, probabilistic reasoning and evolutionary computing, for optimization problems. Several algorithms have already been proposed by different authors. However, these algorithms may require huge computation power, which is seldom considered in those applications. This paper introduces a \"fast estimation of distribution algorithm\" (FEDA) for feature selection that does not evaluate all new individuals by actual fitness function, thus reducing the computational cost and improve the performance. Bayesian networks are used to model the probabilistic distribution and generate new individuals in the optimization process. Moreover, fitness value is assigned to each new individual using the extended Bayesian network as an approximate model to fitness function. Implementation issues such as individual control strategy, model management are addressed. Promising results are achieved in experiments on 5 UCI datasets. The results indicate that, as population-sizing requirements for building appropriate models of promising solutions lead to good fitness estimates, more compact feature subsets that give more accurate result can be found.\nFeature selection (FS) is one of the most important issues in the community of data mining, machine learning, pattern recognition, etc[1]. There are two basic approaches to feature selection: wrapper approaches and filter approaches[2]. While wrappers give better results in terms of the accuracy of the final classifier, being a NP-hard problem, the selection process becomes more complex with the number of features and instances in the given task increasing.  \nEstimation of distribution algorithms (EDAs) are a quite recent topic in optimization techniques. Using different assumption of the joint probability distribution, different algorithms have been proposed and good results have been observed [1], [3], [4]. In the wrappers for feature selection optimization, the time to run EDAs is dominated by the 'slow-to-compute' fitness function evaluation. To compound the problem further, it is often necessary for EDAs to select a large population size for distribution estimation and use a large number of generations to obtain an acceptable solution and  \navoid premature convergence. For evolutionary algorithms models, there are two main ways to reduce the computational cost by integrating approximate models that exploit knowledge of past evaluation into the optimization: evolution control and surrogate approach [5]. As it is difficult to construct an approximate model that is globally correct due to the high dimensionality, ill distribution and limited number of training samples, it is found that the surrogate approach is likely to converge to a false optimum, which is an optimum of the approximate model, but not the one for the actual fitness function. Therefore, the evolution control approach is of more practical importance.  \nThis paper introduces a \"fast estimation of distribution algorithm\" (FEDA) to deal with the computational overburden comes along with the wrapper approach for feature selection. It uses Bayesian Networks (BNs) to estimate the probability distribution of each generation. In addition, the BNs are extended as approximate models to assign fitness values. As those assigned fitness values are not the actual fitness values, the individual control strategy and model management strategy are proposed to find those informative individuals with high fitness values or in an unexplored region. The main aim of the approximate model is not only to assign fitness but also to find informative individuals for updating itself.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:19",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the decomposition of a multivariate joint distribution using copulas, and how does this decomposition facilitate the estimation of the joint density function in the context of multi-objective optimization problems (MOOPs)?",
      "topics": [
        "algorithm"
      ],
      "answer": "The decomposition of a multivariate joint distribution using copulas relies on the principle that any continuous multivariate joint distribution \\(F(x_1, x_2, ..., x_n) = Pr_n b(X_1 \\leq x_1, X_2 \\leq x_2, ..., X_n \\leq x_n)\\) can be represented by a copula \\(C\\) as a function of the marginal distributions \\(F_{X_i}(x_i) = Pr_n b{X_i \\leq x_i}, i=1, 2, ..., n\\), expressed as \\(F(x_1, x_2, ..., x_n) = C(F_1(x_1), F_2(x_2), ..., F_n(x_n)) = C(u_1, u_2, ..., u_n)\\), where \\(u_i = F_{X_i}(x_i)\\). This decomposition is crucial because it separates the marginal distributions from the dependence structure. The joint density function \\(f(x_1, x_2, ..., x_n)\\) can then be expressed as the product of the marginal densities \\(f_i(x_i), i=1, 2, ..., n\\) and the copula density function \\(c(u_1, u_2, ..., u_n)\\), i.e., \\(f(x_1, x_2, ..., x_n) = c(u_1, u_2, ..., u_n) \\cdot f_1(x_1) \\cdot f_2(x_2) \\cdot ... \\cdot f_n(x_n)\\). In MOOPs, this allows for independent modeling of the marginal distributions and the dependence structure, which can simplify the estimation process, especially when using Gaussian copulas, defined as \\(C(u_1, u_2, ..., u_n ; \\mathbf{R}) = \\boldsymbol{\\Phi}_{\\mathbf{R}}(\\varphi^{-1}(u_1), \\varphi^{-1}(u_2), ..., \\varphi^{-1}(u_n))\\), where \\(\\boldsymbol{\\Phi}_{\\mathbf{R}}\\) is the standardized multivariate normal distribution with correlation matrix \\(\\mathbf{R}\\) and \\(\\varphi^{-1}(x)\\) is the inverse of the univariate standard normal distribution.",
      "chunk_id": 5319,
      "paper_id": "Pareto-Based Multi-objective Estimation of Distribution Algorithm with Gaussian Copulas and Application in RFID Network Planning",
      "paper_title": "Pareto-Based Multi-objective Estimation of Distribution Algorithm with Gaussian Copulas and Application in RFID Network Planning",
      "paper_year": "2012",
      "chunk_content": "The general MOOPs can be defined as follows:  \n$$\n\\begin{gathered}\n\\min F(\\mathbf{x})=\\left\\{f_{1}(\\mathbf{x}), f_{2}(\\mathbf{x}), \\cdots, f_{k}(\\mathbf{x})\\right\\} \\\\\n\\text { s.t. } g_{i}(\\mathbf{x}) \\leq 0, \\quad i=1,2, \\ldots, m \\\\\nh_{i}(\\mathbf{x})=0, \\quad i=1,2, \\ldots, p\n\\end{gathered}\n$$  \n$g_{i}(\\mathbf{x}) \\leq 0$ and $h_{i}(\\mathbf{x})=0$ define the feasible region $\\Omega$ and any point in $\\Omega$ defines a feasible solution.  \nThe concept of optimum commonly adopted in MOOPs is Pareto optimality. Pareto optimality is defined as:  \nA point $\\mathbf{x}^{*} \\in \\Omega$ is Pareto optimal if $\\forall \\mathbf{x} \\in \\Omega$ and $\\mathrm{I}=\\{1,2, \\cdots, k\\}$\neither: $\\forall i \\in \\mathrm{I} f_{i}\\left(\\mathbf{x}^{*}\\right) \\leq f_{i}(\\mathbf{x})$\nand, there is at least one $i \\in \\mathrm{I}$ such that $f_{i}\\left(\\mathbf{x}^{*}\\right)<f_{i}(\\mathbf{x})$  \nOther important definitions associated with Pareto optimality are Pareto dominance.  \nA vector $\\mathbf{x}=\\left(x_{1}, x_{2}, \\cdots, x_{n}\\right)$ is said to dominate $\\mathbf{y}=\\left(y_{1}, y_{2}, \\cdots, y_{n}\\right)$, denoted by $\\mathbf{x} \\prec \\mathbf{y}$, if and only if $\\mathbf{x}$ is partially less than $\\mathbf{y}$, i.e., $\\forall i \\in\\{1,2, \\cdots, k\\} \\quad x_{i} \\leq y_{i}$ and, at least for one $i, x_{i}<y_{i}$.  \nFor a given multi-objective problem $F(\\mathbf{x})$, Pareto optimal set $P^{*}$ is defined as:  \n$$\nP^{*}=\\left\\{\\mathbf{x} \\in \\Omega \\mid-\\exists \\mathbf{x}^{\\prime} \\in \\Omega \\quad F\\left(\\mathbf{x}^{\\prime}\\right) \\prec F(\\mathbf{x})\\right\\}\n$$  \nPareto front $P F^{*}$ is defined as:\n$P F^{*}=\\left\\{F(\\mathbf{x})=\\left(f_{1}(\\mathbf{x}), f_{2}(\\mathbf{x}), \\cdots, f_{k}(\\mathbf{x})\\right) \\mid \\mathbf{x} \\in P^{*}\\right\\}$\nA copula[6] is a distribution function with known marginals. Any continuous Multivariate joint distribution of $n$ random variables $x_{1}, x_{2}, \\ldots, x_{n}$\n$F\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\operatorname{Pr}_{n} b\\left(X_{1} \\leq x_{1}, X_{2} \\leq x_{2}, \\ldots, X_{n} \\leq x_{n}\\right\\}$, can be represented by a copula $C$ as a function of the marginal distribution $F_{X_{i}}\\left(x_{i}\\right)=\\operatorname{Pr}_{n} b\\left\\{X_{i} \\leq x_{i}\\right\\}, i=1,2, \\cdots, n$; i.e.  \n$$\n\\begin{aligned}\nF\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) & =C\\left(F_{1}\\left(x_{1}\\right), F_{2}\\left(x_{2}\\right), \\ldots, F_{n}\\left(x_{n}\\right)\\right) \\\\\n& =C\\left(u_{1}, u_{2}, \\ldots, u_{n}\\right)\n\\end{aligned}\n$$  \nWhere $u_{i}=F_{X_{i}}\\left(x_{i}\\right), i=1,2, \\cdots, n$ and $C\\left(u_{1}, u_{2}, \\ldots, u_{n}\\right)$ is the associated copula function. Furthermore, application of the chain rule shows that the corresponding density function $f\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$ can be decomposed as  \n$$\n\\begin{aligned}\nf\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) & =\\frac{\\partial^{n} C\\left(u_{1}, u_{2}, \\ldots, u_{n}\\right)}{\\partial u_{i} \\partial u_{2} \\ldots \\partial u_{n}} \\\\\n& =c\\left(u_{1}, u_{2}, \\ldots, u_{n}\\right) \\cdot f_{1}\\left(x_{1}\\right) \\cdot f_{2}\\left(x_{2}\\right) \\cdot \\ldots \\cdot f_{n}\\left(x_{n}\\right)\n\\end{aligned}\n$$  \nFrom the above it may be seen that the joint density function is the product of the marginals $f_{i}\\left(x_{i}\\right), i=1,2, \\cdots, n$ and copula densities function $c\\left(u_{1}, u_{2}, \\ldots, u_{n}\\right)$.  \nLet $\\mathbf{R}=\\left(r_{i, j}\\right), i=1,2, \\cdots, n, j=1,2, \\cdots, n$ be a symmetric, positive definite matrix with unit diagonal entries. The multivariate Gaussian copula is defined as  \n$$\nC\\left(u_{1}, u_{2}, \\ldots, u_{n} ; \\mathbf{R}\\right)=\\boldsymbol{\\Phi}_{\\mathbf{R}}\\left(\\varphi^{-1}\\left(u_{1}\\right), \\varphi^{-1}\\left(u_{2}\\right), \\cdots, \\varphi^{-1}\\left(u_{n}\\right)\\right)\n$$  \nWhere $\\boldsymbol{\\Phi}_{\\mathbf{R}}$ denotes the standardized multivariate normal distribution with correlation matrix $\\mathbf{R}=\\left(r_{i, j}\\right), i=1,2, \\cdots, n, j=1,2, \\cdots, n . \\varphi^{-1}(x)$ denotes the inverse of the univariate standard normal distribution $\\varphi(x)$.  \nThe corresponding density is\n$c\\left(u_{1}, u_{2}, \\ldots, u_{n} ; \\mathbf{R}\\right)=\\frac{1}{|\\mathbf{R}|^{1 / 2}} \\exp \\left(-\\frac{1}{2} \\boldsymbol{\\omega}^{T}\\left(\\mathbf{R}^{-1}-\\mathbf{I}\\right) \\boldsymbol{\\omega}\\right)$\nwith $\\boldsymbol{\\omega}=\\left(\\varphi^{-1}\\left(u_{1}\\right), \\varphi^{-1}\\left(u_{2}\\right), \\cdots, \\varphi^{-1}\\left(u_{n}\\right)\\right)^{T}$",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:23",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners evaluate the trade-off between computational cost and optimization results when choosing between RW-GEDA, GWO, VCS, and AAVS-EDA?",
      "topics": [
        "convergence"
      ],
      "answer": "When choosing between RW-GEDA, GWO, VCS, and AAVS-EDA, practitioners should consider that RW-GEDA can achieve better optimization results than the other three. However, RW-GEDA has a similar computational cost to GWO and AAVS-EDA, and it outperforms VCS in terms of computational cost. The optimization time for each algorithm should satisfy the constraints of the sampling time, which is 1 second.",
      "chunk_id": 7890,
      "paper_id": "A Gaussian Estimation of Distribution Algorithm With Random Walk Strategies and Its Application in Optimal Missile Guidance Handover for Multi-UCAV in Over-the-Horizon Air Combat",
      "paper_title": "A Gaussian Estimation of Distribution Algorithm With Random Walk Strategies and Its Application in Optimal Missile Guidance Handover for Multi-UCAV in Over-the-Horizon Air Combat",
      "paper_year": "2019",
      "chunk_content": "On basis of the maximum guidance advantage, the allocated guidance UCAV for each missile at different times is  \npresented in Fig. 15(f); a comparison of the best guidance advantages with handover is provided in Fig. 15(g). It can be seen that UCAVs can achieve a greater situation advantage with guidance handover than without handover.  \nTo verify the efficiency of our proposed method, GWO, VCS and AAVS-EDA are employed as competitors. For each algorithm, 10 independent runs are performed to reduce randomness. The average missile guidance advantages obtained from 10 operations is statistically compared in Fig. 16(a). RW-GEDA obtains better optimization results than the other three competitors.Additionally, in this real-time optimization problem, the time consumption is another important evaluation indicator. A comparison of the mean time cost is provided in Fig. 16(b). RW-GEDA displays similar performance to GWO and AAVS-EDA in terms of the computational cost, and outperforms VCS. Although there are slight differences between the optimization results of the four algorithms, the optimization time that each algorithm requires satisfies the constraints of a sampling time of 1 s . Overall, the optimizing capacity of RW-GEDA is competitive compared with those of the other three competitors, verifying the superiority and stability of RW-GEDA in the search process.\nIn this study, we develop a novel GEDA extension with novel search mechanisms. Our proposed RW-GEDA is tested by using CEC 2014 benchmarks with a comparison of other state-of-the-art competitive algorithms from different communities. The statistical results show excellent performance of our proposal in terms of the convergence accuracy and computational efficiency.  \nTo solve the optimal missile guidance handover problem of multiple UCAVs in OTH air combat, we describe our novel mathematical models, and RW-GEDA is applied to solve the problem. The simulation results show that UCAVs can maintain better guidance advantages in the combat process through guidance handover, thus verifying the validity of the established model. Moreover, RW-GEDA can solve this problem effectively and competitively compared with other popular algorithms.  \nAs a novel development of the current GEDA, our RWGEDA has fewer tuning parameters and less parameter sensitiveness in solving different problems. However, the limitation in our RW-GEDA is its greater computational cost. In future studies, it is necessary to reduce the calculation and decomposition of the covariance matrix by hybrid other efficient tools.\nRW-GEDA:\nFrom Cor. Author Wang: wxf825421673@163.com.\nL-SHADE:\nhttp://www.pudn.com/Download/item/id/2840416.html.  \nAAVS-EDA:\nFrom Author Liang: liangyongsheng@stu.xjtu.edu.cn. VCS:\nFrom Cor. Author Li: modernlee@163.com. COA:\nFrom Cor. Author Li: modernlee@163.com.\nBLPSO5:\nhttps://ww2.mathworks.cn/matlabcentral/fileexchange/ 64074-biogeography-based-learning-particle-swarmoptimization?s_tid= srchtitle.",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:25",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the described Estimation of Distribution Algorithm (EDA), how do the learning rates $\\eta_{M}$ and $\\eta_{L}$ influence the update of the probability distribution models $P_{L}$ and $M^{(3)}$, and what effect do large values of these learning rates have on the dependence of the model on previous generations?",
      "topics": [
        "algorithm"
      ],
      "answer": "The EDA updates the probability distribution models $P_{L}$ and $M^{(3)}$ using an additive update rule, where these models are not explicitly zeroed before updating. The learning rates $\\eta_{M}$ and $\\eta_{L}$ determine how much the current elite individuals influence the model. When $\\eta_{M}$ and $\\eta_{L}$ are significantly greater than 1 ($\\eta_{M} \\gg 1$ and $\\eta_{L} \\gg 1$), the models $P_{L}$ and $M^{(3)}$ become almost entirely determined by the current elite, effectively making them independent of the previous history of the algorithm's run.",
      "chunk_id": 5824,
      "paper_id": "A linear estimation-of-distribution GP system",
      "paper_title": "A linear estimation-of-distribution GP system",
      "paper_year": "2008",
      "chunk_content": "The update of the distribution is performed independently for $P_{L}$ and $M^{(3)}$ using an additive update rule as shown in Alg. 3. Note that the arrays are not explicitly zeroed before they are updated. In this way the model used to produce individuals at one particular generation can depend also on successful individuals discovered in previous generations in the run. How much the current elite influences the model depends on two learning rates, $\\eta_{M}$ and $\\eta_{L}$. If desired, these can be made arbitrarily big. When $\\eta_{M} \\gg 1$\n  \nand $\\eta_{L} \\gg 1, P_{L}$ and $M^{(3)}$ are almost entirely determined by the current elite, effectively independent of the previous history of the run.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:27",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the G3P algorithm, specifically when configured as G3PCX, compare to the CauchyEDA algorithm in terms of Expected Running Time (ERT) on functions f1-f24, as measured by the BBOB-2009 benchmark, and what statistical significance is observed in their performance differences?",
      "topics": [
        "optimization"
      ],
      "answer": "Table 11 presents a comparison of G3PCX and CauchyEDA based on Expected Running Time (ERT). The ERT is normalized by dividing by the best ERT measured during BBOB-2009. Bold entries in the table indicate statistically significant differences, with significance levels of p=0.05 or p=10^{-k}, where k>1, using a Bonferroni correction of 48. The number of trials that reached the final target f_{opt}+10^{-8} is indicated by '#succ'. When ERT(10^{-7}) is infinite, the median number of function evaluations is provided in italics.",
      "chunk_id": 7341,
      "paper_id": "Comparison of cauchy EDA and G3PCX algorithms on the BBOB noiseless testbed",
      "paper_title": "Comparison of Cauchy EDA and G3PCX Algorithms on the BBOB Noiseless Testbed",
      "paper_year": "2010",
      "chunk_content": "[IMAGE4]  \nTable 11 Expected running time (ERT in number of function evaluations) divided by the best ERT measured during BBOB-2009 (given in the respective first row) for different $\\Delta f$ values for functions $f_{1}-f_{24}$. The median number of conducted function evaluations is additionally given in italics, if $\\operatorname{ERT}\\left(10^{-7}\\right)=\\infty$. \\#succ is the number of trials that reached the final target $f_{\\text {opt }}+10^{-8}$. 0: G3P is G3PCX and 1: Cau is CauchyEDA. Bold entries are statistically significantly better compared to the other algorithm, with $p=0.05$ or $p=10^{-k}$ where $k>1$ is the number following the FORMULA_47 symbol, with Bonferroni correction of 48.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:29",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EMEA model, focusing on how exploration and exploitation are balanced?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The EMEA model balances exploration and exploitation through the following steps: First, it checks if the parameter $\\alpha$ is greater than $\\alpha_{0}$. If so, K-means clustering is applied to partition the population $\\mathcal{P}$ into $\\left\\{C_{k}, 1 \\leq k \\leq K\\right\\}$; otherwise, previous clustering results are reused. Then, for each solution $\\mathbf{x}_{t}$ in cluster $C_{k}$, a trial solution is sampled from $\\mathcal{N}\\left(\\mu_{k}, \\Sigma_{k}\\right)$ with probability $\\beta$, which is initialized to $\\beta_{0}$. If a trial solution is not sampled, two random solutions from outside $C_{k}$ are selected for $\\mathrm{DE} / \\mathrm{rnd} / 1$. The external archive $\\mathcal{A}$ is updated with new trial solutions using hypervolume metric-based environmental selection. Finally, $\\alpha$ and $\\beta$ are updated based on the search history, where $\\alpha$ reflects population stagnation and $\\beta$ controls the exploration/exploitation tradeoff. This process iterates for $\\mathcal{T}$ generations, and the external archive is returned.",
      "chunk_id": 8261,
      "paper_id": "Balancing exploration and exploitation in multiobjective evolutionary optimization",
      "paper_title": "Balancing exploration and exploitation in multiobjective evolutionary optimization",
      "paper_year": "2019",
      "chunk_content": "We consider the following box-constrained continuous MOPs:  \n$$\n\\begin{array}{ll}\n\\min & \\mathbf{F}(\\mathbf{x})=\\left(f_{1}(\\mathbf{x}), \\cdots, f_{m}(\\mathbf{x})\\right)^{\\top} \\\\\n\\text { s.t. } & \\mathbf{x}=\\left(x_{1}, \\cdots, x_{n}\\right)^{\\top} \\in \\Omega\n\\end{array}\n$$  \nThe developed algorithm is called Exploration/Exploitation Multiobjective Evolutionary Algorithm (EMEA). It maintains a population  \n[^0]:    Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).\nGECCO '18 Companion, July 15-19, 2018, Kyoto, Japan\n(c) 2018 Copyright held by the owner/author(s).  \nACM ISBN 978-1-4503-5764-7/18/07... $\\$ 15.00$\nhttps://doi.org/10.1145/3205651.3205708  \nof solutions $\\mathcal{P}$ and an external archive $\\mathcal{A}$. The algorithmic parameters include the population size $N$, the number of partitions $K$, and two initial control parameters $\\alpha_{0}, \\beta_{0} \\in[0,1]$.  \nIn EMEA, at each generation, first whether K-means should be applied or not is decided. If $\\alpha$ is bigger than $\\alpha_{0}$, K-means is employed to partition $\\mathcal{P}$ to $\\left\\{C_{k}, 1 \\leq k \\leq K\\right\\}$; otherwise, most recent clustering results is reused. At each generation $t$, around each solution $\\mathbf{x}_{t} \\in C_{k}$, with probability $\\beta$ (it is initialized to be $\\beta_{0}$ ), a trial solution is sampled from $\\mathcal{N}\\left(\\mu_{k}, \\Sigma_{k}\\right)$; otherwise, two random solutions from outside $C_{k}$ are chosen for $\\mathrm{DE} / \\mathrm{rnd} / 1$. The external archive is updated incrementally whenever a new trial solution is generated by environmental selection. The hypervolume metric-based environmental selection proposed in SMS-EMOA [1] is adopted to choose promising solutions for the next population. $\\alpha$ and $\\beta$ are then computed according to previous search history. EMEA iterates for $\\mathcal{T}$ generations and returns the external archive.  \nThe value of $\\alpha$ reflects the stagnation of the population, while $\\beta$ determines the exploration/exploitation tradeoff. $\\alpha$ is computed as the ratio of the changed solutions to the population size between adjacent generations. To compute $\\beta$, a survival analysis is used based on the simple fact: high-quality solution will survive longer than low-quality solutions. First, at each generation, the survival time of each solution at its position in the population is computed. Then the average survival time of each solution along the previous $H$ generations, i.e. FORMULA_27, is computed.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:32",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the algorithm's output be measured using the criteria of non-dominated solutions in the proposed Estimation of Distribution Algorithm?",
      "topics": [
        "optimization"
      ],
      "answer": "The algorithm maintains non-dominated solutions, which represent the best solutions found during the optimization process. New solutions are compared to previous ones, and only the best (non-dominated solutions) are kept, implying that the final set of non-dominated solutions represents the quality of the algorithm's output.",
      "chunk_id": 11965,
      "paper_id": "Multi-objective Estimation of Distribution Algorithm based on Voronoi and local search",
      "paper_title": "Multi-objective Estimation of Distribution algorithm based on Voronoi and Local search",
      "paper_year": "2016",
      "chunk_content": "Each particle in particle swarm optimization algorithm, use local information of the best solutions that it has ever achieved (local optima) and the best answer that all particles have ever achieved (global optima). Using local information to exploitation could be helpful. In the proposed method, a mesh selected due to related probability. The control parameter FORMULA_4 set the running algorithm steps. In the first steps due to keeping diversity and new areas exploration, the probability model sample and new solutions in selected mesh and produce by uniform distribution. But in final steps, after exploration of the best area, the local information use to produce new solutions by particle swarm algorithm. At the end, new solutions compare to pervious one and bests (non-dominated solutions) are kept. The proposed algorithm steps are shown in \"Fig. 1\".",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:33",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs using Factorized Distribution Algorithm (FDA) with respect to additive fitness functions and their interaction graphs?",
      "topics": [
        "analysis"
      ],
      "answer": "The Factorized Distribution Algorithm (FDA) aims to construct a probability distribution, p(x), based on the interaction graph, G_f, of an additive fitness function, f. This distribution satisfies two key properties: first, G_f is an I-map of p(x), and second, p(x) can be represented as a factorized product using marginal distributions over subsets of variables, S, derived from a tree decomposition of G_f, where the space complexity of an exact factorization is exponential in the width of the tree decomposition.",
      "chunk_id": 13105,
      "paper_id": "Space complexity of estimation of distribution algorithms",
      "paper_title": "Space complexity of estimation of distribution algorithms",
      "paper_year": "2005",
      "chunk_content": "FDA directly uses the interaction graph, or an estimated interaction graph, of the additive fitness function to model the sampling distribution (Muhlenbein and Mahnig, 1999). For arbitrary fitness functions of which the exact interaction structure is usually unknown, an estimated interaction graph can also be used. Given an additive fitness function $f$ and its interaction graph $G_{f}=G_{f}(V, E)$ with $V=\\left\\{x_{1}, \\cdots, x_{n}\\right\\}$, FDA constructs a probability distribution $p(x)$ satisfying  \n1. $G_{f}$ is an I-map of $p(x)$; and\n2. $p(x)$ can be represented as a factorized product of the form  \n$$\np(x)=\\frac{\\prod_{S \\in \\mathcal{S}} p_{S}(x)}{\\prod_{S, T \\in \\mathcal{S}} p_{S \\cap T}(x)}\n$$  \nwhere $\\mathcal{S}$ is the collection of subsets of variables in a tree decomposition of $G_{f}$ and $p_{S}(x)$ is the marginal distribution over the subset of variables $S \\in \\mathcal{S}$.  \nIn the original definition of the FDA (Muhlenbein et al., 1999), the factorized product representation of $p(x)$ can be either approximated or exact. In an approximated factorized product, the collection of subsets $\\mathcal{S}$ does not necessarily form a tree decomposition of the interaction graph. For the purpose of investigating the space complexity, we require that the factorization is always exact.  \nLet $f(x)=\\sum_{c \\in \\mathcal{C}} f_{c}(x)$ be an additive fitness function with $\\max _{c \\in \\mathcal{C}}|c|<k$, i.e., each local fitness function depends on at most $k$ variables. If the collection of subsets of variables, $\\mathcal{C}$, satisfies the running intersection property, or equivalently it forms a tree decomposition of the interaction graph, then an exact factorized representation can be built on $\\mathcal{C}$ with a space requirement of $O\\left(2^{k}\\right)$ (Muhlenbein et al., 1999). However, as has also been mentioned in (Muhlenbein et al., 1999), such a class of additive fitness functions is very limited. Otherwise, to get an exact factorized representation, one has to find a tree decomposition of the interaction graph, and the resulting exact factorization will have a space complexity exponential in the width of the tree decomposition. Our analysis in this paper will show that for a random additive fitness function, the space complexity of an exact factorization is exponential in the number of the variables even if the interaction structure of the function is sparse.  \nBelow are a few examples to illustrate the concepts of tree decomposition and the factorized representation of a probability distribution.\nExample 3.2. Consider three additive fitness functions defined on the variables $x=$ $\\left\\{x_{1}, x_{2}, x_{3}, x_{4}\\right\\}$ :  \n$$\n\\begin{aligned}\nf_{A}(x) & =f_{1}\\left(x_{1}, x_{2}\\right)+f_{2}\\left(x_{2}, x_{3}\\right)+f_{3}\\left(x_{3}, x_{4}\\right) \\\\\nf_{B}(x) & =f_{1}\\left(x_{1}, x_{2}\\right)+f_{2}\\left(x_{2}, x_{3}\\right)+f_{3}\\left(x_{3}, x_{4}\\right)+f_{4}\\left(x_{4}, x_{1}\\right) \\\\\nf_{C}(x) & =f_{1}\\left(x_{1}, x_{2}, x_{3}\\right)+f_{2}\\left(x_{1}, x_{2}, x_{4}\\right)+f_{3}\\left(x_{2}, x_{3}, x_{4}\\right)\n\\end{aligned}\n$$  \n(1) The interaction graph $G$ of $f_{A}$ is simply a path over four vertices  \n$$\nx_{1}-x_{2}-x_{3}-x_{4}\n$$  \n$G$ has a treewidth of 1 and an optimal tree decomposition of $G$ is $\\mathcal{T}=$ $\\left\\{\\left(x_{1}, x_{2}\\right),\\left(x_{2}, x_{3}\\right),\\left(x_{3}, x_{4}\\right)\\right\\}$. A probability distribution $p(x)$ defined on $G$ can thus be represented as a factorized product of the form  \n$$\np(x)=\\frac{p\\left(x_{1}, x_{2}\\right) p\\left(x_{2}, x_{3}\\right) p\\left(x_{3}, x_{4}\\right)}{p\\left(x_{2}\\right) p\\left(x_{3}\\right)}\n$$  \n(2) The interaction graph of $f_{B}$ is a cycle  \n$$\nx_{1}-x_{2}-x_{3}-x_{4}-x_{1}\n$$  \nand has a treewidth 2. A tree decomposition is  \n$$\n\\mathcal{T}=\\left\\{\\left(x_{1}, x_{2}, x_{4}\\right),\\left(x_{2}, x_{3}, x_{4}\\right)\\right\\}\n$$  \nand a probability distribution defined on the interaction graph can be represented as a factorized product of the form  \nFORMULA_188",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:35",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of power transmission network modeling, what mathematical principles govern the relationship between power injection, voltage phasor angles, and the matrix \\(\\mathbf{B}\\) as defined in the linear DC power flow model?",
      "topics": [
        "optimization"
      ],
      "answer": "In the linear DC power flow model, the relationship between power injection \\(\\mathbf{p}\\), voltage phases \\(\\theta\\), and the symmetric matrix \\(\\mathbf{B}\\) is defined by the equation \\(\\mathbf{p}=\\mathbf{B}^{(k)} \\theta^{(k)}\\), where \\(k\\) represents different outage events. The matrix \\(\\mathbf{B}\\) is constructed as \\(\\mathbf{B}=\\mathbf{M D}_{\\mathbf{x}} \\mathbf{M}^{\\mathbf{T}}=\\sum_{l=1}^{L}\\left(\\frac{1}{x_{l}} \\cdot \\mathbf{m}_{l} \\cdot \\mathbf{m}_{l}^{T}\\right)\\), where \\(\\mathbf{D}_{\\mathbf{x}}\\) is a diagonal matrix with elements \\(1 / x_{l}\\), \\(x_{l}\\) being the reactance of line \\(l\\). The matrix \\(\\mathbf{M}\\) is the bus-line incidence matrix, with elements \\(M_{n l}\\) equal to 1 if the \\(l\\)-th line is from the \\(n\\)-th bus, -1 if the \\(l\\)-th line is to the \\(n\\)-th bus, and 0 otherwise. The vector \\(\\mathbf{m}_{l}\\) is the incidence vector for line \\(l\\), with elements equal to 1 if \\(i=n\\), -1 if \\(i=m\\), and 0 otherwise, where \\(n\\) and \\(m\\) are the buses connected by line \\(l\\). This formulation allows \\(\\mathbf{B}\\) to be viewed as the Laplacian matrix of the weighted graph representing the power transmission network.",
      "chunk_id": 4538,
      "paper_id": "Efficient Multiple Lines Outage Detection in SmartGrid",
      "paper_title": "Efficient Multiple Lines Outage Detection in SmartGrid",
      "paper_year": "2015",
      "chunk_content": "In this section, the system model will be discussed in detail. We modeled a power transmission network with $N$ buses and $L$ transmission lines using a weighted graph $\\mathcal{G}=\\{\\mathcal{N}, \\mathcal{E}\\}$, where $\\mathcal{N}=\\{1,2, \\ldots, N\\}$ and $\\mathcal{E}=\\{(m, n)\\} \\subseteq \\mathcal{N} \\times \\mathcal{N}$ represent the set of buses and the set of edges, respectively. For mathematical convenience, we also denote the set of transmission lines by $\\mathcal{L}=\\{1,2, \\ldots, L\\}$. For line $l \\in \\mathcal{L}$ that connects the buses $n$ and $m$, we denote the reactance along $(m, n)$ by $x_{i}$, as well as $x_{m n}=x_{n m}$, and we define the $i$ th element of its incidence vector $\\mathbf{m}_{l}$ as follows:  \n$$\n\\mathbf{m}_{l}=\\left\\{\\begin{array}{cll}\n1 & , & \\text { if } i=n \\\\\n-1 & , & \\text { if } i=m \\\\\n0 & , & \\text { otherwise }\n\\end{array}\\right.\n$$  \nIn this work, we consider the linear DC power flow model defined in [10]. According to conservation-of-flow constraint for power flow in the linear DC model, the injected power to a particular node $n$ must be equal to the total power going out of it. Mathematically it can be written as,  \n$$\nP_{n}=\\sum_{m \\in \\mathcal{N}(n)} P_{n m}=\\frac{1}{x_{m n}}\\left(\\theta_{n}-\\theta_{m}\\right)\n$$  \nwhere $\\mathcal{N}(n)$ is the set of buses, connected to bus $n$, and $P_{n m}$ denotes the power flowing from buses $m$ to $n$ through their connecting transmission line. Here, $\\theta_{n}$ and $\\theta_{m}$ are the voltage phasor angles of buses $n$ and $m$, respectively. For ease in notation, the real power injection in $\\mathbf{p} \\in \\mathbb{R}^{N \\times 1}$, the voltage phases in $\\theta \\in \\mathbb{R}^{N \\times 1}$ and $\\mathbf{B} \\in \\mathbb{R}^{N \\times N}$ is a symmetric matrix can be stacked into a vector-matrix form as,  \n$$\n\\mathbf{p}=\\mathbf{B}^{(k)} \\theta^{(k)}, \\text { where } k=1,2,3, \\ldots, K\n$$  \nwhere $K$ is the number of possible outage events. $K$ is equal to $2^{L}$, including the normal condition, i.e. the pre-outage can be expressed as [10],  \n$$\n\\mathbf{B}=\\mathbf{M D}_{\\mathbf{x}} \\mathbf{M}^{\\mathbf{T}}=\\sum_{l=1}^{L}\\left(\\frac{1}{x_{l}} \\cdot \\mathbf{m}_{l} \\cdot \\mathbf{m}_{l}^{T}\\right)\n$$  \nwhere $\\mathbf{D}_{\\mathbf{x}}$ is a diagonal matrix with $1 / x_{l}$ as its $l$ th diagonal entry, and $\\mathbf{M}$, formed by the columns $\\left\\{\\mathbf{m}_{l}\\right\\}_{l=1}^{L}$ of length $N$, is the $N \\times L$ bus-line incidence matrix with an $(n, l)$ th entry given by  \n$$\nM_{n l}=\\left\\{\\begin{array}{cl}\n1 & \\text {, if } l-\\text { th line is from } n-\\text { th bus } \\\\\n-1 & \\text {, if } l-\\text { th line is to } n-\\text { th bus } \\\\\n0 & \\text {, otherwise }\n\\end{array}\\right.\n$$  \nWith these definitions, $\\mathbf{B}$ can be viewed as the Laplacian matrix of the weighted graph $\\mathcal{G}$. We are interested to detect if power line outage occurs, and to identify the outaged line/s in $\\mathcal{L}$, where FORMULA_59.",
      "question_type": "algorithmic principles",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:38",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners model the probabilistic model when using the order statistics approach for a scheduling problem?",
      "topics": [
        "scheduling",
        "Estimation of Distribution Algorithms",
        "probabilistic model",
        "order statistics approach"
      ],
      "answer": "When using the order statistics approach as the EDA probabilistic model in a scheduling problem, practitioners should create a matrix of probabilities. This matrix represents the probability of symbol *i* being in position *j*. The EDA then uses this probability matrix for sampling new solutions.",
      "chunk_id": 1344,
      "paper_id": "An EDA-based method for solving electric vehicle charging scheduling problem under limited power and maximum imbalance constraints",
      "paper_title": "An EDA-based method for solving electric vehicle charging scheduling problem under limited power and maximum imbalance constraints",
      "paper_year": "2022",
      "chunk_content": "A comprehensive review of scheduling, clustering and forecasting strategies for controlling EV charging can be found in (Al-Ogaili et al., 2019). From Al-Ogalia's perspective, there are two main EV charging scheduling strategies: centralized and decentralized. In the centralized approach, EVs are connected to an EV aggregator. The EV aggregator collects charging data from EVs and electrical grids to solve the optimization problem for the sake of its stakeholders, operators of charging stations, and EV owners (Jin et al., 2013). In the decentralized strategy, each EV owner has the authority to operate strategically to minimize their charging costs. Although this strategy offers more flexibility to EV owners, it does not guarantee optimality (Ma et al., 2011). Our study is focused on the centralized strategy.  \nAs far as we know, EVCSPs are not reviewed from the operation research (OR) perspective. So, we reviewed EVCSP from their problem  \nTable 3\nReview of recent EDA-based method in solving the scheduling problem.\nconstraints, objective function, and solving method points of view. Table 2 summarizes our findings of the recent literature dealing with centralized EVCSPs from the OR perspective.  \nAccording to Table 2, from the objective function, our study lies in minimizing total tardiness. From a constraints point of view, we consider the power and balance constraints in our research. Moreover, from our optimization and solving method perspective, we proposed an EDA-based method that has not been addressed in the EVCSP literature to the best of the authors' knowledge. In the following, we reviewed, EDA-based approach in scheduling literature.\nConsidering that the EVCSPs lie in scheduling problems, we reviewed the EDA-based method in solving scheduling problems (Table 3). According to the following Table, EDAs are applicable in scheduling problems; nevertheless, it does not use in the EVCSPs yet. It should be pointed out here that most of the EDA-based solving methods in the studied scheduling problem applied the order statistics approach as the EDA probabilistic model. In this approach, EDA probabilistic model is a matrix of probabilities of symbol $i$ in position $j$.\nThis section comprises three sub-sections. This study's preliminary concepts, including introductory concepts of EDAs, Markov networkbased EDA, Mallows Model-based EDA, and the CP paradigm, are briefly described in the first part. Next, our proposed HMM-EDA model is illustrated for solving EVCSP. In the final section, CP as an optimal solving approach for EVCSP is explained.\nEDAs are random optimization methods investigating the potential solutions space by modeling the possible promising solutions (Hauschild \\& Pelikan, 2011). The resulting model helps recognize relationships among variables that provide valuable and understandable insights into the real-world problem structure. In addition, determining a potential distribution could increase the probability of finding an estimated area, including the promising solutions in the entire problem-solving space. Also, this distribution could reduce the number of function evaluations (NFE) for approaching the optimum solution (Larranaga \\& Lozano, 2001). The repetitive steps in an EDA are:  \n1. Selection- selecting a set of promising solutions from the population;\n2. Model Learning- learning a probability model from the promising solutions; and\n3. Sampling- producing a sample from the probability model (Larranaga \\& Lozano, 2001).  \nWe described two EDA versions based on the Mallows model and the Markov network in the first two parts. Besides, a CP model is briefly explained in part three, and the optimal solution obtained from the CP model is considered as a baseline for comparison purposes.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:40",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the PBILA (Population-Based Incremental Learning Algorithm) discussed, how does the learning rate, denoted as alpha, influence the algorithm's parameter optimization, and what is the optimal level for alpha determined using Taguchi's robust design methodology?",
      "topics": [
        "design"
      ],
      "answer": "The learning rate, alpha, in PBILA is a parameter that affects how quickly the algorithm updates its probability distribution based on the elite population. According to the parametric optimization study using Taguchi's robust design methodology, the optimal level for alpha is level 5, which corresponds to a value of 0.4. This optimal value was determined by analyzing the main effects plot for means and SN ratios derived from Taguchi's experiments conducted on the esc16a problem from the QAP Library, considering parameters such as maximum generation (MG), population size (PS), and elite population size (EPS).",
      "chunk_id": 10815,
      "paper_id": "Hybrid estimation of distribution algorithms for solving a keyboard layout problem",
      "paper_title": "Hybrid estimation of distribution algorithms for solving a keyboard layout problem",
      "paper_year": "2018",
      "chunk_content": "In order to find the best parameter combinations for the algorithms, a parametric optimization study has been conducted using Taguchi's robust design methodology. The parameters for the algorithms are number of maximum generations, population size, and elite population size for UMDA and maximum generations, population size, elite population size and learning rate (alpha) for PBILA. Since the local search does not have any parameter, only the base algorithm has to be optimized. For consistency, the parametric optimization is done for PBILA and the same values are applied for UMDA. The list of parameters with corresponding levels is given in Table 2.\nalpha - learning rate, MG - maximum generation, PS - Population Size, EPS - Elite Population Size and Av - Average Solution  \nThe orthogonal array for the DOE is L18 in which there is one parameter with six levels and all other three parameters with three levels each. In order to conduct the Taguchi's experiments an average-sized problem namely, esc16a from QAP Library is selected. Each experiment in the L18 array is done 10 times and the average is reported. Table 3 gives the result of the experiments.  \nTable 1. Summary of literature survey.  \nTable 2. List of Parameters and levels.  \nTable 3. Result of Taguchi's experiments.  \nFrom Figures 7 and 8, we can find out the optimal combination of parameters as alpha $=$ level $5=0.4$, maximum generation $=$ level $2=\\mathrm{N}^{*} 10$, Population Size $=$ level $2=\\mathrm{N}$ and Elite Population Size $=$ level $2=\\mathrm{N} / 2$.  \nTable 4: Data for illustrations  \n[IMAGE3]  \nFigure 7. Main effects plot for means from Taguchi's experiments.\n[IMAGE4]  \nFigure 8. Main effects plot for SN ratios from Taguchi's experiments.  \nTable 4. Distance Matrix. Flow Matrix.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:42",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Based on the information provided, what components constitute the simulation platform used for verifications?",
      "topics": [
        "testing"
      ],
      "answer": "The simulation platform consists of the driver model, powertrain model, control model, and vehicle dynamics model. The powertrain model includes the engine, clutch, electric motor, battery, and AMT.",
      "chunk_id": 1485,
      "paper_id": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_title": "A Novel Energy Management Strategy for Plug-in Hybrid Electric Buses Based on Model Predictive Control and Estimation of Distribution Algorithm",
      "paper_year": "2022",
      "chunk_content": "In this section, the proposed strategy is evaluated on a simulation platform based on MATLAB/Simulink and the HIL test bench. Considering that one WVCITY cycle is too short, the testing time used is quadruple that of the WVCITY cycle. In addition, the battery capacity is set as half of the nominal value in both the simulation and HIL tests. The simulation platform, including the driver model, powertrain model, control model, and vehicle dynamics model, is presented in Fig. 10. The acceleration and braking commands are generated from the driver model. The powertrain model consists of the engine, clutch, electric motor, battery, and AMT, whose setting parameters are  \nTABLE IV\nPSEUDOCODE FOR THE EDA ALGORITHM  \n  \n[IMAGE14]  \nFig. 10. Simulation platform for verifications.\ndetermined as presented in Section II. The vehicle dynamics model is used to compute the tractive force so that the vehicle velocity is obtained.",
      "question_type": "challenge",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:43",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing PBIL-CCPS, what data manipulation steps are necessary to refine the set *H* of searched portfolios before evaluating its performance?",
      "topics": [
        "PBIL-CCPS",
        "Estimation of Distribution Algorithms",
        "data structures",
        "algorithmic steps"
      ],
      "answer": "To refine the set *H* in PBIL-CCPS, the implementation must first remove portfolios that are dominated by other portfolios within *H*. Subsequently, the code should identify and remove equivalent portfolios, retaining only one representative portfolio for those sharing the same risk and expected return. The resulting refined set *H* is then used for performance evaluation, similar to how the set *V* is evaluated.",
      "chunk_id": 7707,
      "paper_id": "An Estimation of Distribution Algorithm Based Portfolio Selection Approach",
      "paper_title": "An Estimation of Distribution Algorithm Based Portfolio Selection Approach",
      "paper_year": "2010",
      "chunk_content": "In the experiment, the standard efficient frontier of each instance is unknown. We still use the standard efficient frontiers adopted in the first experiment and evaluate the resulting $V$ of each algorithm in the way described by Part C. Note that, for each portfolio in $V$, the obtained percentage error is just an upper bound of the exact percentage error which is unable to obtain [2]. Table II shows the comparison on the average MeanPE (avgMeanPE) and the average MedianPE (avgMedianPE) of the resulting $V$ in 15 trials.  \nTABLE II. RESULTS OF CCPS  \na. For each algorithm, $V$ is the set of the portfolios obtained by solving the objective function (4) with 50 different values for $i$.\nb. $H$ is the set of the portfolios searched during the course of solving the problem.\nc. For $V$ and $H$, avgMeanPE and avgMedianPE are respectively the averages of obtained MeanPEs and MedianPEs in 15 trials.\nd. For each algorithm, Portfolios ${ }^{b}$ denotes the number of portfolios in the resulting $H$ whose MeanPE ranks medially in 15 trials.\ne. The best result among the three algorithms for each instance is bold.  \nAs stated in Section II, the efficient frontier of CCPS may be discontinuous due to the presence of cardinality constraint and the bounds for the proportion of capital associated with each invested asset. Therefore it is not very appropriate to investigate the effectiveness of PBIL-CCPS solely using the resulting $V$. Similar to [2], we define a set $H$. For each value of $\\lambda$, suppose that $B(\\lambda)$ is the current best portfolio found by the algorithm. During the course of evaluating $1000 N$ feasible portfolios, a searched portfolio is added to $H$ if it has better fitness than $B(\\lambda)$. As a result, the set $H$ will contain a large number of portfolios which are dominated by other portfolios in the set. Therefore, the dominated portfolios must be removed from $H$. Moreover, in the set $H$, there will be some equivalent portfolios which share the same risk and expected return. For these equivalent portfolios, only one is reserved in $H$. The resulting $H$ is evaluated in the same way as evaluating $V$. For the three algorithms, the comparison on the resulting $H$ is showed in Table II where PBIL-CCPS and PSO achieve better $V$ and $H$ than GA. And for each algorithm, the number Portfolio $\\theta$ of portfolios in the resulting $H$ whose MeanPE ranks medially in 15 trials, is given in Table II. For each instance, the Portfolio FORMULA_279 of PBIL-CCPS is larger than those of GA and PSO except Nikkei.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:45",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific mechanism is used in the described Estimation of Distribution Algorithm (EDA) to mitigate premature convergence, and how does it dynamically adjust the variance during the sampling process?",
      "topics": [
        "optimization"
      ],
      "answer": "To avoid premature convergence, the EDA passes on a proportion of the best individuals to the next generation, supplementing them with new individuals generated by the probability model. A dynamic variance is applied to control the generation of new samples, enhancing global searching early on with a higher variance and improving convergence later with a lower variance. The variance of a vector, as defined by FORMULA_81, is specifically adjusted using an unspecified method.",
      "chunk_id": 4773,
      "paper_id": "Unsupervised Dynamic Fuzzy Cognitive Map",
      "paper_title": "Unsupervised Dynamic Fuzzy Cognitive Map",
      "paper_year": "2015",
      "chunk_content": "Weight learning of FCM is equivalent to the optimization problem of the connection matrix. Many studies have been conducted in the area of applying optimization algorithms to construct the weight matrix. Genetic Algorithm ${ }^{[16]}$ is one of the earliest methods, which is subject to several revisions and improvements. Hebbian learning is another main stream algorithm, and its extensions include differential Hebbian Learning ${ }^{[17]}$, Balanced Differential Algorithm, Nonlinear Hebbian Learning ${ }^{[18]}$, and Active Hebbian Learning ${ }^{[19]}$. With the evolution of new optimization theories, some algorithms such as Particle Swarm Optimization (PSO) ${ }^{[20]}$ and Differential Evolution (DE) algorithm ${ }^{[21]}$ are also introduced gradually to the field of weight learning of FCMs.  \nThe Estimation of Distribution Algorithm (EDA) ${ }^{[22]}$ is a relatively novel evolutionary algorithm. In EDA, conventional genetic operators, such as crossover and mutation, are replaced by a statistical model to describe the probability distributions of solutions. By renovating probability model and sampling new individuals from the model, the solution gradually approaches to the  \noptima. The satisfactory performance of EDA has been proved in many fields of optimization, but its application in the field of FCM learning has not been explored. In this paper, we choose the EDA algorithm to solve the construction of connection matrix in FCM.  \nProbability model is the core in EDA. By employing the probability model and its renovation, EDA can describe the space distribution of solutions and control the overall evolution trend of the population. For the variables in continuous domains, a general approach is to assume that the variables obey Gaussian distribution. By considering the dependencies between variables in our problem space, an estimation of a multivariate normal density function is introduced. At each generation, the mean $\\boldsymbol{\\mu}$, and the covariance matrix $\\boldsymbol{\\Sigma}$ whose element is denoted by $\\sigma_{G}^{2}$ are estimated to describe the multivariate normal distribution. And new individuals are generated by this distribution.  \nTwo main decisions are made in the proposed algorithm. First, we decide on how to generate samples from a multivariate normal density function. The sampling method used in the algorithm is a suitable method proposed by Scheuer and Stoller ${ }^{[23]}$. Given that $\\boldsymbol{\\Sigma}$ is positive-definite and its Cholesky decomposition is unique, the factorization can be written as $\\boldsymbol{\\Sigma}=\\boldsymbol{C C}^{\\mathrm{T}}$, where $\\boldsymbol{C}$ is a lower triangular matrix. A multivariate normal distribution vector $\\boldsymbol{X}$ can be calculated using $\\boldsymbol{X}=\\boldsymbol{\\mu}+\\boldsymbol{C Z}$, where $\\boldsymbol{\\mu}$ is the mean, $\\boldsymbol{C}$ is the Cholesky decomposition of $\\boldsymbol{\\Sigma}$, and $\\boldsymbol{Z}$ is a vector consisting of standard normal random variables.  \nNext, we decide on how to avoid a local optimal solution. There is a drawback of premature convergence associated with continuous EDAs. The estimation of density function is based on a set of individuals, and the information of an individual itself is not reserved. Consequently, there is a possibility that a few excellent individuals strikingly different from others in this set may vanish during the process of averaging, which implies that a possible optimal solution is lost. In order to avoid this situation, at each generation, we pass on a proportion of the best individuals to the next generation. The rest of the individuals are generated by the probability model. And to maintain a high level of diversity, a dynamic variance is applied to control the generation of new samples. A higher variance can enhance the global searching ability at the early stage, and a lower variance can improve the convergence at the final stage. The specific method is adopted to adjust the variance of vector FORMULA_81.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:47",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs using GOMEA and Linkage Trees (LTs)?",
      "topics": [
        "performance"
      ],
      "answer": "The primary objective is to efficiently mix and preserve building blocks (BBs) by inferring variable dependencies through linkage learning, modeled by a Linkage Tree (LT), which is constructed using the Unweighted Pair Grouping Method with Arithmetic-mean (UPGMA) in \\(\\mathcal{O}(n l^{2})\\) time, where \\(n\\) is the population size and \\(l\\) is the number of variables. GOMEA then uses Gene-pool Optimal Mixing (GOM) to evolve parent solutions into offspring by traversing linkage sets in the LT and selecting donors from the population.",
      "chunk_id": 11342,
      "paper_id": "Exploiting Linkage Information and Problem-Specific Knowledge in Evolutionary Distribution Network Expansion Planning",
      "paper_title": "Exploiting Linkage Information and Problem-Specific Knowledge in Evolutionary Distribution Network Expansion Planning",
      "paper_year": "2018",
      "chunk_content": "The performance of EAs depends on their ability to efficiently mix and preserve building blocks ( BBs ) (i.e. good partial solutions) in the population to create new solutions [10]. When just taken out of the box, classic EAs, like GA, are prone to disrupt these BBs due to their BB-blind variation operators (VOs). Practitioners then have to make them BB-aware by customizing them with problem-specific knowledge (PSK). If such valuable PSK is not available, BB information can be inferred from the working population of EAs by linkage learning (LL) procedures, in which problem variables having some degree of dependency are identified so that they can be jointly considered when generating new solutions. GOMEA [2, 10] is a recently developed LL EA that effectively exploits the learned linkage information.  \nWe consider a popular variant of GOMEA that uses the Linkage Tree (LT) [2, 10] to model linkage. An LT is a set of linkage sets arranged in a hierarchical structure. Each linkage set contains variables having some degree of dependency. The lowest level (i.e. leaf nodes) contains singleton (univariate) sets of each variable separately. Other linkage sets at higher levels are multivariate sets that can be formed by merging pairs of lower sets until all sets are merged into a root node containing all variables. Thus, an LT can encode different levels of dependency, from the totally independent state (i.e. leaf nodes) to the all-dependent state (i.e. root node). The root node is removed from the LT because it assumes all variables should be jointly considered by VOs, which means no new solution is created. Note that while bit-flip hillclimbing is not generally useful for solving DNEP, the leaf nodes are still kept here because a solution plan might contain the expansion option of upgrading an existing cable, which is a univariate decision. An LT over a set of problem variables $\\{1,2,3,4,5\\}$ can be, for example, $\\{\\{1\\},\\{2\\},\\{3\\},\\{4\\},\\{5\\},\\{1,3\\},\\{2,5\\},\\{1,3,4\\}\\}$. Given a set of $l$ variables and a population of $n$ solutions, an LT can be constructed efficiently by the Unweighted Pair Grouping Method with Arithmetic-mean (UPGMA) in $\\mathcal{O}\\left(n l^{2}\\right)$ time [5]  \nWe also start GOMEA with a population $\\mathcal{P}$ of $n$ candidate solutions generated by the initialization procedure mentioned above. Every generation, we use tournament selection with tournament size 2 to select a set $\\mathcal{S}$ of $n$ solutions out of $\\mathcal{P}$. The linkage model building procedure is then performed on $\\mathcal{S}$ to build the LT. Using the obtained LT, we transform each existing parent solution $\\boldsymbol{p} \\in \\mathcal{P}$ into a new offspring solution $\\boldsymbol{o} \\in \\mathcal{O}$ whose fitness value is equal to or better than the fitness value of $\\boldsymbol{p}$. The offspring population $\\mathcal{O}$ completely replaces $\\mathcal{P}$ and becomes the new parent population $\\mathcal{P}$ for the next generation.  \nInstead of fully creating new solutions and then evaluating them like in GA, the VO of GOMEA, called Gene-pool Optimal Mixing (GOM [10]), uses the learned LT to evolve each existing parent $\\boldsymbol{p}$ into a new offspring $\\boldsymbol{o}$ in an iterative manner. First, $\\boldsymbol{o}$ and a backup $\\boldsymbol{b}$ are cloned directly from $\\boldsymbol{p}$. Then, each linkage set in the LT is traversed iteratively. For each linkage set, a donor $\\boldsymbol{d}$ is randomly selected from the current population $\\mathcal{P}$. If the donor FORMULA_105 's values for the",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:50",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the preemptive resource leveling problem (PRLP), how does the algorithmic mechanism of allowing any activity to be interrupted at any integer time point, as opposed to restricting preemption to noncritical activities or specific activity subsets, affect the search space and the potential for finding a schedule with more leveled resource utilization?",
      "topics": [
        "heuristic"
      ],
      "answer": "Allowing any activity to be interrupted at any integer time point in the preemptive resource leveling problem (PRLP) enlarges the searching space. While this expansion of the search space increases computational complexity, it also increases the possibility of finding a better schedule that results in more leveled resource utilization compared to approaches like the genetic algorithm proposed by Razavi & Mozayani (2007), which only allows noncritical activities to be interrupted, or the genetic algorithm designed by Doulabi et al. (2011), where not all activities are allowed to be preempted. These restricted preemption strategies limit the exploration of potential schedules and may prevent the algorithm from identifying optimal or near-optimal solutions with more leveled resource utilization.",
      "chunk_id": 9631,
      "paper_id": "PREEMPTIVE RESOURCE LEVELING IN PROJECTS",
      "paper_title": "PREEMPTIVE RESOURCE LEVELING IN PROJECTS",
      "paper_year": "2021",
      "chunk_content": "It is increasingly popular to manage work in the form of projects. $20 \\%$ of the global economic activities are organized by projects, which generate an annual economic value of approximately 12 trillion dollars ( $\\mathrm{Li} \\&$ Hall 2019). In project  \nmanagement, allocating various types of resources effectively is a critical success factor for projects. As a well-known NP-hard problem in project resource scheduling, the resource leveling problem (RLP) has attracted many researchers' attentions. In the RLP, a baseline schedule is formed by specifying start time for each activity. This schedule levels the resource utilization while satisfying the precedence relations constraints and the project deadline constraint. Leveled resource usage can reduce unnecessary capital expenditures and avoid hasty deployment of temporary resources (Doulabi et al. 2011; Li et al. 2018). The systematic reviews of the RLP can be further referred to Demeulemeester \\& Herroelen (2002), Neumann et al. (2003).  \nIn the RLP literature, a typical assumption is that activities are non-preemptive during project execution, which means that activities cannot be interrupted once they have been started. However, preemption is not uncommon in project management practice. Due to management needs or external conditions, the execution of certain activities may be temporarily interrupted, e.g., stopping machines after work, software developers switching between different tasks, etc. (Ballestin et al. 2009). Preemption has been considered in many project scheduling problems, such as multi-project scheduling (Bock \\& Patterson 1990), multi-objective project scheduling (Nudtasomboon \\& Randhawa 1997), resource-constrained project scheduling (Ballestin et al. 2008; Demeulemeester \\& Herroelen 1996), etc.  \nIn the RLP, taking preemption into consideration can lead to more levelled resource utilization (Doulabi et al. 2011; Liu et al. 2019). Therefore, more attentions are being paid to the preemptive resource leveling problem (PRLP) and several exact and meta-heuristic algorithms have been proposed. In terms of exact algorithms, Son \\& Mattila (2004) develop a linear programming model based on binary variables for the PRLP. Hariga \\& El-Sayegh (2011) study a mixed integer programming model to minimize the cost caused by resource fluctuations and activity preemption. Nadjafi et al. (2013) proposes a branch-and-bound procedure to solve the PRLP.  \nThe research on the meta-heuristic algorithms for the PRLP is scarce. Razavi \\& Mozayani (2007) propose a genetic algorithm and they only allow noncritical activities to be interrupted. Alsayegh \\& Hariga (2012) design a hybrid meta-heuristic for PRLP, in which the cost of splitting activities is taken into consideration. Splitting critical activities is not allowed neither. Doulabi et al. (2011) design a genetic algorithm for the PRLP, in which not all activities are  \nallowed to be preempted. Their objective function consists of two terms: minimizing the cost caused by resource utilization variations and that by activity preemption. In their genetic algorithm, the proposed encoding scheme tends to generate individuals violating the precedence relations constraints. So the authors add a feasibility repair mechanism to the genetic algorithm. They validate the genetic algorithm using 220 randomly generated instances and the data of a tunnel construction project. Different from the above-mentioned studies, we allow any activity to be interrupted at any integer time point. In this case, although the searching space will be enlarged, it increases the possibility of finding a better schedule that results in more leveled resource utilization.",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:53",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm incorporating local search, how should practitioners configure the probability parameter, $pls$, to control the application of the insert-neighborhood-based local search?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Local Search",
        "Parameter Configuration"
      ],
      "answer": "Practitioners should set the probability parameter $pls$ to a small value between 0 and 1. For each solution generated, a uniform random number $r$ is generated between 0 and 1. The insert-neighborhood-based local search is applied to the solution only if $r$ is equal to $pls$. If $r$ is not equal to $pls$, the solution does not undergo local search. This probabilistic approach allows for controlling the frequency with which the computationally intensive local search is applied, balancing exploration and exploitation within the EDA framework.",
      "chunk_id": 8531,
      "paper_id": "Migrating Birds Optimization for Lot-streaming flow shop scheduling problem",
      "paper_title": "Migrating Birds Optimization for Lot-streaming flow shop scheduling problem",
      "paper_year": "2019",
      "chunk_content": "In this work, the purpose of the local search is to generate a better solution from the neighborhood of a given solution. We adopt an insert-neighborhood-based local search [14], which has been regarded as superior to the swap or exchange neighborhood. Furthermore, we try to present a simple algorithm with few parameters, so some relative algorithms such as taboo search and simulated annealing algorithm are not applied. In this paper, we apply the local search to the solutions generated in subsection 4.3 with a small probability of $p l s$ (parameter $p l s$ controls whether the solution undergoes the local search or not). That is, a uniform random number $r$ is generated from 0 and 1 , if $r=p l s$, the solution will employ the local search. Otherwise, the solution does not perform the local search.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:03:55",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of scheduling problems and the disjunctive graph representation, what is a 'critical path', and how are 'critical operations' and 'critical blocks' defined in relation to it?",
      "topics": [
        "search"
      ],
      "answer": "In a directed disjunctive graph representing a feasible schedule, the 'critical path' is defined as the longest path from the start node (0) to the end node (*). The length of this path represents the makespan of the schedule. 'Critical operations' are the operations that lie on this critical path. A 'critical block' is then defined as a maximal sequence of adjacent critical operations that are processed on the same machine.",
      "chunk_id": 12230,
      "paper_id": "A hybrid differential evolution and estimation of distribution algorithm based on neighbourhood search for job shop scheduling problems",
      "paper_title": "A hybrid differential evolution and estimation of distribution algorithm based on neighbourhood search for job shop scheduling problems",
      "paper_year": "2016",
      "chunk_content": "It is important for the efficiency and the search quality of the algorithm to select the proper neighbourhood structures. Since the neighbourhood based on the block structure of critical path can avoid unnecessary operations and effectively enhance the performance of the algorithms, it is adopted. The disjunctive graph is employed to describe JSSP to illustrate the neighbourhood structures. A brief example of JSSP is introduced, which is shown in Table 1. Figure 4 presents the model of the disjunctive graph of Table 1. The real arcs to precedence relations, the dashed arcs to pairs of operations performed on the same machine.  \nFor a directed disjunctive graph describing feasible schedule, a key component of it is the critical path, which is the longest path from start 0 to end  and its length represents the makespan. The operations on the critical path are called critical operations, which has important influence on the makespan. Once the start of the critical operation is delayed, the makespan inevitably is also delayed. In Figure 5, the length of the critical path is 15 and the critical path is $0 \\rightarrow o_{31} \\rightarrow o_{21} \\rightarrow o_{22} \\rightarrow o_{23} \\rightarrow o_{13} \\rightarrow *$. A maximal sequence of adjacent critical operations that is processed on the same machine is called a critical block. In Figure 4, the critical operations are $\\left\\{o_{31}, o_{21}, o_{22}, o_{23}, o_{13}\\right\\}$, which include two critical blocks $\\left\\{o_{23}, o_{13}\\right\\},\\left\\{o_{31}, o_{21}\\right\\}$.  \nSince the makespan of a schedule is impossibly less than the length of its critical path, only several critical operations are moved to improve the makespan. The neighbourhood structures based on blocks on critical path are adopted, which includes two neighbourhood structures swap and insert process. As following detailed:",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:03:57",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of MARTEDA compare to MONEDA when both are applied to multi-objective optimization problems, specifically considering the selection mechanism used in MONEDA?",
      "topics": [
        "selection"
      ],
      "answer": "MARTEDA is presented as an improvement over MONEDA for model building in multi-objective Estimation of Distribution Algorithms. The text mentions that MONEDA initially used NSGA-II selection, which is considered less performant. To provide a basis for comparison, MONEDA was also tested with HypE selection. The quality of solutions for both algorithms is evaluated using the hypervolume indicator across WFG4 to WFG9 test problems, each configured with FORMULA_142 and 15 objective functions, with the decision set dimension fixed to 30. Each algorithm was executed 30 times for each problem/dimension pair to assess performance statistically.",
      "chunk_id": 265,
      "paper_id": "Multi-objective optimization with an adaptive resonance theory-based estimation of distribution algorithm",
      "paper_title": "Multi-objective optimization with an adaptive resonance theory-based estimation of distribution algorithm",
      "paper_year": "2013",
      "chunk_content": "The results of the experiments involving MARTEDA, some current state-of-theart MOEDAs and MOEAs in a selection of current community-accepted problems are reported in this section. In particular we deal with problems drawn from two current and complex problem sets: the Walking Fish Group (WFG) problems and the test instances of the CEC'09 multi-objective optimization special session and competition.\nThe Walking Fish Group (WFG) problem toolkit [29] is a toolkit for creating complex synthetic multi-objective test problems. The WFG test suite exceeds the functionality of previous existing test suites. These include: non-separable problems, deceptive problems, a truly degenerate problem, a mixed shape Pareto front problem, problems scalable in the number of position related parameters, and problems with dependencies between position- and distance-related parameters. The WFG test suite provides a better form of assessing the performance of optimization algorithms on a wide range of different problems.  \nFrom the set of nine problems WFG4 to WFG9 were selected because of the simplicity of their Pareto-optimal front that lies on the first orthant of a unit hypersphere. This decision was also caused by the high computational cost of the experiments being carried out and by the length restriction imposed upon this contribution. Each of these problem was devised to challenge the capacity of the optimizer with regard to different aspects. For example, WFG4 is a separable and strongly multi-modal problem while WFG5 is also a separable problem but it has a set of deceptive locally optimal fronts. WFG6 is also separable without the strong multi-modality of WFG4. The remaining three problems have the added difficulty of having a parameter-based bias. WFG7 is uni-modal and separable, like WFG4 and WFG6; WFG8 is a non-separable problem and WFG9 is non-separable, multi-modal and has deceptive local-optima. Each problem was configured with FORMULA_142 and 15 objective functions. For all cases the decision set dimension was fixed to 30 .  \nBesides applying MARTEDA to the aforementioned problems some other MOEDAs and MOEAs are also assessed in order to provide a comparative ground for the tests. One algorithm is of particular interest, the MONEDA [37] algorithm. This approach was previously proposed by the authors to deal with the modelbuilding issue of MOEDAs and MARTEDA is supposed to be an improvement over it. However, as MONEDA used the less-performing NSGA-II selection, we have also tested MONEDA with the HypE selection, in order to have some basis for comparison.  \nBesides MONEDA, we also tested the naive MIDEA [11], MrBOA [1] and RMRMEDA [57] MOEDAs and the SMS-EMOA [8], HypE [5], MOEA/D [55], and  \nNSGA-II [20] MOEAs. The parameters of the algorithms are summarized in Table 1. For each problem/dimension pair each algorithm was executed 30 times. The quality of the solutions is determined by the use of the hypervolume indicator [31].  \nTable 1 Parameters of the algorithms used in the experiments  \nTable 1 (continued)\nThe stochastic nature of evolutionary algorithms prompts the use of statistical tools in order to reach a valid judgement of the quality of the solutions and how different algorithms compare with each other. Box plots [19] are one of such representations and have been repeatedly applied in our context. Although box plots allows a visual comparison of the results and, in principle, some conclusions could be deduced out of them.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:03:59",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model to pinpoint the Bragg wavelength detection problem, considering the incorporation of spectral distortion into the objective function?",
      "topics": [
        "testing"
      ],
      "answer": "The algorithmic steps for the EDA model, as applied to Bragg wavelength detection, involve formulating an objective function that incorporates spectral distortion. The EDA then iteratively searches for the optimal solution to this objective function. This search entails estimating the distribution of promising solutions in the search space, sampling new candidate solutions from this distribution, and updating the distribution based on the fitness of the sampled solutions. The fitness is determined by the objective function, which is designed to pinpoint the Bragg wavelength even in the presence of spectral distortion. The algorithm continues until a satisfactory solution, representing the Bragg wavelength, is acquired.",
      "chunk_id": 2694,
      "paper_id": "Distortion Tolerant Method for Fiber Bragg Grating Sensor Network Using Estimation of Distribution Algorithm and Convolutional Neural Network",
      "paper_title": "Distortion Tolerant Method for Fiber Bragg Grating Sensor Network Using Estimation of Distribution Algorithm and Convolutional Neural Network",
      "paper_year": "2024",
      "chunk_content": "Yuemei Luo ${ }^{\\ominus}$, Member, IEEE, Chenxi Huang ${ }^{\\oplus}$, Chaohui Lin ${ }^{\\ominus}$, Yuan Li ${ }^{\\oplus}$, Jing Chen ${ }^{\\ominus}$, Xiren Miao ${ }^{\\ominus}$, and Hao Jiang ${ }^{\\ominus}$\nIn this article, we proposed a distortion-tolerant method for fiber Bragg grating (FBG) sensor networks based on the estimation of distribution algorithm (EDA) and convolutional neural network (CNN). Addressing the parameter reconstruction of the reflection spectrum, an objective function is formulated to pinpoint the Bragg wavelength detection problem, with the optimal solution acquired via EDA. By incorporating spectral distortion into the objective function, the EDA-based method effectively manages distorted spectrums, ensuring the fidelity of wavelength data. Further, CNN aids in extracting features from the entire FBG sensor network's wavelength information, facilitating the creation of the localization model. By sending the reliable wavelength data obtained by EDA to the trained model, swift identification of the load position is achieved. Testing revealed that under conditions of spectral distortion, EDA can adeptly detect the Bragg wavelength. Additionally, the CNN-trained localization model outperforms other machinelearning techniques. Notably, experimental results demonstrate that the proposed EDA surpasses the second-ranked method, i.e., the maximum method, achieving a root mean square error (RMSE) of merely $1.4503 \\mathbf{~ m m}$ which is substantially lower than the 6.2463 mm achieved by the maximum method. The average localization error remains under 2 mm when 5 out of 9 FBGs' reflection spectra are distorted. Furthermore, Bragg wavelength detection error stays below 1 pm amid spectral distortion. Consequently, our method offers promising application prospects for long-term FBG sensor network monitoring, ensuring high accuracy and robustness in detecting structural damage.  \nIndex Terms-Bragg wavelength detection, convolutional neural network (CNN), estimation of distribution algorithm (EDA), fiber Bragg grating (FBG) sensor network, spectral distortion.",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:01",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the UMDA algorithm, how are marginal probabilities estimated from a selected population to influence the construction of new candidate solutions?",
      "topics": [
        "design"
      ],
      "answer": "The UMDA estimates marginal probabilities, denoted as p(x), from a selected population S, which contains λ elements. The estimation is performed using the formula: p(x) = (1/λ) * Σ (x_k) for all k in {1, 2, ..., N}, where x_k represents the components in the population.",
      "chunk_id": 2152,
      "paper_id": "Precision Analysis for an Optimal Parallel IIR Filter s Implementation",
      "paper_title": "Precision Analysis for an Optimal Parallel IIR Filter's Implementation",
      "paper_year": "2022",
      "chunk_content": "The UMDA has been proposed by Pelikan and Myhlenbein [28]. The information processing strategy of the algorithm consists of using the frequency of the components in a population of candidate solutions in the construction of new candidate solutions. To do so, we must first measure the frequency of each component in the population (the univariate marginal probability) and use the probabilities to influence the probabilistic selection of the components in the component-wise construction of new candidate solutions. The UMDA selects a number $S$ of individuals according to their fitness. Then, based on these individuals, a probabilistic model is constructed. To estimate the marginal probabilities $p(x)$ from a selected population $S$, by assuming $S$ contain $\\lambda$ elements, this template can be written as follows:  \n$$\np(x)=\\frac{1}{\\lambda} \\sum_{x \\in S} x_{k}, \\forall k \\in\\{1,2, \\ldots, N\\}\n$$  \nFinally, a new solution will be generated based on this model.\nThe PBIL algorithm is originally inspired by competitive learning and is designed for binary problems. It is widely studied in the literature although a particular reference should be made for $[4,5]$. It consists of transforming the population of candidate solutions into a probability vector $p(x)=\\left\\{p\\left(x_{1}\\right), p\\left(x_{2}\\right), \\ldots, p\\left(x_{n}\\right)\\right\\}$, where $p\\left(x_{i}\\right)$ denotes the probability of having a 1 in the $i$ th position of the solution bits $(i=1,2, \\ldots, n)$. The purpose of the PBIL algorithm is to reduce the memory space required by a genetic algorithm. This is done by reducing the population of candidate solutions to a single probability vector from which candidate solutions can be generated and evaluated. Updates and mutation operators are also performed on the probability vector rather than on the generated candidate solutions. All positions are initially equiprobable, that is, all probabilities are initialized to 0.5 . After the coding step of the solution, the PBIL algorithm generates $P_{1}$ solutions according to the current probability. Then, each component of the probability vector $p\\left(x_{i}\\right)$ is updated using the following formula:  \n$$\np\\left(x_{i}\\right)=p\\left(x_{i}\\right)+\\alpha\\left(x_{i}^{\\text {best }}-p\\left(x_{i}\\right)\\right) \\text { with } \\alpha \\in[0,1]\n$$  \nThe parameter $\\alpha$ is called the learning rate, and $x_{i}^{\\text {best }}$ is the FORMULA_73 th bit of the best solution already obtained.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:03",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for cooperative path planning of UAVs and UGVs, specifically focusing on the optimization variable P(px, py, pz)?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective is to minimize the time, J, required to achieve complete coverage in a persistent surveillance task by optimizing the 3-D array P(px, py, pz). This array determines whether a point in the environment is active (0 or 1) or inactive (-1), where -1 indicates the point is located at a building, obstacle, or inaccessible 2-D grid. The optimization aims to find the optimal on-off states of the active points, subject to the constraint that the union of the 2-D grids covered by the open points, denoted as f_cov(px, py, pz), must equal the set of ideal 2-D grids, S_ideal(sx, sy), where S_ideal(sx, sy) = 1. The minimization of J involves balancing the travel distances (D_D, D_G) and velocities (v_D, v_G) of drones and UGVs, considering their respective numbers (N_D, N_G) to reduce the longer time of traveling the circular path between the drones and the UGVs.",
      "chunk_id": 9191,
      "paper_id": "Cooperative Path Planning of UAVs & UGVs for a Persistent Surveillance Task in Urban Environments",
      "paper_title": "Cooperative Path Planning of UAVs & UGVs for a Persistent Surveillance Task in Urban Environments",
      "paper_year": "2021",
      "chunk_content": "As the low-altitude airspace in urban environments is described by a number of cubes, the cooperative path planning  \nproblem for the persistent surveillance task becomes a discrete optimization problem. The 3-D array $P$ is regarded as the optimization variables, and the values of the elements $P(p x, p y, p z)$ are determined by\n$P(p x, p y, p z)=\\left\\{\\begin{array}{ll}-1, & G 3(g x, g y, g z) \\epsilon B, G 2(g x, g y) \\epsilon B^{+} \\\\ & \\text {or } f_{\\text {cov }}(p x, p y, p z) \\cap I \\neq \\Phi \\\\ 0 \\text { or } 1 & \\text { others }\\end{array}\\right.$\nwhere $g x=\\{p x-1, p x\\}, g y=\\{p y-1, p y\\}$, and $g z=\\{p z-$ $1, p z\\}$ denote the codes of the cubes or the 2-D grid next to $P(p x, p y, p z) . B$ is the set of cubes that are occupied by the buildings, $B^{+}$is the set of 2-D grids that are occupied by the projections of the buildings in the XOY plane and the obstacles on the ground, and $I$ is the set of 2-D grids that is forbidden to be covered (called as the inaccessible 2-D girds for convenience).  \nIn (6), $P(p x, p y, p z)=-1$ denotes that the point is located at the building, the obstacle, or the inaccessible 2-D grid. In this case, the point is always forbidden to be passed, and it is defined as the inactive point. The other points are defined as the active points, and their on-off states are expressed by \" 1 \" and \" 0 \" and need to be optimized. When the point is closed, the vehicle (drone or UGV) need not pass it during the travel while the vehicle must pass all the open points to realize a complete coverage.  \nBesides, another 2-D array $S_{\\text {ideal }}(s x, s y)(s x=$ $1,2, \\ldots,\\left(X_{\\max } / l\\right) ; s y=1,2, \\ldots,\\left(Y_{\\max } / l\\right)$ ) is introduced to record the ideal state of the 2-D grids when a complete coverage is realized, the value of $S_{\\text {ideal }}(s x, s y)$ is defined in  \n$$\nS_{\\text {ideal }}(s x, s y)=\\left\\{\\begin{array}{ll}\n0, & S_{\\text {ideal }}(s x, s y) \\epsilon\\left(B^{+} \\cup I\\right) \\\\\n1, & \\text { others. }\n\\end{array}\\right.\n$$  \nThen, to realize a complete coverage, the following constraint must be satisfied:\n$\\{(s x, s y) \\mid S_{\\text {ideal }}(s x, s y)=1\\}=\\cup_{P(p x, p y, p z)=\\{f_{\\text {cov }}(p x, p y, p z)}$\nwhere the symbol $\\cup$ is the union of 2-D grids that all the open points can cover. The goal of the persistent surveillance task is to minimize the time of finishing a complete coverage, which can be expressed by  \n$$\nJ=\\max \\left\\{\\frac{D_{D}}{N_{D} \\cdot v_{D}}, \\frac{D_{G}}{N_{G} \\cdot v_{G}}\\right\\}\n$$  \nwhere $D_{D}$ and $D_{G}$ are the lengths of the circular paths for drones and UGVs, respectively, $N_{D}$ and $N_{G}$ are the number of drones and UGVs, and $v_{D}$ and $v_{G}$ are their travel velocities. The $N_{D}$ drones or FORMULA_63 UGVs are distributed evenly along the circular path in the air or on the ground, and they only travel a part of the circular path in every cycle. A greater number of drones and UGVs will result in shorter travel distance of them in each cycle, and the number of drones and UGVs is decided by considering the current available vehicles and the economic benefit comprehensively. The optimization index in (9) is the longer time of traveling the circular path between the drones and the UGVs. In fact, only the 2-D grids that must be covered on the ground are within the task of UGV, and the other 2-D girds all can be covered by the drones' flying. With\nthe index in (9), the UGVs can share the work of the drones by covering more 2-D grids in the premise of finishing their own work, thus reducing the time of performing a complete coverage for the UAVs \\& UGVs system.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:06",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms, how does the algorithmic mechanism of sampling new individuals using Graph Kernels, specifically histograms of short-path distances, address the challenges observed in the edge-max and edge-min problems, and what improvements, such as examining Gibbs sampling, are suggested to mitigate potential biases in the sampling process?",
      "topics": [
        "search"
      ],
      "answer": "The algorithmic mechanism of sampling new individuals using Graph Kernels in the proposed Estimation of Distribution Algorithm relies on referring to the feature space, which is represented by histograms of short-path distances. The edge-max and edge-min problems revealed a need to improve the sampling method due to potential biases. To address this, the text suggests examining Gibbs sampling, even though it may incur expensive computational costs in edge deletions, to potentially reduce or eliminate biases in the sampling process.",
      "chunk_id": 5242,
      "paper_id": "Use of graph kernels in Estimation of Distribution Algorithms",
      "paper_title": "Use of Graph Kernels in Estimation of Distribution Algorithms",
      "paper_year": "2012",
      "chunk_content": "This paper proposed a novel Estimation of Distribution Algorithms with Graph Kernels. Section II showed the potential capability of the Graph Kernels in the case of evolutionary searches. Thanks to the Graph Kernels, new individuals in the proposed method can be sampled by referring to the feature space, i.e., histograms of short-path distances. Two simple problems were introduced: the edge-max problems and the edge-min problems. These problems revealed that 1) the sampling method in the proposed method should be improved, and 2) the proposed methods could show satisfiable performance in terms of that the proposed methods were not affected by the population size.  \nFuture works are summarized as follows: As mentioned in the previous paragraph, the sampling method in the proposed method should be improved, where there are no biases to any direction. We should examine Gibbs sampling even if the computational costs in the edge deletions are expensive. In this paper, we only examined simple problems such that adding/removing edges are required. The proposed method can easily extend to adding/removing nodes or nodes are distinguished with labels. The latter case can be found in practical situations such as graph mining from chemical compounds, social network and so on. We can slightly modify the definition of the distance matrixes and histograms of the short-path distances, where distinguished nodes are not treated as the same type.  \n[IMAGE_4]  \nFig. 6. Experimental results of edge max problems: the average of the best individuals over 30 runs: results of 10 nodes (upper left); 20 nodes (upper right); 30 nodes (lower left); 40 nodes (lower right)\nThis work was partially supported by the Grant-in-Aid for Scientific Research (B) and the Grant-in-Aid for Young Scientists (B) of MEXT, Japan (21700254, 23700267).",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:07",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for the Multi-Objective Next Release Problem, when should practitioners consider using FEDA-NRP instead of UMDA?",
      "topics": [
        "selection"
      ],
      "answer": "Practitioners should consider FEDA-NRP over UMDA when there is explicit knowledge of dependencies between requirements. Without explicitly defined dependencies, FEDA-NRP reduces to the UMDA algorithm because the Bayesian network becomes an empty graph where all variables are independent.",
      "chunk_id": 3579,
      "paper_id": "FEDA-NRP A fixed-structure multivariate estimation of distribution algorithm to solve the multi-objective Next Release Problem with requirements interactions",
      "paper_title": "FEDA-NRP: A fixed-structure multivariate estimation of distribution algorithm to solve the multi-objective Next Release Problem with requirements interactions",
      "paper_year": "2023",
      "chunk_content": "The main contribution of this work is FEDA-NRP, a multivariate EDA to solve the MONRP which explicitly models dependencies between requirements. Embedding the knowledge about requirements interactions in the learning and sampling phases of an EDA helps to obtain good solution sets for the MONRP problem in complex datasets, in terms of hypervolume, balance and cardinality of the number of solutions. The use of the leaky binary noisy-OR gate in the model allows us to maintain a linear complexity while dealing with multivariate information.  \nThe second contribution of the study is the creation of a benchmark of synthetic datasets covering different dimensions of requirements management in agile and classic software projects developments. The variety of this benchmark facilitated the evaluation of the tested algorithms in different regimes. We made this corpus publicly available to promote future research on MONRP, as well as our software to ensure reproducibility and fair comparison. In particular, in this paper, a rigorous experimental evaluation was carried out considering this corpus and involving six algorithms, the main conclusion of which is the superiority of FEDA-NRP over the rest of the tested algorithms when considering the most complex cases and the balance obtained between time required and accuracy of the solutions. It is in the case of complex problems (projects with a large number of requirements)  \nTable A. 8\nNumber of wins for each set of hyperparameter configurations in the C-TAEA ${ }^{c}$ algorithm.  \nTable A. 9\nNumber of wins for each set of hyperparameter configurations in the UMDA algorithm.  \nTable A. 10\nNumber of wins for each set of hyperparameter configurations in the PBIL algorithm.  \nTable A. 11\nNumber of wins for each set of hyperparameter configurations in the MIMIC algorithm.\nthat FEDA-NRP obtained the best HV results of all the algorithms. It is worth noting that its main competitors (in terms of HV) are also EDAs: UMDA and MIMIC, the latter taking twice as long as FEDA-NRP, and UMDA performing worse in terms of UNFR and GD+, besides HV. Another substantial advantage of FEDA-NRP with respect to these EDAs is that it finds the best balanced solutions close to the Pareto Reference, facilitating the decision-maker's choice for a candidate solution.  \nOn the other hand, the main limitation of our proposal is that it requires as input the definition of all dependencies between requirements, although this is also the main motivation of our work. Without explicitly defined dependencies, the Bayesian network would be an empty graph, i.e., all variables would be independent of each other, so FEDA-NRP would be reduced to the UMDA algorithm.  \nAs future work, it would be interesting to measure the complexity added by keeping the $N D S_{\\text {archive }}$ updated during the search, and to optimise this process by updating the solution subset selection per iteration, instead of only once after the search has finished.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:09",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed for the Quay Crane Scheduling Problem, how is the probabilistic model initialized, and what role does the parameter $\\alpha$ play in generating new populations within the algorithm?",
      "topics": [
        "search"
      ],
      "answer": "The EDA initializes the probabilistic model by assigning an initial probability for each pair of quay crane-task. From this initial probabilistic model, a population of size $N$ is generated, where $N$ is considered fixed. In each generation, a new population is created, consisting of a percentage $\\alpha$ of the 'top solutions' from the previous population (those with the best objective function value, $f(\\sigma)$, which denotes the makespan of the schedule $\\sigma$). The remaining individuals in the new population are generated randomly from the probabilistic model. The parameter $\\alpha$, therefore, controls the balance between exploiting previously successful solutions and exploring new solutions derived from the probabilistic model.",
      "chunk_id": 11746,
      "paper_id": "Estimation of Distribution Algorithm for the Quay Crane Scheduling Problem",
      "paper_title": "Estimation of Distribution Algorithm for the Quay Crane Scheduling Problem",
      "paper_year": "2011",
      "chunk_content": "The set of feasible solutions for the QCSP is composed by schedules $\\sigma$ that satisfy the precedence and non-simultaneity relations among tasks and safety and interference restrictions among quay cranes. In this sense, the objective is to determine the feasible schedule $\\sigma^{*}$, which minimizes the completion time of the last task. The evaluation of every schedule is performed following the scheme based on the disjunctive graph model proposed in [1] so that $f(\\sigma)$ denotes the makespan of the schedule $\\sigma$.\nEstimation of Distribution Algorithms (EDA) [3] are a type of optimization techniques that belong to evolutionary computation. Its operation is based on the use of a probabilistic model that generates new solutions for the population. The probabilistic model is updated through statistical information concerning to the individuals that belong to the population and with the intention of reaching the most promising  \n[IMAGE1]  \nFig. 13.2 An unidirectional scheduling  \n  \nregions of the solution space. Unlike other classical evolutionary solution schemes, EDA dismiss the use of mutation or recombination operators by the sampling of the probabilistic model.  \nBroadly speaking, the EDA scheme used in this work for the solution of the QCSP starts with the initialization of the probabilistic model; that is, for each pair of quay crane-task, an initial probability is assigned. From the initial probabilistic model, a population with a defined number of individuals is generated. The population size, $N$, is considered as fixed during the life cycle of the algorithm. For each generation of the process a new population is created. This new population consists of a defined percentage, $\\alpha$, of the individuals belonging to the previous population and the rest is completed with random-generated solutions from the probabilistic model. The set of solutions defined by the parameter $\\alpha$ is denoted as top solutions because they are those with the best objective function value in the population. After the generation of each population the probabilistic model update is performed. These steps are repeated while a stopping criteria is not met. The whole pseudocode of the EDA is sketched in Algorithm 13.1.  \nSince the solution space is limited to unidirectional schedules, the EDA is applied twice, once to find schedules where the sense of movement of the quay cranes is  \nfrom left to right along the length of container vessel and another in the reverse sense. The solution provided by the algorithm is the best found in both searches.  \nIn the following several, solution proposals based on the previous scheme are analized.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:11",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the updating mechanism of the probability matrix Q in this EDA adjust based on superior sub-population information, and what is the role of the learning rate alpha in balancing historical data with new elite solutions?",
      "topics": [
        "selection"
      ],
      "answer": "The probability matrix \\(Q\\) in this EDA is updated at each generation using the formula \\(q_{ij}(l+1)=(1-\\alpha) q_{ij}(l)+\\frac{\\alpha}{i \\times \\text { SP\\_Size }} \\sum_{k=1}^{\\text {SP\\_Size }} I_{i j}^{k}\\), where \\(\\alpha\\) is the learning rate. The term \\((1-\\alpha) q_{ij}(l)\\) represents the retention of historical information from the previous generation \\(l\\), while the term \\(\\frac{\\alpha}{i \\times \\text { SP\\_Size }} \\sum_{k=1}^{\\text {SP\\_Size }} I_{i j}^{k}\\) incorporates information from the superior sub-population of size SP_Size. The indicator function \\(I_{ij}^{k}\\) is 1 if job \\(J_j\\) appears before or in the \\(i\\)th position in the \\(k\\)th solution of the superior sub-population, and 0 otherwise. Thus, \\(\\alpha\\) controls the balance between exploiting previously learned information and exploring new information from the elite solutions. The superior sub-population is determined by two-tournament selection with size SPSize = \\(\\eta\\)\\% * P_Size.",
      "chunk_id": 12693,
      "paper_id": "An Estimation of Distribution Algorithm-Based Memetic Algorithm for the Distributed Assembly Permutation Flow-Shop Scheduling Problem",
      "paper_title": "An Estimation of Distribution Algorithm-Based Memetic Algorithm for the Distributed Assembly Permutation Flow-Shop Scheduling Problem",
      "paper_year": "2016",
      "chunk_content": "The probability model should be well adjusted to make the search procedure tract the promising searching region. As a consequence, an updating mechanism is employed to adjust the model at each generation. First, the superior sub-population that consists of SPSize elite solutions is determined by the widely-used two-tournament selection strategy [42], where SPSize $=\\eta \\% \\cdot P_{-}$Size. Then, probability matrix $\\boldsymbol{Q}$ is updated based on the information of the superior sub-population and the historical information of searching. The updating process can be regarded as a kind of increased learning as follows:  \n$$\nq_{i j}(l+1)=(1-\\alpha) q_{i j}(l)+\\frac{\\alpha}{i \\times \\text { SP_Size }} \\sum_{k=1}^{\\text {SP_Size }} I_{i j}^{k} \\quad \\forall i, j\n$$  \nwhere $\\alpha \\in(0,1)$ is the learning rate of $\\boldsymbol{Q}$ and $I_{i j}^{k}$ is the following indicator function of the $k$ th solution in the superior sub-population:  \n$$\nI_{i j}^{k}=\\left\\{\\begin{array}{ll}\n1, & \\text { if job } J_{j} \\text { appears before or in the } i \\text { th position } \\\\\n0, & \\text { else }\n\\end{array}\\right.\n$$  \n[IMAGE_2]  \nFig. 6. Illustration of the critical path.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:14",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to apply it to the multi-mode resource-constrained project scheduling problem (MRCPSP)?",
      "topics": [
        "genetic"
      ],
      "answer": "The code should use an encoding scheme based on the activity-mode list and a decoding scheme based on the multi-mode serial SGS. Additionally, the implementation should incorporate a combined local search using multi-mode permutation based local search and multi-mode forward-backward improvement to enhance exploitation.",
      "chunk_id": 4901,
      "paper_id": "An effective estimation of distribution algorithm for the multi-mode resource-constrained project scheduling problem",
      "paper_title": "An effective estimation of distribution algorithm for the multi-mode resource-constrained project scheduling problem",
      "paper_year": "2012",
      "chunk_content": "Table 10\nComparison with HGA and SDBB ( 1 s CPU time).  \nTable 11\nComparison with EFEA, JPSO, and DDE ( 0.15 s/activity).\n1 s CPU time. It can be seen from Table 9 that our EDA not only has a higher optimal rate than EFEA and BLSA but also has lower average deviation with less computation resource.  \nIn Table 10, we compare the EDA with the genetic algorithm developed by Hartmann [3] and the truncated branch and bound developed by Sprecher and Drexl [2], which are denoted as HGA and SDBB, respectively. The stopping condition for the comparison is 1 s CPU time. As a branch and bound algorithm, SDBB can solve J10 optimally. However, as the scale of problem increases, the performance of SDBB drops rapidly. It can be seen from Table 10 that the EDA outperforms SDBB in all sets except J10, and our EDA outperform HGA in all tested sets except that the feasible rate of our EDA for J30 is slightly lower than that of HGA.  \nIn Table 11, we compare the EDA with the particle swarm optimization developed by Jarboui et al. [8] denoted as JPSO, the Differential Evolution developed by Damak et al. [11] denoted as DDE, and EFEA. The stopping condition for the comparison is 0.15 s CPU time per activity. It can be seen from Table 11 that our EDA not only has lower average deviation but also has better optimal rate than EFEA, JPSO and DDE for all the problem sets.  \nAs an incremental learning method the EDA needs effort to find and track the most promising area at the beginning of the search procedure. As a result, some algorithms outperform the EDA when small computational effort (i.e. 5000 schedules as stopping condition) is allowed. However, the EDA can provide very competitive results when the allowed computational effort becomes relatively larger ( 1 s CPU time or 0.15 s/activity as stopping condition). All in all, the above comparisons between the EDA and many existing algorithms show that the proposed EDA is an effective algorithm for solving the MRCPSP.\nThis was the first reported work to design an estimation of distribution algorithm for solving the multi-mode resource-constrained project scheduling problem. By using an encoding scheme based on the activity-mode list and a decoding scheme based on the multi-mode serial SGS, the EDA could be applied to\nthe MRCPSP conveniently. By adopting a novel probability model and updating mechanism, the promising area could be tracked effectively to keep finding better solution. By applying the combined local search with multi-mode permutation based local search and multi-mode forward-backward improvement, the exploitation could be enhanced as well. Based on the DDE method, suitable parameter settings were determined, and the guidelines to set parameters of the EDA with different stopping conditions were provided. Simulation results based on the PSPLIB benchmarks and comparisons with some existing algorithms demonstrated the effectiveness of the proposed EDA. The further work is to develop an adaptive EDA with parameter learning mechanism and to extend the EDA method to solve other scheduling problems.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:15",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the marginal probability, \\(\\operatorname{Prob}_{g}\\left(C_{i, j}\\right)\\), calculated in the Univariate Marginal Probability Algorithm (UMDA) for EDAs, and what do the components of the equation represent?",
      "topics": [
        "genetic"
      ],
      "answer": "In UMDA, \\(\\operatorname{Prob}_{g}\\left(C_{i, j}\\right)\\) is calculated as \\(\\frac{\\sum_{k=1}^{\\text{pop}} \\delta_{k}\\left(C_{i, j}=c_{i}\\right)+1 / n}{\\text{pop}+\\text{pop}_{n}}\\) where \\(\\delta_{k}\\left(C_{i, j}=c_{i}\\right)\\) is 1 if city \\(c_i\\) is at position \\(j\\) in solution \\(k\\), and 0 otherwise; \\(\\text{pop}\\) is the population size, and \\(n\\) is the number of cities. This formula estimates the probability of city \\(i\\) being at position \\(j\\) in generation \\(g\\) based on the frequency of its occurrence in the selected population.",
      "chunk_id": 7195,
      "paper_id": "Probabilistic Based Evolutionary Optimizers in Bi-objective Travelling Salesman Problem",
      "paper_title": "Probabilistic Based Evolutionary Optimizers in Bi-objective Travelling Salesman Problem",
      "paper_year": "2010",
      "chunk_content": "Travelling salesman problem (TSP) is one of the famous permutation based combinatorial optimization problems [1]. The problem aims to minimize the total distance travelled, in which each city is visited exactly once and the salesman must return to the starting depot. The adaptation of TSP into multi-objective framework (MOTSP) is another promising area which can be explored [2-3]. In the multi-objective formulation, the aim is to simultaneously optimize several conflicting objectives, such as shortest travelling distance, minimum time, minimum cost and lowest risk [4].  \nProbabilistic based evolutionary algorithms (EAs), commonly known as Estimation of distribution algorithms (EDAs) [1], mimic the biological evolutionary principle to guide the search. The primary difference between EDAs and genetic based EA (specifically genetic algorithm) is that no genetic operators (crossover and mutation) are implemented in EDAs. The reproduction is based on building of probabilistic model from the selected solutions and sampling from the constructed model.  \nSeveral researches have been carried out to study the single objective permutation based problems (specifically TSP) by using EDAs [1]. However, there is no research which studies multi-objective permutation based problems (specifically MOTSP) by using EDAs. In this paper, binary representation of multi-objective univariate marginal probability algorithm (MOUMDA) and multi-objective restricted Boltzmann machine (MORBM) [5] are adapted into a permutation based representation to solve Bi-TSP. The two objectives being considered are travelling distance and travelling cost. Permutation  \nrefinement operator is proposed to refine the cities in a chromosome to guarantee that no city is repeated. A local exploitation operator is also presented to enhance the search capability of the algorithms. Probabilistic based EAs are subsequently combined with genetic based EA to increase the spread of the trade-off solutions.\nTwo modeling approaches are considered in this paper. UMDA [6] learns the distributions of the cities without considering their linkage dependencies with other cities. In the modeling, a $n x n$ probability matrix which models the distribution of the cities is constructed, according to the following equation.  \n$$\n\\operatorname{Prob}_{\\mathrm{g}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}\\right)=\\frac{\\sum_{\\mathrm{k}=1}^{\\mathrm{pop}} \\delta_{\\mathrm{k}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}=\\mathrm{c}_{\\mathrm{i}}\\right)+1 / \\mathrm{n}}{\\mathrm{pop}+\\mathrm{pop}_{\\mathrm{n}}} \\text { where } \\delta_{\\mathrm{k}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}=\\mathrm{c}_{\\mathrm{i}}\\right)=\\left\\{\\begin{array}{l}\n1 \\text { if } \\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}=\\mathrm{c}_{\\mathrm{i}} \\\\\n0 \\text { otherwise }\n\\end{array}\\right.\n$$  \n$\\operatorname{Prob}_{\\mathrm{g}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}\\right)$ is the marginal probability of city i at the $\\mathrm{j}^{\\text {th }}$ place of the chromosome at generation $\\mathrm{g}, \\mathrm{c}_{\\mathrm{i}}$ is the city i , pop is the population size, and n is the number of cities.  \nRBM is energy based neural network [5] which learns the distribution of the input stimuli through unsupervised learning. The probabilistic model is constructed as  \n$$\n\\begin{gathered}\n\\operatorname{Prob}_{\\mathrm{g}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}\\right)=\\frac{\\sum_{\\mathrm{k}=1}^{\\mathrm{pop}} \\mathrm{P}_{\\mathrm{k}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}=\\mathrm{c}_{\\mathrm{i}}\\right)+\\mathrm{z}_{\\mathrm{j}} /(\\text { pop }+ \\text { numc })}{\\mathrm{z}_{\\mathrm{i}}+{ }^{\\mathrm{z}_{\\mathrm{j}} / \\text { pop }}} \\text { where } \\\\\n\\mathrm{P}_{\\mathrm{k}}\\left(\\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}=\\mathrm{c}_{\\mathrm{i}}\\right)=\\left\\{\\begin{array}{l}\n\\sum_{\\mathrm{h}=1}^{\\mathrm{H}} \\mathrm{e}^{-\\mathrm{E}\\left(\\mathrm{v}=\\mathrm{c}_{\\mathrm{i}}, \\mathrm{~h}\\right)} \\text { if } \\mathrm{C}_{\\mathrm{i}, \\mathrm{j}}=\\mathrm{c}_{\\mathrm{i}}, \\mathrm{Z}_{\\mathrm{j}}=\\sum_{\\mathrm{x}, \\mathrm{y}} \\mathrm{e}^{-\\mathrm{E}(\\mathrm{x}, \\mathrm{y})} \\\\\n0 \\text { otherwise }\n\\end{array}\\right. \\\\\n\\mathrm{E}(\\mathrm{v}, \\mathrm{~h})=\\sum_{\\mathrm{i}} \\sum_{\\mathrm{j}} \\mathrm{v}_{\\mathrm{i}} \\mathrm{~h}_{\\mathrm{j}} \\mathrm{w}_{\\mathrm{ij}}-\\sum_{\\mathrm{i}} \\mathrm{v}_{\\mathrm{i}} \\mathrm{~b}_{\\mathrm{i}}-\\sum_{\\mathrm{j}} \\mathrm{~h}_{\\mathrm{j}} \\mathrm{~b}_{\\mathrm{j}}\n\\end{gathered}\n$$  \nwhere v is the input state and h is the hidden state of the network, w and b is the synaptic weights and biases, Z is the normalizing constant, and E is the energy value of the network. The simple probabilistic sampling mechanism [5] is applied to generate offspring based on the built probabilistic model.  \nFor evolutionary optimizer [7], the variation operators are based on crossover and mutation. Single point crossover is used to create the offspring. This operator randomly selects the position to cut the chromosomes for crossing over between two parents. This single point crossover is equivalent to route inter-crossing. After which, mutation is carried out by swapping between two randomly selected alleles within the chromosome. This genetic perturbation provides exploitation capability to the optimizer to search within fitter region.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:18",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the CPLEX model, based on Wu et al.'s model, detailed for the 3D bin packing problem in the context of Estimation of Distribution Algorithms, specifically concerning the constraints and objective function?",
      "topics": [
        "constraints"
      ],
      "answer": "The CPLEX model aims to minimize the total volume of bins used minus the total volume of cartons packed, as expressed by the objective function \\(\\min \\left\\{\\sum_{j=1}^{N} L_{j} * W_{j} * H_{j} * n_{j}-\\sum_{i=1}^{m} l_{j} * w_{j} * h_{j}\\right\\}\\). This is achieved while adhering to constraints that prevent carton overlap (constraints 1-6), ensure cartons are placed in the same bin before checking for overlaps (constraint 7), guarantee each carton is placed in exactly one bin (constraint 8), enforce that each carton's dimensions are aligned with exactly one axis (constraints 9-13), prevent cartons from extending beyond bin boundaries (constraints 14-16), and ensure a bin is marked as used if it contains any cartons (constraint 17). The model uses binary variables like \\(s_{ij}\\) to indicate if carton \\(i\\) is in bin \\(j\\) and \\(n_i\\) to indicate if bin \\(i\\) is used, along with continuous variables \\(x_i, y_i, z_i\\) for carton corner coordinates and binary variables \\(lx_i, ly_i, lz_i, wx_i, wy_i, wz_i, hx_i, hy_i, hz_i\\) to represent carton rotation, and relative position binary variables such as \\(left_{ij}, right_{ij}, front_{ij}, behind_{ij}, below_{ij}, above_{ij}\\) to represent the relative position between cartons.",
      "chunk_id": 133,
      "paper_id": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_title": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_year": "2013",
      "chunk_content": "In this section, a CPLEX model based on the model introduced by Wu et al. [7] is presented.  \nIntroduced variables:\n$N$ : total number of bins\n$m$ : total number of cartons\n$M$ : a large enough number, an acceptable value is $\\sum_{i=1}^{m}\\left(l_{i}+h_{i}+w_{i}\\right)+$ $\\sum_{i=1}^{N}\\left(L_{i}+H_{i}+W_{i}\\right)$\n$\\left(l_{i}, w_{i}, h_{i}\\right)$ : length, width and height of carton $i$\n$\\left(L_{i}, W_{i}, H_{i}\\right)$ : length, width and height of bin $i$\n$s_{i j}$ : binary variables, $s_{i j}=1$ means carton $i$ is in bin $j$\n$n_{i}$ : binary variables, $n_{i}=1$ means bin $i$ is used\n$x_{i}, y_{i}, z_{i}$ : continuous variables, coordinate of the front-left-bottom corner point of carton $i$\n$l x_{i}, l y_{i}, l z_{i}, w x_{i}, w y_{i}, w z_{i}, h x_{i}, h y_{i}, h z_{i}$ : binary variables, indicating the rotation of carton $i$. For example, $l y_{i}=1$ means that length of carton $i$ is paralleled to X -axis.\nleft $_{i j}$, right $_{i j}$, front $_{i j}$, behind $_{i j}$, below $_{i j}$, above $_{i j}$ : binary variables, indicating the relative position between two cartons. For example, behind $_{i j}=1$ means carton $i$ is behind carton $j$.\nconstrains:\nfor all $i$ in $[1 \\ldots m], k$ in $[i+1 \\ldots m]$  \n$$\nx_{i}+l_{i} * l x_{i}+w_{i} * w x_{i}+h_{i} * h x_{i} \\leq x_{k}+\\left(1-\\text { left }_{i k}\\right) * M\n$$  \n$$\n\\begin{gathered}\nx_{k}+l_{k} * l x_{k}+w_{k} * w x_{k}+h_{k} * h x_{k} \\leq x_{i}+\\left(1-\\text { right }_{i k}\\right) * M \\\\\ny_{i}+l_{i} * l y_{i}+w_{i} * w y_{i}+h_{i} * h y_{i} \\leq y_{k}+\\left(1-\\text { front }_{i k}\\right) * M \\\\\ny_{k}+l_{k} * l y_{k}+w_{k} * w y_{k}+h_{k} * h y_{k} \\leq y_{i}+\\left(1-\\text { behind }_{i k}\\right) * M \\\\\nz_{i}+l_{i} * l z_{i}+w_{i} * w z_{i}+h_{i} * h z_{i} \\leq z_{k}+\\left(1-\\text { below }_{i k}\\right) * M \\\\\nz_{k}+l_{k} * l z_{k}+w_{k} * w z_{k}+h_{k} * h z_{k} \\leq z_{i}+\\left(1-\\text { above }_{i k}\\right) * M\n\\end{gathered}\n$$  \nfor all $i$ in $[1 \\ldots m], k$ in $[i+1 \\ldots m], j$ in $[1 \\ldots N]$  \n$$\n\\text { left }_{i k}+\\text { right }_{i k}+\\text { front }_{i k}+\\text { behind }_{i k}+\\text { below }_{i k}+\\text { above }_{i k} \\leq s_{i j}+s_{k j}-1\n$$  \nfor all $i$ in $[1 \\ldots m], k$ in $[i+1 \\ldots m], j$ in $[1 \\ldots N]$  \n$$\n\\begin{gathered}\n\\sum_{j=1}^{N} s_{i j}=1 \\\\\nl x_{i}+l y_{i}+l z_{i}=1 \\\\\nw x_{i}+w y_{i}+w z_{i}=1 \\\\\nh x_{i}+h y_{i}+h z_{i}=1 \\\\\nl x_{i}+w x_{i}+h x_{i}=1 \\\\\nl y_{i}+w y_{i}+h y_{i}=1\n\\end{gathered}\n$$  \nfor all $i$ in $[1 \\ldots m], j$ in $[1 \\ldots N]$  \n$$\n\\begin{gathered}\nx_{i}+l_{i} * l x_{i}+w_{i} * w x_{i}+h_{i} * h x_{i} \\leq L_{j}+\\left(1-s_{i j}\\right) * M \\\\\ny_{i}+l_{i} * l y_{i}+w_{i} * w y_{i}+h_{i} * h y_{i} \\leq W_{j}+\\left(1-s_{i j}\\right) * M \\\\\nz_{i}+l_{i} * l z_{i}+w_{i} * w z_{i}+h_{i} * h z_{i} \\leq H_{j}+\\left(1-s_{i j}\\right) * M\n\\end{gathered}\n$$  \nfor all $j$ in $[1 \\ldots N]$  \n$$\n\\sum_{j=1}^{m} s_{i} j \\leq M * n_{j}\n$$  \nObjective:  \n$$\n\\min \\left\\{\\sum_{j=1}^{N} L_{j} * W_{j} * H_{j} * n_{j}-\\sum_{i=1}^{m} l_{j} * w_{j} * h_{j}\\right\\}\n$$  \nConstraints (1) to (6) ensure that any two cartons do not overlap with each other. Constraint (7) ensures that we will only check no overlap constrain when two cartons are placed in the same bin. Constraint (8) ensures that each carton will be placed in exactly one bin. Constraints (9) to (13) ensure that each carton's length, width, and height are paralleled to exactly one axis. Constraints (14) to (16) ensure that none of the cartons penetrate the bin's boundary surface. Constrains (17) ensures that a bin is considered used if any cartons is placed in it.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:21",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms for the Resource-Constrained Project Scheduling Problem (RCPSP), what algorithmic steps are involved after defining the solution representation and before the learning-based updating mechanism?",
      "topics": [
        "search"
      ],
      "answer": "Based on the description, after defining the solution representation for the RCPSP, the next algorithmic step involves the construction of the probability model. Following that, a local search strategy is applied. The learning-based updating mechanism is the final step mentioned in this sequence.",
      "chunk_id": 7344,
      "paper_id": "An estimation of distribution algorithm for resource-constrained project scheduling problem",
      "paper_title": "An estimation of distribution algorithm for resource-constrained project scheduling problem",
      "paper_year": "2010",
      "chunk_content": "The RCPSP is to study the reasonable utilization of resource and the scheduling of project activities to optimize certain objective function. The RCPSP is of wide engineering background. The well-known job-shop, flow-shop and open-shop scheduling problems can be regarded as the special cases of the RCPSP.  \nThe classic RCPSP can be stated as follows. A project consists $J$ activities that are labeled as $j=1, \\ldots, J$, where the duration of activity $j$ is denoted by $d_{j}$. There are  \n[^0]:    This research is partially supported by NSFC (60774082, 70871065 and 60834004 ) and Program for New Century Excellent Talents in University (NCET).  \nprecedence relations between some activities of project. The precedence relations are given by sets of immediate predecessors $P_{j}$ indicating that an activity $j$ may not be started before each of its predecessors $i \\in P_{j}$ is completed. The set of renewable resources is referred as $K^{\\rho}$. For each resource $k \\in K^{\\rho}$ the per-period-availability is assumed to be constant that is denoted by $R_{k}^{\\rho}$. Activity $j$ requires $r_{j k}$ units of resource $k$ in each period of its non-preemptable duration $d_{j}$. The activities $j=0$ and $j=J+1$ are dummy activities, which represent the start and end of the project respectively. It assumes that the dummy activities do not request any resource and their durations are equal to zero. The set of all activities including the dummy activities is denoted as $J^{+}=\\{0, \\ldots, J+1\\}$. The common used objective for the RCPSP is to minimize the makespan of the project, which is also considered in this paper.  \nThe mathematic model for the RCPSP can be formulated as follows:  \n$$\n\\min \\sum_{i=E F T_{j+1}}^{L F T_{j}} t \\cdot x_{j+1, i}\n$$  \nsubject to  \n$$\n\\begin{aligned}\n& \\sum_{i=E F T_{j}}^{L F T_{j}} x_{j i}=1, j \\in J^{+} \\\\\n& \\sum_{i=E F T_{k}}^{L F T_{j}} t \\cdot x_{k i} \\leq \\sum_{i=E F T_{j}}^{L F T_{j}}\\left(t-d_{j}\\right) x_{j i}, j \\in J^{+} ; h \\in P_{j} \\\\\n& \\sum_{j=1}^{J^{+}, \\min \\{r=l,-1, E F T_{j}\\}}^{r_{j k}, j=J^{+}, i, j} r_{j k} x_{j k} \\leq N R_{k}, k \\in R_{k}^{\\rho} \\\\\n& x_{j i}= \\begin{cases}1, \\text { if activity } j \\text { finishes at time } t . \\\\\n0, \\text { otherwise. }\\end{cases}\n\\end{aligned}\n$$  \nwhere $L F T_{j}$ is the latest finish time of activity $j, E F T_{j}$ is t he earliest finish time of activity $j$.\nIn this section, the EDA for RCPSP is proposed after introducing solution representation, construction of the probability model, local search strategy, and learning based updating mechanism.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:23",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners construct a new population after building a probability model?",
      "topics": [
        "optimization"
      ],
      "answer": "After constructing a probability model that describes the solution space, practitioners should sample the model to generate a new population, often using the Monte Carlo method to sample the model.",
      "chunk_id": 7132,
      "paper_id": "A novel hybrid estimation of distribution algorithm for solving hybrid flowshop scheduling problem with unrelated parallel machine",
      "paper_title": "A novel hybrid estimation of distribution algorithm for solving hybrid flowshop scheduling problem with unrelated parallel machine",
      "paper_year": "2017",
      "chunk_content": "The focus of this work is the hybrid flowshop scheduling problem with unrelated parallel machine (HFSPUPM). To our best knowledge, this is the first work of hybrid estimation of distribution algorithm for the HFSPUPM. The EDA has features in using probability matrix to demonstrate the solution space. The TLBO has features of simple computation and rapid convergence. Considering these features, we propose an algorithm which combines the structure of EDA with the strategies of TLBO for solving this problem. Teaching-learning-based optimization (TLBO) is a kind of newly introduced meta-heuristics [10, 14-16]. It is a population based optimization algorithm inspired by passing on knowledge within a classroom environment, where learners first acquire knowledge from a teacher (i.e., teacher phase) and then from classmates (i.e., learner phase). There are lots of research demonstrating that TLBO outperforming ES, PSO, ABC and DE on a\nnumber of constrained benchmark functions and constrained mechanical design problems, as well as on continuous non-linear numerical optimization problems [9, 10, 14-16]. We introduce the teaching learning based optimization strategies into EDA to improve the efficiency of the individual optimization. Our algorithm combines estimation of distribution algorithm's global search ability to keep diversity with the teaching learning based optimization algorithm's local search ability to explore better solution. By this way, proposed algorithm greatly improves the search efficiency and effectiveness. In the following, we will discuss details of the proposed estimation of distribution algorithm for hybrid flowshop scheduling problem with unrelated parallel machine.\nEstimation of distribution algorithms is proposed firstly by MUHLENBEIN et al [17] in 1996. As a novel randomly optimization algorithm, the estimation of distribution algorithms has a lot of advantages. Firstly, the estimation of distribution algorithms has much difference with traditional evolutionary algorithms when taking the mathematical model into consideration. Therefore, it is based on a mathematical model of the entire population and describes the evolutionary trends of the entire group. So it is just a way of modeling on the macro-level. Secondly, the estimation of distribution algorithms provides a new tool for solving complex optimization problems.  \nEDA is an optimization algorithm which through probability model acquires the excellent solution of the problem based on a probabilistic model. The probabilistic model demonstrates the distribution of the solution to the problem. Depending on different methods of sampling the probability model, EDA develops many measures relying on the characteristic of the problem. But it can mainly be summarized as the following two important steps. The first step is to build a probability model to describe the solution space. Through the assessment of the population, we can choose a collection of outstanding individuals. Then, the statistical learning methods are used to construct a probability model to describe the current solution set. Secondly, the model is sampled to generate the new population. Mostly, using the Monte Carlo method to sample the model for getting new population, the algorithm structure is shown in Fig. 1.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:24",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the UMDA optimizing the LeadingOnes problem, under what mathematical conditions on the population size $\\lambda$ and selection size $\\mu$ can we guarantee that the frequencies $p_i^{(t)}$ for each position $i$ remain within the interval $(\\frac{1}{4}, \\frac{3}{4})$ for all iterations $t$ up to $t_i^{\\text{sel}}$, where $t_i^{\\text{sel}} = \\min\\{t_i', n\\}$ and $t_i'$ is the first iteration position $i$ becomes selection-relevant?",
      "topics": [
        "bounds"
      ],
      "answer": "For the UMDA optimizing LeadingOnes, if the population size $\\lambda$ and selection size $\\mu$ satisfy $\\lambda \\geq \\mu \\geq 64n \\ln n$, then with a probability of at least $1 - 2n^{-1}$, for each position $i \\in [n]$ and for each iteration $t \\leq t_i^{\\text{sel}}$, the frequency $p_i^{(t)}$ is guaranteed to be within the interval $(\\frac{1}{4}, \\frac{3}{4})$. This guarantee holds within the first $n$ iterations, as long as position $i$ remains neutral (not selection-relevant). The proof relies on Theorem 4 with $d = \\frac{1}{4}$ and a union bound over all $n$ frequencies.",
      "chunk_id": 8762,
      "paper_id": "A simplified run time analysis of the univariate marginal distribution algorithm on LeadingOnes",
      "paper_title": "A simplified run time analysis of the univariate marginal distribution algorithm on LeadingOnes",
      "paper_year": "2021",
      "chunk_content": "We start by showing that each frequency stays in the interval $\\left(\\frac{1}{4}, \\frac{3}{4}\\right)$ until its position becomes selection-relevant.\nLemma 3. Consider the UMDA with $\\lambda \\geq \\mu \\geq 64 n \\ln n$. Further, for each position $i \\in[n]$, let $t_{i}^{\\prime} \\in \\mathbb{N}$ denote the first iteration such that position $i$ is selection-relevant, and let $t_{i}^{\\text {sel }}=\\min \\left\\{t_{i}^{\\prime}, n\\right\\}$. Then, with a probability of at least $1-2 n^{-1}$, within the first $n$ iterations, for each position $i \\in[n]$ and for each iteration $t \\leq t_{i}^{\\text {sel }}$, it holds that $p_{i}^{(t)} \\in\\left(\\frac{1}{4}, \\frac{3}{4}\\right)$.  \nProof. Consider a position $i \\in[n]$. Note that, for all iterations $t \\leq t_{i}^{\\text {sel }}$, the frequency $p_{i}$ is neutral. By Theorem 4 with $d=\\frac{1}{4}$, we see that the probability that $p_{i}$ leaves the interval $\\left(\\frac{1}{4}, \\frac{3}{4}\\right)$ within the first $t_{i}^{\\text {sel }} \\leq n$ iterations is at most $2 e^{-\\mu /\\left(32 \\cdot t_{i}^{\\text {sel }}\\right)} \\leq$ $2 e^{-\\mu /\\left(32 \\cdot n\\right)} \\leq 2 n^{-2}$, where we used our lower bound on $\\mu$.  \nApplying a union bound over all $n$ frequencies yields that at least one frequency leaves the interval $\\left(\\frac{1}{4}, \\frac{3}{4}\\right)$ within the first $n$ iterations before being selection-relevant with a probability of at most $2 n^{-1}$, which concludes the proof.  \nWe now show that the maximum selection-relevant position is only roughly $\\log \\frac{\\lambda}{\\mu}$ larger than the critical position during each iteration.  \nLemma 4. Let $\\delta \\in(0,1)$ be a constant, and let $\\zeta=\\frac{3}{4}(1+\\delta)$. Consider the UMDA optimizing LeAdingONes with $\\mu \\geq 6 \\frac{1+\\delta}{2^{2}} \\ln n$ and $\\lambda \\geq \\mu \\cdot \\max \\left\\{1, \\frac{1}{\\epsilon}\\right\\}$. Furthermore, consider an iteration $t \\in \\mathbb{N}$ such that position $i \\in[n]$ is critical and that, for all positions $j>i$, we have  \n$p_{j}^{(t)} \\leq \\frac{3}{4}$. Let $d=\\left\\lceil\\log _{4 / 3}\\left(\\zeta \\frac{\\lambda}{t^{t}}\\right)\\right\\rceil$. Then, with a probability of at least $1-n^{-2}$, the maximum selection-relevant position for iteration $t$ is at most $\\min \\{n, i+d+1\\}$.  \nProof. Note that $d \\geq 0$ by our assumption on $\\lambda$. Similar to the proof of Lemma 2, we consider the offspring population of $\\lambda$ individuals sampled in iteration $t$. Let $X$ denote the number of individuals that have at least $i^{\\prime}:=\\min \\{n, i+d+1\\}$ leading 1 s . By assumption, all frequencies at positions greater than $i$ are at most $\\frac{3}{4}$. Thus, $\\mathrm{E}[X] \\leq \\lambda\\left(\\frac{3}{4}\\right)^{1+d}=\\lambda\\left(\\frac{3}{4}\\right)^{-(1+d)} \\leq \\frac{3}{4} \\frac{\\rho}{\\zeta} \\leq \\frac{\\rho}{1+\\delta}$.  \nWe now apply Theorem 2 in order to show that it is unlikely that at least $\\mu$ individuals from iteration $t$ have at least $i^{\\prime}$ leading 1 s . Using our bounds on $\\mu$ and our estimate on $\\mathrm{E}[X]$ from above, we compute  \n$$\n\\begin{aligned}\n\\operatorname{Pr}[X \\geq \\mu] & \\leq \\operatorname{Pr}[X \\geq(1+\\delta) \\mathrm{E}[X]] \\leq e^{-\\frac{\\rho^{2} \\mathrm{E}[X]}{3}} \\\\\n& \\leq e^{-\\frac{\\rho^{2} \\mathrm{E}(1+\\delta)}{3(1+\\delta)}} \\leq n^{-2}\n\\end{aligned}\n$$  \nThus, with a probability of at least $1-n^{-2}$, fewer than $\\mu$ individuals have at least $i^{\\prime}$ leading 1 s . This means that the maximum selection-relevant position in this iteration is in FORMULA_323.  \nBefore we prove our lower bound, we show that the UMDA does not sample the optimal solution of LeAdingONES with high probability while the critical position is at least logarithmically far away from the end.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:27",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does increasing the maximum number of generated schedules affect the performance of the proposed Estimation of Distribution Algorithm (EDA) in terms of deviation from lower bounds for the Resource-Constrained Project Scheduling Problem (RCPSP)?",
      "topics": [
        "search"
      ],
      "answer": "The text indicates that as the maximum number of generated schedules increases (from 500 to 1000 to 5000), the deviation values from the lower bounds decrease for each set of problems (J30, J60, and J120). This suggests that exploring more schedules leads to better results in finding solutions closer to the lower bounds for the RCPSP.",
      "chunk_id": 7349,
      "paper_id": "An estimation of distribution algorithm for resource-constrained project scheduling problem",
      "paper_title": "An estimation of distribution algorithm for resource-constrained project scheduling problem",
      "paper_year": "2010",
      "chunk_content": "As for the parameter setting, we use the orthogonal method of design of experiment (DOE) to determine a set of suitable parameters for the proposed EDA. Since the J120 contains the hardest problems, we choose 60 instances from J120 to carry out the DOE test. Combinations of the parameter values in Table 1 are evaluated.  \nDue to the limitation of page requirement, we omit the details of the DOE. The best combination of parameters is as follow: the number of initial population Initpop is fixed at 200; the population size of each generation Pop is set equal to 50 ; the number of individuals used to update the\nprobability matrix $N$ is fixed at $5(10 \\% \\mathrm{Pop})$; the learning speed $\\beta$ is set equal to 0.1 ; the local search accept rate Pper is fixed at 0.8 .  \nTable 1. Combinations of parameter values\nFor our experiments, we set the maximum number of generated schedules (500, 1000 and 5000) as the stopping condition. Table 2 lists the results obtained by running our proposed EDA 20 independent times for each instance. The performances include the average, minimum and maximum percentage deviation from the lower bounds as well as the variance of deviation. As for the lower bound, we use the theoretically optimal values for set J30 and employ the critical-path based lower bound for set J60 and set J120.  \nFrom Table 2, it can be seen that the derivation values increase as the size of the problem increases. It shows that RCPSP with large scale is more difficult to solve since the problem is NP-hard. For each set of problems, the derivation values decrease as the maximum number of generated schedules increases. It shows that more schedules are explored better results can be obtained. For J30, the results obtained by the proposed EDA are much close to the optimal bounds, so the EDA is very effective for RCPSP with small scale. In the next sub-section, we will compare our EDA with some existing algorithms to further show the effectiveness of our EDA. In addition, the variance values of deviation for all the sets are very small, which means that our EDA is very robust.  \nTable 2. Results overview of proposed EDA",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:29",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific 2-D copula-EDA described, what data structures are required to represent the population and how are they used in the copula-generator procedure?",
      "topics": [
        "selection"
      ],
      "answer": "The algorithm requires data structures to represent the population (pop) of size N, and a selected sub-population (spop) of size select-rate * N. The copula-generator procedure uses these populations to calculate sample averages (\\(\\bar{X}_{1}, \\bar{X}_{2}\\)) and sample variances (\\(S_{X_{1}}^{*}, S_{X_{2}}^{*}\\) ) for each random variable, which are then used to define the marginal distributions F and G as normal distributions. The parameter ρ, representing the correlation coefficient, is also calculated and stored, using either Moment Estimation or Maximum Likelihood Estimation, to define the copula C.",
      "chunk_id": 7716,
      "paper_id": "Estimation of Distribution Algorithm Based on Copula Theory",
      "paper_title": "Estimation of Distribution Algorithm Based on Copula Theory",
      "paper_year": "2010",
      "chunk_content": "A two-dimensional optimization problem is considered. According to copula theory, the marginal distribution of each random variable and a copula are required. The marginal distributions of $\\left(X_{1}, X_{2}\\right)$ is easy to estimate because the observed values are given. The only thing is to evaluate sample mean and sample variance. 2-D Gauss-copula is selected which is  \n$$\nC(u, v ; \\rho)=\\phi_{\\rho}\\left(\\phi^{-1}(u), \\phi^{-1}(v)\\right), u, v \\in[0,1]\n$$  \nwhere, $\\phi_{\\rho}$ is a binary standard Gaussian distribution with correlation coefficient $\\rho$. Determining $\\rho$ is the key to construct copula.  \nIf the Maximum Likelihood Estimation is used, then the log-likelihood function is  \n$$\nl(\\rho)=\\sum_{i=1}^{s}\\left\\{-\\ln 2 \\pi-\\frac{1}{2} \\ln \\left(1-\\rho^{2}\\right)-\\frac{z_{1 i}^{2}+z_{2 i}^{2}-2 \\rho z_{1 i} z_{2 i}}{2\\left(1-\\rho^{2}\\right)}\\right\\}+\\sum_{i=1}^{s}\\left[\\ln f\\left(x_{1}^{i}\\right)+\\ln g\\left(x_{2}^{i}\\right)\\right]\n$$  \nwhere,  \n$$\nz_{1 i}=\\phi^{-1}\\left(F\\left(x_{1}^{i}\\right)\\right), z_{2 i}=\\phi^{-1}\\left(G\\left(x_{2}^{i}\\right)\\right)\n$$  \nIf Moment Estimation is used, then  \n$$\n\\rho=\\frac{\\frac{1}{s} \\sum_{i=1}^{s} x_{1}^{i} x_{2}^{i}-\\bar{X}_{1} \\bar{X}_{2}}{S_{X_{1}}^{s} S_{X_{2}}^{s}}\n$$  \nwhere,  \n$$\n\\bar{X}_{k}=\\frac{1}{s} \\sum_{i=1}^{s} x_{k}^{i}, S_{X_{k}}^{s}=\\sqrt{\\frac{1}{s-1} \\sum_{i=1}^{s}\\left(x_{k}^{i}\\right)^{2}},(k=1,2)\n$$  \nNext, sampling from the distribution function is discussed. Since  \n$$\n\\begin{aligned}\n& C(u, v ; \\rho)=\\phi_{\\rho}\\left(\\phi^{-1}(u), \\phi^{-1}(v)\\right) \\\\\n& =\\int_{-\\infty}^{u} \\int_{-\\infty}^{v} \\frac{1}{2 \\pi \\sqrt{1-\\rho^{2}}} \\exp \\left\\{-\\frac{\\left[\\phi^{-1}(s)\\right]^{2}+\\left[\\phi^{-1}(t)\\right]^{2}-2 \\rho \\phi^{-1}(s) \\phi^{-1}(t)}{2\\left(1-\\rho^{2}\\right)}\\right\\} d t d s\n\\end{aligned}\n$$  \nthen  \n$$\n\\begin{aligned}\n& \\omega=C_{u}(v)=\\partial C(u, v) / \\partial u \\\\\n& =e^{\\frac{\\left[\\phi^{-1}(u)\\right]^{2}}{2}} \\int_{-\\infty}^{v} \\frac{1}{2 \\pi \\sqrt{1-\\rho^{2}}} \\exp \\left\\{-\\frac{\\left[\\phi^{-1}(t)-\\rho \\phi^{-1}(u)\\right]^{2}}{2\\left(1-\\rho^{2}\\right)}\\right\\} d t\n\\end{aligned}\n$$  \nTherefore,  \n$$\nv=\\sqrt{1-\\rho^{2}} \\phi^{-1}\\left(e^{\\frac{\\left[\\phi^{-1}(u)\\right]^{2}}{2}} \\omega\\right)+\\rho \\phi^{-1}(u)=\\sqrt{1-\\rho^{2}} \\phi^{-1}\\left(\\omega^{\\prime}\\right)+\\rho \\phi^{-1}(u)\n$$  \nSo randomly generate vector $\\left(u, \\omega^{\\prime}\\right) \\sim U[0,1]^{2}$, and then the other random number $v$ is calculated by using equation (16). The vector $\\left(x_{1}, x_{2}\\right)$ can be calculated by using equation (17).  \n$$\nx_{1}=\\sigma_{1} \\phi^{-1}(u)+\\mu_{1}, x_{2}=\\sigma_{2} \\phi^{-1}(u)+\\mu_{2}\n$$  \nwhere,  \n$$\n\\mu_{k}=\\bar{X}_{k}, \\sigma_{k}=S_{X_{k}}^{*},(k=1,2)\n$$  \nConclusively, the algorithm for implementing 2-D copula-EDA is as follows [35]:  \n1. Initialize (pop, $N$ ). Randomly generate initial population pop with size $N$. set generation count $g \\leftarrow 0$.\n2. Selection (pop, spop, select-rate). Select the best select-rate $\\times N$ agents from pop to spop according to the agents' fitness.\n3. copula-generator (pop, spop, mutate-rate).  \n- 3.1. Construct the distribution model of spop:  \n1) calculate the sample average and the sample variance for each random variable according to (13), then the marginal distributions are $F=N\\left(\\bar{X}_{1}, S_{X_{1}}^{*}\\right)$ and $G=N\\left(\\bar{X}_{2}, S_{X_{2}}^{*}\\right)$\n2) calculate the estimation value of parameter $\\rho$ according to equation (11) or (12), then the copula $C$ is the same as (14);  \n- 3.2. Generate a new population by iterative using procedure generation( $C$, $F, G)$, where\n$-v=C_{u}^{(-1)}(\\omega)=\\sqrt{1-\\rho^{2}} \\phi^{-1}(\\omega)+\\rho \\phi^{-1}(u)$.\n- 3.3. Randomly generate some agents by the mutate-rate.  \n4. Stop if the termination criterion is met.\n5. Set $g \\leftarrow g+1$ and go to Step 2 .  \nThe following 9 test functions are used to show the behavior of the proposed algorithm cEDA and to compare the cEDA with PBILc and other EDAs. The test functions $F_{1} \\sim F_{3}$ and $F_{6} \\sim F_{8}$ are also used in [26].  \n- $F_{1}(x)=-\\frac{100}{10^{-5}+\\sum_{i}\\left|y_{i}\\right|}$, where $y_{1}=x_{1}, y_{i}=x_{i}+y_{i-1}(i \\geq 2), x_{i} \\in[-3,3]$, the optimal result is $F_{1}^{*}(0,0, \\ldots, 0)=-10^{7}$.\n- $F_{2}(x)=-\\frac{100}{10^{-5}+\\sum_{i}\\left|y_{i}\\right|}$, where $y_{1}=x_{1}, y_{i}=x_{i}+\\sin y_{i-1}(i \\geq 2), x_{i} \\in[-3,3]$, the optimal result is $F_{2}^{*}(0,0, \\ldots, 0)=-10^{7}$.\n- $F_{3}(x)=-\\frac{100}{10^{-5}+\\sum_{i}\\left|y_{i}\\right|}$, where $y_{i}=0.024 \\times(i-1)-x_{i}, x_{i} \\in[-3,3]$, the optimal result is $F_{3}^{*}(0.024 \\times 2,0.024 \\times 3, \\ldots, 0.024 \\times(n+1))=-10^{7}$.  \n- $F_{4}(x)=\\sum_{i} x_{i}^{2}$, where $x_{i} \\in[-500,500]$, the optimal result is $F_{4}^{*}(0,0, \\ldots, 0)=0$.\n- $F_{5}(x)=1+\\sum_{i}\\left(\\sin x_{i}\\right)^{2}-0.1 \\exp \\left(-\\sum_{i} x_{i}^{2}\\right)$, where $x_{i} \\in[-10,10]$, the optimal result is $F_{5}^{*}(0,0, \\ldots, 0)=0.9$.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:31",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when applied to the reentrant hybrid flow shop scheduling problem, and how are these metrics calculated?",
      "topics": [
        "heuristic"
      ],
      "answer": "The primary performance measure is the percentage deviation ($\\delta$) of the total weighted completion time of each algorithm from a lower bound. This lower bound is obtained using a Linear Relaxation (LR) algorithm, relaxing the machine capacity constraints. The $\\delta$ average is then analyzed across different problem sizes, varying the number of jobs, layers, workstations, and machines to assess the algorithm's performance under different conditions. A smaller $\\delta$ average indicates better performance, as it signifies a closer approximation to the relaxed lower bound.",
      "chunk_id": 10947,
      "paper_id": "A hybrid differential evolution algorithm with estimation of distribution algorithm for reentrant hybrid flow shop scheduling problem",
      "paper_title": "A hybrid differential evolution algorithm with estimation of distribution algorithm for reentrant hybrid flow shop scheduling problem",
      "paper_year": "2018",
      "chunk_content": "To further analyze the data, we tested the effect of number of jobs, number of layers, number of workstations and number of machines on the performance of the four algorithms, respectively. The results are shown in Figs. 3, 4,5 and 6 . The vertical axis represents the $\\delta$ average.  \nFigure 3 shows that the DE-eEDA works the best in most of the job sizes except for the problem of 10 jobs. Figures 4, 5 and 6 show that the DE-eEDA outperforms the others in all different problem sizes.  \nIn Fig. 3, for all the algorithms, when the other factors remain unchanged, $\\delta$ average becomes large with the increase in the number of jobs for the possible reason that the competition for the machines between different jobs becomes more intense when the number of jobs increases. As what we describe in \"Appendix\", the lower bound of our problem is got by using LR algorithm relaxing the\n[IMAGE3]  \nFig. $5 \\delta$ average in different number of workstations\n[IMAGE4]  \nFig. $6 \\delta$ average in different number of machines\nmachine capacity, so when the competition for the machines between jobs becomes tight, the lower bound becomes loose, thus leading to the sharp increase in $\\delta$ average. The same reason goes for the trends shown in Figs. 4, 5 and 6. In Fig. $4, \\delta$ average becomes large with the increase in the number of layers for the possible reason that the competition for the machines between different layers becomes more intense when the number of layers increases. In Fig. 5, $\\delta$ average becomes small with the increase in the number of workstations for the possible reason that the competition for the machines between different layers becomes less intense when the number of workstations increases. In Fig. 6, $\\delta$ average becomes small with the increase in the number of machines for the possible reason that the competition for the machines between different jobs becomes less intense when the number of machines increases.\nThis paper studies a RHFS scheduling problem with inspection and repair operations involved in fabrication of each layer. A mathematical programming model is constructed with an objective of minimizing the total weighted completion time. Seven meta-heuristics have been examined, and the percentage deviation of the total weighted  \ncompletion time of each algorithm from the lower bound proposed in \"Appendix\" is used as a performance measure. In the proposed DE-eEDA, an ensemble model is introduced into the DE. Results have shown that the ensemble model improves the performance of the univariate model for the EDA and the DE by 3.53 and $2.26 \\%$, respectively, while the CPU times are nearly the same. We can also find that the DE with the eEDA involved improves the DE by $8.18 \\%$, and it works better than both the GA and the PSO.  \nAcknowledgements This study was supported by the National Natural Science Foundation of China under Grant Nos. 61273035 and 71471135 .",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:33",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for hybrid flow shop scheduling problems with unrelated parallel machines, specifically concerning makespan minimization?",
      "topics": [
        "mutation"
      ],
      "answer": "The overall purpose is to minimize the makespan, denoted as Cmax(π), in hybrid flow shop scheduling problems with unrelated parallel machines. This involves determining the optimal job permutation π, subject to time constraints and machine availability at each stage, to achieve the smallest possible maximum completion time across all jobs.",
      "chunk_id": 7131,
      "paper_id": "A novel hybrid estimation of distribution algorithm for solving hybrid flowshop scheduling problem with unrelated parallel machine",
      "paper_title": "A novel hybrid estimation of distribution algorithm for solving hybrid flowshop scheduling problem with unrelated parallel machine",
      "paper_year": "2017",
      "chunk_content": "The hybrid flow shop scheduling problem is a hotspot among the complex scheduling problems. After scholars paying a lot of time and effort, some preliminary understandings of this issue have been established. But it is still little comment on hybrid flow shop scheduling problem with unrelated parallel machine. Because each stage contains unrelated parallel machines, this problem demonstrates more complexity. Therefore, it is able to better reflect real processing problems. A relatively simple HFS (e.g., a two-stage HFS with limited waiting time) is NP hard in the strong sense [12, 13]. There is no doubt that hybrid flow shop scheduling problem with unrelated parallel machine has at least the same difficulty. In this work, we focus on hybrid flow shop scheduling problem with unrelated parallel machine and present a new model for solving this problem with makespan minimization.  \nThe mathematic model of the hybrid flow shop scheduling problem with unrelated parallel machine can be formulated as follows:  \n$$\n\\begin{aligned}\n& \\text { Minimize } \\quad C_{\\max }(\\pi) \\max _{i=1,2, \\cdots, n}\\left\\{C_{i, k}\\right\\} \\\\\n& k=s(\\text { the last stage })\n\\end{aligned}\n$$  \n$$\n\\left\\{\\begin{array}{l}\nT_{\\mathrm{s} \\pi(1,1), 1}=0 \\\\\nT_{\\mathrm{s} \\pi(i, 1), 1}=0, i=P S_{d}(\\text { special job in first stage }) \\\\\n\\partial=2,3, \\cdots, M S(k), k=1(\\text { the first stage })\n\\end{array}\\right.\n$$  \n$$\n\\left\\{\\begin{array}{l}\nC_{i, k}=T_{n i, k} \\\\\nT_{n i, k} \\geq T_{n i, k-1}, k=1,2, \\cdots, n \\\\\nT_{\\mathrm{s} \\pi(i, k), k} \\geq T_{\\mathrm{s} \\pi(i-1, k) k}, j=1,2, \\cdots, M S(k) \\\\\nT_{n i, k}=T_{n i, k}+T_{i, j, k}, k=1,2, \\cdots, S\n\\end{array}\\right.\n$$  \nwhere $\\pi$ is the job permutation i.e. the solution to the hybrid flow shop scheduling problem with unrelated parallel machine. $M S(k)$ represents the number of unrelated parallel machines at the stage $k ; T_{u i, j}$ represents the start time of the job $i$ at the stage $j ; T_{u i, j}$ represents the end time of the job $i$ at the stage $j ; T_{i, j, k}$ represents the process time of job $i$ processed on machine $j$ at the stage $k$; the goal is to get the max completion time.  \nEquation (1) describes the objective function which minimizes the makespan $C_{\\max }(\\pi)$. Equation (2) describes the special processing information in the first stage. Equation (3) gives the formulation to calculate makespan $C_{\\max }(\\pi)$. Time constraints of the processing jobs are also detail described.  \nEquation (1) describes the objective function which minimizes the makespan $C_{\\max }(\\pi)$. Following the above recursive Eqs. (2) and (3), the authors firstly calculate the completion time of jobs at the stage one, then that of the stage two, until the last stage.  \nTo illustrate the model and the issues described above, here is an example of processing matrix for understanding its structure. The following example contains 5 jobs and 3 stages. There are three unrelated parallel machines at stage 1 , two unrelated parallel machines at stage 2 and three unrelated parallel machines at stage 3 .\nFORMULA_22",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:34",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the convergence properties of the MEED model, and how does the adaptive MEED model maintain ergodicity despite modifications to population size and constraint size?",
      "topics": [
        "optimization"
      ],
      "answer": "The MEED model's convergence is based on the principle that its Markov chain is ergodic, meaning that the probabilities of state variables converge to an equilibrium distribution $\\pi$ as time step $t$ approaches infinity, regardless of the initial distribution $p^{(0)}$, expressed as $\\lim _{t \\rightarrow \\infty} p^{(t)}(x)=\\pi(x)$. The adaptive MEED model, which adjusts constraint size and selected population size, maintains ergodicity because these adaptations do not disrupt the column-allowable properties of the transition matrices. Specifically, even with a reduced population size $N^{\\prime}$ after adaptive selection, the probability of selecting the same state $i$ remains positive, $p s_{i i}=f(x_{i}) / \\sum_{i \\in[1, N^{\\prime}]} f(x_{i})=f(X_{i}) / \\sum_{i \\in[1, N^{\\prime}]} f(X_{i})>0$, ensuring the transition matrix PS remains column-allowable. Similarly, the probability of a state $i$ mapped into the underlying distribution, $p l_{i i}=\\operatorname{freq}(x_{i}) / N^{\\prime}>0$, ensures that the transition matrix PL remains column-allowable despite constraint size adjustments.",
      "chunk_id": 6479,
      "paper_id": "Adaptive estimated maximum-entropy distribution model",
      "paper_title": "Adaptive estimated maximum-entropy distribution model",
      "paper_year": "2007",
      "chunk_content": "Theorem 3. Markov chain of the MEED is ergodic.\nProof. A Markov chain is ergodic if the probabilities of state variable converge to an equilibrium distribution $\\pi$ when time step $t$ goes to infinite, regardless of initial distribution $p^{(0)}$, i.e. $\\lim _{t \\rightarrow \\infty} p^{(t)}(x)=\\pi(x)$. According to Theorems 1 and 2, Markov chain of the MEED is ergodic.  \nTheorem 4. The ergodic Markov chain of EDA has global asymptotic convergence.\nProof. This is a property of ergodic Markov chain.\nThe above section modelled the MEED model without an adaptive operation. The following shows that an adaptive model can also be modelled as an ergodic Markov chain.  \nTheorem 5. Markov chain of the adaptive MEED is ergodic.\nProof. Adaptive operation is based on the change of domain fitness, and it applies to two parameters: (i) constraint size, and (ii) selected population size. In the case of population size, individuals with a fitness value below thresholds will be lost.  \nFortunately, this will not affect the properties of the transition matrix of proportional selection, and the transition matrix PS is still column-allowable with adaptive operation. In this case, the probability of selecting the same state $i$ is, $p s_{i i}=f\\left(x_{i}\\right) / \\sum_{i \\in\\left[1, N^{\\prime}\\right]} f\\left(x_{i}\\right)=f\\left(X_{i}\\right) / \\sum_{i \\in\\left[1, N^{\\prime}\\right]} f\\left(X_{i}\\right)>0$, where $N^{\\prime}$ is the number of individuals after adaptive selection.  \nSimilarly, in the case of constraint size, the loss of constraints below threshold will not change the properties of the transition matrix of parametric learning. Specifically, the probability of a state $i$ mapped into underlying distribution is $p l_{i i}=\\operatorname{freq}\\left(x_{i}\\right) / N^{\\prime}>0$. So $\\mathbf{P L}$ after adaptive selection is also column-allowable. According to Theorems 1 and 2, therefore the Adaptive MEED algorithm can be modelled as an ergodic Markov chain.  \nThe above discussed the ergodic properties of the proposed model. Being ergodic, the proposed model can be used as a global optimization technique. The next section presents the applications of the Adaptive MEED model to several optimization problems in data mining.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:37",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using Clayton's copula within the SMS-EDA-MEC framework, how should practitioners generate new individuals and integrate precursor individuals to maintain diversity and avoid premature convergence?",
      "topics": [
        "search"
      ],
      "answer": "To generate new individuals, practitioners should first calculate the dependence parameter and then generate $x_{i}$ new individuals using samples $\\mathbf{u}$ from the Clayton's copula. These offspring are merged with the parent population. Subsequently, precursors $r_{n}=F_{n}^{-1}(1-u_{n})$ are generated after a transformation of the samples, where $F_{n}^{-1}$ is the inverse cumulative distribution function. These precursor individuals replace the worst individuals from the resulting population. This process, combined with the multi-objective $\\mathcal{S}$-metric selection mechanism, is repeated until a stop condition is met, ensuring diversity and exploration of other regions of the search space.",
      "chunk_id": 12034,
      "paper_id": "SMS-EDA-MEC Extending Copula-based EDAs to Multi-Objective Optimization",
      "paper_title": "SMS-EDA-MEC: Extending Copula-based EDAs to Multi-Objective Optimization",
      "paper_year": "2016",
      "chunk_content": "Subsequently, $x_{i}$ new individuals are generated using the calculated dependence parameter and the samples $\\mathbf{u}$ from the Clayton's copula. This offspring population is merged with the parents. After that, the worst individuals are selected from the merged population and removed from it.  \nAfter a transformation in the samples generated in the next step, precursors $r_{n}=F_{n}^{-1}\\left(1-u_{n}\\right)$ are generated. According to [14] the precursor individuals correspond to samples of a new probability distribution is obtained as a variation of the learned one so as to generate individuals with a lower probability of appearing in the evolutionary process. This concept has been used to determine the inverse probability for discrete variables [25] and explore other regions of the search space which helps to avoid premature convergence. It consists of using the information which is contained in the probabilistic model to generate individuals which introduces diversity. It must be highlighted that the precursor individuals do not necessarily have to be obtained from the complement of samples; they can be generated from any process able to explore other regions of the search space.  \nFinally, the $r_{n}$ individuals replace the worst individuals from the resulting population. This entire process is repeated until a stop condition is attained, and the best individual is found.\nThe $\\mathcal{S}$-Metric Selection EDA-MEC (SMS-EDA-MEC) extrapolates the concepts developed for EDA-MEC to the multiobjective optimization problem domain by combining it with the multi-objective $\\mathcal{S}$-metric selection mechanism. Although the ideas put forward by EDA-MEC are valid in the multi-\nobjective case some modifications are necessary to deal with the particularities of the problem.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:39",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, what properties of the LBH model contribute to its performance in problems with a large search scope for discrete variables?",
      "topics": [
        "search",
        "Estimation of Distribution Algorithms",
        "discrete variables",
        "LBH model",
        "exploration vs exploitation"
      ],
      "answer": "The LBH model utilizes a learning-based strategy and adaptive learning rate. These features enable the algorithm to avoid early convergence and maintain a balance between exploration and exploitation. The effect of the LBH model is greater than other algorithms when the number of available values makes the combinations of discrete variables grow vigorously, especially in problems where the search scope of variables is extremely large.",
      "chunk_id": 10259,
      "paper_id": "An Estimation of Distribution Algorithm for Mixed-Variable Newsvendor Problems",
      "paper_title": "An Estimation of Distribution Algorithm for Mixed-Variable Newsvendor Problems",
      "paper_year": "2020",
      "chunk_content": "In the LBH model, the adaptive learning-based strategy is employed, which can make the algorithm avoid early convergence and have a good balance between exploration and exploitation in the discrete search space. As the increasing number of available values make the combinations of the discrete variables grow vigorously, the effect of the LBH model is obviously greater than the other algorithms which utilize different methods for discrete variables, especially in the problems where the search scope of variables is extremely large.\n3) Comparison Under Different Degree of Constraint Forces: The multiple constraints in the mixed-variable newsvendor model make the search space become more complicated, especially when the CF becomes strong. The results shown in Table VII also validate that $\\mathrm{EDA}_{m v n}$ has a great performance in these test instances, even if in the problems with strong CF. There are two reasons as follows. First, the AWH model makes every region in the continuous search space have a chance to be searched in each iteration. This feature can help $\\mathrm{EDA}_{m v n}$ avoid getting trapped into the local optima under the complicated environment. Second, the LBH model is also very suitable for the complex problems by using the learning-based strategy and the adaptive learning rate. Therefore, the combination of these two models can help the algorithm find better solutions.\n4) Comparison Under Different Price Sensitivity: From Table VIII, we can see that $\\mathrm{EDA}_{m v n}$ and $\\mathrm{DE}_{m v}$ outperform other algorithms under this comparison. In some ways, the PS is the connection between the continuous and discrete variables. A high selling price will decrease the real demand and influence the order quantity, or vice verse. In $\\mathrm{EDA}_{m v n}$, two histogram models are used to deal with  \nTABLE IV\nComparison Results for $\\mathrm{EDA}_{m v n}$, GA-PSO, $\\mathrm{ACO}_{m v}$, $\\mathrm{DE}_{m v}$, AEDA, and Lingo on the Benchmark Suite. The Best Results Are Shown in Bold TyPe. \" + ,\" \" - ,\" or \"n\" Indicates the Performance Is Better Than, Worse Than or Similar to the Performance of $\\mathrm{EDA}_{m v n}$ at 0.95 Significance Level by a Wilcoxon Rank Sum Test  \nTABLE V\nComparison Results on the Synthetic Benchmark Suite With Different Dimensions of the Search Space. The Results Shown by the Normalized Values. Each Row Shows the Results of Different Algorithms Under a Certain Factor Level. The Best Results Are Shown in Bold Type  \nTABLE VI\nCOMPARISON RESULTS ON THE SYnTHETIC BENCHMARK SUIte WITH DIPFERENT NUMber OF AVAILABLE Values of DISCRETE Variables. The Results Shown by the Normalized Values. Each Row Shows the Results of DIPFERENT Algorithms Under a Certain Factor Level. The Best Results Are Shown in Bold Type  \nthe continuous and discrete variables, respectively, while in $\\mathrm{DE}_{m v}$, original DE and set-based DE are used. The search mechanisms behind each of these two algorithms are highly compatible and consistent. This feature makes these two algorithms have a better performance to deal with these problems where continuous variables are correlate with discrete ones [53]. The results in Table VIII show that $\\mathrm{EDA}_{m v n}$ and $\\mathrm{DE}_{m v}$ have the best performance and validate the compatible and consistent search mechanisms do have good efficiency.  \nFrom the above results and analyses, we can conclude that the proposed FORMULA_358 outperforms other algorithms, which can be attributed to the following three reasons. First, EDA has a great performance in global search capability, which makes it more suitable to solve the problems with complicated search",
      "question_type": "algorithm properties",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:41",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the implementation of UMDA with an infinite population differ from UMDA using fixed-width histogram marginal models with a finite population, specifically in terms of their algorithmic steps?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "UMDA with an infinite population uses proportional selection to update the probability distribution \\(p^{*}(x, t)\\) based on the objective function \\(f(x)\\) and the current distribution \\(p(x, t)\\), followed by a variation step where \\(p(x, t+1)\\) is computed as the product of marginal probabilities \\(p_{i}^{*}(x_{i}, t+1)\\). In contrast, UMDA with fixed-width histogram marginal models generates \\(N\\) points from \\(\\tilde{p}(x, t)\\), selects \\(M\\) points using proportional selection to form \\(Pop^{*}(t)\\), and then computes \\(\\tilde{p}_{i}(x_{i}, t+1)\\) as the fixed-width histogram marginal distribution based on \\(Pop^{*}(t)\\).",
      "chunk_id": 13315,
      "paper_id": "On the convergence of a class of estimation of distribution algorithms",
      "paper_title": "On the convergence of a class of estimation of distribution algorithms",
      "paper_year": "2004",
      "chunk_content": "1) Infinite Population Versus Finite Population: The results in this section are for the infinite population model of FDAs. However, all practical FDAs work with a finite population. Therefore, it is important to study the approximation error of the infinite population model. We have been unable to obtain an upper bound of approximation error for general FDA. In the following, we consider the behavior of UMDA (which is the simplest version of FDA) with finite and infinite population in the case when the objective function  \n$f(x)=(1 / n) \\sum_{i=1}^{n} x_{i}, D=[0,1]^{n}, p(x, 0)=1$ and the selection scheme is proportional. The UMDA with infinite population can be described as the following.  \nStep 1) Proportional Selection  \n$$\np^{*}(x, t)=\\frac{f(x) p(x, t)}{\\int_{D} f(x) p(x, t) d x}\n$$  \nStep 2) Variation  \n$$\np(x, t+1)=\\prod_{i=1}^{n} p_{i}^{*}\\left(x_{i}, t+1\\right)\n$$  \nWe can prove that $p(x, t)$ in the above algorithm has the form  \n$$\np(x, t)=\\prod_{i=1}^{n} g_{t}\\left(x_{i}\\right)\n$$  \nwhere $g_{t}(*)$ is a polynomial of order $t$  \n$$\ng_{t}(s)=\\sum_{i=0}^{t} a_{t, i} s^{t}\n$$  \n$a_{0,0}=1$ and $a_{t, i}(t \\geq 1, i=0,1,2, \\ldots, t)$ can be computed recursively  \n$$\n\\begin{aligned}\na_{t+1,0} & =\\frac{n-1}{n} a_{t, 0} \\\\\na_{t+1, k} & =\\frac{n-1}{n} a_{t, k}+\\left(n \\sum_{i=0}^{t} \\frac{a_{t, i}}{i+2}\\right)^{-1} a_{t, k-1}, 1 \\leq k \\leq t \\\\\na_{t+1, t+1} & =\\left(n \\sum_{i=0}^{t} \\frac{a_{t, i}}{i+2}\\right)^{-1} a_{t, t}\n\\end{aligned}\n$$  \nThus, $E(t)$ (as defined in Section II-A) becomes  \n$$\nE(t)=\\sum_{i=0}^{t} \\frac{a_{t, i}}{i+2}\n$$  \nThere are several ways to implement UMDA with a finite population, We consider UMDA using fixed-width histogram marginal models [34], which works as follows.  \nStep 1) Set $t:=0$ and $\\tilde{p}\\left(x_{i}, 0\\right)=1$ for all $1 \\leq i \\leq n$.\nStep 2) Generate $N$ points in $D$ from $\\tilde{p}(x, t)=$ $\\prod_{i=1}^{n} \\tilde{p}_{i}\\left(x_{i}, t\\right)$ to form the population $\\operatorname{Pop}(t)$.\nStep 3) Use proportional selection to select $M$ points from $\\operatorname{Pop}(t)$ to form $\\operatorname{Pop}^{*}(t)$.\nStep 4) Compute $\\tilde{p}_{i}\\left(x_{i}, t+1\\right)$, the fixed-width histogram marginal distribution on each $x_{i}$ in $\\operatorname{Pop}^{*}(t)$.\nStep 5) Set $t:=t+1$ and go to Step 2).\nIn the marginal fixed-width histogram distribution model, the search space for each variable $x_{i}$ (which is $[0,1]$ in our case) is divided into $H$ bins. The probability density is constant in each bin. In our experiments for the above two algorithms, we consider the case $n=3$ and we set $N=M=H=100$ for the algorithm with finite population. Fig. 1 shows the evolution of the average objective function value for UMDA with infinite population, the mean and standard deviation of the average objective function value for ten independent runs of UMDA with finite population. We can see that the long term behaviors of\n[IMAGE0]  \nFig. 1. Evolution of the average objective function value for UMDA with infinite population, the mean and standard deviation of the average objective function value for UMDA with finite population.\ntwo algorithms are quite similar. The discrepancy comes from sample fluctuations.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:43",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to manage the population update using the probability matrix, and what considerations should be made for balancing exploration and exploitation during this process?",
      "topics": [
        "bounds"
      ],
      "answer": "To implement the EDA, the code should maintain a population of size `Pop`, initialized to `Initpop = 200`. A key aspect is updating the probability matrix using a subset `N` of individuals from the population, where `N` is fixed at `5` (10% of `Pop`). The learning speed `β` (set to 0.1) controls the influence of selected individuals on the probability matrix. The local search accept rate `Pper` (fixed at 0.8) governs the acceptance of local search moves. Balancing exploration and exploitation involves adjusting `β` and `Pper`; a smaller `β` favors exploration by slowing down the adaptation of the probability matrix, while a larger `Pper` encourages exploitation by accepting more local search moves. The algorithm terminates when the maximum number of generated schedules (500, 1000, or 5000) is reached, representing a trade-off between solution quality and computational cost.",
      "chunk_id": 7349,
      "paper_id": "An estimation of distribution algorithm for resource-constrained project scheduling problem",
      "paper_title": "An estimation of distribution algorithm for resource-constrained project scheduling problem",
      "paper_year": "2010",
      "chunk_content": "As for the parameter setting, we use the orthogonal method of design of experiment (DOE) to determine a set of suitable parameters for the proposed EDA. Since the J120 contains the hardest problems, we choose 60 instances from J120 to carry out the DOE test. Combinations of the parameter values in Table 1 are evaluated.  \nDue to the limitation of page requirement, we omit the details of the DOE. The best combination of parameters is as follow: the number of initial population Initpop is fixed at 200; the population size of each generation Pop is set equal to 50 ; the number of individuals used to update the\nprobability matrix $N$ is fixed at $5(10 \\% \\mathrm{Pop})$; the learning speed $\\beta$ is set equal to 0.1 ; the local search accept rate Pper is fixed at 0.8 .  \nTable 1. Combinations of parameter values\nFor our experiments, we set the maximum number of generated schedules (500, 1000 and 5000) as the stopping condition. Table 2 lists the results obtained by running our proposed EDA 20 independent times for each instance. The performances include the average, minimum and maximum percentage deviation from the lower bounds as well as the variance of deviation. As for the lower bound, we use the theoretically optimal values for set J30 and employ the critical-path based lower bound for set J60 and set J120.  \nFrom Table 2, it can be seen that the derivation values increase as the size of the problem increases. It shows that RCPSP with large scale is more difficult to solve since the problem is NP-hard. For each set of problems, the derivation values decrease as the maximum number of generated schedules increases. It shows that more schedules are explored better results can be obtained. For J30, the results obtained by the proposed EDA are much close to the optimal bounds, so the EDA is very effective for RCPSP with small scale. In the next sub-section, we will compare our EDA with some existing algorithms to further show the effectiveness of our EDA. In addition, the variance values of deviation for all the sets are very small, which means that our EDA is very robust.  \nTable 2. Results overview of proposed EDA",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:46",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the LI-EDA-ADR algorithm when varying the compensation factor?",
      "topics": [
        "convergence"
      ],
      "answer": "The effectiveness of the LI-EDA-ADR algorithm with different compensation factors is evaluated using the averaged hypervolume and the best hypervolume. An increase in the compensation factor leads to an increase in averaged hypervolume, while it also leads to a decrease in the best hypervolume.",
      "chunk_id": 8303,
      "paper_id": "Dynamic deployment optimization of near space communication system using a novel estimation of distribution algorithm",
      "paper_title": "Dynamic deployment optimization of near space communication system using a novel estimation of distribution algorithm",
      "paper_year": "2019",
      "chunk_content": "The compensation factor balances the convergence and divergence of the LI-EDA-ADR. To investigate to what extent the compensation factor affects the performance of the LI-EDA-ADR, we solve the test problem 1 with 5 airships using different compensation factors, and the result is shown in Fig. 9.  \nFrom this figure, we can notice that there are two opposite trends. As the compensation factor increases, the averaged hypervolume increases while the best hypervolume decreases. The reason is, with a small compensation factor, the LI-EDAADR explores the promising area with more effort which helps generate more qualified solutions like the case of 0.005 as shown in Fig. 9. However, due to the relatively poor diversity, it is easy for some inferior solutions to survive in the less competitive population. Thus, the averaged hypervolume is relatively low. With a bigger compensation factor, the diversity of the LIDM is alleviated. More qualified individuals are estimated by the LIDM, thus, the averaged hypervolume increases. However, the limited computation resource is assigned to more individuals. The improvement of the promising individuals is deteriorated. Therefore, the cases like FORMULA_301 and 0.7 have better averaged hypervolumes but fewer solutions of high quality. Based on the analysis above, we can conclude that the compensation factor balances the computation resource allocation between the exploration and exploitation. With a small compensation factor, the proposed algorithm is able to obtain solutions of high quality, while the averaged fitness of the solutions is relatively poor. A  \nlarger compensation factor prompts the algorithm to improve the fitness of the whole population, while less computation resource is used to improve the fitness of the best solutions.\nIn this paper, we propose a local incremental estimation of distribution algorithm with an asymmetrical domination relationship to solve the deployment optimization problem of the near space communication system in the dynamic environment. We first conclude the features of the dynamic user distribution and propose a dynamic user distribution model. And then the deployment optimization in the dynamic environment is proposed as a multiobjective optimization problem based on two major concerns of the NSCS. Based on the features of the target MOP and similar problems, we summarize the development and advantages of the EDA. Three major issues of the EDA are theoretically analyzed in the dynamic environment: dynamic environment's effect, the conflict between the selection mechanism of the external and internal population and the exploration ability in the probability model space. Based on the analysis of these three issues, the LI-EDA-ADR is proposed. We test the proposed algorithm compared with the other four popular algorithms. The result demonstrates that the proposed LI-EDA-ADR is an effective algorithm and outperforms the other four algorithms significantly. Important parameters like the length of the estimated generations, the compensation factor and environment change frequency are investigated in the experiments. Some guidelines for tuning these parameters are given as well.  \nThere are also many interesting problems that are worth notice. The first one is that an adaptive mechanism for the compensation factor can help the algorithm perform well. The second one is that it might be helpful to add a noise to the objective functions of a static MOP or dynamic MOP to improve the solution quality. These two problems will be investigated in our future work.\nThis work was supported by the National key research and development program of China (Grant no. 2017YFB0802200), the National Natural Science Foundation of China (Grant nos. 61772393), and the Key research and development program of Shaanxi Province (Grant no. 2018ZDXM-GY-045).",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:47",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when comparing NMBDE against DBDE, DBPSO, BAS, and MBDE in both low and high-dimensional numerical optimization problems?",
      "topics": [
        "convergence"
      ],
      "answer": "The primary objective is to evaluate the optimization ability and scalability of NMBDE by comparing its solution quality and performance against DBDE, DBPSO, BAS, and MBDE on benchmark functions. The assessment includes analyzing search accuracy, convergence speed, and success rate in finding global optima, particularly when the dimensionality of the search space is increased, using metrics derived from numerical results and $t$-tests at a $95\\%$ confidence level.",
      "chunk_id": 4969,
      "paper_id": "A novel modified binary differential evolution algorithm and its applications",
      "paper_title": "A novel modified binary differential evolution algorithm and its applications",
      "paper_year": "2012",
      "chunk_content": "In the following section, NMBDE are used to solve the numerical optimization problems and multidimensional knapsack problems to test its optimization ability. In order to compare the solution quality and performance of NMBDE, four binary-coded optimization algorithms, i.e., DBDE [26], DBPSO [27], BAS [28], and MBDE [23] with the recommended parameter values were applied to the both applications as well. Table 4 lists the parameter settings of all the algorithms.\nFirstly, NMBDE, DBDE, DBPSO, BAS and MBDE were applied to optimize 20 benchmark functions in low-dimension. Then eight functions of them, which can be extended to high-dimension, were increased to 30-dimensions to verify the optimization ability and scalability of the algorithms. Each variable in the solution vector was encoded by 20 bits.\nFor low-dimension tests, the maximum generation and the population size of all algorithms were set to 3000 and 40 respectively, and the experiments were repeated for 100 times independently. The numerical results and the $t$-test results are both given in Table 5 where \" + \" indicates that NMBDE is significantly better than the compared algorithm at the $95 \\%$ confidence; \"-\" means that NMBDE is significantly worse than\nthe compared algorithm; and \" $\\approx$ \" represents that the difference is not significant. The convergence curves of four algorithms on parts of the benchmarks are drawn in Fig. 4.  \nTable 5 shows that NMBDE outperforms DBDE, DBPSO, BAS and MBDE on almost all the test functions in terms of search accuracy and convergence speed. Specifically, NMBDE is only inferior to DBDE and MBDE on $f_{2}$ on $f_{10}$, respectively.  \nFrom Fig. 4, it is obvious that NMBDE searches out the better solutions and converges faster than the other algorithms on the majority of functions as the proposed probability estimation operator can provide better global searching ability and prevent NMBDE from trapping in the local optima.\nOn high-dimensional numerical experiment, the population size of all algorithms was set as $N P=200$ and the maximal generation number was 5000 . The experimental results are listed in Table 6 and the convergence curves of the average best fitness values are displayed in Fig. 5, which show that NMBDE is superior to DBDE, DBPSO, BAS and MBDE on all eight high-dimensional benchmark functions. For $f_{9}, f_{17}, f_{18}, f_{19}$ and $f_{20}$, NMBDE searched out the global optima with $100 \\%$ success rate with a faster convergence speed as well as MBDE while DBDE, DBPSO and BAS failed to achieve the global best values. However, the highdimension numerical optimization is a very difficult problem as the search space is expanded to $2^{600}$. NMBDE did not find out the optimal values of $f_{1}, f_{8}$ and $f_{9}$, but its solutions are still better than those of DBDE, DBPSO, BAS and MBDE. Therefore, it is fair to claim that NMBDE has the better optimization ability especially for the complicated problems.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:49",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of random rescaling, as employed in the Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) for permutation optimization problems, influence the processing of dependencies between partial solutions, and what are the observed performance trade-offs when combined with the population re-encoding operator?",
      "topics": [
        "optimization"
      ],
      "answer": "Within GOMEA, random rescaling and population re-encoding are mechanisms intended to maintain diversity and increase the chance of effectively processing dependencies between partial solutions. The random-rescaling operator (X-O) has a bigger positive impact on performance than the re-encoding operator (O-R), especially as instance size increases. Combining both re-encoding and random rescaling (X-R) improves the positive effect of random rescaling for some cases, but degrades the performance of X-O in several cases. For the largest instances (set $500 \\times 20$), the X-R variant appears to be the best, but the results are not statistically significantly different from those obtained by the X-O variant, indicating a trade-off between diversity maintenance and performance gains depending on the problem instance.",
      "chunk_id": 12287,
      "paper_id": "Expanding from Discrete Cartesian to Permutation Gene-pool Optimal Mixing Evolutionary Algorithms",
      "paper_title": "Expanding from Discrete Cartesian to Permutation Gene-pool Optimal Mixing Evolutionary Algorithms",
      "paper_year": "2016",
      "chunk_content": "ing only a single GOMEA variant (e.g., X-R). On a side note, we argue that the inefficiency of the population-management scheme can easily be justified by the great added value in terms of usability, allowing practitioners to use GOMEA without the need for any time-consuming parameter tuning.  \nWhile the O-O variant (i.e., without re-encoding and without random rescaling) already works fairly well on all PFSP instances (in configuration 3), even when solving the biggest instances (set $500 \\times 20$ ), the results still leave room for improvement. The random-rescaling operator (X-O) appears to be have a bigger positive impact on performance than the re-encoding operator (O-R), especially when the size of instances increases. The combination of both re-encoding and random rescaling (X-R) improves the positive effect of random rescaling for some cases, but it also degrades the performance (of X-O) in several cases. Hence, comparing the performance of the X-O and X-R variants yields alternating results, depending on the problem instance. For the largest instances (set $500 \\times 20$ ), the X-R variant appears to be the best, but the obtained results are not statistically significantly different from those obtained by the X-O variant.  \nFinally, considering the best-known results as reported in the latest major publication on PFSP [5] in which besides GM-EDA, also various local search algorithms and hybrid EAs were tested, our GOMEA variants found new bestknown solutions (i.e. new upper bounds) for 2 problem instances in the set FORMULA_184 (underlined in Tables 2 and 3). This further underlines the promise and potential of GOMEA, both for discrete Cartesian and permutation spaces, because it is very difficult for a black-box, general-purpose solver (i.e. without the use of specialized (local search) operators) to obtain solutions of higher quality than those found by state-of-the-art problem-specific algorithms. Given this excellent basis, combining GOMEA with powerful, problemspecific, local search is a worthwhile future extension.\nIn this paper, for the first time, we proposed a Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) for permutation optimization problems. We did so by making use of the random-keys encoding so that the known strengths of GOMEA for solving discrete Cartesian-space optimization problems can be harnessed effectively. We further employed a population-management scheme that eliminates the need for manually setting a population size and two specific additional operators, random rescaling and population reencoding, to maintain diversity longer and to increase the chance of effectively processing dependencies between partial solutions. Using the linkage tree for the linkage model, the performance of the novel GOMEA for permutation optimization problems was tested on 120 problem instances of the permutation flowshop scheduling problem (PFSP), targeted at minimizing total flow time. Results confirmed that the excellent performance of GOMEA that was previously observed for discrete Cartesian search spaces, is retained. Even though no (problem-specific) local search was employed, GOMEA reliably obtained high-quality solutions, significantly outperforming the recent state-of-the-art generalized Mallows estimation-of-distribution algorithm (GMEDA), and even finding new best-known solutions for two problem instances. Altogether, the proposed novel GOMEA based on random keys may be considered to be a promising new EA for permutation optimization.\nWe thank Josu Ceberio and Jose A. Lozano for providing us with outcomes of all runs of GM-EDA on the Taillard instances so that we could perform statistical hypothesis tests.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:51",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to manage battery state of charge (SoC) in PHEVs/PEVs, how should practitioners define the maximum and minimum SoC thresholds to prevent overcharging or overdischarging?",
      "topics": [
        "optimization"
      ],
      "answer": "To mitigate overcharging or overdischarging when using an Estimation of Distribution Algorithm for PHEV/PEV battery management, the maximum SoC ($SoC_{s, max}$) should be set to 95% and the minimum SoC ($SoC_{s, min}$) should be set to 5% for all vehicles. These values define the operational boundaries for the battery's state of charge.",
      "chunk_id": 4931,
      "paper_id": "Intelligent PHEV charging and discharging strategy in smart grid",
      "paper_title": "Intelligent PHEV Charging and Discharging Strategy in Smart Grid",
      "paper_year": "2012",
      "chunk_content": "$$\nL=a \\cdot D o D^{-b}\n$$  \nFor NiMH battery, the relationship between battery cycle life and DoD can be expressed as a exponential function:  \n$$\nL=\\beta_{0}\\left(\\frac{D o D_{R}}{D o D}\\right)^{\\beta_{1}} \\exp \\left(\\beta_{2} \\cdot\\left(1-\\frac{D o D}{D o D_{R}}\\right)\\right)\n$$  \nAccording to PJM market data [20-21], the price for regulation capacity $p_{\\text {reg_capacity }}$ is $\\$ 38.2 / \\mathrm{MW}-\\mathrm{h}$. The price  \nfor regulation electricity $p_{\\text {reg_electricity }}$ is assumed to be the average spot energy price $\\$ 0.1 / \\mathrm{kWh}$. The participated vehicles are awarded \"free charging\" when providing regulation services. In this paper, the Time-of-Use (TOU) pricing schedule provides two-tiered pricing for $\\mathrm{PHEVs} / \\mathrm{PEVs}$ with a dedicated meter for On- and Off-Peak time. Generally speaking, the electricity price will be cheaper during the low load period, and will be higher in the peak period. According to PJM recent study [20], OnPeak hours are 12:00-21:00 daily (including weekends) and Off-Peak hours are all other hours. Off-Peak prices are approximately $\\$ 0.06017 / \\mathrm{kWh}$ and On-Peak prices from summer and winter seasons were averaged to $\\$ 0.14345 / \\mathrm{kWh}$. Due to the lack of the operational data, the invariable component $R{\\text {value }}$ is assumed to be zero in this paper. In order to reduce the risk of overcharging or overdischarging battery in V2G mode, $S o C{s, \\max }$ and $S o C{s, \\max }$ is defined as $5 \\%$ and $95 \\%$ for all the vehicles, respectively. Since the overall objective is to take full advantage of the energy storage in $\\mathrm{PHEVs} / \\mathrm{PEVs}$, the desired departure $\\mathrm{SOC} S o C{s-d e i r a k}$ is set as a moderate level $50 \\%$ for all the participated vehicles.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:53",
      "generation_style": "practical_application"
    },
    {
      "question": "Considering that several meta-heuristics are applied to telecommunication optimization problems, are there any mentions of Estimation of Distribution Algorithms (EDAs) with specific convergence guarantees or computational complexity analysis in the provided text? If so, what are the key mathematical properties or results?",
      "topics": [
        "optimization"
      ],
      "answer": "The provided text does not mention Estimation of Distribution Algorithms (EDAs). It focuses on heuristic and meta-heuristic algorithms applied to telecommunication optimization problems such as routing and wavelength assignment. Specific meta-heuristics mentioned include genetic algorithms, particle swarm optimization (PSO), artificial immune systems (AIS), ant colony optimization (ACO), and viral systems (VS). The text provides examples of how these algorithms are applied, for instance, an AIS applied to find a set of spanning trees or PSO applied to static and dynamic routing and wavelength problems, but it does not offer mathematical convergence proofs, complexity analyses, or performance guarantees for any algorithm, including EDAs, nor does it provide specifics beyond algorithmic application.",
      "chunk_id": 11490,
      "paper_id": "Two-stage EDA-based approach for all optical WDM mesh network survivability under SRLG constraints",
      "paper_title": "Two-stage EDA-based approach for all optical WDM mesh network survivability under SRLG constraints",
      "paper_year": "2011",
      "chunk_content": "Optimization problems in telecommunication have been extensively studied in the literature from different perspectives. Readers are referred to [37] for details about the problems including planning and design of telecommunication networks, routing, network protection, grooming, restoration, wireless communications, network location and assignment problems, Internet protocol, world wide web, stochastic issues and many others. In this paper, we focused on the application of heuristics/meta-heuristics to the routing and wavelength assignment problem. For a comprehensive review, readers are referred to [6].  \nHeuristic algorithms have been applied for dynamic RWAP considering different objectives, or based on different protection schemes. For examples, Oki et al. [32] proposed a weighted-SRLG selection algorithm (WSRLG) for finding a given number of disjoint  \npaths between the source and destination nodes with the smallest cost. Xiao et al. [41] presented a simple heuristic as well for finding the maximum disjoint paths. Lee et al. [26] developed a hierarchical scheme for handling multiple simultaneous failures under SRLG constraints. In the papers of [42,43], the multiple segment protection scheme is proposed for the SRLG protection. Heuristics have also been proposed for the static RWAP [33,34,38,40,50].  \nAdditionally to these heuristics, many meta-heuristics including genetic algorithms, particle swarm optimization (PSO), artificial immune systems (AIS), ant colony optimization (ACO), and viral systems (VS) and many others have also been applied for the telecommunication optimization problems.  \nThe artificial immune systems, firstly introduced by Farmer et al. [10] have continued being applied to several network problems. For examples, an AIS developed in [4] is applied to find a set of FORMULA_25 Spanning trees; the AIS in [22,25] is applied to the routing problem. The viral system (VS) [7] has been applied to a library of medium-to-large-sized cases of the Steiner problem.  \nParticle swarm optimization (PSO), firstly introduced by Kennedy et al. [9,23], has been applied to the static and dynamic routing and wavelength problems in [17,36] and [15,16,18], respectively. An adaptive PSO has been applied to the RWA [5], a discrete PSO has been applied to the multiple destination routing problem [47]. Branch-and-bound and PSO have been hybridized to the peer-to-peer optimization in large unreliable networks [3]. The multiple constrained QoS multicast routing has been addressed by the PSO as in [21]. Algorithms based on other swarm intelligence including ant colony [8] and bee colony [31] have been applied to the network optimization problems, such as dynamic server allocation problem in Internet hosting centers [31], the RWAP [27], the multicast Routing problem [20], and so on.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:04:55",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "In the context of genetic algorithms and linkage learning, how is the Stochastic Non-negative Matrix Factorization (SNMF) approach used to learn linkage groups in decomposable problems, and what role does the matrix $H$ play in analyzing performance across different generations?",
      "topics": [
        "genetic"
      ],
      "answer": "The Stochastic Non-negative Matrix Factorization (SNMF) approach is applied to learn linkage groups in decomposable problems. The matrix $H$ is analyzed across different generations to observe examples of SNMF performance. Algorithm 1 is then used to identify linkage groups in problems that have overlapping building blocks. The effect of the max $F N$ parameter, which is used in Algorithm 1, is analyzed to determine its impact on the algorithm's performance.",
      "chunk_id": 601,
      "paper_id": "Estimation of distribution algorithm using factor graph and Markov blanket canonical factorization",
      "paper_title": "Estimation of Distribution Algorithm using Factor Graph and Markov Blanket Canonical Factorization",
      "paper_year": "2014",
      "chunk_content": "In this section, we look closely at the SNMF approach by looking at the examples learned by this approach. In subsection 5.1, we see examples of SNMF performance for learning linkage groups in decomposable problems in the context of genetic algorithm and linkage learning. We analyze the matrix $H$ with an example through different generations. In the second subsection, algorithm 1 is used to find the linkage groups in problems with overlapping building blocks to\nsee if the approach is capable of finding the building blocks for additively decomposable problems with overlapping BBs or not. The next subsection is dedicated to the analysis of the effect of the max $F N$ parameter used in algorithm 1 on the performance of the algorithm.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:04:57",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model described, focusing on how heuristic selection probabilities are used?",
      "topics": [
        "search"
      ],
      "answer": "The EDA model uses probabilities associated with low-level heuristics (LH1, LH2, LH3, LH4, LH5, LH6) to guide the search. The probability value of each heuristic is directly proportional to its performance in a given generation. These probabilities are then used to select a low-level heuristic for the next generation. A higher probability value means a greater chance of the heuristic being selected. The selection process incorporates randomness, such as using the RWS (Roulette Wheel Selection) method, so the average probability of a heuristic does not directly determine its average selection frequency.",
      "chunk_id": 8123,
      "paper_id": "An evolutionary algorithm based hyper-heuristic framework for the set packing problem",
      "paper_title": "An evolutionary algorithm based hyper-heuristic framework for the set packing problem",
      "paper_year": "2019",
      "chunk_content": "In this section, we investigate the behavior of the components of the EA-HH approach. In Fig. 4(a), the portions of the probability shared by low-level heuristics LH1, LH2, LH3, LH4, LH5, and LH6 in each generation for instance pb1000rnd07 are plotted. In the figure, the Generation axis represents generations from 1 to 100 and the Probability axis represents the percentage share of the probability by each heuristic in each generation. The probability value of each heuristic is directly proportional to the performance of the particular heuristic in any generation. The probability values help in the selection of a low-level heuristic in the next generation. In the figure, it can be observed that the probability share changes with the generation and this directly affects the heuristic selection rule. The larger its probability value, the greater is the chance of the heuristic being selected in the next generation. The average probability shares of heuristics LH1, LH2, LH3, LH4, LH5, and LH6 are $0.160,0.162,0.160,0.184,0.174$, and 0.159 , respectively.  \nFig. 4(b) shows the distribution of heuristics in each generation. In the figure, the Generation axis represents the generations from 1 to 100 and the Heuristic axis represents the percentage share of frequencies of each heuristic in each generation. The average number of times heuristics LH1, LH2, LH3, LH4, LH5, and LH6 were selected was 242, 240, 255, 265, 281, and 217, respectively. The average number of frequencies of the heuristics shows that the search process is not dependent on any one of the heuristics and each heuristic contributed to the search process.  \nFrom Fig. 4(a) and (b), it can be observed that the $\\%$ frequency of each heuristic in each generation is directly affected by the $\\%$ probability share of each heuristic in the corresponding generation. However, the average probability of the heuristics does not have direct influence on the corresponding average frequency of heuristic. The reason of this is randomness in the RWS method.  \n[IMAGE2]  \nFig. 3. Convergence behavior of the EA-HH approach with different values of $\\beta$ and $\\zeta$ on instance pb1000rnd07.\n[IMAGE_3]\n(a) Changes in probability of heuristics with generations (b) Changes in frequency of heuristics with generations  \nFig. 4. Changes in probability and heuristic frequency with generation on instance pb1000rnd07.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:04:58",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output for a multi-objective optimization problem (MOP) be measured using the concept of Pareto optimality?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The quality of an EDA's output, specifically the local Pareto-optimal set ($\\mathcal{P}^{*}$), is evaluated by how well it represents the true Pareto-optimal set ($\\mathcal{D}^{*}$). The local Pareto-optimal front ($\\mathcal{P} \\mathcal{F}^{*}$), which is the image of $\\mathcal{P}^{*}$ in the objective space, aims to approximate the Pareto-optimal front ($\\mathcal{O}^{*}$). A better EDA will produce a $\\mathcal{P}^{*}$ that is closer to $\\mathcal{D}^{*}$, and consequently, a $\\mathcal{P} \\mathcal{F}^{*}$ that is a better representation of $\\mathcal{O}^{*}$.",
      "chunk_id": 1139,
      "paper_id": "Understanding the Treatment of Outliers in Multi-Objective Estimation of Distribution Algorithms",
      "paper_title": "Understanding the Treatment of Outliers in Multi-Objective Estimation of Distribution Algorithms",
      "paper_year": "2014",
      "chunk_content": "Multi-objective optimization has received lot of attention by the evolutionary computation community leading to multi-objective evolutionary algorithms (MOEAs) (cf. [1). A multi-objective optimization problem (MOP) could be expressed as the problem in which a set of $M$ objective functions $f_{1}(\\boldsymbol{x}), \\ldots, f_{M}(\\boldsymbol{x})$ with should be jointly optimized;  \n$$\n\\min \\boldsymbol{F}(\\boldsymbol{x})=\\left\\langle f_{1}(\\boldsymbol{x}), \\ldots, f_{M}(\\boldsymbol{x})\\right\\rangle ; \\boldsymbol{x} \\in \\mathcal{D}\n$$  \nwhere $\\mathcal{D} \\subseteq \\mathbb{R}^{n}$ is known as the feasible set and could be expressed as a set of restrictions over the decision set, that is usually $\\mathbb{R}^{n}$. The image set of $\\mathcal{D}$  \nproduced by function vector $\\boldsymbol{F}(\\cdot), \\mathcal{O} \\subseteq \\mathbb{R}^{M}$, is called feasible objective set or criterion set.  \nThe solution of (1) is a set of trade-off points. The adequacy of a solution can be expressed in terms of the Pareto dominance relation. The solution of (1) is the Pareto-optimal set, $\\mathcal{D}^{*}$; which is the subset of $\\mathcal{D}$ that contains all elements of $\\mathcal{D}$ that are not dominated by other elements of $\\mathcal{D}$. Its image in objective space is called Pareto-optimal front, $\\mathcal{O}^{*}$.  \nIf an MOP has certain characteristics, e. g., linearity or convexity of the objective functions or convexity of $\\mathcal{S}$, the efficient set can be determined by mathematical programming approaches [8. However, in the general case, finding the solution of (1) is an $N P$-complete problem. In this case, heuristic or metaheuristic methods can be applied in order to have solutions of practical value at an admissible computational cost.  \nGenerally, an heuristic algorithm solving an MOP yields a discrete local Pareto-optimal set, $\\mathcal{P}^{*}$, that attempts to represent $\\mathcal{S}^{*}$ as best as possible, although, in the general case, optimality can not be guarantied. The image of $\\mathcal{P}^{*}$ in objective space, $\\mathcal{P} \\mathcal{F}^{*}$, is known as the local Pareto-optimal front.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:01",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when utilizing Probabilistic Model Building Genetic Network Programming (PMBGNP) for intelligent agent control?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary purpose of PMBGNP, a graph-based EDA, is to estimate the probability distribution of graph structures to solve intelligent agent control problems, differentiating it from conventional EDAs that focus on bit-string or tree structures. PMBGNP leverages Genetic Network Programming (GNP) as its base model and has been extended to Reinforced PMBGNP (RPMBGNP), which uses reinforcement learning to estimate the probability distribution of directed graphs, improving evolution efficiency for decision-making rules.",
      "chunk_id": 486,
      "paper_id": "Creating stock trading rules using graph-based estimation of distribution algorithm",
      "paper_title": "Creating Stock Trading Rules Using Graph-Based Estimation of Distribution Algorithm",
      "paper_year": "2014",
      "chunk_content": "In recent years, there has been a significant development of Estimation of Distribution Algorithm (EDA) [1], [2], [3], [4]. Different from the traditional evolutionary computation (EC) techniques which simulate the biological evolution for generating the new population stochastically, EDA focuses on building a probabilistic model from the perspective of machine learning (ML). The probabilistic model estimates the probability distribution of the current population, and is used to sample the new population. Currently, it has been demonstrated that EDA is capable of realizing significant speed-up of evolution efficiency comparing with traditional EC techniques when applying to solve many problems, i.e., function optimization [5], [6], bioinformatics [7], [8], multiobjective optimization [9], [10], scheduling [11], dynamic problems [12], continuous optimization [13], [14], program generation [15], [16], [17], [18], [19], information retrieval [20], etc.  \nRecently, a new type of EDA techniques called probabilistic model building genetic network programming (PMBGNP) [21], [22], [23] has been developed. Different from the existing EDA techniques which apply the concept of probabilistic modeling into bit-string structure based GA [24] and tree structure based GP [25], PMBGNP is dedicated to estimate the probability distribution of a more complex solution structure graph structure. Accordingly, it can be viewed as a graph-based EDA. PMBGNP applies a recent proposed EC technique, i.e., genetic network programming (GNP) [26], [27], [28], as the base model to construct its individuals. Following the research directions of EDA, the univariate [22], pairwise [29] and continuous PMBGNP [30] were proposed previously, which have also been studied in both theory [31] and applications [32], [33]. Different from the conventional EDA techniques,  \nPMBGNP is dedicated to solve a different sort of problems, that is, the intelligent agent control. In the previous research, it has been successfully applied to the benchmark problems [23] of the intelligent agent control, as well as the real mobile robot control [34], [35], where its superiority has been demonstrated in comparison with the traditional state-of-the-art techniques.  \nBeyond the much success of EDA in the past studies, it has been reported and accepted that one of its most important challenges is to explore its applications to solve wider range of problems [36], especially its real-world practical usage. Particularly, there have been numerous studies in applying the soft computing techniques to the stock trading task, such as GA [37], GP [38], [39], GNP [40], neural network (NN) [41], etc., which soon becomes one of the most active research problems. However, this problem has been rarely addressed in the EDA literature, where a gap remains to be filled.  \nIn this paper, we are dedicating to develop an EDAbased stock trading model using PMBGNP. Particularly, an advanced version of PMBGNP called Reinforced PMBGNP (RPMBGNP) [23], [42] is utilized as the base technique to efficiently evolve the stock trading rules. RPMBGNP developed a reinforcement learning (RL)-based probabilistic modeling approach to estimate the probability distribution of its directed graphs, which showed efficient evolution ability for generating compact programs with decision-making rules.  \nThe fundamental basis of the proposed model arises from that when developing an intelligent trading system, a large number of technical indices should be considered to track the movement of the real stock market which sometimes causes the dramatic expansion of the search space. However, due to its efficient scalability and evolution ability under large search space, EDA may provide significant improvement of evolution efficiency when comparing with standard EC techniques.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:03",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the updating of the $G_{EHM}$ matrix in the context of the Execution time based Heuristic Model (EHM), and how does it differ from the updating of $G_{NHM}$?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The $G_{EHM}$ matrix, used in the Execution time based Heuristic Model, is updated using the formula $G_{EHM}(i, j)=\\left(1-\\mu_{c}\\right) \\cdot G_{EHM}(i, j)+\\mu_{c} \\cdot K_{2} \\cdot \\frac{F_{c}(i, j)}{D(i, j) \\cdot N_{b}}$, where $\\mu_{c} \\in(0,1)$ is the learning rate, $K_{2}$ is a constant coefficient, $F_{c}(i, j)$ is an element of the frequency matrix $F_{c}$, $D(i,j)$ is not defined in the text, and $N_{b}$ is also not defined in the text. The frequency matrix $F_{c}$ is calculated as $F_{c}(i, j)=\\sum_{k=1}^{N_{c}}\\left\\{I_{c}^{k}(i, j)\\left(1+\\Delta F_{c}(i, j)\\right)+I_{c}^{k}(j, i)\\left(1-\\Delta F_{c}(j, i)\\right)\\right\\}$, where $I_{c}^{k}(i, j)$ is an indicator function that equals 1 if task $i$ is before task $j$ in the $k$-th individual in $Z_{k}$, and 0 otherwise. $\\Delta F_{c}(i, j)$ is an offset calculated as $\\Delta F_{c}(i, j)=\\frac{K_{1} \\cdot \\alpha_{j}}{\\beta \\cdot V}$, where $K_{1}$ is a constant coefficient. In contrast, the $G_{NHM}$ matrix is updated using the formula $G_{\\text {NHM }}(i, j)=\\left(1-\\mu_{n}\\right) \\cdot G_{\\text {NHM }}(i, j)+\\mu_{n} \\cdot \\frac{F_{n}(i, j)}{N_{k}}$, where $\\mu_{n} \\in(0,1)$ is the learning rate, and $F_{n}(i, j)$ is an element of the frequency matrix $F_{n}$. The frequency matrix $F_{n}$ is calculated as $F_{n}(i, j)=\\sum_{k=1}^{n} I_{n}^{k}(i, j)$, where $I_{n}^{k}(i, j)$ is an indicator function that equals 1 if task $i$ is the $j$-th task finished in the $k$-th individual in $Z_{b}$, and 0 otherwise. The key difference lies in the inclusion of the offset $\\Delta F_{c}(i, j)$ in the $G_{EHM}$ update, which accounts for the asymmetry introduced by execution time, as well as the $D(i,j)$ term.",
      "chunk_id": 11313,
      "paper_id": "A Multi-Model Estimation of Distribution Algorithm for Agent Routing Problem in Multi-Point Dynamic Task",
      "paper_title": "A Multi-model Estimation of Distribution Algorithm for Agent Routing Problem in Multi-point Dynamic Task",
      "paper_year": "2018",
      "chunk_content": "It is necessary to introduce $F_{n}$ as the frequency matrix to save frequency data of $Z_{b} . F_{n}$ can be initialized as follows:  \n$$\nF_{n}=\\left[F_{n}(i, j)\\right]_{\\text {min }}=\\left[\\begin{array}{cccc}\n0 & 0 & \\cdots & 0 \\\\\n0 & 0 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 0\n\\end{array}\\right]\n$$  \nThen, $I_{n}^{k}(i, j)$ is the indicator function corresponding to the $k$-th individual in $Z_{b}$ :  \n$$\nI_{n}^{k}(i, j)=\\left\\{\\begin{array}{l}\n1, \\text { if task } i \\text { is the } j \\text {-th task finished in } k \\text {-th individual in } Z_{b} \\\\\n0, \\text { otherwise. }\n\\end{array}\\right.\n$$  \nThe procedure of statistics is showed in (17):  \n$$\nF_{n}(i, j)=\\sum_{k=1}^{n} I_{n}^{k}(i, j)\n$$  \nThe formula of updating $G_{\\text {NHM }}$ is as follows:  \n$$\nG_{\\text {NHM }}(i, j)=\\left(1-\\mu_{n}\\right) \\cdot G_{\\text {NHM }}(i, j)+\\mu_{n} \\cdot \\frac{F_{n}(i, j)}{N_{k}}\n$$  \nwhere $\\mu_{n} \\in(0,1)$ denotes the learning rate and $i, j=1,2, \\ldots, n$.\nThe access sequence of each individual is obtained by the roulette wheel. The procedure of generating a new individual based on $G_{\\text {NHM }}$ is as follows:  \nStep 1: Set $i=1$;\nStep 2: Select task point $k$ according to the elements in the line $i$ of $G_{\\text {NHM }}$ by the roulette wheel. Let $\\mathbf{z}(i)=k$;  \nStep 3: Set all the elements of the column $k$ in $G_{\\text {NHM }}$ to zero;  \nStep 4: Let $i=i+1$ and repeat Steps 2 and 3 until all of the task points are selected.\n1) Initialization  \nIn this case, the traveling time dominates the total time and EHM suits this case. $G_{\\text {EHM }}$ can be initialized as follows:  \n$$\nG_{E H M}=\\left[G_{E H M}(i, j) \\|_{a=0}=\\left[\\begin{array}{cccc}\n0 & 1 & \\cdots & 1 \\\\\n1 & 0 & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & 0 & 1 \\\\\n1 & \\cdots & 1 & 0\n\\end{array}\\right]\\right.\n$$\nIntroduce $F_{c}$ as the frequency matrix to save frequency information of $Z_{k}, F_{c}$ can be initialized as follows:  \n$$\nF_{c}=\\left[F_{c}(i, j) \\|_{a=0}=\\left[\\begin{array}{cccc}\n0 & 0 & \\cdots & 0 \\\\\n0 & 0 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 0\n\\end{array}\\right]\\right.\n$$  \nThen, $I_{c}^{k}(i, j)$ is the indicator function corresponding to the $k$-th individual in $Z_{k}$ :  \n$$\nI_{c}^{k}(i, j)=\\left\\{\\begin{array}{l}\n1, \\text { if task } i \\text { is before task } j \\text { in } k \\text {-th individual in } Z_{k} \\\\\n0, \\text { otherwise. }\n\\end{array}\\right.\n$$  \nBecause of the effect of the execution time, ARP-MPDT is no longer a symmetric routing problem. It is necessary to make an adaptable change in the updating strategy. Then, an offset is introduced as follows:  \n$$\n\\Delta F_{c}(i, j)=\\frac{K_{1} \\cdot \\alpha_{j}}{\\beta \\cdot V}\n$$  \nwhere $\\Delta F_{c}(i, j) \\in[0,1)$ is an offset related to partial elements of the problem, and $K_{1}$ is a constant coefficient to ensure that $\\Delta F_{c}(i, j) \\in[0,1)$.  \nThe procedure of statistics is showed in (23):  \n$$\nF_{c}(i, j)=\\sum_{k=1}^{N_{c}}\\left\\{I_{c}^{k}(i, j)\\left(1+\\Delta F_{c}(i, j)\\right)+I_{c}^{k}(j, i)\\left(1-\\Delta F_{c}(j, i)\\right)\\right\\}\n$$  \nThe formula of updating $G_{E H M}$ is as follows:  \n$$\nG_{E H M}(i, j)=\\left(1-\\mu_{c}\\right) \\cdot G_{E H M}(i, j)+\\mu_{c} \\cdot K_{2} \\cdot \\frac{F_{c}(i, j)}{D(i, j) \\cdot N_{b}}\n$$  \nwhere $\\mu_{c} \\in(0,1)$ denotes the learning rate; $K_{2}$ is a constant coefficient to offset the influence of the order of magnitude of $D(i, j)$ and FORMULA_101.",
      "question_type": "algorithmic mechanism",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:07",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using LSTM for time-series prediction, how should practitioners calculate the cell state $c_{t}$ at time $t$, and what role do the forget gate $f_{t}$ and input gate $i_{t}$ play in this calculation?",
      "topics": [
        "control"
      ],
      "answer": "To calculate the cell state $c_{t}$ in an LSTM-based EDA at time $t$, practitioners should use the formula $c_{t}=f_{t} \\cdot c_{t-1}+i_{t} \\cdot \\tanh (W_{c} \\cdot [h_{t-1}, x_{t}]+b_{c})$. Here, the forget gate $f_{t}$ determines how much of the previous cell state $c_{t-1}$ is retained, while the input gate $i_{t}$ regulates the entry of new information, modulated by the $\\tanh$ function, into the cell state. $W_{c}$ and $b_{c}$ represent the weight parameters and bias term, respectively, and $x_{t}$ is the input at time $t$, $h_{t-1}$ is hidden state at time $t-1$.",
      "chunk_id": 2376,
      "paper_id": "A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification",
      "paper_title": "A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification",
      "paper_year": "2022",
      "chunk_content": "LSTM has been widely used in sequence modeling problems because it can capture and maintain important features over a long range of sequences. A basic LSTM unit (Hochreiter and Schmidhuber, 1997) consists of a cell state and three gates. The cell state is used to convey information throughout the timeline, while three gates are used to control the amount of information. Specifically, the forget gate is used to determine whether the input information enters the cell state, the input gate is used to adjust the entry of new information into the cell, and the output gate calculates the output of the LSTM unit. Eqs. (1)-(4)  \n[IMAGE1]  \nFig. 2. Architecture of the residual convolutional network.\n[IMAGE2]  \nFig. 3. RNN-based time-series module.\nsummarize the calculation of forget gate $f_{t}$, input gate $i_{t}$, output gate $o_{t}$, and cell state $c_{t}$ in a basic LSTM unit:\n$f_{t}=\\sigma\\left(W_{f} \\cdot\\left[h_{t-1}, x_{t}\\right]+b_{f}\\right)$\n$i_{t}=\\sigma\\left(W_{i} \\cdot\\left[h_{t-1}, x_{t}\\right]+b_{i}\\right)$\n$o_{t}=\\sigma\\left(W_{o} \\cdot\\left[h_{t-1}, x_{t}\\right]+b_{o}\\right)$\n$c_{t}=f_{t} \\cdot c_{t-1}+i_{t} \\cdot \\tanh \\left(W_{c} \\cdot\\left[h_{t-1}, x_{t}\\right]+b_{c}\\right)$\nwhere $x_{t}$ is the input at time $t, h_{t-1}$ is hidden state at time $t-1 . W_{o}$ and $b_{o}$ represent the weight parameters and bias term of each gate $\\alpha$. And $\\sigma$ is the sigmoid activation function, $c_{t-1}$ and $c_{t}$ are the cell state at time $t-1$ and time $t, \\tanh (\\cdot)$ is the arctangent function. The output hidden state $h_{t}$ of current LSTM unit can be computed as $h_{t}=o_{t} \\cdot \\tanh \\left(c_{t}\\right)$.\nIn AHM, spatially varying parameter fields, such as permeability, need to be adjusted by observed data $d_{\\text {obs }} \\in R^{T \\times \\text { hd }}$, such as OPR and WPR of different production wells. It is necessary to input the estimating parameter fields into the numerical simulator to obtain the corresponding production data $\\chi^{\\text {sim }} \\in R^{T \\times \\text { hd }}$, which is usually a computationally time-consuming process. Therefore, we propose the HRCN surrogate model to approximate this process:\n$F: R^{H \\times W \\times N_{k}} \\rightarrow R^{T \\times N d}$\nwhere $H \\times W$ is the spatial discretization resolution, $N_{k}$ is the number of the parameter fields, $T$ is the number of time-step of production data, and FORMULA_37 is the number of measurement types.  \nAs shown in Fig. 1, the proposed HRCN surrogate model consists of a spatial feature extraction module and a time series prediction module. In the following, we describe the proposed model in detail.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:09",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Gaussian estimation of distribution algorithm (EDA) used within the offline learning co-evolutionary algorithm (OLCA), what specific properties of the fitness landscape, as learned by the random forest, influence the selection and application of this EDA strategy for complex continuous real-valued problems?",
      "topics": [
        "optimization"
      ],
      "answer": "The offline learning co-evolutionary algorithm (OLCA) uses a random forest to establish a relationship between strategies and fitness landscapes. Before the evolutionary process begins, the random forest trains on the fitness landscape's properties, and the OLCA determines a suitable strategy, such as the Gaussian estimation of distribution algorithm (EDA), based on these learned properties. The specific properties of the fitness landscape that influence the selection of the Gaussian EDA are not explicitly detailed, but the algorithm uses the learned landscape characteristics to enhance the search ability of the EDA for complex continuous real-valued problems.",
      "chunk_id": 1821,
      "paper_id": "An offline learning co-evolutionary algorithm with problem-specific knowledge",
      "paper_title": "An offline learning co-evolutionary algorithm with problem-specific knowledge",
      "paper_year": "2022",
      "chunk_content": "Fuqing Zhao ${ }^{\\mathrm{a}, *}$, Bo Zhu ${ }^{\\mathrm{a}}$, Ling Wang ${ }^{\\mathrm{b}}$, Tianpeng Xu ${ }^{\\mathrm{a}}$, Ningning Zhu ${ }^{\\mathrm{a}}$, Jonrinaldi Jonrinaldi ${ }^{\\mathrm{c}}$${ }^{a}$ School of Computer and Communication, Lanzhou University of Technology, Lanzhou 730050, China${ }^{\\mathrm{b}}$ Department of Automation, Tsinghua University, Beijing 10084, ChinaFORMULA_8 Department of Industrial Engineering, Universitas Andalas, Padang 25163, Indonesia\nKeywords:\nFitness landscape\nRandom forest\nOffline-learning\nEstimation of distribution\nDifferential evolution\nThe meta-heuristics is an effective way to solve the complex optimization problems. However, the applicability of meta-heuristic is restricted in real applications due to the various characteristics of the corresponding problems. An offline learning co-evolutionary algorithm (OLCA) based on the fitness landscape analysis that introduces the Gaussian estimation of distribution algorithm (EDA) and a variant of differential evolution (DE) for enhancing the search ability, is proposed for complex continuous real-valued problems. The relationship between strategies and fitness landscapes is established by using offline learning of a random forest. The suitable strategy is determined based on the properties of the fitness landscape trained by a random forest before the beginning of the evolutionary process. The proposed OLCA is tested by using the CEC 2017 benchmark test suite and is compared with several state-of-the-art algorithms. The results show that the proposed OLCA is efficient and competitive for solving complex continuous optimization problems. In addition, the effectiveness of the proposed OLCA is also verified by using 19 IEEE CEC 2011 benchmark problems for tackling real-world problems.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:11",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the AFHH algorithm compare to the FHH algorithm in the context of path planning, given the specified parameter settings?",
      "topics": [
        "performance"
      ],
      "answer": "Both AFHH and FHH algorithms are used for path planning with a bin size $K$ set to 50 and $S$ set to 100. The performance comparison is based on using the same maximum function evaluations (FEs) of 5000000 and a population size of 200 across 30 independent runs. The algorithms were executed on a PC with an Intel Core i7 processor running at 3.6 GHz with 8 GB of RAM.",
      "chunk_id": 10791,
      "paper_id": "Estimation of Distribution Algorithm for Autonomous Underwater Vehicles Path Planning",
      "paper_title": "Estimation of Distribution Algorithm for Autonomous Underwater Vehicles Path Planning",
      "paper_year": "2018",
      "chunk_content": "The real underwater environment is simulated like the ones in Fig. 4. The area is 20 m long, 40 m width and 20 m depth. Four scenarios are used to measure AFHH's performance. AFHH, FHH, PSO, enhance differential evolution with random walk (RWDE) [12], and ADE [7] are used to make a comparison of their ability on path planning [7]. For the FHH and AFHH algorithms, bins size $K$ is set as 50 , and $S$ is set as 100. The PSO is a conventional global topology PSO variant, whose $w$ is set as 0.5 . $c_{1}$ and $c_{2}$ are both set as 2.0. For the RWDE algorithm, two pairs of fixed parameters are used $(F=0.5, C R=0.1 ; F=0.1, C R=0.5)$. All algorithms use the same maximum function evaluations (FEs) 5000000, and the same population's size 200. All results are got after 30 times independently run. All algorithms are implemented on a PC with Intel core i7 processor running 3.6 GHz , RAM of 8 GB .  \n  \nFig. 3. Procedure of the proposed AFHH algorithm for path planning\n[IMAGE2]\n(a) Scenario 1\n[IMAGE3]\n(b) Scenario 2\n[IMAGE4]\n(c) Scenario 3\n[IMAGE_5]\n(d) Scenario 4  \nFig. 4. The 3-D static environment models we simulate.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:13",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing KEDA (Knowledge-guided Estimation of Distribution Algorithm) and comparing its performance against NSGA-II and MOEA/D, what specific metric is used to quantify the dominance relationship between the solutions generated by these algorithms, and how is this metric calculated?",
      "topics": [
        "genetic"
      ],
      "answer": "The 'C' metric is used to quantify the dominance relationship between the solutions generated by KEDA, NSGA-II, and MOEA/D. Specifically, C(A,B) represents the proportion of solutions in set B that are dominated by at least one solution in set A. For example, C(KEDA, NSGA-II) represents the proportion of NSGA-II solutions dominated by KEDA solutions. The values $C_{L, n}$ and $C_{n, k}$ are used as simplifications for C(KEDA,NAGAII) and C(NAGA-II,KEDA) respectively. Similarly, $C_{\\mathrm{L}, m}$ and $C_{m, k}$ represent C(KEDA, MOEA/D) and C(MOEA/D, KEDA).",
      "chunk_id": 2435,
      "paper_id": "A knowledge-guided Estimation of Distribution Algorithm for energy-efficient Joint Robotic Assembly Line Balancing and Feeding Problem",
      "paper_title": "A knowledge-guided Estimation of Distribution Algorithm for energy-efficient Joint Robotic Assembly Line Balancing and Feeding Problem",
      "paper_year": "2024",
      "chunk_content": "In this section, two commonly used multi-objective optimization algorithms: A Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) [39] and Non-dominated Sorting Genetic AlgorithmII (NSGA-II) [40], are adopted as the comparison algorithms to verify the effectiveness of KEDA in solving the energy efficient JRALB-FP. For  \nTable 9\nComparison results of $C$ metric between KEDA and A3.\n[IMAGE9]  \nFig. 10. Boxplot of $C$ metric between KEDA and A3.\neach case, the average $C$ metric of ten independent runs is summarized in Tables 10 and 11. The boxplots of the comparison between all $C$ metrics of KEDA and the comparison algorithm are shown in Figs. 11 and 12. The T-hypothesis test with a $95 \\%$ confidence level is carried out, setting alternative hypothesis H1 such that the $C$ metric achieved by KEDA is greater than the $C$ metric achieved by the comparison algorithms. If H1 is implemented significantly ( $p<0.05$ ), then the flag is labeled as Y, otherwise it is labeled as N. C metric C(KEDA,NAGAII) and C(NAGA-II,KEDA) are denoted as $C_{L, n}$ and $C_{n, k}$ respectively for simplification in the tables. C(KEDA, MOEA/D) and C(MOEA/D, KEDA) are denoted as $C_{\\mathrm{L}, m}$ and $C_{m, k}$.  \nIn addition, the IGD of the proposed algorithm and two comparative algorithms, and presented them in the Table 12. The true Pareto front is composed of the common Pareto front obtained by all algorithms. KEDA, NSGA-II and MOEA/D are denoted as $A k, A n$ and $A m$ respectively for simplification. The Pareto fronts obtained by KEDA, NSGA-II, and MOEA/D are illustrated in Figs. 13-16.  \nIt can be seen from the results that C(KEDA, NSGA-II) are larger than C(NSGA-II, KEDA) in most cases, which implies that KEDA performs better than NSGA-II in solving this problem. The average value of C(KEDA, NSGA-II) is 0.770 and the average value of C(NSGA-II, KEDA) is 0.066 , which implies that about $77.0 \\%$ NSGA-II solutions are dominated by the KEDA solutions, while about $6.6 \\%$ KEDA solutions are dominated by NSGA-II solutions.\n[IMAGE10]  \nFig. 11. Boxplot of $C$ metric for KEDA and NSGA-II.\n[IMAGE11]  \nFig. 12. Boxplot of $C$ metric for KEDA and MOEA/D.  \nSimilarly, it can be seen from the results that C(KEDA, MOEA/D) are larger than C(MOEA/D), KEDA) in most cases, which implies that KEDA performs better than MOEA/D in solving this problem. The average value of C(KEDA, NSGA-II) is 0.881 and the average value of C(NSGAII, KEDA) is 0.002 . About $88.1 \\%$ MOEA/D solutions are dominated by the KEDA solutions, while about FORMULA_485 KEDA solutions are dominated  \nTable 10",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:15",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model in achieving convergence, spread, and uniformity of solutions in the Pareto front, and how are these metrics calculated?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The effectiveness of the EDA model is evaluated using three metrics: Inverted Generation Distance, Convergence Metric, and Spacing. Inverted Generation Distance, denoted as D(P*, P), measures both convergence and spread by calculating the average minimum Euclidean distance between points in a uniformly distributed set P* along the Pareto front (PF) and the points in the approximation P. The Convergence Metric, denoted as Y(P, P*), estimates the distance of nondominated solutions from the Pareto-optimal set by computing the average minimum Euclidean distance between points in P and points in P*. Spacing assesses the uniformity of the Pareto-optimal solutions obtained by the EDA, although the specific calculation for the spacing metric is not provided.",
      "chunk_id": 440,
      "paper_id": "Multiobjective Memetic Estimation of Distribution Algorithm Based on an Incremental Tournament Local Searcher",
      "paper_title": "Multiobjective Memetic Estimation of Distribution Algorithm Based on an Incremental Tournament Local Searcher",
      "paper_year": "2014",
      "chunk_content": "6.1. Test Problems. The first five ZDT problems were developed by Zitzler et al. [36] (so called ZDT problems), and the next five DTLZ problems were defined by Deb et al. [37] (so called DTLZ problems). These problems have been cited in a number of significant past studies in EMO community and they can test evolutionary multiobjective optimization algorithms in different aspects. Furthermore, ten problems with variable linkages proposed by Zhang et al. [14] have also been introduced in our paper, which can bring trouble to most of variable-wise EMO methodology, and have been validated by Zhang et al. Lastly, two more difficult problems proposed by ourselves are also presented in Table 1.  \nIt is necessary to note that the performance of an MOEA in tackling multiobjective constrained optimization problems may largely depend on the constraint-handling technique used [38], so we do not mention side-constrained problems in this study.\n6.2. Performance Metrics. Zitzler et al. [39] suggested that for a $k$-objective optimization problem, at least $k$ performances are needed to compare two or more solutions and an infinite number of metrics to compare two or more sets of solutions.  \nTable 1: Test instances.\nTable I: Continued.\nCoello Coello et al. [8] proposed three issues to allow a quantitative assessment of the performance of a multiobjective optimization algorithm. As we know, it is a common task for any multiobjective optimization algorithm to find solutions as close as possible to the Pareto front and to make them as diverse as possible in the obtained nondominated front. Furthermore, the latter case includes maximizing the spread and the uniformity of solutions found in the final Pareto front. For this end, three metrics are employed in our paper to investigate the performance of the algorithm. As [14], we apply inverted generation distance to the final Paretooptimal set obtained by an MOEA to evaluate its convergence and spread performance. We also adopt convergence metric proposed by Deb et al. [6] to measure the convergence to the final solutions. Finally, in order to check the uniformity of Pareto-optimal solutions we get in final generation and spacing devised by Schott [40] metric is employed in our paper. The three metrics are summarized as follows.\n6.2.1. Inverted Generation Distance. Let $P^{*}$ be a set of uniformly distributed points in the objective space along the PF. Let $P$ be an approximation to the PF; the inverted generational distance from $P^{*}$ to $P$ is defined as  \n$$\nD\\left(P^{*}, P\\right)=\\frac{\\sum_{v \\in P^{*}} d(v, P)}{\\left|P^{*}\\right|}\n$$  \nwhere $d(v, P)$ is the minimum Euclidean distance between $v$ and the points in $P$. The inverted generation distance denotes the metric convergence and spread, which represents the distance between the set of the true Pareto-optimal fronts and converged Pareto solutions obtained by EMOAs.\n6.2.2. Convergence Metric. Metric $Y$ is used to estimate how far the elements in the set of nondominated solutions found so far are from those in the Pareto-optimal set, and it is defined as  \n$$\nY\\left(P, P^{*}\\right)=\\frac{\\sum_{v \\in P} d\\left(v, P^{*}\\right)}{|P|}\n$$  \nwhere $d\\left(v, P^{*}\\right)$ is the minimum Euclidean distance between $v$ and the points in $P^{*}$. Since multiobjective algorithms can be tested on problems having a known set of Pareto-optimal solutions, the calculation of the two metrics is possible.\n6.2.3. Spacing. Let $P$ be the final approximate Pareto-optimal set obtained by an MOEA. The function FORMULA_169 is as follows:",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:17",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the Forced Improvement (FI) procedure within the context of Estimation of Distribution Algorithms (EDAs) like GOMEA?",
      "topics": [
        "benchmarks"
      ],
      "answer": "The primary objective of the Forced Improvement (FI) procedure is to overcome situations where GOMEA cannot improve the current parent solution or when it oscillates between solutions with the same fitness value due to plateaus. FI uses the best-found-so-far solution as the donor and only accepts mixing events that result in strict fitness improvement, terminating as soon as such an improvement is found. If FI fails, it returns the best-found-so-far solution as the new offspring.",
      "chunk_id": 11343,
      "paper_id": "Exploiting Linkage Information and Problem-Specific Knowledge in Evolutionary Distribution Network Expansion Planning",
      "paper_title": "Exploiting Linkage Information and Problem-Specific Knowledge in Evolutionary Distribution Network Expansion Planning",
      "paper_year": "2018",
      "chunk_content": "variables indicated the linkage set differ from those in $\\boldsymbol{o}$ in at least one position, these values are copied from $\\boldsymbol{d}$ into $\\boldsymbol{o}$. This partially-altered solution $\\boldsymbol{o}$ is evaluated and compared against its backup $\\boldsymbol{b}$. If $\\boldsymbol{o}$ is equally good or better than $\\boldsymbol{b}$ (i.e. fitness $|\\boldsymbol{o}| \\geq$ fitness $|\\boldsymbol{b}|$ ), the changes are accepted (i.e. the values copied from $\\boldsymbol{d}$ ) and updated into $\\boldsymbol{b}$ as well. Otherwise, the changes are undone and $\\boldsymbol{o}$ reverts to its backup state $\\boldsymbol{b}$. Note that the acceptance of solutions having equal fitness can be beneficial to move across a fitness plateau [2]. It can be seen that each linkage set corresponds with a mixing event, in which the current solution is recombined with a random donor solution and the variables in the same linkage set are treated together, preserving the BB structure. When we traverse the whole LT, an offspring $\\boldsymbol{o}$ is then fully constructed, replacing the original parent $\\boldsymbol{p}$ in the next generation.  \nIt can happen that GOM cannot improve the current parent solution $\\boldsymbol{p}$ into a new offspring or that, because of a significant plateau, GOM keeps transforming back and forth solutions of different genotypes but with the same fitness value. To overcome this, if GOM cannot yield a new offspring or when the number of subsequent generations that the best-found-so-far solution $\\boldsymbol{x}^{\\text {best }}$ does not change, i.e. the no-improvement stretch (NIS), exceeds a certain threshold, we invoke the Forced Improvement (FI [2]) procedure. In essence, FI is similar to GOM but we always use $\\boldsymbol{x}^{\\text {best }}$ as the only donor solution. FI only accepts the mixing event that results in a strict improvement (i.e. fitness $|\\boldsymbol{o}|>$ fitness $|\\boldsymbol{b}|$ ) and FI stops as soon as such mixing event is found. Previous research [2] on GOMEA suggest a threshold for NIS of $1+\\left\\lfloor\\log _{10}(n)\\right\\rfloor$. If FI does not succeed in evolving $\\boldsymbol{p}, \\boldsymbol{x}^{\\text {best }}$ is returned as the new offspring.\nSetting the population size parameter in real-world applications of EAs is hard because a suitable population size setting depends on the structure of the problem instance at hand and also on the specific EA being used. DNEP practitioners often need to experiment with different population sizes. Here, we adapt a population sizing-free scheme, proposed and tested on academic benchmarks in [7]. In essence, we run multiple instances of the EA in parallel. Each instance has a different population size but larger populations have a slower generational cycle. We start with the first population $P_{1}$ of some small size $n_{1}$. Then, by doubling the population size, the next population $P_{i}$ is twice as large as the previous one, i.e. $n_{i}=2 n_{i-1}$ for $i>1$. All the populations are scheduled with the principle that for every 2 generations of population $P_{i}, 1$ generation of population FORMULA_134 is run (or initialized if it does not exist yet). A population is terminated when it converges, i.e., all solutions in that population have the same fitness value. Having no maximum population size, the EA runs and grows its populations until the computing time budget is used up.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:19",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms (EDAs) for protein folding, how does the algorithmic mechanism of using probability distributions contribute to outperforming previous evolutionary optimization methods, specifically in the simplified protein folding models mentioned?",
      "topics": [
        "analysis"
      ],
      "answer": "Estimation of Distribution Algorithms (EDAs) utilize probability distributions to guide the search for solutions. In the context of protein folding models, the algorithm builds and samples from a probability distribution that represents the likelihood of different protein conformations. By learning and exploiting the structure of promising solutions encoded in the probability distribution, the EDA can effectively explore the search space and outperform previous evolutionary optimization methods for difficult instances of the models.",
      "chunk_id": 13239,
      "paper_id": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_title": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_year": "2004",
      "chunk_content": "Roberto Santana, Pedro Larranaga, and Jose A. LozanoIntelligent System GroupDepartment of Computer Science and Artificial IntelligenceUniversity of the Basque CountryP.O. Box 649, 20080 San Sebastian - Donostia, Spain\\{rsantana, ccplamup, lozano\\}@si.ehu.es\nThis paper introduces a new type of evolutionary computation algorithm based on probability distributions for the solution of two simplified protein folding models. The relationship of the introduced algorithm with previous evolutionary methods used for protein folding is discussed. A number of experiments for difficult instances of the models under analysis is presented. For the instances considered, the algorithm is shown to outperform previous evolutionary optimization methods.  \nKeywords: Estimation of Distribution Algorithms, protein folding, HP model.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:21",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within the intelligent multi-restart memetic framework described, how should practitioners determine when to apply the derivative-free optimisation algorithm NEWUOA to improve the current best solution?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "Practitioners should apply the NEWUOA algorithm when the current search, within the EDA framework, fails to find a better solution in some consecutive generations. The specific number of consecutive generations without improvement that triggers the application of NEWUOA is not explicitly defined, but should be configured empirically based on the characteristics of the optimisation problem.",
      "chunk_id": 56,
      "paper_id": "An Intelligent Multi-Restart Memetic Algorithm for Box Constrained Global Optimisation",
      "paper_title": "An Intelligent Multi-Restart Memetic Algorithm for Box Constrained Global Optimisation",
      "paper_year": "2013",
      "chunk_content": "In this paper, we have studied the application of a memetic algorithm to continuous optimisation problems, and proposed an intelligent multi-restart memetic framework. We developed an EDA-like algorithm based on the proposed framework. In the implementation, an adaptive multivariate model is constructed and used to sample offspring. To replace a solution, we sample more than one solution from the probability model,  \nand pick the best of these to replace the current one. A derivative-free optimisation algorithm, NEWUOA, is applied to improve the current best solution when the current search cannot find a better solution in some consecutive generations. When the stop criterion has not been met, we restart the search. Hence, the new search will be carried out intelligently by incorporating the history information of previous searches. Experiments on some commonly used benchmark global optimisation problems showed that the proposed algorithm is very competitive with the best known EAs, including the winner of the CEC 2005 competition, and significantly better than other EAs.  \nIn summary, we believe that the developed algorithm, based on our new framework, achieves highly competitive results (in terms of the solution quality) across a wide range of functions of various dimensions. Often it does this by using fewer fitness evaluations than other competitive algorithms. We also believe that the framework is relatively simple and flexible. Hence, we believe that this framework is a significant contribution, worthy of future study.  \nMoreover, we intend to explore four interesting avenues of research. The first avenue will be to examine the use of the niching technique (De Jong, 1975) to help the search escape from local optima and hence make the diversification more intelligent. The second avenue will be to apply the developed framework to a range of problems in combinatorial optimisation. The third avenue will be to modify the framework to accommodate the search for multiple optimum solutions in multi-modal optimisation problems. The fourth avenue will be to investigate a completely adaptive intelligent multi-restart algorithm, based on the proposed framework, to save manpower in practice.\nThis work was supported by BBSRC and EPSRC through grants BB/D019613/1 (The Centre for Plant Integrative Biology), EP/H010432/1 and EP/J004111/1.\nTable A1 lists the benchmark functions used in our study. Functions $f_{1}$ through $f_{25}$ are the same functions as $F_{1}$ through $F_{25}$ defined in Suganthan et al. (2005), respectively.  \nTable A1: The basic characteristics of the test functions used in Noman and Iba (2008) and Suganthan et al. (2005). FORMULA_357 is the global optimum. In the table, properties such as epistasis (Epi), multi-modal (Mul), and discontinuous (Disc), are also shown.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:22",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the described folding procedure, under what condition is a direction chosen for the next residue during the detection process?",
      "topics": [
        "search"
      ],
      "answer": "The detected direction can be chosen for the next residue only when the detection procedure meets the current boundaries, or when the number of detected empty positions is larger than the length of the remaining residues. This condition is used within the Floodfill strategy for labeling empty positions. The allowed moves for each residue are stored in a table denoted by $\\lambda$, where $\\lambda_{\\mathrm{k}}$ represents the list of allowed moves for the $(k+1)$-th residue. The parameter $s$ represents a partial conformation involving $|s|$ residues, and the operator represents the sequence concatenation operator.",
      "chunk_id": 7612,
      "paper_id": "A Hybrid EDA for Protein Folding Based on HP Model. IEEJ",
      "paper_title": "A Hybrid EDA for Protein Folding Based on HP Model",
      "paper_year": "2010",
      "chunk_content": "Fig. 5. The pseudocode of the detection procedure\n3. The detected direction could be chosen for the next residue only when the following condition is achieved: the detection procedure meets the current boundaries or the number of detected empty positions is larger than the length of the remaining residues.  \nThe pseudocode of the detection algorithm is shown in Fig. 5 It use a Floodfill strategy to label the empty positions connected with the detected direction. $\\lambda$ is a table containing the allowed moves for each residue; thus, $\\lambda_{\\mathrm{k}}$ is a list of allowed moves for the $(k+1)$-th residue. Parameter $s$ is a partial conformation involving $|s|$ residues. The operator represents the sequence concatenation operator.  \nFor long protein sequences, there are many invalid closed areas in the folding procedure. The improved method can significantly reduce the computational cost. Although the detection procedure involves some computational cost, it is far less than the cost of backtracking searching operations for invalid closed areas.  \nThe main reason of improvement is that the proposed method can significantly reduce the number of backtracking operation. The folding procedure implements backtracking operation only under a few special circumstances. As shown in Fig. 4(b), assume the folding procedure has selected the right (R) direction for the $n+1$ residues. But at the $n+i$ position, the folding procedure produces two sub-closed areas and both are invalid closed areas for the remaining residues. The folding procedure should implement a backtracking operation under this situation. It will back to the $n+i-1$ residue and search for other possible directions.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:24",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is a key advantage of Repair Operator 2 (RO2) over Repair Operator 1 (RO1) when addressing the feasibility of solutions in the multidimensional knapsack problem (MKP)?",
      "topics": [
        "initialization"
      ],
      "answer": "A key advantage of RO2 is that it eliminates the need to solve the LP relaxation of the MKP, which RO1 requires. The text states that solving the LP relaxation is difficult for large-scale problems, implying that RO2 is more scalable as it relies on a matrix Q and an assistant matrix F computed using specific knowledge of the MKP without needing to solve an LP problem.",
      "chunk_id": 5341,
      "paper_id": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_title": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_year": "2012",
      "chunk_content": "The above way to generate new solutions does not take into account the feasibility of the solutions that are sampled based on the probability model. The individuals could be illegal for violating some of the resource constraints. So, a repair procedure is needed if illegal individuals are constructed. In this sub-section, we provide two repair operators as follows:  \nRepair Operator 1 (RO1): The general technique is a greedylike heuristic based on the pseudo-utility ratios that are calculated by the surrogate duality approach (Pirkul, 1987). The general idea of this method is described briefly as follows:  \nThe surrogate relaxation problem of the MKP can be defined as follows:  \nMaximize $\\sum_{j=1}^{n} p_{j} x_{j}$\nSubject to $\\sum_{j=1}^{n}\\left(\\sum_{k=1}^{m} \\omega_{i} r_{i j}\\right) x_{j} \\leq \\sum_{i=1}^{m} \\omega_{i} b_{i}$.\n$x_{j} \\in\\{0,1\\}, \\quad j=1,2, \\ldots, n$\nwhere $\\omega=\\left\\{\\omega_{1}, \\omega_{2}, \\ldots, \\omega_{m}\\right\\}$ is a set of surrogate multipliers (or weights) of some positive real numbers. These weights can be obtained by solving the LP relaxation of the original MKP and the values of the dual variables are viewed as the weights. In other words, the weight $\\omega_{i}(i=1,2, \\ldots, m)$ can be regarded as the shadow price of the $i$-th constraint in the LP relaxation of the MKP.  \nHaving obtained the weights, the pseudo-utility ratio for each variable can be computed as follows:\n$u_{j}=\\frac{p_{j}}{\\sum_{i=1}^{m} \\omega_{i} r_{i j}}$\nBefore performing the repair procedure, the variables are ordered in the decreasing order according to their pseudo-utility ratios. The repair operator consists of two phases. The first phase examines each bit of the solution string in the increasing order of $u_{j}$ and changes a bit from one to zero until the solution is legal. The second phase reverses the process by examining each bit in the decreasing order of $u_{j}$ and changes a bit from zero to one as long as the feasibility is not violated. The pseudo-code of this repair operator is illustrated in Fig. 3.\nProcedure Repair Operator 1\nLet: $I=\\{1,2, \\cdots, m\\}$.  \n1: Initialize $R_{i}=\\sum_{j=1}^{n} r_{i j} x_{j}, \\forall i \\in I$\n2: FOR $j=n$ to 1 DO\n3: $\\quad$ IF $\\left(x_{j}=1\\right)$ and $\\left(R_{i}>b_{i}, \\exists i \\in I\\right)$ THEN\n4: Set $x_{j} \\leftarrow 0$;\n5: Set $R_{i} \\leftarrow R_{j}-r_{i j}, \\forall i \\in I$;\n6: END IF\n7: END FOR\n8: FOR $j=1$ to $n$ DO\n9: $\\quad$ IF $\\left(x_{j}=0\\right)$ and $\\left(R_{i}+r_{i j} \\leq b_{i}, \\forall i \\in I\\right)$ THEN\n10: Set $x_{j} \\leftarrow 1$;\n11: Set $R_{i} \\leftarrow R_{j}+r_{i j}, \\forall i \\in I$.\n12: END IF\n13: END FOR\nFig. 3. Procedure of RO1.  \nRepair Operator 2 (RO2): The above repair operator requires solving the LP relaxation of the MKP. So far, most mathematical tools are only able to solve the LP problems with small or medium scale, and it is difficult to implement that operator when the problem scale is large. Thus, we propose a new repair operator based on the specific knowledge of the MKP. With this technique, there is no need to solve the LP relaxation of the MKP in advance.  \nDuring the initialization phase, a simple matrix $Q$ and an assistant matrix $F$ are obtained. The element $q_{i j}$ in $Q$ is computed as follows:\nFORMULA_72",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:26",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for feature subset selection, what data structures are required to represent a solution, and how are they used in calculating the fitness function?",
      "topics": [
        "selection"
      ],
      "answer": "The EDA uses a binary string of length $l$ to represent a solution, where $l$ is the number of eigenvectors. Each bit $g_i$ in the string corresponds to an eigenvector; $g_i = 1$ indicates the $i$-th eigenvector is selected, and $g_i = 0$ indicates it is not. This binary string chromosome is evaluated by a fitness function comprising three terms: performance accuracy $F(R)$, and generalization terms $F_{range}(G)$ and $F_{null}(G)$. The $F_{range}(G)$ and $F_{null}(G)$ terms require calculating $D_{rb}$ and $D_{rw}$, which represent the between-class and within-class distances in the range subspace, and $D_{slb}$ and $D_{nw}$, which represent the between-class and within-class distances in the null subspace of $S_W$, respectively. The fitness function combines these terms with weights $\\mu$ and $\\lambda$ to guide the evolutionary process.",
      "chunk_id": 6351,
      "paper_id": "Full-space LDA with evolutionary selection for face recognitiont",
      "paper_title": "Full-space LDA with evolutionary selection for face recognitiont",
      "paper_year": "2006",
      "chunk_content": "We use binary string to represent the composition of optimal feature subset. Each bit $g_{i}(i=1,2, \\cdots, l)$ is corresponding to an eigenvector, that means: if $g_{i}=1$, the $i$ th eigenvector is selected into the optimal subset, otherwise, it is not selected. The length of chromosome is set to be $l$ according to the number of all  \neigenvectors in the full space of $S_{W}$. A chromosome represents a solution of feature selection problem.\nFitness function plays a crucial role in choosing offspring for the next generation from the current generation. It guides the direction of the evolution. In this paper, the fitness function is defined as Eq.(9):  \n$$\n\\text { fitness }=\\mu F(R)+\\lambda F_{\\text {range }}(G)+F_{\\text {sull }}(G)\n$$  \nWhere $\\mathrm{F}(\\mathrm{R})$ is the performance accuracy term in tuning set, $F_{\\text {range }}(G)$ and $F_{\\text {null }}(G)$ are the generalization terms which aim to select eigenvectors that have better generalization at the testing set. Here $F_{\\text {range }}(G)$ and $F_{\\text {null }}(G)$ are defined as Eq.(10) and Eq.(11):  \n$$\n\\begin{aligned}\n& F_{\\text {range }}(G)=\\min \\left(D_{r b}\\right) / \\max \\left(D_{r W}\\right) \\\\\n& F_{\\text {null }}(G)=\\min \\left(D_{r b}\\right) / \\max \\left(D_{r W}\\right)\n\\end{aligned}\n$$  \nWhere $D_{r b}$ and $D_{r w}$ are the distance of betweenclass and within-class in the range subspace of $S_{W}$, respectively. $D_{s l b}$ and $D_{n w}$ are the distance of between-class and within-class in the null subspace of $S_{W}$, respectively.  \nWeight $\\mu$ and $\\lambda$ are empirically chosen to represent contribution of three terms to the fitness. By combining those two terms together(with proper weight $\\mu$ and $\\lambda$ ), EDA can evolve balanced results displaying good performance on both turning and testing set.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:28",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when evolving artificial neural networks?",
      "topics": [
        "encoding"
      ],
      "answer": "The effectiveness of the Estimation of Distribution Algorithm when evolving artificial neural networks can be evaluated by assessing whether it improves the evolvability of the topology and weights of candidate ANN solutions. The goal is to match the results of Gene Expression Programming.",
      "chunk_id": 7677,
      "paper_id": "Toward an estimation of distribution algorithm for the evolution of artificial neural networks",
      "paper_title": "Toward an Estimation of Distribution Algorithm for the Evolution of Artificial Neural Networks",
      "paper_year": "2010",
      "chunk_content": "Graham HolkerRyerson University350 Victoria St.Toronto, ON, Canadagholker@ryerson.ca\nThis paper presents the preliminary results of a unique method of neuroevolution called Probabilistic Developmental Neuroevolution (PDNE). PDNE builds upon Gene Expression Programming (GEP) and Probabilistic Incremental Program Evolution (PIPE). Instead of building a Probabilistic Prototype Tree, as in PIPE, a Probabilistic Prototype Chromosome is built. The chromosome has a similar structure to a GEP chromosome (head, tail, and weight domain) and contains probabilities for each element of the gene. With this methodology, neural networks can be expressed in a similar manner to GEP, and solutions can be evolved via an Estimation of Distribution Algorithm. Preliminary results show promise, but further work is required to match the results of GEP.\nIn this paper we put forward the hypothesis that the evolvability of the topology and weights of an artificial neural network (ANN) can be improved by an Estimation of Distribution Algorithm (EDA) that maintains a probability distribution of encodings for the topologies and weights of candidate ANN solutions.  \nNeural networks exist in artificial and biological systems. ANNs were inspired by the biological neural networks found in brains [4]. ANNs contain any number of neurons connecting the inputs and the outputs. The neuron performs a weighted sum of its inputs and generates an output based on the sum. The specifics of neuron function and network architecture are application dependent. Artificial neural networks have many uses such as function approximation, regression analysis, classification, data processing, game playing, and robot control.  \nNeurons are defined by the number of inputs, the weights of those inputs, and their activation function. The inputs can come as inputs to the network or can be the output of neurons 'down-stream' in the network. The activation  \n[^0]",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:29",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of integrating Estimation of Distribution Algorithms (EDAs) with surrogate models like Gaussian Processes (GPs) in the context of expensive black-box optimization problems?",
      "topics": [
        "genetic"
      ],
      "answer": "The primary objective is to leverage the global optimization capabilities of EDAs, which model the population distribution for solution generation, to enhance the search efficiency of surrogate-assisted evolutionary algorithms (SAEAs). While GPs offer reliable modeling and uncertainty estimation, their cubic computational cost limits their applicability to large-scale problems. Integrating EDAs aims to address this limitation by using global information to guide the population search, potentially improving the balance between exploration and exploitation in SAEAs.",
      "chunk_id": 2745,
      "paper_id": "Efficient Surrogate Model Assisted Estimation of Distribution Algorithm for Expensive Optimization",
      "paper_title": "Efficient Surrogate Model Assisted Estimation of Distribution Algorithm for Expensive Optimization",
      "paper_year": "2024",
      "chunk_content": "Among the various surrogate models highlighted in the literature, GPs have emerged as the preferred surrogate model for SAEAs due to their reliable modeling capabilities and accurate estimation of model response uncertainty. The combination of Gaussian Processes with acquisition functions, also known as model management strategies [17], allows for effective balancing of exploration and exploitation trade-offs, enabling SAEAs to exhibit powerful global optimization abilities when tackling expensive black-box optimization problems. However, due to the high computational cost of GPs modeling, which is scaled cubically concerning the number of data points [18], it is not suitable for medium-to-large scale problems, which has limited the development of SAEAs.  \nIn terms of reproduction operators, current SAEAs employ methods such as genetic algorithms (GA) [12], differential evolution (DE) [19], and particle swarm optimization (PSO)\n[20] as operators for producing new solutions. These operators have all demonstrated good global search capabilities in SAEAs. However, another type of population-based solution generation operator has not been widely used in SAEAs, namely the distribution estimation algorithm (EDA) [21]. This method models the current population and generates new solutions through sampling. By utilizing global information to guide population search, it exhibits stronger global optimization capabilities, potentially enhancing the search efficiency of SAEAs.  \nCai et al. [22] explore event-triggered consensus in multiagent systems, highlighting efficiency in communication and computation, crucial for cooperative control in distributed systems. He et al. [23] introduce the Dynamic Opinion Maximization Framework (DOMF) for social networks, addressing the dynamic nature of user opinions and challenges like non-monotonicity and non-submodularity. They present a blockchain-based solution for secure data offloading in healthcare, combining blockchain technology with deep reinforcement learning for enhanced data privacy and computational efficiency [24]. Cai et al. [25] focus on adaptive control in heterogeneous systems, improving real-time response and synchronization, essential for managing multi-agent system behaviors. Zhong et al. [26] introduce a surrogate ensemble-assisted hyper-heuristic algorithm designed to tackle expensive optimization problems. It combines multiple surrogate models to estimate the fitness of potential solutions, enhancing the efficiency and accuracy of finding optimal solutions. This method is particularly useful in scenarios where traditional optimization techniques fall short due to computational expense or complexity. Pan et al. [27] present a hybrid optimization algorithm that integrates surrogate models with evolutionary strategies. It aims to reduce computational costs while solving expensive optimization challenges, demonstrating significant improvements in both speed and solution quality. The approach provides a promising direction for addressing complex problems in various engineering fields. Chen et al. [28] detail a surrogate model-assisted algorithm for multi-objective optimization with an application in wind farm layout design. By incorporating Sparse Gaussian Process models, the algorithm achieves high accuracy and computational efficiency, showcasing its capability to enhance wind farm performance and its applicability to real-world engineering problems. He et al. [29] present a reinforcement-learningbased approach for competitive opinion maximization in signed social networks. The authors develop a two-phase model incorporating an activated dynamic opinion model and a reinforcement-learning-based seeding process to identify and influence key individuals in social networks, optimizing the spread of opinions against competitive opinions. The results confirm the method's effectiveness in achieving superior opinion propagation across various datasets.  \nIn SA-EDA [30], a GPs assisted EDA algorithm is proposed, which utilizes a variable-width histogram (VWH) to represent the distribution of the population. Due to its  \nfocus on the potentially optimal regions, this VWH exhibits good performance on expensive black-box problems. However, due to the use of Gaussian processes as the surrogate model, the algorithm still faces challenges related to the curse of dimensionality and high computational complexity. To address these issues, this paper proposes an efficient surrogate assisted EDA, called ESAEDA. The main contributions of this algorithm are as follows:",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:31",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms using $\\Delta$-entropy, what fundamental properties distinguish the $\\Delta$-entropy $H_{\\Delta}(X)$ from the classical discrete entropy $H(X)$, and how does Theorem 4, which states $H_{\\Delta}(X) \\geqslant \\log \\left(\\frac{2 \\mathrm{~N} p_{\\min }}{M}\\right)+\\frac{1}{2} \\log (\\operatorname{Var}(X))$, highlight this difference in terms of variance $\\operatorname{Var}(X)$ when $p_{\\min}$ (the minimum probability) is greater than zero?",
      "topics": [
        "proof"
      ],
      "answer": "The key distinction lies in how minimizing the $\\Delta$-entropy $H_{\\Delta}(X)$ constrains the variance $\\operatorname{Var}(X)$, a property not shared by the classical discrete entropy $H(X)$. Theorem 4, $H_{\\Delta}(X) \\geqslant \\log \\left(\\frac{2 \\mathrm{~N} p_{\\min }}{M}\\right)+\\frac{1}{2} \\log (\\operatorname{Var}(X))$, where $N$ represents a normalization factor, $p_{\\min}$ is the minimum probability, and $M$ is the number of discrete values, explicitly links the $\\Delta$-entropy to the variance. This inequality demonstrates that a lower $\\Delta$-entropy implies a constrained variance, indicating that the algorithm favors solutions with less dispersion around the mean. In contrast, classical discrete entropy does not inherently provide such a variance constraint, making $\\Delta$-entropy a potentially more suitable measure when variance control is desired in the optimization process within EDAs.",
      "chunk_id": 11563,
      "paper_id": "Δ-Entropy: Definition",
      "paper_title": "Δ-Entropy: Definition, properties and applications in system identification with quantized data",
      "paper_year": "2011",
      "chunk_content": "$$\n\\log \\left(\\max _{j=1,2, \\ldots M-1}\\left|s_{j+1}-s_{j}\\right|\\right) \\geqslant H_{\\Delta}(X)-H(X) \\geqslant \\log \\left(\\min _{j=1,2, \\ldots M-1}\\left|s_{j+1}-s_{j}\\right|\\right)\n$$  \nProof. Omitted due to simplicity.  \nRemark 2. An appealing feature of Theorem 2 is that, if the minimum interval between two successive discrete values is larger than one, we have $H_{\\Delta}(X)>H(X)$, whereas if the maximum interval between two successive discrete values is smaller than one, we have $H_{\\Delta}(X)<H(X)$.  \nTheorem 3. If $X$ is a discrete random variable with equally spaced values, i.e. $\\forall i, 1 \\leqslant i \\leqslant M-1,\\left|s_{i+1}-s_{i}\\right| \\equiv \\Delta$, and $\\Delta=1$, then $H_{\\Delta}(X)=H(X)$.  \nProof. For equally spaced intervals, the difference between the $\\Delta$-entropy and the discrete entropy equals $\\log \\Delta$. Hence, the statement follows directly.  \nNow we can understand why we chose the name $\\Delta$-entropy for the new measure: when the scale goes to zero we end up with differential entropy and when the scale defaults to the natural numbers the measure is indistinguishable from discrete entropy. Classification is a typical example of the error variable distributed on equally spaced values $(0,1,2,3, \\ldots)$. Therefore, in classification, the error's discrete entropy is equivalent to the $\\Delta$-entropy. This fact also gives an interpretation for why the discrete entropy can be successfully used in the test and classification problems [1431].  \nWe can use Theorem 2 and the bound of the discrete entropy to obtain a bound on the $\\Delta$-entropy.\n$$\n\\log \\left(\\min _{j=1,2, \\ldots, M-1}\\left|s_{j+1}-s_{j}\\right|\\right) \\leqslant H_{\\Delta}(X) \\leqslant \\frac{1}{2} \\log \\left(2 \\pi e\\left(\\sum_{i=1}^{M} p_{i}\\right)^{2}-\\left(\\sum_{i=1}^{M} i p_{i}\\right)+\\frac{1}{12}\\right)\\left(\\max _{j=1,2, \\ldots, M-1}\\left|s_{j+1}-s_{j}\\right|\\right)^{2}\\right)\n$$  \nProof. In information theory, it has been proved that (see [4, p. 489])  \n$$\n0 \\leqslant H(X) \\leqslant \\frac{1}{2} \\log \\left(2 \\pi e\\left(\\sum_{i=1}^{M} p_{i}\\right)^{2}-\\left(\\sum_{i=1}^{M} i p_{i}\\right)+\\frac{1}{12}\\right)\\right)\n$$  \nCombining the above result and Theorem 2, the corollary is proved.\nThe lower bound of the $\\Delta$-entropy can also be expressed in term of the variance $\\operatorname{Var}(X)$, as given in the following theorem.\nTheorem 4. If $p_{\\min }=\\min \\left\\{p_{i}\\right\\}>0$, then $H_{\\Delta}(X) \\geqslant \\log \\left(\\frac{2 \\mathrm{~N} p_{\\min }}{M}\\right)+\\frac{1}{2} \\log (\\operatorname{Var}(X))$.\nProof. See Appendix B.\nThe above lower bound confirms the fact that minimizing the $\\Delta$-entropy will constrain the variance. This is a key difference between the $\\Delta$-entropy and the classical discrete entropy.  \nTheorem 5. For any discrete random variable $X, \\forall c \\in \\mathbb{R}, H_{\\Delta}(X+c)=H_{\\Delta}(X)$.\nProof. Since $H(X+c)=H(X)$, and $\\Delta(X+c)=\\Delta(X)$, we have FORMULA_123.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:34",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for energy-efficient scheduling in cloud computing, how should practitioners configure the multi-model EDA (mEDA) regarding subpopulation usage?",
      "topics": [
        "scheduling"
      ],
      "answer": "Practitioners should adopt three subpopulations within the mEDA to explore a larger solution space. One probability model should produce task processing permutations, and another should produce VSL assignment arrays. The specific operators and scheme are designed to optimize the solutions.",
      "chunk_id": 11189,
      "paper_id": "A multi-model estimation of distribution algorithm for energy efficient scheduling under cloud computing system",
      "paper_title": "A multi-model estimation of distribution algorithm for energy efficient scheduling under cloud computing system",
      "paper_year": "2018",
      "chunk_content": "Energy efficient scheduling problem under cloud computing system is considered in this paper. A multi model EDA is designed to where one probability model produces task processing permutation and the other produces VSL assignment array. Three subpopulations are adopted to explore larger solution space. Besides, some operators and scheme are designed to optimize the solutions. Compared with heuristic methods, a large proportion of solutions  \nTable 8\n$C$ metric comparative results.  \nare dominated by mEDA. Compared with bGA, mEDA is better than bGA in terms of both number of Pareto solutions and $C$ metric. The experimental comparisons demonstrate the efficiency of mEDA.  \nThe future work could focus on heterogeneous system which is closer to the actual cloud computing scheduling problem. Uncertainty is considered to be added into our model and we are going to design a corresponding scheduling algorithm. On the other hand, in terms of the objective, the economic factor is considered. Utilization of processors influences the cost of guests. A large number of processors lead to good time performance but cost a lot of money and energy. We would like to find a trade-off between time performance, energy consumption and expense.\nThis research is supported by the National Key R\\&D Program of China [No. 2016YFB0901900] and the National Natural Science Fund for Distinguished Young Scholars of China [No. 61525304].",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:36",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of power transmission network modeling using a weighted graph, how does the matrix $\\mathbf{B}$, defined as $\\mathbf{B}=\\mathbf{M D}_{\\mathbf{x}} \\mathbf{M}^{\\mathbf{T}}=\\sum_{l=1}^{L}\\left(\\frac{1}{x_{l}} \\cdot \\mathbf{m}_{l} \\cdot \\mathbf{m}_{l}^{T}\\right)$, relate to the Laplacian matrix of the graph and what is the significance of $x_l$ and $\\mathbf{m}_l$ in this relationship?",
      "topics": [
        "optimization"
      ],
      "answer": "The matrix $\\mathbf{B}$ is presented as the Laplacian matrix of the weighted graph $\\mathcal{G}$, which models the power transmission network. Here, $x_l$ represents the reactance along the $l$-th transmission line, and $\\mathbf{m}_{l}$ is the incidence vector for that line. The $i$th element of $\\mathbf{m}_{l}$ is 1 if $i$ equals the 'from' bus, -1 if $i$ equals the 'to' bus, and 0 otherwise. The matrix $\\mathbf{D}_{\\mathbf{x}}$ is a diagonal matrix with $1/x_l$ as its $l$th diagonal entry. Therefore, $\\mathbf{B}$ is constructed by summing the contributions of each transmission line, where each contribution is proportional to the inverse of the line's reactance and involves the outer product of the line's incidence vector with itself. This construction allows $\\mathbf{B}$ to capture the network's connectivity and line reactances, which are crucial for calculating power flow using the equation $\\mathbf{p}=\\mathbf{B}^{(k)} \\theta^{(k)}$.",
      "chunk_id": 4538,
      "paper_id": "Efficient Multiple Lines Outage Detection in SmartGrid",
      "paper_title": "Efficient Multiple Lines Outage Detection in SmartGrid",
      "paper_year": "2015",
      "chunk_content": "In this section, the system model will be discussed in detail. We modeled a power transmission network with $N$ buses and $L$ transmission lines using a weighted graph $\\mathcal{G}=\\{\\mathcal{N}, \\mathcal{E}\\}$, where $\\mathcal{N}=\\{1,2, \\ldots, N\\}$ and $\\mathcal{E}=\\{(m, n)\\} \\subseteq \\mathcal{N} \\times \\mathcal{N}$ represent the set of buses and the set of edges, respectively. For mathematical convenience, we also denote the set of transmission lines by $\\mathcal{L}=\\{1,2, \\ldots, L\\}$. For line $l \\in \\mathcal{L}$ that connects the buses $n$ and $m$, we denote the reactance along $(m, n)$ by $x_{i}$, as well as $x_{m n}=x_{n m}$, and we define the $i$ th element of its incidence vector $\\mathbf{m}_{l}$ as follows:  \n$$\n\\mathbf{m}_{l}=\\left\\{\\begin{array}{cll}\n1 & , & \\text { if } i=n \\\\\n-1 & , & \\text { if } i=m \\\\\n0 & , & \\text { otherwise }\n\\end{array}\\right.\n$$  \nIn this work, we consider the linear DC power flow model defined in [10]. According to conservation-of-flow constraint for power flow in the linear DC model, the injected power to a particular node $n$ must be equal to the total power going out of it. Mathematically it can be written as,  \n$$\nP_{n}=\\sum_{m \\in \\mathcal{N}(n)} P_{n m}=\\frac{1}{x_{m n}}\\left(\\theta_{n}-\\theta_{m}\\right)\n$$  \nwhere $\\mathcal{N}(n)$ is the set of buses, connected to bus $n$, and $P_{n m}$ denotes the power flowing from buses $m$ to $n$ through their connecting transmission line. Here, $\\theta_{n}$ and $\\theta_{m}$ are the voltage phasor angles of buses $n$ and $m$, respectively. For ease in notation, the real power injection in $\\mathbf{p} \\in \\mathbb{R}^{N \\times 1}$, the voltage phases in $\\theta \\in \\mathbb{R}^{N \\times 1}$ and $\\mathbf{B} \\in \\mathbb{R}^{N \\times N}$ is a symmetric matrix can be stacked into a vector-matrix form as,  \n$$\n\\mathbf{p}=\\mathbf{B}^{(k)} \\theta^{(k)}, \\text { where } k=1,2,3, \\ldots, K\n$$  \nwhere $K$ is the number of possible outage events. $K$ is equal to $2^{L}$, including the normal condition, i.e. the pre-outage can be expressed as [10],  \n$$\n\\mathbf{B}=\\mathbf{M D}_{\\mathbf{x}} \\mathbf{M}^{\\mathbf{T}}=\\sum_{l=1}^{L}\\left(\\frac{1}{x_{l}} \\cdot \\mathbf{m}_{l} \\cdot \\mathbf{m}_{l}^{T}\\right)\n$$  \nwhere $\\mathbf{D}_{\\mathbf{x}}$ is a diagonal matrix with $1 / x_{l}$ as its $l$ th diagonal entry, and $\\mathbf{M}$, formed by the columns $\\left\\{\\mathbf{m}_{l}\\right\\}_{l=1}^{L}$ of length $N$, is the $N \\times L$ bus-line incidence matrix with an $(n, l)$ th entry given by  \n$$\nM_{n l}=\\left\\{\\begin{array}{cl}\n1 & \\text {, if } l-\\text { th line is from } n-\\text { th bus } \\\\\n-1 & \\text {, if } l-\\text { th line is to } n-\\text { th bus } \\\\\n0 & \\text {, otherwise }\n\\end{array}\\right.\n$$  \nWith these definitions, $\\mathbf{B}$ can be viewed as the Laplacian matrix of the weighted graph $\\mathcal{G}$. We are interested to detect if power line outage occurs, and to identify the outaged line/s in $\\mathcal{L}$, where FORMULA_59.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:39",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the allocation of simulation replications differ between a standard Estimation of Distribution Algorithm (EDA) and an Order Comparison Based Allocation (OCBA) enhanced EDA, specifically concerning solutions with high \\(\\delta_{b, i}\\) values?",
      "topics": [
        "performance"
      ],
      "answer": "In a standard EDA, simulation replications might be distributed without specific regard to a solution's \\(\\delta_{b, i}\\) value. However, in an OCBA-enhanced EDA, the algorithm allocates very few replications to inferior solutions characterized by a high \\(\\delta_{b, i}\\), where \\(\\delta_{b, i}\\) represents a measure of the difference between the best solution \\(b\\) and solution \\(i\\). Conversely, OCBA allocates more simulation replications to solutions with high \\(s_{i}\\), which represents the standard deviation of the makespan value for solution \\(i\\), aiming to improve the accuracy of performance evaluation for promising solutions. The number of simulation replications \\(n_i(h+1)\\) for each solution \\(i\\) at iteration \\(h+1\\) is calculated based on \\(s_i\\) and \\(\\delta_{b, i}\\), as shown in the provided formulas, indicating a direct dependency of replication allocation on these factors.",
      "chunk_id": 4425,
      "paper_id": "An order-based estimation of distribution algorithm for stochastic hybrid flow-shop scheduling problem",
      "paper_title": "An order-based estimation of distribution algorithm for stochastic hybrid flow-shop scheduling problem",
      "paper_year": "2015",
      "chunk_content": "Based on the basic idea of order comparison and goal softening, ordinal optimisation (Ho, Sreenivas, and Vakili 1992) is an effective way to solve complex stochastic optimisation problems. Later, Chen et al. $(2000,2009)$ presented the OCBA technique to intelligently allocate a limited computing budget to efficiently evaluate and reliably identify good solutions. In the OEDA, a number of simulation replications, $N_{\\text {total }}$, are given in each generation; then, OCBA is used to assign the simulation replications iteratively to each individual according to the acquired knowledge. The procedure of the OCBA is described as follows (Chen et al. 2009; Zhang, Song, and Wu 2012).  \nStep 1: Perform $n_{0}$ simulation replications for all solutions, and calculate the average makespan value and $s_{i}$ for each solution $i$. Set $h=0, n_{1}(h)=n_{2}(h)=\\ldots=n_{P s t i z e}$ $(h)=n_{0}$ and $N(h)=n_{0} \\cdot$ Psize.  \nStep 2: If $\\sum_{i=1}^{P s t i z e} n_{i}(h) \\geq N_{\\text {total }}$, stop the procedure and set the number of the stochastic scenarios for evaluating solution $i$ as $n_{i}=n_{i}(h)$.  \nStep 3: Let $N(h+1)=N(h)+\\Delta$, and compute the new budget allocation $n_{1}(h+1), n_{2}(h+1), \\ldots, n_{P s t i z e}(h+1)$ using the following sub-procedure.  \nStep 3.1: Locate the best solution and record its index as $b$. Then randomly find $j$ such that $j \\neq b$.  \nStep 3.2: Calculate $n_{i}(h+1)$ as follows.  \n$$\n\\begin{aligned}\nn_{i}(h+1)= & N(h+1) \\\\\n& \\times\\left\\{\\sum_{\\substack{i=1 \\\\\ni \\neq h}}^{P \\text { size }}\\left(\\frac{s_{i} / \\delta_{b, i}}{s_{j} / \\delta_{b, i}}\\right)^{2}+s_{b} \\times\\left[\\sum_{\\substack{i \\neq 1 \\\\\ni \\neq h}}^{P \\text { size }} \\frac{1}{s_{i}^{2}}\\left(\\frac{s_{i} / \\delta_{b, i}}{s_{j} / \\delta_{b, i}}\\right)^{4}\\right]^{\\frac{1}{2}}\\right\\}^{-1}\n\\end{aligned}\n$$  \nStep 3.3: Calculate $n_{i}(h+1)$ (For all $i \\neq j$ and $i \\neq b$ ) as follows.  \n$$\nn_{i}(h+1)=n_{j}(h+1) \\times\\left(\\frac{s_{i} / \\delta_{b, i}}{s_{j} / \\delta_{b, i}}\\right)^{2}\n$$  \nStep 3.4: Calculate $n_{b}(h+1)$ as follows.  \n$$\nn_{b}(h+1)=n_{j}(h+1) \\times s_{b} \\times\\left[\\sum_{\\substack{i=1 \\\\ i \\neq b}}^{P \\text { size }} \\frac{1}{s_{i}^{2}}\\left(\\frac{s_{i} / \\delta_{b, i}}{s_{j} / \\delta_{b, i}}\\right)^{4}\\right]^{\\frac{1}{2}}\n$$  \nStep 4: Perform additional $\\max \\left\\{0, n_{i}(h+1)-n_{i}(h)\\right\\}$ simulations for evaluating solution $i(i=1,2, \\ldots, P$ size $)$ and update the average makespan value and $s_{i}$ for each solution $i$ if necessary.  \nStep 5: Let $n_{i}(h+1)=\\max \\left\\{n_{i}(h+1), n_{i}(h)\\right\\}$. Let $h=h+1$ and go to Step 2.  \nFor a solution $x$ in the population, its simulation replications $n_{x}$ is obtained by the OCBA. Then, its objective value $f(x)$ is calculated as in Section 3.2. From Equation (9), it can be seen that very few replications are provided by OCBA for the inferior solution with a high $\\delta_{b, i}$. Thus, the inferior solution will have few chances to be evaluated in the subsequent allocation. In contrast, more simulation replications are allocated by OCBA to the solutions with high $s_{i}$ to promote the evaluation accuracy of performance.  \nTo balance the simulation budget and the accuracy, both $n_{0}$ and $\\Delta$ should not be too small or too large. According to the suggested range of $n_{0}$ and $\\Delta$ (Chen et al. 2000, 2009), it sets $n_{0}=10$ and $\\Delta=10$ in this paper.",
      "question_type": "COMPARATIVE_ANALYSIS",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:41",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model based on Gaussian Mixture Model (GMM) with boosting, as mentioned, to optimize multimodal functions?",
      "topics": [
        "Estimation of Distribution Algorithm",
        "Gaussian Mixture Model",
        "Boosting",
        "Multimodal function optimization"
      ],
      "answer": "The EDA model, based on GMM with boosting, involves estimating the GMM by boosting simple GMMs, specifically with two components. This boosting process can be viewed as a gradient search in function space to achieve a good fit of some objective. The algorithm automatically learns the model structure and parameters without needing prior knowledge.",
      "chunk_id": 6202,
      "paper_id": "Continuous Optimization based-on Boosting Gaussian Mixture Model",
      "paper_title": "Continuous optimization based-on boosting Gaussian mixture model",
      "paper_year": "2006",
      "chunk_content": "Bin LiNature Inspired Computation and Applications Laboratory, University of Science and Technology of China, Hefei, China, 230026binli@ustc.edu.cnRun-tian ZhongDepartment of Electronic Science and Technology,University of Science and Technology of China, Hefei, China, 230026rtzhong@mail.ustc.edu.cn\nA new Estimation of Distribution Algorithm(EDA) based-on Gaussian Mixture Model (GMM) is proposed, in which boosting, an efficient ensemble learning method, is adopted to estimate GMM. By boosting simple GMM with two components, it has the ability of learning the model structure and parameters automatically without any requirement for prior knowledge. Moreover, since boosting can be viewed as a gradient search for a good fit of some objective in function space, the new EDA is time efficient. A set of experiments is implemented to evaluate the efficiency and performance of the new algorithm. The results show that, with a relatively smaller population and less number of generations, the new algorithm can perform as well as compared EDAs in optimizing multimodal functions.",
      "question_type": "algorithm",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:44",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model, HMOBEDA, in approximating the probabilistic Pareto Front, and how are these metrics interpreted?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The effectiveness of HMOBEDA is evaluated using hypervolume and inverted generational distance indicators. Higher hypervolume values indicate better coverage of the objective space, while lower inverted generational distance values signify a closer approximation to the true Pareto front. Additionally, diversity in the solution set is considered as a quality measure for the Pareto Front approximation.",
      "chunk_id": 7030,
      "paper_id": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_title": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_year": "2017",
      "chunk_content": "Marcella S. R. Martins,Myriam Delgado and Ricardo LudersFederal University of Technology - ParanaEmail: \\{marcella,myriamdelg,luders\\}@utfpr.edu.brRoberto SantanaUniversity of the Basque CountryEmail: roberto.santana@ehu.esRichard A. Goncalvesand Carolina P. de AlmeidaMidwest State University of ParanaEmail: \\{richard,carol\\}@unicentro.br\nMetaheuristics that explore the decision variables space to construct probabilistic modeling from promising solutions, like estimation of distribution algorithms (EDAs), are becoming very popular in the context of Multi-objective Evolutionary Algorithms (MOEAs). The probabilistic model used in EDAs captures certain statistics of problem variables and their interdependencies. Moreover, the incorporation of local search methods tends to achieve synergy of MOEAs' operators and local heuristics aiming to improve the performance. In this work, we aim to scrutinize the probabilistic graphic model (PGM) presented in Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm (HMOBEDA), which is based on a Bayesian network. Different from traditional EDA-based approaches, the PGM of HMOBEDA provides the joint probability of decision variables, objectives, and configuration parameters of an embedded local search. HMOBEDA has shown to be very competitive on instances of Multi-Objective Knapsack Problem (MOKP), outperforming state-of-the-art approaches. Two variants of HMOBEDA are proposed in this paper using different sample methods. We aim to compare the learnt structure in terms of the probabilistic Pareto Front approximation produced at the end of evolution. Results on instances of MOKP with 2 to 8 objectives show that both proposed variants outperform the original approach, providing not only the best values for hypervolume and inverted generational distance indicators, but also a higher diversity in the solution set.  \nKeywords-Multi-objective optimization; estimation of distribution algorithms; automatic algorithm configuration;",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:46",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of introducing the IIR digital low pass filter, as represented by the transformation function \\(H(z)=\\frac{\\lambda z^{-1}}{1-(1-\\lambda) z^{-1}}\\), into the update mechanism of EDAs such as IUMDA, PBIL, and HCwL?",
      "topics": [
        "convergence"
      ],
      "answer": "The primary objective is to enhance the low-frequency content and restrain the high-frequency content in the population distribution, thereby restraining the surge near the convergent point and improving the convergence speed of the EDA. The parameter \\(\\lambda\\), where \\(0 \\leq \\lambda \\leq 1\\), controls the filter's behavior, balancing the influence of the selected population \\(P^{c}(x, t-1)\\) and the previous population \\(P(x, t-1)\\) on the new population \\(P(x, t)\\).",
      "chunk_id": 6810,
      "paper_id": "High-order EDA",
      "paper_title": "HIGH-ORDER EDA",
      "paper_year": "2009",
      "chunk_content": "In EDA, the new population is normally generated by the distribution of $P^{c}(t)$, i.e.,  \n$$\nP(x, t)=P^{c}(x, t-1)\n$$  \nFrom this equation we can find that the new population only uses the information of the selected population and has no relation with the last generation. Some researchers noticed this point and proposed some new algorithms, such as IUMDA [7], PBIL [8] and HCwL [9]. Although the realization of these algorithms is different, the basic ideas are the same as the following:  \n$$\nP(x, t)=\\lambda P^{c}(x, t-1)+(1-\\lambda) P(x, t-1) \\quad 0 \\leq \\lambda \\leq 1\n$$  \ni.e., the distribution of the new population not only use the information after selection; but also use the information before selection. When $\\lambda=1$, it belongs to the traditional EDA. When $\\lambda=0$, the individual probability keeps unchanged and loses the capability of finding optimal solution.  \nIf we consider equation (1) as the description of a linear system, we can get the transformation function of this linear system  \n$$\nH(z)=\\frac{\\lambda z^{-1}}{1-(1-\\lambda) z^{-1}}\n$$  \nObviously it is an IIR digital low pass filter. It can enhance the low-frequency content and restrain the high-frequency content. In this way the serge near the convergent point will be restrained and at the same time the convergence speed will be improved. Because $0 \\leq \\lambda \\leq 1$, this filter is steady. But when $\\lambda$ tends to 0 the inertia will be increased and the function of the selection operator will be decreased. When $\\lambda=0$ the selection is useless; In order to prevent this problem, we can limit the range of $\\lambda$. We also can use FIR filter. In this situation we let  \n$$\n\\begin{gathered}\nP(x, t)=\\sum_{i=1}^{m} \\alpha_{i} P^{c}(x, t-i) \\\\\n0 \\leq \\alpha_{i} \\leq 1, \\quad \\sum_{i=1}^{m} \\alpha_{i}=1\n\\end{gathered}\n$$  \nWe call the algorithm based on equation (2) as high-order EDA and $m$ is the order. The corresponding transformation function is  \n$$\nH(z)=\\sum_{i=1}^{m} \\alpha_{i} z^{-i}\n$$  \nIn the following, we let $m=2$ for simplicity and it can be called as $2^{\\text {nd }}$-order EDA. The core equation of\n$2^{\\text {nd }}$-order EDA can be written as  \n$$\nP(x, t)=\\lambda P^{c}(x, t-1)+(1-\\lambda) P^{c}(x, t-2) \\quad 0 \\leq \\lambda \\leq 1\n$$  \nAnd the frame of 2-order EDA can be summarized as  \n1) $t=0$, randomly generate initial population $P(0)$\n2) select a set of promising solutions $P^{c}(0)$ from $P(0)$\n3) estimate the distribution of the selected set $P^{c}(0)$\n4) create a new population $P(1)$ according to the estimate, $t=1$\n5) select a set of promising solutions $P^{c}(t)$ from $P(t)$\n6) estimate the distribution of the selected set $P^{c}(t)$\n7) create a new population according to the estimate $P(x, t)=\\lambda P^{c}(x, t-1)+(1-\\lambda) P^{c}(x, t-2)$\n8) if the termination criteria are not met, FORMULA_39, go to 5)",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:48",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the Hybrid Imperialist Competitive Algorithm (HICA) for outpatient scheduling, how does the algorithmic mechanism of incorporating an Estimation of Distribution Algorithm (EDA) component, specifically controlled by the parameter $\\beta$, contribute to improving the quality of solutions, and what does a lower value of $\\beta$ suggest about the algorithm's performance?",
      "topics": [
        "scheduling"
      ],
      "answer": "The Hybrid Imperialist Competitive Algorithm (HICA) uses an Estimation of Distribution Algorithm (EDA) component to improve poor colonies. The parameter $\\beta$ represents the ratio of poor colonies improved through the EDA. Based on the experimental results using the Design of Experiment (DOE) Taguchi method, the algorithm shows the best performance when $\\beta$ is at level 1. This suggests that a lower ratio of poor colonies being improved by the EDA leads to better overall performance of the HICA in this specific application. The method indicates that the mutation strategy is effective by performing a multifactor analysis of variance (ANOVA) with a confidence level of 95%, where a p-value less than 0.05 indicates a significant difference.",
      "chunk_id": 9107,
      "paper_id": "A hybrid imperialist competitive algorithm for the outpatient scheduling problem with switching and preparation times",
      "paper_title": "A hybrid imperialist competitive algorithm for the outpatient scheduling problem with switching and preparation times",
      "paper_year": "2021",
      "chunk_content": "This section evaluates the effectiveness of the proposed HICA on outpatient scheduling problem. All numerical experiments have been conducted on a Lenovo PC with a 3.3-GHz processor and 4-GB memory running Windows 7. The FJSP approach has been coded in C++ to add speed and robustness.\nThe algorithm has four important parameters: the country size pop, the ratio of the imperialist to countries Nim/pop, the ratio of good colonies improved through SA $\\alpha$, and the ratio of poor colonies improved through the EDA $\\beta$. The levels of each parameter are listed in Table 1. To evaluate the influence of these parameters on the performance of the HICA, the DOE (Design of Experiment) Taguchi method [10] was used, in which an orthogonal array $L_{1 h}$ is constructed. Then, for each parameter combination, the proposed algorithm independently ran 30 times, and the average fitness value of the algorithm was collected as the response variable. Finally, a factor level trend chart for the four parameters was created based on the obtained data. As seen in Fig. 3, when pop is at level 2, Nim/Pop is at level 1, $\\alpha$ is at level 2 , and $\\beta$ is at level 1 , the proposed algorithm shows the best performance.\nTo verify the quality of the algorithm for solving outpatient scheduling problem, this section compares HICA and IBM ILOG CPLEX algorithm. The settings for the precision solver were configured as follows. The maximum number of threads was 3 , and the time limit was set to 3 h . For the HICA, due to its ability to obtain a satisfactory solution within an acceptable time, a maximum CPU time of 30 s was applied as a stop criterion. Then, 18 small-scale examples of outpatient scheduling problems are randomly generated based on the practical problems.  \nTable 1: Key parameter levels.\n[IMAGE2]  \nFig. 3: Factor level trends for the four key parameters.\nWith an increase in the number of patients and stages, there is an exponential increase in time to solve the problem to optimality on CPLEX because of the NP-hard property [11]. Thus, for the other instances, the optimal solutions cannot be obtained on CPLEX within 3 h . Table 2 presents the comparison results between the proposed algorithm and the CPLEX solver. The first column lists the instance name, the second column lists the best fitness values for each instance. The fitness values for each instance are provided in the fourth and fifth columns, while the sixth and seventh columns provide the deviation of the objective value of each algorithm compared with the best value.  \nTable 2: Comparison results for the CPLEX solver and HICA.\nThe following observations can be made from Table 2. (i) For solving the given 18 instances, HICA obtained higher quality solutions than the CPLEX solver. (ii) CPLEX did not solve large-scale examples better than HICA.\nTo verify the effectiveness of the proposed mutation strategy, we performed detailed comparisons of the two\nalgorithms, namely, the algorithm with all of the components of the proposed HICA except for the proposed mutation strategy (hereafter called the HICANMS) and the proposed HICA with all of the components. To determine whether the resulting comparisons were significantly different, we performed a multifactor analysis of variance (ANOVA) [12]. The confidence level was set to $95 \\%$. When the p-value was less than 0.05 , the difference between the algorithms was significant, and Fig. 4 indicates that our strategy is effective.\n[IMAGE_3]  \nFig. 4: ANOVA of the mutation strategy",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:05:50",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the incremental Gaussian mixture model (IGMM) to update model parameters \\(\\Theta=\\left\\{\\pi_{k}, \\boldsymbol{\\mu}_{k}, \\Sigma_{k}\\right\\}_{k=1}^{K}\\) when new data \\(\\left\\{\\mathbf{x}^{*}\\right\\}\\) becomes available, and how does the algorithm determine when to stop updating?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The IGMM algorithm updates model parameters \\(\\Theta=\\left\\{\\pi_{k}, \\boldsymbol{\\mu}_{k}, \\Sigma_{k}\\right\\}_{k=1}^{K}\\) through an iterative Expectation-Maximization (EM) process. First, in the E-step, compute the posterior probabilities \\(p(k \\mid \\mathbf{x}^{*})\\) for each mixture component \\(k\\) and the expectation vector \\(E_{k}^{t} = N \\pi_{k}^{t}\\). Next, in the M-step, re-estimate the parameters using the formulas: \\(\\pi_{k}^{t+1}=\\frac{E_{k}^{t}+p(k \\mid \\mathbf{x}^{*})}{N+1}\\), \\(\\boldsymbol{\\mu}_{k}^{t+1}=\\frac{E_{k}^{t} \\boldsymbol{\\mu}_{k}^{t}+\\mathbf{x}^{*} p(k \\mid \\mathbf{x}^{*})}{E_{k}^{t}+p(k \\mid \\mathbf{x}^{*})}\\), and \\(\\Sigma_{k}^{t+1}=\\frac{E_{k}^{t}\\left(\\Sigma_{k}^{t}+\\left(\\boldsymbol{\\mu}_{k}^{t}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)\\left(\\boldsymbol{\\mu}_{k}^{t}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)^{T}\\right)}{E_{k}^{t}+p(k \\mid \\mathbf{x}^{*})}+\\frac{p(k \\mid \\mathbf{x}^{*})\\left(\\mathbf{x}^{*}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)\\left(\\mathbf{x}^{*}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)^{T}}{E_{k}^{t}+p(k \\mid \\mathbf{x}^{*})}\\). Finally, evaluate the log-likelihood \\(L(\\Theta_{t+1})=\\sum_{k=1}^{K} p(k \\mid \\mathbf{x}^{*})[\\ln \\pi_{k}^{t+1}+\\ln \\mathscr{N}(\\mathbf{x}^{*} \\mid \\boldsymbol{\\mu}_{k}^{*}, \\Sigma_{k}^{t})]\\). The algorithm iterates between the E-step and M-step until the absolute difference between successive log-likelihood values, \\(\\left|L(\\Theta_{t+1})-L(\\Theta_{t})\\right|\\), is less than or equal to a termination tolerance \\(\\Delta\\), a small positive scalar.",
      "chunk_id": 9214,
      "paper_id": "An incremental-learning model-based multiobjective estimation of distribution algorithm",
      "paper_title": "An incremental-learning model-based multiobjective estimation of distribution algorithm",
      "paper_year": "2021",
      "chunk_content": "Require: the existent model parameters $\\Theta_{0}=\\left\\{\\pi_{k}^{0}, \\boldsymbol{\\mu}_{k}^{0}, \\Sigma_{k}^{0}\\right\\}_{k=1}^{K}$, the number of collected data $N$, the newly available data $\\left\\{\\mathbf{x}^{*}\\right\\}$.\nEnsure: the newly model parameters $\\Theta=\\left\\{\\pi_{k}, \\boldsymbol{\\mu}_{k}, \\Sigma_{k}\\right\\}_{k=1}^{K}$.\n1: while $\\left|L\\left(\\Theta_{t+1}\\right)-L\\left(\\Theta_{t}\\right)\\right| \\leqslant \\Delta$ do\n2: E-step: Evaluate the posterior probabilities, i.e. the membership weight of the newly available data $\\mathbf{x}^{*}$ in mixture component $K$, by:  \n$$\np\\left(k \\mid \\mathbf{x}^{*}\\right)=\\frac{\\pi_{k}^{t} \\mathscr{N}\\left(\\mathbf{x}^{*} \\mid \\boldsymbol{\\mu}_{k}^{*}, \\Sigma_{k}^{t}\\right)}{\\sum_{j=1}^{K} \\pi_{j}^{t} \\mathscr{N}\\left(\\mathbf{x}^{*} \\mid \\boldsymbol{\\mu}_{j}^{*}, \\Sigma_{j}^{t}\\right)}, \\quad 1 \\leqslant k \\leqslant K\n$$  \nand compute the expectation vector $E_{k}^{t}$, by:  \n$$\nE_{k}^{t}=N \\pi_{k}^{t}, \\quad 1 \\leqslant k \\leqslant K\n$$  \n3: M-step: Re-estimate the parameters using the current responsibilities:  \n$$\n\\begin{aligned}\n& \\pi_{k}^{t+1}=\\frac{E_{k}^{t}+p\\left(k \\mid \\mathbf{x}^{*}\\right)}{N+1} \\\\\n& \\boldsymbol{\\mu}_{k}^{t+1}=\\frac{E_{k}^{t} \\boldsymbol{\\mu}_{k}^{t}+\\mathbf{x}^{*} p\\left(k \\mid \\mathbf{x}^{*}\\right)}{E_{k}^{t}+p\\left(k \\mid \\mathbf{x}^{*}\\right)} \\\\\n& \\Sigma_{k}^{t+1}=\\frac{E_{k}^{t}\\left(\\Sigma_{k}^{t}+\\left(\\boldsymbol{\\mu}_{k}^{t}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)\\left(\\boldsymbol{\\mu}_{k}^{t}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)^{T}\\right)}{E_{k}^{t}+p\\left(k \\mid \\mathbf{x}^{*}\\right)}+\\frac{p\\left(k \\mid \\mathbf{x}^{*}\\right)\\left(\\mathbf{x}^{*}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)\\left(\\mathbf{x}^{*}-\\boldsymbol{\\mu}_{k}^{t+1}\\right)^{T}}{E_{k}^{t}+p\\left(k \\mid \\mathbf{x}^{*}\\right)}\n\\end{aligned}\n$$  \n4: Evaluate the log-likelihood:  \n$$\nL\\left(\\Theta_{t+1}\\right)=\\sum_{k=1}^{K} p\\left(k \\mid \\mathbf{x}^{*}\\right)\\left[\\ln \\pi_{k}^{t+1}+\\ln \\mathscr{N}\\left(\\mathbf{x}^{*} \\mid \\boldsymbol{\\mu}_{k}^{*}, \\Sigma_{k}^{t}\\right)\\right]\n$$  \n5: $\\quad i \\leftarrow i+1$.\n6: end while  \nAlgorithm 1 presents the main learning steps in the expectation-maximization algorithm for IGMM. The approach has separate code for the newly arrived data and for the data already fed to learn the model. The assumption is that the set of posterior probabilities $\\left\\{p\\left(k \\mid \\mathbf{x}_{i}\\right)\\right\\}_{j=1}^{N}$ remains the same when the model parameters are updated for the newly arrived data $\\left\\{\\mathbf{x}^{*}\\right\\}$. By defining the newly arrived data $\\left\\{\\mathbf{x}^{*}\\right\\}$ as an increase and the parameters of the learned model as $\\left\\{\\pi_{k}, \\boldsymbol{\\mu}_{k}, \\Sigma_{k}\\right\\}_{k=1}^{K}$, the model parameters are updated after initialization via an iterative method with two steps: an expectation step (E-step) and a maximization step (M-step). In the E-step (line 2), the posterior probabilities of the component memberships are computed for the newly available data. It then computes the expectation vector for the next step. In the M-step (line 3), using the component-membership posterior probabilities as weights, the parameters $\\left\\{\\pi_{k}, \\boldsymbol{\\mu}_{k}, \\Sigma_{k}\\right\\}_{k=1}^{K}$ are estimated based on maximizing the log-likelihood function. The E- and M-steps are constantly iterated until the log-likelihood function converges to the termination tolerance $\\Delta$, which is a small positive scalar (line 4).  \nFig. 1 is a demo of how an IGMM learns from a data stream. The data stream has six different groups, each of which contains 100 data points (from [15]). From demos 1 to 6 , the model is updated continually as the data stream is incrementally  \n[IMAGE0]  \nFig. 1. The learning processes of IGMM.\nfed into it. After the 6 -th demo, the learning process has efficiently adapted the model to represent the data stream. Unlike an evolving data stream in an evolutionary search, the data stream used in the demo is independent and static. It has a global view of the data, i.e., all data points are randomly accessible. As the data stream is in a permuted order, the model does not change in the demo.  \nIn contrast, the data in an evolving data stream depend on the generation and dynamically change. A window can be defined that slides over the evolving data stream, creating a partial view of the data. For a short window, the data are pseudo-stationary, whereas they converge over a longer time. Moreover, in IGMM, the data are stored and preserved during the learning process. An evolutionary search is an optimization process, and nondominated solutions gradually replace the worst solutions in the population during the evolutionary cycle. Hence, it is necessary to adjust IGMM if it is utilized to extract the structure of evolving data during an evolutionary process.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:05:55",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the optimization of the annual-mean marine zinc cycle model using experimental data, how do variations in the stoichiometric uptake parameter $r_{\\mathrm{Zn}:\\mathrm{P}}$, which represents the dependence of zinc uptake on dissolved zinc concentration, influence the resulting zinc export flux distributions and dissolved zinc concentrations, and what does this imply about the identifiability of underlying biogeochemical parameters?",
      "topics": [
        "control"
      ],
      "answer": "The optimization experiments demonstrate that variations in the stoichiometric uptake parameter $r_{\\mathrm{Zn}:\\mathrm{P}}$ directly affect the zinc export flux distributions. Specifically, when $r_{\\mathrm{Zn}:\\mathrm{P}}$ underestimates the reference value at low zinc concentrations and exceeds it at higher concentrations (around 1 nM), the optimized zinc export flux increases in zinc-rich regions like the Antarctic Zone and decreases in the Subantarctic Zone and at lower latitudes. Furthermore, the magnitude of residuals in the dissolved zinc distribution can be reduced by up to approximately 50% through optimization, even while the patterns of residuals remain similar. This sensitivity of the zinc export flux to variations in $r_{\\mathrm{Zn}:\\mathrm{P}}$ suggests that the identifiability of other biogeochemical parameters is strongly coupled to the accurate representation of this uptake relationship.",
      "chunk_id": 1421,
      "paper_id": "Influence of GEOTRACES data distribution and misfit function choice on objective parameter retrieval in a marine zinc cycle model",
      "paper_title": "Influence of GEOTRACES data distribution and misfit function choice on objective parameter retrieval in a marine zinc cycle model",
      "paper_year": "2022",
      "chunk_content": "Figure 6 illustrates how the optimised parameter sets influence a key aspect of the Zn cycling model: the dependence of the stoichiometric uptake parameter $r_{\\mathrm{Zn}: \\mathrm{P}}$ on dissolved Zn (hereafter uptake curve or uptake systematics). We use this emergent relationship as a measure of model similarity since it controls the geographical systematics of Zn uptake and export (de Souza et al., 2018), although of course the stoichiometry of $\\mathrm{Zn}: \\mathrm{P}$ uptake in the real ocean is not likely to follow a single dependence on Zn concentration. In sub-  \n[IMAGE4]  \nFigure 5. Results from the last generation of all synObs experiments. Error bars represent 2 standard deviations calculated using the 10 individuals of the last generation. Dots represent parameter values resulting in minimum misfit within the prescribed boundaries during optimisation, coloured according to misfit metric.\nsequent subsections, we describe the retrieval of reference biogeochemical model behaviour for three optimisation experiments with varying degrees of dissimilarity between optimised and reference uptake systematics.\nThe experiment synObsALLseas optimises our annualmean model towards a target field produced when seasonal variability is simulated, with perfect data coverage. The RMSE-optimised parameter values in this experiment differ by $12 \\%-60 \\%$ from the reference values used to produce the target field (Table S2). These values result in Zn uptake systematics that are broadly similar to the reference uptake systematics (Fig. 6b), although $r_{\\mathrm{Zn}: \\mathrm{P}}$ underestimates the reference $r_{\\mathrm{Zn}: \\mathrm{P}}$ at low concentrations and exceeds it above $\\sim 1 \\mathrm{nM}$. As a consequence, the RMSE-optimised Zn export flux is increased in the Zn -rich Antarctic Zone but decreased in the Subantarctic Zone and at lower latitudes, relative to\nthe reference Zn export flux distribution (Fig. S5b). These systematic changes reflect the trends observed when comparing Zn export flux distributions in the target and reference simulations (Fig. S5d), although differences between the reference and the RMSE-optimised Zn export fluxes are smaller than those between the reference and the target. Similarly, a comparison of residuals in the dissolved Zn distribution of the RMSE-optimised model (Fig. 7b, e, h) to those between the reference and target field (Fig. S1e, h, k) reveals that optimisation has reduced the magnitude of residuals by up to $\\sim 50 \\%$, while the patterns of the residuals remain nearidentical. In both cases, the surface ocean simulated with annual-mean TMs is generally biased to higher Zn concentrations (Figs. 7b, S1e). High positive residuals in the surface Southern Ocean and North Pacific are associated with negative residuals below the euphotic zone (e.g. Fig. 7e, h).  \nAlthough there are several optimisations that result in a similar uptake curve as the RMSE-optimised synObsALLseas experiment (Fig. 6), we would like to note  \n[IMAGE_5]  \nFigure 6. Zn uptake systematics resulting from optimised parameter sets obtained in synObs experiments. Dashed lines in panels (e) and (f) are results obtained with the IDP+ data coverage (see text).\nthat both distribution and magnitude of residuals can be quite different (cf. second columns of Figs. 7, 8) between experiments.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:05:58",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of Estimation of Distribution Algorithm (EDA) compare to Genetic Algorithm (GA) in terms of global search ability and convergence speed, based on the information provided?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Genetic Algorithms",
        "global search",
        "convergence speed"
      ],
      "answer": "EDA is described as sampling the superior area in the search space to generate new superior solutions, making the population evolve based on the quality of solutions. Compared to GA, which uses crossover and mutation operators to generate new solutions, EDA is stated to have a stronger ability in global search and faster convergence.",
      "chunk_id": 8852,
      "paper_id": "A hybrid estimation of distribution algorithm for distributed flexible job shop scheduling with crane transportations",
      "paper_title": "A hybrid estimation of distribution algorithm for distributed flexible job shop scheduling with crane transportations",
      "paper_year": "2021",
      "chunk_content": "Other types of distributed scheduling problems have also been developed. Hsu et al. proposed an agent-based fuzzy constraint-directed negotiation mechanism [27] for the distributed job shop scheduling problem (DJSP). In addition, Zhang et al. developed a distributed ant colony system [28] to solve the flexible assembly job shop scheduling problem with multiple objectives. Zheng et al. proposed a cooperative co-evolution algorithm [29] for the multi-objective fuzzy distributed hybrid flow shop scheduling problem (DHFSP), where an EDA-mode search and IG-mode search were designed as a cooperation scheme for mode switching based on information entropy and the diversity of elite solutions. Shao et al. proposed a multi-neighborhood IG [30] for the DHFSP. However, energy factors should also be taken into account to satisfy the demands of green manufacturing.\nThe DFJSP is another type of distributed scheduling problem, where each factory has a flexible job shop scheduling system. In studies on the DFJSP, the main objective is the makespan. De Giovanni and Pezzella proposed an improved genetic algorithm (GA) [31] for the DFJSP. Ziaee developed a fast heuristic algorithm [32] based on a constructive procedure to solve the DFJSP. Then, Lu et al. proposed a GA with a new and concise chromosome representation [33] for the DFJSP, modeling a three-dimensional scheduling solution using a one-dimensional scheme. Liu et al. proposed a refined GA [34] that integrates probability into the encoding method, reducing the length of chromosomes and saving computational space; and Liu et al. designed a GA [35] with an encoding operator to solve the DFJSP. Chang and Liu proposed a hybrid GA [36] to solve the DFJSP, where an encoding mechanism was used to handle invalid job assignment. Li et al. proposed a hybrid Pareto-based tabu search (TS) algorithm [2] to solve the DFJSP considering four objectives simultaneously. Wu et al. proposed a MILP model and an improved differential evolution algorithm [37] to solve the DFJSP with the assembly process. Additionally, Marzouki et al. proposed a chemical reaction optimization metaheuristic [38] in solving the DFJSP to minimize the makespan. Meng et al. proposed four MILP models and a constraint programming (CP) model [39] for the DFJSP. Recently, Luo et al. have proposed an efficient memetic algorithm (EMA) [40] to solve the DFJSP with transfers. Zhang et al. proposed a three-stage approach based on decomposition [41], providing the decomposition optimization theory of this study. Zou et al. established an effective IG [42] for solving a scheduling problem in a matrix manufacturing workshop. However, most of the researches did not consider the energy consumption and transportation process in the DFJSP. EDA is a newly developed statistics-  \nbased optimization algorithm in evolutionary algorithms family. Compared with GA that generates new solutions with crossover and mutation operators, EDA sampled the superior area in search space to generate new superior solutions, making the population evolves based on the quality of solutions. Therefore, EDA has a stronger ability in global search and faster convergence. In this study, EDA is employed as the exploration component to solve DFJSP with crane transportation.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:00",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing the update of the upper bound in the described Estimation of Distribution Algorithm, what programming considerations are important regarding the variables `UB(g+1)`, `UB(g)`, and `C_best`?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The implementation must ensure that `UB(g+1)` is assigned the minimum value between the current upper bound `UB(g)` and `C_best`, where `C_best` represents the cycle time of the best solution found in the current generation. This requires a comparison operation and assignment, ensuring `UB(g+1)` always reflects the best-so-far objective value. The data types of `UB(g)`, `UB(g+1)`, and `C_best` must be compatible for the comparison and assignment to function correctly, typically numerical types representing cycle time.",
      "chunk_id": 9675,
      "paper_id": "An estimation of distribution algorithm with branch-and-bound based knowledge for robotic assembly line balancing",
      "paper_title": "An estimation of distribution algorithm with branch-and-bound based knowledge for robotic assembly line balancing",
      "paper_year": "2021",
      "chunk_content": "where $\\beta \\in(0,1)$ represents the learning rate and $I_{k i}^{h}(g)$ is the following indicator function corresponding to the $h$ th elite solution:  \nTable 1 Parameter values\n$I_{i c}^{h}(g)=\\left\\{\\begin{array}{ll}1, & \\text { if task } i \\text { is assigned to workstation } k \\text { in the } h \\text { th elite solution } \\\\ 0, & \\text { otherwise }\\end{array}\\right.$\nThe upper bound is updated using the objective value of the best solution found in each generation as (11). In this way, the best-so-far objective value is recorded as the upper bound and will be used as a reference value when generating new solutions in the following generation:\n$U B(g+1)=\\min \\left\\{U B(g), C_{\\text {best }}\\right\\}$,\nwhere $U B(g)$ is the upper bound in generation $g, C_{\\text {best }}$ is the cycle time of the best solution.  \nTable 2 Orthogonal array and ARVs\n[IMAGE5]  \nFig. 6 Factor level trend",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:02",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when employing the Univariate Marginal Distribution Algorithm (UMDA) for combinational optimization?",
      "topics": [
        "genetic"
      ],
      "answer": "The UMDA algorithm estimates the joint probability distribution using the formula  p_{j}(x)=p(x | D_{t-1}^{N_{t}})=\\prod_{i=1}^{t} p_{j}(x_{i})=\\prod_{i=1}^{t} \\frac{\\sum_{i=1}^{N} \\delta_{i}(X_{i}=x_{i} | D_{t-1}^{N_{t}})}{N}, where \\delta_{i} is an indicator function, N represents the number of selected individuals, and x_i represents a variable. The effectiveness is implicitly evaluated by how well this estimated distribution allows for sampling to produce new, improved populations D_t in each iteration. A key measure would be the fitness of individuals in D_t compared to D_{t-1}, reflecting the algorithm's ability to learn and sample from advantageous groups. There are no explicit metrics mentioned, but the improvement in fitness scores across generations serves as an implicit indicator.",
      "chunk_id": 6817,
      "paper_id": "Research and New Development of Application of the Estimation of Distribution Algorithms",
      "paper_title": "Research and New Development of Application of the Estimation of Distribution Algorithms",
      "paper_year": "2009",
      "chunk_content": "In order to solve these problems of genetic algorithms ,the improved method is to alter the basic principles of recombination operation, changes cross and mutation operation of genetic algorithm to learning the probability distribution of good solutions, the basic idea is to Select some excellent solutions from the current population , and use these excellent solutions to estimate and learning distribution model, and then sampling the distribution model to produce a new population. Take turns iteration, finally approaching the optimal solution. Based on this distribution model the algorithm is called Estimation of Distribution Algorithm. It can be described as follows:\n$D_{0} \\leftarrow$ Generated M individuals as the initial population randomly.\nRepeat for $1=1,2, \\ldots$ until the termination of the guidelines to achieve .\n$D_{t-1}^{N_{t}} \\leftarrow$ According to selection to choose $N \\leq M$ individuals from $D_{t-1}$ as the advantaged groups .\n$p_{j}(x)=p\\left(x \\mid D_{t-1}^{\\text {N }}\\right) \\leftarrow$ Estimated the joint probability distribution .\n$D_{t} \\leftarrow$ Sampling M times From $p_{j}(x)$, get a new groups.  \nAccording to the model order of complexity, EDAs divides into three kinds:\n(1)Without dependencies\n(2)Bivariate dependencies\n(3)Multiple dependencies.\nA. EDA approaches to combinational optimization  \n- Without dependencies  \nIt has three algorithms:\n(1)Univariate Marginal Distribution Algorithm UMDA\n$p_{j}(x)=p\\left(x \\mid D_{t-1}^{N_{t}}\\right)=\\prod_{i=1}^{t} p_{j}\\left(x_{i}\\right)=\\prod_{i=1}^{t} \\frac{\\sum_{i=1}^{N} \\delta_{i}\\left(X_{i}=x_{i} \\mid D_{t-1}^{N_{t}}\\right)}{N}$\n(2)Population Based Incremental Learning, PBIL\n$p_{j+1}(x)=(1+\\alpha) p_{j}(x)+\\alpha \\frac{1}{N} \\sum_{k=1}^{N} \\chi_{k: M}^{j}$\n(3)compact Genetic Algorithm, cGA  \n- Bivariate dependencies  \nIt has three algorithms:\n(1)Mutual Information Maximization for Input Clustering, MIMIC  \n$$\np_{i}^{m}(x)=p_{i}\\left(x_{i 1} \\mid x_{i 2}\\right) \\cdot p_{i}\\left(x_{i 2} \\mid x_{i 3}\\right) \\cdots p_{i}\\left(x_{i n-1} \\mid x_{i n}\\right) \\cdot p_{i}\\left(x_{i n}\\right)\n$$  \n(2)Combining Optimizers with Mutual Information Trees $\\operatorname{COMIT} p_{j}(x)=p\\left(x \\mid D_{t-1}^{N_{t}}\\right)=\\prod_{i=1}^{t} p_{j}\\left(x_{i} \\mid x_{j(t)}\\right)$\n(3)Bivariate Marginal Distribution Algorithm, BMDA.  \n$$\np_{j}(x)=\\prod_{i, k=0}^{t} p_{j}\\left(x_{i}\\right) \\prod_{i, j \\in \\mathcal{N}_{j}} p_{j}\\left(x_{i} \\mid x_{j(t)}\\right)\n$$  \nMIMICCOMIT and BMDA all assume interdependencies between the variables from the database of selected individuals, they adopt chain  tree and forest structure.  \n- Multiple dependencies  \nIt has six algorithms:\n(1)Extended compact Genetic Algorithm, EcGA  \n$$\n\\begin{aligned}\n& p_{i}(x)=p\\left(x \\mid D_{t-1}^{N_{t}}\\right)=\\prod_{i=1}^{t} p_{i}\\left(x_{i} \\mid D_{t-1}^{N_{t}}\\right) \\\\\n& -N \\sum_{i \\in \\mathcal{N}_{j}} \\sum_{k=1}^{t} p\\left(X_{i_{1}}=x_{i_{1}}\\right) \\log p\\left(X_{i_{2}}=x_{i_{2}}\\right)+\\log N \\sum_{i \\in \\mathcal{N}_{j}} \\operatorname{dim} X_{i_{j}}\n\\end{aligned}\n$$  \n(2)Factorized Distribution Algorithm FDA  \n$$\np_{i}(x)=\\prod_{t=1}^{1} p_{i}\\left(x_{i_{t}} \\mid x_{i_{t}}\\right)\n$$  \n(3)Polytree Approximation of Distribution Algorithms PADA\n(4)Estimation of Bayesian network Algorithm EBNA\n(5)Bayesian Optimization Algorithm, BOA  \n$$\np(X)=\\prod_{i=1}^{n} p\\left(X_{i} \\mid \\prod_{i=1}^{n}\\right)\n$$  \n(6)Mixture models  \n$$\nf_{N}(x ; \\mu, \\Sigma)=\\prod_{t=1}^{n} f_{N}\\left(x_{i} ; \\mu_{i}, \\sigma_{i}^{2}\\right)=\\prod_{t=1}^{n} \\frac{1}{\\sqrt{2 \\pi} \\sigma_{i}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu_{i}}{\\mu_{i}}\\right)^{2}}\n$$  \nB. EDA approaches in continuous domains  \n- Without dependencies  \nIt has three algorithms:\n(1)The Univariate Marginal Algorithm for continuous domains UMDAc  \n$$\nf_{i}\\left(x ; \\theta^{\\prime}\\right)=\\prod_{t=1}^{n} f_{i}\\left(x_{i}, \\hat{\\theta}_{i}^{\\prime}\\right)\n$$  \n(2)Stochastic Hill Climbing with Learning by Vector of Normal Distributions SHCLVND  \n(3)an extension of Boolean PBIL algorithm to continuous spaces PBILc  \n- Bivariate dependencies $M I M I C_{s}^{G}$\n- Multiple dependencies  \nIt has six algorithms:\n(1)Estimation of multivariate normal algorithm $E M N A_{\\text {global }}$\n(2)Estimation of multivariate normal algorithm adaptive $E M N A_{a}$\n(3)Estimation of multivariate normal algorithm icremental $E M N A_{i}$\n(4)Estimation of Gaussian Network Algorithm, EGNA Including FORMULA_39\n(5)Iterated Density Evolutionary Algorithms IDIA\n(6)Mixture models",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:05",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for insurance investment models that consider multiple life insurance policies?",
      "topics": [
        "search"
      ],
      "answer": "The algorithmic approach aims to create a more realistic insurance investment model by considering multiple life insurance policies, where the death compensation Z(t) is the sum of individual policies, calculated using premium I(t) and premium-payout ratios η(t). A data-driven model approximates the expectation payout J(t ; X, β) using historical data to estimate mortality rate p(t), cash value V(t), death compensation Z(t), and disposable cash C(t), aiming to optimize an individualized insurance portfolio plan.",
      "chunk_id": 2089,
      "paper_id": "A Coevolutionary Estimation of Distribution Algorithm for Group Insurance Portfolio",
      "paper_title": "A Coevolutionary Estimation of Distribution Algorithm for Group Insurance Portfolio",
      "paper_year": "2022",
      "chunk_content": "$$\nu(c)=\\frac{1}{1-\\gamma} c^{1-\\gamma}\n$$  \nwhere $\\gamma>0$ is the coefficient of relative risk aversion.\nHowever, since more and more insurance products have arisen, only considering a single insurance policy is not realistic enough. Therefore, an insurance investment model [6],\nwhich has taken several types of life insurance policies into consideration, has been proposed. In this model, the wealth accumulation function is the same as the previous models, but the death compensation $Z(t)$ is the sum of policies [6]  \n$$\nZ(t)=Z_{1}(t)+\\cdots+Z_{k}(t)=\\frac{I_{1}(t)}{\\eta_{1}(t)}+\\cdots+\\frac{I_{k}(t)}{\\eta_{k}(t)}\n$$  \nwhere $Z_{i}(t)$ is the death compensation of the $i$ th life insurance policy; $I_{i}(t)$ is the premium of the $i$ th life insurance policy; and $\\eta_{i}(t)$ is the premium-payout ratio of the $i$ th life insurance policy.  \nIn the above model, different policies are with different premium-payout ratios at different time. However, it is obvious that the best investment plan is to choose the policy with the highest premium-payout ratios. Even though different policies are considered, this model oversimplifies the payout mechanism and thus, cannot suit the practical market well.  \nActually, few companies simply offer life insurance policies with only death compensation in reality. Endowment policies [19] with the function of savings are much more popular. Traditional models cannot fully express the relationship between the payout and the premium.  \nIn our previous work [7], a data-driven model is proposed to solve the insurance investment problem considered several types of hospitalization policies in addition to endowment policies. The statistical value of the total payout at a specific time $t$ is approximated as  \n$$\nJ(t ; X, \\beta)=[1-p(t)] V(t)+p(t) Z(t)+C(t)\n$$  \nwhere $\\boldsymbol{X}$ denotes the investment plan of endowment policies and $\\beta$ is the selected hospitalization policy. $V(t)$ is the cash value, which cannot be extracted by the policyholder until the termination of the policy; $Z(t)$ is the death compensation, which can be gain after the death of the insured; $C(t)$ is the cash the policyholder can be disposed of at will; and $p(t)$ is the mortality rate of the insured.  \nIn this data-driven model, the historical data of the death toll are utilized to estimate the mortality rate of the insured. The historical incidence rate is utilized to estimate the medical cost and calculate the optimal solution of $\\beta$. Historical data of the payout are utilized to evaluate the cash value and death compensation of each endowment policy. The historical data of the income are utilized to evaluate the investable amount.  \nBy using these huge amounts of historical data, an approximation of the expectation payout of the insurance portfolio problem can be gained and an individualized insurance portfolio plan can be optimized precisely for a specific insured.\n2) Group Model: However, in some situations, the policyholders care about how to get the most payout for a whole group instead of a single person when making an insurance portfolio plan.  \nMany researchers discover this phenomenon and study the insurance investment model for the whole group [8]-[10]. Huang et al. [8] considered the investment problem for the whole family instead of a single policyholder. Different wealth accumulation functions are considered before and after the death or retirement of parents.  \nBefore the death or retirement of parents, i.e., $t<\\tau$, since there are still annual incomes from parents, the wealth accumulation function is the same as (1). After the death or retirement of parents, i.e., $t>\\tau$, since there are no annual incomes from parents, the wealth accumulation function changes to  \n$$\nd M(t)=-c(t) \\mathrm{dt}+d \\alpha(t)+M(t) \\beta(t) \\mathrm{dt}\n$$",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:06",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the AMS (Adaptive Mean Shift) within iMAMaLGam contribute to aligning the distribution estimate with the direction of improvement, and what specific parameter adjusts the proportion of AMS-altered solutions?",
      "topics": [
        "constraints"
      ],
      "answer": "Within iMAMaLGam, the AMS mechanism shifts solutions in the direction of the difference between the means of subsequent generations, denoted as $\\overline{\\boldsymbol{\\mu}}^{\\text {Shift }}(t)=\\overline{\\boldsymbol{\\mu}}(t)-\\overline{\\boldsymbol{\\mu}}(t-1)$. This shift aims to move solutions further down the slope of improvement. To control the proportion of solutions altered by AMS, a parameter $\\alpha$ is used, where $\\alpha 100 \\%$ of the newly sampled solutions are moved in the direction of the AMS, according to the equation $\\boldsymbol{x} \\leftarrow \\boldsymbol{x}+2 \\overline{\\boldsymbol{\\mu}}^{\\text {Shift }}(t)$. The value of $\\alpha$ is calculated as $\\alpha=\\frac{1}{2} \\tau \\frac{n}{n-n^{\\text {elinist }}}$, where $n$ is the population size, $n^{\\text {elinist }}$ is the number of elitist solutions maintained, and $\\tau$ determines the number of selected solutions, with $\\lfloor\\tau n\\rfloor$ solutions being selected. This ensures that the distribution estimate is better aligned with the direction of improvement by selecting both unaltered and AMS-altered solutions.",
      "chunk_id": 730,
      "paper_id": "A novel population-based multi-objective CMA-ES and the impact of different constraint handling techniques",
      "paper_title": "A Novel Population-based Multi-Objective CMA-ES and the Impact of Different Constraint Handling Techniques",
      "paper_year": "2014",
      "chunk_content": "The following is a brief description of the MO-EDA that we compare our results to. The MO-EDA follows the above framework and was previously called iMAMaLGam-X ${ }^{+}$, indicative of being an extension of an earlier version called iMAMaLGam-X and the SO-EDA iAMaLGam (the internal mechanisms of which are used in each cluster in the multi-objective framework). For a more in-depth explanation the interested reader is referred to literature [6, 9]. In the remainder however, for simplicity, we shall generally use the acronym iMAMaLGam to indicate the frameworkleveraged MO version of iAMaLGam. Moreover, we shall use iMAMaLGam ${ }^{\\mathrm{Old}}$ to denote the use of the previously existing framework without the above mentioned new aspects.  \nAfter clustering and explicit cluster registration, a Gaussian distribution is estimated in each of the clusters and adapted using the combination of AMS, SDR and AVS as in [6]. The AMS is computed as the difference between the means of subsequent generations, i.e. $\\overline{\\boldsymbol{\\mu}}^{\\text {Shift }}(t)=\\overline{\\boldsymbol{\\mu}}(t)-\\overline{\\boldsymbol{\\mu}}(t-$ 1). If the AMS-altered solutions violate box constraints, a shrinking factor is used to keep the solution feasible. Specifically $\\alpha 100 \\%$ of the newly sampled solutions are moved in the direction of the AMS: $\\boldsymbol{x} \\leftarrow \\boldsymbol{x}+2 \\overline{\\boldsymbol{\\mu}}^{\\text {Shift }}(t)$. The rationale is that solutions so changed are further down the slope. Selecting those solutions as well as solutions not changed by AMS aligns the distribution estimate better with the direction of improvement. In a population of size $n$ where $\\lfloor\\tau n\\rfloor$ solutions are selected, $n^{\\text {elinist }}$ solutions are maintained and $n-n^{\\text {elinist }}$ new solutions are generated, proportioning the selected solutions perfectly between unaltered and AMS-altered solutions requires $\\alpha\\left(n-n^{\\text {elinist }}\\right)=\\frac{1}{2} \\tau n$ and thus $\\alpha=\\frac{1}{2} \\tau \\frac{n}{n-n^{\\text {elinist }}}$.  \nBy estimating the distribution only using the selected solutions of the current generation, the density contours can become aligned with directions in which only solutions of similar quality can be found. Methods that only adaptively scale the covariance matrix, such as SDR-AVS, do no help\nmuch as it almost solely increases search effort in the futile direction perpendicular to the direction of improvement. In SDR-AVS, a distribution multiplier $e^{\\text {Multiplist }}$ is maintained by which the covariance matrix is multiplied in each generation. This multiplier is scaled up if improvements are found that are more than standard deviation away from the mean and scaled down if no improvements are found.  \nIn iMAMaLGam memory decay is used in estimating the covariance matrix and the AMS in generation $t$ as follows:  \n$$\n\\begin{aligned}\n& \\hat{\\boldsymbol{\\Sigma}}(t)=\\left(1-\\eta^{\\Sigma}\\right) \\hat{\\boldsymbol{\\Sigma}}(t-1)+\\eta^{\\Sigma} \\frac{1}{|\\boldsymbol{\\beta}|} \\sum_{i=0}^{|\\boldsymbol{\\beta}|-1}\\left(\\boldsymbol{\\mathcal { S }}_{i}-\\overline{\\boldsymbol{\\mu}}(t)\\right)\\left(\\boldsymbol{\\mathcal { S }}_{i}-\\overline{\\boldsymbol{\\mu}}(t)\\right)^{T} \\\\\n& \\overline{\\boldsymbol{\\mu}}^{\\text {Shift }}(t)=\\left(1-\\eta^{\\text {Shift }}\\right) \\overline{\\boldsymbol{\\mu}}^{\\text {Shift }}(t-1)+\\eta^{\\text {Shift }}(\\overline{\\boldsymbol{\\mu}}(t)-\\overline{\\boldsymbol{\\mu}}(t-1)) .\n\\end{aligned}\n$$  \nValues for the learning-rate parameters $\\eta^{\\Sigma}$ and $\\eta^{\\text {Shift }}$ were determined empirically [9]. The cluster sizes computed from the selected solutions were set according to guidelines from recent literature on SO [9]: FORMULA_82.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:10",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners configure the RK-EDA for solving Flow Shop Scheduling Problems (FSSP), specifically regarding initial variance and elitism?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "RK-EDA",
        "Flow Shop Scheduling Problems",
        "Parameter Configuration",
        "Initial Variance",
        "Elitism"
      ],
      "answer": "When configuring the RK-EDA for the FSSP, practitioners should set the initial variance to 0.15, as this value has been shown to produce competitive results. Furthermore, practitioners should not consider elitism, as preliminary experiments indicate that elitism does not improve the performance of RK-EDA on FSSP instances.",
      "chunk_id": 12303,
      "paper_id": "RK-EDA- A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_title": "RK-EDA: A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "In addition to the reviewed algorithms, other permutation based EDAs exist but were not included in the previous comparison because their results are not reported on the selected problems. GM-EDA [4] exhibits the best results on FSSP when hybridised with local search procedures such as variable neighbourhood search (VNS). We therefore compare RK-EDA with GM-EDA on a selected set of FSSP instances. In order to compare the two EDAs in a fair way, we use the reported results of GM-EDA without VNS.  \nWe use the same set of parameters presented by the authors in [4] except that we do not consider elitism. This is because preliminary experiments show that  \nTable 5. Parameter values and stopping criteria for experiments on FSSP based on TFT  \nTable 6. Average TFT for FSSP  \nelitism does not improve the performance of RK-EDA. In addition, 0.15 initial variance value particularly produced competitive results for FSSP instances. Table 5 shows the parameters of RK-EDA, which are adapted for solving the FSSP.  \nIn Table 6, we present the average fitness over 20 runs for RK-EDA as well as GM-EDA. The results are based on the Total Flow Time (TFT) objective function  \nand we compare using instances of $\\mathrm{FSSP}_{s}$ and $\\mathrm{FSSP}_{l}$. The results for GM-EDA have been extracted from [4]. Values that are significantly better are presented in bold. The results show that the GM-EDA is significantly better on two of the smallest problems (tai20-5-0 and tai20-10-1) while RK-EDA shows significant improvement on the largest problems (tai100-20-0 and tai100-20-1). There are however no significant difference between the performance of the algorithms on other instances.  \nResults from comparing RK-EDA with GM-EDA as shown in Table 6 also indicate that RK-EDA is competitive and should be further explored to solve bigger and more complex problems.\nEDAs based on RKs have previously been considered the poorest of permutation based EDAs [3]. One of the problems posed by RKs is attributed to the variety of ways of representing an ordering [13]. In this paper, we introduce a novel RK based EDA (RK-EDA) which addresses this by rescaling the RKs uniformly. This approach improves the information captured by the probabilistic model. Furthermore, RK-EDA uses a cooling scheme to manage the rate of exploration/exploitation of the search space such that there is better exploration at the start of the algorithm and better exploitation of already found good pattern as the search progresses.  \nFurthermore, learning a probability structure is considered the most expensive operation in EDAs [2], we present a simple model, which only saves the mean of solutions in a selected population. This is relatively computationally efficient. RK-EDA whose procedure is comparatively simple produces very competitive results. It outperforms other reviewed continuous EDAs. It is also competitive with the best permutation EDAs in general.  \nRK-EDA's most competitive performance is seen on FSSP and the least on QAP. It's performance on FSSP gets more competitive as the problem size increases presenting the best results on the largest of the considered FSSP instances. The performance of RK-EDA on larger problems is therefore recommended for further investigation.  \nIn addition, the use of local search has been reported to improve the performance of the GM-EDA, hybridisation of the RK-EDA may also improve its performance.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:11",
      "generation_style": "practical_application"
    },
    {
      "question": "How does the hybrid MOEA for optimal gene subset selection, which combines NSGA-II with EDA, generate a new population in each iteration, and what role does the learning dataset play in this process?",
      "topics": [
        "selection"
      ],
      "answer": "The hybrid MOEA generates a new population through the following steps: First, a learning dataset $D_{n}$ is created by performing crowding tournament selection on the current population $P O_{n}$, where the size of $D_{n}$ is M, which is less than the population size Q. Then, the Estimation of Distribution Algorithm (EDA) learns from this learning dataset $D_{n}$ to generate an offspring population $O_{n}$ of size Q. The learning dataset $D_{n}$ guides the EDA in creating new individuals that are likely to have better fitness based on the characteristics of the selected individuals in $D_{n}$.",
      "chunk_id": 5621,
      "paper_id": "Optimal Genes Selection with a New Multi-objective Evolutional Algorithm Hybriding NSGA-II with EDA",
      "paper_title": "Optimal genes selection with a new multi-objective evolutional algorithm hybriding NSGA-II with EDA",
      "paper_year": "2008",
      "chunk_content": "3.2.1 Initial gene pool. Because the number of genes in the dataset is always huge and some of them are not useful for classification, it is necessary to narrow down genes from many thousand down to the order of $10^{2}$ to speed up searching with MOEAs which may cost a lot of running time. There are many filter approaches can do this. Instead of using principle component analysis  \n(PCA), which is most common way, we use the ratio of between-groups to within-groups sum of squares (BSS/WSS) given by Dudoit[9].  \n$$\n\\operatorname{Rank}(x)=\\frac{B S S(x)}{W S S(x)}=\\frac{\\sum_{j=1}^{n} \\sum_{j=1}^{c} I\\left(y_{j}=j\\right)\\left(\\bar{x}_{, j}-\\bar{x}\\right)^{2}}{\\sum_{i=1}^{n} \\sum_{j=1}^{c} I\\left(y_{j}=j\\right)\\left(x_{i}-\\bar{x}_{, j}\\right)^{2}}\n$$  \nHere, for gene $x, x_{i}$ is the expression value on the ith sample, n is the number of samples and c is the number of sample types, $\\bar{x}$ is the average expression value in all n samples, $\\bar{x}_{, j}$ is the average expression value in samples belonging to class j. $I\\left(y_{j}=j\\right)$ is a judging function, whose value equals one when the class label of sample is j , otherwise it returns zero. Rank(x) calculates the ratio of between-groups to within-groups sum of squares and its value will be big if gene x can perfectly distinguish the c types on all n samples.  \nIn order not to miss discriminative genes as much as possible, we consider to calculate genes' BSS/WSS rank in the conditions of all distinct combinations of c sample types. For each combination, best $S$ genes will be reserved in the gene pool. For example, supposing the total number of sample classes is 3 and donated as 1 , 2 and 3 , all distinct combinations are $\\{1,2\\},\\{2,3\\},\\{1,3\\}$ and $\\{1,2,3\\}$, thus genes' BSS/WSS rank will be calculated in these four conditions. In that way, those genes which can separate only some sample types are able to be kept. After all, this is a preprocessing step and an optimal gene subset may be composed of complementary genes that individually do not separate well the data.\n3.2.2 Hybriding NSGA-II with EDA. Given a gene pool $\\zeta$, each possible optimal gene subset is represented by an individual with fixed sized binary string whose length equals the number of genes included in $\\zeta$. If the value of the ith bit in the individual is one, it means that the corresponding gene i in $\\zeta$ will be included in the optimal gene subset. The fitness functions used in our method is given by the formula (2). The new hybrid MOEA for optimal gene subset selection is shown in table I.  \nTABLE I. HYBRID MOEA FOR OPTIMAL GENE SUBSET SELECTION  \n1. Generate a population $P O_{n}$ composed of Q uniformly generated individuals. $\\mathrm{u}=1$.\n2. while the stopping condition is not met do\n3. Calculate the multi-objective fitness functions .\n4. Rank the population using dominance criteria .\n5. Calculate crowding distance.\n6. Perform crowding tournament selection to generate learning dataset $D_{n},\\left|D_{n}\\right|=\\mathrm{M}<\\mathrm{Q}$.\n7. Perform EDA to generate offspring population $O_{n}$ by learning $D_{n},\\left|O_{n}\\right|=\\mathrm{Q}$.\n8. Combine $P O_{n}$ and offspring $O_{n}$\n9. Rank the mixed population .\n10. Calculate the crowding distance using dominance criteria.\n11. Generate $P O_{n+1}$ with the best Q members of the combined population $P O_{n}$ and offspring $O_{n}$ by crowding tournament selection .\n12. FORMULA_48.\n13. Return the best individuals found so far .",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:14",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is the key difference in how the EDA-EP algorithm uses the EDA D value compared to the standard EDA operation described, and how does this impact individual offspring generation?",
      "topics": [
        "control"
      ],
      "answer": "In the standard EDA operation, the EDA D value (representing the means of the first $M_1$ good individuals) is used for EP variation with a probability $P_{EDA}$. If a random number is greater than $P_{EDA}$, EDA D is used for EP variation. In contrast, EDA-EP transfers the EDA operation by using the percentage of good individuals of parents to *estimate* the individuals' best individual value. EDA-EP uses this estimate to influence the selection of parents for mutation and crossover, ultimately affecting the offspring individuals generated, whereas the standard EDA uses EDA D directly for variation conditionally.",
      "chunk_id": 6819,
      "paper_id": "Research and New Development of Application of the Estimation of Distribution Algorithms",
      "paper_title": "Research and New Development of Application of the Estimation of Distribution Algorithms",
      "paper_year": "2009",
      "chunk_content": "EDA operation can be described as follows:  \n1) set up a certain proportion of the optimal number of individual $M_{1}=\\mathrm{M} \\cdot P_{L}, 0<P_{L}<1$;\n2) According to the value of the father of individual to sort\n3) Get the means of the first $M_{1}$ good individual of parent individual, recorded as EDA D;\n4) Produce a random number, if the random number is greater than the EDA set probability $P_{E D A}$, will be used EDA D for EP variation operation, and produce a probability estimate \"best\" of the individual offspring.\nEDA-EP realizes the step description to be as follows:\n1)Generate a random initialization individual, $\\mathrm{t}=0$, initialization individual, that is nearest neighbor of control factor a and the variation step b.\n2)Updating of the individual, and calculate the individual fitness.\n3)According to the father of the individual to sort of size (corresponding to change $\\mathrm{a}, \\mathrm{b}$ in the order), directly retain a  \ncertain percentage of good individual; may be appropriate to introduce cross operator.\n4)Transfer the EDA operation. Use the percentage of good individual of parents to estimate the individuals' best individual value.\n5)Mutation. Mutant the parents which are selected and crossed, then produce their own offspring individuals, some of which according to certain probability to generate the offspring individuals.\n6) Calculate the fitness of offspring individual.\n7) Compare parents with offspring individuals one-to-one, the individual of good performance for the winner, as the parent cycle into the next round.\n8)If achieves the optimal solution , stop the algorithm ;Otherwise, $\\mathrm{t}=\\mathrm{t}+1$, go to Step 3.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:16",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing an online surrogate-based Approximate History Matching (AHM) method, and choosing between Polynomial Chaos Expansion (PCE), Gaussian Process (GP), and Radial Basis Function (RBF) models, what programming considerations should be taken into account regarding the trade-offs between model complexity, computational cost, and the need for dynamic sampling?",
      "topics": [
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "For online surrogate-based AHM, the choice of PCE, GP, or RBF models involves trade-offs. PCE and RBF models are easier to train and have explicit mathematical representations, making them computationally efficient for single evaluations. However, their performance degrades significantly as variable dimension and problem nonlinearity increase, necessitating dynamic sampling and sophisticated management to focus on local regions. GP models, while potentially more accurate for complex problems, typically have higher computational cost for training and evaluation, especially with large datasets, impacting the overall AHM runtime. Therefore, the developer must balance surrogate model complexity with the computational budget available for dynamic sampling and model retraining during the AHM process.",
      "chunk_id": 2373,
      "paper_id": "A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification",
      "paper_title": "A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification",
      "paper_year": "2022",
      "chunk_content": "In the development of oil and gas, it is necessary to establish accurate and reliable numerical models of the underground reservoir for management and optimization (Liu and Oliver 2005, Oliver and Reynolds, 2008). However, geological properties such as permeability and porosity bring nonnegligible uncertainty to the numerical model (Liao and Zhang, 2015). AHM is an effective and efficient approach to reduce the uncertainty of model parameters by correcting numerical simulation results to match historical observations (Oliver and Chen, 2011). Under the Bayesian framework, AHM can be transformed into a posterior probability sampling problem (Stuart, 2010). In the last few decades, various numerical methods have been developed to solve the history matching problem, such as ensemble-based data assimilation methods and optimization algorithms (Emerick and Reynolds, 2013; Liao et al., 2019; Ma et al., 2020). However, these numerical methods usually need\na lot of numerical simulations, and a single simulation run may spend minutes to hours of CPU time (Tang et al., 2020, Xue et al., 2022). Therefore, it is still an open question how to conduct AHM at a reasonable computational cost.  \nBecause of non-invasive features and ease of implementation, integrating the data-driven surrogate models into AHM methods has been widely studied to tackle this problem (Saad et al., 2009, Zeng and Zhang, 2010; Li et al., 2011; Elsheikh et al., 2014). According to the construction method of surrogate models, the surrogate-based AHM methods can be divided into online and offline. The online method is to continuously sample and dynamically build the surrogate models during the solving process. Li and Lin (2015) developed an adaptive importance sampling algorithm for history matching using a mixture of polynomial chaos expansions (PCE). Chang et al. (2017) proposed a surrogate-assisted iterative ensemble smoother algorithm combining PCE and interpolation models. To gradually reduce the surrogate error, Zhang et al. (2018)  \n[^0]\n[^0]:    a Corresponding author. School of Petroleum Engineering, China University of Petroleum, Qingdao, China.  \nE-mail address: zhangkai@upc.edu.cn (K. Zhang).  \n[IMAGE_0]  \nFig. 1. Architecture of the proposed HRCN surrogate model.\ndesigned an adaptive multi-fidelity Gaussian process (GP) model and applied it to Markov chain Monte Carlo (MCMC). Ma et al. (2021) introduced a multimodal differential evolution algorithm for history matching and used a radial basis function (RBF) model as the proxy. The surrogate models used in online methods are usually traditional machine learning models, such as PCE, GP, RBF, etc. These surrogate models have explicit mathematical representation and are easy to train. However, as the variables dimension and the nonlinear degree of the problem increase, the surrogate performance will decrease significantly. Therefore, it is often suitable for approximating local regions in the search space, which requires dynamic sampling and sophisticated management.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:18",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the effectiveness of reactive power control using smart inverters evaluated in the context of voltage stabilization?",
      "topics": [
        "control"
      ],
      "answer": "The effectiveness is evaluated by minimizing the sum of the absolute difference between the voltage magnitude at each bus with DERs installed ($V_j$) and 1 p.u., as represented by the objective function: $\\min _{Q_{j}} \\sum_{j=1}^{M}\\left|1-V_{j}\\right|$, where $Q_j$ represents the reactive power at bus j and M is the total number of buses with DERs.",
      "chunk_id": 2167,
      "paper_id": "Data-Enabled Reactive Power Control of Distributed Energy Resources via a Copula Estimation of Distribution Algorithm",
      "paper_title": "Data-Enabled Reactive Power Control of Distributed Energy Resources via a Copula Estimation of Distribution Algorithm",
      "paper_year": "2022",
      "chunk_content": "A common feature of (weak) distribution feeders is the high line resistance compared to the line reactance, i.e., a high $R / X$ ratio. This exacerbates the voltage difference $\\Delta V$ across the line, as can be deduced from the following approximation [5]:  \n$$\nV_{1}-V_{2}=\\Delta V \\approx R \\cdot P+X \\cdot Q\n$$  \n[^0]where $P$ and $Q$ are active and reactive power (in W and var), respectively. Equation (1) shows that variable active power injection via DERs increases voltage, but reactive power absorption can balance the voltage rise. Smart inverters can counteract voltage fluctuations using reactive power on the same timescale as solar irradiance fluctuations, as opposed to slow controllable devices such as OLTCs [17]. We formulate voltage stabilization to 1 p.u. as an optimization problem using smart inverter reactive power as decision variable as follows:  \n$$\n\\begin{aligned}\n& \\min _{Q_{j}} \\sum_{j=1}^{M}\\left|1-V_{j}\\right| \\\\\n& \\text { s.t. } P_{i}=\\left|V_{i}\\right| \\sum_{k=1}^{N}\\left|V_{k}\\right|\\left(G_{i k} \\cos \\left(\\theta_{i}-\\theta_{k}\\right)\\right. \\\\\n& +B_{i k} \\sin \\left(\\theta_{i}-\\theta_{k}\\right)), \\\\\n& \\forall i, k \\in \\mathcal{I}, \\\\\n& Q_{i}=\\left|V_{i}\\right| \\sum_{k=1}^{N}\\left|V_{k}\\right|\\left(G_{i k} \\sin \\left(\\theta_{i}-\\theta_{k}\\right)\\right. \\\\\n& \\left.+B_{i k} \\cos \\left(\\theta_{i}-\\theta_{k}\\right)\\right), \\\\\n& \\forall i, k \\in \\mathcal{I}, \\\\\n& Q_{j} \\leq Q_{j} \\leq \\bar{Q}_{j}, \\\\\n& \\forall j \\in \\mathcal{J}, \\\\\n& \\forall j \\in \\mathcal{J}, \\\\\n& S_{j}^{2}=\\bar{Q}_{j}^{2}+P_{j}^{2}, \\\\\n& \\forall j \\in \\mathcal{J} .\n\\end{aligned}\n$$  \nIn the formulation above, the set of all buses $\\mathcal{N}$ with index set $\\mathcal{I}=\\{1,2, \\ldots, N\\}$ is indexed by $i$ and $k$, i.e., $\\left\\{\\mathcal{N}_{i, k}\\right\\}_{i, k \\in \\mathcal{I}}$. Similarly, the set of all buses with DERs installed is $\\left\\{\\mathcal{M}_{j, l}\\right\\}_{j, l \\in \\mathcal{J}}$ with $\\mathcal{J}=\\{1,2, \\ldots, M\\}$ and $\\mathcal{M} \\subset \\mathcal{N}$. Furthermore, $G_{i k}$ and $B_{i k}$ represent elements from the real and imaginary part of the admittance matrix, respectively, and $\\theta$ the voltage phase angle. The transformer primary side voltage is assumed to be constant and 1 p.u., therefore $V_{j}$ in (2a) is expressed in p.u. The optimization problem in (2a)-(2e) differs from the classic optimal power flow (OPF) problem in that (2e) applies to the DERs in $\\mathcal{M}$ rather than all buses in $\\mathcal{N}$ and in that the voltage phase angle is not explicitly constrained [19]. The formulation in (2a)-(2e) disregards line limits because the voltage magnitude is often the most limiting factor when it concerns DER hosting capacity [20]. However, such a constraint could be included in future work and active power curtailment could be used to satisfy this constraint if necessary.  \nEquation (2f) determines the reactive power limit as a function of the inverter rated capacity $S$ (in VA). For the inverters, Watt priority is assumed, i.e., real power is not curtailed to enable more reactive power control and the reactive power limit $\\bar{Q}_{i}$ therefore depends on the active power output and the inverter rated capacity. There are no further restrictions on reactive power output, so $Q_{j}$ can assume any value that satisfies (2f). Watt priority with undersized inverters would limit the ability for reactive power support during the times when it is most needed, i.e., when high solar PV generation leads to overvoltages. To enable voltage control at all times, inverters are oversized by $10 \\%$ compared to the PV DC power capacity. Therefore, even for solar PV operating at rated DC  \n[^0]:    ${ }^{1}$ Note that population based methods such as PSO assume some dependence structure that is encoded by the control parameters [18].  \npower, $42 \\%$ of the reactive power remains available for voltage control.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:20",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when scheduling between continuous casting (CC) and hot rolling (HR) processes, considering the objective function and constraints?",
      "topics": [
        "algorithm"
      ],
      "answer": "The primary objective is to minimize both the continuous casting and rolling (CCR) mode and the interval between the CC and HR stages for all slabs. This is achieved by optimizing an objective function subject to constraints that ensure proper sequencing and timing, including setup times between casts and rolling units, while also maintaining a specified linkage mode range using a flexible coefficient, $\\alpha_{p}$, to adjust the linkage mode interval of each rolling unit. The constraints also enforce that each cast is allocated to only one continuous casting machine (CCM) and processed continuously.",
      "chunk_id": 2246,
      "paper_id": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_title": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_year": "2022",
      "chunk_content": "$s_{p, i}^{R} \\quad$ starting time of slab $i$ in rolling unit $p$ at HR stage.\n$v_{i} \\quad$ interval between CC-HR of slab $i$.\nThe mathematical model is formulated as follows.  \n$$\n\\min F=\\left(\\lambda_{1} \\sum_{i=1}^{n} k \\cdot z_{i, k}+\\sum_{i=1}^{n}\\left(s_{p, i}^{R}-s_{b, i}^{C}-t^{C}\\right)\\right)\n$$  \nSubject to  \n$$\n\\begin{gathered}\n\\sum_{m=1}^{M} X_{b, m}=1 \\\\\n\\sum_{d=1, j=n}^{n^{C}-1} Y_{b, d, m}=\\sum_{d=0, j=n}^{n^{C}-1} Y_{b, d, m}=X_{b, m} \\\\\ns_{b}^{C}+T_{b}^{C}+U^{C}-b i g M\\left(3-X_{b, m}-X_{d, m}-Y_{b, d, m}\\right) \\leq s_{d}^{C} \\\\\ns_{b, i}^{C}=s_{b}^{C}+\\left(a_{b, i}^{C}-1\\right) t^{C} \\\\\n\\sum_{p=1, j=q}^{n^{C}-1} Y_{p, q}=\\sum_{p=0, j=q}^{n^{C}-1} Y_{q, p}=1 \\\\\ns_{p}^{R}+T_{p}^{R}+U^{R}-b i g M\\left(1-Y_{p, q}\\right) \\leq s_{q}^{R} \\\\\ns_{p, i}^{R}=s_{p}^{R}+\\left(a_{p, i}^{R}-1\\right) t^{R} \\\\\n\\sum_{k=1}^{1} Z_{i, k}=1 \\\\\nv_{i}=s_{p, i}^{R}-s_{b, i}^{C}-t^{C} \\\\\n\\sum_{k=2}^{3}\\left(1+\\alpha_{p}\\right) T_{k}^{\\min } Z_{i, k} \\leq v_{i} \\leq \\sum_{k=2}^{3}\\left(1+\\alpha_{p}\\right) T_{k}^{\\max } Z_{i, k}\n\\end{gathered}\n$$  \nThe objective function (1) minimizes CCR mode and the interval of all slabs between CC and HR. Constraint (2) ensures each cast is allocated to one CCM. Constraint (3) ensures there is only one predecessor and only one successor for casts processed on the same CCM. Constraint (4) ensures enough setup time between two adjacent casts on one CCM. Constraint (5) shows the CC is continuously processed and the start of each slab can be calculated. Constraint (6) ensures there is only one predecessor and only one successor for rolling units. Constraint (7) ensures enough setup time between two consecutive rolling units. Constraint (8) shows the rolling process is continuous and then the start rolling time of each slab can be calculated. Constraint (9) ensures each slab is processed by one linkage mode. Constraint (10) shows the interval of the slab between the CC stage and HR stage can be calculated. Constraint (11) ensures the interval between CC and HR must be in the specified linkage mode range.  \nIt is worth noting that we proposed a flexible coefficient $\\alpha_{p}$ to adjust the linkage mode interval of each rolling unit, which can reduce the CCR mode slabs, reduce energy consumption and improve production efficiency.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:22",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of truncation selection, specifically with a threshold \\$\\tau=50 \\%\\$, impact the trade-off between Steiner tree cost and convergence time, and what properties of the 'new-EDA' algorithm address this trade-off compared to ACO and PSOTREE?",
      "topics": [
        "optimization"
      ],
      "answer": "Truncation selection, as used in the EDA, selects the best \\$50 \\%\\$ of solutions as elites. While a larger initial population size lowers the Steiner tree cost, it also increases convergence time. The 'new-EDA' algorithm addresses this trade-off by enabling individuals to randomly select the crossover operation, leading to faster convergence compared to ACO (Ant Colony Optimization) and PSOTREE. ACO requires a large number of parameters to retrieve positive feedback of pheromone, and inappropriate parameter settings may lead to unexpected results, whereas 'new-EDA' achieves a Steiner tree cost close to PSOTREE with better convergence time, especially with increasing network size.",
      "chunk_id": 4691,
      "paper_id": "An improved EDA for solving Steiner tree problem",
      "paper_title": "An improved EDA for solving Steiner tree problem",
      "paper_year": "2015",
      "chunk_content": "The size of initial population is critical for the statistical analysis of the algorithm. The bigger the size, the more accurate the probability distribution; however, it needs more time to converge. It is a tradeoff. To this end, a proper size of the initial population may enable the algorithm to obtain optimized cost with little expense and suitable for finding the probability model to describe the probability distribution. A lot of simulation experiments have been carried out in order to get proper size.  \nIn the first scenario, the network has 50 nodes following the power-law topology. Two groups of results have been given. Figure 3 shows how the Steiner tree cost has been affected by the initial population size increment. On the other hand, Figure 4 depicts significant convergence time increment with the growth of the initial population size. The truncation selection operation is used with threshold $\\tau=50 \\%$, which means $50 \\%$ best solutions as the elites individuals are selected. From the test of this scenario, it is readily seen that the Steiner tree cost indeed lowered down with large population size. As aforementioned, the convergence time increases when the population size grows. The burst in Figure 3 is caused by the random selection of the elites. For the scenario of 50 node network, we can compare the tree cost and the corresponding convergence time by using the developed the method. It is not hard to see that the initial population of 160 is the optimized results.  \nFigures 5 and 6 are based on the topologies generated via Inet 3.0. The improved EDA algorithm is marked as new-EDA. The results by using PSOTREE algorithm are obtained from Zhou's work [35], which is widely recognized compared to other algorithms in solving multicast routing optimization. It is worth noting that the developed algorithm is applied on solving multicast routing optimization in\n[IMAGE1]  \nFigure 2. Network topology with 50 nodes generated via Inet 3.0.  \n[IMAGE2]  \nFigure 3. Steiner tree cost with different initial population sizes.\n[IMAGE3]  \nFigure 4. Convergence time with different initial population sizes.\n[IMAGE4]  \nFigure 5. Comparison of Steiner tree cost in different scales.\norder to compare the results with Zhou's work, and the following ant colony optimization (ACO) algorithm. The topology nodes are from 50 to 100, and the number of the group member is $15 \\%$ of the topology nodes. As shown in Figure 5, ACO, which is an intelligence random search algorithm proposed by Dorigo [43]. According to the ants colony optimization algorithm, a large number of parameters are required to retrieve positive feedback of pheromone. Inappropriate parameter settings may lead to the unexpected way. Figure 5 suggests that the Steiner tree cost by employing newEDA is close to those of PSOTREE algorithm [42] on all the test topologies, and it is much better than those of ACO algorithm. On the other hand, the convergence time of adopting new-EDA is faster than the other two algorithms shown in Figure 6 especially with the increment of network size. With the increase of the iterations, the probability distribution is stabilized, and the solution  \n[IMAGE5]  \nFigure 6. Comparison of convergence time in different scales.\napproaches to the optimal. This is because the new EDA algorithm enables the individual to select the crossover operation randomly, which make the algorithm get the solution with less convergence time.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:25",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm such as the Bayesian Optimization Algorithm (BOA), how should practitioners generate new offspring after training the Bayesian Network?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Bayesian Optimization Algorithm",
        "offspring generation",
        "Bayesian Network"
      ],
      "answer": "After training the Bayesian Network in BOA, new offspring are generated in two steps: first, order the nodes to create a suitable sequence of variables, ensuring that the parents of each node are generated before the node itself using ancestral ordering. Second, sample the solution space according to this order, computing the distribution of each variable based on the conditional probability given the values of its parents, and generate a new value according to this distribution.",
      "chunk_id": 5105,
      "paper_id": "Modified Bayesian optimization algorithm for planar array design",
      "paper_title": "Modified Bayesian Optimization Algorithm for Planar Array Design",
      "paper_year": "2012",
      "chunk_content": "Once the structure and the parameters of BN have been trained, new offspring will be generated by sampling the trained network. This procedure is in two steps: first ordering the nodes and then sampling the solution space according to the order.  \nThe purpose of the node ordering is to generate a suitable sequence of variables so that the value of parents of each\nnode will be generated before the generation of the node itself. Following the ancestral ordering, given values of parents of a variable, the distribution of each variable is computed by the corresponding conditional probability, and new value is generated according to this distribution.\nAs described above, the BOA performance greatly depends on the distribution of the current good solutions. However, the initial population for the BOA is randomly generated, and this means that there would be some cases in which this initial sampling of the solution space would not provide a good enough distribution of the considered problem, thus the algorithm hardly converges. To overcome this difficulty, one possibility is to increase the population size; therefore it will increase the quality of the distribution of the good solution, but this solution will be extremely time consuming. In this paper, we propose a new approach developed by adding a suitable mutation operator to the traditional BOA. By introducing a mutation operator, some individuals will be used to explore the space out of the distribution of the supposed good ones and therefore, the algorithm will be less easily trapped at local optimum with respect to the traditional implementation. This is similar to Genetic Algorithms (GA) [5], Population Based Incremental Learning (PBIL) [6], and Compact Genetic Algorithm (CGA) [7], which use mutation as one of most important operator for the solution space. However, in the proposed algorithm, we use a Bayesian Network to represent the probability model and to generate the new offspring. Moreover, we worked with a variable vector, which is much more effective for real-variable problems, as for microwave components design, compared with the use of a probability vector as PBIL and CGA. In our work, we implemented the Modified BOA introducing tournament selection and individual mutation for the optimization of a planar array.\nIn this paper, we present result of modified BOA for Onemax problem as test function and then we apply for planar array design. For all tested problems, 30 independent runs are performed and the results showed here are mean values.\nOnemax problem is defined as sum of bits in the input binary string. The optimum of Onemax is the string of all ones. Figure 1 reports the number of fitness valuations until MBOA finds the optimum solutions. The size of the problems ranges from 100 to 500 bits. The number of fitness evaluation can be approximated by FORMULA_8. The result indicates that the Modified BOA can solve Onemax with an almost linear number of evaluations.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:27",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, what future research is suggested to improve feature selection performance, and what specific aspect of the EDA is targeted for modification?",
      "topics": [
        "selection",
        "EDAs",
        "fitness function"
      ],
      "answer": "The text suggests investigating \"other more effective definition of fitness function for feature selection\" within the EDA. This implies that the current fitness function may not be optimal for identifying eigenvectors with significant discriminative information when using EDA to select eigenvectors in the full space of FORMULA_117.",
      "chunk_id": 6354,
      "paper_id": "Full-space LDA with evolutionary selection for face recognitiont",
      "paper_title": "Full-space LDA with evolutionary selection for face recognitiont",
      "paper_year": "2006",
      "chunk_content": "In this paper, a EDA+full-space LDA approach for the eigenvectors selection in the full space of FORMULA_117 is proposed. EDA is used to pursuit a subset of eigenvectors with significant discriminative information. EDA+Full-space LDA is tested on ORL face image database. Experimental results demonstrate that our method is better than others LDA methods. In future research, we will investigate other more effective definition of fitness function for feature selection.\nThe work is partially supported by the Natural Science Foundation of China(NSFC) under grand No. 60401015 and No. 60518002, the Natural Science Foundation of Anhui province under grand No. 050420201, and the Science Research Fund of MOEMicrosoft Key Laboratory of Multimedia Computing and Communication under grant No. 05071811.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:28",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the improved EDA algorithm perform in estimating the parameters of an ARMAX model under different noise distributions, specifically when comparing the resulting \\(\\hat{F}\\) values for Gaussian, Beta, and Exponential distributions?",
      "topics": [
        "control"
      ],
      "answer": "The improved EDA algorithm estimates parameters for an ARMAX model under different noise distributions. The \\(\\hat{F}\\) values, representing some estimated parameter related to the model, vary depending on the noise distribution. For a Normal distribution N(0,0.255), \\(\\hat{F}\\) is [1, 0.8486]; for a Beta distribution B(2,9), \\(\\hat{F}\\) is [1, 0.8822]; and for an Exponential distribution E(0.5), \\(\\hat{F}\\) is [1, 0.8085]. The algorithm's performance, measured by these \\(\\hat{F}\\) values, differs quantitatively depending on the underlying noise distribution.",
      "chunk_id": 10425,
      "paper_id": "Non-Gaussian Systems Control Performance Assessment Based on Rational Entropy",
      "paper_title": "Non-Gaussian Systems Control Performance Assessment Based on Rational Entropy",
      "paper_year": "2018",
      "chunk_content": "In this simulation, the gain of the controller is chosen as $K=1.2 . v_{t}$ is assumed to follow a unimodal distribution including normal distribution $\\mathrm{N}(0,0.255)$, Beta distribution $\\mathrm{B}(2,9)$ and exponential distribution $\\mathrm{E}(0.5)$. The corresponding parameter estimation results are as follows  \n(1) Normal distribution  \n$$\n\\begin{gathered}\n\\hat{\\theta}=[-0.9219,0.9247,-0.9239,-0.0733] \\\\\n\\hat{F}=[1,0.8486]\n\\end{gathered}\n$$  \n(2) Beta distribution  \n$$\n\\begin{gathered}\n\\hat{\\theta}=[-0.9732,0.9921,-0.9930,-0.0910] \\\\\n\\hat{F}=[1,0.8822]\n\\end{gathered}\n$$  \n(3) Exponential distribution  \n$$\n\\begin{gathered}\n\\hat{\\theta}=[-0.9190,0.9432,-0.9422,-0.1105] \\\\\n\\hat{F}=[1,0.8085]\n\\end{gathered}\n$$  \nThe results show that the parameters of the ARMAX model can be estimated by the improved EDA algorithm under different noises. However, we are more concerned with the noise estimated values and its distribution.  \nNoise estimated values can be obtained by the improved EDA algorithm. There are many ways to describe the estimation effect, such as histogram and kernel density estimation. Since PDF is used in the MEC-based CPA index, the kernel density estimation method for actual noises and estimated noises will be used to show the estimation effect. The corresponding PDF estimation results of actual noises and estimated noises are shown in Figures 4-6.  \n[IMAGE3]  \nFigure 4. PDF estimation of the actual and estimated Gaussian distribution noises.  \n[IMAGE4]  \nFigure 5. PDF estimation of the actual and estimated Beta distribution noises.\n[IMAGE5]  \nFigure 6. PDF estimation of the actual and estimated Exponential distribution noises.  \nAfter identification by the improved EDA algorithm, not only the parameters of the system are obtained but also the distribution of noise is estimated. It is clear that the estimated disturbance distribution is close to the true system disturbance distribution. Hence, the simulation results in this case demonstrate the efficiency of the improved EDA algorithm. With this distribution and the feedback-invariant estimation, the MEC-based indices can be easily computed as shown in Table 1.  \nTable 1. CPA index values using MVC and MEC benchmark.  \nBased on Table 1, the CPA index under MVC and MEC maintain at around 0.82 and 0.94, respectively. It indicates that when the system noise obeys the Gaussian distribution or the other unimodal distribution, there is no significant difference between the minimum variance and the minimum entropy criterion.  \nTo illustrate that MEC-based CPA index is more applicable than MVC-based under the circumstances where the variance may fail. Bimodal distribution noises are selected as an example in the next subsection.",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:30",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model when analyzing evolvability using the Fitness Landscape Partial (FLP) technique?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Fitness Landscape Analysis",
        "Evolvability"
      ],
      "answer": "The algorithmic steps involve using FLP to analyze the ability of different probability-based operators to sample promising regions on fitness landscapes. This includes calculating the evolvability \\(E_{ev}(x_g)\\), which is the probability of a solution \\(x_g\\) with fitness \\(f_{ope}(x_g)\\) not generating offspring of lower fitness. The flag function, \\(flag(x)\\), is used to determine if a solution \\(x\\) has a fitness \\(f(x)\\) less than or equal to the fitness of the current best solution \\(f(x_g)\\). The evolvability is then calculated using the provided formula involving integrals of \\(f_{ope}(x)\\) and \\(flag(x)\\).",
      "chunk_id": 6782,
      "paper_id": "A Self-adaptive Mixed Distribution Based Uni-variate Estimation of Distribution Algorithm for Large Scale Global Optimization",
      "paper_title": "A Self-adaptive Mixed Distribution Based Uni-variate Estimation of Distribution Algorithm for Large Scale Global Optimization",
      "paper_year": "2009",
      "chunk_content": "In this section, the evolvability analysis of different kernel probability distributions is presented in terms of fitness landscape analysis on low dimensional landscapes. Based on the theoretical analysis, an effective self-adaptive heavy tail based sampling operator is proposed to strengthen the search ability of uni-variate EDAs.\nIn fitness landscape analysis, the optimization problems can be expressed as a set of landscapes containing one or more optima [29, 34]. Based on the number of the optima, we also classify the landscapes into smooth or rugged problems. Evolution can thus be viewed as the movement of the population, represented by a set of points (genotypes), towards lower (fitter) areas of the landscape [28]. In order to explore the evolvability of different probability based operators, we adopt partial FLP technique to test the ability of sampling population on more promising regions by different operators on two typical landscapes.  \nFLP that was derived from comprehensive local view for sampling is adopted as an effective tool to analyze the evolvability of given operator on special landscapes. The metric selected for describing the evolvability of different operators is defined as follows:  \n$$\n\\begin{aligned}\n& \\operatorname{flag}(x)= \\begin{cases}1, & \\text { if } f(x) \\leq f\\left(x_{g}\\right) \\\\\n0, & \\text { otherwise }\\end{cases} \\\\\n& E_{e v}\\left(x_{g}\\right)=\\frac{\\int_{-\\infty}^{+\\infty} f_{o p e}(x) \\cdot \\operatorname{flag}(x) d x}{\\int_{-\\infty}^{+\\infty} f_{o p e}(x) d x}\n\\end{aligned}\n$$  \nwhere evolvability $E_{e v}\\left(x_{g}\\right)$ of solution $x_{g}$ with fitness $f_{\\text {ope }}\\left(x_{g}\\right)$ for the EA operator ope is directly tied to the probability of solution FORMULA_45 not generating offspring of lower fitness.  \nSince the difficulty of searching global optimum related to the structure of the fitness landscape closely is now clear, two typical fitness landscapes (i.e. sphere landscape and rugged landscape), which include most of the existing landscapes, are chosen to evaluate the evolvability of Gaussian, Cauchy and mixed probability sampling operators.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:33",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's probabilistic model be assessed based on the variable dependencies it captures, specifically when considering univariate, bivariate, and multivariate models?",
      "topics": [
        "search"
      ],
      "answer": "The quality of an EDA's probabilistic model is reflected in how accurately it captures variable dependencies. In univariate models, such as PBIL, UMDA, IDEA, cGA, and UMDA ${ }_{c}^{G}$, the model assumes complete independence between variables, represented as \\(P(x_{1}, \\ldots, x_{n}) = \\prod_{i=1}^{n} P(x_{i})\\). Bivariate models, like MIMIC, MIMIC ${ }_{c}^{G}$, and algorithms based on optimal dependency-trees, consider pairwise interactions, modeled as \\(P(x_{1}, \\ldots, x_{n}) = \\prod_{i=1}^{n} P(x_{i} \\mid x_{\\pi_{i}})\\), where \\(x_{\\pi_{i}}\\) is the single parent variable of \\(x_{i}\\). The quality, therefore, hinges on whether the chosen model (univariate, bivariate, or multivariate) appropriately reflects the true dependencies within the optimization problem.",
      "chunk_id": 4571,
      "paper_id": "An Estimation of Distribution Algorithm With Cheap and Expensive Local Search Methods",
      "paper_title": "An Estimation of Distribution Algorithm With Cheap and Expensive Local Search Methods",
      "paper_year": "2015",
      "chunk_content": "THIS paper considers the continuous box-constrained global optimization problem  \n$$\n\\begin{aligned}\n& \\min f(x) \\\\\n& \\text { s.t. } \\quad x \\in\\left[a_{i}, b_{i}\\right]^{n}\n\\end{aligned}\n$$  \nwhere $x=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)^{T} \\in R^{n}$ is a decision vector, $\\left[a_{i}, b_{i}\\right]^{n}$ is the feasible region of the search space and $a_{i} \\leq x_{i} \\leq b_{i}$ for $i=1,2, \\ldots, n$, and $f: R^{n} \\rightarrow R$ is the objective function.  \nManuscript received February 27, 2014; revised June 30, 2014 and October 17, 2014; accepted December 14, 2014. Date of publication January 5, 2015; date of current version November 25, 2015. This work was supported in part by the National Basic Research Program ( 973 Program) under Grant 2011CB707104, in part by the China National Instrumentation Program under Grant 2012YQ180132, and in part by the National Natural Science Foundation of China under Grant 61273313.\nA. Zhou is with the Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai 200241, China, and also with the Department of Computer Science and Technology, East China Normal University, Shanghai 200241, China (e-mail: amzhou@cs.ecnu.edu.cn).\nJ. Sun is with the Faculty of Engineering and Science, University of Greenwich, Chatham Maritime, Kent ME4 4TB, U.K.\nQ. Zhang is with the Department of Computer Science, City University of Hong Kong, Hong Kong, and also with the School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, U.K.  \nColor versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.\nDigital Object Identifier 10.1109/TEVC.2014.2387433  \nModern heuristics such as evolutionary algorithms (EAs) [1]-[3] have been attracting much attention for tackling global optimization problems. Estimation of distribution algorithms (EDAs) [4], [5] is an EA paradigm. Unlike traditional EAs, EDAs do not use crossover or mutation operators to generate new trial solutions. Instead, they extract global statistical information from solutions visited so far and build a probabilistic model for modeling distribution of promising solutions. New trial solutions are sampled from the model built. Variable linkage information is considered very important for optimization. In EDAs, variable linkages are often represented by a Bayesian network [6], which can be obtained through various machine learning and statisticallearning techniques [7], [8]. EDAs have been applied to many discrete and continuous optimization problems and more details of EDAs are referred to [6] and [9]-[12].  \nWith proper Bayesian network models, EDAs are able to detect variable linkages and sample high-quality solutions. Based on variable linkages being used, Bayesian network models in EDAs can be categorized into the following three classes [9], [10].  \n1) Univariate Models: It assumes that decision variables are independent. The joint probability of the variables is fully factorized as  \n$$\nP\\left(x_{1}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} P\\left(x_{i}\\right)\n$$  \nExamples of such algorithms include PBIL [13], UMDA [4], IDEA [14], cGA [15], and UMDA ${ }_{c}^{G}$ [16].\n2) Bivariate Models: Pairwise variable interactions are considered as  \n$$\nP\\left(x_{1}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} P\\left(x_{i} \\mid x_{\\pi_{i}}\\right)\n$$  \nwhere $x_{\\pi_{i}}$ is the single parent variable of $x_{i}$. Examples include MIMIC [17], MIMIC ${ }_{c}^{G}[16]$ and the algorithm based on optimal dependency-tree [18].\n3) Multivariate Models: Multivariate interactions are considered as  \nFORMULA_12",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:35",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of deriving the transmission ratios (i_1, i_2, i_3, i_R) for the Ravigneaux planetary gear system, as it relates to optimization within the context of Estimation of Distribution Algorithms (EDAs)?",
      "topics": [
        "optimization"
      ],
      "answer": "The derived transmission ratios (i_1, i_2, i_3, i_R), which define the relationships between input and output speeds for each gear, serve as constraints or objectives in an optimization problem. Specifically, these ratios, calculated using the number of gear teeth (N_0, N_1, N_2, N_3, N_4, N_6), are used to formulate a problem where the goal is to find the optimal number of gear teeth that best fulfill imposed transmission ratio requirements. This optimal configuration can then be integrated within an Estimation of Distribution Algorithm (EDA) framework to efficiently search the solution space for the most suitable gear design.",
      "chunk_id": 6356,
      "paper_id": "Teeth-Number Synthesis of a Multispeed Planetary Transmission Using an Estimation of Distribution Algorithm",
      "paper_title": "Teeth-number synthesis of a multispeed planetary transmission using an estimation of distribution algorithm",
      "paper_year": "2006",
      "chunk_content": "Figure 1 shows a planetary transmission of the Ravigneaux type with three forward and one reverse gears used in automobiles [36,37]. A kinematic diagram of the transmission is available in Fig. 2, where the broad planet gear is shown as two compound gears 2 and 3 . Based on the clutch/brake activation required in each gear (Table 1), it can be shown that in the first and reverse gears, the planet carrier is immobile and the equivalent transmission is a fixed-axle one with the following transmission ratios  \n$$\ni_{1}=N_{0} / N_{4}\n$$  \nand  \n$$\ni_{R}=-\\left(N_{2} N_{6}\\right) /\\left(N_{1} N_{3}\\right)\n$$  \nIn the third gear, the planet carrier, sun gears, and ring gear rotate together as a whole  \n$$\ni_{3}=1\n$$  \ni.e., a direct drive, which ensures an increased mechanical efficiency of the transmission.  \nThe second gear configuration is the only case when the transmission works as a planetary gear set. Considering the planet carrier $c$ immobile, three basic transmission ratios can be defined as follows  \n$$\ni_{16}^{\\prime}=-\\frac{N_{0} N_{6}}{N_{1} N_{3}} \\quad i_{46}^{\\prime}=\\frac{N_{0}}{N_{4}} \\quad i_{14}^{\\prime}=-\\frac{N_{2} N_{4}}{N_{1} N_{3}}\n$$  \nThrough motion inversion, which converts the planetary gear into a fixed axle transmission, the following additional relations between the angular velocities of the sun gears 1 and 4 , ring gear 6 , and planet carrier $c$ can be written as  \n$$\ni_{16}^{\\prime}=\\frac{\\omega_{2}-\\omega_{c}}{\\omega_{6}-\\omega_{c}} \\quad i_{46}^{\\prime}=\\frac{\\omega_{4}-\\omega_{c}}{\\omega_{6}-\\omega_{c}} \\quad i_{14}^{\\prime}=\\frac{\\omega_{1}-\\omega_{c}}{\\omega_{4}-\\omega_{c}}\n$$  \nEliminating $\\omega_{c}$ between any two of the above equations and for $\\omega_{4}=0$, the sought-for transmission ratio of the second gear can be obtained  \n$$\ni_{2}=\\frac{N_{0}\\left(N_{1} N_{3}+N_{2} N_{4}\\right)}{N_{1} N_{3}\\left(N_{6}-N_{4}\\right)}\n$$  \n[IMAGE0]  \nFig. 1 Ravigneaux planetary gear [36]: 1 small sun gear; 2-3 broad planet gear; 4 large sun gear; 5 narrow planet gear; 6 ring gear\n[IMAGE1]  \nFig. 2 Kinematic diagram of a $3 \\times 1$ transmission ratios Ravigneaux planetary transmission. Note that the broad planet 2-3 consists now of two distinct gears  \nThe expressions of the transmission ratios $i_{1}, i_{2}$, and FORMULA_14 previously derived will be further used in formulating the problem of finding the optimum number of gear teeth for which imposed transmission ratios are best fulfilled.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:37",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the classification of EDAs based on their ability to capture dependencies between variables, and how does this classification affect their performance on complex optimization problems?",
      "topics": [
        "optimization"
      ],
      "answer": "EDAs are classified into three groups based on their ability to capture dependencies between variables. The first group assumes no dependencies, where the $n$-dimensional joint probability distribution factorizes as a product of $n$ univariate and independent probability distributions. Examples include the univariate marginal distribution algorithm (UMDA), compact genetic algorithm (cGA), and population based incremental learning. The second group considers bivariate dependencies, taking into account dependencies between pairs of variables; algorithms include mutual information maximization for input clustering (MIMIC), bivariate marginal distribution algorithm (BMDA), and Tree-EDA. The third group considers multiple dependencies, including algorithms like estimation of Bayesian networks algorithm (EBNA), estimation of Gaussian networks algorithms (EGNAs), and the Bayesian optimization algorithm (BOA). EDAs without dependencies are computationally easy to learn but may struggle with complex problems due to the strong independence assumption. Bivariate dependency EDAs offer a balance between computational cost and expressive power. Multiple dependency EDAs can solve very complex problems but are computationally expensive to learn.",
      "chunk_id": 7360,
      "paper_id": "Multi-marker tagging single nucleotide polymorphism selection using estimation of distribution algorithms",
      "paper_title": "Multi-marker tagging single nucleotide polymorphism selection using estimation of distribution algorithms",
      "paper_year": "2010",
      "chunk_content": "The most important step in EDAs is the learning of the probabilistic model. This fifth step has a significant influence on the behavior of the EDA from the point of view of complexity and performance. Therefore EDAs are usually classified into three groups, according to their ability to capture the dependencies between variables:  \n- Without dependencies: It is assumed that the $n$-dimensional joint probability distribution factorizes as a product of $n$ univariate and independent probability distributions. Algorithms that use this model are, among others, univariate marginal distribution algorithm (UMDA) [18], compact genetic algorithm (cGA) [24] and population based incremental learning [25].\n- Bivariate dependencies: Only the dependencies between pairs of variables are taken into account. This way, the process of estimating the joint probability can still be fast. This group includes: mutual information maximization for input clustering (MIMIC) [26], bivariate marginal distribution algorithm (BMDA) [27] and Tree-EDA [28].\n- Multiple dependencies: Higher order dependencies between the variables are considered. In this group we can find algorithms like estimation of Bayesian networks algorithm (EBNA) [29], estimation of Gaussian networks algorithms (EGNAs) [30] and the Bayesian optimization algorithm (BOA) [31].  \nThe algorithms in the first group deal with computationally easy to learn probabilistic models. However, given the strong independence assumption between the variables of the problem, they are sometimes unable to solve complex optimization problems. The second group of algorithms represent a balance between the computational cost of learning a probabilistic model and their expressive power. Finally, the third group includes the least restrictive models, being able to solve very complex problems but assuming the expensive cost of learning it.  \nFor detailed information about the characteristics of these EDAs and other algorithms that take part of this family see [16,17,19].",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:39",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm in a dynamic environment like the moving peaks benchmark, how should practitioners configure the UMDA parameter alpha to balance exploration and exploitation, given that a fixed population size N of 40 individuals is used?",
      "topics": [
        "fitness"
      ],
      "answer": "When configuring UMDA for the moving peaks benchmark with a population size N fixed at 40, practitioners should set the UMDA parameter alpha to 0.5. This value of alpha is used across all experiments, providing a balance between exploration and exploitation when updating the probability distribution.",
      "chunk_id": 5922,
      "paper_id": "An Improved Estimation of Distribution Algorithm in Dynamic Environments",
      "paper_title": "An Improved Estimation of Distribution Algorithm in Dynamic Environments",
      "paper_year": "2008",
      "chunk_content": "In order to test the performance of the proposed algorithm, we use the publicly available moving peaks benchmark(MPB)[4-5]. The function is formulated as follows:\n$F(x, t)=\\max _{i=1, \\cdots 10} \\frac{H_{i}(t)}{1+W_{i}(t) \\sum_{j=1}^{5}\\left(x_{j}-X_{j}(t)\\right)^{2}}$\nwhere $H_{i}(t)=H_{i}(t-1)+k_{0} \\sigma, \\quad W_{i}(t)=W_{i}(t-1)+k_{0} \\sigma$,\n$\\sigma \\in N(0,1) \\quad, \\quad X(t)=X(t-1)+\\omega_{i}(t)$,\n$\\omega_{i}(t)=\\frac{s}{|r+\\omega_{i}(t-1)|}\\left((1-\\lambda) r+\\lambda \\omega_{i}(t-1)\\right)$.\nThe moving peak function consists of a number of peaks $X(t)$, of varying heights $H_{i}(t)$ and widths $W_{i}(t)$, moving by a fixed shift length $s$ in random directions. The peaks change position every $\\tau$ generation by a distance of $s=1$ in a random direction. These parameter settings are summarized in Table 1.  \nTable 1 Standard settings for the moving peaks benchmark  \nExperiments were carried out to compare the performance of the proposed algorithm, IUMDA and MUMDA on the test environments constructed above. IUMDA is UMDA with random immigrants[9], and MUMDA is hyper mutation based UMDA[10], in which hyper mutation is selected to increase the diversity when the problem is changed.  \nFor each experiment of combining different algorithm and test problems, 50 independent runs were executed with the same set of random seeds. For each run of different algorithm on each problem, the best of generation fitness was recorded every generation. And for\neach run of an algorithm on a dynamic problem, 500 generations are allowed.  \nIn order to compare performance of different algorithms, the total population size $N$ was fixed at 40 individuals. The parameter of UMDA $\\alpha=0.5$ was used for all experiments. And the average errors which are the averages of the error of the best solution on each generation over all run are located in figures. The simulation results on different change severities $s$ are shown in Fig.1-3 (the solid line represent the improved UMDA, the dotted line represent the IUMDA, and the dash-dot line represent the MUMDA ).\n[IMAGE0]  \nFig. 1 Experimental results on MPB  \n$$\n(p=10, \\tau=25, s=1)\n$$  \n[IMAGE1]  \nFig. 2 Experimental results on MPB  \n$$\n(p=10, \\tau=30, s=2)\n$$  \n[IMAGE2]  \nFig. 3 Experimental results on MPB  \nFORMULA_80  \nFrom the simulation results, the following considerations can be drawn.\n(1) First, generally, the improved UMDA outperforms IUMDA and MUMDA in the same environment. One straight forward approach to make EAs more suitable for dynamic environments is to increase the diversity of the population after a change.\n(2) The proposed algorithm increases the diversity by generating the new individuals with combing transfer model. Thus the proposed algorithm makes useful of the current and history information of the optimal solutions to increase the diversity by guide fashion. The new individuals are close to or in the promising region. So the time to track the optimum for the proposed algorithm is shorter than other algorithm.\n(3) By using improved UMDA, the optimum solution is achieved in dynamic environments. Dynamic optimum problem field is extended by using EDAs.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:41",
      "generation_style": "practical_application"
    },
    {
      "question": "How does the Estimation of Distribution Algorithm (EDA) leverage kinematic computations and torque minimization to optimize continuum robot designs, and what quantitative improvement in objective function values is observed compared to Genetic Algorithms (GAs) in this specific application?",
      "topics": [
        "analysis"
      ],
      "answer": "The Estimation of Distribution Algorithm (EDA) is employed to find optimal robot dimensions while considering reachability. This involves leveraging both forward and inverse kinematic computations for reachability analysis. During inverse kinematics, torque minimization at joints is integrated to find robot configurations requiring the minimum actuator torque to reach a given workspace. The objective function used for optimization could be the total length of the robot or the actuator torque required to operate the robot. Experimentally, the EDA demonstrates superiority over a Genetic Algorithm (GA) by achieving objective values for the best solutions that are 4-15% lower than those found by the GA within a given number of iterations.",
      "chunk_id": 9276,
      "paper_id": "Optimal Design of Continuum Robots With Reachability Constraints",
      "paper_title": "Optimal Design of Continuum Robots With Reachability Constraints",
      "paper_year": "2021",
      "chunk_content": "Hyunmin Cheong ${ }^{\\circledR}$, Mehran Ebrahimi, and Timothy Duggan\nWhile multi-joint continuum robots are highly dexterous and flexible, designing an optimal robot can be challenging due to its kinematics involving curvatures. Hence, the current work presents a computational method developed to find optimal designs of continuum robots, given reachability constraints. First, we leverage both forward and inverse kinematic computations to perform reachability analysis in an efficient yet accurate manner. While implementing inverse kinematics, we also integrate torque minimization at joints such that robot configurations with the minimum actuator torque required to reach a given workspace could be found. Lastly, we apply an estimation of distribution algorithm (EDA) to find optimal robot dimensions while considering reachability, where the objective function could be the total length of the robot or the actuator torque required to operate the robot. Through three application problems, we show that the EDA is superior to a genetic algorithm (GA) in finding better solutions within a given number of iterations, as the objective values of the best solutions found by the EDA are $4-15 \\%$ lower than those found by the GA.  \nIndex Terms-Kinematics, methods and tools for robot system design, optimization and optimal control, soft robot applications.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:43",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the clustering accuracy of the LSMEDA algorithm compare to the GN, FN, and TGA algorithms as the network community structure becomes increasingly fuzzy, specifically when evaluated using the normalized mutual information (NMI) method?",
      "topics": [
        "mutation"
      ],
      "answer": "When the average number of edges between communities (zout) increases, indicating a more fuzzy network community structure, the LSMEDA algorithm demonstrates a significantly higher clustering accuracy, as measured by NMI, compared to the GN, FN, and TGA algorithms. Specifically, even when zout equals 8, where the average number of edges between communities is equal to the average number of edges within the community, LSMEDA can still detect the community structure, while GN, FN, and TGA become ineffective.",
      "chunk_id": 10844,
      "paper_id": "The Improved Estimation of Distribution Algorithms for Community Detection",
      "paper_title": "The Improved Estimation of Distribution Algorithms for Community Detection",
      "paper_year": "2018",
      "chunk_content": "In our quantitative analysis of the LSMEDA algorithm, we used a benchmark network and a real large-scale network for testing and verification. The experimental environment used to implement the algorithm was as follows: an Intel(R) Core(TM) M450 processor running at $2.40 \\mathrm{GHz}, 6.00 \\mathrm{~GB}$ of memory, a 320-GB hard disk, Microsoft Windows 764 -bit operating system, and the Matlab 7.10 programming environment.  \nThe algorithm parameters were: maximum iterative algebra $L=100$, population size $\\operatorname{PopSize}=500$, mutation probability $\\beta=0.6$, learning rate $\\alpha=0.1$, truncation selection parameter $\\gamma=0.5$, and mutation selection parameter $\\lambda=0.5$ ( $50 \\%$ of the fittest population was selected as the dominant group, and $50 \\%$ of the dominant population's mutations were selected).\n[IMAGE0]  \nFigure 1. Community detection accuracy comparison\nIn 2002, Newman et al. proposed a random network model $R N(a, s, d$, zout $)$ to test the performance of a detection algorithm in a network community ${ }^{[15]}$. The community structures are known in the model, $a$ represents the size of the network community, $s$ represents the number of nodes in each community, $d$ represents the average node degree, and zout represents the average number of edges between nodes inside the community and outside the community. A previous study ${ }^{[17]}$ proposed the use of standard normalised mutual information ( $N M I$ ) to evaluate the accuracy of the clustering effects based on information theory and demonstrated that $N M I$ was fair and reasonable. In the present study, we used the $N M I$ method to evaluate the clustering accuracy of different network community detection algorithms by comparing LSMEDA with popular algorithms such as $\\mathrm{GN}^{[3]}, \\mathrm{FN}^{[18]}$, and Tasgin's GA (TGA) ${ }^{[6]}$. The results are shown in Figure 1. The random network parameter used in the diagram is $R N(4,32,16$, zout). If zout  \nis larger, the detection algorithm finds it more difficult to determine the fuzzy network's corresponding community structure.  \nIf zout $>8$, i.e. the average number of edges between communities is greater than the average number of edges within the community, we considered that the network did not have a community structure ${ }^{[5]}$. In the figure, the y -axis represents the clustering accuracy, and the value on the xaxis represents the value of zout. Each data point on the curve represents the average accuracy of the algorithm based on 100 runs. The figure shows that the clustering accuracy of the LSMEDA algorithm was much higher than that of GN, FN, and TGA as zout increased (as the network community structure became increasingly fuzzy). Thus, LSMEDA was obviously the best method. In addition, even when zout $=8$ (the average number of edges between communities was equal to the average number of edges within the community), the LSMEDA algorithm could still detect the community structure, whereas the GN, FN, and TGA algorithms were ineffective.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:45",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "In the GAEDA algorithm, which improves the normal distribution using crossover operations, what specific parameters must be configured during implementation, and what are their suggested values according to the experimental setup?",
      "topics": [
        "genetic",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The implementation of GAEDA requires configuring parameters such as the initial population size, the number of iterations, and the selection probability. Based on the provided context, the initial population size should be set to 1000, the number of iterations to 100, and the selection probability to 0.4. These values are crucial for the algorithm's convergence and solution accuracy.",
      "chunk_id": 11234,
      "paper_id": "A new Algorithm based on the Gbest of Particle Swarm Optimization algorithm to improve Estimation of Distribution Algorithm",
      "paper_title": "A new Algorithm based on the Gbest of Particle Swarm Optimization algorithm to improve Estimation of Distribution Algorithm",
      "paper_year": "2018",
      "chunk_content": "In reference [11], we propose an estimation of distribution algorithm that uses crossover operations in genetic algorithms to improve the normal distribution. Through the crossover operation, the search capability of the improved algorithm (GAEDA) is greatly improved. This section mainly compares the algorithm introduced in this paper (PSOEDA) with the GAEDA (improved genetic algorithm) and the improved EDA (non-improved distribution estimation algorithm). Ten computer experiments in Table 1 are used to simulate the commonly used benchmark functions to objectively evaluate the three algorithms in convergence and solution accuracy. In the parameter setting, the parameters of the three algorithms are with the same setting, the size of the initial population 1000 , iteration 100 times, the learning factors c 1 and c 2 are all setting to 2 , the selection probability is 0.4 . The test results of the ten test functions correspond to the following Fig 2 to 11 respectively.  \nTABLE 1 TEN BENCHMARK FUNCTIONS\n[IMAGE1]  \nFig. 2. Simulation Results of F1  \n[IMAGE2]  \nFig. 3. simulation results of F2\n[IMAGE3]  \nFig 4 simulation results of F3\n[IMAGE4]  \nFig. 5. Simulation Results of F4\n[IMAGE5]  \nFig 6. simulation results of F5\n[IMAGE6]  \nFig. 7 simulation results of F6\n[IMAGE7]  \nFig 8 simulation results of $F 7$\n[IMAGE8]  \nFig 9 simulation results of F8\n[IMAGE9]  \nFig.10. Simulation Results of F9  \n[IMAGE10]  \nFig.11. simulation results of F10\nThis paper improves the estimation of distribution algorithm and tries a new fusion method on the basis of previous researchers' fusion of estimation of distribution algorithm and other algorithm; it is bold to propose the fusion of particle swarm algorithm and distribution estimation algorithm that has not been tried before. This paper proposes to optimize the estimation of distribution algorithm by optimizing the population generated by each iteration of particle swarm optimization as elected objects for modeling the estimation of distribution algorithm. The simulation test results of ten benchmark test functions show that the proposed algorithm is superior to the GA_EDA (Improved generic algorithm is) and the basic distribution estimation (EDA) algorithm both in convergence and accuracy. Preliminary excremental results can proves the feasibility of the attempt, but the algorithm parameter settings, optimization and application remain to be further research, such as the subsequent will continue to focus on this problem for a bigger breakthrough",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:47",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific conditions define an admissible value for the variance scaling factor $k$ in the context of preventing premature convergence in an Estimation of Distribution Algorithm?",
      "topics": [
        "evaluation metrics"
      ],
      "answer": "An admissible value for the variance scaling factor $k$ is defined by the condition $k_{\\min } = \\frac{1}{\\sqrt{c_{\\text {slope }}}} \\leq k < \\frac{1}{\\sqrt{c_{\\text {valley }}}} = k_{\\max }$, where $c_{\\text {slope }}$ represents the ratio of population variances in consecutive generations on a linear fitness landscape (slope), and $c_{\\text {valley }}$ represents the ratio of population variances in consecutive generations on a sphere fitness landscape (valley). This condition ensures that the variance is large enough to traverse slopes but not so large as to prevent convergence in valleys.",
      "chunk_id": 5970,
      "paper_id": "Preventing Premature Convergence in a Simple EDA Via Global Step Size Setting",
      "paper_title": "Preventing Premature Convergence in a Simple EDA Via Global Step Size Setting",
      "paper_year": "2008",
      "chunk_content": "According to [15], the optimal behaviour of the self-adaptive EAs in real spaces arises from balancing two antagonistic forces: (1) the variance shrinking effect of selection, and (2) the variance enlarging effect of the variational operators (distribution sampling, in our case). In this article, an approach of [14] is used where the combined effect of the selection and variation is taken into account.  \nTwo simple fitness landscapes are used: a linear and a sphere function:  \n$$\n\\begin{aligned}\nf_{\\text {lin }}(\\mathbf{x}) & =x_{1} \\\\\nf_{\\text {sphere }}(\\mathbf{x}) & =\\sum_{d=1}^{D} x_{d}^{2}\n\\end{aligned}\n$$  \nThese functions can be regarded [15] as local approximations of the real fitness functions; the fitness landscape is often modelled as consisting of slopes and  \nvalleys (see e.g. [10], [16], [12]). The slopes and valleys are modelled with the linear (Eq. 1) and the sphere function (Eq. 2), respectively.  \nThere are two fundamental requirements on the development of the population variance that ensure a reasonable behavior of the algorithm as a whole:  \n1. The variance must not shrink on the slope. This ensures that the population position is not bounded and that it eventually finds at least a local optimum.\n2. The variance must shrink in the valley. In the neighborhood of the optimum, the algorithm must be allowed to converge to find the optimum precisely.\nThese two conditions constitute the bounds for the variance scaling factor $k$ which must be large enough to traverse the slopes, but must not be too large to be able to focus to the optimum.\nThe evolution of the model variance from one generation to another can be described as follows: (1) sample new individuals with variance $\\left(\\sigma^{t}\\right)^{2}$, (2) select the best individuals, and (3) compute the variance $\\left(\\sigma^{t+1}\\right)^{2}$ for the next sampling. Without selection and using ML estimate, the two variances are expected to be the same. For our two fitness landscapes, the selection reduces the variance, thus  \n$$\n\\left(\\sigma^{t+1}\\right)^{2}=\\left(\\sigma^{t}\\right)^{2} \\cdot c\n$$  \nwhere $c$ is the ratio of the population variances in two consecutive generations, $t$ and $t+1$, and $c<1$ in our case. Of course, the ratio $c$ differs for various fitness landscapes, thus it will be designated as $c_{\\text {slope }}$ and $c_{\\text {valley }}$, respectively.  \nAs already said in the introduction, the simplest method of preventing premature convergence is to enlarge the estimated standard deviation $\\sigma$ by a constant factor $k$ (step 6 of the algorithm in Fig. 1). Thus  \n$$\n\\sigma^{t+1}=k \\cdot \\sigma^{t} \\cdot \\sqrt{c}\n$$  \nIn order to prevent the premature convergence on the slope, the ratio of the consecutive standard deviations should be at least 1 , i.e.  \n$$\n\\frac{\\sigma^{t+1}}{\\sigma^{t}}=k \\cdot \\sqrt{c_{\\text {slope }}} \\geq 1, \\text { thus } k \\geq \\frac{1}{\\sqrt{c_{\\text {slope }}}} \\stackrel{\\text { def }}{=} k_{\\min }\n$$  \nOn the other hand, to be able to focus to the optimum, the model must be allowed to converge in the valley. The ratio of the two consecutive standard deviations should be lower than 1 , i.e.  \n$$\n\\frac{\\sigma^{t+1}}{\\sigma^{t}}=k \\cdot \\sqrt{c_{\\text {valley }}}<1, \\text { thus } k<\\frac{1}{\\sqrt{c_{\\text {valley }}}} \\stackrel{\\text { def }}{=} k_{\\max }\n$$  \nJoining these two conditions together gives us the bounds for the constant $k$ :  \n$$\nk_{\\min }=\\frac{1}{\\sqrt{c_{\\text {slope }}}} \\leq k<\\frac{1}{\\sqrt{c_{\\text {valley }}}}=k_{\\max }\n$$  \nIn this paper, the value of $k$ is called admissible if it satisfies condition 7 .",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:49",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs with differential perturbation for the generalized redundancy allocation problem (GRAP)?",
      "topics": [
        "complexity"
      ],
      "answer": "The primary objective is to determine an optimal system structure for GRAPs that minimizes cost under constraints by using redundant components in parallel, achieved through a novel discrete bat algorithm. This involves using a cellular automata based Monte Carlo simulation method to estimate system reliability, which is an NP-hard problem, and calculating the computational complexity of the proposed algorithm.",
      "chunk_id": 7818,
      "paper_id": "A hybrid enhanced bat algorithm for the generalized redundancy allocation problem",
      "paper_title": "A hybrid enhanced bat algorithm for the generalized redundancy allocation problem",
      "paper_year": "2019",
      "chunk_content": "Yue Xu, Dechang FORMULA_0Collage of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China\nKeywords:\nGeneralized redundancy allocation problem Cellular automata\nMonte Carlo simulation\nConstriction coefficient\nTransfer function\nDiscrete bat algorithm\nEstimation of distribution algorithm with differential perturbation\nA majority of existing works dealing with redundancy allocation problems are based on traditional series-parallel structures. While in many real-life scenarios, the way of connecting subsystems is not limited to a series-only configuration. This paper considers a generalized redundancy allocation problem (GRAP), where the system structure is a more general network. Since the reliability evaluation in GRAPs is a NP-hard problem and the traditional exact symbolic reliability calculation is not suitable, a cellular automata based monte carlo simulation method is implemented in this paper to estimate the system reliability. It is a relatively simple but effective method without knowing the MPs/MCs. Moreover, to deal with GRAPs, a novel discrete bat algorithm is proposed in this paper with a goal of determining an optimal system structure that achieves the minimum cost under several constraints by using redundant components in parallel. Computational complexity of the proposed algorithm is also calculated in this paper. In the end, three experiments are carried out based on ten networks to set parameters, measure the effectiveness of the modifications, and compare with other state-of-the-art algorithms, separately. The reported computational results show that the proposed algorithm is powerful, which is more superior on this sort of problems.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:50",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the $N S_{\\text {PM_RS_guide }}$ Estimation of Distribution Algorithm, how does the algorithmic mechanism of dynamically constructing blocks, as seen in Algorithm 10, contribute to the search process, and what probabilistic considerations are involved in extending these blocks as detailed in Algorithm 9?",
      "topics": [
        "search"
      ],
      "answer": "The $N S_{\\text {PM_RS_guide }}$ algorithm, as shown in Algorithm 10, dynamically constructs blocks with strong correlation and promising patterns during neighborhood search (Line 7), leading to searches in various Insert-based neighborhoods (Lines 11-17). This dynamic construction aims to increase search depth and maintain high neighbor quality. Algorithm 9, `VariableBlock`, details how these blocks are extended. Specifically, within the `while` loop, a probability $p_r$ is calculated for extending the block based on the relationship between $\\pi^{\\text {gen }}(k+l e n-1)$ and $\\pi^{\\text {gen }}(k+l e n)$. The block is extended if either $p_r \\geq 0.2$, or if $p_r < 0.2$ and a random number generated by `rand()` is less than 0.35. If neither condition is met, the block extension is halted using `break`. The length of the block, `len`, is incremented if the block is extended, and finally, `len` and $\\boldsymbol{\\pi}_{\\text {block }}$ are returned.",
      "chunk_id": 2050,
      "paper_id": "A matrix-cube-based estimation of distribution algorithm for blocking flow-shop scheduling problem with sequence-dependent setup times",
      "paper_title": "A matrix-cube-based estimation of distribution algorithm for blocking flow-shop scheduling problem with sequence-dependent setup times",
      "paper_year": "2022",
      "chunk_content": "From Algorithm 10, it can be seen that the core idea of the $N S_{\\text {PM_RS_guide }}$ is to dynamically construct blocks with strong correlation and promising pattern in the process of neighborhood search (see Line 7), and then search the Insert-based neighborhood determined by each block (see Lines 11-17). Since the constructed blocks are different in most cases, the $N S_{\\text {PM_RS_guide }}$ can perform rich searches in a variety of Insert-based neighborhoods, which is conducive to increasing the search depth. Moreover, the $N S_{\\text {PM_RS_guide }}$ can ensure that the overall quality of neighbors in the constructed neighborhood is high, which helps to improve the search quality.  \nAlgorithm 9:VariableBlock $\\left(k\\right.$, pos, len, $\\left.\\boldsymbol{\\pi}^{\\text {gen }}, \\boldsymbol{\\pi}_{\\text {best }}, P M_{n \\times n \\times n}^{\\text {gen }}\\right)$\nInput: $k$, pos, len, $\\boldsymbol{\\pi}^{\\text {gen }}, \\boldsymbol{\\pi}_{\\text {best }}$, and $\\mathbf{P M}_{\\mathbf{n}=\\mathbf{n}=\\mathbf{n}}^{\\text {gen }}$.\nOutput: len and $\\boldsymbol{\\pi}_{\\text {block }}$.  \n1: while $\\pi^{\\text {gen }}(k+\\operatorname{len})=\\pi_{\\text {best }}(\\operatorname{pos}+l$ len $)$ do\n2: Calculate $p_{r}$ for $\\pi^{\\text {gen }}(k+l e n-1)$ and $\\pi^{\\text {gen }}(k+l e n)$.\n3: $\\quad$ if $\\left(p_{r} \\geq 0.2\\right)$ or $\\left(\\left(p_{r}<0.2\\right)\\right.$ and $\\left(\\operatorname{rand}()<0.35\\right)$ ) then\n4: $\\quad \\pi_{\\text {block }}(\\operatorname{len}) \\leftarrow \\pi^{\\text {gen }}(k+l e n)$.\n5: else\n6: $\\quad$ break.\n7: end if\n8: $\\quad$ len $=$ len +1 .\n9: end while\n10: return len and $\\boldsymbol{\\pi}_{\\text {block }}$.  \nAlgorithm 10:ReferenceNeighborSearch $\\left(\\boldsymbol{\\pi}^{\\text {gen }}, \\boldsymbol{\\pi}_{\\text {best }}, P M_{n \\times n \\times n}^{\\text {gen }}\\right)$\nInput: $\\boldsymbol{\\pi}_{\\text {best }}, \\boldsymbol{\\pi}^{\\text {gen }}$ and $\\mathbf{P M}_{\\mathbf{n}=\\mathbf{n}=\\mathbf{n}}^{\\text {gen }}$.\nOutput: The updated $\\boldsymbol{\\pi}^{\\text {gen }}$ and $C_{\\max }\\left(\\boldsymbol{\\pi}^{\\text {gen }}\\right)$.\n$1: \\quad N_{c}=1$.\n2: while $N_{c} \\leq n$ do\n$3: \\quad k=1, \\operatorname{len}=1, \\operatorname{pos}=N_{c}, \\boldsymbol{\\pi}_{\\text {block }} \\leftarrow \\varnothing$.\nwhile $\\pi^{\\text {gen }}(k) \\neq \\pi_{\\text {best }}(\\operatorname{pos})$ do\n$4: \\quad k=k+1$.\nend while\n7: $\\boldsymbol{\\pi}_{\\text {block }} \\leftarrow$ VariableBlock $\\left(k\\right.$, pos,len, $\\left.\\boldsymbol{\\pi}^{\\text {gen }}, \\boldsymbol{\\pi}_{\\text {best }}, \\mathbf{P M}_{\\mathbf{n}=\\mathbf{n}=\\mathbf{n}}^{\\text {gen }}\\right)$. //Algorithm 9\n8: if len $=1$ then\n$9: \\quad \\pi_{\\text {block }}(1)=\\pi_{\\text {best }}(\\operatorname{pos})$.\n10: end if\n11: $\\boldsymbol{\\pi}_{\\text {left }} \\leftarrow$ Remove job block $\\boldsymbol{\\pi}_{\\text {block }}$ from $\\boldsymbol{\\pi}^{\\text {gen }}$.\n12: for $i=1$ to $(n-l e n+1)$ do\n$13: \\quad \\pi_{\\text {new }} \\leftarrow \\operatorname{Insert}\\left(\\boldsymbol{\\pi}_{\\text {left }}, i, \\boldsymbol{\\pi}_{\\text {block }}\\right)$.\n14: if $C_{\\max }\\left(\\boldsymbol{\\pi}_{\\text {new }}\\right)<C_{\\max }\\left(\\boldsymbol{\\pi}^{\\text {gen }}\\right)$ then\n$15: \\quad \\pi^{\\text {gen }}=\\boldsymbol{\\pi}_{\\text {new }}, C_{\\max }\\left(\\boldsymbol{\\pi}^{\\text {gen }}\\right)=C_{\\max }\\left(\\boldsymbol{\\pi}_{\\text {new }}\\right), N_{c}=1$.\nend if\n17: end for\n$18: \\quad N_{c}=N_{c}+1$.\n19: end while\n20: return FORMULA_710.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:53",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners approach feature selection from speech utterances to optimize emotion recognition performance?",
      "topics": [
        "search"
      ],
      "answer": "Practitioners should focus on selecting and extracting relevant features from speech utterances. The specific approach involves speech processing to identify features that can be classified and used for training classifiers. While the exact features and classifiers are not detailed here, the process emphasizes the importance of feature selection as a crucial step in building an effective emotion recognition system.",
      "chunk_id": 12671,
      "paper_id": "Classifier Subset Selection for the Stacked Generalization Method Applied to Emotion Recognition in Speech",
      "paper_title": "Classifier Subset Selection for the Stacked Generalization Method Applied to Emotion Recognition in Speech",
      "paper_year": "2016",
      "chunk_content": "Acknowledgments: This research work was partially funded by the Spanish Ministry of Economy and Competitiveness (Project TIN2014-52665-C2-1-R) and by the Department of Education, Universities and Research of the Basque Government (Grants IT395-10 and IT313-10). Egokituz Laboratory of HCI for Special Needs, Galan research group and Robotika eta Sistema Autonomoen Ikerketa Taldea (RSAIT) are part of the Basque Advanced Informatics Laboratory (BAILab) unit for research and teaching supported by the University of the Basque Country (UFI11/45). The authors would like to thank Karmele Lopez de Ipina and Innovae Vision S.L. for giving permission to use RekEmozio database for this research.  \nAuthor Contributions: The current research was completed through the collaboration of all of the authors. Aitor Alvarez was the team leader and responsible for the speech processing part, selecting and extracting the features to be classified from the speech utterances. Basilio Sierra managed the machine learning part, training and evaluating the classifiers used for the project. Andoni Arruti helped with the audio analysis and with designing the new classification paradigm. Juan-Miguel Lopez-Gil worked preparing the RekEmozio and Emo-DB and provided the state of the art to the team. Nestor Garay-Vitoria completed the state of the art, helped in the data and results interpretation and guided the focus of the article writing.  \nConflicts of Interest: The authors declare no conflict of interest.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:06:55",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, what termination criteria are commonly used to stop the algorithm and return the best solution found?",
      "topics": [
        "optimization"
      ],
      "answer": "The common termination criteria adopted for Estimation of Distribution Algorithms (EDAs) include reaching a maximum number of iterations, achieving a homogeneous population, or experiencing a lack of improvement in the solutions for a certain number of iterations. The algorithm repeats until one of these termination criteria is satisfied.",
      "chunk_id": 8895,
      "paper_id": "A variable neighbourhood search enhanced estimation of distribution algorithm for quadratic assignment problems. OPSEARCH",
      "paper_title": "A variable neighbourhood search enhanced estimation of distribution algorithm for quadratic assignment problems",
      "paper_year": "2021",
      "chunk_content": "Estimation of distribution algorithms (EDAs) [13, 63, 68) are a set of relatively new algorithms that explore the solution space by sampling the probabilistic model constructed from the favourable solutions evolved till now. They are considered to  \nbe variants of genetic algorithms in which the reproduction operations, crossover and mutation are replaced with probabilistic sampling. EDAs belong to the class of population-based stochastic optimization algorithms. As in other population-based algorithms, the EDAs also start with an initial random population sampled from the set of all permissible solutions. The members of the population are then ranked according to their fitness value-higher the fitness, better the solution. The subset of most promising solutions is selected from this ranked population using a selection operator. Then the algorithm constructs a probabilistic model from the selected set of promising solutions. The new set of solutions for the next generation is sampled from this model and the algorithm repeats until the termination criterion is satisfied and returns the best solution found over the generations. The common termination criteria adopted are a maximum number of iterations, homogeneous population, or lack of improvement in the solutions for a certain number of iterations. Figures 1 and 2 represent the pseudocode and flowchart for general EDA respectively.  \nBased on this general procedure, researchers have developed a number of different algorithms for various categories of optimization problems. The basic categorization of EDAs is done based on the complexity of the probabilistic models demonstrating the relationship between the variables. The broad categories of EDAs consist of univariate, bivariate and multivariate models. There are multiple algorithms in each of these categories and a short review of them is given in the succeeding subsections. The different aspects of EDAs have been studied by many and can be obtained from the works of Hauschild and Pelikan [53], Ceberio et al. [27], Pelikan et al. [83] and Santana et al. [87].",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:06:56",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the distance, as computed by Equation (20), between ansatzes generated by EDA models A and B compare when assessing the closest cluster for a given Hamiltonian index $i$ and number of qubits $n$?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Distance Comparison",
        "Clustering"
      ],
      "answer": "The distance, calculated using Equation (20), is used to determine the closest cluster ($D_i^n$) to the ansatzes generated by $\\mathrm{EDA}_{ij}^{A}$ and $\\mathrm{EDA}_{ij}^{B}$. Tables 3 and 4 show these distance computations for $n=4$ and $n=8$ respectively. A key difference is highlighted by the bold values: In Table 3, bold values indicate instances where the closest cluster to $\\mathrm{EDA}_{ij}^{A}$ is $D_i^A$, while in Table 4, bold values indicate instances where the closest cluster to $\\mathrm{EDA}_{ij}^{B}$ is $D_i^B$. This suggests a difference in how the EDA models' generated ansatzes relate to the clusters depending on the number of qubits.",
      "chunk_id": 3109,
      "paper_id": "Trainability maximization using estimation of distribution algorithms assisted by surrogate modelling for quantum architecture search",
      "paper_title": "Trainability maximization using estimation of distribution algorithms assisted by surrogate modelling for quantum architecture search",
      "paper_year": "2024",
      "chunk_content": "Here we detail the distance comparison between all the proposed solutions within $\\mathrm{EDA}_{i}^{n}$ and each of the clusters $D_{i}^{n}$ by computing Equation (20). Note that index $j$ denotes each of the 5 best results found by the EDA. Table 3-5 show the distance computations for $n \\in[4,8,12]$, respectively.  \nTable 3 Distance (Equation (20)) between each ansatz in $\\mathrm{EDA}_{i j}^{A}$ and $D_{i}^{A}$, where $i$ denotes the Hamiltonian index and $n=4$. Bold values represent those instances in which the closest cluster to $\\mathrm{EDA}_{i j}^{A}$ is $D_{i}^{A}$  \nTable 4 Distance (Equation (20)) between each ansatz in $\\mathrm{EDA}_{i j}^{B}$ and $D_{i}^{B}$, where $i$ denotes the Hamiltonian index and $n=8$. Bold values represent those instances in which the closest cluster to $\\mathrm{EDA}_{i j}^{A}$ is $D_{i}^{B}$\nFigure 10 shows the Pareto frontier approximation for different $H$ and number of qubits. The columns refer to the problem instances, while the rows refer to the number of qubits  \nTable 5 Distance (Equation (20)) between each ansatz in $\\mathrm{EDA}_{5}^{12}$ and $D_{i}^{12}$, where $i$ denotes the Hamiltonian index and $n=12$\n[IMAGE0]  \nFigure 10 Pareto frontier approximation (orange spots) over all the ansatzes considered (blue spots) during optimization process. Columns refer to problem instances, while rows refer to number of qubits ( $n$ )\n(n). Each subplot shows all the evaluated ansatzes (blue spots) from which the nondominated solutions are highlighted (orange spot).  \n[IMAGE1]  \nFigure 11 Pareto frontier approximation (black stars) over all the ansatzes considered (colored spots) during the optimization process. Black triangles regard the ansatzes included in the dataset. Columns refer to problem instances, while rows refer to number of qubits ( $n$ )  \nTable 6 Mean and standard deviation of expectation value (E) (Equation (1)) and information content (IC) (Equation (7)), respectively, found in the ansatz in the dataset whose depth is in the range $m \\pm \\sqrt{m}$, for different number of qubits $n$ and Hamiltonian $H_{i}$\nTable 7 Best expectation value (E) (Equation (1)) and information content (IC) (Equation (7)) found by the EDA approach (assisted by COBYLA) for different number of qubits ( $n$ ) and Hamiltonians $\\left(H_{i}\\right)$, where FORMULA_70 is maximized in the best Pareto approximation",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:06:59",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to handle sensors with adjustable sensing ranges in a wireless sensor network?",
      "topics": [
        "genetic"
      ],
      "answer": "Given that sensors have adjustable sensing ranges, the implementation must account for multilevel sensor activation modes instead of a binary sleep/activated state. This requires representing the sensor activation level as a variable in the code. Furthermore, the energy consumption model within the EDA must be updated to reflect the varying energy costs associated with different sensing ranges. The search space for coverage schemes becomes significantly larger; therefore, the EDA implementation should prioritize efficient search strategies and data structures to represent and manipulate the coverage schemes.",
      "chunk_id": 8776,
      "paper_id": "Maximizing Lifetime of Range-Adjustable Wireless Sensor Networks  A Neighborhood-Based Estimation of Distribution Algorithm",
      "paper_title": "Maximizing Lifetime of Range-Adjustable Wireless Sensor Networks: A Neighborhood-Based Estimation of Distribution Algorithm",
      "paper_year": "2021",
      "chunk_content": "W'IRELESS sensor networks (WSNs) have been deployed for automation of various tasks, such as environmental monitoring, intrusion detection, and intelligent farming [1]-[3]. The lifetime of a WSN is the total amount of time that the WSN can stay functional and fulfill certain objectives [4]-[6]. Many functions of WSNs rely on full coverage of specified objects, which can be an area [7]-[9]; a barrier [10], [11]; or a set of targets [12]-[14]. In many scenarios, batteries of sensors have limited energy and recharging the batteries is impractical. Therefore, how to utilize sensor energy efficiently for guaranteeing full coverage becomes the key to prolong the lifetime of WSNs.  \nThe sensor activity scheduling is an effective way to prolong the lifetime of WSNs. In order to provide high-quality service, sensors are usually densely deployed. Activating a subset of sensors is already sufficient for achieving full coverage of specified objects (called a coverage scheme), and the other sensors can switch to the sleep mode for saving energy. Therefore, the network lifetime can be prolonged by finding a set of disjoint coverage schemes that use different sensors and activating them in sequence. Following this idea, a wealth of sensor activity scheduling approaches has been proposed. Liao and Ting [15] proposed a memetic algorithm based on a genetic algorithm and a local search operator. Wan et al. [16] proposed a scheduling algorithm for the roadside sensor network, where the road should be monitored by multiple sensors simultaneously. Zhang et al. [17] proposed a Kuhn-Munkres parallel genetic algorithm that used a divide-and-conquer strategy for the large-scale WSNs. Chen et al. [18] proposed a hybrid memetic framework that considered the dynamic coverage maintenance.  \nAll the above approaches are subject to the assumption that sensors have a fixed sensing range. However, in recent years, the usage of sensors with adjustable sensing ranges has become more prevalent [19], [20]. This posts new challenges to the sensor activity scheduling task. With adjustable sensing ranges, the sensor activation mode is no longer binary (sleep/activated) but multilevel. The search space for finding coverage schemes thus becomes larger. In addition, sensors activated at different sensing ranges consume different amounts of energy for the same length of time. Thus, sensors activated in one coverage scheme may have  \n[^0]:    Manuscript received June 11, 2019; revised October 8, 2019 and December 15, 2019; accepted February 25, 2020. This work was supported in part by the National Natural Science Foundation of China under Grant 61772569, Grant 61873095, and Grant U1611262. This article was recommended by Associate Editor R. Selmic. (Corresponding author: Ying Lin.)  \nZong-Gan Chen, Yue-Jiao Gong, and Zhi-Hui Zhan are with the School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China, and also with the Guangdong Provincial Key Laboratory of Computational Intelligence and Cyberspace Information, South China University of Technology, Guangzhou 510006, China.  \nYing Lin is with the Department of Psychology, Sun Yat-sen University, Guangzhou 510006, China (e-mail: linying23@mail.sysu.edu.cn).\nJun Zhang is with Victoria University, Melbourne, VIC 8001, Australia (e-mail: junzhang@ieee.org).  \nColor versions of one or more of the figures in this article are available online at http://ieeexplore.ieee.org.\nDigital Object Identifier 10.1109/TCYB.2020.2977858",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:01",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the performance of multiobjective estimation of distribution algorithms (EDAs) evaluated, considering they aim to find Pareto-optimal solutions instead of a single optimal solution?",
      "topics": [
        "evolutionary"
      ],
      "answer": "Multiobjective EDAs are evaluated by their ability to find a set of Pareto-optimal solutions, which represent optimal tradeoffs between multiple objectives. The regularity model-based multiobjective EDA (RM-MEDA) is one such algorithm. The effectiveness of hybrid approaches, like combining local linear embedding (LLE) and an immune inspired algorithm (SICA), is assessed through experiments on multiobjective problems.",
      "chunk_id": 6565,
      "paper_id": "Hybrid multiobjective estimation of distribution algorithm by local linear embedding and an immune inspired algorithm",
      "paper_title": "Hybrid Multiobjective Estimation of Distribution Algorithm by Local Linear Embedding and an Immune Inspired Algorithm",
      "paper_year": "2009",
      "chunk_content": "In real-world optimization applications, it is often necessary to optimize multiple objectives in one problem synchronously. The simultaneous optimization of multiple objectives is different from single objective optimization in that there is no unique solution to MOPs. A set of optimal tradeoff solutions known as the Pareto-optimal solutions are required. During the past two decades, evolutionary algorithms (EAs) have been recognized to be well suited to multiobjective optimization since early in their development because they can be suitably applied to deal simultaneously with a set of possible solutions. A number of multiobjective evolutionary algorithms (MOEAs) have been developed for MOPs [1], [2], [3]. Recently, the multiobjective estimation of distribution algorithms (EDAs) has attracted much interest from MO researchers [4]. The estimation of distribution algorithms (EDAs) are a new computing paradigm in evolutionary computation [1]. A posterior  \n[^0]probability distribution model based on globally statistical information from the selected solutions is built to generate new solutions for next generation. This new type of algorithms replaces the crossover and mutation operators in traditional genetic algorithms by learning and sampling the probability distribution of the promising individuals at per iteration. Working in such a way, the relationships between the variables involved in the problem could be captured and exploited. Among current multiobjective EDAs [1] [4], the regularity model-based multiobjective EDA (RM-MEDA) [1] solves MOPs unconventionally and shows good performance. RM-MEDA uses local principal component analysis algorithm to build the probability model. New individuals are sampled from the model.  \nAs we know, almost all the EDAs build probability distribution model by globally statistical information, therefore, it seems that they do not care about how to take advantage of the independent behavior of each individual. It is interesting that if we hybridize EDAs with individual behavior oriented algorithms. In recent years, artificial immune systems (AIS) have received significant amount of interest from researchers and industrial sponsors. Applications of AIS include such areas as machine learning, fault diagnosis, computer security, and optimization [5], [6]. Recently, immune inspired multiobjective algorithms have been proposed and obtain good performance [7] [8].  \nIn this study, we design a hybrid multiobjective EDA combining local linear embedding and an immune inspired algorithm. Local linear embedding (LLE) is a manifold learning algorithm [9]. Here, it is used to build the statistical model in the manifold space. Later, some of individuals are generated from the manifold model. Besides, the rest individuals are produced by an immune inspired sparse individual clone algorithm (SICA). The LLE based model is built by global statistical information, while SICA emphasizes the nondominated individuals in the sparse regions. Therefore, hybridization of the two methodologies is interesting to the optimization process. Experiments demonstrating the effectiveness of the hybridization scheme are provided for several state-of-the-art multiobjective problems.  \nThe remainder of this paper is organized as follows: Section II describes related background including the definitions of multobjective optimization and local linear embedding. Section III describes the main loop of HMEDA. In Section IV, experimental study is presented and experimental results are analyzed and summarized. Finally,  \n[^0]:    This work was supported by the National Natural Science Foundation of China (Grant Nos. 60703107, 60703108), the National High Technology Research and Development Program (863 Program) of China (Grant No. 2009AA12Z210), the National Basic Research Program (973 Program) of China (Grant No. 2006CB705700), the Program for New Century Excellent Talents in University, and the Program for Cheung Kong Scholars and Innovative Research Team in University (Grant No. IRT0645).",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:03",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs using the Bayesian Optimization Algorithm (BOA) combined with heuristics like DRC, DPS, and SDRC, specifically in relation to minimizing the probe set size?",
      "topics": [
        "heuristic"
      ],
      "answer": "The primary objective is to evaluate the performance of BOA, when combined with heuristics DRC, DPS, and SDRC (BOA+DRC, BOA+DPS, and BOA+SDRC respectively), in finding the minimum set of probes. This is assessed by comparing the cardinality of the minimal probe set obtained by these combinations against state-of-the-art approaches such as Integer Linear Programming (ILP), Optimal Cutting Plane Algorithm (OCP), and a Genetic Algorithm (DRC-GA). The improvement, Imp, is calculated using the formula Imp = (Pmin^(BOA+DRC) - Pmin^Method) / Pmin^Method * 100, where Method is ILP, OCP, or DRC-GA, to quantify the relative reduction in probe set size achieved by the BOA-based approaches.",
      "chunk_id": 6978,
      "paper_id": "Bayesian Optimization Algorithm for the Non-unique Oligonucleotide Probe Selection Problem",
      "paper_title": "Bayesian Optimization Algorithm for the Non-unique Oligonucleotide Probe Selection Problem",
      "paper_year": "2009",
      "chunk_content": "In all experiments, the parameters $c_{\\min }$ and $s_{\\min }$ were set to ten and five, respectively. Each run of BOA has been executed for 100 iterative steps. The number of probes in each dataset are the number of variables $(n)$ used in the BOA. Based on the convergence condition of BOA, mentioned in the section 4.1, the population size should be of $O\\left(2^{k} \\cdot n^{1.05}\\right)$. Two different series of experiments are performed, and the results are presented. In each series, we chose the population size for each dataset proportional to the number of the variables, which is sum of the number of real and the number of virtual probes of dataset. The considered level of dependency $(k)$ among variables is simulated by a parameter named maximum incoming edges in the BOA software.  \nExperiments with the default parameters. First series of experiments have been performed with the default parameters of BOA [15]. For instance, the maximum number of incoming edges to each node was set to two, and the percentage of the offspring and parents in the population was set to 50 . The results we obtain by applying this approach are presented in Table 4. The comparison between the results is based on the minimum set of probes obtained from each approach. We have named the combination of BOA and heuristics DRC, DPS, and SDRC respectively BOA+DRC, BOA+DPS, and BOA+SDRC. Three columns have been included related to experiments performed by state-of-the-art approaches Integer Linear Programming (ILP) [5 4, Optimal Cutting Plane Algorithm (OCP) [8, and Genetic Algorithm (DRC-GA) 11. The last three columns show the improvement of our approach over each of the three latest approaches. The improvement is calculated by Eq. 8.  \n$$\nI m p=\\frac{P_{\\min }^{B O A+D R C}-P_{\\min }^{M e t h o d}}{P_{\\min }^{M e t h o d}} \\times 100\n$$  \nwhere Method can be substituted by either ILP, OCP, or DRC-GA.  \nTable 4. Comparison of the cardinality of the minimal probe set for different approaches: Performance of various algorithms evaluated using ten datasets with different number of targets $(|T|)$, probes $(|P|)$, and virtual probes $(|V|)$. The last three columns are showing the improvement of BOA+DRC over three methods ILP, OCP, and DRC-GA (see Eq. 8).  \nThe calculated value of Imp is negative(positive) when BOA+DRC returns a probe set smaller(larger) than $P_{\\text {min }}^{\\text {Method }}$. Therefore, smaller value of Imp shows more efficiency of the BOA+DRC method. For instance, regarding Table 4 (last three columns), for dataset a3, our approach has obtained $0.18 \\%$ and $2.02 \\%$ better results (smaller probe set) than DRC-GA and OCP, respectively, and FORMULA_96 worse result (larger probe set) than ILP.  \nAs shown in the Table 4, the best results are obtained with the BOA+DRC, while we expected better results from the BOA+DPS, because the DPS has shown better performance on the non-unique probe selection [12]. The results obtained by the [8] are considered as the best ones in the literature for the non-unique probe selection problem. As shown in the 4, Wang et. al. [11] have recently reported the results (noted as DRC-GA) which are comparable to (and in most cases better than) [8].",
      "question_type": "evaluation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:05",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of using CMA-ES for parameter optimization in scenarios where target fields cannot be perfectly reproduced by the model, how do the ranges of optimized values for parameters such as $a_{\\mathrm{Zn}}$, $b_{\\mathrm{Zn}}$, $c_{\\mathrm{Zn}}$, $\\alpha_{\\mathrm{Zn}}$, and $-L$ reflect the identifiability of these parameters, given that the optimization algorithm almost always identifies a parameter set that provides a better fit than the reference values?",
      "topics": [
        "complexity"
      ],
      "answer": "When target fields cannot be perfectly reproduced, CMA-ES identifies a parameter set that gives a better fit than the reference parameter values, but does not exactly retrieve the reference values. The ranges of optimized parameter values reflect their identifiability. For instance, the parameters $b_{\\mathrm{Z\\mathrm{n}}}$ and $c_{\\mathrm{Z\\mathrm{n}}}$ span almost the entire range of allowed values, indicating lower identifiability. Conversely, $\\alpha_{\\mathrm{Zn}}$ and $-L$ span a relatively limited range, suggesting higher identifiability. Furthermore, the median values for $\\alpha_{\\mathrm{Zn}}$ and $L$ are close to the reference values, while the median value for $b_{\\mathrm{Zn}}$ is clearly higher than the reference value, and the value for $c_{\\mathrm{Zn}}$ coincides with the lower boundary. The parameter $a_{\\mathrm{Zn}}$ determines the asymptotic Zn:P value of the non-linear portion of the Zn uptake equation (Eq. 2). The fact that the optimized value for $c_{\\mathrm{Zn}}$ was found at its lower boundary in 70% of synObs experiments indicates the difficulty of constraining this parameter.",
      "chunk_id": 1418,
      "paper_id": "Influence of GEOTRACES data distribution and misfit function choice on objective parameter retrieval in a marine zinc cycle model",
      "paper_title": "Influence of GEOTRACES data distribution and misfit function choice on objective parameter retrieval in a marine zinc cycle model",
      "paper_year": "2022",
      "chunk_content": "Our TWIN experiments are a test case in which the model can exactly reproduce the synthetic observations. In these experiments, all parameter values were perfectly retrieved regardless of data coverage, even though calculating misfits in TWINIDP (i.e. with the data coverage of IDP2017) only involves $12 \\%$ of the data from the target field of TWINALL (perfect data coverage). Thus, the reduced and inhomogeneous spatial coverage of the GEOTRACES IDP2017 will not prevent the optimisation algorithm from converging to the correct parameter values if the observations can be perfectly matched by the model equations. Figure 3 shows the evolution of the parameter values and the logarithmic misfit during the TWINALL experiment. High variances reflect a wide range of parameter values in a single generation of 10 individual simulations and occur mainly at the beginning of the optimisation. For parameter $a_{\\mathrm{Zn}}$, which determines the asymptotic $\\mathrm{Zn}: \\mathrm{P}$ value of the non-linear portion of the Zn uptake equation (Eq. 2; Fig. 2), the average parameter value approaches the reference value earlier than for the other parameters.  \n[IMAGE2]  \nFigure 3. Evolution of parameter values and misfit (RMSE) in experiment TWINALL. Red lines indicate the target parameter values. Black trajectories show the mean parameter value over all individuals in each generation of 10 individuals, while blue lines mark maximum and minimum parameter values in the generation.  \nIn synObs experiments, i.e. when target fields cannot be perfectly reproduced by the model, CMA-ES does not exactly retrieve reference parameter values. However, optimisation almost always identifies a parameter set that gives a better fit to the target field than would have been produced with reference parameter values (Table S2). Figure 4 provides an overview of the range of values determined for each of the four biogeochemical parameters optimised in our optimisation ensemble. This overview shows that the various types of complexity we introduce into our synObs experiments lead to a range of optimised values for each parameter. While the optimised values for parameter $b_{\\mathrm{Z} \\mathrm{n}}$ and $c_{\\mathrm{Z} \\mathrm{n}}$ span (almost) the entire range of allowed values, those for parameter $\\alpha_{\\mathrm{Zn}}$ and to a lesser extent $-L$ span a relatively limited range (Fig. 4). Also, the median values for $\\alpha_{\\mathrm{Zn}}$ and $L$ lie close to the reference values, whereas the median value for $b_{\\mathrm{Zn}}$ is clearly higher than the reference value and that for $c_{\\mathrm{Zn}}$ coincides with the lower boundary. The fact that the optimised value for $c_{\\mathrm{Zn}}$ was found at its lower boundary in $70 \\%$ of synObs experiments leads to an interquartile range in Fig. 4 that appears relatively narrow, although its optimised values range over the entire allowed parameter space, indicating the difficulty of constraining this parameter.\n[IMAGE3]  \nFigure 4. Boxplots of optimised parameter values obtained in all synObsexperiments, presented in parameter space rescaled to the interval FORMULA_93, i.e. turquoise lines at 0 and 1 correspond to boundary values for each parameter. Red stars indicate the reference parameter values.",
      "question_type": "relationship",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:09",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm in conjunction with Differential Evolution, how should practitioners utilize EDA to accelerate convergence, as seen in hybrid approaches?",
      "topics": [
        "convergence"
      ],
      "answer": "To accelerate convergence in a hybrid DE with EDA, practitioners can employ the EDA to generate offspring, as demonstrated by the DE/GM algorithm which utilizes a Gaussian probabilistic model-based operator from the EDA. This involves using the EDA's probabilistic model to guide the generation of new candidate solutions, focusing the search on promising regions of the search space and speeding up the convergence process.",
      "chunk_id": 4118,
      "paper_id": "A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning",
      "paper_title": "A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning",
      "paper_year": "2023",
      "chunk_content": "Another popular and promising means of improving performance is incorporating various intelligent optimization algorithms with the superiority of each algorithm (Shi et al., 2022). The collaboration between the EDA and DE is representative. (Liao et al., 2019) presents a hybrid DE with EDA by the random walk mutation to preserve the population diversity, and the EDA is employed to accelerate the convergence. (Fang et al., 2018) develops a novel algorithm, named the DE/GM, which utilizes both crossover/mutation operators from the DE and a Gaussian probabilistic model-based operator from the EDA for offspring generation. (Zhou and Tan, 2020) studies a discrete supermarket location problem that considers the utilization rate and capacity constraint of the\n[IMAGE0]  \nFig. 1. The main idea of KCACIL.  \n[IMAGE1]  \nFig. 2. The flow chart of KCACIL.\nsupermarkets by a self-adaptive EDA with a differential DE. In (Zhou and Tan, 2020), a hybrid DE with EDA using an ensemble model is studied to minimize the total weighted completion time for a reentrant hybrid flow shop scheduling problem.  \nThe performance of the algorithms is related to exploration and exploitation in the search space (Zhao et al., 2022a). Exploration finds the potential area where the optimal solution is located and involves searching over a large range. Exploitation focuses on the precise location and a refined search over a small area (Khishe, 2020). If the exploration is emphasized excessively, it improves the potential to find the optimal solution but ignores the accuracy of the generated solutions. In contrast, the candidate solutions are refined when only the exploitation is focused. However, the opportunity to seek high-quality solutions from the global area is abandoned, and the search falls into the local optimum. Exploration is vital during the early stage of the algorithms, and refined exploitation is paid more attention during the later evolution (Givi and Hubalovska, 2023). Hence, the trade-off between exploration and exploitation is essential to achieve promising effects. The design of a reasonable algorithm framework and efficient rules are indispensable and challenging (Karaduman et al., 2019).  \nDynamic adaptive adjustment of key parameters is beneficial for exploration and exploitation. (Liao et al., 2023a) presents a knowledge transfer-based adaptive DE that carries out parameter adaptation with niching level and knowledge transfer between two niching techniques to balance diversity and convergence. Reasonable individuals are selected for the transfer to overcome the deficiencies of crowding and speciation. (Huynh et al., 2021) implements the Q-learning DE, which integrates the Q-learning model into the DE to adaptively adjust the control parameters of the algorithm at each iteration for different search domains. (Wei et al., 2020) presents a PSO variant based on multiple adaptive strategies (MAPSO) with an adaptive strategy for the population size. (Liao et al., 2023b) develops a neighborhood information-based adaptive DE with a dynamic neighborhood size mechanism and a novel mutation strategy. (Xiong et al., 2023) develops an enhanced neighborhood-based\nspeciating DE with adaptive control parameters, an external archive, and a crowding relieving mechanism to solve multimodal optimization problems. The aforementioned research shows that parameter adaptation is helpful for exploration and exploitation and saves computational resources. However, multiple-parameter adaptive strategies combined with diverse mechanisms to fully achieve automatic configuration based on various stages is rare.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:10",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA-LGD, what mathematical property of the Gradient-driven densities ($\\nabla_{d} \\mathrm{D}$) allows it to be considered a predictive model?",
      "topics": [
        "convergence"
      ],
      "answer": "The Gradient-driven densities ($\\nabla_{d} \\mathrm{D}$) used in EDA-LGD produce samples in a similar direction as the gradient estimation. This property allows the density to be regarded as a predictive model. The Gradient-Driven density explores the search domain, while the empirical density intends fast convergence, balancing exploration and exploitation.",
      "chunk_id": 928,
      "paper_id": "A New EDA by a Gradient-Driven Density",
      "paper_title": "A New EDA by a Gradient-Driven Density",
      "paper_year": "2014",
      "chunk_content": "This paper presents a new EDA based on the Gradient-driven densities $\\left(\\nabla_{d} \\mathrm{D}\\right)$. In order to build the proposed EDA (EDA-LGD) two main contributions were developed: the Expected Gradient Estimate (EGE) and the $\\nabla_{d} \\mathrm{D}$. Also, a technique has been proposed to compute a gradient estimate for any individual only by using the actual knowledge about the problem. Hence, the estimation of the gradient does not need extra evaluations of function. The $\\nabla_{d} \\mathrm{D}$ are statistical models built by taking into account a gradient estimate. This new framework can create a density function for any individual. Consequently, any simulation from those densities has a random gradient component. Here, Gradient-driven densities based on the Multivariate Normal have been constructed. However, the developed framework allows for the assumption of other statistical models. The ideas discussed above motivated a new EDA: EDA-LGD. It is based on the Gradient-driven Independent Normal, the EGE and the hierarchical latent variable model. Moreover, it was tested in 10 benchmark problems; where the EDA-LGD shows competitive performance against CMA-ES and xNES. In summary, the EDA-LGD is an interesting approach because of the performance of the algorithm and its mathematical foundation. Since the $\\nabla_{d} \\mathrm{D}$ will produce samples in a similar direction as the gradient estimation, this density can be regarded as a predictive model. Thus, the Gradient-Driven density allows for exploration of the search domain whilst the empirical density intends fast convergence (exploitation). Finally, notice that the main contributions developed here can be extended to other evolutionary algorithms.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:12",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the hybrid EDA-PSO approach compare to that of continuous EDAs alone, specifically concerning the number of generations and evaluations required for convergence on problems with varying local optima complexity?",
      "topics": [
        "convergence",
        "Estimation of Distribution Algorithms",
        "Particle Swarm Optimization",
        "performance comparison",
        "local optima"
      ],
      "answer": "On problems without local optima, like Sphere, the hybrid EDA-PSO approach does not show its full potential. However, for Ackley functions, where local optima have larger valleys than in Griewangk, EDA-PSO demonstrates an increase in performance compared to EDA alone. In Griewangk functions, which feature small local optima, EDA-PSO allows convergence in fewer generations and with a slight reduction in the number of individuals evaluated. Statistical tests show a p-value of 0.706 for the number of generations between EDA and all EDA-PSO executions, and a p-value less than 0.001 for the number of evaluations. Comparing EDA and EDA-PSO with P=10, p-values less than 0.001 are obtained for both the number of generations and evaluations.",
      "chunk_id": 7664,
      "paper_id": "EDA-PSO- A Hybrid Paradigm Combining Estimation of Distribution Algorithms and Particle Swarm Optimization",
      "paper_title": "EDA-PSO: A Hybrid Paradigm Combining Estimation of Distribution Algorithms and Particle Swarm Optimization",
      "paper_year": "2010",
      "chunk_content": "Table 1. Mean results of each of the problems and algorithms. Here are cases of $N=100$ for $\\mathrm{EGNA}_{\\mathrm{ee}}$, and $N=50$ for $\\mathrm{UMDA}_{\\mathrm{e}}$ and $\\mathrm{MIMIC}_{\\mathrm{e}}$. The Gen. column is the mean generations and Eval. corresponds to the mean number of evaluations. In cases in which not all executions converged, Gen. shows the convergence percentage and Eval. is the mean fitness obtained out of all executions.\nThis table also illustrates the complementarity of this hybrid EDA and PSO approach for optimization problems of different complexity. When there are no no local optima like in Sphere, the contribution of our hybrid approach does not show all its potential. For the case of Ackley where local optima have bigger valleys than in Griewangk, in all cases an increase of performance is shown with EDA-PSO over EDA, although the choice $P=50$ appears the best for EGNA while UMDA performs better with $P=10$. Finally, when having small local optima such as in Griewangk EDA-PSO allows convergence in less generations as well as a small reduction on the number of individuals evaluated to reach converge. In order to check statistical significance between algorithms' behavior the non-parametric tests of Kruskal-Wallis and Mann-Whitney were applied. The null hypothesis of the same distribution densities was tested between EDA and all EDA-PSO executions obtaining $p=0.706$ for the number of generations and $p<0.001$ for such of evaluations respectively. On the other hand, considering the cases of EDA and EDA-PSO with $P=10 p<0.001$ was obtained both for the number of generations and evaluations.\nThis work demonstrates the validity of a new full hybrid EDA-PSO approach, analysing its performance depending on the nature and complexity of the optimization problem. Preliminary experimental results to compare the performance of this new approach on typical optimization problems in continuous domains have been shown, and they have been compared with such of continuous EDAs. At the light of the results we can conclude that EDA-PSO has proved to be a new paradigm capable of improving the results of continuous EDAs, where the  \nnumber of particles have an important influence on the efficiency of the algorithm and can contribute to better efficiency when set adequately.  \nThere is a lot of space for improvement and future research by applying diverse variants on how to hybridate EDA and PSO when updating each generation FORMULA_97 which we are currently studying. Future work also is to be done with other well known optimisation problems such as Schwefel or Griewangk, and also other problems in which both EDA and PSO are known not to perform efficiently (such as satisfactibility problems).  \nAcknowledgments. This work has been partially supported by the Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Government), TIN2008- 06815-C02-01 and Consolider Ingenio 2010 - CSD2007- 00018 projects (Spanish Ministry of Science and Innovation) and COMBIOMED network in computational biomedicine (Carlos III Health Institute).",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:14",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model, specifically when using Univariate Marginal Distribution Algorithms (UMDAs) for resource allocation in cognitive radio systems?",
      "topics": [
        "search"
      ],
      "answer": "The text indicates that Estimation-of-Distribution Algorithms (EDAs) are used to produce a new population by evaluating probability density distribution rather than manipulating strings, as done in genetic algorithms. When implementing the EDA model with Univariate Marginal Distribution Algorithms (UMDAs), the primary step involves evaluating the probability density distribution to generate new populations for relay assignment and subcarrier allocation. The text mentions this approach is chosen due to its simplicity, implying that the implementation focuses on univariate marginal distributions for this probabilistic evaluation.",
      "chunk_id": 11714,
      "paper_id": "EDA-based Joint Power",
      "paper_title": "EDA-based Joint Power, Subcarrier Allocation and Relay Assignment Scheme for Multiuser Relaying in OFDMA-based Cognitive Radio Systems",
      "paper_year": "2011",
      "chunk_content": "Recently, Cognitive Radio [1], [2], [3] has gained much attention of engineers and researchers as it suggests a solution to the problem of spectrum scarcity. The scheme allows the secondary users (SUs) to utilize [4], [5] frequency bands of the licensed primary users (PUs) [6] as long as the SUs avoid causing unacceptable interference to the PUs. In the system of the SUs, using relays is helpful for reducing the interference to the PUs because the secondary user nodes' transmission power can be reduced if their communication is assisted by the relays. Orthogonal Frequency Division Multiple Access (OFDMA) [7] has been developed as one of the most promising techniques for high performance transmission in cellular networks. In this paper, we consider the problem of efficiently allocating wireless resources in OFDMA-based cognitive radio systems.  \nWe consider the downlink of a cognitive radio system comprising a single source, multiple relays employing decode and forward (DF) relaying [8] on multiple receivers. We focus on the method of jointly assigning transmission power and subcarriers to the relays and subcarriers to the receivers with the objective of maximizing the sum rate capacity for all receivers.  \nWe consider the spectrum underlay approach [3], in which SUs are allowed to access PU's channels as long as the interference due to them is below a specified limit. The objective of our joint allocation is to maximize the sum capacity of the receivers under the constraints defined by the spectrum underlay approach. In a DF [8],[9],[10] relaying scheme, a relay receives the signal from the source, decodes it and forwards it to the destination. The performance of the system improves when we use multiple relays rather than a single relay. In the multiple relay scenario, one issue is how to assign the relays to the receivers and allocate relay powers in the best way to maximize the performance and satisfy the interference constraint on the PUs too. OFDMA separates signals carried by different subcarriers, so another issue is how to allocate subcarriers to different users and different relays. Regarding the previous related works, [11] provides a power allocation scheme for OFDM based Cognitive Radio Systems but doesn't take cooperative communication into consideration. Reference [10] provides assignment of relays and subcarriers but does not look into the Cognitive Radio technique. In [12], [13] an efficient scheme for multiple relay selection in Cognitive Radio Systems is introduced but it is not for OFDMA systems.  \nExhaustive search algorithm could be considered for such relay assignment and subcarrier allocation for optimal solution but its complexity increases exponentially with the number of relays, subcarriers and SUs. In this paper we explore the idea of using Estimation-of-Distribution Algorithms (EDA) [14], which is categorized as a probabilistic evolutionary algorithm. Unlike the genetic algorithm, EDA produces a new population by evaluating probability density distribution rather than manipulating strings. In this paper, we experiment with the univariate marginal distribution algorithms (UMDAs) [14] due to its simplicity. The rest of the paper is organized in this way: Section 2 presents our system model, section 3 presents our  \nEDA based algorithm, Upper Bound calculation is explained in section 4 and simulation results in section 5.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:16",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output be measured using the criteria of convergence performance when applied to large knapsack problems?",
      "topics": [
        "optimization"
      ],
      "answer": "The convergence performance of Estimation of Distribution Algorithms on large knapsack problems (specifically, problems with 10000 and 20000 items) serves as a measure of their success in escaping from local optima. Datasets are randomly generated using classical methods. The performance is evaluated by observing the algorithm's ability to escape local optima during the entire evolution process.",
      "chunk_id": 818,
      "paper_id": "An exploratory research of elitist probability schema and its applications in evolutionary algorithms",
      "paper_title": "An exploratory research of elitist probability schema and its applications in evolutionary algorithms",
      "paper_year": "2014",
      "chunk_content": "The population size of the PeCGA was set to 100 to adapt it to the large knapsack problem. The termination condition was set to 600 generations. The other parameters were the same as described in Sect. 5.1.  \n[IMAGE2]  \nFig. 9 Convergence curves on large knapsack problem (10000 items)\n[IMAGE3]  \nFig. 10 Convergence curves on large knapsack problem (20000 items)\nThe large knapsack problem is one of the most difficult problems in combinatorial optimization. Generally, there are much more local optima than in the small knapsack problems. Therefore, the convergence performance of EAs on the large knapsack problem can be used to evaluate how successfully they are at escaping from local optima.  \nWe ran experiments for the large knapsack problems (10000 items and 20000 items). The specified datasets were randomly generated using the classical methods of generating test datasets (see Sect. 3.2). The proposed algorithms significantly outperformed the other algorithms in Figs. 9 and 10. During the whole evolution process, the proposed algorithms escaped from the local optima. This is a very valuable characteristic for solving the large knapsack problems in real applications.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:17",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of CEGO and UMM when initialized with a greedy nearest neighbor solution in the context of permutation optimization?",
      "topics": [
        "convergence"
      ],
      "answer": "When initialized with a greedy nearest neighbor solution, CEGO typically improves upon this initial solution, leveraging the good starting point to build a surrogate model, although it can become stuck due to the surrogate model's limitations in accurately estimating the objective function. In contrast, UMM struggles to find improving solutions from the greedy start because its sampling of new permutations is strongly biased by the relatively high objective value of the initial greedy solution, causing it to remain stuck.",
      "chunk_id": 1402,
      "paper_id": "The Asteroid Routing Problem- A Benchmark for Expensive Black-Box Permutation Optimization",
      "paper_title": "The Asteroid Routing Problem: A Benchmark for Expensive Black-Box Permutation Optimization",
      "paper_year": "2022",
      "chunk_content": "In this section, we evaluate the effect of providing a good initial solution to the UMM-rank and CEGO-order variants selected above. This initial solution is generated using the greedy nearest neighbor heuristic as the initial point of the max-min-distance sequential design, as explained above, that creates the 10 initial solutions of both UMM and CEGO.  \nFigure 3 shows the evolution of the algorithms. In addition to the results provided by CEGO and UMM with and without the initial greedy solution, we plot the objective function value of the greedy solution as a horizontal line. Table 3 provides a summary of the results of the two best variants of CEGO and UMM together with the result obtained by the Greedy Nearest Neighbor Heuristic. A first observation is that UMM only reaches the fitness level of the greedy solution after 10 evaluations. The reason is that we evaluate first the 9 random solutions generated by the max-min-distance design to show how much the greedy solution improves over them. Moreover, without knowledge of the  \nTable 2. p-values of a Wilcoxon sumrank test of all the hypotheses checked in during the experimental study for each instance of the problem. Columns two and three correspond to a test comparing the two representations (rank and order) for CEGO and UMM in a black-box setting. The fourth column compares the best black-box UMM (using ranking) with the best black-box CEGO (using order). The final two columns compare UMM-ranking and CEGO-order in a black-box versus informed settings (including the greedy initialization).\nTable 3. Objective value of the best solution found by each algorithm in a single run. For CEGO and UMM, the values are the mean (and standard deviation) over 30 independent runs.\ngreedy solution, CEGO or UMM are only able to match the greedy solution under 400 evaluations on a few small instances $(n \\leq 20)$. Unsurprisingly, when starting from the greedy solution, both algorithms outperform their uninformed counterparts. However, UMM struggles to find any improving solutions, whereas  \n[IMAGE1]  \nFig. 2. Convergence of the best-so-far objective value over the number of evaluations. Each line is the mean value over 30 runs and the shaded area is the FORMULA_153 confidence interval around the mean. The instances shown are 15.42 (top) and 25.73 (bottom).  \nCEGO is typically able to further improve the greedy solution, although not by much. In the case of UMM, this behavior is explained by the fact that the sampling of new permutations is strongly biased by the relative objective values of the permutations already evaluated. Since the greedy solution is so much better than any other initial permutation, the algorithm remains stuck at the initial permutation. In the case of CEGO, starting from a good initial solution provides a good starting point around which the surrogate model can be built. However, in several instances, after a quick initial improvement of the greedy solution, CEGO appears stuck and unable to further find any improvements. This behavior of CEGO was already reported for other problems [6] and it is attributed to the inability of the surrogate model to accurately estimate the underlying objective function beyond a certain point, thus leading to a blind search.",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:19",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms (EDAs), how does the algorithmic mechanism of estimating the probability distribution directly influence the search for Pareto optimal solutions?",
      "topics": [
        "optimization"
      ],
      "answer": "The Estimation of Distribution Algorithm (EDA) uses a probability model to guide the search for optimal solutions. The EDA procedure involves initializing a population and a probability model, then sampling this model to generate a new population. A critical step is estimating the probability distribution, where different probability models are established based on the characteristics of the problem to estimate a reasonable promising probability distribution. The elite population is constructed, and the probability model is updated based on this elite population. This updated model is then used in subsequent iterations to generate new populations, iteratively refining the search towards the Pareto set.",
      "chunk_id": 4397,
      "paper_id": "Reduction of carbon emissions and project makespan by a Pareto-based estimation of distribution algorithm",
      "paper_title": "Reduction of carbon emissions and project makespan by a Pareto-based estimation of distribution algorithm",
      "paper_year": "2015",
      "chunk_content": "Let $x=\\left\\{x_{j m t}, j \\in \\boldsymbol{J}^{+}, m=1,2, \\ldots, M_{j}, t=1,2, \\ldots, T\\right\\}$ be a solution and $\\chi$ be the set of all solutions. Consider two solutions $x_{1}, x_{2} \\in \\chi$, $x_{1}$ dominates $x_{2}\\left(x_{1}>x_{2}\\right)$ if\n$M S\\left(x_{1}\\right) \\leq M S\\left(x_{2}\\right) \\quad$ and $\\quad \\operatorname{Carbon}\\left(x_{1}\\right) \\leq \\operatorname{Carbon}\\left(x_{2}\\right)$\nwhere at least one of the inequalities is strict. A solution $x$ is called a Pareto optimal solution or a non-dominated solution iff there does not exist another solution $x^{\\prime} \\in \\chi$ that dominates $x$. The Pareto set is constituted by all Pareto optimal solutions.  \nA simple example of the MOMRCPSP-Makespan-Carbon with four activities is shown in Fig. 3, in which activity 0 and activity 3 are dummy activities. An activity-on-node network is used to represent the project, where activities are denoted as nodes and precedent restraints between activities are denoted as arcs. Each non-dummy activity has two modes. The power requirements and corresponding durations are shown in Table 1. The peak power load limit is 16 , i.e., $P_{\\max }=16$, and the quantity of carbon emissions per unit of electric energy consumption is 1 , i.e., $\\varepsilon=1$. The Pareto set is presented in Fig. 4.\nAs a relatively new paradigm in the field of evolutionary computation, EDA (Larranaga and Lozano, 2002; Lozano et al., 2006) is a general framework of statistical learning based optimization algorithm. With statistical analysis tool, the EDA makes the population movement track the promising search areas based on the available experience. For a minimization problem, the procedure of the EDA is shown below.  \nStep 1: Initialize the population and the probability model.\nStep 2: Sample the probability model to generate a new population.  \nStep 3: Construct the elite population and update the probability model.\nStep 4: Go to Step 2 unless a stopping criterion is met.  \nThe critical step of the EDA procedure is to estimate the probability distribution. According to the characteristics of different problems, different probability models should be established to estimate the reasonable promising probability distribution. In the next section, a specially designed EDA with a probability model and an updating mechanism will be presented to obtain a Pareto set for the low-carbon production scheduling problem.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:21",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to optimize the non-convex function f5, how should practitioners handle the `u(x_i, a, k, m)` component, specifically concerning the parameters `a`, `k`, and `m`?",
      "topics": [
        "optimization"
      ],
      "answer": "When optimizing the non-convex function f5 using an Estimation of Distribution Algorithm, the component `u(x_i, a, k, m)` requires careful consideration. Specifically, `u(x_i, a, k, m)` is defined piecewise. If `x_i` is greater than `a`, then `u(x_i, a, k, m)` equals `k(x_i - a)^m`. If `x_i` is between `-a` and `a`, then `u(x_i, a, k, m)` is 0. If `x_i` is less than `-a`, then `u(x_i, a, k, m)` equals `k(-x_i - a)^m`. For function f5, the parameters are defined as `a = 10`, `k = 100`, and `m = 4`. Therefore, during the EDA's sampling and evaluation steps, these specific values must be used when calculating the fitness of each solution.",
      "chunk_id": 13333,
      "paper_id": "Hybrid estimation of distribution algorithm for global optimization",
      "paper_title": "Hybrid Estimation of Distribution Algorithm for Global Optimization",
      "paper_year": "2004",
      "chunk_content": "The following well-known functions are used in our experimental studies. All these functions are non-convex functions with many local minima.  \n$$\n\\begin{aligned}\nf_{1} & =\\sum_{i=1}^{n}\\left(-x_{1} \\sin \\left(\\sqrt{\\left|x_{i}\\right|}\\right)\\right. \\\\\nf_{2} & =\\sum_{i=1}^{n}\\left(-x_{i}^{2}-10 \\cos \\left(2 \\pi x_{i}\\right)+10\\right) \\\\\nf_{3} & =-20 \\exp \\left(-0.2 \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{2}}\\right)-\\exp \\left(\\sum_{i=1}^{n} \\cos \\left(2 \\pi x_{i}\\right)\\right) \\\\\nf_{4} & =\\frac{1}{4,000} \\sum_{i=1}^{n}\\left(-x_{i}^{2}-\\prod_{i=1}^{n} \\cos \\left(\\frac{x_{i}}{\\sqrt{i}}\\right)+1\\right) \\\\\nf_{5}= & \\frac{\\pi}{n}\\left\\{10 \\sin ^{2}\\left(\\pi y_{i}\\right)+\\sum_{i=1}^{n-1}\\left(y_{i}-1\\right)^{2}\\left[1+10 \\sin ^{2}\\left(\\pi y_{i+1}\\right)\\right]+\\left(y_{n}-1\\right)^{2}\\right\\} \\\\\n& +\\sum_{i=1}^{n} u\\left(x_{i}, 10,100,4\\right)\n\\end{aligned}\n$$  \nwhere  \n$$\ny_{i}=1+\\frac{1}{4}\\left(x_{i}+1\\right)\n$$  \nand  \n$$\n\\begin{aligned}\n& u\\left(x_{i}, a, k, m\\right)= \\begin{cases}k\\left(x_{i}-a\\right)^{m} & x_{i}>a \\\\\n0 & -a \\leq x_{i} \\leq a \\\\\nk\\left(-x_{i}-a\\right)^{m} & x_{i}<-a\\end{cases} \\\\\n& f_{6}=\\frac{1}{10}\\left\\{\\sin ^{2}\\left(3 \\pi x_{1}\\right)+\\sum_{n=1}^{n-1}\\left(x_{i}-1\\right)^{2}\\left[1+\\sin ^{2}\\left(3 \\pi x_{i+1}\\right)\\right]\\right. \\\\\n& \\left.+\\left(x_{n}-1\\right)^{2}\\left(\\left[1+\\sin ^{2}\\left(2 \\pi x_{n}\\right)\\right]\\right)\\right\\}+\\sum_{i=1}^{n} u\\left(x_{i}, 5,100,4\\right) \\\\\n& f_{7}=-\\sum_{i=1}^{n} \\sin \\left(x_{i}\\right) \\sin ^{m}\\left(\\frac{i \\times x_{i}^{2}}{\\pi}\\right) \\\\\n& f_{8}=-\\sum_{i=1}^{n}\\left[\\sum_{j=1}^{n}\\left(a_{i j} \\sin \\omega_{j}+b_{i j} \\cos \\omega_{j}\\right)-\\sum_{j=1}^{n}\\left(a_{i j} \\sin x_{j}+b_{i j} \\cos \\omega_{j}\\right)\\right]\n\\end{aligned}\n$$  \nwhere $a_{i j}$ and $b_{i j}$ are random integers in $[-100,100]$, and $\\omega_{j}$ is a random number in $[-\\pi, \\pi]$.  \nFORMULA_183  \nThe basic characteristics of these test functions are given in Table I.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:23",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed with infinite population size and truncation selection having threshold \\(\\mu\\), what is the mathematical relationship between the number of iterations and the initial value \\(d(\\xi(0))\\) that guarantees the termination condition is met, and what is the convergence rate of the sequence \\(\\{d(\\xi(n)) ; n=0,1,2, \\ldots\\}\\) to 0?",
      "topics": [
        "convergence"
      ],
      "answer": "For an EDA with infinite population size and truncation selection with threshold \\(\\mu\\), the termination condition is met after \\(1+(\\log (1-d(\\xi(0))) / \\log \\mu)\\) iterations, where \\(d(\\xi(0))\\) represents the initial value of the probability that a randomly selected solution \\(\\mathbf{X}\\) from the search space \\(D^*\\) is not a global optimum at iteration 0. The sequence \\(\\{d(\\xi(n)) ; n=0,1,2, \\ldots\\}\\), which represents the probability that a randomly selected solution is not a global optimum at iteration \\(n\\), converges to 0 with a convergence rate of \\(1 / \\mu\\), according to the definition \\(\\lim _{n \\rightarrow \\infty} \\frac{\\left|a_{n+1}-a^{*}\\right|}{\\left|a_{n}-a^{*}\\right|}=\\beta\\), where \\(\\beta\\) is the convergence rate.",
      "chunk_id": 13063,
      "paper_id": "A study on the global convergence time complexity of estimation of distribution algorithms",
      "paper_title": "A study on the global convergence time complexity of estimation of distribution algorithms",
      "paper_year": "2005",
      "chunk_content": "$$\n\\begin{aligned}\n& E\\{d(\\xi(n))-d(\\xi(n+1)) \\mid d(\\xi(n))>0\\} \\geq\\left(\\frac{1}{\\mu}-1\\right)(1-d(\\xi(0)))= \\\\\n& \\frac{1}{\\frac{\\mu}{(1-\\mu)(1-d(\\xi(0)))}}=\\frac{1}{h_{1}}\n\\end{aligned}\n$$  \nFrom (16) and (17) we conclude that conditions of Lemma 3 are satisfied and therefore we can write,  \n$$\nE\\{\\tau \\mid d(\\xi(0))>0\\} \\leq h_{0} h_{1}=\\frac{\\mu d(\\xi(0))}{(1-\\mu)(1-d(\\xi(0)))}\n$$  \nHence the proof. Q.E.D.\nProof theorem 2: Using the definition of $d(\\xi(n))$ and steps 2 and 3 of EDA algorithm, we can write,  \n$$\n\\begin{aligned}\n& E\\{d(\\xi(n))-d(\\xi(n+1)) \\mid \\xi(n)\\}=E\\left\\{\\sum_{\\mathbf{x} \\in D^{*}} P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n+1))-\\right. \\\\\n& \\left.\\sum_{\\mathbf{x} \\in D^{*}} P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n)) \\mid \\xi(n)\\right\\}=E\\left\\{\\sum_{\\mathbf{x} \\in D^{*}} P\\left(\\mathbf{X}=\\mathbf{x} \\mid \\xi^{S}(n)\\right)-\\sum_{\\mathbf{x} \\in D^{*}} P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n)) \\mid \\xi(n)\\right\\}\n\\end{aligned}\n$$  \nUsing (3) and the fact that for all $\\mathbf{y} \\in \\mathrm{D}$ we have $f_{\\max } \\geq f(\\mathbf{y})$, we can rewrite (18) as  \n$$\n\\begin{aligned}\n& E\\left\\{\\sum_{\\mathbf{x} \\in D^{*}}\\{2 P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n)) \\underbrace{\\int_{f_{\\max }=f(\\mathbf{x}) \\geq f(\\mathbf{y})} P(\\mathbf{X}=\\mathbf{y} \\mid \\xi(n))}_{1}-\\sum_{\\mathbf{x} \\in D^{*}} P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n)) \\mid \\xi(n)\\right\\} \\\\\n& E\\left\\{\\sum_{\\mathbf{x} \\in D^{*}} P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n)) \\mid \\xi(n)\\right\\}=(1-d(\\xi(n)))\n\\end{aligned}\n$$  \nUsing (19) and induction on $n$ we can write  \n$$\nd(\\xi(n)) \\leq d(\\xi(0))=h_{0}\n$$  \nUsing the (18), (19) and (20) we have  \n$$\nE\\{d(\\xi(n))-d(\\xi(n+1)) \\mid \\xi(n)\\} \\geq(1-d(\\xi(0)))=\\frac{1}{h_{1}}\n$$  \nSince conditions of Lemma 3 are satisfied and we have,  \n$$\nE\\{\\tau \\mid d(\\xi(0))>0\\} \\leq h_{0} h_{1}=\\frac{d(\\xi(0))}{1-d(\\xi(0))}\n$$  \nHence the theorem. Q.E.D.\nIn this section, some strong results about the convergence of EDA are derived. As stated before $\\{d(\\xi(n)) ; n=0,1,2, \\ldots\\}$ is a random sequence in general and when population size tends to infinity this sequence becomes a deterministic sequence. In other words by knowing $d(\\xi(n-I))$ we can compute the exact value of $d(\\xi(n))$. We can use these properties to derive some strong results about the convergence of EDA.\nDefinition 1. (Convergence Rate). Let $\\left\\{a_{n} ; n=0,1,2, \\ldots\\right\\}$ be a sequence that converges to $a^{*}$. If we have  \n$$\n\\lim _{n \\rightarrow \\infty} \\frac{\\left|a_{n+1}-a^{*}\\right|}{\\left|a_{n}-a^{*}\\right|}=\\beta\n$$  \nthen $\\left\\{a_{n} ; n=0,1,2, \\ldots\\right\\}$ converges to $a^{*}$ with convergence rate $\\beta$.\nThe results for the exact number of iterations needed for EDA to converge to global optima reported in this paper can be summarized by the following two theorems\nTheorem 3. If we use an EDA with infinite population size and truncation selection method having threshold $\\mu$ then a) After $1+(\\log (1-d(\\xi(0))) / \\log \\mu)$ iterations the condition of termination is met. b) $\\{d(\\xi(n)) ; n=0,1,2, \\ldots\\}$ converges to 0 with convergence rate $1 / \\mu$.\nTheorem 4. If we use an EDA with infinite population size and 2 -tornumant selection method, then a) After $1+(\\log (1-d(\\xi(0))) / \\log 0.5)$ iterations the condition of termination is met. b) $\\{d(\\xi(n)) ; n=0,1,2, \\ldots\\}$ converges to 0 with convergence rate 2 .  \nBefore we give the proofs of theorems 3 and 4 , we state two lemmas for the computation of $d(\\xi(n))$.  \nLemma 4. For EDA algorithm with infinite population size and truncation selection method $d(\\xi(n))$ can be computed as follows,  \n$$\nd(\\xi(n))=1-(1-d(\\xi(0))) \\frac{1}{\\mu}^{n}\n$$  \nwhere $0<\\mu<l$ is the selection threshold.\nProof. We the definition $d(\\xi(n))$ and (2) we have,  \n$$\n\\begin{aligned}\nd(\\xi(n+1)) & =1-\\sum_{\\mathbf{x} \\in D^{n}} P(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n+1))=1-\\sum_{\\mathbf{x} \\in D^{n}} P\\left(\\mathbf{X}=\\mathbf{x} \\mid \\xi^{S}(n)\\right) \\\\\n& =1-\\frac{1}{\\mu} \\sum_{\\mathbf{x} \\in D^{n}} P\\left(\\mathbf{X}=\\mathbf{x} \\mid \\xi(n)\\right)=1-\\frac{1}{\\mu}(1-d(\\xi(n)))\n\\end{aligned}\n$$  \nFrom (21) we have  \n$$\nd(\\xi(n+1))-\\frac{1}{\\mu} d(\\xi(n))=\\left(1-\\frac{1}{\\mu}\\right)\n$$  \nCharacteristic equation of (22) is,  \n$$\nr^{2}-\\left(\\frac{1}{\\mu}+1\\right) r+\\frac{1}{\\mu}=0\n$$  \nBy solving (23) we have  \nFORMULA_184",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:26",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What algorithmic differences exist between the polytree approximation distribution algorithm (PADA) for binary variables and the Gaussian Polytree EDA for continuous variables?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Gaussian Polytree",
        "Polytree Approximation Distribution Algorithm"
      ],
      "answer": "The polytree approximation distribution algorithm (PADA) models distributions in EDAs using polytrees, but it is designed for binary variables. The Gaussian Polytree EDA extends this approach to continuous variables, specifically using Gaussian variables within the polytree structure. A key difference lies in the orientation principle, where the Gaussian Polytree EDA uses conditional mutual information for orientation, and also incorporates overfitting control by comparing conditional and marginal mutual information strengths to determine a threshold value.",
      "chunk_id": 11551,
      "paper_id": "Global Optimization with the Gaussian Polytree EDA",
      "paper_title": "Global Optimization with the Gaussian Polytree EDA",
      "paper_year": "2011",
      "chunk_content": "Ignacio Segovia Dominguez, Arturo Hernandez Aguirre, and Enrique Villa DiharceCenter for Research in MathematicsGuanajuato, Mexico\\{ijsegoviad,artha, villadi\\}@cimat.mx\nThis paper introduces the Gaussian polytree estimation of distribution algorithm, a new construction method, and its application to estimation of distribution algorithms in continuous variables. The variables are assumed to be Gaussian. The construction of the tree and the edges orientation algorithm are based on information theoretic concepts such as mutual information and conditional mutual information. The proposed Gaussian polytree estimation of distribution algorithm is applied to a set of benchmark functions. The experimental results show that the approach is robust, comparisons are provided.  \nKeywords: Polytrees, Estimation of Distribution Algorithm, Optimization.\nThe polytree ia a graphical model with wide applications in artificial intelligence. For instance, in belief networks the polytrees are the de-facto graph because they support probabilistic inference in linear time [13. Other applications make use of polytrees in a rather similar way, that is, polytrees are frequently used to model the joint probability distribution (JPD) of some data. Such JPD is also called a factorized distribution because the tree encodes a joint probability as a product of conditional distributions.  \nIn this paper we are concerned with the use of polytrees and their construction and simulation algorithms. Further more, we asses the improvement that polytrees bring to the performance of Estimation of Distribution Algorithms (EDAs). As mentioned the polytree graphs have been applied by J. Pearl to belief networks [13], but also Acid and de Campos researched them in causal networks [1], 14. More recently, M. Soto applied polytrees to model distributions in EDAs and came up with the polytree approximation distribution algorithm, known as PADA [11. However, note that in all the mentioned approaches the variables are binary. The goal of this paper is to introduce the polytree for continuous variables, that is, a polytree in continuous domain with Gaussian variables and its application to EDAs for optimization. The proposed approach is called the Gaussian Polytree EDA. Polytrees with continuous variables have been studied  \nby Ouerd [12], 9]. In this paper we extend a poster presented [16] and we further develop the work of Ouerd [12]. We introduce two new algorithmic features to the gaussian polytree: 1) a new orientation principle based on conditional mutual information. We also prove that our approach is correct, 2) overfitting control of the model through a comparison of conditional and marginal mutual information strengths. The determination of the threshold value is also explained.  \nThis paper is organized as follows. Section 2 describes two polytree algorithms in discrete variables; Section 3 explains how to build a Gaussian polytree while Section 4 provides the implementation details. Section 5 describes two sets of experiments and provides a comparison with other related approaches. Section 6 provides the conclusions and lines of future research.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:28",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What programming techniques are suggested to optimize the EDA's, specifically the $UMDA^{G}$, convergence, and what data should be monitored to implement a suitable stopping criterion?",
      "topics": [
        "convergence",
        "UMDA^G",
        "stopping criterion",
        "optimization"
      ],
      "answer": "To optimize the $UMDA^{G}$ and ensure convergence, the variance of the search distribution should be measured and used as a stopping criterion. This approach aims to reduce the number of execution parameters and avoid arbitrary stopping criteria like a fixed number of iterations, which can lead to suboptimal solutions. Monitoring the variance allows the algorithm to stop when it converges to a small region in the variable space, ensuring robustness and a closed approximation to a local optimum.",
      "chunk_id": 9628,
      "paper_id": "Robust parameter estimation of a PEMFC via optimization based on probabilistic model building",
      "paper_title": "Robust parameter estimation of a PEMFC via optimization based on probabilistic model building",
      "paper_year": "2021",
      "chunk_content": "In this work, we present a statistical comparison of four evolutionary algorithms for the parameter estimation of a PEMFC, they are the $U M G A^{G}, G A, P S O$, and $C M A E S$, in addition, they are compared with reported results in the literature. We found advantageous to use the $U M D A^{G}$ in contrast with other methods, besides its simplicity, low computational cost in operations and memory, and its performance to estimate the parameters. Then, we propose to use the convergence, measured via the variance of the search distribution, as a stopping criterion for the $U M D A^{G}$. The convergence property, which is not the rule in Evolutionary Algorithms, is advantageous for reducing the number of execution parameters and avoiding arbitrary stopping criteria such as the number of  \n[IMAGE3]  \nCase 1 with SSE\n[IMAGE4]  \nCase 2 with SSE\n[IMAGE5]  \nCase 1 with SAE\nFig. 4. Correlation matrix of 30 independent executions of cases 1 and 2 with SSE and SAE. The lower side of the correlation matrix shows numeric values, while the upper shows an ellipse representation, the narrower an ellipse is the higher the correlation.\niterations/generations, which provokes suboptimal solutions, wasted computations, or requires of expert tuning. The $U M D A^{G}$ improves the confidence of the results because it converges to a small region in the variable space and the objective space. This ensures two crucial features of the solution: (1) robustness, considering that the parameters estimated in 30 independent executions belong to a closed neighborhood and share similar objective values, that is to say, any of the 30 executions of our proposal delivers an adequate estimation, (2) the solution is a closed approximation to a local optimum because the algorithm intensively samples in a very small neighborhood of the best solution at the last iterations.  \nThe $U M D A^{G}$ is suited for handling non-derivable and multimodal objective functions, we use this advantage for approaching the minimum of three objective functions, which solution is consistent with previously reported results, but presents a lower error, besides we approach robust estimations. In this regard, the SSE is quite sensitive to outliers, nevertheless, it is the most widely used in literature due to its differentiability. The objective function that uses the sum of the absolute values of the error, SAE, is less biased by atypical data, while MAE practically avoids any outlier.  \nThe information from several executions is used to determine relations among variables and the objective function, in this regard, we infer that the water content in the membrane, $\\psi$, is the most critical parameter in the PEMFCs used in this study.  \nThe results showed that the FORMULA_270 is a competitive algorithm compared with the state of the art and the most recent bio-inspired algorithms in the literature.  \nFuture work contemplates the use of parameters estimated for the semi-empirical model to feed the agglomerate and macro-homogeneous models, to define consistent simulations of the same fuel cell through all of them.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:30",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output be measured using the criteria of vital-status in the context of predicting survival rates following TIPS?",
      "topics": [
        "analysis"
      ],
      "answer": "The quality of the EDA's output, when predicting survival rates post-TIPS, can be measured by assessing its ability to accurately classify the 'vital-status' variable, which indicates whether a patient died within the first 6 months after the TIPS procedure. This involves evaluating the model's performance in correctly predicting the two classes of the problem: whether a patient survived longer than 6 months or died within that period, given the 77 clinical findings available for each patient before TIPS placement. The proportion of correctly classified instances for each class can serve as a quality metric.",
      "chunk_id": 6100,
      "paper_id": "Feature subset selection by genetic algorithms and estimation of distribution algorithms",
      "paper_title": "Feature subset selection by genetic algorithms and estimation of distribution algorithms -: A case study in the survival of cirrhotic patients treated with TIPS",
      "paper_year": "2001",
      "chunk_content": "The prospective study includes 127 patients with liver cirrhosis who underwent TIPS from May 1991 to September 1998 in the University Clinic of Navarra, Spain. The diagnosis of cirrhosis was based in liver histology in all cases.  \nThe indications for TIPS placement were: prophylaxis of rebleeding ( 68 patients); refractory ascites ( 28 patients); prophylaxis of bleeding ( 11 patients); acute bleeding refractory to endoscopic and medical therapy ( 10 patients); portal vein thrombosis ( 9 patients) and Budd-Chiari syndrome (1 patient).  \nTable 1\nAttributes of the study database\nThe analysis includes 107 patients as 20 underwent liver transplants the first 6 months after TIPS placement. The follow-up of these transplanted patients was censored on the day of the transplant. This censoring was done to remove the effect of transplantation when modeling the 6 -months survival of patients who undergo TIPS. If these patients were not censored, deaths due to surgical mortality related to transplantation might have influenced the selection of variables that are prognostic for the TIPS procedure. On the other hand, transplantation may prolong survival compared with patients who do not undergo TIPS. It is predictably found that survival in patients who undergo transplantation is significantly improved compared with those who do not undergo transplantation [31].  \nThe database contains 77 clinical findings for each patient. These 77 attributes were measured before TIPS placement (see Table 1). A new binary variable is created, called vital-status, which reflects whether the patient died in the first 6 months after the placement of the TIPS or not: this variable reflects both classes of the problem. In the first 6 months after the placement of the TIPS, 33 patients died and 74 survived for a longer period, thus reflecting that the utility and consequences of the TIPS were not homogeneous for all the patients.  \nThe study was approved by the local Ethics Committee, and informed oral consent was obtained from all patients.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:31",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs within the MNSGA2-EDA algorithm?",
      "topics": [
        "performance"
      ],
      "answer": "The primary objective is to improve the effectiveness and efficiency of multi-objective semantic service composition by using EDA-based local search to overcome limitations in hybrid approaches. Specifically, MNSGA2-EDA constructs distribution models from Pareto front solutions and samples effective solutions, generating trade-off solutions regarding both QoSM and QoS, while also employing a clustering technique to select candidate Pareto-optimal solutions for local search.",
      "chunk_id": 8490,
      "paper_id": "Using EDA-Based Local Search to Improve the Performance of NSGA-II for Multiobjective Semantic Web Service Composition",
      "paper_title": "Using EDA-Based Local Search to Improve the Performance of NSGA-II for Multiobjective Semantic Web Service Composition",
      "paper_year": "2019",
      "chunk_content": "address these two limitations. Besides that, to the best of our knowledge, existing EC-based multi-objective fully automated approaches only focus on QoS and overlook QoSM of composition solutions. In practice, some customers often demand highly accurate and reliable outputs of composite services (i.e., high QoSM), therefore, are willing to trade QoS for QoSM. However, a portion of customers may prefer (demand) a more highly responsible composite service at an affordable cost (i.e., high QoS). In this paper, we propose a memetic NSGAII with EDA-based local search (henceforth referred to as MNSGA2-EDA) for multi-objective fully automated semantic service composition, where EDA can effectively handle the two limitations of the local search in Hybrid [6]. Besides that, MNSGA2-EDA tackles two practical objectives, i.e., two objective functions in Eqs. (2) and (3), with respect to the functional and non-functional quality criteria, achieving substantially high performances in effectiveness and efficiency. The contributions of this paper are listed below, and some initial ideas have been recently accepted in a poster [21].  \n1. To avoid pre-determining a large number of single-objective subproblems in advance, we propose a new clustering technique to select candidate Paretooptimal solutions for local search, which is performed separately and concurrently in different regions of the Pareto front that contributes to wide and uniformly distributed near-optimal Pareto solutions produced by our MNSGA2-EDA.\n2. To perform effective local search using the useful information of good candidate solutions in each generation. We propose a model-guided local search, which first constructs distribution models from suitable Pareto front solutions and other good candidate solutions selected by our proposed clustering technique, and then samples effective solutions from the distribution models.\n3. To generate a set of trade-off solutions regarding both QoSM and QoS, NHSGA2-EDA is effectively utilized in this paper to solve challenging multiobjective service composition problems with requirements for both QoSM and QoS. Empirical comparison with NSGA-II and Hybrid [6] shows that NHSGA2-EDA is much more effective and efficient. To explore the scalability of multi-objective approaches we propose a new benchmark dataset. Experiments conducted with this dataset show that NSGA2-EDA can maintain high performance on problems with significantly larger sizes.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:33",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms applied to multi-robot task planning, what role does the matrix \\(X\\), where \\(X=\\left[\\begin{array}{cccc} p_{1,1} & p_{1,2} & \\cdots & p_{1, n} \\\\ p_{2,1} & p_{2,2} & \\cdots & p_{2, n} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ p_{m, 1} & p_{m, 2} & \\cdots & p_{m, n} \\end{array}\\right]\\), play in representing a feasible solution, and how do the arriving time matrix \\(T_{arr}\\) and completion time matrix \\(T_{com}\\) contribute to the decoding strategy described in Algorithm 1?",
      "topics": [
        "mutation"
      ],
      "answer": "In the context of the multi-robot multi-point dynamic aggregation problem, the matrix \\(X\\) encodes a feasible solution by representing the visiting routes of \\(m\\) robots to \\(n\\) task points. Each row \\(\\left[p_{i, 1} \\quad p_{i, 2} \\quad \\cdots \\quad p_{i, n}\\right]\\) in the matrix \\(X\\) represents an integer permutation of the \\(n\\) task points for robot \\(rob_i\\). The arriving time matrix \\(T_{arr}\\), where \\(T_{arr} = \\left[\\begin{array}{cccc} t_{1,1}^{a} & t_{1,2}^{a} & \\cdots & t_{1, n}^{a} \\\\ t_{2,1}^{a} & t_{2,2}^{a} & \\cdots & t_{2, n}^{a} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ t_{m, 1}^{a} & t_{m, 2}^{a} & \\cdots & t_{m, n}^{a} \\end{array}\\right]\\), records the time instant \\(t_{i, j}^{a}\\) when robot \\(rob_i\\) arrives at task \\(task_j\\). Similarly, the completion time matrix \\(T_{com}\\), where \\(T_{com} = \\left[\\begin{array}{cccc} t_{1,1}^{c} & t_{1,2}^{c} & \\cdots & t_{1, n}^{c} \\\\ t_{2,1}^{c} & t_{2,2}^{c} & \\cdots & t_{2, n}^{c} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ t_{m, 1}^{c} & t_{m, 2}^{c} & \\cdots & t_{m, n}^{c} \\end{array}\\right]\\), stores the time instant \\(t_{i, j}^{c}\\) when robot \\(rob_i\\) finishes task \\(task_j\\). These matrices, along with the event matrix \\(T_h\\), are used within Algorithm 1's decoding strategy to determine the actual visiting route of each robot, taking into account task completion times. If a task's state drops to zero before a robot arrives, as determined using \\(T_{arr}\\) and \\(T_{com}\\), the task is removed from the robot's route.",
      "chunk_id": 10409,
      "paper_id": "An Estimation of Distribution Algorithm for Multi-robot Multi-point Dynamic Aggregation Problem",
      "paper_title": "An Estimation of Distribution Algorithm for Multi-robot Multi-point Dynamic Aggregation Problem",
      "paper_year": "2018",
      "chunk_content": "In an MPDA task planning problem with $m$ robots and $n$ task points, a feasible solution is encoded as an $m \\times n$ matrix $X$ :  \n$$\nX=\\left[\\begin{array}{cccc}\np_{1,1} & p_{1,2} & \\cdots & p_{1, n} \\\\\np_{2,1} & p_{2,2} & \\cdots & p_{2, n} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\np_{m, 1} & p_{m, 2} & \\cdots & p_{m, n}\n\\end{array}\\right]\n$$  \nwhere the $i$ th row $\\left[\\begin{array}{llll}p_{i, 1} & p_{i, 2} & \\cdots & p_{i, n}\\end{array}\\right](i=1,2, \\ldots, m)$ is an integer permutation of $n$ task points, which stands for the visiting route of $r o b_{i}$. For example, permutation [2 431] means that the robot will first visit task ${ }_{2}$ and execute the task, then move to task $_{4}$, task $_{3}$ and finally move to task $_{1}$ if necessary.  \nIn the decoding strategy, if the state of one task has dropped to zero before the robot arrives, the task will be deleted from the visiting route of this robot. Robots cannot leave their current task point until the task is finished. In a feasible solution, different robots may have the same visiting route, but each task can appear only once in a permutation. The decoding strategy is described as Algorithm 1.  \nIn the algorithm, the arriving time matrix $T_{\\text {arr }}$ and the completion time matrix $T_{\\text {com }}$ is described as:  \n$$\n\\begin{aligned}\nT_{a r r} & =\\left[\\begin{array}{cccc}\nt_{1,1}^{a} & t_{1,2}^{a} & \\cdots & t_{1, n}^{a} \\\\\nt_{2,1}^{a} & t_{2,2}^{a} & \\cdots & t_{2, n}^{a} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nt_{m, 1}^{a} & t_{m, 2}^{a} & \\cdots & t_{m, n}^{a}\n\\end{array}\\right] \\\\\nT_{c o m} & =\\left[\\begin{array}{cccc}\nt_{1,1}^{c} & t_{1,2}^{c} & \\cdots & t_{1, n}^{c} \\\\\nt_{2,1}^{c} & t_{2,2}^{c} & \\cdots & t_{2, n}^{c} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nt_{m, 1}^{c} & t_{m, 2}^{c} & \\cdots & t_{m, n}^{c}\n\\end{array}\\right]\n\\end{aligned}\n$$  \nwhere $t_{i, j}^{a}(i=1,2, \\ldots, m ; j=1,2, \\ldots, n)$ represents the time instant when $r o b_{i}$ arrives at $t a s k_{j}$ in the order of the matrix $X$, and $t_{i, j}^{c}(i=1,2, \\ldots, m ; j=1,2, \\ldots, n)$ represents the time instant when task ${ }_{j}$ is finished by $r o b_{i} . t_{i, j}^{a}$ is set to -1 when\nthe task has been finished. An event matrix $T_{h}$ describes the execution process of all the tasks:  \n$$\nT_{h}=\\left[\\begin{array}{cccc}\nr o b N u m_{1} & \\text { taskNum }_{1} & \\operatorname{arrTime}_{1} & \\operatorname{comTime}_{1} \\\\\nr o b N u m_{2} & \\text { taskNum }_{2} & \\operatorname{arrTime}_{2} & \\text { comTime }_{2} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nr o b N u m_{\\delta} & \\text { taskNum }_{\\delta} & \\operatorname{arrTime}_{\\delta} & \\text { comTime }_{\\delta}\n\\end{array}\\right]\n$$  \nwhere $\\operatorname{robNum}_{k}$ and $\\operatorname{taskNum}_{k}(k=1,2, \\ldots, \\delta)$ represent the number of the robot and the task in the $k$ th event separately, while $\\operatorname{arrTime}_{k}$ and comTime ${ }_{k}$ represent the arriving moment and completion moment separately. $T_{h}$ consists of $\\delta$ events, and each event describes the arriving of a robot or the completion of a task.",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:38",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using Archimedean copulas, what specific parameter settings and termination criteria should practitioners consider when optimizing functions like f1, f2, and f3, given their shared structure of \\(-\\frac{100}{10^{-5}+\\hat{\\mathbf{a}}_{1}\\|y_{i}|}\\)?",
      "topics": [
        "convergence"
      ],
      "answer": "When implementing Archimedean Copula EDAs for functions f1, f2, and f3, practitioners should set the maximal generation (g) to 1000. The search terminates if the distance between the best solution found so far and the optimum is less than a predefined precision of 10^-5. Suggested parameter settings include a select-rate of 0.2, a mutate-rate of 0.05, and a population size (N) of 100. These settings were used when optimizing functions f1, f2, f3, f4, f5, f6 and f8. However, a different precision of 10^-3 was used for f7.",
      "chunk_id": 6758,
      "paper_id": "Estimation of distribution algorithm based on archimedean copulas",
      "paper_title": "Estimation of Distribution Algorithm Based on Archimedean Copulas",
      "paper_year": "2009",
      "chunk_content": "The following functions are used to test the effectiveness of the proposed algorithm. $f_{1}-f_{3}$ and $f_{4}-f_{8}$ are adopted from [3].  \n- $\\min f_{1}=-\\frac{100}{10^{-5}+\\hat{\\mathbf{a}}_{1}\\left|y_{i}\\right|}, \\quad y_{1}=x_{1}, y_{i}=x_{i}+y_{i-1}\\left(i^{3} 2\\right)$\n$x_{1} \\hat{1}[-3,3]$, the optimal is $f_{1} *(0,0, \\ldots 0)=-10^{7}$.\n- $\\min f_{3}=-\\frac{100}{10^{-5}+\\hat{\\mathbf{a}}_{1}\\left|y_{i}\\right|}, \\quad y_{3}=x_{1}, y_{i}=x_{i}+\\sin y_{i-1}\\left(i^{3} 2\\right)$\n$x_{i} \\hat{1}[-3,3]$, the optimal is $f_{2} *(0,0, \\ldots 0)=-10^{7}$.\n- $\\min f_{3}=-\\frac{100}{10^{-5}+\\hat{\\mathbf{a}}_{1}\\left|y_{i}\\right|}, \\quad y_{3}=0.024^{\\circ}(i+1)-x_{i} \\cdot x_{i} \\hat{1}[-3,3]$, the optimal is $f_{3} *(0.024^{\\circ} 2,0.024^{\\circ} 3, \\ldots 0.024^{\\circ}(n+1))=-10^{7}$.\n- $\\min f_{4}=\\hat{\\mathbf{a}}_{1} x_{i}^{2} \\quad, \\quad x_{i} \\hat{1}[-500,500]$, the optimal is $f_{4} *(0,0, \\ldots 0)=0$.\n- $\\min f_{5}=1+\\hat{\\mathbf{a}}_{1}\\left(\\sin x_{i}\\right)^{2}-0.1 \\exp \\left(-\\hat{\\mathbf{a}}_{1} x_{i}^{2}\\right) \\cdot x_{i} \\hat{1}[-10,10]$, the optimal is $f_{5} *(0,0, \\ldots 0)=0.9$.\n- $\\min f_{6}=\\hat{\\mathbf{a}}_{1}\\left(x_{i}^{2}-A \\cos \\left(2 p x_{i}\\right)\\right)+A\\right) \\cdot x_{i} \\hat{1}[-5,5]$, the optimal is $f_{6} *(0,0, \\ldots 0)=0$.\n- $\\min f_{7}=\\hat{\\mathbf{a}}_{1}\\left(418.9829+x_{i} \\sin \\sqrt{\\left|x_{i}\\right|}\\right), x_{i} \\hat{1}[-500,500]$, the optimal is $f_{7} *(-420.9687,-420.9687, \\ldots-420.9687)=0$.\n- $\\min f_{8}=\\hat{\\mathbf{a}}_{1} x_{i}^{2}-\\bigodot_{i} \\cos \\left(\\frac{x_{i}}{\\sqrt{i+1}}\\right) \\cdot x_{i} \\hat{1}[-100,100]$, the optimal is $f_{8} *(0,0, \\ldots 0)=-1$.\n- $\\min f_{8}=\\left[1+\\left(x_{1}+x_{2}+1\\right)^{2}\\left(19-14 x_{1}+3 x_{1}^{2}-14 x_{2}+6 x_{1} x_{2}+3 x_{2}^{2}\\right)\\right]$\n$\\left[30+\\left(2 x_{1}-3 x_{2}\\right)^{2}\\left(18-32 x_{1}+12 x_{1}^{2}+48 x_{2}-36 x_{1} x_{2}+27 x_{2}^{2}\\right)\\right]$,\n$x_{1}, x_{2} \\hat{1}[-2,2]$, the optimal is $f_{8} *(0,-1)=3^{\\circ}$\nThe following two Archimedean copulas are chosen.\n- $C_{1}(u, v)=\\left(u^{-\\theta}+v^{-\\theta}-1\\right)^{-1 / \\theta}, \\theta \\geq-1, \\theta \\neq 0$\n- $C_{2}(u, v)=\\frac{u v}{1-\\theta(1-u)(1-v)},-1 \\leq \\theta<1$  \nAll the one-dimensional marginal distributions are normal distributions. Table 1 displays the experimental results.  \nTable 1. Experimental results of Archimedean Copula EDAs  \nAll test functions are optimized in 2-dimensional spaces, the maximal generation $g$ is set to 1000 . The search terminates if the distance between the best solution found so far and the optimum is less than the predefined precision $\\left(10^{-5}\\right.$ for other test functions in spite of $10^{-5}$ for $f_{7}$ ). Parameters are set to (select-rate $=0.2$, mutate-rate $=0.05$, population size $N=100$ ) for all experiments. The convergence rate and the convergence generations are the average results of 50 runs. The experimental results show that Copula-EDA converges to the global optimum quickly in the test functions. There is not much difference in performance between two copulas for other test functions despite $f_{3}$ and FORMULA_108. Both the algorithms proposed in this paper perform better than the copula-EDA based on Gaussian copula and PBILc [20].\nCompared with GAs, EDAs utilizes well the information provided from the promising population, and becomes the hot topic of Intelligence Computation. Whereas, it is a complex process to model and sample the probability distribution of the promising population. Copula theory in statistics provides an easier way for it. The process of modeling the probability distribution can be divided into modeling univariate margins and selecting a copula. Sampling from the constructed model can also be done by use of copula. From the experimental results it is obvious that the  \nArchimedean Copula EDAs proposed in this paper is effective. But two-dimensional Archimedean copula EDAs is only an attempt to join EDAs with copulas. The multi-dimensional algorithm is the next target of our study.\nThis work was supported in part by the Youth Research Fund of Taiyuan University of Science and Technology (No.2007116), the Chinese Nature Science Fund (No. 60674104) and the Youth Research Fund of ShanXi province (No. 2006021019).",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:41",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the RM-MEDA, a distribution estimation algorithm, what is the core mechanism described for its optimization method?",
      "topics": [
        "optimization"
      ],
      "answer": "The RM-MEDA is described as an algorithm that uses global statistical information to construct a probability model. This probability model is the basis for the distribution estimation algorithm's optimization method.",
      "chunk_id": 8205,
      "paper_id": "Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine",
      "paper_title": "Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine",
      "paper_year": "2019",
      "chunk_content": "In general, our proposed algorithm is applicable to any kind of population-based optimization algorithm. In our experiment, we chose three representative experiments to prove our method. The first multiobjective optimization algorithm is based on particle swarm optimization [18], it was called MOPSO for short. The second one is the NSGA-II and it is a multiobjective genetic algorithm that applies nondominated sorting and crowding distance. The third one is a distribution estimation algorithm [19] based on global statistical information to construct a probability model, We simply refer to it as the RM-MEDA. Obviously, these three algorithms belong to different categories, and they were not originally designed for dynamic optimization. But they are well developed, so we can  \n  \nimprove our level of persuasion and confidence in the technologies we propose. The three corresponding algorithms with incremental SVM are called ISVM-MOPSO, ISVM-NSGAII, and ISVM-RMMEDA respectively. It is worth noting that parameters, such as population size, iteration number are all the same. In other words, for the three groups of algorithms, we did not deliberately adjust the experimental parameters for getting better performances.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:42",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantages are gained by using an estimation of distribution algorithm (EDA) with a mixed sampling operator for large scale global optimization (LSGO) problems, compared to classical evolutionary algorithm (EA) operators?",
      "topics": [
        "optimization"
      ],
      "answer": "Classical evolutionary algorithm (EA) operators are typically developed for low-dimensional tasks and lose efficiency for high-dimensional tasks, making their performance on large scale global optimization (LSGO) problems difficult to measure effectively. An estimation of distribution algorithm (EDA) with a mixed sampling operator, along with approaches like population reduction for differential evolution (DE) and Dynamic multi-swarm PSO, optimizes the LSGO problems as an entire body without divide-and-conquer methods. These specific operators strengthen the algorithm's capability for higher dimensional tasks.",
      "chunk_id": 6777,
      "paper_id": "A Self-adaptive Mixed Distribution Based Uni-variate Estimation of Distribution Algorithm for Large Scale Global Optimization",
      "paper_title": "A Self-adaptive Mixed Distribution Based Uni-variate Estimation of Distribution Algorithm for Large Scale Global Optimization",
      "paper_year": "2009",
      "chunk_content": "Considered as a kind of classical yet extremely difficult task, large scale global optimization (LSGO) has attracted more and more research interest in recent years [21, 31]. LSGO problems have numerous scientific and engineering applications, such as designing large scale electronic systems, scheduling problems with large number of resources, vehicle routing in large scale traffic networks, gene detection in bioinformatics, etc. Therefore, effective LSGO algorithms are in high demand.  \nInherently, the nonlinear characteristics of the practical applications usually include discontinuous prohibited zones, ramp rate limits, and nonsmooth or convex  \n[^0]\n[^0]:    Yu Wang $\\cdot$ Bin Li\nNature Inspired Computation and Application Laboratory (NICAL), University of Science and Technology of China\ne-mail: wyustc@mail.ustc.edu.cn, binli@ustc.edu.cn  \ncost functions. Historically, a number of algorithms, including both mathematical and evolutionary algorithms, have been proposed to handle LSGO problems $[5,10,15,17,23,26,32,33,36,37,38,42,43]$. Various evolutionary algorithms (EAs) have been developed, in which significant progress has been observed [20] compared to the mathematical algorithms. The major advantages of these EAs over other classical methods can be summarized as: 1) prior knowledge of the search problem is not necessary for EAs, while for mathematical approaches the highly nonlinear characteristic of the problem must be approximated beforehand; 2) they work with a population of candidate solutions and can handle LSGO problems automatically through a single run. However, almost all of these approaches inevitably suffer from the \"curse of dimensionality\", which means poor performances on LSGO problems.  \nWithout loss of generality, LSGO problems considered in this chapter can be stated as follows:  \n$$\n\\begin{aligned}\n& \\operatorname{minimize} F(\\mathbf{x})=f\\left(x_{1}, x_{2}, \\ldots, x_{D}\\right) \\\\\n& \\text { subject to } \\mathbf{x} \\in X\n\\end{aligned}\n$$  \nwhere $X \\subset R^{D}$ denotes the decision space with $D$ dimensions; $\\mathbf{x}=\\left\\{x_{1}, x_{2}, \\ldots, x_{D}\\right\\} \\in$ $R^{D}$ is the decision variable vector; $f: X \\rightarrow R$ stands for a real-valued continuous objective function for mapping from $D$ dimensional space to 1 dimensional fitness value $F(\\mathbf{x})$. The dimensions of LSGO problems considered in this chapter are more than 100. Hence, the purpose of the approaches is to search for the minimized solution in such a large dimensional space. If $X$ is a closed and connected region in $R^{D}$, we call eq. (1) continuous LSGO.  \nIn the previous works on LSGO, developing more effective operators for EAs has attracted much research attention. The successful implementations consist of selfadapting strategies for parameter setting, modification of the classical EA operators, etc. The reason of making these modifications is that the classical operators are usually developed for low-dimensional task and they lose their efficiency for highdimensional tasks. Their performances on LSGO problems cannot be measured effectively [31]. Recently, this field has attracted increased research attention and the typical approaches include population reduction for differential evolution (DE) [5], Dynamic multi-swarm PSO [43], and estimation of distribution algorithm (EDA) with mixed sampling operator [33]. For these approaches, the LSGO problems are optimized as an entire body, which means no divide-and-conquer methods are used. Actually, the implementation of specific operators is attributed to strengthening the algorithm's capability for higher dimensional tasks.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:44",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the Estimation of Distribution Algorithm (EDA) for the flexible job shop scheduling problem (FJCSP) with AGV routing, how should a developer structure the code to leverage the probability model for generating new solutions, and what programming techniques are suggested to optimize the EDA's performance in absorbing problem-specific knowledge?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The EDA implementation should begin by estimating the probability distribution of elite individuals from the population. This involves constructing a probability model that captures the statistical information of the most promising search area based on historical search experience. To incorporate problem-specific knowledge, the probability model can be designed to reflect heuristics relevant to FJCSP and AGV routing, such as considering machine workload balance or AGV path congestion. Optimization techniques include using efficient data structures for representing the probability model (e.g., probability tables or Bayesian networks), and employing techniques such as model simplification or parameter tuning to balance model complexity and computational cost. Furthermore, the code should allow for easy integration of custom heuristics that guide the probability model construction, thereby enhancing the EDA's ability to leverage problem knowledge for improved performance.",
      "chunk_id": 3976,
      "paper_id": "Simultaneous Scheduling of Processing Machines and Automated Guided Vehicles via a Multi-View Modeling-Based Hybrid Algorithm",
      "paper_title": "Simultaneous Scheduling of Processing Machines and Automated Guided Vehicles via a Multi-View Modeling-Based Hybrid Algorithm",
      "paper_year": "2023",
      "chunk_content": "As a popular evolutionary algorithm, genetic algorithm (GA) has been designed into many variants to solve\nsimilar problems. Ulusoy et al. adopted a genetic algorithm with a special uniform crossover operator and two mutation operators, and lots of instances were solved to evaluate the proposed algorithm [10]. Chaudhry et al. proposed a spreadsheet-based GA approach to solving the co-scheduling problem. An adaptation of the proprietary GA software was demonstrated to minimize the total completion time or makespan in FMS [11]. Badakhshian et al. adopted a fuzzy controller to control the behavior of the GA during solving the scheduling problem [12]. Nouri et al. proposed a hybrid metaheuristic approach based on clustered holonic multiagent model. A neighborhood-based GA for global exploration was adopted and a set of cluster agents used tabu search for promising regions [13]. Meng et al. designed a diversity check method into GA to prevent the decline of population diversity [14].  \nSome other evolutionary algorithms were also employed to solve FJCSP. Gnanavel Babu et al. proposed a new meta-heuristic differential evolution algorithm to minimize the makespan [15]. Tatsushi et al. addressed a bilevel decomposition algorithm for solving the simultaneous scheduling and conflict-free routing problems for AGVs to minimize the total weighted tardiness. A mixed-integer formulation was decomposed into task assignment and routing subproblems which were solved by using Lagrangian relaxation [16]. Zheng et al. established a mixed-integer linear programming model and proposed heuristic algorithm based on tabu search, which included a novel two-dimensional solution representation and the generating operation of two neighbor solutions [17]. Wen et al. designed a harmony search algorithm with a neighborhood search incorporating problem knowledge to guide the search [18].  \nMore hybrid or multi-stage algorithms were proposed to solve the complex problem. Saidi Mehrabad et al. considered the scheduling problem containing the conflict-free routing problem for AGVs and the basic job-shop scheduling problem, and proposed a two-stage ant colony algorithm to solve it [19]. Considering real situations such as deadlock or blockage, Lin et al. proposed a hybrid algorithm based on GA and optimal computing budget allocation to reduce simulation replications [20]. Nageswararao et al. proposed a new meta-heuristic gravitational search algorithm to solve the simultaneous scheduling problem and the adequacy of the algorithm was demonstrated by comparing it with existing results [21]. Lyu et al. adopted a hybrid consisting of GA and Dijkstra algorithm to solve the scheduling problem with the objectives of minimizing the makespan and the transportation time [22].  \nDespite the above research, the problem is still worth studying further. As most scholars have stated, FJCSP is an expansion of the traditional FJSP [23]. However, on the other hand, due to the AGVs introduced into the problem, the routing issue of AGVs arises and may even become dominant in some cases. Therefore, the approach to solving this problem needs to be designed from the above two views. As we know, the estimation of distribution algorithm (EDA) is a novel evolutionary algorithm based on statistical learning theory and has been applied widely to similar scheduling problems [2].  \nEDA estimates the probability distribution of elite individuals and builds a probability model of the most promising area by statistical information according to the historical search experience. In addition, the ant colony algorithm (ACO) has been widely applied to path-related scheduling problems such as the path planning problem [24] and vehicle routing problem [25], [26]. EDA and ACO are both based on statistical models, namely the probability model and the pheromone model, respectively. Compared with the other methods like GAs, EDA and ACO are conducive to absorbing various problem knowledge. For a complex problem, reasonable heuristics designed by fully using the problem knowledge can commonly achieve better performance.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:46",
      "generation_style": "implementation_focused"
    },
    {
      "question": "With makespan criterion, how can the effectiveness of a neighborhood search operator, specifically SWS(i, j, k), be determined based on the completion times of critical machines?",
      "topics": [
        "search"
      ],
      "answer": "A neighborhood search operator SWS(i, j, k) is considered effective if the completion times of all critical machines can be shortened. More specifically, the makespan can be reduced by SWS(i, j, k) if \\(R_k > R_{k'}\\) for all \\(k' \\neq k\\), meaning \\(M_k\\) is the only critical machine, and either \\(ST_{[i-1],[j],[k]} + ST_{[j],[i],[k]} + ST_{[i],[j+1],[k]} < ST_{[i-1],[i],[k]} + ST_{[i],[j],[k]} + ST_{[j],[j+1],[k]}\\) when \\(j = i+1\\), or \\(ST_{[i-1],[j],[k]} + ST_{[j],[i+1],[k]} + ST_{[j-1],[i],[k]} + ST_{[i],[j+1],[k]} < ST_{[i-1],[i],[k]} + ST_{[i],[i+1],[k]} + ST_{[j-1],[j],[k]} + ST_{[j],[j+1],[k]}\\) when \\(j > i+1\\).",
      "chunk_id": 12897,
      "paper_id": "A Hybrid Estimation of Distribution Algorithm for Unrelated Parallel Machine Scheduling with Sequence-Dependent Setup Times",
      "paper_title": "A Hybrid Estimation of Distribution Algorithm for Unrelated Parallel Machine Scheduling with Sequence-Dependent Setup Times",
      "paper_year": "2016",
      "chunk_content": "To calculate the makespan of the new solution after applying a search operator, the computational effort can be reduced with a speed-up evaluation procedure ${ }^{[13]}$. In addition, it is possible to identify invalid operators by some necessary conditions of the corresponding operators ${ }^{[15]}$. Inspired by the above, we derive some necessary and sufficient conditions for the neighborhood search operators.  \nDefinition 1. If $R_{k^{*}}=\\max \\left\\{R_{k} \\mid k=1,2, \\ldots, m\\right\\}$, then $M_{k^{*}}$ is called a critical machine, where $R_{k}=$ $\\max \\left\\{X_{i, j, k} C_{j} \\mid i=0,1, \\ldots, n ; j=1,2, \\ldots, n\\right\\}$.  \nObviously, the release times of the critical machines are equal to the makespan of a schedule. With makespan criterion, a neighborhood search operator is effective if the completion times of all the critical machines can be shortened.  \nProperty 1. The makespan can be reduced by $\\operatorname{SWS}(i, j$, $k$ ) iff $R_{k}>R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right)$ and:  \n1) When $j=i+1, S T_{[i-1],[j],[k]}+S T_{[j],[i],[k]}+$ $S T_{[i],[j+1],[k]}<S T_{[i-1],[i],[k]}+S T_{[i],[j],[k]}+S T_{[j],[j+1],[k]}$;\n2) When $j>i+1, S T_{[i-1],[j],[k]}+S T_{[j],[i+1],[k]}+$ $S T_{[j-1],[i],[k]}+S T_{[i],[j+1],[k]}<S T_{[i-1],[i],[k]}+S T_{[i],[i+1],[k]}+$ $S T_{[j-1],[j],[k]}+S T_{[j],[j+1],[k]}$.\nProof.  \n1) Case $j=i+1$.  \nBefore execution:  \n$$\n\\begin{aligned}\nR_{k}= & \\sum_{a=1}^{i-2} A P_{a, a+1, k}+A P_{i-1, i, k}+A P_{i, j, k}+A P_{j, j+1, k} \\\\\n& +\\sum_{a=j+1}^{N_{k}-1} A P_{a, a+1, k}\n\\end{aligned}\n$$  \nAfter execution:  \n$$\n\\begin{aligned}\nR_{k}^{\\prime}= & \\sum_{a=1}^{i-2} A P_{a, a+1, k}+A P_{i-1, j, k}+A P_{j, i, k}+A P_{i, j+1, k} \\\\\n& +\\sum_{a=j+1}^{N_{k}-1} A P_{a, a+1, k} \\\\\n\\triangle_{k}= & R_{k}^{\\prime}-R_{k} \\\\\n= & A P_{i-1, j, k}+A P_{j, i, k}+A P_{i, j+1, k}-A P_{i-1, i, k} \\\\\n& -A P_{i, j, k}-A P_{j, j+1, k} \\\\\n= & \\left(S T_{[i-1],[j],[k]}+P_{[j], k}\\right)+\\left(S T_{[j],[i],[k]}+P_{[i], k}\\right) \\\\\n& +\\left(S T_{[i],[j+1],[k]}+P_{[j+1], k}\\right)-\\left(S T_{[i-1],[i],[k]}+P_{[i], k}\\right) \\\\\n& -\\left(S T_{[i],[j],[k]}+P_{[i], k}\\right)-\\left(S T_{[j],[j+1],[k]}+P_{[j+1], k}\\right) \\\\\n= & S T_{[i-1],[j],[k]}+S T_{[j],[i],[k]}+S T_{[i],[j+1],[k]} \\\\\n& -S T_{[i-1],[i],[k]}-S T_{[i],[j],[k]}-S T_{[j],[j+1],[k]}\n\\end{aligned}\n$$  \n2) Case $j>i+1$.  \nBefore execution:  \n$$\n\\begin{aligned}\nR_{k}= & \\sum_{a=1}^{i-2} A P_{a, a+1, k}+A P_{i-1, i, k}+A P_{i, i+1, k} \\\\\n& +\\sum_{a=i+1}^{j-2} A P_{a, a+1, k}+A P_{j-1, j, k}++A P_{j, j+1, k} \\\\\n& +\\sum_{a=j+1}^{N_{k}-1} A P_{a, a+1, k}\n\\end{aligned}\n$$  \nAfter execution:  \n$$\n\\begin{aligned}\n& R_{k}^{\\prime}=\\sum_{a=1}^{i-2} A P_{a, a+1, k}+A P_{i-1, j, k}+A P_{j, i+1, k} \\\\\n& \\quad+\\sum_{a=i+1}^{j-2} A P_{a, a+1, k}+A P_{j-1, i, k}++A P_{i, j+1, k} \\\\\n& \\quad+\\sum_{a=j+1}^{N_{k}-1} A P_{a, a+1, k} \\\\\n& \\triangle_{k}=R_{k}^{\\prime}-R_{k} \\\\\n& =A P_{i-1, j, k}+A P_{j, i+1, k}+A P_{j-1, i, k} \\\\\n& \\quad+A P_{i, j+1, k}-\\left(A P_{i-1, i, k}+A P_{i, i+1, k}\\right. \\\\\n& \\left.\\quad+A P_{j-1, j, k}+A P_{j, j+1, k}\\right) \\\\\n& =\\left(S T_{[i-1],[j],[k]}+P_{[j], k}\\right)+\\left(S T_{[j],[i+1],[k]}+P_{[i+1], k}\\right) \\\\\n& \\quad+\\left(S T_{[j-1],[i],[k]}+P_{[i], k}\\right)+\\left(S T_{[i],[j+1],[k]}+P_{[j+1], k}\\right) \\\\\n& \\quad-(S T_{[i-1],[j],[k]}+P_{[j], k})-\\left(S T_{[i],[j+1],[k]}+P_{[j+1], k}\\right) \\\\\n& =S T_{[i-1],[j],[k]}+S T_{[j],[i+1],[k]}+S T_{[j-1],[i],[k]} \\\\\n& \\quad+S T_{[i],[j+1],[k]}-S T_{[i-1],[i],[k]}-S T_{[i],[i+1],[k]} \\\\\n& \\quad-S T_{[j-1],[j],[k]}-S T_{[j],[j+1],[k]}\n\\end{aligned}\n$$  \nBecause $R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right)$ remains unchanged after operator $\\operatorname{SWS}(i, j, k)$, the makespan can be reduced by $\\operatorname{SWS}(i, j, k)$  \niff $M_{k}$ is the only critical machine and $R_{k}$ is smaller, i.e., $R_{k}>R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right)$ and $\\triangle_{k}<0$.  \nProperty 2. The makespan can be reduced by ISS $(i, j$, $k$ ) iff $R_{k}>R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right), S T_{[i-1],[i+1],[k]}+S T_{[j],[i],[k]}+$ $S T_{[i],[j+1],[k]}<S T_{[i-1],[i],[k]}+S T_{[i],[i+1],[k]}+S T_{[j],[j+1],[k]}$.  \nProof.  \n$$\n\\begin{aligned}\nR_{k}= & \\sum_{a=1}^{i-2} A P_{a, a+1, k}+A P_{i-1, i, k}+A P_{i, i+1, k} \\\\\n& +\\sum_{a=i+1}^{j-1} A P_{a, a+1, k}+A P_{j, j+1, k} \\\\\n& +\\sum_{a=j+1}^{N_{k}-1} A P_{a, a+1, k} \\\\\nR_{k}^{\\prime}= & \\sum_{a=1}^{i-2} A P_{a, a+1, k}+A P_{i-1, i+1, k} \\\\\n& +\\sum_{a=i+1}^{j-1} A P_{a, a+1, k}+A P_{j, i, k}+A P_{i, j+1, k} \\\\\n& +\\sum_{a=j+1}^{N_{k}-1} A P_{a, a+1, k} \\\\\n& \\triangle_{k}=R_{k}^{\\prime}-R_{k} \\\\\n= & A P_{i-1, i+1, k}+A P_{j, i, k}+A P_{i, j+1, k} \\\\\n& -\\left(A P_{i-1, i, k}+A P_{i, i+1, k}+A P_{j, j+1, k}\\right) \\\\\n= & \\left(S T_{[i-1],[i+1],[k]}+P_{[i+1], k}\\right)+\\left(S T_{[j],[i],[k]}\\right. \\\\\n& \\left.+P_{[i], k}\\right)+\\left(S T_{[i],[j+1],[k]}+P_{[j+1], k}\\right) \\\\\n& -\\left(S T_{[i-1],[i],[k]}+P_{[i], k}\\right)-\\left(S T_{[i],[i+1],[k]}+P_{[i+1], k}\\right) \\\\\n& -\\left(S T_{[j],[j+1],[k]}+P_{[j+1], k}\\right) \\\\\n= & S T_{[i-1],[i+1],[k]}+S T_{[j],[i],[k]}+S T_{[i],[j+1],[k]} \\\\\n& -S T_{[i-1],[i],[k]}-S T_{[i],[i+1],[k]}-S T_{[j],[j+1],[k]}\n\\end{aligned}\n$$  \nBecause $R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right)$ remains unchanged after operator ISS $(i, j, k)$, the makespan can be reduced by ISS $(i, j, k)$ iff $M_{k}$ is the only critical machine and $R_{k}$ is smaller, i.e., $R_{k}>R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right)$ and $\\triangle_{k}<0$.  \nProperty 3. The makespan can be reduced by RVS $(i, j, k)$ iff $R_{k}>R_{k^{\\prime}}\\left(\\forall k^{\\prime} \\neq k\\right), S T_{[i-1],[j],[k]}+S T_{[i],[j+1],[k]}+$ $\\sum_{a=i}^{j-1} S T_{[a+1],[a],[k]}<S T_{[i-1],[i],[k]}+S T_{[j],[j+1],[k]}+$ FORMULA_154.",
      "question_type": "evaluation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:49",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in the context of aircraft path planning, considering the constraints and terrain generation?",
      "topics": [
        "constraints"
      ],
      "answer": "The algorithmic approach aims to generate an optimal flight path for an aircraft by fusing an original digital terrain with equivalent terrains of threats, subject to constraints such as maximum altitude $H_{max}$, minimum altitude $H_{min}$, maximum turning angle $\\phi$, maximum path length $L_{max}$, and maximum climb/dive angle $\\varphi$. A penalty method is employed to handle these constraints during the optimization of the path planning model, ensuring the generated path adheres to the specified limitations.",
      "chunk_id": 12546,
      "paper_id": "Path planning of aircraft based on adaptive multiobjective estimation of distribution algorithm",
      "paper_title": "Path Planning of Aircraft Based on Adaptive Multiobjective Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "In this paper, suppose that an aircraft flies across a combat area with size $200 \\times 200 \\mathrm{~km}^{2}$, and there are six threats in the area. According to Eq.(1), Eq.(13) is used to generate the original digital terrain shown in Fig.1(a).  \n$$\n\\begin{aligned}\nz_{1}(x, y)= & \\sin (y / 90+3 \\pi / 2)+\\sin (x / 15) / 10+ \\\\\n& 9 \\cos \\left(\\sqrt{(y / 18)^{2}+(x / 15)^{2}} / 2\\right) / 10+ \\\\\n& \\sin \\left(\\sqrt{(y / 18)^{2}+(x / 15)^{2}} / 2\\right) / 2+ \\\\\n& 3 \\cos (y / 18) / 10\n\\end{aligned}\n$$  \nParameters of the five peak terrains of threats are set as: heights $\\mathcal{H}=\\{0.7,2.5,3.2,2.34,1.77\\}$; horizontal coordinates of the centers $\\mathcal{X}_{c}=\\{50,100,100,130,160\\}, \\mathcal{Y}_{c}=$ $\\{60,160,100,20,100\\}$; parameters of the terrain profiles $\\mathcal{X}_{t}=$ $\\{140,280,150,160,170\\}, \\mathcal{Y}_{t}=\\{20,220,280,190,230\\}$. Based on the parameters, the yielded equivalent terrains of threats are presented in Fig.1(b).  \nThrough fusing the original digital terrain and the equivalent terrains of threats, the generated equivalent digital terrain is shown in Fig.1(c). The path planning in this paper is conducted based on the digital terrain in Fig.1(c). The start and target points of flight are $[0,0,0.25]$ and $[200,200,0]$, respectively.\n[IMAGE0]\n(a)\n[IMAGE1]\n(c)  \nFig. 1. (a) Original digital terrain; (b) Equivalent terrain of threats; (c) Equivalent digital terrain.  \nIn addition, in the path planning model, the allowed highest altitude, lowest flight altitudes, maximum turning angle, maximum total length of flight path and maximum climb/dive angle are set as $H_{\\max }=1.5 \\mathrm{~km}, H_{\\min }=0.05 \\mathrm{~km}, \\phi=60^{\\circ}$, $L_{\\max }=500 \\mathrm{~km}$ and $\\varphi=45^{\\circ}$, respectively; the required  \nshortest length of path segment is set as FORMULA_228. The penalty method is used to handle the constraints when the path planning model is optimized.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:50",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of UMDA\n$\\textsuperscript{G}$\n, as depicted in the provided diagram, contribute to solving optimization problems, and what are the core steps involved in its general diagram?",
      "topics": [
        "control"
      ],
      "answer": "The text mentions a \"General diagram of the UMDA$\\textsuperscript{G}$ algorithm\" and refers to Blanco-Cocom et al. (2021) for more details. While the specific algorithmic steps are not detailed in the provided text, the presence of a general diagram suggests that UMDA$\\textsuperscript{G}$ likely involves steps for population initialization, selection of promising solutions, building a probabilistic model from the selected solutions, sampling new solutions from the probabilistic model, and evaluating these solutions. These steps are iteratively repeated to improve the quality of the solutions found. The diagram, although not provided in detail, is central to understanding the flow of information and control within the UMDA$\\textsuperscript{G}$ algorithm.",
      "chunk_id": 3839,
      "paper_id": "Parameter estimation for empirical and semi-empirical models in a direct ethanol fuel cell",
      "paper_title": "Parameter estimation for empirical and semi-empirical models in a direct ethanol fuel cell",
      "paper_year": "2023",
      "chunk_content": "In Pramanik and Basu (2010), the authors used a single fuel cell with a MEA of $5 \\mathrm{~cm}^{2}$ electrode area with a serpentine-type channel geometry of $2 \\mathrm{~mm} \\times 2 \\mathrm{~mm}$, for both the anode and the cathode. The catalysts were $\\mathrm{Pt} / \\mathrm{Ru}(40: 20 \\mathrm{wt} \\%$ )/C and high surface area (HSA) platinum black (Johnson Matthey Inc., UK). The chamber's pressure was set at 1 bar. The fuel cell was fed with ethanol\n[IMAGE1]  \nFig. 2. General diagram of the UMDA ${ }^{\\text {G }}$ algorithm, more details in Blanco-Cocom et al. (2021).  \n1M at a rate of $1.2 \\mathrm{~mL} \\mathrm{~min}^{-1}$, Nafion ${ }^{\\circledR}$ (SE-5112, DuPont, USA) was the membrane. Pure oxygen ( $99.99 \\%$ by volume) was used. Hydrogen peroxide and $\\mathrm{H}_{2} \\mathrm{SO}_{4}$ (E. Merck) were used for cleaning and protonation of the fused membrane, in addition, isopropanol (E. Merck) was used as diluent. Temperature controllers were used to setting different values of temperature at the anode and cathode, respectively, more details in Pramanik and Basu (2010).\nThe experimental tests were obtained with an open-cathode DEFC designed in our laboratory, see Fig. 4. The anode has a serpentine flow pattern with a 1.5 mm channel width, 1.5 mm rib, 1.5 mm channel depth, $50 \\%$ electrical contact to electrode area. The cathode has an architecture open to the atmosphere with rhombohedral pins as electric contacts, a 2.12 channel width, 1.5 mm channel depth, and $61 \\%$ of electrical contact with respect to the area of the electrode. Both electrodes have an active area of $9 \\mathrm{~cm}^{2}$. Nafion ${ }^{\\circledR} 117$ membrane was the electrolyte. We used a PtRu/C catalyst at the cathode with a metal loading of 1 mgPt $\\mathrm{cm}^{-2}$. At the anode side, we use a combination of two catalyst layers: one inner catalyst layer of $\\mathrm{PtSn} / \\mathrm{C}$ deposited directly onto the membrane with a metal loading of $0.5 \\mathrm{mgPt} \\mathrm{cm}^{-2}$, plus an outer catalyst layer of $\\mathrm{PtRu} / \\mathrm{C}$ deposited on the carbon cloth diffuser with a metal loading of $0.5 \\mathrm{mgPt} \\mathrm{cm}^{-2}$. Before testing the cell, the membrane-electrode-assembly (MEA) was activated by flowing $1.5 \\mathrm{~mL} \\mathrm{~min}^{-1}$ of deionized water through the anode side for 3 h at $60^{\\circ} \\mathrm{C}$. Then the voltage was fixed at 100 mV for 1800 s . After that, it was changed to 600 mV for 300 s . DEFC polarization curves were recorded at 25 and $60^{\\circ} \\mathrm{C}$ with a scan rate of 10 $\\mathrm{mV} \\mathrm{s}^{-1}$ and using a FORMULA_103 solution, more details about experimentation in Moreno-Jimenez et al. (2015).",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:52",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "When analyzing the search landscape of an Estimation of Distribution Algorithm, how can Search Trajectory Networks (STNs) practically be used to compare the behavior of different algorithms?",
      "topics": [
        "optimization"
      ],
      "answer": "Search Trajectory Networks (STNs) can be used to compare algorithm search behaviors by reducing the search landscape to a connected network of visited local optima. These networks chart the ability of a search algorithm to move from one local optimum or basin of attraction to another, allowing for comparison of how different algorithms explore the problem landscape.",
      "chunk_id": 4079,
      "paper_id": "Towards explainable metaheuristics Feature extraction from trajectory mining",
      "paper_title": "Towards explainable metaheuristics: Feature extraction from trajectory mining",
      "paper_year": "2023",
      "chunk_content": "In this section, we review work related to the use of algorithm search trajectories in the XAI field in two categories: the visualisation of search trajectories using dimension reduction and analysis of the search landscape, and the deriving of feature importances from generated solutions.\nPrevious work covering the visualisation of algorithm trajectories using PCA can be seen in Collins (2003). In this work, PCA is used to attempt to attribute algorithm design to the search path taken and compare algorithm solution quality. Other examples of work involving the exploration of  \nalgorithm paths via dimension reduction include work by Pohlheim (2006) in which Sammon mapping is explored as a method of reduction for visualisation and Michalak (2019) in which Euclidean embedding is applied. These works focus on the visualisation of an algorithm through the search space as a means of exploration and how these visualisations may, in some way, aid in the understating of the search methods employed. Their aims are somewhat similar to those in this article however our approaches also have the potential to be used in extracting features from algorithm paths.  \nLandscape analysis, a survey of which can be seen in Malan (2021), can be considered a key set of tools for the generation of explanations regarding algorithm behaviour. Recent methods of visualisation and analysis of the landscape involve the creation of search trajectory networks (Ochoa et al., 2021a; 2021b) which highlight algorithm behavioural differences through their search of the problem landscape using Local Optima Networks. These networks chart the ability of a search algorithm to move from one local optimum or basin of attraction to another. By doing so, algorithm search behaviours can be compared by reducing the search landscape to a connected network of visited local optima. The concept of STNs has since been extended to multi-objective evolutionary algorithms (Lavinas et al., 2022). More recently, a move towards 'explainable landscape-aware optimization' and analysis (Trajanov et al., 2021; 2022) developments have seen a move towards the prediction of algorithm performance based on landscape analysis.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:07:54",
      "generation_style": "practical_application"
    },
    {
      "question": "How does the implemented greedy local search (Algorithm 2) within the Estimation of Distribution Algorithm (EDA) mitigate the computational cost associated with evaluating potential bit flips, and what mechanism is employed to escape local optima?",
      "topics": [
        "design"
      ],
      "answer": "The greedy local search (Algorithm 2) reduces computational cost by storing local fitness values in memory, requiring only local computations to evaluate the effect of bit flips. Instead of recomputing the entire fitness, only a fraction of computations are needed to evaluate the 'n' possible bit flips from the current solution. To escape local optima, the optimizer allows a predefined number of transitions (5) to solutions with lower fitness when the initial solution is a local optimum. In these cases, the bit-flip that decreases the fitness the least is selected, providing a mechanism to escape local optima without implementing memory or more sophisticated components.",
      "chunk_id": 12326,
      "paper_id": "Evolutionary Approaches to Optimization Problems in Chimera Topologies",
      "paper_title": "Evolutionary Approaches to Optimization Problems in Chimera Topologies",
      "paper_year": "2016",
      "chunk_content": "In step 3 of Algorithm 1 a greedy local search method was added as part of the evaluation process. Previous works $[19,22]$ have shown that without the inclusion of local optimizers, EAs are not expected to be competitive algorithms for large Ising spin glass problems.  \nThe details of the greedy local search implemented are shown in Algorithm 2. One main characteristic of the method is that the local fitness value of the current solution are stored in memory and only local computations are needed to evaluate the effect of bit flips. Therefore, only a fraction of computations are needed to evaluate the $n$ possible bitflips possible from the current solution. In addition, when the initial solution is a local optimum and no bit-flip improves the current fitness value, the local optimizer allows a predefined number of transitions (5) to solutions with lower fitness. In these cases, the bit-flip that decreases the fitness the least is selected. This mechanism, similar to one of the components of Tabu search was designed as a way to help the algorithm to escape from local optima. However, the local optimizer does not implement a memory or any other type of more sophisticated components. The local optimizer stops when the current solution can not be improved or the maximum number of transitions to solutions of lower fitness has been consumed.  \n  \nAfter solutions have been evaluated a random bit-flip mutation operator was applied. Extensive preliminary experiments showed that this way of infusing diversity in the pop-\nulation was a required ingredient for avoiding early convergence to poor solutions. More remarkably, a high mutation rate of $p_{m}=0.2$ showed to produce the best results. Notice, that all the EAs are compared in the same conditions. The only difference between the implementation of the six EAs is in step 5 of Algorithm 1. This step comprises the recombination operator for the GAs and the learning and sampling step for EDAs. The termination criteria for all algorithms was a maximum of 1000 generations or reaching a low diversity in the population ( 10 or less genotypically different individuals).",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:07:56",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "According to the details in the chunk, what advantages does QiSNN have over NBC and MLP in feature selection on the hypercube dataset, specifically regarding the number of selected features and convergence speed?",
      "topics": [
        "genetic"
      ],
      "answer": "On the hypercube dataset, QiSNN demonstrates the ability to decrease the feature number faster than NBC and MLP. While NBC achieves optimal classification accuracy, it does so without removing all irrelevant and redundant features, leading to some irrelevant features being selected due to genetic drift. QiSNN, in contrast, is capable of more rapidly reducing the number of features. The evolution of the average selected feature subset is similar across all methods, but QiSNN demonstrates a faster convergence towards a smaller feature subset.",
      "chunk_id": 6712,
      "paper_id": "Integrated feature and parameter optimization for an evolving spiking neural network  Exploring heterogeneous probabilistic models",
      "paper_title": "Integrated feature and parameter optimization for an evolving spiking neural network: Exploring heterogeneous probabilistic models",
      "paper_year": "2009",
      "chunk_content": "[IMAGE18]  \nFig. 6. Results on the hypercube dataset (see the text for explanation).\nthe beginning of the evolutionary run, towards high quality solutions in later generations. MLP and NBC display a more flat fitness evolution. We believe that fitness gradient is partially responsible for turning eSNN in a very good quality measure for feature subsets.  \nAccording to the presented results on the QiSNN, a strong correlation between classification accuracy and feature number appears advantageous in the context of a feature selection task. Fig. 5(g)-(i) present this dependence for the investigated induction methods. Each point in the diagram corresponds to a tuple (accuracy, feature number) obtained from the generational best individual of every generation. The color indicates the generation itself, the lighter the color the later the generation in which a given tuple was obtained. In the case of QiSNN (cf. Fig. 5(g)) a strong relationship between feature number and accuracy can be observed. ${ }^{1}$ Even for small decreases of the feature number significant accuracy improvements are reported. The strong correlation between feature number and classification accuracy introduces a gradient and partially reduces neutrality in the fitness landscape. Removing a redundant or irrelevant feature from the selected subset corresponds to a fitness gain for QiSNN, which may not necessarily be true for the other two tested methods. If the feature removal does not lead to a certain fitness gain and thus two solutions may have the same fitness value, the fitness landscape has a neutral dimension at the corresponding parameter. Due to genetic drift the neutral parameter will converge randomly, which means a random selection or non-selection of the encoded feature. In the fitness landscape defined by eSNN neutral dimensions are replaced by a fitness gradient, which allows the identification and exclusion of low quality features from the current subset. As a result the fitness landscape can be easily climbed by the optimization algorithm, leading to faster and more consistent convergence towards the optimal feature subset.  \nFig. 5(j) and (k) present the evolution of the eSNN parameters for the two versions of QiSNN. Although both methods have evolved similar final parameter configurations, the continuous exploration is much smoother compared to the binary one and allowed a finer parameter tuning. Due to the balanced nature of the dataset the parameter setting for the two classes have evolved to be approximately identical, i.e. $c_{1} \\approx c_{2}, m_{1} \\approx m_{2}$ and $s_{1} \\approx s_{2}$.  \nA similar analysis was done for the second benchmark dataset. We want to note that this dataset was very easy to solve by any of the tested algorithms. Even without feature selection MLP and NBC reported a very high classification accuracy. Nevertheless  \n[^0]we have decided to present these results here, since they show the proper functioning of all tested methods on an additional independent benchmark problem. Fig. 6 summarizes the results on the hypercube problem. In Fig. 6(a) the evolution of the average selected feature subset is shown. We have included the diagram for the enhanced QiSNN only, since the other methods report very similar results. Thus QiSNN was chosen as a representative of all tested algorithms. Similar to the figures presented on the spiral data above, different gray levels reflect how often a specific feature was selected at a certain generation. In this diagram the first five features correspond to the relevant features, followed by 30 irrelevant and finally five redundant features. All methods clearly identify the five relevant variables. QiSNN was capable of decreasing the feature number faster than NBC and MLP, cf. Fig. 6(b). NBC reports optimal classification accuracy without removing all irrelevant and redundant features. Without the presence of any selective pressure some features converge randomly due to genetic drift, which has resulted in the selection of some irrelevant features in case of NBC.",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:07:58",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the calculation of the GD (Generational Distance) quality indicator for an Estimation of Distribution Algorithm, what programming steps are necessary based on its definition?",
      "topics": [
        "convergence",
        "GD indicator",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "To calculate the GD indicator, a developer needs to compute the Euclidean distance of each solution in the solution set to its nearest point on the Pareto Front (PF). The GD is then the quadratic mean of these Euclidean distances. This involves iterating through each solution in the set, finding its nearest neighbor on the PF, calculating the Euclidean distance, and then computing the quadratic mean of all these distances.",
      "chunk_id": 10189,
      "paper_id": "An inverse model-based multiobjective estimation of distribution algorithm using Random-Forest variable importance methods",
      "paper_title": "An inverse model-based multiobjective estimation of distribution algorithm using Random-Forest variable importance methods",
      "paper_year": "2020",
      "chunk_content": "A simple way to evaluate the quality of solution sets is Quality indicators (QIs). In general, QIs can be classified in to six categories: ${ }^{47}$ (i) QIs for convergence, (ii) QIs for spread, (iii) QIs for uniformity, (iv) QIs for cardinality, (v) QIs for both spread and uniformity, and (vi) QIs for incorporated quality of the four quality aspects. There are two classes of convergence in QIs: one is to evaluate the Pareto dominance relation between solutions or sets and two is to evaluate the distance of a solution set to the PF. The GD indicator measures the quadratic mean of the Euclidean distances of solutions set to the nearest point on the PF. ${ }^{48}$ Spread quality is related to the area of a solution set covering. The pure diversity (PD) summarizes the dissimilarity of each solution to the remaining solutions of a solution set. ${ }^{49}$ Quality indicators for uniformity evaluate how uniformly a set's solutions are distributed and measuring the variation of the distance between the  \nsolutions, such as spacing (SP). ${ }^{50}$ QIs for cardinality add a different nondominated solution to the set under regard should improve the evaluation result. The QIs for spread and uniformity are closely related and can be used together to show the diversity of solution sets and classified into two groups: distance-based indicators and region division-based indicators. The region division-based QIs partitions a special space into many equal size cells and then computes the number of cells having solutions of the set. Some of them considers grid-like cells which partition the space into many hyperboxes, such as diversity metric (DM). ${ }^{51}$ QIs for all quality aspects cover convergence, spread, uniformity, and cardinality and they can be classified into two groups: distance-based QIs that measures the distance of PF to the solution set under consideration, such as inverted generational distance (IGD) ${ }^{2,52}$ and volume-based QIs that measures the size of volume and is specified by the consideration solution set in conjunction with some specifications, such as hypervolume (HV). ${ }^{53}$\nIn this work, QIs of GD, PD, DM, HV, and IGD are applied to measure the performance on test instances F1 to F10 (most of whih are biobjective MOPs) and 500 uniformly distributed points are selected from the PF of each test instance to be $P^{*}$. Also, IGD and HV is applied to measure the performance on the three objective WFG test instances, and the reference point FORMULA_404 is used to for all instances.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:00",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when optimizing energy consumption in route segments, and how are these metrics balanced against computational cost?",
      "topics": [
        "control"
      ],
      "answer": "The EDA's effectiveness is evaluated using a fitness value function, denoted as \\(F_{c}=\\int \\omega_{i}\\left(x_{k}, u_{k}\\right)+\\omega_{i} \\frac{P_{\\text {turi }}}{Q_{\\text {inc }}} d_{i}\\), where \\(\\omega_{k}\\) is the weight on electric energy consumption. Inequality constraints, such as \\(SOC_{\\min } \\leq SOC \\leq SOC_{\\max }\\) for the State of Charge, \\(P_{\\text {turi, } \\min } \\leq P_{\\text {turi }} \\leq P_{\\text {turi, max }}\\) for power, and \\(T_{\\text {con, } \\min } \\leq T_{\\text {con }} \\leq T_{\\text {con, max }}\\) and \\(T_{\\text {req, } \\min } \\leq T_{\\text {req }} \\leq T_{\\text {req, max }}\\) for temperatures, are also considered. The evaluation balances accuracy, optimization effect, and computation burden, with the number of iterations and population size adjusted to trade off these factors. Specifically, computation intensity, terminal battery SOC deviation, and fuel consumption are compared for different population sizes and iterations, demonstrating the trade-off between solution accuracy and computational cost.",
      "chunk_id": 10290,
      "paper_id": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
      "paper_title": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
      "paper_year": "2020",
      "chunk_content": "The energy consumption in each route segment is fundamentally planned by EDA, which is one of the validated evolution algorithms in parameter estimation and global optimal control [43,44]. By virtue of the probabilistic models, priori information in terms of problem structure is integrated into the optimizing process, contributing to generation of the ideal performance of EDA [45]. EDA tries to obtain the solution by evaluating the general performance in each iteration, rather than digging out the personally optimum in each iteration from the perspective of individual performance solved by GA or PSO. In addition, the unknown information of optimization space can be detected by the probabilistic model, so as to increase the probability of obtaining the optimal solutions [46]. The execution process of EDA is shown in Fig. 3 (a).  \nIn the implementation process of EDA, the fitness value function of evaluating the macroscopic performance can be expressed as:\n$F_{c}=\\int \\omega_{i}\\left(x_{k}, u_{k}\\right)+\\omega_{i} \\frac{P_{\\text {turi }}}{Q_{\\text {inc }}} d_{i}$,\nwhere $\\omega_{k}$ is the weight on electric energy consumption. The inequality constraints can be expressed as:  \n$$\n\\left\\{\\begin{array}{l}\nS O C_{\\min } \\leq S O C \\leq S O C_{\\max } \\\\\nP_{\\text {turi, } \\min } \\leq P_{\\text {turi }} \\leq P_{\\text {turi, max }} \\\\\nT_{\\text {con, } \\min } \\leq T_{\\text {con }} \\leq T_{\\text {con, max }} \\\\\nT_{\\text {req, } \\min } \\leq T_{\\text {req }} \\leq T_{\\text {req, max }} \\\\\n\\omega_{\\text {con, } \\min } \\leq \\omega_{\\text {con }} \\leq \\omega_{\\text {con, max }} \\\\\n\\omega_{\\text {req, } \\min } \\leq \\omega_{\\text {req }} \\leq \\omega_{\\text {req, max }}\n\\end{array}\\right.\n$$  \nwhere the subscripts min and max denotes the minimum and maximum value of each variable, respectively. The optimization control by EDA is performed in distance domain for better satisfying the local constraints. In the distance domain calculation, velocity at next location can be described as:\n$v(k+1)=v(k)+\\bar{v}(k) \\frac{2 \\Delta s}{v(k)+v(k+1)}$\nwhere $\\Delta s$ is the calculation step in distance, and $k$ and $k+1$ denote the location at current and next step. The probabilistic model in EDA is the Gaussian network model [47], and each continuous variable $X_{i} \\in X$ in the local density function can be written as:\n$f\\left(x_{i} \\mid p a_{i}^{\\prime}, \\theta_{i}\\right) \\equiv N\\left(x_{i} ; m_{i}+\\sum_{x_{i} \\in m_{i}} b_{i j}\\left(x_{i}-m_{j}\\right), \\frac{1}{v_{i}}\\right)$\nwhere $N\\left(x ; \\mu, \\sigma^{2}\\right)$ is the univariate normal distribution with mean value $\\mu$ and variance $\\sigma^{2} ; b_{i}$ is the local parameter which includes $m_{i}, b_{i}$ and $v_{i} . m_{i}$ denotes the unconditional mean of $X_{i} ; b_{i}$ is a column vector; $v_{i}$ is the conditional variance of $X_{i}$ under assigned $p a_{i}^{\\prime}$; and $b_{i j}$ is the linear coefficient reflecting the dependence between $X_{i}$ and FORMULA_105. The adopted sampling and learning methods in EDA are the univariate Gaussian model based method and greedy score method, respectively [48,49].  \nTo fast complete the optimization process in EDA with preferable performance, it is recommended that the iteration and population number should be carefully determined by trail-and-error. Given the WLTC driving cycle [50], the computation intensity, terminal battery SOC deviation, and fuel consumption by EDA with different populations and iterations are compared, and the results are presented in Fig. 3 (b). As can be observed, it looks closer to the set terminal SOC constraint with larger population and iteration. Likewise, the fuel consumption will be certainly lower. However, the increase of population and iteration will incur more computation labor, which is not applicable in real-time implementation. By comprehensively trading off accuracy, optimization effect, and computation burden, the number of iteration and population are set to 800 and 200, respectively.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:03",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically concerning community detection in complex networks, and what mechanisms are incorporated to enhance its performance?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to solve community detection problems using an Estimation of Distribution Algorithm with Local Sampling strategies (EDALS), employing modularity density as a fitness function. To improve convergence speed and accuracy, a local sampling strategy is developed based on a sampling probability matrix acquired from the local similarity matrix. Furthermore, a biased initialization of the population, also using a local similarity matrix, accelerates convergence, and simulated annealing selection is adopted to avoid EDALS becoming trapped in local optima, thereby increasing population diversity during the evolutionary procedure.",
      "chunk_id": 12316,
      "paper_id": "Estimation of Distribution Algorithm with Local Sampling Strategy for Community Detection in Complex Networks",
      "paper_title": "Estimation of Distribution Algorithm with Local Sampling Strategy for Community Detection in Complex Networks",
      "paper_year": "2016",
      "chunk_content": "To further test the effectiveness of the proposed algorithm, the experiments were performed on five well-known real-life\n[IMAGE5]  \nFig. 6. NMI and modularity for each dataset determined by each algorithm.\nnetworks, namely, the ${ }^{33)}$ Zacharys Karate Club network, Dolphin social network, American College Football network, ${ }^{34)}$ Krebs Books on US Politics network, and Facebook network.  \nComparison experiments of NMI and modularity on the five real-life networks were carried out and the results are shown in Figs. 6(a) and 6(b), respectively. The algorithm EDALS demonstrates a better performance than the relative given algorithms from what is recorded on the Zacharys Karate Club, Dolphin, Facebook, Krebs Books on US Politics, and American College Football networks. In the case of the Krebs Books on US Politics network and the Facebook network, the performance of the proposed algorithm EDALS is slightly worse than those of the FTQ and Informat algorithms.  \nTo give a time cost analysis of the proposed algorithm, an experiment on the time comparison of three nature-inspired algorithms is carried out in Fig. 7. It is clear that the proposed algorithm has a comparative time cost, and TGA is the most time-consuming since the time complexity of the decoding step is greater than those of the others.  \nFrom the above experiments, EDALS is considerable more efficient and competitive in solving community structure partition problems than FN, TGA, Infomap, FTQ, and iMeme-net. The local sampling strategy contributes to the  \n[IMAGE6]  \nFig. 7. Computational time of three algorithms.\nimprovement of executive speed for the EDAs and the accuracy of community detection, and simulated annealing selection can increase population diversity in the evolutionary procedure.\nIn this paper, an estimation of the distribution algorithm with local sampling strategies is proposed to solve community detection problems using modularity density as a fitness function. The sampling probability matrix can be acquired from the local similarity matrix, by which the local sampling strategy is developed to improve convergence speed and accuracy. Furthermore, a biased initialization of population is designed using a local similarity matrix to speed up the convergence. To avoid EDALS stall at local optimums, a simulated annealing selection is adopted. The performance of EDALS was tested on some artificial networks, LFR networks and several authentic networks with known community structures. The experiments on them showed that the performance of EDALS was good and modularity density maximization can resolve the resolution limit problem. In the future, we can improve our algorithm to reveal communities on large-scale networks.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:05",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the construction of the fitness function H(x, y, λ) using the penalty method, and how does the NCP function \\$\\phi(a, b) = \\min \\{a, b\\}\\$ contribute to handling constraints from the lower level problem's KKT conditions?",
      "topics": [
        "optimization"
      ],
      "answer": "The fitness function H(x, y, λ) is constructed using a penalty method to evaluate candidate solutions in the feasible region. It is defined as H(x, y, λ) = -F(x, y) - p1 * sum(max{0, Gi(x, y)}) - p2 * sum(max{0, |∇pj L(x, y, λ)|}) - p3 * sum(max{0, |\\$\\phi(-gs(x, y), λt)\\$|}), where F(x, y) represents the objective function, Gi(x, y) represents the upper level constraints, ∇pj L(x, y, λ) represents the KKT conditions, and \\$\\phi(-gs(x, y), λt)\\$ represents complementary conditions from the lower level problem's KKT conditions. The NCP function \\$\\phi(a, b) = \\min \\{a, b\\}\\$ is used to reformulate the complementary conditions from the lower level problem's KKT conditions. It has the property that \\$\\phi(a, b) = 0\\$ if and only if \\$a \\geqslant 0\\$, \\$b \\geqslant 0\\$, and \\$ab = 0\\$. The penalty parameters p1, p2, and p3 are sufficiently large to penalize violations of the upper level constraints or KKT conditions, ensuring that the fitness value at any infeasible point is lower than that at any feasible point.",
      "chunk_id": 1152,
      "paper_id": "Estimation of distribution algorithm for a class of nonlinear bilevel programming problems",
      "paper_title": "Estimation of distribution algorithm for a class of nonlinear bilevel programming problems",
      "paper_year": "2014",
      "chunk_content": "To handle the constraints in SLP, a new fitness function is provided by using a penalty method to evaluate the quality of each candidate solution. Hence, those better candidates receive higher fitness values, while the relatively worse solutions show lower fitness values. Moreover, the constraints of the original BLPP are also applied to keep individuals from the new population in the feasible region. Based on these processes, the estimation of distribution algorithm uses real encoding for both the upper and lower level variables, and the Lagrangian multipliers are designed as follows.\nFirst, the floating vector coding method is adopted for its faster convergence rate and higher computing precision. To keep each individual of the initial population in the feasible region and to make full use of the hierarchical structure of BLPP, the following two rules for the initialization step are set in advance:\n(1) the upper level decision of each individual belongs to the projection of the feasible solution region onto the solution space of the upper level problem.\n(2) the lower level decision of each candidate solves the lower level problem for the corresponding fixed upper level problem.  \nThe population size of each generation is denoted by PopSize. We first randomly generate PopSize vectors, $x^{i} \\in S(X), i=1,2$, ..., PopSize, as the upper level components of the initial points. Then, for each fixed $x^{i}$, the vector $y^{i}$ is obtained by solving the following lower level parametric problem (using the MATLAB Optimization Toolbox):  \n$$\n\\begin{aligned}\n& \\min _{y, t} f\\left(x^{i}, y\\right) \\\\\n& \\text { s.t. } g\\left(x^{i}, y\\right) \\leqslant 0\n\\end{aligned}\n$$  \nAfterward, with the fixed upper and lower level variables $\\left(x^{i}, y^{i}\\right)$, the corresponding KKT multipliers $\\lambda^{i}$ can be gained through solving the lower level problem's KKT conditions (6)-(9). Hence, the individuals generated in this way satisfy the original constraints and the KKT conditions of the follower's problem. All of the points $z^{i}=\\left(x^{i}, y^{i}, \\lambda^{i}\\right)$ form the initial population Pop(0) with the population size PopSize.\nIn this section, the penalty method is applied to address the constraints of SLP. We denote the fitness function at the point $z=(x, y, \\lambda)$ with $H(z)=H(x, y, \\lambda)$, which is defined by the following formula:  \n$$\nH(x, y, \\lambda)=-F(x, y)-p_{1} \\sum_{i=1}^{q} \\max \\left\\{0, G_{i}(x, y)\\right\\}-p_{2} \\sum_{j=1}^{m} \\max \\left\\{0,\\left|\\nabla_{p_{j}} L(x, y, \\lambda)\\right|\\right\\}-p_{3} \\sum_{i=1}^{p} \\max \\left\\{0,\\left|\\phi\\left(-g_{s}(x, y), \\lambda_{t}\\right)\\right|\\right\\}\n$$  \nwhere $m, p, q$ are defined as those in Section 2, and the NCP function $\\phi: R \\times R \\rightarrow R$ is defined for the complementary conditions from the lower level problem's KKT conditions as  \n$$\n\\phi(a, b)=\\min \\{a, b\\}\n$$  \nNote that the NCP function has the following property, which guarantees its efficiency in reformulating the complementary conditions:  \n$$\n\\phi(a, b)=0 \\Longleftrightarrow a \\geqslant 0, b \\geqslant 0, a b=0\n$$  \nLet $p_{1}, p_{2}, p_{3}$ denote the sufficiently large penalty parameters. Then, the fitness function that is defined in this way has the following property: the fitness value at any point $z$, which violates the upper level constraints or KKT conditions, is smaller than that at any feasible point. In this way, feasible solutions can be distinguished from infeasible solutions, and better individuals can be selected effectively. To be noticed, the optimal solution of the BLPP will achieve the highest fitness value.\nFrom the above ranked population, a subset of the most promising solutions are selected by the selection operator. In this paper, the selection operator is truncation selection with a threshold $\\tau$. For example, $\\tau=50 \\%$ means selecting the FORMULA_76 best solutions.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:08",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners estimate the distribution of selected subpopulations when using Univariate Marginal Distribution Algorithm (UMDA) compared to MIMIC?",
      "topics": [
        "optimization"
      ],
      "answer": "When using UMDA, practitioners should estimate the joint normal distribution assuming all variables are independent. In contrast, when using MIMIC, practitioners should estimate the distribution assuming variables are pairwise dependent. Both distributions are then used to generate new populations in the next generation.",
      "chunk_id": 13029,
      "paper_id": "Convergence of estimation of distribution algorithms in optimization of additively noisy fitness functions",
      "paper_title": "Convergence of estimation of distribution algorithms in optimization of additively noisy fitness functions",
      "paper_year": "2005",
      "chunk_content": "Yi Hong ${ }^{1}$, Qingsheng Ren ${ }^{1}$, Jin Zeng ${ }^{2}$, Yuchou Chang ${ }^{3}$${ }^{1}$ Department of Computer Science and Engineering, Shanghai Jiao tong University, P.R.China${ }^{2}$ Department of Mathematics, Shanghai Jiaotong Univeristy, P.R.ChinaFORMULA_6 Institute of ImageProcessing and Pattern Recognitiongoodji@sjtu.edu.cn\nNoise is a common phenomenon in many real-world optimizations. It has long been argued that evolutionary algorithm (EA) should be relatively robust against it. As a novel computing model in evolutionary computations, Estimation of Distribution Algorithm (EDA) is also encountered with it. This paper initially presents three dynamic models of EDA under the additively noisy environment with three different selection methods (proportional selection method, truncation selection method and tournament selection method). We verify that when the population size is infinite, EDA can converge to the global optimal point. This concept establishes the theoretic foundation for optimization of noisy fitness functions with EDA.\nGenetic algorithm (GA) [1] is a population based search method inspired from the notion of Darwinian evolution: Survival of the Fittest. According to this notion, GA employs such three simple operators as selection, crossover and mutation to generate the new populations. GA is simple to execute, and can search the global optimal point not depending on the gradient of target functions. Thus, it has been applied to a very wide range of problems. But Darwinian-type genetic algorithm is just semi-blind: positions of crossover and mutation are random. This randomness has greatly delayed the convergence speed of GA. Low convergence efficacy has become a major obstacle for its generalizations in real-world applications.  \nTo tackle the problem of low efficacy of GA, many effective methods have been proposed. Among them is Estimation of Distribution Algorithm (EDA). EDA was firstly proposed by Muhlenbein in 1996 [2], and has become a novel research area in evolutionary computation(EC)[3].Completely abandoning crossover\noperator and mutation operator, EDA turns to analyze the selected subpopulations to estimate their distribution, and then uses this estimated probability distribution to produce the population in the next generation. The kernel of EDA is how to estimate their distribution. To realize it, different methods have been proposed. Univariate Marginal Distribution Algorithm (UMDA) is perhaps the simplest EDAs. It supposes that all variables are independent, and uses their joint estimated normal distribution to generate the new populations. A more complex model is MIMIC, which supposes that variables are pairwise dependent. BOA and BEA are perhaps the most commonly-used EDAs. Both of them are based on Bayesian network, and their performances are very satisfactory. The frame of EDA is shown in figure 1. EDA has greatly improved the speed of genetic algorithm, and sometimes is more effective to solve some hard deceptive problems. But EDA is just a fresh research area, where there are so many works to be done. In this paper, we analyze the convergent performance of EDA under the additively noisy conditions.  \nArrangement of this paper is as follows. In section 2, we briefly introduce the existed models for EDA in noiseless conditions. Section 3 presents the dynamic models for EDA with three different selection methods under additively noisy conditions. In section 4, we verify that EDA can converge to the global optimal point under additively noisy conditions.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:09",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, how does the `CalculateMeanEvals` procedure aggregate evaluations to refine the model `M`, and what properties are guaranteed for the resulting model?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "model learning",
        "evaluation aggregation"
      ],
      "answer": "The `CalculateMeanEvals` procedure aggregates evaluations stored for state-position pairs by calculating, for each unique pair $\\langle S^{\\prime}, v^{\\prime}\\rangle$, an average evaluation from all triples $\\langle S, v, e\\rangle$ in which $S^{\\prime}=S$ and $v^{\\prime}=v$. After aggregation, the model `M` contains triples with unique values of `S` and `v`; specifically, no duplicate pairs $\\langle S, v\\rangle$ exist. The model `M` contains ordered triples $\\langle S, v, e\\rangle$ where `S` is a graph state, `v` is a protected node number, and `e` is the average evaluation achieved, rewarding assignments that are good at a given graph state by high final evaluations.",
      "chunk_id": 7073,
      "paper_id": "Estimation of Distribution Algorithms for the Firefighter Problem",
      "paper_title": "Estimation of Distribution Algorithms for the Firefighter Problem",
      "paper_year": "2017",
      "chunk_content": "```  \nAlgorithm 2 uses the following procedures:\nCanSpread - Returns a logical value indicating if in the graph state $S$ the fire can still spread, that is, if there are untouched nodes adjacent to burning ones. SelectPositions - Returns a set of $N_{f}$ numbers that correspond to untouched nodes in the state $S$ and are placed nearest the beginning of the permutation $\\pi$ (i.e. the first $N_{f}$ nodes in the state ' U ' appearing in $\\pi$ ).\nSpreadFire - Performs one step of the fire spreading by changing to ' B ' the state of all untouched (' U ') nodes adjacent to the burning ('B') ones.\nEvaluateState - Evaluates the final state $S$ by calculating the sum of values assigned to those vertices that are not burning ('B') in the state $S$.\nCalculateMeanEvals - Aggregates the evaluations stored for state-position pairs by calculating, for each unique pair $\\left\\langle S^{\\prime}, v^{\\prime}\\right\\rangle$, an average evaluation from all  \ntriples $\\langle S, v, e\\rangle$ in which $S^{\\prime}=S$ and $v^{\\prime}=v$. After the aggregation the model $M$ contains triples with unique values of $S$ and $v$ (no duplicate pairs $\\langle S, v\\rangle$ exist).  \nAfter the learning of the model is completed the set $M$ contains ordered triples $\\langle S, v, e\\rangle$. In each such triple a state of the graph $S$ is combined with the position (node number) $v$ which got protected and the average evaluation FORMULA_160 that was finally achieved. Using this scheme, assignments that are good at a given graph state are rewarded by high final evaluations.",
      "question_type": "algorithm analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:11",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the naive Bayes classifier, when used within Estimation of Distribution Algorithms (EDAs) for continuous domains, model variable dependencies compared to other Bayesian classifiers?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The naive Bayes classifier assumes that all variables $X_{1}, \\ldots, X_{n}$ are conditionally independent given the class value $C$. This means the joint density function is factorized into a product of unidimensional, conditionally independent normal densities, simplifying the model structure. Other Bayesian classifiers may consider interdependencies between variables, unlike naive Bayes which treats them as independent given the class.",
      "chunk_id": 6190,
      "paper_id": "Evolutionary Bayesian classifier-based optimization in continuous domains",
      "paper_title": "Evolutionary Bayesian classifier-based optimization in continuous domains",
      "paper_year": "2006",
      "chunk_content": "In EBCOAs for continuous domains, the classifiers are based on the learning of probabilistic graphical models, more concretely Bayesian classifiers based on conditional Gaussian networks [11]. The literature contains several examples of classifiers combined with evolutionary computation techniques. One of the first examples is the LEM algorithm [14] which makes use of rules to build a classifiers that records the main differences between the groups of best and worst individuals of each population.  \nThe supervised classification problem with $n$ continuous predictor variables consists in assigning any vector $\\boldsymbol{x}=\\left(x_{1}, \\ldots, x_{n}\\right) \\in \\mathcal{R}^{n}$ to one of the $|C|$ classes of a class variable $C$ that is known. The class value is denoted by $c$ and therefore we have that $c \\in\\{1,2, \\ldots,|C|\\}$. As a result, a classifier in supervised classification is defined as a function $\\gamma:\\left(x_{1}, \\ldots, x_{n}\\right) \\rightarrow\\{1,2, \\ldots,|C|\\}$ that assigns class labels to observations.  \nNext, we provide some examples of the classifiers from the ones considering less interdependencies to the ones considering most of them.\nThe Bayesian classifier that considers all the variables $X_{1}, \\ldots, X_{n}$ to be conditionally independent given the class value $C$ is known as naive Bayes [15]. In this case, the probabilistic graphical model can be considered to be a fixed structure as illustrated in Figure 1(a). In continuous domains it is usual to assume that the joint density function follows a $n$-dimensional normal distribution, and since independence between the variables - given the class variable $C$ - is assumed, this is factorized by a product of unidimensional and conditionally independent normal densities. Therefore, when classifying a new individual using the naive Bayes classifier we have that:  \n[IMAGE0]  \nFig. 1. Example of structures of Bayesian classifiers that can be obtained as a result of the different classification model building algorithms in a problem with four variables $X_{1}, \\ldots, X_{4}$ and the classvariable $C$ : (a) naive Bayes (b) seminaire Bayes (c) tree augmented naive Bayes.  \n$$\np\\left(C=c \\mid X_{1}=x_{1}, \\ldots X_{n}=x_{n}\\right) \\propto p(c) \\cdot f\\left(x_{1} \\mid c\\right) \\cdot f\\left(x_{2} \\mid c\\right) \\cdot \\ldots \\cdot f\\left(x_{n} \\mid c\\right)\n$$  \nwhere  \n$$\nf\\left(x_{i} \\mid c\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{i c}} e^{-\\frac{1}{2}\\left(\\frac{x_{i}-\\mu_{i c}}{\\sigma_{i c}}\\right)^{2}}\n$$  \nfor all $i=1, \\ldots, n$ and $c=1, \\ldots,|C|$ with $\\mu_{i c}$ and $\\sigma_{i c}$ representing the mean and the standard deviation of $X_{i} \\mid C=c$ respectively.  \nIn order to apply a naive Bayes classifier in EBCOAs, the estimation of the a priori probability of the class, $p(c)$, as well as the parameters $\\mu_{i c}$ and $\\sigma_{i c}$ of the conditional density functions, FORMULA_25, are carried out from the database of selected individuals at each generation.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:13",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned, what data structures are required to manage the population and probability vector, and how are they used during the iterative phase?",
      "topics": [
        "optimization"
      ],
      "answer": "The EDA requires a data structure to hold the probability vector, which is initialized with values of 0.5. During the iterative phase, another data structure is needed to store the set of \\(M\\) individuals produced based on the probability vector using random encoding. A subset of \\(N\\) individuals from this set forms an intermediate population. The algorithm then performs a random local search on each individual in this intermediate population, potentially requiring a data structure to manage the neighboring individuals. If \\(V\\) neighboring individuals (where \\(V \\leq N\\)) lead to fitness function enhancement, they replace individuals in the intermediate population.",
      "chunk_id": 8272,
      "paper_id": "A novel approach for protein structure prediction based on an estimation of distribution algorithm",
      "paper_title": "A novel approach for protein structure prediction based on an estimation of distribution algorithm",
      "paper_year": "2019",
      "chunk_content": "Concerning the proposed EDA in Algorithm 2, it could be observed that the algorithm attempts to explore the various parts in the search space using a stochastic local search (SLS). The employed selection strategy is a potential factor in the enhancement of the algorithm in the areas such as searching the whole search space and moving away from the local optimal.  \nAs it can be observed in the pseudo-code of the algorithm, the probability value is initially set to 0.5 . In the iterative phase, the first set of $M$ individuals is produced based on the values in the probability vector according to random encoding. Then, a subset of $N$ individuals is selected from the previous set and created an intermediate population and random local search is performed on each selected individuals in the intermediate population. In each stage of the local search, $V$ individual $(V \\leq N)$ selected if the neighboring individual leads to an enhancement of the fitness function, it is replaced in the individual from the intermediate population. Finally, the algorithm attempts to update\nthe probability curve in the last repetition. The estimation of distribution procedure is run until the termination condition is satisfied. A summary of the algorithm is shown in Algorithm 2.\nThe proposed EDA has been implemented within Visual Studio 2008 and C\\# programming language in a personal computer having a 2.5 GHz dual-core processor and a 3 GB RAM. To examine the direction and correctness of the proposed method and present its efficiency and strength, we arranged a set of assessments that are represented in this section. Generally, performance of the evolutionary solutions developed for optimization problems is verified using certain types of assessment methods. Accordingly, a number of these standard assessment tools have been applied to analyze and examine the proposed solution. Furthermore, the performance of the proposed algorithm was assessed using different sets of benchmarks.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:15",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific performance improvement has been observed when applying relaxation by margins to the univariate marginal distribution algorithm (UMDA) on the BVLEADINGONES fitness function, and how is this improvement quantified in terms of runtime complexity?",
      "topics": [
        "search"
      ],
      "answer": "Introducing margins, which restrict the estimated marginal probabilities in the univariate distribution to the interval $[1 / M, 1-1 / M]$ where $M$ represents the offspring population size, improves the runtime of UMDA on the unimodal fitness function BVLEADINGONES from infinite (with overwhelming probability) to $O(N n)$ (with overwhelming probability), where $N$ is the parent population size and $n$ is the problem size.",
      "chunk_id": 6899,
      "paper_id": "When is an estimation of distribution algorithm better than an evolutionary algorithm",
      "paper_title": "When Is an Estimation of Distribution Algorithm Better than an Evolutionary Algorithm?",
      "paper_year": "2009",
      "chunk_content": "In a series of papers, Chen et al [11], [12], [13] have analysed the runtime of another univariate EDA called the univariate marginal distribution algorithm (UMDA) on several non-linear problems. In contrast to the cGA, the UMDA employs a population of individuals, where the parent and offspring population sizes are specified by parameters $N$ and $M$, respectively. The initial analysis was made under a \"no-random-error\" assumption, showing that the expected runtime of UMDA on the LEADINGONES function is $O(N n)$ [11]. Furthermore, it was proved that a variant of this problem called TRAPLEADINGONES is hard for the UMDA. However the \"no-random-error\" assumption does not hold in practice. Improved techniques were therefore later developed to lift this assumption, and proving that the runtime of $O(N n)$ on the LEADINGONES function still holds [13]. This and the following results hold when the population sizes are sufficiently large, i.e. as in Theorem 2 in this paper.  \nAs for the cGA, the probability distribution updated by the traditional UMDA can under certain circumstances get stuck  \n[^0]:    The authors are listed in alphabetic order. T. Chen, K. Tang and X. Yao are with the Nature Inspired Computation and Applications Laboratory (NICAL), Department of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China. P. K. Lehre (X. Yao) is (also) with the Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, University of Birmingham, Edgbaston, Birmingham B15 2TT, UK. (Email: cetacy@mail.ustc.edu.cn, P.K.Lehre@cs.bham.ac.uk, ketang@ustc.edu.cn, x.yao@cs.bham.ac.uk)  \nat certain values. To alleviate for this problem, the univariate distribution learned by the UMDA can be restricted in some way. One such idea is the relaxation by margins, which restricts the estimated marginal probabilities in the univariate distribution to the interval $[1 / M, 1-1 / M]$. It has been proved that this modification can dramatically improve the runtime on some fitness functions [13]. In particular, introducing margins on the unimodal fitness function BVLEADINGONES improves the runtime from infinite (with overwhelming probability), to $O(N n)$ (with overwhelming probability) [13]. Gonzales has proved that using Laplace correction, which is a similar but earlier idea, one can obtain a general exponential upper bound on the expected runtime of several EDAs, including UMDA on any fitness function [14]. On the other hand, in recent work, it has been proved that the function TraPLEAdingONES remains hard for the UMDA, even with relaxation by margins [12].",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:16",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the specific EDA discussed in conjunction with PLS for creating calibration models?",
      "topics": [
        "selection"
      ],
      "answer": "The key takeaway is that combining EBNA$_{\\text {BIC }}$ for feature selection with PLS leads to more accurate and valid calibration models compared to using PLS alone, particularly for datasets where PLS struggles to achieve a calibration error of less than 10%. The EBNA$_{\\text {BIC }}$ also reduces the number of features, resulting in more interpretable models.",
      "chunk_id": 6142,
      "paper_id": "Parallel EDA to create multivariate calibration models for quantitative chemical applications",
      "paper_title": "Parallel EDA to create multivariate calibration models for quantitative chemical applications",
      "paper_year": "2006",
      "chunk_content": "Once the experiments have been carried out, we can analyze the obtained results from two points of view: quality of\n[IMAGE6]  \nFig. 12. Small problem. Boxplot of MSEPs.\nthe calibration models (in terms of MSEP) and execution time required by each approach.\nResults are provided in Table 4 and Figs. 12-14 (boxplot diagrams). It can be seen that, in all but one case, PLS-based approaches outperform those based on MLP. A prior filtering of the database, looking for the most relevant variables, seems to be useful for the MLP approach (better results for all the problems) but not for PLS. The use of EBNA $_{\\text {BIC }}$ to carry out a selection of variables shows itself really helpful in terms of improvement of the modelling ability of PLS: compare the resulting errors and deviations with that obtained using the whole set of features. In addition, the number of features selected by $\\operatorname{EBNA}_{\\text {BIC }}$ (50, 47, and 66 for the small, medium, and large problems respectively), provide easily interpretable models.  \nIn the quantitative chemistry field, a model is considered valid when the calibration error is equal or less than a $10 \\%$. We  \n[IMAGE7]  \nFig. 13. Medium problem. Boxplot of MSEPs.\n[IMAGE8]  \nFig. 14. Large problem. Boxplot of MSEPs.\nhave summarized in Table 5 the calibration errors for the two best approaches (PLS and EDA + PLS), expressed in percentage, for the three datasets. These percentages have been calculated applying the following formula generally used in this field:  \n$$\n\\text { Percentage error }=100 \\sqrt{\\frac{\\sum_{i=1}^{c}\\left(\\hat{C}_{i}-C_{i}\\right)^{2}}{\\sum_{i=1}^{c} C_{i}^{2}}}\n$$  \nwhere c is the number of cases, and $\\hat{C}_{i}$ and $C_{i}$ are the predicted and actual concentration values, respectively. Note that these values $\\left(\\hat{C}_{i}\\right.$ and $\\left.C_{i}\\right)$ should be the real, non-normalized ones. Error percentages have been calculated using the values obtained in the best execution of each algorithm.  \nAccording to these results, PLS by itself (using all the variables) is able to obtain a valid model only for the small and large datasets. However, the EDA + PLS method provides valid models for all the problems, even if for the medium dataset the results are quite tight (we attribute this to the reduced number of cases in the dataset). In addition, this approach presents models that can be more interpretable as the number of features is reduced from thousands to four-six tens.  \nThe conclusion of this section is that, in terms of accuracy of calibration and validity of the models, the combination of parallel $\\mathrm{EBNA}_{\\mathrm{BIC}}$ with PLS is the most promising of all the techniques considered, for the three databases used in this study.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:18",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs applied to neural network optimization, how does the algorithmic mechanism of Population-Based Incremental Learning (PBIL) differ when used for evolving weights in a single-layer feedforward neural network versus optimizing the discrete architecture of a multilayer perceptron?",
      "topics": [
        "evolutionary"
      ],
      "answer": "When applied to single-layer feedforward neural networks, PBIL optimizes the 'input weights and hidden biases' by coupling with the extreme learning machine model. In this scenario, the individuals in PBIL are real vectors representing the weights. However, when optimizing the discrete architecture of a multilayer perceptron, PBIL is used in combination with a quasi-Newton method to simultaneously optimize the discrete architecture and the corresponding real-valued weights. In the case of pruning synaptic connections, the individuals consist of assigning a bit for each connection between nodes in the multilayer perceptron, where the bit denotes whether the connection is to be used.",
      "chunk_id": 2533,
      "paper_id": "Estimation of Distribution Algorithms in Machine Learning A Survey",
      "paper_title": "Estimation of Distribution Algorithms in Machine Learning: A Survey",
      "paper_year": "2024",
      "chunk_content": "network, $n_{i}$ and $f_{i}$ are the number of nodes and the transfer function, respectively, in the $i$ th hidden layer, and $\\boldsymbol{w}^{i}$ is the vector of weights connecting nodes between the $(i-1)$ th and $i$ th hidden layers.  \nEarly work on EDAs in artificial neural networks focused on evolving the weights of multilayer perceptrons with a fixed topology [129], [130], [131], [132], and the use of this evolutionary computation method was considered as an alternative to the backpropagation method given its local optimality characteristic, stemming as a gradient descent method. In all these works, the multilayer perceptron topology only allowed one hidden variable layer. The individuals of the EDAs were real vectors of dimensions equal to the number of weights of the multilayer perceptron. The EDAs used for the search of the optimal weights were PBIL [129], [130], UMDA ${ }_{c}^{G}$ [131], [132], and MIMIC ${ }_{c}^{G}$ [131]. The input weights and hidden biases are the variables to be optimized in [133] in singlelayer feedforward neural networks, coupling an EDA (PBIL) and the extreme learning machine model.  \nThe simultaneous search for the optimal structure and weights of a multilayer perceptron is a more complex problem, that has also been addressed with EDAs. While PBIL was used in combination with a quasi-Newton method in [134] to optimize the discrete architecture and its corresponding real value weights at the same time, in [135], a variant of UMDA FORMULA_221 within the probabilistic incremental program evolution framework was applied.  \nA simpler problem is that of the optimal pruning of synaptic connections from a complete artificial neural network topology, such as that developed in [136] for the case of a multilayer perceptron with a single hidden layer. In this case, the representation of individuals is direct and consists of assigning a bit for each connection between nodes in the multilayer perceptron. The bit denotes whether the corresponding connection is to be used. Three EDAs were used: 1) cGA; 2) EcGA; and 3) BOA.  \nThe automatic design of a fully connected multilayer perceptron with only a hidden layer was approached with a UMDA in [137] for time series forecasting. The parameters to be optimized were the number of input nodes, the number of hidden neurons, how the nodes are connected (weights), and the seed used to initialize the connection weights in the backpropagation method.  \nDeep neural networks [138] contain multiple hidden layers of units between the input and output layers rendering the search for their optimal hyperparameters much more complex than in a multilayer perceptron with a single hidden layer of units. Evolutionary computation algorithms applied to optimize deep learning is called evolutionary deep learning. According to [22], evolutionary deep learning has been used in all deep learning models, roughly divided into convolutional neural networks, deep belief networks, stacked autoencoders, recurrent neural networks, and generative adversarial networks. The formulation above would contain additional parameters in the case of deep neural networks, e.g., the number of kernels in the convolutional layer, the kernel size, and the kind of pooling layer. In [139], univariate EDAs (with continuous and discrete variables treated separately) were used in convolutional networks for the simultaneous optimal",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:20",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners interpret the symbol $\\pi_{i j}^{t}$ in the context of converting an individual's solution into an integer sequence?",
      "topics": [
        "mutation"
      ],
      "answer": "The symbol $\\pi_{i j}^{t}$ represents the $j$th dimension of the $i$th conversion sequence at generation $t$, where the conversion sequence, denoted by $\\pi$, is the integer representation of an individual's solution, used within the EDA to facilitate probability distribution learning and sampling of new solutions. This conversion is crucial for adapting continuous EDA methods to discrete optimization problems such as job shop scheduling.",
      "chunk_id": 12223,
      "paper_id": "A hybrid differential evolution and estimation of distribution algorithm based on neighbourhood search for job shop scheduling problems",
      "paper_title": "A hybrid differential evolution and estimation of distribution algorithm based on neighbourhood search for job shop scheduling problems",
      "paper_year": "2016",
      "chunk_content": "Some symbols used mostly through this paper are summarised as follows:\n$n \\quad$ number of jobs\n$m \\quad$ number of machines\n$o_{i j} \\quad$ the $j$ operation of the job $i$\n$J_{i} \\quad$ the $i$ th job\n$M_{i} \\quad$ the $i$ th machine\n$t \\quad$ the $t$ th generation\n$\\boldsymbol{X}_{i} \\quad$ the population of $i$ th iteration\n$\\boldsymbol{X}_{i}^{\\prime}(i) \\quad$ the $i$ th individual of the population of $i$ th iteration\n$\\boldsymbol{x}_{i} \\quad$ the $i$ th individual in population\n$x_{i j} \\quad$ the $j$ th dimension of the $i$ th individual\n$\\mu_{j} \\quad$ the mean of the $j$ th dimension in current population\n$\\sigma_{j} \\quad$ the standard of the $j$ th dimension in current population\n$F_{t} \\quad$ the value of the scale factor of $t$ th iteration\n$C R_{t} \\quad$ the value of the crossover rate of $t$ th iteration\n$\\gamma_{t} \\quad$ the value of the differential decisive factor of $t$ th iteration\n$v_{i}^{t} \\quad$ the $i$ th mutation individual in $t$ th generation\n$v_{i j}^{t} \\quad$ the $j$ th dimension of the $i$ th mutation individual in $t$ th generation\n$\\boldsymbol{u}_{i j}^{t} \\quad$ the $j$ th dimension of the $i$ th crossover individual in $t$ th generation\nrand a real number between 0 and 1 with uniform distribution\n$\\pi \\quad$ the integer conversion sequence of the individual in population\n$\\pi_{i j}^{t} \\quad$ the $d$ th dimension of the $i$ th conversion sequence\nBlock $_{i}$ the $i$ th critical sub-block",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:22",
      "generation_style": "practical_application"
    },
    {
      "question": "Within the context of the asset allocation algorithm, how are the minimum necessary proportion $L$ and the maximum usable proportion $U$ determined for an asset $k$, and what constraints do they aim to satisfy?",
      "topics": [
        "constraints"
      ],
      "answer": "The minimum necessary proportion $L$ for asset $k$ is defined as the maximum of three values, which ensure the algorithm meets budget, grouping, and boundary constraints. Specifically, these values are derived from the unassigned proportion availableweight to exhaust availableweight, the unreached lower group bound value $d_{g_{k}}$ to fulfill the lower group bound constraint, and the lower bound $lb_{k}$ to satisfy boundary constraint. The maximum usable proportion $U$ for asset $k$ is the minimum of three values, ensuring the algorithm meets budget, grouping, and boundary constraints. These values are derived from the minimum necessary proportion of each group, the lower bound value $f_{g_{k}}$ from $c_{g_{k}}$, and the upper bound $ub_{k}$ under boundary constraint. The WeightAssignment() function then adjusts the proportion value $w_{k}$ for asset $k$ to fall within the range of $L$ and $U$, ensuring that all constraints are satisfied.",
      "chunk_id": 3903,
      "paper_id": "A knowledge-based constructive estimation of distribution algorithm for bi-objective portfolio optimization with cardinality constraints",
      "paper_title": "A knowledge-based constructive estimation of distribution algorithm for bi-objective portfolio optimization with cardinality constraints",
      "paper_year": "2023",
      "chunk_content": "```  \n$c_{m}$ is the remaining usable proportion of group $m$ which is calculated by subtracting the assigned proportion from the upper group bound $u g_{m} . e_{m}$ is the sum of remaining assets' upper bound of group $m$. The maximum usable proportion of group $m$ is the smaller value of $c_{m}$ and $e_{m}$. In order to meet budget constraint, we need to make sure the unassigned proportion availableweight can be exhausted. We assume that each group except group $g_{k}$ takes the maximum usable proportion and the remaining assets in group $g_{k}$ take their upper bound value $e_{g_{k}}$. After that, the remaining proportion should be assigned to asset $k$ to exhaust availableweight. In order to meet grouping constraint, we need to make sure the unreached lower group bound value $d_{g_{k}}$ can be fulfilled. We assume that the remaining assets in group $g_{k}$ take their upper bound value $e_{g_{k}}$ from $d_{g_{k}}$, the remaining proportion should be assigned to asset $k$ to fulfill the lower group bound constraint. In order to meet boundary constraint, the investment proportion of asset $k$ should greater than $l b_{k}$. The minimum  \nnecessary proportion $L$ is the maximum value of the above three values.\n$d_{m}$ is the unfulfilled proportion of group $m$ which is calculated by subtracting the assigned proportion from the lower group bound $\\lg _{m} . f_{m}$ is the sum of the remaining assets' lower bound of group $m$. The minimum necessary proportion of group $m$ is the bigger value of $d_{m}$ and $f_{m}$. To fulfill budget constraint, we assume that each group takes the minimum necessary proportion and the remaining assets in group $g_{k}$ take their lower bound value $f_{g_{k}}$. After that, the remaining proportion is the maximum proportion that can be assigned to asset $k$. In this way, the remaining $K$ k assets still have a feasible assign space. We assume that the remaining assets in group $g_{k}$ take their lower bound value $f_{g_{k}}$ from $c_{g_{k}}$, the remaining proportion is the maximum proportion of asset $k$ under grouping constraint. The investment proportion of asset $k$ should smaller than $u b_{k}$ under boundary constraint. The maximum usable proportion $U$ is the minimum value of the above three values. After finding out the minimum necessary proportion $L$ and the maximum usable proportion $U$ of asset $k$, WeightAssignment() function can adjust the proportion value $w_{k}$ for asset FORMULA_233 to satisfy all constraints.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:24",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What enhancement does the modified variable neighborhood search (MVNS) provide to the Estimation of Distribution Algorithm (EDA) in the context of flexible manufacturing system (FMS) scheduling, and how are its local searches adapted?",
      "topics": [
        "scheduling"
      ],
      "answer": "The modified variable neighborhood search (MVNS) is developed as an efficiency enhancement of the Estimation of Distribution Algorithm (EDA). The local searches in MVNS are modified to accommodate the Petri net (PN) models of flexible manufacturing systems (FMSs).",
      "chunk_id": 10903,
      "paper_id": "An estimation of distribution algorithm for scheduling problem of flexible manufacturing systems using Petri nets",
      "paper_title": "An estimation of distribution algorithm for scheduling problem of flexible manufacturing systems using Petri nets",
      "paper_year": "2018",
      "chunk_content": "researchers. It uses neither crossover nor mutation operator, but reproduces offsprings based on a probabilistic model learned from a population of parents. This model-based approach to optimization allows EDA to successively solve many complex and large problems [28-31]. However, to the best of our knowledge, no work has been done for the scheduling problem of FMSs using EDA Can EDA be used to solve this problem and obtain more promising results than existing methods?  \nThis work intends to answer the question by proposing a new EDA. A candidate solution of the scheduling problem is represented as an individual of two sections, route information and operation sequence. This first section contains the route information of parts and the second is a permutation with repetition for all the parts. To exclude infeasible individuals, a kind of PN-based deadlock controllers for FMSs is imbedded. Since the probabilistic model of EDA constitutes the main issue and the performance of the algorithm is closely related to it [32], in this work, an effective setting procedure is adopted to construct the model. The longest common subsequence (LCS) that finds the common elements of two individuals is also embedded in the model for mining excellent genes. Then, an effective individual is produced based on the model from a seed individual, which is selected from the current population by a roulette method. Furthermore, to achieve a better result, a modified variable neighborhood search (MVNS) is developed as an efficiency enhancement of EDA. The local searches in MVNS are modified to accommodate the PN models of FMSs. To the author's knowledge, only a few research works [20-25] study the scheduling problem considered in this paper. Hence, we test and compare our proposed algorithm with all existing comparable examples and works. Experimental results and comparisons show that the proposed scheduling algorithm outperforms the existing ones, as it provides the best known solutions for 13 of 16 benchmark instances among the five compared approaches. Our proposed scheduling algorithm can be also applied to industrial problems such as flexible manufacturing cells and flexible job-shop production systems.  \nThe rest of the paper is organized as follows. Sect. 2 reviews the PN modeling of FMSs and PN-based deadlock controllers. Sect. 3 develops a scheduling method via PN and EDA, together with the MVNS. The experimental results and comparisons are shown in Sect. 4. Sect. 5 concludes this paper.\nThis section first briefly reviews the basics of Petri nets (PNs), then the PN model of FMS for scheduling and the deadlock controller. For more details, the readers are referred to FORMULA_6.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:26",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the DE/EDA method when applied to the optimization of PCF structure characteristics, as described?",
      "topics": [
        "optimization",
        "algorithms",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The text specifies that the DE/EDA method is applied for the optimization of the PCF structure with desirable properties. While the specific steps of the DE/EDA method are not detailed, the text mentions optimizing the structure to achieve an ultra-low confinement loss (on the order of $10^{-7}$) and low dispersion at $1.55 \\mu m$ wavelength with a dispersion slope of $\\pm 0.012 ps nm^{-2}$ over the C communication band. Further optimization involves increasing the number of individuals' chromosomes (PCF parameters) within the DE/EDA method to improve PCF characteristics.",
      "chunk_id": 6832,
      "paper_id": "Advanced design and optimization of single mode photonic crystal fibers",
      "paper_title": "Advanced design and optimization of single mode photonic crystal fibers",
      "paper_year": "2009",
      "chunk_content": "In further work, we are going to combine EDA with the hill climbing (HC) algorithm for tackling this optimization problem. Also we will try to present the cost function using a combination of dispersion, dispersion slope, loss, bending loss and mode area characteristics in order to design an optimum photonic crystal fiber. Furthermore, we will attempt to\ndemonstrate that the number of the individuals' chromosomes (PCF parameters) can be increased to achieve a PCF structure with better characteristics.\nIn this article, a novel design method based on the Nero-Fuzzy system and the DE/EDA method is introduced. We have investigated the suitability of the Nero-Fuzzy system to predict the properties of PCFs. After numerous tests, it is revealed that this method is remarkably effective in predicting the properties of PCF such as dispersion, dispersion slope and loss over the C communication band. It can predict the characteristics of PCFs with high accuracy of more than $99 \\%$. The DE/EDA method is applied for the optimization of the structure with desirable properties. The simulation results demonstrate that DE/EDA is an excellent method in the optimization problem of the PCF structure. The optimized PCF exhibits an ultra low confinement loss in the order of $10^{-7}$ and low dispersion at $1.55 \\mu \\mathrm{~m}$ wavelength with a dispersion slope of $\\pm 0.012 \\mathrm{ps} \\mathrm{nm}^{-2}$ FORMULA_138 over the C communication band. With further optimization of the structure and increasing the number of individuals' chromosomes in the DE/EDA method, PCF characteristics can be further improved.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:27",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmark datasets are used to evaluate the performance of the Estimation of Distribution Algorithm (EDA) for the Direct Acyclic Graph Task Scheduling Problem (DAG-SP)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The EDA's performance is evaluated using a commonly used DAG dataset from http://www.kasahara.elec.waseda.ac.jp/schedule/ and DAG applications from real-world problems, including the Gauss elimination algorithm (GE) and Fast Fourier Transformation (FFT), along with scientific workflows. New datasets are also produced based on different CCR values, where the data communication size follows a normal distribution.",
      "chunk_id": 9483,
      "paper_id": "A path relinking enhanced estimation of distribution algorithm for direct acyclic graph task scheduling problem",
      "paper_title": "A path relinking enhanced estimation of distribution algorithm for direct acyclic graph task scheduling problem",
      "paper_year": "2021",
      "chunk_content": "Two benchmark datasets are adopted in this paper: A commonly used DAG dataset [41] (http://www.kasahara.elec.waseda. ac.jp/schedule/) and DAG applications from real world. To supplement the communication data information of [41], new datasets are produced in accordance to different CCR values. Data communication size is produced following normal distribution with the average value of a certain $C C R$ according to (1). In addition, the settings of $\\{n, m, C C R\\}$ can be referred to Table 2. For each combination of $\\{n, m, C C R\\}, 60$ independent cases are produced.  \nIn addition, DAG applications from real world problems are carried out as the test instances: Gauss elimination algorithm (GE) [42] and Fast Fourier Transformation (FFT) [43] and scientific workflows [44]. The general structures of these DAGs are presented as Figs. 13 and 14.  \nThe detailed datasets can be referred in https://www.research gate.net/publication/352697650DAG-benchmark.  \nFor the comparison algorithms, HEFT [18], PEFT [15], GA[23] and PSO[29] are selected as. HEFT is considered as the best DAG-SP list scheduling heuristic in terms of robustness and performance compared with around 20 heuristic methods [45]. In this simulation test, the minimum makespan among HEFT-t-level, HEFT-b-level and HEFT-tb-level is adopted as its result. Compared to HEFT, PEFT considers the impact of task assignment on its children nodes. Besides, GA is an efficient evolutionary algorithm designed for solving DAG-SP, which adopts existing heuristic permutations to initialize the population. Similar with GA, PSO is also an evolutionary algorithm tailored for DAG-SP, which considers more than one objectives simultaneously.  \nDuring the simulation, two parameters of our proposed EDA: population size $(N)$ and learning rate $(\\alpha)$ are set as the parameters in the simulation experiments based on our previous works [35]. The population size and stopping criterion are set the same for EDA, GA and PSO. The detailed settings are listed as follows.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:29",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when applied to the multiple Traveling Salesman Problem (mTSP), as evidenced by the various chromosome representations?",
      "topics": [
        "genetic"
      ],
      "answer": "The algorithmic approaches aim to efficiently represent and optimize solutions for the mTSP using various chromosome representations within EDAs. These representations, such as one-chromosome, two-chromosome, two-part chromosome, and multichromosome, each attempt to balance solution space size and computational complexity. Strategies like pheromone-based crossover operators, local search (relocation, exchange, and 2-opt), and grouping GAs are employed to enhance solution quality by minimizing total distance traveled or minimizing the maximum distance traveled by any salesman.",
      "chunk_id": 5465,
      "paper_id": "A Hybrid Estimation of Distribution Algorithm with Decomposition for Solving the Multiobjective Multiple Traveling Salesman Problem",
      "paper_title": "A Hybrid Estimation of Distribution Algorithm with Decomposition for Solving the Multiobjective Multiple Traveling Salesman Problem",
      "paper_year": "2012",
      "chunk_content": "In this section, a literature review, focusing on the application of evolutionary approaches to mTSP, is provided. See [24] for a more rigorous review of the works that involved nonevolutionary techniques, which is out of scope of this paper. A brief introduction on EDAs and local search metaheuristics will also be presented.\nThe first implementation of genetic algorithm (GA) to solve the mTSP was carried out in [25]. Zhang et al. used a simple GA with natural representation to schedule the multiple teams of photographers to visit a large number of elementary and secondary schools. The objective is to minimize both the total distance traveled and the time consumed, such that the time constraints are satisfied and each team must be able to visit at least two schools daily. Unfortunately, the authors did not elaborate on how they manipulated multiple teams in their chromosome representation.  \nAnother application of the mTSP, involving a hot rolling scheduling problem in Shanghai Baoshan Iron and Steel Complex, was studied by Tang et al. [4]. The problem considers actual production constraints and aims to schedule multiple turns within the same shift. The authors first modeled the hot rolling scheduling problem as an mTSP. Next, the mTSP was converted into a classical TSP through the proposal of a one-chromosome representation. The selection operation was modified such that\nthe best solutions obtained so far were always selected to be one of the parent chromosomes to undergo crossover operation.  \nIn [26], Park studied the vehicle scheduling problem using GA. Since there are multiple vehicles involve in the routing, the problem can, basically, be classified as an mTSP. In the paper, a two-chromosome representation was proposed. The first chromosome locates the cities, while the second chromosome indicates which vehicle is to be assigned to visit the city specified in the first chromosome. In [27], a two-part chromosome representation was proposed for the mTSP. Under this scheme, the chromosome for a gene is divided into two distinct parts. The first part of the chromosome allots the permutation of the cities, while the second part of the chromosome determines the number of cities to be visited by each salesman. This means that there will be an additional of $m$ genes in the chromosome for $m$ salesmen. In this two-part chromosome representation, the solution space is also smaller than the two-chromosome representation. The results also demonstrated that the proposed representation is able to produce better results than the one-chromosome representation under most of the test instances.  \nZhao et al. [28] proposed a GA, which utilized the onechromosome representation, to solve the mTSP. The algorithm employed a pheromone-based crossover operator that utilized information of edge lengths, adjacency relations, and pheromone levels to construct new solutions. Several local search strategies (relocation, exchange, and 2-opt) were also used to facilitate the search. The grouping GA was also used by Singh and Baghel [6] who proposed a replacement policy to reduce problem redundancy. In their work, two different objective functions were considered-minimizing total distance traveled by all salesmen, and minimizing the maximum distance traveled by any salesman.  \nRecently, multichromosome representation of mTSP solutions has been proposed in [29] where the route assigned to each salesman was represented in a chromosome. Therefore, each solution has FORMULA_7 associated chromosomes. The crossover and mutation operators designed to deal with the representation were also proposed.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:31",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of path relinking, as incorporated into the P-EDA, theoretically contribute to the algorithm's performance in addressing the blocking flow-shop scheduling problem (BFSP) with the makespan criterion?",
      "topics": [
        "heuristic",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The P-EDA incorporates path relinking to avoid blindness of the search and improve the convergence property. This technique, combined with a modified referenced local search designed to enhance the local exploitation, aims to guide the search process more effectively than relying solely on the probabilistic model constructed from superior individuals selected by a modified linear rank selection. The probabilistic model describes the probabilistic distribution of the promising solution space, and path relinking is used to refine solutions found within this space by exploring paths between elite solutions, thus enhancing the algorithm's ability to find optimal or near-optimal solutions for the BFSP.",
      "chunk_id": 11002,
      "paper_id": "Estimation of distribution algorithm with path relinking for the blocking flow-shop scheduling problem",
      "paper_title": "Estimation of distribution algorithm with path relinking for the blocking flow-shop scheduling problem",
      "paper_year": "2018",
      "chunk_content": "Zhongshi Shao ${ }^{\\mathrm{a}}$, Dechang $\\mathrm{Pi}^{\\mathrm{a}, \\mathrm{b}}$ and Weishi Shao ${ }^{\\mathrm{a}}$${ }^{a}$ College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, PR China; FORMULA_4 Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, PR China\nThis article presents an effective estimation of distribution algorithm, named P-EDA, to solve the blocking flow-shop scheduling problem (BFSP) with the makespan criterion. In the P-EDA, a Nawaz-Enscore-Ham (NEH)based heuristic and the random method are combined to generate the initial population. Based on several superior individuals provided by a modified linear rank selection, a probabilistic model is constructed to describe the probabilistic distribution of the promising solution space. The path relinking technique is incorporated into EDA to avoid blindness of the search and improve the convergence property. A modified referenced local search is designed to enhance the local exploitation. Moreover, a diversitymaintaining scheme is introduced into EDA to avoid deterioration of the population. Finally, the parameters of the proposed P-EDA are calibrated using a design of experiments approach. Simulation results and comparisons with some well-performing algorithms demonstrate the effectiveness of the P-EDA for solving BFSP.\nReceived 15 November 2016 Accepted 22 June 2017\nFlow-shop scheduling with blocking; estimation of distribution algorithm; path relinking; makespan",
      "question_type": "algorithmic",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:33",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the EDA when generating naive Bayes classifiers, given the confidence intervals for conditional and class probabilities?",
      "topics": [
        "heuristic"
      ],
      "answer": "After estimating the confidence intervals, the EDA generates multiple naive Bayes classifiers by selecting parameter values for each classifier *within* their corresponding confidence intervals. Each naive Bayes classifier is represented by a tuple of dimension $r_{0}(1 + \\sum_{i=1}^{n} r_{i})$, where $r_0$ is the number of class values and $r_i$ represents the possible values of variable $X_k$. The selected values $p^{*}$ must satisfy the constraints $\\sum_{i=1}^{r_{0}} p_{i}^{*}=1$ and $\\forall k \\forall i \\sum_{r=1}^{r_{k}} p_{k, r}^{* i}=1$ to ensure a valid naive Bayes classifier. Each generated individual is then evaluated using a fitness function based on the percentage of successful predictions on the dataset.",
      "chunk_id": 13209,
      "paper_id": "Learning semi naive Bayes structures by estimation of distribution algorithms",
      "paper_title": "Learning semi naive Bayes structures by estimation of distribution algorithms",
      "paper_year": "2003",
      "chunk_content": "Given the dataset, the first step is to calculate the confidence intervals for each conditional probability and for each class probability. For the calculation of the intervals first the point estimations of these parameters must be computed.\nThis way, each conditional probability $p_{k, r}^{i}=P\\left(X_{k}=x_{k}^{r} \\mid C=c_{i}\\right)$, that has to be estimated from the dataset must be computed with the next confidence interval.  \nFor $k=1, \\ldots, n ; i=1, \\ldots, r_{0} ; r=1, \\ldots, r_{k}$ the next formula:  \n$$\n\\left(\\hat{p}_{k, r}^{i}-z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{k, r}^{i}\\left(1-\\hat{p}_{k, r}^{i}\\right)}{N_{i}}} ; \\hat{p}_{k, r}^{i}+z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{k, r}^{i}\\left(1-\\hat{p}_{k, r}^{i}\\right)}{N_{i}}}\\right)\n$$  \ndenotes the interval estimation for the conditional probabilities $p_{k, r}^{i}$, where, $r_{k}$ denotes the possible values of variable $X_{k}$ $r_{0}$ represents the possible values of the class\n$\\hat{p}_{k, r}^{i}$ denotes the point estimation of the conditional probability $P\\left(X_{k}=x_{k}^{r} \\mid C=c_{i}\\right)$ $z_{\\alpha}$ denotes the $\\left(1-\\frac{\\alpha}{2}\\right)$ percentil in the $\\mathcal{N}(0,1)$ distribution\n$N_{i}$ is the number of cases in dataset where $C=c_{i}$\nAlso, in a similar way, the probabilities for the class values $p_{i}=P\\left(C=c_{i}\\right)$, are estimated with the next confidence interval,  \n$$\n\\left(\\hat{p}_{i}-z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{i}\\left(1-\\hat{p}_{i}\\right)}{N}} ; \\hat{p}_{i}+z_{\\alpha} \\sqrt{\\frac{\\hat{p}_{i}\\left(1-\\hat{p}_{i}\\right)}{N}}\\right)\n$$  \nwhere, $\\hat{p}_{i}^{i}$ is the point estimation of the probability $P\\left(C=c_{i}\\right)$\n$z_{\\alpha}$ is the $\\left(1-\\frac{\\alpha}{2}\\right)$ percentil in the $\\mathcal{N}(0,1)$ distribution\n$N$ is the number of cases in dataset\nOnce the confidence intervals are estimated from the dataset, it is possible to generate as many naive Bayes classifiers as needed. The parameters of these naive Bayes classifiers must only be taken inside theirs corresponding confidence intervals.\nIn this way, each naive Bayes classifier is going to be represented with the next tupla of dimension $r_{0}\\left(1+\\sum_{i=1}^{n} r_{i}\\right)$  \n$$\n\\left(p_{1}^{*}, \\ldots, p_{r_{0}}^{*}, p_{1,1}^{* 1}, \\ldots, p_{1,1}^{* r_{0}}, \\ldots, p_{1, r_{1}}^{* r_{0}}, \\ldots, p_{n, r_{n}}^{* r_{0}}\\right)\n$$  \nwhere each component in the tupla $p^{*}$ represents the selected value inside its corresponding confidence interval.  \nThus, the search space for the heuristic optimization algorithm is composed of all the valid tuplas. A tupla is valid when it represents a valid naive Bayes classifier. Formally,  \n$$\n\\sum_{i=1}^{r_{0}} p_{i}^{*}=1 ; \\forall k \\forall i \\sum_{r=1}^{r_{k}} p_{k, r}^{* i}=1\n$$  \nFinally, each generated individual must be evaluated with a fitness function. This fitness function is based on the percentage of successful predictions on each dataset, which means that we are carrying out one wrapper approach.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:35",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the UMDA, what information is propagated across generations when using a permutation vector representation versus an inversion vector representation, and how does this difference potentially affect the algorithm's performance on problems like PFSP and QAP?",
      "topics": [
        "mutation"
      ],
      "answer": "When UMDA uses a permutation vector representation, the first-order marginal, specifically the probability of items appearing at each position of the solution $\\sigma$, denoted as $p(\\sigma(i)=j)$, is propagated across generations. Conversely, when using the inversion vector representation $I$, the number of items smaller than $\\sigma(i)$ that lie to the right of position $i$ are counted, and a certain information represented by FORMULA_182 is propagated. The text suggests that this difference in propagated information may explain why the inversion vector allows UMDA to obtain better results for the PFSP, while the permutation codification is preferred for the QAP, because converting a permutation to its corresponding inversion vector changes the explicit information that the model receives.",
      "chunk_id": 9940,
      "paper_id": "Alternative Representations for Codifying Solutions in Permutation-Based Problems",
      "paper_title": "Alternative Representations for Codifying Solutions in Permutation-Based Problems",
      "paper_year": "2020",
      "chunk_content": "Previous experiments demonstrated the influence of the representation used to codify the solutions when optimizing the problem. On one hand, we observed that in the case of the PFSP, the inversion vector allows the UMDA to obtain better results. On the other hand, contrarily to the PFSP, in the QAP the usual permutation codification turned out to be clearly preferred. Based on these results, it is obvious that when converting a permutation to its corresponding inversion vector, the explicit information that the model receives changes, and this affects the performance of the algorithm. Some times this effect is beneficial (such as in PFSP), and other times it is negative (like for QAP).  \nAn interesting point is that the distribution over permutations learnt and sampled by UMDA under the different representations differs drastically. Under the permutation vector representation, the information that is propagated across generations is the first order marginal, i.e., the probability of the items to appear at each position of the solution $\\sigma$, $p(\\sigma(i)=j)$. Conversely, when using the inversion vector representation $I$, for each position $i$, the number of items  \nsmaller than $\\sigma(i)$ that lie to the right of position $i$ are counted, and FORMULA_182 is propagated.  \nNevertheless, beyond the propagated information for each representation, the reason for the variations observed in the results is not clear. Moreover, the influence of each type of representation for each problem is a pending task. Ultimately, the relevant questions is: which is the best representation to codify my solutions?  \nThis paper aims at throwing light in a wide research line that analyze the characteristics of the solutions that have to be taken into account so that a standard algorithm (local search, probabilistic evolutionary algorithms, ...) successes at optimizing a particular problem. For example, in an EA the best solutions are selected and the next generation is supposed to keep the characteristics that made the solutions well adapted. In this way, the question is which are the characteristics of the solutions that the EA should preserve in order to improve the current solution?  \nIn this paper, the inversion vector was used, however, there exist other types of representation that could be also used under the same setting. One of them is the codification of permutations used in the Repeated Insertion Model (RIM) [12].  \nThe representations introduced previously are bijective, which means that for each permutation there is a unique transformation, and this holds also in the opposite direction. Nevertheless, there are transformations that are not necessarily bijective and could be used in the context presented in this paper. Other possible representations are the decomposition vectors of the Cayley [15] and Hamming [16] distances in the permutations space. The first one is related to the cycle structure of permutations and the second one with the fixed points of the permutation.  \nIn the case of the Cayley and Hamming transformations, unlike with Inversion vectors or RIM, there are multiple permutations that can generate the same decomposition vectors (the transformations are not bijective). Then, using such transformations may introduce large redundancies in the codification that usually provoke a poor performance of the algorithm.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:37",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What performance trade-offs are observed between HEDA1, using repair operator RO1, and HEDA2, using repair operator RO2, considering the percentage deviations from best-known solutions and the scale of the multidimensional knapsack problem?",
      "topics": [
        "initialization"
      ],
      "answer": "HEDA1, employing repair operator RO1, achieves lower minimum and average percentage deviations (Min.Dev and Ave.Dev) from best-known solutions on the first 8 problems of test set 2 compared to HEDA2, which uses RO2. However, RO1's dependence on solving the LP relaxation problem limits its applicability to problems with a smaller number of variables (m+n). Consequently, HEDA2 can solve problems with larger scales that HEDA1 cannot, demonstrating a trade-off between solution quality and the scale of problems solvable by each approach. The statistical results regarding deviations are summarized in Table 4.",
      "chunk_id": 5344,
      "paper_id": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_title": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_year": "2012",
      "chunk_content": "The proposed HEDA contains several key parameters: the population size of each generation $(P)$, the number of selected individual to update the probability model $(N)$, the learning speed $(\\alpha)$ and the bias level of initialization $(\\beta)$. To investigate the influence of those parameters on the performance of the algorithm, we implement the Taguchi method of design of experiment (DOE) (Montgomery, 2005) by using the problem 100.10.05. Combinations of different values of these parameters are shown in Table 1.  \nFor each parameter combination, the HEDA is run 50 times independently with the maximum number 10,000 of the constructed solutions as the stopping criterion. The average response variable (ARV) value is the average of profit obtained by the HEDA in 50 times. According to the number of parameters and the number of factor levels, we choose the orthogonal array $L_{10}\\left(4^{4}\\right)$. That is, the total number of treatment is 16 , the number of parameters is 4 , and the number of factor levels is 4 . The orthogonal array and the obtained ARV values are listed in Table 2.  \nTable 1\nCombinations of parameter values.\nTable 2\nOrthogonal array and ARV values.\n[IMAGE2]  \nFig. 6. Factor level trend of the HEDA.  \nTable 3\nResponse value.  \nAccording to the orthogonal table, we illustrate the trend of each factor level in Fig. 6. Then, we figure out the response value of each parameter to analyze the significance rank of each parameter. The results are listed in Table 3.  \nFrom Table 3 it can be seen that $P$ is the most significant parameter among the four parameters. In condition of a fixed maximum number of constructed solutions, small population size allows more generations so that it may provide deeper search. In addition, the significant rank of $\\beta$ is the second and the performance of the HEDA is better when $\\beta$ is more than zero, which demonstrates that the new initialization mechanism of the probability model is efficient. A better choose of the parameter combination is: $P=20$, $N=6, \\alpha=0.01$, and $\\beta=0.1$.\nNext, we study the influence of the repair operator in the HEDA. Denote HEDA1 as the HEDA with RO1 and HEDA2 as the HEDA\nwith RO2. We run both HEDA1 and HEDA2 20 times independently by using test set 2 . Since test set 2 has medium or large scale, we set $P=200, N=10, \\alpha=0.01, \\beta=0.1$, and set the maximum number 100,000 of the constructed solutions as the stopping criterion.  \nThe statistical results are summarized in Table 4, where Min.Dev and Ave.Dev represent the minimum and average percentage deviations from the best-known solutions, and Var. Dev denotes the variance of the deviations.  \nFrom Table 4, it can be seen that the performance of HEDA1 is better than that of HEDA2 on the first 8 problems. However, since RO1 depends on solving the LP relaxation problem of the MKP, it is very difficult to solve the problem with LP when the number of $m+n$ is very large. So, HEDA2 can solve another 3 problems with larger scale while HEDA1 cannot solve those problems. The conclusion is that the repair operator is important to improve the performance of the algorithm. Comparing RO2, RO1 is superior to achieve better results but it can only applied to the problems with small or medium size.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:39",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the kernel density estimation (KDE) within an Estimation of Distribution Algorithm (EDA) using the provided formulas, what programming steps are necessary to estimate the probability density function (PDF) denoted as $\\hat{p}(x')$?",
      "topics": [
        "optimization"
      ],
      "answer": "To implement the KDE, a developer should first calculate the scaled samples $x'_i = \\tau x_i$, where $\\tau = \\tilde{\\Delta} / \\Delta_{\\min}$. Then, for each point $x'$ where the PDF needs to be estimated, compute $\\hat{p}(x')$ using the formula $\\hat{p}(x^{\\prime})=\\frac{1}{n} \\sum_{i=1}^{n} K(x^{\\prime}-x_{i}^{\\prime})$, where $K$ is the kernel function. Specifically, using the uniform kernel $K_{\\hat{A}}(x)$, the implementation involves checking if $x^{\\prime}$ falls within the interval $[x_{i}^{\\prime} - \\hat{A}/2, x_{i}^{\\prime} + \\hat{A}/2]$. If it does, the contribution to the sum is $1/\\hat{A}$; otherwise, it is 0. Finally, sum these contributions and divide by $n$ to obtain the estimated PDF value at $x'$.",
      "chunk_id": 11566,
      "paper_id": "Δ-Entropy: Definition",
      "paper_title": "Δ-Entropy: Definition, properties and applications in system identification with quantized data",
      "paper_year": "2011",
      "chunk_content": "Assume $\\left\\{x_{1}, x_{2}, \\ldots, x_{n}\\right\\}$ are samples from a discrete random variable $X$, we rewrite the plug-in estimate (26) as  \n$$\nH_{\\Delta}(\\widetilde{\\boldsymbol{S}}, \\widetilde{\\boldsymbol{P}})=-\\sum_{i=1}^{M} \\tilde{p}_{i} \\log \\tilde{p}_{i}+\\log \\tilde{\\Delta}\n$$  \nwhere $\\tilde{\\Delta}=\\sum_{i=1}^{M-1}\\left|\\tilde{s}_{i-1}-\\tilde{s}_{i}\\right| \\frac{\\tilde{p}_{i}+\\tilde{p}_{i-1}}{2}+\\frac{\\left\\|s_{M}-\\tilde{s}_{1}\\right\\|}{M-1} \\frac{\\tilde{p}_{1}+\\tilde{p}_{M}}{2}$.\nDenote $\\Delta_{\\min }=\\min _{i=1, \\ldots, M-1}\\left|\\tilde{s}_{i-1}-\\tilde{s}_{i}\\right|$, and let $\\tau=\\tilde{\\Delta} / \\Delta_{\\min }$, we construct another set of samples:  \n$$\n\\left\\{x_{1}^{\\prime}, x_{2}^{\\prime}, \\ldots, x_{n}^{\\prime}\\right\\}=\\left\\{\\tau x_{1}, \\tau x_{2}, \\ldots, \\tau x_{n}\\right\\}\n$$  \nwhich can be regarded as the samples from discrete random variable $\\tau X$. It follows easily that  \n$$\n\\nabla x_{i}^{\\prime} \\neq x_{j}^{\\prime}, \\quad\\left|x_{i}^{\\prime}-x_{j}^{\\prime}\\right| \\geqslant \\tilde{\\Delta}\n$$  \nWe now consider $\\left\\{x_{1}^{\\prime}, x_{2}^{\\prime}, \\ldots, x_{n}^{\\prime}\\right\\}$ as samples from a \"continuous\" random variable $X^{\\prime}$. The PDF of $X^{\\prime}$ can be estimated by the kernel approach [5]  \n$$\n\\hat{p}\\left(x^{\\prime}\\right)=\\frac{1}{n} \\sum_{i=1}^{n} K\\left(x^{\\prime}-x_{i}^{\\prime}\\right)\n$$  \nThe kernel function $K: \\mathbb{R} \\rightarrow[0, \\infty)$ satisfies $K \\geqslant 0$ and $\\int_{-\\infty}^{\\infty} K(x) d x=1$. Here we use the following uniform kernel:  \n$$\nK_{\\hat{A}}(x)= \\begin{cases}1 / \\hat{A}, & x \\in[-\\hat{A} / 2, \\hat{A} / 2] \\\\ 0 & \\text { otherwise }\\end{cases}\n$$  \nThen the kernel density estimation (KDE) of (39) becomes  \n$$\n\\hat{p}\\left(x^{\\prime}\\right)=\\frac{1}{n} \\sum_{j=1}^{n} K_{\\hat{A}}\\left(x^{\\prime}-x_{j}^{\\prime}\\right)=\\frac{1}{n} \\sum_{i=1}^{M} n_{i} K_{\\hat{A}}\\left(x^{\\prime}-x_{i}^{\\prime}\\right) \\stackrel{( \\circ ) { ( } { ) } { \\pm } \\stackrel{p_{i}}{\\rightarrow}, x^{\\prime} \\in\\left[x_{i}^{\\prime}-\\hat{A} / 2, x_{i}^{\\prime}+\\hat{A} / 2\\right]$\nwhere (a) follows from $\\hat{p}_{i}=n_{i} / n$, and $\\forall x_{i}^{\\prime} \\neq x_{j}^{\\prime},\\left|x_{i}^{\\prime}-x_{j}^{\\prime}\\right| \\geqslant \\hat{A}$. The differential entropy of $X^{\\prime}$ can be estimated by the plug-in approach:\n\n$$\n\\begin{aligned}\n\\hat{h}\\left(X^{\\prime}\\right) & =-\\int{-\\infty}^{\\infty} \\hat{p}\\left(x^{\\prime}\\right) \\log \\hat{p}\\left(x^{\\prime}\\right) d x^{\\prime}=-\\sum{i=1}^{M} \\int{x{i}^{\\prime}-\\hat{A} / 2}^{x{i}^{\\prime}+\\hat{A} / 2} \\hat{p}\\left(x^{\\prime}\\right) \\log \\hat{p}\\left(x^{\\prime}\\right) d x^{\\prime}=-\\sum{i=1}^{M} \\int{x{i}^{\\prime}-\\hat{A} / 2}^{x{i}^{\\prime}+\\hat{A} / 2} \\frac{p{i}}{\\hat{A}} \\log \\frac{p{i}}{\\hat{A}} d x^{\\prime} \\\\\n& =-\\sum{i=1}^{M} p{i} \\log p{i}+\\log \\hat{A}=H{\\hat{A}}(\\widehat{\\mathbf{S}}, \\widehat{\\boldsymbol{P}})\n\\end{aligned}\n$$\n\nAs a result, the plug-in estimate of the $\\Delta$-entropy equals a uniform kernel based estimate for the differential entropy from the scaled samples (37).\n\n# 4.2. Relation to differential entropy estimate based on sample-spacing \n\nIt is also interesting to note that the plug-in estimate of the $\\Delta$-entropy has a close connection with the sample-spacing estimate $[23,34]$ of differential entropy. Suppose the sample data are different from each other, and have been rearranged in an increasing order: $\\left\\{x_{1}<x_{2}<\\cdots<x_{n}\\right\\}$, the $m$-spacing estimate is given by [23]\n\n$$\n\\hat{h}{m}(X)=\\frac{1}{n} \\sum{i=1}^{n-m} \\log \\left(\\frac{n}{m}\\left(x{i+m}-x{i}\\right)\\right)\n$$\n\nwhere $m \\in \\mathbb{N}$, and $m<n$. Let $m=1$, we obtain the 1 -spacing estimate:\n\n$$\n\\hat{h}{1}(X)=\\frac{1}{n} \\sum{i=1}^{n-1} \\log \\left(n\\left(x{i+1}-x{i}\\right)\\right)\n$$\n\nIn general, regarding $\\left\\{x_{1}, x_{2}, \\ldots, x_{n}\\right\\}$ as samples from a discrete distribution, we estimate the value set and probabilities as\n\n$$\n\\left\\{\\begin{array}{l}\n\\widehat{\\mathbf{S}}=\\left(x{1}, x{2}, \\ldots, x{n}\\right) \\\\\n\\widehat{\\boldsymbol{P}}=(1 / n, 1 / n, \\ldots, 1 / n)\n\\end{array}\\right.\n$$\n\nThen the plug-in estimate of $\\Delta$-entropy can be calculated as\n\n$$",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:42",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output be measured using the criteria of variable linkage when employing a histogram model?",
      "topics": [
        "optimization"
      ],
      "answer": "When using a histogram model in EDAs, variable linkage can be addressed through two primary approaches: probabilistic graphical models (PGM) and space transformation. PGM considers Markov properties to avoid estimating complete probabilities, while space transformation aims to cancel out dominant linkages through transformations in the original space. The accuracy and computational complexity differ, with PGM generally being more accurate but computationally expensive, and transformation offering the opposite trade-off.",
      "chunk_id": 5996,
      "paper_id": "Linkages Detection in Histogram-Based Estimation of Distribution Algorithm",
      "paper_title": "Linkages Detection in Histogram-Based Estimation of Distribution Algorithm",
      "paper_year": "2008",
      "chunk_content": "Estimation of distribution algorithms (EDAs) are a class of evolutionary algorithms that use probabilistic model of promising solutions found so far to obtain new candidate solutions of optimized problems. One of the charming characteristics of this evolutionary paradigm is that the joint probability density can explicitly represent correlation among variables [1,16]. It is verified by several researchers [2] that multivari-ate-dependency EDAs have the potential ability to optimize hard problems with strong nonlinearity. However, it is also noted that how to efficiently learn the complex probabilistic model is a bottleneck problem. Therefore, obtaining a good balance between the complication of probabilistic models and the efficiency of learning method is a key factor for designing new EDAs.  \nIn continuous domain, the predominant probabilistic model applied by EDAs is based on Gaussian probability distribution. Continuous EDAs based on multivariate Gaussian distribution have polynomial computational complexity. However, the inherent shortcoming of Gaussian-based EDA is that the unimodal model is too rough and thus is likely to mislead the search to a local optimum when solving complex optimization problems. Although clustering techniques such as Gaussian mixture model, Gaussian kernel model are considered to conquer this shortcoming in the literature, their complicated probabilistic distributions make it more difficult to estimate the linkage information, and thus the computational complexity increases remarkably.  \nHistogram model is another alternative probabilistic model in the continuous EDA. It is also called a kind of discretization of the continuous problem. In comparison with  \nunimodal Gaussian model, histogram probabilistic model is able to represent multiple local optima by bins of different heights. Histogram model has already been used in previous work [3-11,13,14]. For example, marginal histogram models are applied in the FWH [7] by S. Tsutsui et al. and the histogram-based EDA (HEDA) [8,9] by N. Ding et al. B. Yuan et al. [11] also proposed the HEDA as an extension of the PBIL [12]. Q. Zhang et al. introduce EDA/L [14] in which several local search strategies are employed in a marginal histogram model.  \nIn those above algorithms, the complete probability is approximated by the product of the marginal probability of each variable, that is to say, the linkages of the variables are discarded. However, as we know, when optimizing problems with bounded epistasis, the linkage information should be given prior consideration in the process of the evolutionary algorithms. The IDEA [4,5] based on histogram model (IDEA-H) by P.A.N. Bosman et al. used the multivariate histogram model to consider the variable linkage, but they also remarked that the complexity of the IDEA-H grows exponentially when expressing joint probability of multiple random variables.  \nThe aim of the chapter is to conquer the linkage problem of HEDA from two aspects: one is based on probabilistic graphical models (PGM), where the multivariate histogram model is considered; and the other is based on space transformation, where the marginal distribution is built in the transformed space. PGM takes the Markov properties into account, where the variable is independent of each other when given its neighbors in the graphical models, thus it avoids estimating the complete probability. Space transformation works under the assumption that a decent transformation from the original space may cancel out some of the dominant linkages among the variables. The two methods deal with the variables linkages of the optimization problem with different accuracy and with different computational complexity. Probabilistic graphical model is generally more accurate but always associated to high-cost, while transformation is the opposite.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:43",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when comparing the Histogram-based Estimation of Distribution Algorithm (HEDA) with other continuous evolutionary algorithms, and how is this objective evaluated?",
      "topics": [
        "genetic"
      ],
      "answer": "The primary objective is to demonstrate that HEDA is a superior optimization method based on a histogram probability model compared to FWH, another histogram-based EDA, and to establish that HEDA holds an outstanding position among various continuous evolutionary algorithms like UMDA-Gaussian, SGA, and CMA-ES for solving continuous test functions. This is evaluated using convergence property, measured by the number of runs to find the global optimum within a tolerance \\$\\pm \\varepsilon\\$ of 0.1 and the mean number of function evaluations (MNE), and scalability, assessed by observing the algorithm's behavior as the problem dimension increases in the two-peak problem.",
      "chunk_id": 6243,
      "paper_id": "Optimizing Continuous Problems Using Estimation of Distribution Algorithm Based on Histogram Model",
      "paper_title": "Optimizing continuous problems using estimation of distribution algorithm based on histogram model",
      "paper_year": "2006",
      "chunk_content": "Several well-known continuous test functions, which include the 20 -variable twopeak function, the 20 -variable Rastrigin function, the 10 -variable Griewank function and the 5 -variable Schfewel function, are used to verify the performance of HEDA. Table 1 lists these experimental functions and their respective optimal solutions.  \nTable 1. Test functions  \nIn the experiments, the proposed HEDA has been compared with several wellknown continuous evolutionary algorithms including FWH, UMDA-Gaussian, SGA and CMA-ES. FWH is the original proposed continuous EDA based on histogram probability model [5]. The objective of comparison with FWH is to show that HEDA is a superior optimization method based on histogram model. UMDA-Gaussian is an EDA based on Gaussian probability model [7]; SGA refers to simple genetic algorithm; CMA-ES is an advanced evolution strategy with covariance matrix adaptation [11]. The objective of the comparison with UMDA-Gaussian, SGA and CMA-ES is to show that, among many kinds of continuous evolutionary algorithms, HEDA hold an outstanding position in solving the above test functions.  \nTo evaluate the performance of HEDA, two criteria are used: convergence property and scalability. The convergence property is to measure the ability of the algorithm to reach the global optimum. In our experiments, we evaluate the convergence property by measuring the number of runs in which algorithm succeeds in finding the global optimum and the mean number of function evaluations (MNE) to find the global optimum in those successful runs. We define the successful detection of the solution as being within $\\pm \\varepsilon$ of the actual optimum point $(\\varepsilon=0.1)$. The scalability of HEDA in solving two-peak problem is used to see how the behavior of algorithms changes when the dimension of the problem increases.  \nAll the algorithms run 20 independent times on each problem. The termination condition for the 5 algorithms is detection of optimal solution or maximum 100,000 function evaluations. In all the algorithms, the initial population is generated uniformly. The parameter settings HEDA, FWH, SGA, UMDA-Gaussian and CMA-ES are as follows.  \nHEDA: the width of bin is set 0.1 , mutation rate is set 0.05 , and accumulation rate $0.2 .50 \\%$ of population is selected for model updating. Elitist strategy is used.  \nFWH: we directly use the results obtained by FWH published in [5].\nSGA: crossover probability 0.8 and mutation probability 0.05 . Selection method is tournament selection. Elitist strategy is used.  \nUMDA-Gaussian: the Gaussian probability model is updated using method introduced in [9]. 50\\% of parent population is selected for model updating. Elitist strategy is used.  \nCMA-ES: $\\mu=\\lambda / 4$, where is $\\lambda$ is the size of parent population and $\\mu$ is the number of descendants. The Matlab code of CMA-ES in [13] is used in the experiments.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:45",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of generating new samples $(x, y)$ of random variables $(X, Y)$ using a copula $C$ rely on the pseudo-inverse of a distribution function?",
      "topics": [
        "optimization"
      ],
      "answer": "The algorithm generates new samples $(x, y)$ of random variables $(X, Y)$ by first generating a pair of observations $(u, v)$ of random variables $(U, V)$ and computing the copula $C$. Then, it transforms $(u, v)$ to $(x, y)$ using the inverse transformation method. Specifically, $x$ is computed as $F_{X}^{[-1]}(u)$ and $y$ is computed as $F_{Y}^{[-1]}(v)$, where $F_{X}^{[-1]}$ and $F_{Y}^{[-1]}$ represent the pseudo-inverses of the marginal distribution functions $F_{X}$ and $F_{Y}$ respectively. The pseudo-inverse $F^{[-1]}(t)$ is defined as $\\inf \\{x: F(x) \\geq t\\} = \\sup \\{x: F(x) \\leq t\\}$ for $t$ in the interval $\\mathbb{I}$. The pair $(u, v)$ is generated by sampling independent random variables $u$ and $t$ uniformly in $\\mathbb{I}$ and defining $v = C^{[-1]}(t)$.",
      "chunk_id": 1608,
      "paper_id": "Vine copula-based EDA for dynamic multiobjective optimization",
      "paper_title": "Vine copula-based EDA for dynamic multiobjective optimization",
      "paper_year": "2022",
      "chunk_content": "Copulas have a direct application in the simulation of the dependent variables. We present the general procedure to simulate bi-variate dependents variables. First, we start by a short description of what is a pseudo-inverse of a distribution function.\n[IMAGE1]  \nDefinition 4 Let $F$ be a univariate distribution function. A pseudo-inverse of $F$ is function [19] $F^{[-1]}: \\mathbb{I} \\rightarrow \\mathbb{R}$ such that for $t \\in \\mathbb{I}$ :\n$F^{[-1]}(t)=\\inf \\{x: F(x) \\geq t\\}=\\sup \\{x: F(x) \\leq t\\}$\nA general algorithm to generate new samples $(x, y)$ of a pair of random variables $(X, Y)$ with the marginals $F_{X}, F_{Y}$, joint distribution $F_{X Y}$, and a copula $C$ is defined as follows. Initially, we generate a pair of observations $(u, v)$ of random variables $(U, V)$ and compute the copula $C$. Then, using the inverse transformation method, we transform $(u, v)$ to $(x, y)$ using :\n$x=F_{X}^{[-1]}(u)$\n$y=F_{Y}^{[-1]}(v)$\nTo generate the pair $(u, v)$ we perform the following steps:  \n- Sample from independent random variables $u, t$ uniformly in $\\mathbb{I}$.\n- Define $v=C^{[-1]}(t)$.  \nThe generate pair is then FORMULA_99.",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:47",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within the MAPS framework, what are the key differences in the covariance matrix estimation step (step 3 of PROCESSING) when using UMDA\n  $_{c}$, EMNA$_{g}$, and EEDA, respectively?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "covariance matrix estimation",
        "UMDA",
        "EMNA",
        "EEDA",
        "MAPS"
      ],
      "answer": "When implementing MAPS with different single Gaussian model-based EDAs, the covariance matrix estimation differs as follows: UMDA$_{c}$ assumes variable independence and estimates the covariance matrix by separately estimating the standard deviations of each dimension. EMNA$_{g}$ estimates the covariance matrix using Maximum Likelihood Estimation (MLE). EEDA fine-tunes the minimal eigenvalue of the covariance matrix to the maximal eigenvalue, providing an approximation to the negative gradient of the fitness function.",
      "chunk_id": 4667,
      "paper_id": "Improving Estimation of Distribution Algorithm on Multimodal Problems by Detecting Promising Areas",
      "paper_title": "Improving Estimation of Distribution Algorithm on Multimodal Problems by Detecting Promising Areas",
      "paper_year": "2015",
      "chunk_content": "In order to show the effectiveness of the multiple sub-models maintenance technique of MAPS, some multiple sub-models based EDAs should be necessarily included in the compared algorithms. For this purpose, three related work  \nTABLE I\nEXPERIMENTAL SETTINGS FOR ALL THE TEST AlGORITHMS  \nintroduced in Section II, e.g., CEGDA [15], NichingEDA [16], and IslandEDA [22], are chosen. Moreover, in the view of the ability of problem-solving, comparisons between MAPS and those canonical EAs are also required. In [34]-[37], quite a few EAs-based methods have been suggested to deal with multimodal problems. However, most of them focus on finding multiple local optima simultaneously, which unfits our goal. Apart from that, there are still some state-of-the-art approaches that can be adopted to search for the global optimum on multimodal problems [38]-[41]. In this experiment, modified DE (MDE) with p-best crossover (MDE $p$ BX) [42], a recently proposed differential evolution (DE), has also been employed as a compared algorithm. In MDE $p$ BX, a new mutation operator, called DE/current-to-grbest/1, is suggested. It uses the best of a group of randomly selected solutions from the current population to perturb the parent vector. Besides, a novel scheme of adapting two of its vital parameters is also proposed to improve its performance. Empirical studies have shown that $\\mathrm{MDE}_{-} p \\mathrm{BX}$ can statistically outperform some well-known DE variants on a wide variety of tested problems.  \nFor MAPS, since it is independent from the employed single Gaussian model-based EDA, it is comprehensive to test how MAPS performs when employing different single Gaussian model-based EDAs. Thus, MAPS employing UMDA ${ }_{c}$ [1], denoted as MAPS $_{\\text {UMDA }}$, the MAPS employing EMNA $_{g}$ [1], denoted as MAPS $_{\\text {EMNA }}$, and the MAPS employing EEDA [2], [10], denoted as MAPS $_{\\text {EEDA }}$ are also included in the experiment. The reason for choosing these three EDAs is that they are all typical single Gaussian model-based EDAs and are widely used to evolve sub-models [16], [22]. Thus, it is easy to compare and analyse the different behaviors between the compared EDAs based algorithms. For these three MAPS based EDAs, the only difference during the implementation process happens in the step 3) of the PROCESSING. Considering they all estimate the mean vector by MLE, the differences among them exist when estimating covariance matrix. Detailedly, UMDA ${ }_{c}$ assumes variables are independent, and it  \nTABLE II\nBrief Information About Test Functions  \nthus estimates a covariance matrix by separately estimating the standard deviations of each dimension. In contrast, EMNA $_{g}$ is a classic multivariate Gaussian model-based EDA, and it estimates covariance matrix by MLE. EEDA is a variant of EMNA $_{g}$ that fine-tunes the minimal eigenvalue of the covariance matrix to the maximal one, after which it has an approximation to the negative gradient of the fitness function.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:49",
      "generation_style": "practical_application"
    },
    {
      "question": "In the EDAhybrid algorithm described, how is the probability value, denoted as $P_{S S}$, of assigning a facility calculated, and what is the significance of modifying the original formula by adding $\\phi_{S S}$ and $\\psi_{i j}$ instead of multiplying them?",
      "topics": [
        "mutation"
      ],
      "answer": "In EDAhybrid, the probability value $P_{S S}$ of assigning a facility is calculated using the formula $P_{S S}=\\frac{\\phi_{S S}+\\psi_{i j}}{\\sum_{o, \\Omega}\\left(\\phi_{S S}+\\psi_{i j}\\right)}$, where $\\phi_{S S}$ represents the statistical information from one probabilistic model, $\\psi_{i j}$ represents statistical information from another probabilistic model, and $\\Omega$ is the set of unassigned facilities. The modification from multiplying $\\phi_{i j l j}$ and $\\psi_{i j}$ to adding them is stated to yield better results when tested within the EDAhybrid framework. The numerator sums these two values, and the denominator sums these values over all unassigned facilities $o$ within the set $\\Omega$.",
      "chunk_id": 278,
      "paper_id": "Hybrid Estimation of Distribution Algorithm for solving Single Row Facility Layout Problem",
      "paper_title": "Hybrid Estimation of Distribution Algorithm for solving Single Row Facility Layout Problem",
      "paper_year": "2013",
      "chunk_content": "```  \nFig. 2. EDAhybrid pseudocode.  \nLet $P_{i j l j}$ be the probability value of assigning facility $i$ at position [i]. Selecting facility $i$ has better probability value than other facilities when both probabilistic models' statistical information is used, $\\phi_{i j l j}$ is added by $\\psi_{i j}$. They will summarize the probability values of all unassigned facilities that could be set at position [i].  \nFor every particles' offspring $O^{1}, O^{2}, \\ldots$, and $O^{N}$, some methods are used to assign facilities to a specified location. Selecting a facility at the first location, our approach picks randomly the first facility that appears in the group of selected $C$ particles, that is $X[1]$. We think that this approach is more promising than the one proposed in Chen et al. (2012), which generates facility randomly.  \nFor assigning the remaining facilities, we modify the formula used in Chen et al. (2012) which multiplying $\\phi_{i j l j}$ with $\\psi_{i j}$. We change the formula to become adding $\\phi_{i j l j}$ with $\\psi_{i j}$, that is Eq. (6). The reason is because add operation, not multiplication one, gives better result when tested in EDAhybrid.\n$P_{S S}=\\frac{\\phi_{S S}+\\psi_{i j}}{\\sum_{o, \\Omega}\\left(\\phi_{S S}+\\psi_{i j}\\right)}$\nwhere $P_{i j l j}$ : the probability value of assigning facility $i$ at position [i], $[i]=2,3, \\ldots, n ; i, j=1,2, \\ldots, n, \\Omega=$ set of unassigned facilities. The pseudocode shown in Fig. 3 demonstrates the assignment procedure for placing facilities into location 2 until $n$. This pseudocode is a modified version from the one presented in Chen et al. (2012).\nPSO procedure starts when current generation is odd and begins with initialization of all related parameters. Next, the velocities\ncalculation of every particle is operated. If the velocity is larger, the particle is more likely to change to a new permutation sequence. The velocity update formula remains the same like provided in Haupt and Haupt (2004), while the particle update process is changed. EDAhybrid uses permutation based particle updating based on concept from Hu, Eberhart, and Shi (2003).",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:51",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What limitation is described regarding the use of local optimization algorithms for computing Innovation Estimators?",
      "topics": [
        "selection"
      ],
      "answer": "The performance of Innovation Estimators computed by local optimization algorithms strongly depends on the quality of the initial parameter values. This dependence requires significant user expertise to obtain satisfactory estimates.",
      "chunk_id": 9547,
      "paper_id": "Estimation of distribution algorithms for the computation of innovation estimators of diffusion processes",
      "paper_title": "Estimation of distribution algorithms for the computation of innovation estimators of diffusion processes",
      "paper_year": "2021",
      "chunk_content": "Diffusion processes defined through Stochastic Differential Equations (SDEs) have became an important mathematical tool for describing the dynamics of several phenomena, e.g., the dynamics of assets prices in the market, the fire of neurons, etc. In many applications, the statistical inference of diffusion processes is of great importance for model building and model selection. Typically, this inference problem consists in the estimation of unknown parameters of the diffusion process given a set of discrete observations. For systems in which all variables of the diffusion are observed without noise, a variety of approximate Maximum Likelihood, Bayesian, $M$ and $Z$ estimators for the parameters have been developed (for a review see, e.g., [19] and references therein). Contrarily, when only noisy observations of some components of the diffusion processes are accessible, just a few  \n[^0]\n[^0]:     Corresponding author.  \nE-mail addresses: zochil@ime.uerj.br (Z.G. Arenas), jcarlos@icimaf.cu (J.C. Jimenez), llozada@freepik.com (L.-V. Lozada-Chang), roberto.santana@ebu.es (R. Santana).  \nestimators are available. They are the maximum likelihood method considered in [47] for linear SDEs with additive noise and the $M$-methods: Prediction Error Recursions [50], the Prediction-Based Estimating Functions [38] and the Innovation method [40]. Among these, the Innovation Estimators stand out for the diversity and number of successful applications (see, e.g. [19,24,56] and references therein).  \nLike any FORMULA_11 estimator, the computation of the Innovation Estimators involves the minimization of an objective or fitness function, which is a non-quadratic function of the parameters in most of situations. By using a deep empirical know-how on the possible parameter values of a model for a particular application, this optimization problem has been regularly and successfully solved by means of local optimization algorithms (see, e.g., [41,44,55]). In these works, the known Gaussianity of the fitting-innovation process [22,40,41] is used to validate the results provided by the optimization algorithm. However, since the performance of the innovation estimators computed by local optimization algorithms strongly depends on the quality of the parameter's initial value, a great expertise of the users is needed to obtain satisfactory estimates.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:53",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA FORMULA_104 model, as summarized in Algorithm 3?",
      "topics": [
        "search"
      ],
      "answer": "The provided content only mentions that the general framework of the EDA with local search is summarized in Algorithm 3, but does not provide the specific steps within that algorithm.",
      "chunk_id": 12110,
      "paper_id": "Minimizing makespan in a no-wait flowshop with two batch processing machines using estimation of distribution algorithm",
      "paper_title": "Minimizing makespan in a no-wait flowshop with two batch processing machines using estimation of distribution algorithm",
      "paper_year": "2016",
      "chunk_content": "Based on the above sections, the general framework of the EDA with local search (EDA FORMULA_104 for short) is summarised in Algorithm 3.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:54",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measures are proposed to quantify the performance of the EDA compared to the greedy algorithm, and what is the significance level used for this comparison?",
      "topics": [
        "search"
      ],
      "answer": "The performance of the EDA is compared to the greedy algorithm using a Wilcoxon signed ranks test to determine if statistically significant differences exist between the results of both algorithms. A confidence level of 0.05 is used to assess statistical significance, with the result being a $p$ value.",
      "chunk_id": 12394,
      "paper_id": "User Adapted Motor-Imaginary Brain-Computer Interface by means of EEG Channel Selection Based on Estimation of Distributed Algorithms",
      "paper_title": "User Adapted Motor-Imaginary Brain-Computer Interface by means of EEG Channel Selection Based on Estimation of Distributed Algorithms",
      "paper_year": "2016",
      "chunk_content": "In Figure 5 a topographical map for each subject shows the frequency of occurrence of the channels in the 60 best solutions (one for each iteration). The low values correspond to first discarded channels and the highest to the most significant for the classification task. It can be seen that the distribution is subject-dependant, thus justifying the development of an automatic method for searching the optimal subset of channels, making the adaptation of the system to each subject automatic.\n5.1. EDA Approach. Seeing the results obtained with the greedy algorithm, we decided to carry out a sequence of experiments with the EDA, changing the top channel number limit in the interval from 16 to 1 , wider than the minimum range (from 10 to 1 ) observed with the greedy algorithm. This\nfocuses on the work of the EDA to a range where doing a more refined search could be interesting.  \nWith respect to EDA parameters, and based on preliminary experiments, the population size is 200 and the number of generations 20.  \nTo show a sample of the evolution of the EDA, Figures 6, 7 , and 8 show intermediate results for the 3 subjects using 6 channels. The figures show the evolution of fitness function. A validation value obtained for the best solution of each generation, with the testing dataset, is also shown, but these values are not used by EDA. A topographic map shows the presence of channels in 50 solutions (the best ten in the last 5 generations). The results show that, for the subject L1b, with only 6 channels the EDA is able to find a solution even better than using all the channels. For subjects K3b and K6b the found solutions are near to the 60 -channel based solution.  \n[IMAGE6]  \nFigure 7: Results obtained with EDA search algorithm with a maximum of 6 channels for subject K6b.  \nFigures 9, 10, and 11 show results obtained with EDA in the last generation with different number of channels for the 3 subjects. Values obtained with the greedy search algorithm are also shown. As it can be seen, the EDA finds a better solution for the subjects K6b and L1b than the solution based on all the channels (with only 4 channels) and finds a similar solution with 10 channels for the K3b subject.  \nIn Figure 12 channel position and frequency as a percentage, in best solutions (the best ten in the last 5 generations of 13 experiments), are shown for the tree subjects. This figure shows again the different distribution of the selected channels for the three subjects, making a specific selection of channels for each subject necessary.  \nFinally, the results obtained with the EDA have been compared with the results obtained with the greedy algorithm. We applied a Wilcoxon signed ranks test ( 0.05 confidence level) to determine if statistically significant differences are between the results of both algorithms. The test shows that the differences are statistically significant ( $p$ value FORMULA_67 ).  \nTherefore, the combination of the two algorithms in a two-step system is a good option to achieve a simpler user adapted interface maintaining or, even, improving the accuracy of the system.\n5.2. Final Discussion. Experimental results show the adequacy of the proposed approach. On the first step, a greedy approach has been used in order to show that channel number reduction is appropriate in a 60-electrode EEG-BCI model. It can be seen in the obtained results that electrode number is decreased to about ten/sixteen channels without losing accuracy for the three subjects, focusing on the search",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:08:55",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when constructing the conditional preference probability matrix (CPPM)?",
      "topics": [
        "initialization"
      ],
      "answer": "The primary purpose is to calculate the conditional preference probability matrix (CPPM) by determining the objective preference ($op_i$), selection probability ($p_i$), and preference probability ($q_i$) for each variable $x_i$ within the elite set ($ES$). This involves using equations to quantify the relationships between variables to guide the solution construction phase in the Estimation of Distribution Algorithm.",
      "chunk_id": 8600,
      "paper_id": "A Hybrid Metaheuristic of Integrating Estimation of Distribution Algorithm with Tabu Search for the Max-Mean Dispersion Problem",
      "paper_title": "A Hybrid Metaheuristic of Integrating Estimation of Distribution Algorithm with Tabu Search for the Max-Mean Dispersion Problem",
      "paper_year": "2019",
      "chunk_content": "```  \nAlgorithm 1: Main scheme of the EDA-TS algorithm.\n(1) Input: a distance matrix $D=\\left(d_{i j}\\right)_{\\text {next }}$\n(2) Output: an initial elite set $E S$\n(3) cursize $=0, E S=\\emptyset$\n(4) repeat\n(5) $x \\longleftarrow$ RandInitialSol()\n(6) $x^{c} \\longleftarrow$ TabuSearch $(x)$\n(7) if $x^{c}$ is not a duplicate of any solutions in $E S$ then\n(8) $E S=E S \\cup\\left\\{x^{c}\\right\\}$\n(9) cursize = cursize + 1\n(10) end if\n(11) until cursize $\\geqslant|E S|$  \nAlgorithm 2: Outline of the elite set initialization.\ndenote the size of $\\operatorname{SubES}_{i}, f(x)$ denote the objective function value of the solution $x$, and $f_{\\min }$ denote the minimum objective function value among all the solutions in $E S$. Then, the objective preference $o p_{i}$ of the variable $x_{i}$ is defined as  \n$$\no p_{i}=\\frac{\\sum_{x \\in \\operatorname{SubES}_{i}} f(x)-f_{\\min }}{\\left|\\operatorname{SubES}_{i}\\right|}\n$$  \nDefinition 2. Given the sets $E S$ and $\\operatorname{SubES}_{i}$, the selection probability $p_{i}$ of the variable $x_{i}$ is defined as  \n$$\np_{i}=\\frac{\\left|\\operatorname{SubES}_{i}\\right|}{|E S|}\n$$  \nDefinition 3. Given the selection probability $p_{i}$ and the objective preference $o p_{i}$, the preference probability $q_{i}$ of selecting the variable $x_{i}$ is defined as  \n$$\nq_{i}=p_{i} \\cdot o p_{i}\n$$  \nDefinition 4. Let $c o_{i j}$ denote the number of solutions in $E S$ where both variables $x_{i}$ and $x_{j}$ receive value 1 . Then, the interaction selection probability $\\operatorname{cop}_{i j}$ associated with the variables $x_{i}$ and $x_{j}$ is defined as  \n$$\n\\operatorname{cop}_{i j}=\\frac{c o_{i j}}{|E S|}\n$$  \nDefinition 5. Given the selection probability $p_{i}$ and the preference probability $q_{j}$ as well as the interaction selection probability $\\operatorname{cop}_{i j}$, the conditional preference probability $q_{j j i}$ of the variable $x_{j}$ upon having selected the variable $x_{i}$ is defined as  \n$$\nq_{j j i}=q_{j} \\cdot \\frac{\\operatorname{cop}_{i j}}{p_{i}}\n$$  \nThe procedure to calculate the CPP matrix is shown in Algorithm 3.  \nIn order to illustrate the CPP matrix construction, Table 1 gives a small instance $D=\\left(d_{i j}\\right)_{5 \\times 5}$ to show how to calculate the information stored in the memory structures.\n2.3.2. EDA Guided Solution Construction Phase. Algorithm 4 shows the outline of the EDA guided solution construction  \n(1) Input: an elite set $E S$ and the objective function value of each solution $f(x)$ in $E S$\n(2) Output: a conditional preference probability matrix $C P P M$\n(3) for $i=1$ to $n$ do\n(4) Calculate the objective preference $o p_{i}$ of the variable $x_{i}$ according to Eq. (4)\n(5) Calculate the selection probability $p_{i}$ of the variable $x_{i}$ according to Eq. (5)\n(6) Calculate the preference probability $q_{i}$ of each variable FORMULA_97 according to Eq. (6)\n(7) end for",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:08:57",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the Univariate Marginal Distribution Algorithm (UMDA) utilize the Bernoulli distribution to estimate the distribution of good solutions, and what fundamental properties distinguish this approach from using other distribution estimation methods within the broader EDA framework?",
      "topics": [
        "crossover"
      ],
      "answer": "The Univariate Marginal Distribution Algorithm (UMDA) estimates the distribution of good solutions by using binary coding and the Bernoulli distribution. This means that each variable in the candidate solutions is represented using binary coding, and the probability of each variable being 0 or 1 is modeled using a Bernoulli distribution. The UMDA estimates the parameters of these Bernoulli distributions based on the selected 'M' individuals from the previous generation. The new generation is then sampled from these estimated Bernoulli distributions. This approach is distinguished by its use of univariate marginal distributions, meaning that it models each variable independently, as opposed to considering dependencies between variables. The population size is denoted by 'N'.",
      "chunk_id": 11303,
      "paper_id": "Decentralized Estimation of Distribution Algorithms for Large Scale Networked Systems",
      "paper_title": "Decentralized Estimation of Distribution Algorithms for Large Scale Networked Systems",
      "paper_year": "2018",
      "chunk_content": "Estimation of Distribution Algorithms(EDAs) are a series of algorithms used to optimize a function by keeping track of statistics of the population of candidate solutions [9].  \nAn EDA is a kind of evolution algorithms. However, in an EDA there are neither crossover nor mutation operators. Instead, the new population of individuals is sampled from a probability distribution, which is estimated from a database containing selected individuals from the previous generation. The process repeats from one generation to the next until we get the proper solutions. The framework of an EDA is shown as follows.\n1: Initialize a population of candidate solutions, population size is $N$\n2: while not termination criterion do\n3: Compute the loss function value of each individual;\n4: Select $M$ individuals from the population based on some rules;\n5: Estimate the distribution of good solutions based on the FORMULA_32 individuals;\n6: Sample from the distribution to generate the new generation;\n7: end while\n8: Choose the solution with least loss value.\nFor some real-world problems, the loss is measured rather than calculated. What we get is a set of data and we can't use the gradient method to solve the optimization problem. An EDA doesn't need the gradient information. It can be more widely applied.  \nEDAs have different ways for estimating the distribution. Here we use the Univariate Marginal Distribution Algorithm(UMDA). It uses binary coding and Bernoulli distribution to estimate the whole distribution [9].",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:08:59",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners perform the individual replacement step in a multi-population parallel copula EDA using Clayton and Gumbel copulas, specifically addressing the roles of 'evFlag1', 'pop1g', and the output of the 'Claytonsample' procedure?",
      "topics": [
        "genetic"
      ],
      "answer": "In a multi-population parallel copula EDA, the individual replacement step is conditionally executed based on the evaluation flag 'evFlag1'. If 'evFlag1' is equal to 1, the algorithm proceeds to evolve 'pop1g' using the Clayton copula. This involves estimating the univariate marginal distribution function $F_{i}$ for each dimension from the selected subpopulation 'spop1'. Subsequently, for 'k' from 1 to 'l', where 'l' likely represents the number of new individuals to generate, the 'Claytonsample(k)' procedure is invoked to generate new individuals $\\left(x_{1}^{(k)}, x_{2}^{(k)}, \\ldots, x_{n}^{(k)}\\right)$. Finally, the old individuals of 'pop1g' are replaced with these newly generated individuals. The algorithm sets 'evFlag1' to 0 when the stopping criterion for 'pop1g' is met, halting further evolution with the Clayton copula.",
      "chunk_id": 11620,
      "paper_id": "A Multi-population Parallel Estimation of Distribution Algorithms Based on Clayton and Gumbel Copulas",
      "paper_title": "A Multi-population Parallel Estimation of Distribution Algorithms Based on Clayton and Gumbel Copulas",
      "paper_year": "2011",
      "chunk_content": "According to the framework of copula EDA [12], the copula EDA is an iterative run containing three main steps. The first step is to select a subpopulation denoted by $\\mathrm{x}=\\left\\{x^{i}=\\left(x j^{i}, x z^{i}, \\ldots x_{n}{ }^{i}\\right), j=1,2, \\ldots, s\\right\\}$. The second step is to estimate the margins $F_{i}$ for each random variable $X_{i}, i=1,2, \\ldots, n$ according to the samples $\\left\\{x_{i}^{j}, j=1,2, \\ldots, s\\right\\}$. The last step is to select or to construct a copula $C$ according to $x$, and then sample from $C$. Assuming the sampled vectors are $\\left\\{u^{(k)}=\\left(u_{1}^{(k)}, u_{2}^{(k)}, \\ldots, u_{n}^{(k)}\\right), k=1,2, \\ldots, l\\right\\}$, the new individuals $\\left\\{\\boldsymbol{x}^{(k)}=\\left(x_{1}^{(k)}, x_{2}^{(k)}, \\ldots, x_{n}^{(k)}\\right), k=1,2, \\ldots, l\\right\\}$ can be calculate3d by using  \n$$\nx_{i}^{(k)}=F_{i}^{-1}\\left(u_{i}^{(k)}\\right), i=1, \\ldots, n, k=1, \\ldots, l\n$$  \nwhere, $F_{i}{ }^{j}$ is the inverse function of the $i$ th marginal distribution function.\ncopula EDA replaces some old individuals of the original population with the new generated individuals and progresses the new evolution until the terminate condition is met.\n[IMAGE0]  \nFig. 1. The flow chart of multi-population parallel copula EDA  \nSome authors have studied on the optimization effectiveness of different copula functions under the framework of copula EDA [17],[18]. The results show that in many cases, the different copulas are used in common basic test function to bring about  \ndifferent performances, because each copula function has special characteristic. So modeling and sampling by a pre-assigned single copula function without judgment is difficult to exactly describe the multivariate correlation of practical problem.  \nIn order to possibly speed up the search of EDAs and to increase the diversity of the population, the idea of parallel Genetic Algorithms is introduced into copula EDA. Multi-population parallel copula EDA separates the individuals into certain independent subpopulations. According to the frame work of copula EDA, each subpopulation use different copulas to model and sample, respectively. We choose two famous Archimedean copulas: Clayton and Gumbel. The sampling algorithm from copula is the algorithm proposed by Marshall and Olkin[19], [20].  \nConcluding the analysis presented above, the multi-population parallel copula EDA works as Figure 1 and Algorithm 1, where, the procedure Clatyton sample and Gumbel sample is shown in Algorithm 2 and Algorithm 3 respectively.  \nAlgorithm 1. Pseudo code for multi-population parallel copula EDA.\nStep1. Randomly generate initial population with size $N$, and divide them into two subpopulations: pop1g, pop2g, and set $g \\leftarrow 0$.\nStep2. Initialize evaluation flag: evFlag $1 \\leftarrow 1 \\overline{1} \\mathrm{evFlag} 2 \\leftarrow 1$.\nStep3. Select two subpopulations spop1 and spop2 with same size of $s$ from pop1 $g$, pop2g. According to certain select-strategy, respectively.\nStep4. If evFlag $1==1$, evolve pop1g based on Clayton copula.\nStep4-1 Estimate the univariate marginal distribution function $\\bar{\\imath} F_{i}$ for each dimension from spop1.1  \nStep4-2. For $k=1$ to 1 do $\\left(x_{1}^{(k)}, x_{2}^{(k)}, \\ldots, x_{n}^{(k)}\\right)=$ Claytonsample(k).\nStep4-3. Replace the old individuals of pop1g with the new individual.\nStep4-4. If the stopping criterion of pop1g is reached, setlevFlag $1 \\leftarrow 0$.\nStep5. If evFlag2==1, evolve, pop2g base on Gumbel copula.\nStep5-1. Estimate the univariate marginal distribution function $F_{i}$ for each dimension from $2 s p o p 2$.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:02",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Boltzmann-based estimation of distribution algorithm, what range of energy savings and TAC reductions have been reported when applied to HIDiC configurations, specifically in the context of rigorous optimization studies?",
      "topics": [
        "analysis"
      ],
      "answer": "Rigorous optimization studies using the Boltzmann-based estimation of distribution algorithm have achieved energy savings between 52% and 84% and TAC reductions from 2% to HIDiC configurations with TAC 35% larger than conventional columns. Also, a constrained Boltzmann-based estimation of distribution algorithm was used in the optimization of HIDiC sequences, achieving energy savings between 85% and 87% and TAC reductions of 27%.",
      "chunk_id": 3702,
      "paper_id": "Study of dynamic performance of heat-integrated distillation columns considering the effect of relative volatility of the mixtures",
      "paper_title": "Study of dynamic performance of heat-integrated distillation columns considering the effect of relative volatility of the mixtures",
      "paper_year": "2023",
      "chunk_content": "and rectifying section have led to energetic improvements over the known typical HIDiC configuration (Wakabayashi et al., 2019). Authors also suggest that good control properties are expected for these novel configurations due to the adequate heat exchange structure at limited points between both sections of the HIDiC column. Likewise, several levels of heat integration (internal and external heat integration) have been achieved, Schmal et al. (2006). Also, some sensitivity studies by manipulating CR, TNS and RR have been performed (e.g. Jana and Mali, 2010). Hence, energy savings of $44 \\%$ and TAC reductions of $14 \\%$ at optimal CR of about 1.5 were determined in the analysis of a debutanizer HIDiC. Thus, the major influence on the energy consumption and TAC was determined for CR, followed by the influence of RR and low influence of TNS. Notice also that rigorous optimization studies using stochastic algorithms, such as the Boltzmann-based estimation of distribution algorithm (Gutierrez-Guerra et al., 2014), have been achieved. In this case, energy savings between $52 \\%$ and $84 \\%$ and TAC reductions from $2 \\%$ to HIDiC configurations with TAC $35 \\%$ larger than the conventional columns were obtained. In addition, TAC reductions of 6.60-9.75\\% were determined by optimizing the HIDiC columns using Genetic algorithms (Shahandeh et al., 2014). Besides, the optimization of HIDiC sequences by using a constrained Boltzmann-based estimation of distribution algorithm (Gutierrez-Guerra et al., 2016) and a MINLP algorithm (Harwardt et al., 2010) conducted to establish that the maximum potential (energy savings and TAC) of the HIDiC columns is obtained in the separation of mixtures with low $\\alpha$. Similarly, the best energy savings and TAC were identified for the separation of non-equimolar systems, 0.75/ 0.25 , (Gutierrez-Guerra et al., 2017), by optimizing HIDiC sequences using a constrained Boltzmann-based estimation of distribution algorithm. In this case, energy savings between $85 \\%$ and $87 \\%$ were computed. Similar reductions for the cooling water and carbon dioxide emissions were calculated. In addition, TAC reductions of $27 \\%$ were obtained. Besides, it is important to underline that the energetic and economic performance of the HIDiC configurations have been mainly focused on the separation of binary mixtures and only few multicomponent mixtures have been considered.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:03",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the approach of Zhao et al. for determining inspection schedules differ from periodic inspection policies, particularly concerning the aging rate and defect detection probability?",
      "topics": [
        "performance"
      ],
      "answer": "Zhao et al. developed a mathematical model to evaluate the reliability of a single-unit system and optimize the inspection schedule non-periodically, whereas periodic inspection is the most commonly used policy. Zhao et al.'s approach is suited when the aging rate of a unit is unknown and must be estimated with information gathered by inspection. They assume a defect can be detected by inspection with a specific probability, and this probability significantly affects reliability. The optimal inspection intervals are determined by maximizing the reliability of the unit within a given period [0, t], rather than merely meeting the required reliability.",
      "chunk_id": 10557,
      "paper_id": "Determining the inspection intervals for one-shot systems with support equipment",
      "paper_title": "Determining the inspection intervals for one-shot systems with support equipment",
      "paper_year": "2018",
      "chunk_content": "[^0]:     Corresponding author.  \nE-mail addresses: chaoyangxue@gmail.com (Q.Q. Zhao), wonyun@pusan.ac.kr (W.Y. Yun). http://dx.doi.org/10.1016/j.ress.2017.08.007  \npredetermined age. Renewal function, point unavailability and time average unavailability, and the effect of age based on $P M$ policy were evaluated. They concluded that the point unavailability can be reduced by PM. Cui et al. [7] obtained the instantaneous availability and the limiting average availability under periodic inspections for a single-unit storage system. The instantaneous availability is obtained by using the virtual age concept, and they assumed that the virtual age during the failure time is the same as at the moment before the system fails. Inspection is assumed to be perfect, and if failure is detected, there are two possible maintenance actions: minimal repair for regular failures and perfect repair at Nth inspection time point.  \nIto and Nakagawa [8] considered optimal inspection policies for a system with two units in storage, one of which is maintained upon inspection and the other degrading over time. To maintain a higher degree of system reliability, the system is inspected and maintained periodically, and it is overhauled if the reliability becomes less than or equal to a specific value. The optimal inspection times were determined to minimize the average cost, including inspection and overhaul costs. In a later study, Ito and Nakagawa [9] assumed that the system would be replaced upon the detection of failure or when its reliability decreases beyond a specific value. Ito and Nakagawa [10] also considered a system that contains a component that degrades over time, and they determined the optimal inspection intervals that minimize the expected total cost, including inspection and loss costs. They later determined the optimal inspection times that would minimize the mean down time and average cost until overhaul [11]. They also considered three types of units: Unit 1 is inspected and maintained at time interval $T$, Unit 2 is partially replaced at time interval NT, and Unit 3 is only overhauled if the reliability is less than or equal to a specific value. The optimal inspection and replacement times were determined to minimize the expected total cost until overhaul [12].  \nBadia et al. [13] proposed an inspection policy for a single-unit system that is renewed upon the observation of failure through periodic inspection. They assumed that the inspection might not be perfect, and the optimal inspection intervals were determined to minimize the average cost per unit of time over an infinite time span. Wolde and Ghobbar [14] considered reliability, availability, and cost as optimization criteria. Availability and reliability were used to evaluate the system performance. They showed how these optimization criteria are related to each other and that improved reliability can impact availability. They suggested a mathematical model to determine the optimal inspection intervals to improve reliability and availability while reducing cost.  \nPeriodic inspection is the most commonly used inspection policy. However, the information gathered during inspection is used to decide when the next inspection will take place. Hence, non-periodic inspection might be more appropriate, especially when the aging rate of a unit is unknown and must be estimated with information gathered by inspection. Zhao et al. [15] developed a mathematical model to evaluate the reliability of a single-unit system and optimize the inspection schedule. If a defect is detected by non-periodic inspection, the system is repaired immediately but minimally. They assumed that a defect can be detected by inspection with a specific probability. The probability of defect detection had a significant effect on reliability. The optimal inspection intervals were determined by maximizing the reliability of the unit rather than merely meeting the required reliability within a given period $[0, t]$.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:05",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model to find model parameter values close to the data uncertainty, as mentioned in the context of calibrating an epidemiological model?",
      "topics": [
        "selection",
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "The EDA is applied as the initial step in a two-step process for probabilistic model calibration. Specifically, the EDA is used to identify sets of model parameter values that align with the inherent data uncertainty. This involves exploring the parameter space to locate values that produce model outputs consistent with the range of uncertainty observed in the available data. The subsequent selection algorithm then refines these parameter sets to accurately capture the data uncertainty.",
      "chunk_id": 1909,
      "paper_id": "Probabilistic calibration and short-term prediction of the prevalence herpes simplex type 2 A transmission dynamics modelling approach",
      "paper_title": "Probabilistic calibration and short-term prediction of the prevalence herpes simplex type 2: A transmission dynamics modelling approach",
      "paper_year": "2022",
      "chunk_content": "Juan-Carlos Cortes | Pablo Martinez-Rodriguez (1) Jose-Antonio Morano (1)Jose-Vicente Romero (1) Maria-Dolores Rosello | Rafael-Jacinto Villanueva  \nInstituto Universitario de Matematica Multidisciplinar, Universitat Politecnica de Valencia, Valencia, Spain\nPablo Martinez-Rodriguez, Instituto Universitario de Matematica Multidisciplinar, Universitat Politecnica de Valencia, Valencia, Spain.\nEmail: pabmarr2@upv.es  \nCommunicated by: J. R. Torregrosa\nGeneralitat Valenciana, Grant/Award Number: AICO/2019/215  \nAn epidemiological model is proposed to study the transmission dynamics of the herpes virus type 2, a sexually transmitted infectious disease. This model considers two states, susceptible and infected, divides the population into sexes, assumes only heterosexual contacts and includes different transmission rates depending on whether the transmission is woman-man or man-woman. Reported and prevalence series data are retrieved from several sources. We consider the inherent data survey errors and the sensitivity of the diagnosis tests (data uncertainty). To calibrate the model to the available data and their uncertainty, a novel technique is proposed in two steps: (1) the application of the estimation of distribution algorithm (EDA) to find sets of model parameter values close to the data uncertainty and (2) the application of a selection algorithm to get a reduced number of model parameter values whose model outputs capture accurately the data uncertainty. Then, we check its robustness, and we provide a prediction of the evolution of the infected over the next 4 years. From the technical point of view, we conclude that the proposed technique to calibrate probabilistically the model is reliable and robust. Also, it is able to provide confidence intervals for the model parameter values and the predictions. From the medical point of view, the model returns that the transmission woman-man is higher than the man-woman, according to recent literature, and there is a mild increasing trend in the number of infected people over the next years.\ncomputational technique, data uncertainty quantification, herpes simplex virus type 2, modelling infectious diseases, probabilistic calibration, transmission dynamics",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:07",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model for point-set registration, as indicated by the experimental results?",
      "topics": [
        "convergence"
      ],
      "answer": "The effectiveness of the EDA model is evaluated based on its robustness compared to state-of-the-art registration algorithms. The experimental results show the method has the best robustness.",
      "chunk_id": 2316,
      "paper_id": "An Estimation of Distribution Algorithm Based on Variational Bayesian for Point-Set Registration",
      "paper_title": "An Estimation of Distribution Algorithm Based on Variational Bayesian for Point-Set Registration",
      "paper_year": "2022",
      "chunk_content": "Hualong Cao ${ }^{\\oplus}$, Qiqi He, Haifeng Wang ${ }^{\\ominus}$, Zenghui Xiong, Ni Zhang, and Yang Yang FORMULA_2, Member, IEEE\nPoint-set registration is widely used in computer vision and pattern recognition. However, it has become a challenging problem since the current registration algorithms suffer from the complexities of the point-set distributions. To solve this problem, we propose a robust registration algorithm based on the estimation of distribution algorithm (EDA) to optimize the complex distributions from a global search mechanism. We propose an EDA probability model based on the asymmetric generalized Gaussian mixture model, which describes the area in the solution space as comprehensively as possible and constructs a probability model of complex distribution points, especially for missing and outliers. We propose a transformation and a Gaussian evolution strategy in the selection mechanism of EDA to process the deformation, rotation, and denoising of selected dominant individuals. Considering the complexity of the model, we choose to optimize from the perspective of variational Bayesian, and introduce a prior probability distribution through local variation to reinforce the convergence of the algorithm in dealing with complex point sets. In addition, a local search mechanism based on the simulated annealing algorithm is added to realize the coarse-to-fine registration. Experimental results show that our method has the best robustness compared with the state-of-the-art registration algorithms.  \nIndex Terms-Asymmetric generalized Gaussian mixture model (AGGMM), estimation of distribution algorithm (EDA), evolution strategy (ES), point-set registration (PSR), variational Bayesian.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:08",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "Based on the text, what is the main conclusion regarding the performance and diversity maintenance of MB-GNG compared to other Estimation of Distribution Algorithms like MrBOA, SDR-AVS MIDEA, and MAMaLGaM-X$^+$?",
      "topics": [
        "convergence",
        "diversity",
        "Estimation of Distribution Algorithms",
        "MB-GNG",
        "MDEF"
      ],
      "answer": "The main conclusion is that MB-GNG, designed to address the outliers issue, not only achieves good convergence to the Pareto-optimal front but also maintains a higher population diversity compared to MrBOA, SDR-AVS MIDEA, and MAMaLGaM-X$^+$. Statistical tests on the MDEF values confirm that MB-GNG sustains a population diversity comparable to regular evolutionary algorithms, while the other algorithms exhibit consistently lower diversity.",
      "chunk_id": 1144,
      "paper_id": "Understanding the Treatment of Outliers in Multi-Objective Estimation of Distribution Algorithms",
      "paper_title": "Understanding the Treatment of Outliers in Multi-Objective Estimation of Distribution Algorithms",
      "paper_year": "2014",
      "chunk_content": "Figures 1 and 2 summarize the average results of 30 runs for every algorithm and problem combination. From them it is noticeable that there is a substantial difference on MDEF scores between the 'pure' machine learning model-building algorithms, in particular MrBOA. Results from more advanced algorithms like SDR-AVS MIDEA and MAMaLGam-X ${ }^{+}$yield a better performance and also better MDEF scores, something that supports their leitmotif. Finally, and in our opinion most importantly, it is observable how MB-GNG - an algorithm that was devised with the particular objective of solving the outliers issue - is not  \nTable 1: Results Mann-Whitney-Wilcoxon U tests comparing the MDEF values of HypE (H), MrBOA (M), naive MIDEA (N), SDR-AVS MIDEA (S), MAMaLGaM-X ${ }^{+}(\\mathrm{A})$ and MB-GNG (G) as the optimization progressed. When the algorithm in the row yielded larger MDEF than one in the column is marked with a + , if smaller with a - . If there is not a significant difference in results a $\\sim$ is used.  \nonly capable of producing good results in terms of convergence to the Paretooptimal front, but also is the algorithm that is able to maintain a higher diversity on its population.  \nThe statistical validity of the judgment of these results calls for the application of statistical hypothesis tests. It has been previously remarked by different authors that the Mann-Whitney-Wilcoxon $U$ test is particularly suited for experiments in the context of multi-objective evolutionary optimization [20]. This test is commonly used as a non-parametric method for testing equality of population medians. In our case we performed pair-wise tests on the significance of the difference of the indicator values yielded by the executions of the algorithms. A significance level, FORMULA_92, of 0.05 was used for all tests.  \nThe results of these tests applied to the MDEF values yielded at the end of each run are summarized in Table 1 That table reflects when an algorithm produced significantly larger or smaller values of MDEF and when the results are indistinguishable from one another. This condensed representation prompts  \nsome interesting and relevant conclusions. First, and most importantly, MGGNG was the only algorithm capable to maintain a population diversity similar to that of a regular evolutionary algorithm, and correspondingly, larger than the rest of the algorithms. The rest of the algorithms consistently exhibited a lower diversity with regard to the EA and to MB-GNG. It is also very interesting how SDR-AVS MIDEA and MAMaLGaM-X frequently had similar MDEF scores.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:10",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of flexible flow shop scheduling problems, what mathematical principles govern the calculation of the total processing time $T_{i k l}^{c}$ for a turning operation $O_{i k}$, and how do the parameters $V_{i k}^{c}$, $a p_{i k}$, $f_{i k}$, $d_{i}^{0}$, and $n_{k l}^{c}$ influence this calculation?",
      "topics": [
        "optimization"
      ],
      "answer": "The total processing time $T_{i k l}^{c}$ for a turning operation $O_{i k}$, where job $i$ is handled on lathe $k$, is calculated as the sum of job-loading time $t_{i k}^{l}$, lathe spindle speeding-up time $t_{k l}^{S}$, job cutting time $t_{i k l}^{c}$, lathe stopping time $t_{k l}^{D}$, and job-unloading time $t_{i l}^{u}$, as expressed in the equation $T_{i k l}^{c}=t_{i k}^{l}+t_{k l}^{S}+t_{i k l}^{c}+t_{k l}^{D}+t_{i l}^{u}$. Since $t_{i k}^{l}, t_{k l}^{S}, t_{k l}^{D}$ and $t_{i k}^{u}$ can be seen as parameters when job $i$ and machine $k$ are known, the cutting time $t_{i k l}^{c}$ can be further detailed as $\\frac{60 V_{i k}^{c}}{\\pi \\times a p_{i k} \\times f_{i k} \\times d_{i}^{0} \\times n_{k l}^{c}}$, where $V_{i k}^{c}$ is the total removed volume from the semi-product of job $i$ by lathe $k$, $a p_{i k}$ is the depth of cutting, $f_{i k}$ is the feed rate, $d_{i}^{0}$ is the semi-product diameter of job $i$, and $n_{k l}^{c}$ is the spindle speed of level $l$ of the lathe $k$. Therefore, the total processing time $T_{i k l}^{s}$ can be expressed as $T_{i k l}^{s}=t_{i k}^{l}+t_{k l}^{s}+\\frac{60 V_{i k}^{c}}{\\pi \\times a p_{i k} \\times f_{i k} \\times d_{i}^{0} \\times n_{k l}^{c}}+t_{k l}^{D}+t_{i l}^{u}$. The parameters $V_{i k}^{c}$, $a p_{i k}$, $f_{i k}$, and $d_{i}^{0}$ are directly proportional to the cutting time, thus increasing any of these parameters increases the cutting time, while $n_{k l}^{c}$ is inversely proportional, meaning increasing the spindle speed decreases the cutting time.",
      "chunk_id": 12240,
      "paper_id": "Estimation of Distribution Algorithm for Energy-Efficient Scheduling in Turning Processes",
      "paper_title": "Estimation of Distribution Algorithm for Energy-Efficient Scheduling in Turning Processes",
      "paper_year": "2016",
      "chunk_content": "Since the fine turning begins only after the rough turning completes, and there is usually more than one lathe for each turning process, this workshop can be regarded as a two-stage flexible flow shop. Meanwhile, energy saving is a new focus in this workshop.  \nThus, the problem under consideration can be regarded as a flexible flow shop scheduling problem with two objectives: production efficiency and energy saving. Makespan noted as Cmax, is chosen as the production index evaluator. The energy consumption is evaluated by the total energy consumption noted as TEC.  \nUtilizing the three-field notation proposed by Graham et al. [38], we express the above problem as $F F_{m}(r) \\mid \\mid C \\max +T E C$, where $F F$ represents the flexible flow shop, $m$ the number of stages, $r$ unrelated parallel machine, || no special constraints, and $C \\max +T E C$ the optimization goals.  \nFor the convenience of mathematical modeling of this problem, the turning operations and energy consumption are analyzed in the following.\nA turning operation $\\left(O_{i k}\\right)$ can be defined as: job $i$ is handled on lathe $k$, and it generally needs to pass five steps which are job-loading, lathe starting, job cutting, lathe stopping, and job-unloading. Because a turning operation of $O_{i k}$ contains five sub-operations, the total processing time is the summation of them. Therefore, the total processing time of $O_{i k}$ can be achieved with Equation (1).  \n$$\nT_{i k l}^{c}=t_{i k}^{l}+t_{k l}^{S}+t_{i k l}^{c}+t_{k l}^{D}+t_{i l}^{u}\n$$  \nwhere, $t_{i k}^{l}$ is the loading time of job $i$ onto machine $k, t_{k l}^{S}$ the time for speeding up the spindle of lathe $k$ to $l$ level, $t_{i k l}^{c}$ the cutting time of job $i$ is processed on the lathe $k$ at the speed level $l, t_{k l}^{D}$ the time for stopping lathe, and $t_{i k}^{u}$ the unloading time of job $i$ from machine $k$.  \nWhen job $i$ and machine $k$ are known, $t_{i k}^{l}, t_{k l}^{S}, t_{k l}^{D}$ and $t_{i k}^{u}$ can be seen as parameters, and the total processing time of any turning operation can be expressed by Equation (2) according to Equation (10) in Section 2.4.  \n$$\nT_{i k l}^{s}=t_{i k}^{l}+t_{k l}^{s}+\\frac{60 V_{i k}^{c}}{\\pi \\times a p_{i k} \\times f_{i k} \\times d_{i}^{0} \\times n_{k l}^{c}}+t_{k l}^{D}+t_{i l}^{u}\n$$  \nwhere, $V_{i k}^{c}$ is the total removed volume from the semi-product of job $i$ by lathe $k$, $a p_{i k}$ the depth of cutting, $f_{i k}$ the feed rate, $d_{i}^{0}$ the semi-product diameter of job $i$, and $n_{k l}^{c}$ the spindle speed of level $l$ of the lathe $k$.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:14",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing a society of hill-climbers (SoHC) for constraint satisfaction, how should practitioners utilize the breakout management mechanism (BMM) within the distributed hill-climber?",
      "topics": [
        "constraints"
      ],
      "answer": "In a society of hill-climbers (SoHC), each agent \\(a_i\\) maintains a breakout management mechanism (BMM). This BMM records and updates the weights of all breakout elements corresponding to the nogoods of discovered local minima. The distributed hill-climber using the BMM seeks to minimize the number of conflicts plus the sum of all the weights of the violated breakout elements.",
      "chunk_id": 6294,
      "paper_id": "A Comparison of Evolutionary Protocols for Solving Distributed Constraint Satisfaction Problems",
      "paper_title": "A comparison of evolutionary protocols for solving distributed constraint satisfaction problems",
      "paper_year": "2006",
      "chunk_content": "A CSP [6],[19],[30],[45]-[48] can be viewed as triple $\\langle X, D, C\\rangle_{\\text {where }} \\mathrm{X}$ is set of variables, D is set of domains where each $\\mathrm{xie} \\mathrm{X}$ takes its value from the corresponding domain die D , and where C is a set of r constraints. Consider a binary constraint network (one where each constraint constrains the value of exactly two variables) ${ }^{1}$ $\\langle X, D, C\\rangle_{\\text {where }} \\mathrm{X}=\\{\\mathrm{E}, \\mathrm{F}, \\mathrm{G}\\}, \\mathrm{D}=\\{\\mathrm{dE}=\\{\\mathrm{e} 1, \\mathrm{e} 2, \\mathrm{e} 3\\}, \\mathrm{dF}=$ $\\{\\mathrm{f} 1, \\mathrm{f} 2, \\mathrm{f} 3\\}, \\mathrm{dG}=\\{\\mathrm{g} 1, \\mathrm{~g} 2, \\mathrm{~g} 3\\}\\}$, and $\\mathrm{C}=\\{\\mathrm{cEF}, \\mathrm{cEG}, \\mathrm{cFG}\\}$. Suppose that the constraints $\\mathrm{cEF}, \\mathrm{cEG}, \\mathrm{cFG}$ are as follows:\n$c_{E F}=\\{\\langle\\mathrm{el}, \\mathrm{f} 2\\rangle,\\langle\\mathrm{el}, \\mathrm{f} 3\\rangle,\\langle\\mathrm{e} 2, \\mathrm{f} 2\\rangle,\\langle\\mathrm{e} 3, \\mathrm{f} 2\\rangle\\}$\n$c_{E G}=\\{\\langle\\mathrm{e} 2, \\mathrm{~g} 3\\rangle,\\langle\\mathrm{e} 3, \\mathrm{gl}\\rangle\\}$\n$c_{F G}=\\{\\langle\\mathrm{f} 2, \\mathrm{~g} 1\\rangle,\\langle\\mathrm{f} 2, \\mathrm{~g} 3\\rangle\\}$\nConstraint networks possess two additional attributes: tightness and density. The tightness of a constraint is the ratio of the number of tuples disallowed by the constraint to the total number of tuples in di x dj. The average constraint tightness of a binary constraint network is the sum of the tightness of each constraint divided by the number of constraints in the network. The density of a constraint network is the ratio of the number of constraints in the network to the total number of constraints possible.  \nConstraints in a binary constraint network may also be represented as two directional constraints referred to as arcs [46],[48]. For example, the symmetric constraint $C_{E F}$ can be represented as\n$c_{E F}=\\left\\{\\begin{array}{l}c_{E F}, c_{E F} \\\\ c_{E G}=c_{D}\\end{array}\\right\\}$ where\n$c_{D}=c_{D}=\\{\\langle\\mathrm{e} 1, \\mathrm{f} 2\\rangle,\\langle\\mathrm{e} 1, \\mathrm{f} 3\\rangle,\\langle\\mathrm{e} 2, \\mathrm{f} 2\\rangle,\\langle\\mathrm{e} 3, \\mathrm{f} 2\\rangle\\}$,\nwhere $c_{E F}$ represents the directional constraint imposed on variable F by variable E , and where $c_{E F}$ represents the directional constraint imposed on variable E by variable F .  \n[^0]This view of a symmetric binary constraint admits the possibility of an asymmetric binary constraint between variables E and F as one where $c_{E F} \\neq c_{E F}$.\nA society of hill-climbers (SoHC) [5],[6],[29]-[32], [34], [49] is a collection of hill-climbers that search in parallel and communicate promising (or futile) directions of search to one another through some type of external collective structure. In the society of hill-climbers that we present in this paper, the external collective structure which records futile directions of search comes in the form of a distributed list of breakout elements, where each breakout element corresponds to a previously discovered nogood ${ }^{2}$ of a local minimum [50]. Before presenting the SoHC, we must first discuss the distributed hill-climber that makes up the algorithm. In this section, we first introduce a modified version of Yokoo's distributed breakout algorithm with broadcasting [34] (mDBA) which is based on Morris' Breakout Algorithm [50]. After introducing mDBA we will describe the framework of a SoHC.  \nFor the mDBA , each agent $a_{i} \\in A$ is responsible for the value assignment of exactly one variable. Therefore, agent $a_{i}$ is responsible for variable $s_{i} \\in X$, can assign variable $s_{i}$ one value from domain $d_{i} \\in D$, and has as constraints $C_{s_{i}, s_{j}}$ where $i \\neq j$. The objective of agent $a_{i}$ is to satisfy all of its constraints $C_{s_{i}, s_{j}}$. Each agent also maintains a breakout management mechanism (BMM) [29]-[32] that records and updates the weights of all of the breakout elements corresponding to the nogoods of discovered local minima. This distributed hill-climber seeks to minimize the number of conflicts plus the sum of all of the weights of the violated breakout elements.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:16",
      "generation_style": "practical_application"
    },
    {
      "question": "Given the Pareto front representation defined by the equation $\\overline{\\mathbf{F}}(\\mathbf{x})=\\left(f_{1}-b_{1}, \\ldots, f_{k}-b_{k}\\right)$, where $f_i$ are scalar objective functions and $b_i$ represent their respective lower bounds, how might the choice of weighting vectors influence the convergence and spread of the resulting Pareto front in an Estimation of Distribution Algorithm (EDA)?",
      "topics": [
        "bounds"
      ],
      "answer": "The text hypothesizes that the choice of weighting vectors will greatly influence the convergence and spread of the resulting Pareto front, where the Pareto front is defined using the equation $\\overline{\\mathbf{F}}(\\mathbf{x})=\\left(f_{1}-b_{1}, \\ldots, f_{k}-b_{k}\\right)$. This equation represents a transformation of the objective space, where $f_i$ are the scalar objective functions and $b_i$ are their corresponding lower bounds. The hypothesis suggests that different weighting vectors will lead to variations in how the EDA converges to and distributes solutions along this Pareto front, impacting the quality and diversity of the obtained solutions.",
      "chunk_id": 984,
      "paper_id": "Generalized decomposition and cross entropy methods for many-objective optimization",
      "paper_title": "Generalized decomposition and cross entropy methods for many-objective optimization",
      "paper_year": "2014",
      "chunk_content": "$$\n\\overline{\\mathbf{F}}(\\mathbf{x})=\\left(f_{1}-b_{1}, \\ldots, f_{k}-b_{k}\\right)\n$$  \n[IMAGE1]  \nFig. 1. Various Pareto front geometries that satisfy the following equation: $f_{1}^{p}+f_{2}^{p}=1$ for $p=\\{100,6,2,1, \\frac{1}{2}, \\frac{1}{6}\\}$.\nwhere $b_{i}$ are the respective lower bounds for the scalar objective functions $f_{i}$. For details on the formalism of disciplined convex programming, the interested reader is referred to [40-42].  \nIn concluding this section, we hypothesise that the choice of weighting vectors will greatly influence the convergence and spread of the resulting Pareto front. However this choice has, to date, been either arbitrary or based on invalid assumptions.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:18",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the IEDA-MsH model compare to the RBFIEDA model in the context of personalized search for movies, specifically concerning Root Mean Squared Error (RMSE), Hit Ratio (HR), and Average Precision (AP)?",
      "topics": [
        "optimization"
      ],
      "answer": "In the personalized search for movies, the RMSE of IEDA-MsH is reported to be 1.164, which is 5.67% lower than that of RBFIEDA. The Hit Ratio (HR) for IEDA-MsH is 0.01168 and the Average Precision (AP) is 0.839, representing improvements of 26.13% and 13.84% respectively, when compared to the HR and AP values achieved by RBFIEDA. This suggests IEDA-MsH more accurately identifies preferred items.",
      "chunk_id": 2241,
      "paper_id": "Multisource Heterogeneous User-Generated Contents-Driven Interactive Estimation of Distribution Algorithms for Personalized Search",
      "paper_title": "Multisource Heterogeneous User-Generated Contents-Driven Interactive Estimation of Distribution Algorithms for Personalized Search",
      "paper_year": "2022",
      "chunk_content": "[IMAGE10]\n(b)\n[IMAGE11]\n(c)  \nFig. 7. Personalized search in Apps. (a) RMSE. (b) HR. (c) AP.\n[IMAGE12]  \nFig. 8. Personalized search in movies. (a) RMSE. (b) HR. (c) AP.\ninformation. More knowledge should be more helpful if it is effectively extracted and applied. Furthermore, taking Movies as an example, the RMSE of IEDA-MsH is $1.164,5.67 \\%$ lower than that of the result given by RBFIEDA. The HR and MAP are 0.01168 and 0.839 , improving $26.13 \\%$ and $13.84 \\%$ higher than those values of the RBFIEDA, respectively. These results demonstrate the IEDA assisted with UGCs-driven RBM can help users to more accurately find preferred items in most cases.\n2) IEDA-MsH and IEDA-CT perform better than IEDAcateg on most datasets, which demonstrates that fusing both users text comments and items categories with IEDA is more valuable than only using items categories as traditional personalized search methods did. The reason lies in that more preference information implied in the comments is further extracted with our RBM model to enhance the optimization performance of IEDA. Especially, the UGCs-driven RBM model can not only track users preference but also provide a reliable fitness surrogate and probability model for IEDA. Such results also turn out the feasibility and effectiveness of the proposed methods on integrating and representing the domain knowledge of the personalized search with EAs.  \nTen users are randomly selected in each dataset to perform the IEAs on personalized search, and the comparative algorithms on RMSE, HR, and AP metrics are visualized to intuitively show the superiority of our algorithm. Each IEA method performs ten iterations and the evolutionary searching results are shown in Figs. 6-8 on Music, Apps, and Movies.  \nIn Figs. 6-8, IEDA-MsH represented with blue star line is significantly superior to other compared algorithms on the evaluation metrics in these cases. The experiments on multiple real-world datasets from different domains demonstrate that the proposed algorithm outperforms other compared IEAs in prediction accuracy and recommendation results. Accordingly, we can also conclude that the developed IEDA with UGCs and corresponding knowledge fusion is effective and applicable for the personalized search in the complex environment.\nWe first state two key points of applying EAs to solve practical optimization problems, i.e., the fusion of domain knowledge and conversion of optimal objectives. Aiming at the personalized search with UGCs, we present a multisource heterogeneous UGCs-enhanced IEDA to improve the search efficiency by sufficiently extracting the users preference and individualized requirements. The UGCs are mathematically  \nrepresented by using binary and doc2vec-based feature vectors, and then used to train an RBM to track the users preference. Based on the RBM, the reproduction probability model together with the optimization objectives termed as fitness surrogate is designed for successfully driving the EDA process. The effectiveness of representing UGCs-based domain knowledge, constructing RBM surrogate, and fusing such knowledge with IEDA is experimentally demonstrated by comparing with popular algorithms on Amazon datasets.\nThe UGCs used here only includes items ranks, comments, and category tags. Besides these, other domain knowledge as images or videos is also very helpful on designing more competitive IEAs for solving personalized search problems. We will carry out further work from these viewpoints in the future.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:21",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "Based on the description of Genetic Network Programming (GNP) as an Estimation of Distribution Algorithm (EDA), what distinguishes it from other related Evolutionary Algorithms (EAs) in terms of node connections and function types?",
      "topics": [
        "evolutionary",
        "algorithm implementation",
        "data structures"
      ],
      "answer": "GNP differs from other EAs like parallel algorithm discovery and orchestration (PADO), parallel distributed GP (PDGP), cartesian GP (CGP), and evolutionary programming (EP) by not requiring a terminal node. Furthermore, GNP allows nodes to be connected arbitrarily and separates judgment and processing functions.",
      "chunk_id": 4800,
      "paper_id": "Continuous probabilistic model building genetic network programming using reinforcement learning",
      "paper_title": "Continuous probabilistic model building genetic network programming using reinforcement learning",
      "paper_year": "2015",
      "chunk_content": "[^0]\n[^0]:    ${ }^{2} V_{i}$ and $x_{i}$ denote the state-value and continuous variables of node $i$, which will be described in the next section. They are not included in the discrete PMBGNP.  \n[IMAGE1]  \nFig. 1. Illustration of the directed graph structure.  \nIn a certain respect, GNP can be considered as an extension of GP to graph structure, which naturally allows more flexibility and higher expression ability for some complex problems. In addition to a class of related EAs, including parallel algorithm discovery and orchestration (PADO) [37], parallel distributed GP (PDGP) [38], cartesian GP (CGP) [39] and evolutionary programming (EP) [40], GNP does not require the terminal node and the nodes can be connected arbitrarily. Most importantly, by separating judgment and processing functions, GNP can efficiently generate POMDP by selecting only the necessary judgments for the current state of the problems.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:22",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the FRM-MEDA algorithm, how is the offspring population Qt2 generated, and what parameters are used to sample the Full Gaussian Model (FGM)?",
      "topics": [
        "fitness"
      ],
      "answer": "The offspring population Qt2 in FRM-MEDA is created by sampling the FGM, which involves generating a random sequence 'x' from a distribution denoted as x ∼ (μ, Σ). Here, μ represents the mean vector, and Σ represents the covariance matrix. These parameters (μ, Σ) for the FGM are calculated based on the current population using the MatEDA toolbox, and the sampling is performed using a full Gaussian variable sampling method.",
      "chunk_id": 10758,
      "paper_id": "A full variate Gaussian model-based RM-MEDA without clustering process",
      "paper_title": "A full variate Gaussian model-based RM-MEDA without clustering process",
      "paper_year": "2018",
      "chunk_content": "Step 0 Initialization: Set $\\mathrm{t}=0, \\mathrm{~K}=1$ (without clustering process). Create an initial population P0\nStep1 Modeling: Establish the probabilistic model by the (m-1)-D local PCA and select elitist solutions ( $10 \\%$ ofthesolutionsin the paper) to build the FGM for estimating the distribution of the candidate solutions in Pt\nStep 2 Sampling: Create the offspring population Qt1 by sampling the (m-1)-D PCA and Qt2 by sampling the FGM. Calculate the fitness value of each candidate solution in Qt1and Qt2\nStep 3 Selection: Select N solutions from Qt1, Qt2 and Pt to create the population $\\mathrm{Pt}+1$ for the next generation\nStep 4 Stopping Condition: If the stopping criterion is met, stop and return the fitness vectors of the non-dominatedsolutions of the obtained population, otherwise set $t=t+1$ andthen go to Step 2  \nFor the better description of the FRM-MEDA, a general framework of FRM-MEDA is given as in Fig. 6.  \nIn FRM-MEDA, the number of clusters $K$ is fixed at 1 during the evolution. The steps of modeling, sampling and selection related to $(m-1)-D$ PCA are conducted exactly as in RM-MEDA. In addition, $10 \\%$ of the solutions based on non-domination sorting in the population are selected to build the FGM. The sampling of FGM is to generate a random sequence $x$ and $x \\sim(\\mu, \\Sigma)$.\nThe Matlab toolbox for EDAs (MatEDA) [25] is a commonly used code platform proposed by Santana et al. for EDAs in 2010. The modeling and sampling methods of FGM are implemented by use of the MatEDA, in which we firstly calculate the parameters $(\\mu, \\Sigma)$ for FGM according to the current population and then sample the FGM by adopting related full Gaussian variable sampling method.\n[IMAGE_5]  \nFig. 6 The general framework of FRM-MEDA",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:24",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the proposed imputation method, utilizing NIGCC, in comparison to mean imputation, spline interpolation, and k-NN for handling missing data in industrial processes like BFG generation flow?",
      "topics": [
        "performance"
      ],
      "answer": "The proposed imputation method, leveraging NIGCC (Non-equal-length granules correlation coefficient) to analyze industrial data features, achieves higher imputation accuracy compared to mean imputation, spline interpolation, and k-NN. Mean imputation struggles with consecutive missing values, spline interpolation is prone to overfitting due to large fluctuations and noise, and k-NN can introduce deviations due to uncertain periodicity, whereas NIGCC is capable of obtaining more fitted samples, improving imputation accuracy for data with missing ratios.",
      "chunk_id": 12720,
      "paper_id": "Data imputation for gas flow data in steel industry based on non-equal-length granules correlation coefficient",
      "paper_title": "Data imputation for gas flow data in steel industry based on non-equal-length granules correlation coefficient",
      "paper_year": "2016",
      "chunk_content": "In industrial practice, there are often many acquired original data with large fluctuations and high level noises, such as the BFG generation flow data. The length of each imputing sequence is set to be 50 , considering the production rhythm of the blast furnace. In order to show the reliability and stability of the proposed method, the imputing results (errors) of different methods are listed in Table 1, where the proposed method exhibits the highest accuracy under different missing ratios validated by the original data.  \n[IMAGE6]\n(a) The process of correlation analysis and the analysis results of no missing points.\n[IMAGE7]\n(b) Analysis results of $\\mathbf{x}$ with missing ratio 10\\%, where (c) Analysis results of $\\mathbf{x}$ with missing ratio 20\\%, where $\\operatorname{SGCC}(a, p)=0.0013$\n[IMAGE8]\n(d) Analysis results of $\\mathbf{x}$ with missing ratio 30\\%, where (e) Analysis results of $\\mathbf{x}$ with missing ratio 40\\%, where $\\operatorname{SGCC}(a, p)=0.0033$.  \nFig. 6. Correlation analysis results of different missing ratios.  \nTo further illustrate the experimental results, a series of 100 -minute data are selected from the $40 \\%$ missing ratio experiment, as shown in Fig. 7. It can be apparently that, the mean imputation method exhibits good performance when there is few consecutive missing points. However, for the multiple consecutive missing values, the data feature could not be well reflected, see the results in the a-zone of Fig. 7. The spline interpolation uses the spline function to learn the characteristics of the data, which could reflect the dynamic features. But, due to the large fluctuations and high level noises, the results  \nTable 1  \n[IMAGE9]  \nFig. 7. Imputation results of the BFG generation flow data with missing ratio $40 \\%$.\nmight be large deviation due to the over-fitting problem of the spline function, see the results in the b-zone and d-zone of Fig. 7. The results of the k-NN method might bring out some deviations of data tendency because of the uncertain periodicity of a manufacturing procedure, see the results in the c-zone and d-zone. In contrast, the proposed method uses NIGCC to study the features of the industrial data and is capable of getting the more fitted samples, which greatly improved the imputation accuracy.",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:26",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the Improved Estimation of Distribution Algorithm (IEDA) relate to the standard Estimation of Distribution Algorithm (EDA) and Genetic Algorithm (GA) in the optimization of distributed generation (DG) placement and sizing?",
      "topics": [
        "search"
      ],
      "answer": "The Improved Estimation of Distribution Algorithm (IEDA) and the standard Estimation of Distribution Algorithm (EDA), along with the Genetic Algorithm (GA), all generate solutions that satisfy equality and inequality constraints when optimizing distributed generation (DG) placement and sizing. However, IEDA leverages Bayesian statistical inference with distribution estimation to improve its convergence speed compared to EDA and GA. While the optimum placement achieved by IEDA is identical to that of EDA and GA, IEDA minimizes the real power loss more quickly and simply without complex calculations, resulting in better accuracy and convergence speed.",
      "chunk_id": 10785,
      "paper_id": "Applied Research on Distributed Generation Optimal Allocation Based on Improved Estimation of Distribution Algorithm",
      "paper_title": "Applied Research on Distributed Generation Optimal Allocation Based on Improved Estimation of Distribution Algorithm",
      "paper_year": "2018",
      "chunk_content": "In this paper, Bayesian statistical-inference with distribution estimation creates a powerful optimization algorithm known as IEDA which reduces the total power loss and improves the voltage profile with proper allocation and sizing of DG. The global search ability of EDA algorithm is outstanding. Combined with Bayesian statistical reasoning, it can improve its convergence speed. EDA, GA and IEDA generate solutions which satisfy all the equality and inequality constraints. However, IEDA converges faster when compared to EDA and GA. The practical application and efficacy of this method was evaluated using three various common test systems (12, 34, and 69 bus). The comparative analysis of EDA, GA and IEDA methods for optimal placement and sizing of DG in a distribution system to minimize the total real power loss was successfully done. From the results, it is concluded that IEDA algorithm gives better results than EDA algorithm and GA algorithm, in terms of its accuracy and convergence speed. However, the optimum placement is identical to EDA and GA algorithms. IEDA algorithm can minimizes the real power loss simply and quickly without any complex calculations. Thus, the results obtained pave the way for new and promising research area, utilizing EDA algorithm with improvement, giving better results with high convergence speed.  \nIn the future, to reduce the computational burden further optimal DG placement can be done by any of the recent methods such as sensitivity analysis, voltage stability consideration, loss sensitivity factor, etc. and the sizing can be done with IEDA.  \nAuthor Contributions: Conceptualization, L.Y.; Methodology, Y.W.; Project administration, X.Y.; Supervision, X.Y., Y.W. and X.L.; Validation, L.Y. and Y.W.; Writing-original draft, L.Y.; Writing-review and editing, X.Y  \nAcknowledgments: This work was supported in part by the National Natural Science Foundation of China (51765042, 61463031, 61773051 and 61662044), Jiangxi Provincial Department of Science and Technology (JXYJG-2017-02), Jiangxi Natural Science Foundation (20171ACB20007) and Jiangxi Provincial Department of Science and Technology (20121BBE50023 and 20133BCB22002).\nConflicts of Interest: The authors declare no conflict of interest.\nDG Distributed generation\nIEDA Improved estimation of distribution algorithm\nEDA Estimation of distribution algorithm\nGA Genetic algorithm\n$T_{\\text {Loss }} \\quad$ The total power loss of the radial distribution system\n$P_{D G i} \\quad$ The real power generation using DG at bus $i$\n$P_{D i} \\quad$ The power demand at bus $i$\n$P_{\\text {Loss }} \\quad$ The line loss on the bus $i$\n$U_{\\text {min }} \\quad$ The lower limits of voltages at bus $i$\n$U_{\\text {max }} \\quad$ The upper limits of voltages at bus $i$\n$I_{\\text {max }} \\quad$ The maximum current value of branch $i$\n$S_{1} \\quad$ The apparent power of bus $i$\n$P_{i} \\quad$ The active power of bus $i$\n$Q_{i} \\quad$ The reactive power of bus $i$\nBCBV The branch-current to bus-voltage matrix\nBIBC The bus-injections to branch-currents matrix\n$P_{L i} \\quad$ The active load powers on bus $i$\n$Q_{L i} \\quad$ The reactive load powers on bus FORMULA_124",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:28",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing the multi-objective generative deep network-based estimation of distribution algorithm (MODEDA), how should practitioners utilize the Variational Autoencoder (VAE) to generate new solutions, specifically addressing the sampling method?",
      "topics": [
        "evolutionary"
      ],
      "answer": "To generate new solutions in MODEDA using the VAE, practitioners should first map the cost function variables to the VAE's input layer, where the number of variables equals the input layer size. The encoder compresses the search space into a low-dimensional latent space with a Gaussian distribution. To sample, add Gaussian noise N(0,1) to a portion (e.g., 25) of the latent variables obtained by encoding existing parent solutions. The decoder then reconstructs new solutions from these modified latent variables, effectively exploring the space near the parents in the latent space. This contrasts with using entirely random latent variables, allowing for more effective discovery of non-dominated solutions.",
      "chunk_id": 1929,
      "paper_id": "Multi-Objective Deep Network-Based Estimation of Distribution Algorithm for Music Composition",
      "paper_title": "Multi-Objective Deep Network-Based Estimation of Distribution Algorithm for Music Composition",
      "paper_year": "2022",
      "chunk_content": "The proposed multi-objective generative deep network-based estimation of distribution algorithm (MODEDA) can adaptively deploy any operator of standard MOEAs [21], such as ranking, selection, or archiving, by replacing crossover and mutation with a specific generative deep network. MODEDA framework is illustrated in Figure 1. In this study, non-dominance ranking, crowding distance, and binary tournament selection that are similar to the operators in NSGA-II [14] are employed. Moreover, the $k$-means clustering is used to isolate the data group that conflicts with each other.  \n[IMAGE1]  \nFIGURE 2. Sampling method for exploring new solution based on parent.  \nThe overall procedures are described in Algorithm 2. Input layer's units in the network are mapped to a set of variables in the cost function; the number of variables in the fitness function denotes the size of the input layer in VAE. The encoder part of the VAE compresses the search space to a low dimension to learn the critical dependencies of the training dataset, and then converts it into a latent space of the Gaussian distribution. The decoder part reconstruct the latent variable from the input data, and then to accommodate the new latent variable to generate new solutions. Each solution remapped the search space $(\\mathrm{N})$ and the newly optimized solution $(\\mathrm{N})$ in the Pareto optimal subspace to the original search space. The final solution set $(2 \\mathrm{~N})$ was fitted by the objective function in the search space.  \nThe proposed algorithm utilizes multiple models along with the result of $k$-means clustering that decomposes a given problem [21], [37]. In general, the user determines the value of $k$; in this study, $k$ is set to the number of objectives. The modeling and sampling process in Figure 1 is described as an example when the number of objectivities is 2 . Thus, the whole population is divided into two groups, and a VAE model is trained in each cluster independently. Then, the models create $\\frac{n}{k}$ offspring by sampling the VAE model.  \nOur sampling method generates a new solution by adding a Gaussian noise to the parent population. To be more exact, VAE is able to represent data in a continuous probability distribution space, but the value itself is a black box. Thus, we add a Gaussian noise of $N(0,1)$ to 25 of the latent variables, which are obtained by entering the existing parent into the encoder layer. When generating new data from the trained VAE model, random latent variables are generally used as the input of the decoder. The Gaussian distribution of the trained VAE is unknown, and there are only a limited number of chances of sampling in the evolutionary process.  \nAs shown in Figure 2, in order to effectively conduct the sampling process for discovering a non-dominated solution under these constraints, we use a modified latent variable of the training data. Random Gaussian noise FORMULA_45 is added to some part of the latent variable, which is obtained from the encoder by putting the training data as the input. Then the\ndecoder generates new data from the modified latent variable. In this way, we can find more effectively new non-dominated solutions by generating data close to parents in the latent space.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:30",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the hybrid self-organizing migrating algorithm based on estimation of distribution (HSOMA), how does it leverage the estimation of distribution algorithm (EDA) to address the premature convergence issue observed in the self-organizing migrating algorithm (SOMA)?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms",
        "Self-Organizing Migrating Algorithm",
        "convergence"
      ],
      "answer": "HSOMA incorporates the EDA approach by reproducing the genes of new individuals using both SOMA and EDA. The proportion of each algorithm's contribution is governed by a control parameter. This hybrid approach aims to exploit the statistical information on the population derived from EDA to enhance population diversity, which in turn mitigates premature convergence and improves convergence speed compared to SOMA alone. The continuous domain Population Based Incremental Learning algorithm (PBILe) and hybrid migrating behavior based self-organizing migrating algorithm (HBSOMA) are also mentioned as comparators.",
      "chunk_id": 508,
      "paper_id": "Hybrid Self-organizing Migrating Algorithm Based on Estimation of Distribution",
      "paper_title": "Hybrid Self-organizing Migrating Algorithm Based on Estimation of Distribution",
      "paper_year": "2014",
      "chunk_content": "LIN Zhi-yiFaculty of ComputerGuangdong University of TechnologyGuangzhou, Chinae-mail: lzy291@gdut.edu.cn  \nWANG li-juanFaculty of ComputerGuangdong University of TechnologyGuangzhou, Chinae-mail: ljwang@gdut.edu.cn\nA new hybrid self-organizing migrating algorithm based on estimation of distribution (HSOMA) is proposed to resolve the defect of premature convergence in the self-organizing migrating algorithm (SOMA) and improve the search ability of SOMA. In order to make full use of the statistical information on population and increase the diversity of migration behavior, HSOMA introduces the thought of estimation of distribution algorithm (EDA) into SOMA and reproduces the genes of new individuals by both SOMA and EDA. The proportion of the use of two algorithms is decided by a control parameter. In this way, HSOMA can increase the population diversity and improve the convergence speed. HSOMA is tested on several complex benchmark functions taken from literature and its efficiency is compared with SOMA, the continuous domain PopulationBased Incremental Learning algorithm(PBILe) and hybrid migrating behavior based self-organizing migrating algorithm(HBSOMA). On the basis of comparison it is concluded that HSOMA shows better global search ability and convergence accuracy.  \nKeywords- self-organizing migrating algorithm; estimation of distribution algorithm; premature convergence; population diversity; function optimization",
      "question_type": "algorithm comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:32",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "The provided text describes a control input \\(u(k)\\) and its relation to \\(X(k+1)\\). How does the equation for \\(X(k+1)\\) incorporate the control input \\(u(k)\\), and what parameters influence its effect?",
      "topics": [
        "control"
      ],
      "answer": "The equation \\(X(k+1) = A(k) X(k) + B(k) u(k) + D(k)\\) shows that the control input \\(u(k)\\) is incorporated through the term \\(B(k) u(k)\\). The effect of \\(u(k)\\) on \\(X(k+1)\\) is influenced by the matrix \\(B(k)\\), which includes parameters such as \\(\\Delta s\\) (change in \\(s\\)), \\(m\\) (mass), \\(f_r\\) (unspecified coefficient), \\(\\eta_{rs}\\) (unspecified efficiency), \\(R_w\\) (wheel radius), \\(GR_{TC}\\) (gear ratio), and \\(\\eta_{TC}\\) (unspecified efficiency). These parameters scale the influence of the control input \\(u(k)\\) on the resulting \\(X(k+1)\\).",
      "chunk_id": 11291,
      "paper_id": "Hierarchical Energy Management for Power-Split Plug-In HEVs Using Distance-Based Optimized Speed and SOC Profiles",
      "paper_title": "Hierarchical Energy Management for Power-Split Plug-In HEVs Using Distance-Based Optimized Speed and SOC Profiles",
      "paper_year": "2018",
      "chunk_content": "Therefore, the control input $u(k)$ is set as  \n$$\nu(k)=\\left[T_{\\text {eng }}(k), \\omega_{\\text {eng }}(k), T_{\\text {mot }}(k), F_{\\text {brake }}(k)\\right]^{T}\n$$  \nwhere the superscript T represents the transpose matrix. By replacing $v(k)^{2}$ and $v(k+1)^{2}$ with $X(k)$ and $X(k+1)$, (15) can be described by  \n$$\nX(k+1)=A(k) X(k)+B(k) u(k)+D(k)\n$$  \nwhere $A(k)=\\left(1-2 \\Delta s C_{1}\\right), \\mathrm{B}(\\mathrm{k})=\\frac{2 \\Delta s}{m}\\left[\\frac{f_{r} \\eta_{r s}}{R_{w}(Z+1)}, 0, \\frac{f_{r} \\eta_{r s}}{R_{w}}\\right.$ $\\left.G R_{T C} \\eta_{T C},-1\\right]$, and $D(k)=-2 \\Delta s C_{2}(k)$.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:34",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "Based on the information provided, what performance metrics are available to evaluate and compare the effectiveness of the GA and MARLEDA algorithms in detecting financial statement fraud?",
      "topics": [
        "comparison"
      ],
      "answer": "The GA and MARLEDA algorithms can be compared based on the following performance metrics: Accuracy (training and validation), Sensitivity, Specificity, ActiveRules, and ActiveVars. Accuracy is measured as a percentage of correctly classified data observations. Sensitivity measures the percentage of correctly classified actual fraudulent observations, while Specificity measures the percentage of correctly classified actual non-fraudulent observations. ActiveRules and ActiveVars also contribute to the overall performance assessment.",
      "chunk_id": 5157,
      "paper_id": "Detection of Financial Statement Fraud Using Evolutionary Algorithms",
      "paper_title": "Detection of Financial Statement Fraud Using Evolutionary Algorithms",
      "paper_year": "2012",
      "chunk_content": "Table 2 shows the primary training and validation classification statistics for the GA and MARLEDA in terms of the Accuracy, ActiveRules, and ActiveVars performance measures. Over the ten cross-validation iterations, both EA models demonstrate an ability to detect patterns of fraud. The GA yields an average training accuracy rate of 75.47 percent and an average validation accuracy rate of 63.75 percent, with 292 of 458 data observations correctly classified and a maximum validation accuracy of 75.56 percent for classification of the eighth validation dataset. Demonstrating a similar potential of detecting fraud, MARLEDA yields an average training accuracy of 74.26 percent and an average validation accuracy of 64.46 percent, with 295 of 458 data observations correctly classified and a maximum validation accuracy of 73.33 percent for the classification of the ninth validation dataset. Many financial statement fraud and misstatement studies, including Skousen et al. (2009) and Dechow et al. (2011), use logistic regression models. In comparison, using logistic regression with our data set and financial variables results in an accuracy rate of 58.30 percent.\nTable 3 presents supplemental validation statistics for the GA and MARLEDA. For the Sensitivity measure, the GA and MARLEDA correctly classify the actual fraudulent observations 66.38 and 68.12 percent of the time, respectively. The Specificity measure reveals that the GA and MARLEDA correctly classify the actual non-fraudulent observations 61.14 and 60.70 percent of the time, respectively.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:36",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when applied to model checking safety properties of systems modeled by graph transformations, and how does the comparison against existing meta-heuristic and evolutionary techniques manifest in terms of these metrics?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The effectiveness of the proposed Markov chain based Estimation of Distribution Algorithm (EDA) is evaluated based on its speed and accuracy in model checking safety properties. The average running time on several benchmarks is compared against existing meta-heuristic and evolutionary techniques to demonstrate the EDA's performance. Specifically, the EDA's performance is assessed by its ability to refute safety properties, as demonstrated in the context of the dining philosopher's problem.",
      "chunk_id": 9663,
      "paper_id": "Using Markov Chain Based Estimation of Distribution Algorithm for Model-Based Safety Analysis of Graph Transformation",
      "paper_title": "Using Markov Chain Based Estimation of Distribution Algorithm for Model-Based Safety Analysis of Graph Transformation",
      "paper_year": "2021",
      "chunk_content": "As mentioned before, checking a safety property $q$ in all possible states may expose the problem of state\n[IMAGE9]  \nFig.9. Comparing the accuracy of the approaches to refuting the safety properties in the (a) particular and (b) general cases for the dining philosopher's problem with 12 philosophers. maxDepth $=24$.  \n[^0]\n[^0]:    (5) https://sourceforge.net/projects/groove-and-mceda/files/impactaccuracy.pdf/, May 2021.  \n(244 000/nps), unsafe packets do not reach the internal network in the specified model of the firewalls problem.\nIn this paper, we used model checking for modelbased safety analysis of systems modeled by graph transformations. The problem of model checking is that it may face the state space explosion problem in large and complex systems. Unfortunately, recently proposed meta-heuristic and evolutionary algorithms to handle this problem suffer from the low effectiveness in terms of accuracy and speed of convergence. In exploring the state space of such systems, since allowed rules on the current state depend on only applied rules on the previous state, a Markov chain can be employed to capture this type of dependencies. Moreover, Estimation of Distribution Algorithm (EDA) is an evolutionary algorithm to guide the search for the optimal solution by learning and sampling probabilistic models through the best individuals of the population at each generation. Hence, in this paper, we proposed an approach using Markov chain based Estimation of Distribution Algorithm (EDA) to improve the accuracy and speed of convergence in model checking of safety properties of systems. To evaluate the effectiveness of the proposed approach, it was implemented in GROOVE, an open source toolset for designing and model checking graph transformation systems. The comparison of average running time of SAMEDA with other approaches on several benchmarks showed that the proposed approach has a high speed and accuracy in comparison with the existing meta-heuristic and evolutionary techniques in safety analysis of systems. Using other probabilistic models can be a future research. Also, improving the proposed fitness functions can be another piece of future work.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:38",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in the context of stock market index modeling?",
      "topics": [
        "performance"
      ],
      "answer": "The primary purpose is to develop a reliable and efficient technique using Estimation of Distribution Algorithms (EDAs) to optimize a Local Linear Wavelet Neural Network (LLWNN) for modeling the behavior of stock market indices, specifically Nasdaq-100 and S\\&P CNX NIFTY, and to determine if the resulting model provides a sufficiently accurate and robust forecast.",
      "chunk_id": 12932,
      "paper_id": "Stock index modeling using EDA based Local Linear Wavelet Neural Network",
      "paper_title": "Stock index modeling using EDA based Local Linear Wavelet Neural Network",
      "paper_year": "2005",
      "chunk_content": "Yuehui ChenSchool of Information Science and EngineeringJinan UniversityJiwei road 106, Jinan 250022, P.R.ChinaE-mail: yhchen@ujn.edu.cnXiaohui DongSchool of Information Science and EngineeringJinan UniversityJiwei road 106, Jinan 250022, P.R.ChinaE-mail: nicop2@ujn.edu.cnYaou ZhaoSchool of Information Science and EngineeringJinan UniversityJiwei road 106, Jinan 250022, P.R.ChinaE-mail: yaouzhao@yahoo.com.cn\nThe use of intelligent systems for stock market predictions has been widely established. In this paper, we investigate how the seemingly chaotic behavior of stock markets could be well represented using Local Linear Wavelet Neural Network (LLWNN) technique. To this end, we considered the Nasdaq-100 index of Nasdaq Stock Market ${ }^{\\text {TM }}$ and the S\\&P CNX NIFTY stock index. We analyzed 7 -year Nasdaq-100 main index values and 4 -year NIFTY index values. This paper investigates the development of novel reliable and efficient techniques to model the seemingly chaotic behavior of stock markets. The LLWNN are optimized by using Estimation of Distribution Algorithm (EDA). This paper investigates whether the proposed method can provide the required level of performance, which is sufficiently good and robust so as to provide a reliable forecast model for stock market indices. Experiment results shown that the model considered could represent the stock indices behavior very accurately.",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:40",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of genetic algorithms applied to the school bus routing problem, how does the algorithmic mechanism of representing a solution as binary values, as used in Niu's approach, influence the exploration of the solution space when compared to representing the solution as a vehicle routing problem with time windows, as used by Minocha and Tripathi?",
      "topics": [
        "genetic"
      ],
      "answer": "Niu's heuristic method, based on a genetic algorithm, uses a binary representation where each bit indicates whether a bus departs at a corresponding time point. This binary representation allows for exploring different combinations of bus departure times. Conversely, Minocha and Tripathi transform the school bus routing problem into a vehicle routing problem with time windows, where vertices represent stops and time windows constrain arrival times. This alternative approach directly encodes the routes and schedules, focusing on optimizing the sequence of stops within given time constraints. The binary representation in Niu's method emphasizes the selection of departure times, while the vehicle routing problem with time windows focuses on the sequence and timing of visits to bus stops.",
      "chunk_id": 12909,
      "paper_id": "Probability model to Solve the School Bus Routing Problem with Stops Selection",
      "paper_title": "Probability model to Solve the School Bus Routing Problem with Stops Selection",
      "paper_year": "2016",
      "chunk_content": "The transportation of students is an important factor in the efficient management of the services offered by the different schools especially when such transportation complexity increases as the number of students to attend. A large number of transport companies and schools in different countries are faced with the transport situation every day for students. Various laws that regulate the way in which students are transported and to where the bus stops can be placed is discussed, approved and modified continuously. The school bus routing problem is a logistics issue that requires more accountability and better service by drivers and the companies that offer the service. Bus stops are constantly changing. As students move or change of degree, it may be necessary to move, add or delete any stop on the route. Security considerations also come into play with the location of stops, for example, whether the bus turns to the right for a pickup or students crossing the street can be critical in making decision the correct location of the stop bus. An additional requirement may be that a stop should be located at a distance of no more than n meters in the direction of each student.  \nUnlike traditional vehicle routing formulations where there is a set of nodes (vertices) already established, this research focuses on the school bus routing problem where a set of potential bus stops is known. Then, determining the set of bus stops really to use is a part of the formulation in this research. The objective of this problem is (1) finding the set of bus stops to visit, (2) determine for each student what bus stop should be addressed and (3) set the path for the chosen bus stops, so that the total travel time is minimized.  \nMinocha and Tripathi [1] describe a real school bus routing problem. The authors develop a roadmap for the bus service of a school located in Rajasthan, India, so it is able to serve students in an efficient manner with maximum capacity utilization of the buses using a hybrid genetic algorithm. In this research, the authors transform the school bus routing problem with the format of a vehicle routing problem with time windows. Therefore, the vertices of the graph are the stops where students board the bus. Schittekat et al. [2] solve a school bus routing problem with stops selection using a meta-heuristic. The meta-heuristic proposed called adaptive randomized greedy search procedure, based on a method of neighborhood, use an exact algorithm to solve optimally the problem of allocation of students to the stops when the routing is defined. This meta-heuristic starts from a solution in which all stops are visited on separate routes. Therefore, the solution is represented by numbers representing the buses. The results of the meta-heuristic approach was compared with solutions found by a sequential method, with solutions obtained by applying a mixed integer programming model using commercial software, and solutions obtained by a column generation approach.  \nPerez-Rodriguez and Hernandez-Aguirre / Probability model to solve the school bus routing problem with stops selection. IJCOPI, Vol. 7, No. 1, Jan-April 2016, pp. 30-39. ISSN: 2007-1558.  \nNiu [3] focuses on how to determine an operations schedule for an urban transportation company (a real case) for the peak hours during the morning. An operations schedule at irregular intervals intends to match the demands in terms of time and increase the use of vehicles. This program allows buses depart at times different from each other. In addition, a linear programming model is formulated to minimize the waiting time and costs incurred by the use of vehicles. Finally, a heuristic method based on a genetic algorithm is developed to generate feasible solutions. The representation of the solution is binary and indicates that a bus part or not in the corresponding time point.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:42",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to solve a reliability allocation problem, what specific steps should be taken to ensure the feasibility of solutions when sampling the probabilistic model, given that the maximum number of components for each subsystem is 8 and there are cost and weight upper bounds?",
      "topics": [
        "bounds"
      ],
      "answer": "To guarantee the feasibility of solutions when sampling within an Estimation of Distribution Algorithm for reliability allocation, a repair method should be implemented. This method modifies a given individual (solution) to ensure that all constraints are satisfied. Specifically, in the context of a system with a maximum of 8 components per subsystem and cost/weight upper bounds, the repair method must check if the generated individual violates these constraints. If a violation occurs, the repair method must adjust the number of components in the subsystem or adjust component characteristics until the solution adheres to the defined cost and weight limits. The sampling method itself is dependent on the specific probabilistic model used within the EDA, such as a Gaussian Univariate Distribution as implemented in the example.",
      "chunk_id": 4824,
      "paper_id": "Redundancy Allocation problem for a Series-Parallel system using Estimation of Distribution Algorithm",
      "paper_title": "Redundancy Allocation problem for a Series-Parallel system using Estimation of Distribution Algorithm",
      "paper_year": "2012",
      "chunk_content": "4) Sampling function: Once the probabilistic model has been estimated the model is sampled to generate new individuals (new solutions), which will be used to generate a new model in the new generation. This procedure is repeated until the stopped criteria is satisfied. The type of sampling method is therefore dependent on the class of probabilistic method used. In order to guarantee the feasibility of solution\nwe used a repair method that modifies a given individual to guarantee that the constraints are satisfied.\n[IMAGE2]  \nFig. 3. Procedure of Estimation-of-the-Distribution-algorithm\nThe experiment was carried out to test the performance of the Estimation-of-Distribution-Algorithm, using a system with 20 subsystems as shown in fig. 4 , where it is necessary to determine the number of components in parallel. The maximum number of components for each subsystem is 8 . The cost and the weight upper bounds are set to 250 .\n[IMAGE3]  \nFig. 4. A considered parallel-series system  \nTABLE III\nNUMERICAL EXAMPLE DATA  \nThe data used for each component in the system is as follows:\nThe program is run in MATLAB in a Intel Core (TM) 2 Duo CPU 3.00 Hz and 4GB in RAM. For 50 generations. The number of variables was 20 for this problem, with a population of 100 and a maximum of 100 generations. However the EDA reach the optimal solution at the 50 generation.  \nTABLE IV\nNUMERICAL EXAMPLE DATA\nThe Estimation of distribution Algorithm is a new algorithm that has not tested in different fields or applications. In this research an Estimation-of-Distribution-Algorithm for a Reliability allocation Problem with high Availability and Maintainability is presented. A Gaussian Univariate Distribution is implemented and the preliminary results are presented. Although a preliminary result is presented, the algorithm seems to yield good solutions. The algorithm learn from the problem structure in order to find the best combinations for the number of components and get a optimal solution in small number of generations, however the search space for this problem is not so large so it is necessary to tested in a large space.\nFor future work, a multi-choice component for the redundancy allocation, using components with different reliability and maintainability values. A real application is considered. Also, a comparison with other meta-heuristic methods for the redundancy allocation, such as PSO and GA is considered in\norder to test the performance of the EDA. The RAP can also be considered as a multi-objective problem and the EDA could be used to find the optimal set of solutions for this problem.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:44",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, what convergence criterion is used to terminate the simulation, and how is premature convergence addressed?",
      "topics": [
        "optimization"
      ],
      "answer": "The EDA simulation terminates if the best candidate solutions satisfy a convergence criterion based on the fitness function. Another termination criterion is reaching a fixed number of generations. To avoid premature convergence, if the fitness does not change for L generations, a thresholding method is applied. This method truncates the probability of a feature j to 0.75 if it exceeds 0.85, and wraps the probability of feature j to 0.25 if it goes below 0.15.",
      "chunk_id": 10580,
      "paper_id": "An insight to the performance of estimation of distribution algorithm for multiple line outage identification",
      "paper_title": "An insight to the performance of estimation of distribution algorithm for multiple line outage identification",
      "paper_year": "2018",
      "chunk_content": "EDA is one of the types stochastic optimization algorithms, where it optimizes a function by keeping track of the statistics of the population. EDA follows iterative probabilistic approach to find the sub-optimal solution. This is the reason that in each iteration the new population is generated, instead of keeping the former population alive. In each generation, the population with strong statistics is selected, so that the new population is more healthier. EDA has three main steps of the algorithm, i.e., 1) how to select the healthier candidate solutions from the total population, 2) what statistics are to be calculated from the selected solutions, and 3) how to use the calculated statistics to produce the new population. Keeping in mind the above discussion, EDA performs following steps to find the solution:  \n1. Generate initial population. The initial population is obtained by sampling according to the uniform distribution. As the line outage detection problem is a binary problem, the population will be binary in nature, where each ' 1 ' will represent if that particular line is in outage and every ' 0 ' will represent the line in normal condition.\n2. According to the fitness function, evaluate the current population. For the said problem, the fitness function is shown in (14).\n3. Sort the individuals according to the fitness inside the current population.\n4. If the best candidate solutions (the one with least fitness in the line outage problem) satisfy the convergence criterion then terminate the simulation. There are some other termination criterion as well, e.g.,  \nTable 2\nIEEE bus systems' details.  \nthe number of generations. In the case of number of generations, the simulation run for a fix number of iterations.\n5. Select the best candidate solutions (individuals) from current population. As the fitness function in (14) is a minimization function, the candidate solutions with minimum fitness will be selected, according to selection probability. The selection probability is an input to the function. In our case, we have set the selection probability equal to 0.5 , i.e., $50 \\%$ of the best individuals will be selected.\n6. On the basis of best candidate solutions, estimate the probability distribution of each feature, i.e., the probability distribution of ' 1 's and ' 0 's in each column of the selected population.\n7. If the fitness does not change for $L$ many generations, apply thresholding, i.e., truncate the probability of a feature $j$ to 0.75 if it exceeds 0.85. Similarly, wrap the probability of a feature $j$ to 0.25 if it goes below 0.15 . In this way, the pre-mature convergence can be avoided, which eventually leads to local minima or maxima problems.\n[IMAGE1]  \nFig. 3. Success generation ratio for IEEE 14-bus system.\n[IMAGE2]  \nTable 3\nTime consumed (in seconds) by different algorithms for IEEE-14 bus system.\n8. Generate new candidate solutions (individuals) on the basis of new probability vector obtained from the selected candidate solutions in the current population. Replace the bad candidate solutions with newly generated candidate solutions and generate a new population having better candidate solutions as compared to the previous population.\n9. Go to step 2 and repeat all the steps from 2 to 6 Fig. 1.  \nThe flow diagram of EDA is shown in Fig. 2.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:46",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "When using the UMDA for permutation-based problems, how does the performance of the algorithm using the $I^{*}$ representation compare to using the $\\sigma$ representation, specifically regarding the types of problem instances where each excels?",
      "topics": [
        "representation",
        "UMDA",
        "PFSP",
        "QAP"
      ],
      "answer": "The UMDA using the $I^{*}$ representation obtains better results in almost every tested PFSP (Permutation Flow Shop Problem) instance, being the best option in 18 out of 22 instances. However, when solving QAP (Quadratic Assignment Problem) instances, the UMDA performs better using the permutation representation denoted as FORMULA_146, making the permutation-vector representation the better option for QAP problems. With $\\sigma$ representation, the sampling procedure must be adapted to avoid drawing unfeasible (non-permutation) solutions due to the repetition of items, a constraint not present when using $I^{*}$ for PFSP instances or FORMULA_146 for QAP instances.",
      "chunk_id": 9937,
      "paper_id": "Alternative Representations for Codifying Solutions in Permutation-Based Problems",
      "paper_title": "Alternative Representations for Codifying Solutions in Permutation-Based Problems",
      "paper_year": "2020",
      "chunk_content": "Regarding the UMDA, $n$ being the size of the problem, the population size was set to $10 n, 5 n$ best solutions were selected by truncation and $10 n$ new solutions were sampled from the probability model at each iteration. The algorithm stops after $100 n$ iterations. This parameters were set following the usual trends and without fine-tuning the behavior of the algorithm.  \nIn order to draw solid conclusions, each algorithm (UMDA under the different representations) was run on each instance 20 times, and median values were collected.\nIn the first experiment, the UMDA was run under $\\sigma, I$ and $I^{*}$ representations. In the case of $\\sigma$, when sampling solutions, using the classical procedure it is possible to draw unfeasible solutions (non-permutation) because of the repetition of the items. Therefore, the sampling was adapted to hold the permutation nature of solutions (once an item has been sampled, set the probability of sampling that item in any other position to zero, as described in Fig. 1).  \nResults can be observed in Tables I and II. When optimizing PFSP instances, the UMDA over $I^{*}$ obtains better results in almost every tested PFSP instance, being the best option in 18 instances out of 22. In contrast, when solving QAP instances, the performance of the UMDA over the permutation representation, FORMULA_146, is better, thus, being the permutation-vector representation systematically the best option for this problem.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:48",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the EDAMA for the DAPFSP, what data structures are required to represent a solution, and how does the chosen representation differ from previous EDA implementations for similar problems?",
      "topics": [
        "comparison"
      ],
      "answer": "The EDAMA implementation for the DAPFSP requires a bi-vector-based representation of solutions. This includes a vector representing the job sequence and an additional 'factory assignment vector' indicating the factory assigned to each job. This differs from the solution representation used in previous work on the DPFSP, which only utilized a single vector for job sequencing, lacking the explicit factory assignment component needed for the DAPFSP.",
      "chunk_id": 12689,
      "paper_id": "An Estimation of Distribution Algorithm-Based Memetic Algorithm for the Distributed Assembly Permutation Flow-Shop Scheduling Problem",
      "paper_title": "An Estimation of Distribution Algorithm-Based Memetic Algorithm for the Distributed Assembly Permutation Flow-Shop Scheduling Problem",
      "paper_year": "2016",
      "chunk_content": "In our previous works, several EDA-based algorithms with different probability models have been proposed for the multimode RCPSP [36], HFSP [39], FJSP [40], and DPFSP [23], respectively. In this paper, an effective EDA-based MA (EDAMA) is proposed for solving the DAPFSP with the criterion of minimizing the maximum completion time. The new contributions of this paper are as follows.  \n1) To execute the searching operator efficiently, a novel bi-vector-based method is proposed to represent a solution for the DAPFSP. Compared with the solution representation in [23], an additional vector, i.e., the factory assignment vector is adopted in this paper to represent the corresponding factory for each job.\n2) Because of an additional assembly stage, the DAPFSP is more complex than the DPFSP studied in [23]. To avoid invalid searching operators, critical path of the DAPFSP is analyzed in this paper. Accordingly, a critical-path-based local search (CPLS) strategy is proposed to perform exploitation in the EDAMA. The effectiveness of a CPLS strategy is demonstrated by comparative experiments.\n3) In the DAPFSP, each job belongs to a defined product. A uniform sampling mechanism for the EDA in [23] is not helpful to start an assembly stage of products early. Therefore, a novel selective-enhancing sampling mechanism is proposed for the EDAMA in this paper. The results from the analysis of variance (ANOVA) show that the novel selective-enhancing sampling mechanism is significantly better than the uniform sampling mechanism [23].\n4) In the EDAMA, the EDA-based exploration and CPLS-based exploitation are incorporated within the MA framework. Based on 1710 benchmark instances, numerical simulations and comparisons with the existing algorithms show the effectiveness of the EDAMA for  \n[IMAGE_0]  \nFig. 1. Illustration of the DAPFSP.\nsolving the DAPFSP. In addition, the best-known solutions of 181 instances are updated by the EDAMA.\nThe remainder of this paper is organized as follows. In Section II, the DAPFSP is described. Then, the EDAMA for the DAPFSP is introduced in Section III. Numerical results and comparisons are provided in Section IV. Finally, the conclusion is given in Section V.",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:50",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when using the unsupervised estimation of Bayesian network algorithm (UEBNA)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The unsupervised estimation of Bayesian network algorithm (UEBNA) is evaluated against other EDAs. The chunk does not specify the exact metrics used for evaluation.",
      "chunk_id": 10097,
      "paper_id": "Bivariate estimation-of-distribution algorithms can find an exponential number of optima",
      "paper_title": "Bivariate estimation-of-distribution algorithms can find an exponential number of optima",
      "paper_year": "2023",
      "chunk_content": "A key feature of evolutionary algorithms (EAs) is their applicability to a wide range of optimization problems. EAs require little problem-specific knowledge and generally provide the user with a  \n[^0]BDBI\ngood solution. Since many real-world optimization problems are multimodal [1, 11, 23], it is desirable for an EA to return multiple solutions. This way, the user also gains precious insight into their problem.  \nUnfortunately, classical population-based EAs tend to converge to a single solution, due to strong selection operators and due to a long-known phenomenon called genetic drift [4]. In order to counteract this behavior, different techniques have been introduced, commonly subsumed under the term niching [15, 17, 23]. These techniques maintain diversity in the population and assist in finding and keeping multiple good solutions. While this approach is useful for increasing the number of different solutions, it still limits the insights gained about the underlying problem, as the only information the EA returns is the solutions themselves. As such, it only provides information about areas of the search space that it has visited and does not propose further promising regions.  \nA different algorithmic approach that aims to additionally incorporate information about the entire search space is the framework of estimation-of-distribution algorithms (EDAs; [21]). Instead of an explicit set of solutions, EDAs maintain a probabilistic model of the search space. This model acts as a solution-generating mechanism and reflects information about which parts of the search space seem more favorable than others. An EDA evolves its model based on samples drawn from it. This way, the model is refined such that it generates better solutions with higher probability. In the end, an EDA returns the best solutions found as well as its model.  \nEDAs are commonly classified by the power of their model [21]. This results in the following trade-off: an EDA with a simple model performs an update quickly but may be badly suited to accurately represent the distribution of good solutions. In contrast, the update of an EDA with a complex model is computationally expensive, but the model is better capable of representing good solutions. The complexity of a model is determined by how many dependencies it can detect among different problem variables. For example, a univariate EDA assumes independence of all problem variables, whereas a bivariate EDA can represent dependencies among pairs of variables. We go into detail about these types of EDAs in Section 1.1.  \nWhile increasing the complexity of an EDA's model is useful for finding optima in a larger class of problems [20], it is not evident that an increased model complexity is also useful for finding multiple optima or representing them adequately in the model. In fact, EDAs have been designed specifically with the intention of being used for multimodal optimization. Pena et al. [18] introduce the unsupervised estimation of Bayesian network algorithm (UEBNA), which uses unsupervised learning in order to generate the Bayesian network of its model. The algorithm is tested against other EDAs and evaluated  \n[^0]:    Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\nGECCO '20, July 8-12, 2020, Cancun, Mexico",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:52",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically concerning the integration of Ant Colony System (ACS) principles?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective is to enhance the search capabilities of Estimation of Distribution Algorithms (EDAs) by incorporating mechanisms from Ant Colony System (ACS). The hybrid EDA$_{\\text{ACS}}$ algorithm iteratively refines solutions using a filter strategy and local search, constructs pheromone trails based on local best solutions (representing a probability model), and employs an ACS solution construction method for generating members in subsequent iterations. A jump strategy is included to escape local optima. The algorithm aims to minimize the makespan ($C_{\\max}$) in permutation flow shop scheduling problems, denoted as $Fm \\mid prmu \\mid C_{\\max}$, by determining an optimal job ordering.",
      "chunk_id": 5227,
      "paper_id": "A hybrid EDA with ACS for solving permutation flow shop scheduling",
      "paper_title": "A hybrid EDA with ACS for solving permutation flow shop scheduling",
      "paper_year": "2012",
      "chunk_content": "The proposed hybrid algorithm, $\\mathrm{EDA}_{\\mathrm{ACS}}$, integrates the ideas of ACS into EDA. In each iteration of the searching process, it applies a new filter strategy and a local search method to update the local best solution; then, based on the local best solution, it generates pheromone trails (a probability model) and applies a solution construction method of ACS, according to the pheromone trails, to generate members for the next iteration. In addition, a new jump strategy is developed to help the search escape if the search becomes trapped at a local optimum. Computational experiments on Taillard's benchmark data sets will be performed to evaluate the effectiveness of the proposed algorithm by comparing its performance with populationbased search algorithms, such as genetic algorithms, ant colony optimization, and particle swarm optimization.  \nThe remainder of the paper is organized as follows: Section 2 gives the problem statement. The proposed $\\mathrm{EDA}_{\\text {ACS }}$ is described in Section 3. Section 4 provides computational experiments, and the conclusion is presented in Section 5.\nPFSP-makespan can be denoted as $F m \\mid p r m u \\mid C_{\\max }$ using the notation proposed by Graham et al. [17]; given a set $J$ of $n$ jobs, a set $M$ of $m$ machines, and processing times $p_{i j}$ for each job $j$ on each machine $i$, the problem consists of scheduling all $n$ jobs at each one of the $m$ machines. The processing sequence of the jobs must be the same on all the machines, and each job $j$ can only start its execution on a machine $i$ if both the previous job on the same machine $i$ and the same job $j$ on the previous machine $i-1$ have already been processed. Furthermore, the order in which a job must pass through the machines is predefined and identical for all the jobs. The objective of this problem is to determine a job ordering that minimizes the completion time of the last job in\nthe last machine, called the makespan. Although Garey et al. [1] showed that the problem with two machines can be solved in polynomial time, the general case with $m$ machines is known to be NP-hard. Given a permutation schedule $j_{1}, \\ldots$, $j_{n}$ for an $m$ machine flow shop, the completion time of job $j_{k}$ at machine $i, C_{i j_{k}}$, can be computed easily through a set of recursive equations:\n$C_{i j_{1}}=\\sum_{l=1}^{i} p_{i j_{1}} \\quad i=1,2, \\ldots, m$\n$C_{1 j_{k}}=\\sum_{l=1}^{k} p_{1 j_{l}} \\quad k=1,2, \\ldots, n$\n$C_{i j_{k}}=\\max \\left(C_{i-1 j_{k}}, C_{i j_{k-1}}\\right)+p_{i j_{k}} \\quad i=2, \\ldots, m ; \\mathrm{k}=2, \\ldots, n$  \nThen makespan, $C_{\\max }$, is obtained by $C_{\\max }=C_{m j_{n}}$.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:09:54",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of multi-objective optimization algorithms for dynamic multi-objective problems (DMOPs), what fundamental properties distinguish Pareto-dominance based algorithms such as non-dominated sorting genetic algorithm II (NSGA-II) and strength Pareto evolutionary algorithm (SPEA2) from indicator-based algorithms like indicator-based EA (IBEA) and approximation-guided EMO (AGE) regarding their approach to determining individual retention for the next iteration?",
      "topics": [
        "genetic"
      ],
      "answer": "Pareto-dominance based algorithms, such as NSGA-II and SPEA2, utilize the dominance concept to determine whether obtained individuals can be retained for the next iteration. This approach focuses on whether one solution dominates another. In contrast, indicator-based algorithms, like IBEA and AGE, are designed according to performance metrics such as the hypervolume, the epsilon indicator, and the R2 indicator. Therefore, the key distinction lies in the criteria for retaining individuals: Pareto-dominance uses a direct comparison of solution dominance, while indicator-based algorithms use quantitative performance metrics to guide the optimization process.",
      "chunk_id": 2011,
      "paper_id": "Solving dynamic multi-objective problems using polynomial fitting-based prediction algorithm",
      "paper_title": "Solving dynamic multi-objective problems using polynomial fitting-based prediction algorithm",
      "paper_year": "2022",
      "chunk_content": "Change detection is a core part of the framework, since it determines the timing of environmental change and whether there is a need to adopt environmental response mechanisms. Dynamic detection techniques include re-evaluating solutions [2] and checking population statistical information [3] through sensors. The former is more popular, since it is simple and easy to implement, but it also suffers from noise sensitivity. On the contrary, the latter is not sensitive to noise, but it needs some control parameters. Besides, sensors are placed appropriately for change detection [4] and need to be tested on various problems or applications. It is difficult to select an appropriate detection technique, since each method has its advantages and limitations for different DMOPs.\nApart from dynamic detection, multi-objective algorithm is also one of the key components for solving DMOPs. The existing research on multi-objective algorithms mainly focuses on three types described as follows. The first category is Pareto dominated-based algorithms, which utilize the dominance concept to determine whether the obtained individuals can be retained for next iteration. Various classical and representative algorithms have been proposed recently years, such as non-dominated sorting genetic algorithm II (NSGA-II) [5], NSGA-III [6] and strength Pareto evolutionary algorithm (SPEA2)[7]. In addition, some swarm intelligence algorithms are also adopted for multi-objective optimization, such as multi-objective grasshopper optimization algorithm (MOGOA) [8], and multi-objective multi-verse optimizer (MOMVO) [9], and so on. Pareto-dominance strategies perform well in different applications, but suffer from the risk of generating excessive boundary individuals in some cases.  \nThe second category is indicator-based algorithms, which are designed according to performance metrics. The hypervolume [10], the epsilon indicator and the R2 have been widely employed to design optimization algorithms, such as indicatorbased EA (IBEA) [11], approximation-guided EMO (AGE) [12]. The last category is decomposition-based algorithms, which are designed by decomposing an MOP into several sub-problems and solving them simultaneously. Typically, MOEA based on decomposition (MOEA/D) [13] and multi-objective particle swarm optimization algorithm based on decomposition (MPSOD) [14]. This kind of algorithm is effective, but depends heavily on weight vectors.  \nIn addition, the research on complicated real-world problems is also important for evaluating the algorithmic effectiveness and guiding the algorithmic design. Some practical applications in various areas are described briefly as follows. Mirjalili et al. [15] assessed the performance of algorithms by solving several popular engineering design problems including four-bar truss design, speed reducer design, disk brake design, welded beam design, cantilever beam design and brushless DC wheel motor. Wang et al. [16] investigated urban bus scheduling problem considering route, number of vehicles and drivers. Besides, there exist many different optimization models, such as change detection in SAR images [17], elevator group control[18] and so on.",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:09:56",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners configure the population size and number of generations when using UMDA, Tree-EDA, and EBNA?",
      "topics": [
        "optimization"
      ],
      "answer": "Practitioners should consider two settings for population size and generations: I) a population size of 500 with 30 generations, and II) a population size of 1000 with 60 generations. These settings aim to keep the number of function evaluations relatively small, as determined after preliminary experiments. Note that the choice of setting can impact the performance of algorithms like EBNA, Tree-EDA, and UMDA, with EBNA generally achieving better results.",
      "chunk_id": 7492,
      "paper_id": "Using Probabilistic Dependencies Improves the Search of Conductance-Based Compartmental Neuron Models",
      "paper_title": "Using Probabilistic Dependencies Improves the Search of Conductance-Based Compartmental Neuron Models",
      "paper_year": "2010",
      "chunk_content": "The main objective of our experiments is to investigate whether the use of interactions, represented by the graphical models used by EDAs, improves the results achieved when no interactions are taken into account. We assume that,  \nTable 2. Target neuron models selected from the database and a number of properties and measures determined from their simulation  \nif EDAs that represent probabilistic dependencies, i.e. Tree-EDA and EBNA, outperform those that do not represent such dependencies, i.e. UMDA, then the problem exhibits interactions between the variables and these interactions are important to solve the problems.  \nTo test the algorithms, we select 10 functions defined by selecting different target neuron models from the data sets. The target neurons, shown in Table 2, are all bursting neurons during the spontaneous activity and have been selected trying to cover different patterns of electrical activity of the neurons. Under spontaneous activity, the first five neurons have the following relevant characteristics: for 720973: a high burst period and small burst duration; for 1522117: a high burst period and high burst duration; for 833389: the smallest burst period; for 965338: one of the smallest burst durations; for 436821: one of the highest number of maxima. The rest of the target neurons have been randomly selected from the set of bursting neurons.  \nIn the table, Index is the index of the neuron in the database, $T_{s}, T_{3}$ and $T_{6}$ are the types of electrical activity under the different experimental conditions, coded as silent neuron (0), spiking neuron (1), bursting neuron (2). Similarly $f q_{s}, f q_{3}$ and $f q_{6}$ represent the frequencies under the different experimental conditions.  \nWe conducted 30 experiments of UMDA, Tree-EDA and EBNA for each of the 10 functions and with two different settings: I) Population size is 500 and 30 generations; II) Population size is 1000 and 60 generations are conducted. These settings were determined aiming to keep the number of function evaluations relatively small, and after preliminary experiments were conducted. The number of times each algorithm found the optimum for all the functions are shown in Table 3. It can be seen in the table that only one of the problems is relatively easier to solve by the methods. Instance 1071411 is particularly complex for all the methods. However, the best results are clearly achieved by EBNA that outperforms both the Tree-EDA and UMDA.  \nTo determine whether differences between the algorithms are statistically significant, we have used the Kruskal-Wallis test to accept or reject the null hypothesis that the samples have been generated from the same probability distribution. The test significance level was 0.01 . For all instances, except instances 833389 and 436821, significant statistical differences have been found between  \nTable 3. Number of times each algorithm found the optimum for each of the 10 functions  \n[IMAGE1]  \nFig. 2. Distance of the solutions found by the different EDAs to the best solutions for: a) EDA setting $(500-30)$. b) EDA setting FORMULA_60.\nthe EBNA and the other two EDAs for the two settings. There were not significant statistical differences between EBNA and Tree-EDA for instance 436821 for both EDA settings, and between EBNA and the other two EDAs for instance 833389 , setting II.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:09:58",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the multi-objective evolutionary algorithm based on decomposition (MOEA/D) developed for the hybrid flow-shop with buffer constraint, what specific aspects of the algorithm's mathematical properties, such as convergence, are implicitly leveraged for energy efficiency in the flowshop scheduling problem?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The description indicates the MOEA/D algorithm optimizes for multiple objectives, including nonprocessing energy in a hybrid flow-shop. While explicit convergence guarantees or mathematical proofs for MOEA/D itself are not detailed, the algorithm's effectiveness relies on the decomposition strategy to manage multiple objectives. The implicit assumption is that the Pareto-based approach guides the search towards solutions that balance makespan and energy consumption, although specific mathematical bounds on the trade-off are not provided. The algorithm's success hinges on its ability to efficiently explore the solution space and identify solutions that simultaneously minimize both makespan and energy usage, but the precise mathematical properties ensuring this efficiency are not elaborated upon.",
      "chunk_id": 1944,
      "paper_id": "Scheduling of energy-efficient distributed blocking flowshop using pareto-based estimation of distribution algorithm",
      "paper_title": "Scheduling of energy-efficient distributed blocking flowshop using pareto-based estimation of distribution algorithm",
      "paper_year": "2022",
      "chunk_content": "Recently, the energy-conscious flowshop scheduling problem has gained extensive attention. A variety of machine-based policies and strategies have been investigated to improve energy efficiency. Mouzon et al. (2007) observed that the non-bottleneck machines would waste a huge amount of energy in idle time. They constructed a manufacturing framework with turn-on and turn-off strategies for non-bottleneck machines to minimize the energy cost and other objectives. Limited by the actual situation on-site, the turn-on and turn-off strategy may not applicable since machine status cannot be frequently switched during the manufacturing process. Wang et al. (2018) found that converting blocking time to idle time could save energy while keeping makespan unvaried. They integrated this strategy into a parallel variable neighborhood search algorithm (PNVS) to optimize the energy consumption and makespan for a BFSP. Similar to Wang et al. (2018), Jiang and Zhang (Jiang \\& Zhang, 2019) have investigated the property of nonprocessing energy in a hybrid flow-shop with buffer constraint and developed a multi-objective evolutionary algorithm based on decomposition (MOEA/D). Besides, Fazli and Wang (Fazli Khalaf \\& Wang, 2018) proposed a framework that decreased the energy demand through on-site renewables and energy storage strategy, which was proven to be effective to optimize the electricity cost for a two-stage stochastic flowshop. Recently, some researchers considered that machines can consume different energy due to different operation patterns. Thereby, a speed control mechanism for machine operation was proposed (Fang et al., 2011, 2013). When the mechanism requires a machine to processes at a higher speed, the energy consumption grows whereas the processing time reduces. Obviously, the setting of speed level will cause a conflict between the processing time and energy consumption. Based on this framework, some scheduling models have been further proposed and investigated (Lei et al., 2018). For an energy-aware flowshop scheduling problem, Ding et al. (2016) developed an extended NEHInsertion procedure, which was able to realize the synchronous adjustment of processing speed when executing the job insertion procedure for finding a better position in solution space. Jiang and Wang (Jiang \\& Wang, 2019) proposed an improved multi-objective evolutionary algorithm (IMOEA) to optimize the flowshop with makespan and energy consumption criteria. Oztop et al. (2020) proposed a multi-objective variable block insertion heuristic to study the trade-off between TFT and energy consumption of a permutation flowshop. Yuksel et al. (2020) proposed a multi-objective discrete artificial bee colony algorithm to minimize total tardiness and energy consumption for a no-wait flowshop scheduling problem (NWPFSP). Besides, Schulz et al. (2019) proposed three energy-saving strategies, which not only consider the varied process speed of the machine but also the varied energy unit price and the peak-valley load as energy-related decision variables. The proposed strategies were integrated to optimize the multi-objective for a hybrid flowshop.  \nConcerning the energy-aware scheduling problems in a distributed manufacturing environment, the literature is rather limited. Deng and Wang et al. (2016) investigated the DFSP with multi-objective developed a competitive memetic algorithm (CMA) to minimize the",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:00",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is a key difference between Word2Vec and Doc2Vec in representing text, and how does this difference impact their application in optimization problems described by text?",
      "topics": [
        "search"
      ],
      "answer": "Word2Vec generates vector representations for individual words, while Doc2Vec generates a fixed-length vector representation for larger blocks of text such as sentences, paragraphs, or entire documents. This allows Doc2Vec to encode semantic information for larger textual units, which is expected to be useful for solving optimization problems described by text using Estimation of Distribution Algorithms without losing semantic relationships among words.",
      "chunk_id": 10268,
      "paper_id": "Language model based interactive estimation of distribution algorithm",
      "paper_title": "Language model based interactive estimation of distribution algorithm",
      "paper_year": "2020",
      "chunk_content": "As far as we know, language models have not been studied in EC/IEC to solve problems described by documents/texts. However, many language models have been proposed over the past decades to model text in the field of Natural Language Processing (NLP), e.g. Bag-of-Words (BOW) [45], TF-IDF [46], Latent Semantic Analysis (LSA) [47], and Probabilistic Latent Semantic Analysis (PLSA) [47]. Moreover, many studies employed word-based models to a wide range of applications [48,49]. Recently, Latent Dirichlet Allocation (LDA) [50], Word2Vec [18], and Doc2Vec [19] have achieved remarkable results in many NLP and machine learning (ML) tasks [51-53]. Particularly, the Doc2Vec achieves state-of-the-art best performance on sentiment analysis [19,54,55]. The focus here is Doc2Vec since it will be used to encode individuals in our work.  \nWord2Vec is a powerful tool for distributed representation of words with vectors and was presented by Google in 2013. This model uses deep learning to simplify the processing of text to the vector operation in FORMULA_10-dimensional vector space, and the similarity of text semantics is expressed by that in vector space. Word2Vec\nis widely used in NLP tasks due to its high efficiency and rich semantic information [56-58]. As an extension of Word2Vec, Doc2Vec generates a fixed-length feature as the representation for large blocks of text, e.g. sentences, paragraphs, or entire documents.  \nInspired by recent work on learning vector representations of words with neural networks [18,59,60], Le et al. [19] proposed Doc2Vec by concatenating the document vector with a number of word vectors from a document and predicted the following words in the given context; they conducted the research with neural-network-based paragraph vectors, also known as neural language models, under an unsupervised framework.  \nIf an item described with words can be represented with vectors by using Doc2Vec, the word/document-described optimization problems are expected to be effectively solved by using EC/IEC without losing semantic relationships among words.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:02",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "For implementing the described Estimation of Distribution Algorithm (EDA), what specific value is assigned to the probability of mutation ($P_m$), and how many generations ($g$) without improvement will cause the algorithm to stop?",
      "topics": [
        "mutation"
      ],
      "answer": "The probability of mutation, denoted as $P_m$, is set to 0.02. The algorithm will terminate if the best individual in the population remains unchanged for 100 generations, represented by $g=100$.",
      "chunk_id": 933,
      "paper_id": "An EDA-based Community Detection in Complex Networks",
      "paper_title": "An EDA-based Community Detection in Complex Networks",
      "paper_year": "2014",
      "chunk_content": "In this section, the proposed algorithm is assessed and compared with other community detection algorithms. We use the library of SNAP ${ }^{1}$ for executing Girvan-Newman (GN) [12], Clauset-Newman-Moore (CNM) [4], and Infomap [3] algorithms.  \nWe use the Normalized Mutual Information (NMI) to evaluate the results [13]. Let $A$ and $B$ be two partitions of a network and $\\mathbf{N}$ be the confusion matrix, where the rows correspond to the partition $A$ and the columns correspond to the partition $B$. The element of $\\mathbf{N}, N_{i}$, is the number of nodes of the community $i$ of the partition $A$ that appear in the community $j$ of the partition $B$. The normalized mutual information that is based on information theory is defined as follows:  \n$$\nI(A, B)=\\frac{-2 \\sum_{i=1}^{c_{A}} N_{j=1}^{c_{B}} N_{i j} \\log \\left(\\frac{N_{i j} N}{N_{i} N_{j}}\\right)}{K_{i=1}^{c_{A}} N_{i} \\log \\left(\\frac{N_{i j}}{N}\\right)+\\sum_{j=1}^{c_{B}} N_{j} \\log \\left(\\frac{N_{j j}}{N}\\right)}\n$$  \nwhere $N$ is the number of nodes, $c_{A}$ is the number communities in the partition $A$, and $c_{B}$ is the number communities in the partition $B . N_{i}$ represents the sum over row $I$, and $N_{j}$ expresses the sum over column $j$ of matrix $\\mathbf{N} . A$ is considered as actual partition and $B$ as detected partition. The value of $I(A, B)$ is between 0 to 1 . If the detected communities and actual communities are equal, then $I(A, B)$ takes the value 1 . If the detected communities are entirely independent of the actual communities, then $I(A, B)$ takes the value 0 .  \nAll of the experiments have been performed on a machine with Core2 Duo 1.83 GHz processor and 2 GB RAM. We use two synthetic and three real data sets with ground truth communities to assess the quality of our approach. Both modularity and community score (with $r=1.5$ ) are used in the experiments. The parameters of our algorithm are set as follows. The population size is 300 , the probability of mutation $P_{\\mathrm{m}}=0.02$, tournament size is 10 , the number of selected members for computing probability vectors is 50 , and the algorithm will stop if the best individual of the population has not changed during $g=100$ last generations. We denote our algorithm with modularity objective function by Ours-Q and with community score by Ours-CS. For each data set, we run our algorithm 10 times and the average NMI of these runs is reported.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:04",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach is outlined to assess the psDSMGA-IIc algorithm against other evolutionary methods?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The benchmarking approach involves comparing psDSMGA-IIc with psDSMGA-II, psDSMGA-IIe, psLTGA, and P3 on a test problem set extended from DSMGA-II papers. The experiments are limited to 8 hours, with a time-based stop condition to address the influence of fitness-caching. For each problem type, 30 independent runs are executed, and the experiments are conducted on a HP Elite Desk800 3.4 GHz 8GB RAM server with Intel Core i7-4770 CPU and Windows 7 64-bit installed.",
      "chunk_id": 9838,
      "paper_id": "Comparative Mixing for DSMGA-II",
      "paper_title": "Comparative Mixing for DSMGA-II",
      "paper_year": "2020",
      "chunk_content": "In this section, the results of the performed research are presented. We had two main objectives. First, we wish to check if the proposed psDSMGA-IIc performs better than psDSMGA-II and psDSMGAIIe for NK-landscapes problems, and at least equally well for other considered problems. The second research objective was to compare psDSMGA-IIc with other up-to-date evolutionary methods that are psLTGA and P3.  \nThe test problem set was taken from DSMGA-II papers [2, 9]. We only extended this set by problems of greater sizes. Our experiments were limited to 8 hours. The time-based stop condition was chosen because of the influence of fitness-caching [15]. Thus, to ensure the fairness of the comparison, all technical assumptions from [14, 15] were met. We used HP Elite Desk800 3.4 GHz 8GB RAM server with Intel Core i7-4770 CPU and Windows 764 -bit installed to carry out all experiments. For each problem type, 30 independent runs were executed. The data pack that contains the full source code, the settings files, and detailed experiment results are available at https://github.com/kommar/psDSMGA-IIc. The source code of each competing method was downloaded from the Author's code repository and included in the data pack.  \nTable 2: Folded trap function FORMULA_60 values",
      "question_type": "evaluation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:06",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for scheduling semiconductor final tests (SFTS) when considering the dynamic configuration of testers, handlers, and accessories?",
      "topics": [
        "control"
      ],
      "answer": "The primary purpose of the algorithmic approach is to efficiently schedule jobs in the SFTS problem, which involves managing resources like testers ($\\mathbf{R}^{1}$), handlers ($\\mathbf{R}^{2}$), and accessories ($\\mathbf{R}^{3}$) under constraints such as non-preemption and limited resource availability ($Q_{r}$). The approach must address the dynamic machine configuration, where various operations require different machine types ($m \\in \\mathbf{M}_{o}$) with dissimilar processing times ($P_{o m}$), and sequence-dependent setup times ($S_{l m}$) are incurred when switching between machine types. The goal is to optimize the scheduling of jobs through functional testing, while adhering to resource limitations and machine configuration constraints.",
      "chunk_id": 910,
      "paper_id": "The cooperative estimation of distribution algorithm  a novel approach for semiconductor final test scheduling problems",
      "paper_title": "The cooperative estimation of distribution algorithm: a novel approach for semiconductor final test scheduling problems",
      "paper_year": "2014",
      "chunk_content": "The SFTS problem shares common characteristics with S-MRS (shown in Fig. 1) and is one of the most complex and common scheduling problems (Wu and Chien 2008b). The semiconductor final test considers the IC in lots released from on-hand WIP or the forecasting output of the assembly (i.e., the preceding operation to the final test). Each job $j \\in \\mathbf{J}$ generally passes through the sequential processes, including a set of operations $o \\in \\mathbf{O}_{j}$ (e.g., functional test, burn-in, scan, bake, tape and reel, and package and load) for a shortterm planning horizon (Uzsoy et al. (991). Because of differing product specifications, various jobs may require differing steps of functional testing. Functional testing is the main operation site of the final test process and includes room tests, hot tests, and cold tests. After an operation starts processing a\nparticular resource, it must continue until completion, which is a non-preemption constraint.  \nSpecific products can only be tested using appropriate machine configurations of testers $\\left(\\mathbf{R}^{1}\\right)$, handlers $\\left(\\mathbf{R}^{2}\\right)$, and accessories $\\left(\\mathbf{R}^{3}\\right)$. Test heads connect the tester (a central processing unit that loads test programs) to the packaged IC devices to test their functions. Handlers with built-in temperature control systems, which enable tests under various temperatures, use suitable material handling devices, called boats, to load ICs by lots packed in plastic antistatic trays or tubes. The boats release ICs from the trays or tubes, and the suction devices (called nests) lift and load the ICs onto an electrical interface (called the load board) between the packaged circuits and the tester. After the functional test, the tested ICs are placed into the classified trays (or tubes) according to the results (i.e., passed or failed). The board and the nest are the accessories (or kit). Resources for SFTS problems are expensive and can only be prepared in limited amounts; for example, $Q_{r}, r \\in \\mathbf{R}^{n}, n \\in\\{1,2,3\\}$. Thus, the number of operations that overlap in time and require a particular resource must not exceed the total amount of available resources.  \nConversely, machine configuration is dynamic. Various operations may require differing machine (configuration) types for processes, whereas more than one machine type can process one operation, which indicates the virtual unrelated parallel machine environment (Chien and Chen 2007a,b). Various machine types, $m=\\left(r^{1}, \\ldots, r^{n}, \\ldots, r^{N}\\right) \\in$ $\\mathbf{M}_{o}, r^{n} \\in \\mathbf{R}^{n}, \\quad n \\in\\{1,2,3\\}$ with dissimilar processing time (e.g., $P_{o m}$ ) can perform an operation $o$. However, it is impossible to configure resources arbitrarily to form a machine type. Consequently, the universal set of all machine types is $\\mathbf{M}=\\bigcup_{o \\in \\mathbf{O}_{j}, j \\in \\mathbf{J}} \\mathbf{M}_{o} \\subseteq \\mathbf{R}^{1} \\times \\mathbf{R}^{2} \\times \\mathbf{R}^{3}$. A sequencedependent setup time (SDST), denoted by $S_{l m}$, is further  \nFig. 1 Illustrative scheme of S-MRSs\n[IMAGE0]  \nrequired (Wu and Chien 2008b) to disassemble the original machine type $l$ and assemble and calibrate the new machine type FORMULA_19 for the incoming operation. The setup activities include resource assembly and disassembly, temperature change, software download, and calibration. The detailed modeling of SFTS problems was presented by Wu and Chien (2008b).",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:08",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms, how does the algorithmic mechanism of the proposed hybrid multi-objective estimation of distribution algorithm combining locally linear embedding (HMOEDA_LLE) utilize the locally linear embedding (LLE) approach, and what role does the entropy-based criterion play in its operation?",
      "topics": [
        "search"
      ],
      "answer": "The hybrid multi-objective estimation of distribution algorithm combining locally linear embedding (HMOEDA_LLE) uses locally linear embedding (LLE) with a small neighbor parameter to learn the local geometry of the manifold. The algorithm switches between two phases: an early evolutionary stage using traditional crossover and mutation, and a later stage where new offspring are sampled from probability models based on statistical distribution information. The entropy-based criterion determines the switching time between these two phases of evolutionary search.",
      "chunk_id": 581,
      "paper_id": "HMOEDA LLE  A hybrid multi-objective estimation of distribution algorithm combining locally linear embedding",
      "paper_title": "HMOEDA LLE  A hybrid multi-objective estimation of distribution algorithm combining locally linear embedding",
      "paper_year": "2014",
      "chunk_content": "Yuzhen Zhang, Guangming Dai, Lei Peng, Maocai WangSchool of Computer ScienceChina University of GeosciencesWuhan, China\nBased on the regularity that: the Pareto set of a continuous m-objectives problem is a piecewise continuous ( $\\mathrm{m}-1$ )dimensional manifold, a novel hybrid multi-objective optimization algorithm is proposed in this paper. In the early evolutionary stage, traditional crossover and mutation operations are used to produce offspring, in addition, the locally linear embedding (LLE) with small neighbor parameter approach is introduced to learn the local geometry of the manifold. When certain regularity in population's distribution is detected, new offspring are sampled from the probability models created by the statistical distribution information. An entropy-based criterion is imported to determine the switching time of the two different phases of evolutionary search. The proposed hybrid multiobjective estimation of distribution algorithm combining locally linear embedding (HMOEDA_LLE) adopts several widely used test problems to conduct the comparison experiments with two state-of-the-art multi-objective evolutionary algorithms NSGA-II and RM-MEDA. The simulated results show the effectiveness of the entropy-based criterion and the proposed algorithm has better optimization performance.  \nKeywords-regularity; multi-objective optimization; locally linear embedding; entropy-based criterion",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:10",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm with Local Sampling strategies (EDALS) for community detection, how should practitioners utilize the local community structure property, where \\(k_{i}^{\\text {in}}\\) represents the sum of connections within a subgraph \\(S\\) and \\(k_{i}^{\\text {out}}\\) represents the sum of connections outside the subgraph \\(S\\), to guide the sampling strategy?",
      "topics": [
        "evolutionary"
      ],
      "answer": "In EDALS, practitioners should design a local sampling strategy that prioritizes subgraphs \\(S\\) where the sum of internal connections \\(\\sum_{i \\in S} k_{i}^{\\text {in}}\\) is greater than the sum of external connections \\(\\sum_{i \\in S} k_{i}^{\\text {out}}\\). This reflects the property that interconnections within a community are typically more numerous than connections to the rest of the network. This can be achieved by sampling nodes with a higher probability of belonging to a community based on this inequality, thereby improving the speed and accuracy of community detection.",
      "chunk_id": 12306,
      "paper_id": "Estimation of Distribution Algorithm with Local Sampling Strategy for Community Detection in Complex Networks",
      "paper_title": "Estimation of Distribution Algorithm with Local Sampling Strategy for Community Detection in Complex Networks",
      "paper_year": "2016",
      "chunk_content": "In this paper, an estimation of distribution algorithm with local sampling strategies (EDALS) is proposed to solve community detection problems. In EDALS, the phenomenon of local community structure was considered by designing a local sampling strategy to improve both the speed and the accuracy for community detection. At the same time, a simulated annealing selection was adopted to enhance population diversity during the evolutionary procedure.  \nExperimental results on some ${ }^{18)}$ artificial networks, ${ }^{19)}$ LFR networks, and ${ }^{20)}$ authentic networks illustrate the effectiveness of EDALS. Additionally, comparisons of EDALS with other state-of-the-art algorithms demonstrate that the proposed algorithm is competitive.  \nThe remainder of this paper is presented as follows. Some related works are discussed in Sect. 2. A detailed description of the proposed method is given in Sect. 3. In Sect. 4, we demonstrate the experiment on the EDALS in comparison with relative algorithms. In Sect. 5, we summarize the conclusions.\nA network can be represented as $G=(V, E)$, where $V$ and $E$ indicate the vertices and links, respectively. Assume that $A$ is the adjacency matrix of $G$. If there is a link between the nodes $i$ and $j, A_{i, j}=1$; otherwise, $A_{i, j}=0$. Suppose that $S$ is a subgraph that belongs to $G$, and $i$ is a node that belongs to $S . k_{i}$ is the degree of the vertex $i ; k_{i}^{\\text {in }}=\\sum_{i, j \\in S} A_{i, j}, k_{i}^{\\text {out }}=$ $\\sum_{i \\in, j \\in S} A_{i, j} .{ }^{21)}$ The community of a network usually has the following property:  \n$$\n\\sum_{i \\in S} k_{i}^{\\text {in }}>\\sum_{i \\in S} k_{i}^{\\text {out }}\n$$  \nIt means that the interconnections in the community are more than the out-connections toward the rest of the network.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:12",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the center point-based prediction strategy for dynamic multiobjective optimization (DMOEAs), how are the moving step sizes, denoted by $\\alpha$, determined for the predicted populations $P_{i}^{1}$ and $P_{i}^{2}$, and what is the significance of these values in adapting to environmental changes?",
      "topics": [
        "search"
      ],
      "answer": "In the center point-based prediction strategy, two populations, $P_{i}^{1}$ and $P_{i}^{2}$, are used to predict the population's movement in response to environmental changes. For $P_{i}^{1}$, the moving step size $\\alpha$ is set to 1, indicating that it completely follows the center point's movement trend from the previous environmental change. This signifies an accurate response to changes very similar to the previous one. For $P_{i}^{2}$, which is designed for environmental changes similar to but different from the previous one, the moving step size $\\alpha$ is defined as a random number between 0.5 and 1.5. A value of 0.5 represents a more slight change compared to the previous environment, while 1.5 represents a more drastic change. This range allows the algorithm to adapt to varying degrees of environmental change.",
      "chunk_id": 1687,
      "paper_id": "Combining a hybrid prediction strategy and a mutation strategy for dynamic multiobjective optimization",
      "paper_title": "Combining a hybrid prediction strategy and a mutation strategy for dynamic multiobjective optimization",
      "paper_year": "2022",
      "chunk_content": "Environmental changes present linear and regularity in many cases, and the current environment may have the same or similar degree of change with the previous last environment. In these cases, we assume that the center points moving trend represents the population's moving trend. In other words, the other members of the population are supposed to have a similar moving trend with the center point. Therefore, the prediction for the moving trend of the center point is vital. At the same time, we should take into consideration that similar degree of change but not totally the same between the current environment and the previous last one. So when an environmental change is detected, we should use the useful information (the center point's moving trend) from the previous environmental change with varying degrees.  \nIn this subsection, we follow the principle that the moving direction between the two consecutive environments is the same, but the moving  \n[IMAGE1]  \nFig. 2. Schematic diagram of the predicted population generation of population when $\\alpha=0.5,1.0$ and 1.5 .\nstep size is different due to the degree of change between two consecutive environments to develop the prediction strategy. The center pointbased prediction strategy uses two populations, $P_{i}^{1}$ and $P_{i}^{2}$, respectively, to implement prediction with the same moving direction but different moving step sizes.\n$P_{i}^{1}$ completely follows the step size of the center point's movement trend in the last environmental change, namely $\\alpha=1$. It means that our algorithm can accurately respond to very similar changes to the previous last environmental change. Because of its simplicity and clarity, this usage is widespread in many existing first-order difference linear prediction models in DMOEAs.\n$P_{i}^{2}$ is specifically designed for situations where the current environmental change is similar to but different from the previous last one. Because the similarity between continuous environmental changes has not been accurately measured, the moving step size of $P_{i}^{2}$ along the moving direction is uncertain. The current change is normally smoother or more drastic than the previous last one. The moving step size $(\\alpha)$ is therefore defined as a random number between 0.5 (refers to more slightly change) and 1.5 (refers to more drastic change). Fig. 2 represents the schematic diagram of the predicted population generation when $\\alpha$ is $0.5,1.0$ and 1.5 respectively in the population search process after the occurrence of new environmental changes.  \nThe process is given in Algorithm 1. First, the moving direction $V_{t}$ is",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:14",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "According to the details in the chunk, what advantages does the NEDA method have over other Estimation of Distribution Algorithms in solving the Traveling Salesman Problem?",
      "topics": [
        "performance"
      ],
      "answer": "The NEDA algorithm is described as having efficiency, excellent performance, good stability, and fast convergence speed when solving the Traveling Salesman Problem, suggesting these are advantages over other Estimation of Distribution Algorithms.",
      "chunk_id": 375,
      "paper_id": "An Novel Estimation of Distribution Algorithm for TSP",
      "paper_title": "An Novel Estimation of Distribution Algorithm for TSP",
      "paper_year": "2013",
      "chunk_content": "In this paper, an improved estimation of distribution algorithm for TSP was proposed. NEDA is an improved algorithm with efficiency and excellent performance in solving traveling salesman problem. On the whole, the proposed algorithm can achieve satisfied solutions, the stability of the algorithm is good and the convergence speed is fast. There is also some problems need further study such as dynamic TSP and others.\nThis research is supported by supported by Guangxi Experiment Centre of Science and Technology under grant No. LGZXKF201208.\n10.4028/www.scientific.net/AMM.373-375\n10.4028/www.scientific.net/AMM.373-375.1089",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:16",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing MUEDA for large-scale global optimization, what is the observed relationship between computational cost and dimensionality, and how does this compare to algorithms like DE and PSO?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "MUEDA",
        "Computational Cost",
        "Dimensionality",
        "DE",
        "PSO",
        "Scalability"
      ],
      "answer": "The computational cost of MUEDA tends to increase linearly with dimensionality. In contrast, DE (Differential Evolution) and PSO (Particle Swarm Optimization) exhibit significantly lower efficiencies, especially as the dimensionality, denoted as 'D', becomes very large. MUEDA's scaling is more efficient than breeder GA, which scales like D ln(D).",
      "chunk_id": 6789,
      "paper_id": "A Self-adaptive Mixed Distribution Based Uni-variate Estimation of Distribution Algorithm for Large Scale Global Optimization",
      "paper_title": "A Self-adaptive Mixed Distribution Based Uni-variate Estimation of Distribution Algorithm for Large Scale Global Optimization",
      "paper_year": "2009",
      "chunk_content": "In order to study the scalability of MUEDA, we compare it with cooperative coevolution based LSGO approach Cooperative coevolution differential evolution II (DECC-II) on the 1500 dimensional problems. The reasons of selecting DECC-II in this experiment are as follows: 1) the cooperative coevolution appears to be a very promising method and has becomes very popular in LSGO domain [31]; 2) Compared with the classical cooperative coevolution based algorithms FEPCC [15] and CCGA [23], DECC-II has performed better on most problems [36]. In DECC-II, the variables selected for optimization in one iteration are chosen randomly with constant size 100. The other parameters chosen for experiment are the same as [36]. The comparison of evolution process between MUEDA and DECC-II on 1500 dimensional function optimization is shown in Fig. 8, and the comparison of final error between the best solution and true global optimum is shown in Table 7.  \nIt is apparent that for unimodal function 1 and function 2, the proposed algorithm outperforms DECC-II not only in convergence speed, but also in the accuracy of results obtained. This is especially true for function 2 whose variables are linked. Similar conclusion can be drawn for multimodal functions globally, although the results achieved by DECC-II and proposed algorithm on function 4 (i.e. shift Rastrigin) are comparable. The reasons for this result have been analyzed in the first experiment. It is observed that the proposed algorithm works well on function 5 and 6 within such low computational cost even for 1500 D . In summary, the proposed algorithm provides a steady and accurate performance even for problems scaling to 1500 dimensions.\nIn the traditional analysis of $[18,19]$, the efficiency of the search method is tested on the problems with different dimensionality setting. Efficiency is defined on number of function evaluations needed to solve the problem [18]. In order to evaluate the efficiency of MUEDA, the results for multimodal problems - Ackley function (function 9 in Table 1) and Giewangk function (function 10 in Table 1) are presented in Table 8, 9 and Fig. 9. Moreover, the effective algorithms DE and PSO are also implemented in order to provide comparison results. For fair comparison, we  \n[IMAGE7]  \nFig. 8 Evolutionary curves of 1500 D problems\nchoose the same population size 200 for all algorithms and the most commonly used extensive parameters for respective algorithms.  \nIt is apparent that the computational cost of MUEDA tends to increase linearly as the dimensionality arises. For DE and PSO, the efficiencies are much less. This is especially true when $D$ is very large. It is evident that handling large scale optimization problems is a difficult task for evolutionary algorithms. Compared to breeder  \nTable 7 Experimental results for $1500 D$ cec08 function optimization  \nStatistical experimental results of 25 runs  \nTable 8 Efficiency test on Ackley function  \nTermination criterion is $10^{-3}$.  \nTable 9 Efficiency test on Giewangk function  \nTermination criterion is $10^{-3}$.  \n[IMAGE8]  \nFig. 9 Efficiency test on Ackley function on the left and Giewangk function on the right  \nGA scaling like $D \\ln (D)$, MUEDA shows excellent efficiency, which scales linearly. Thus, the advantages of MUEDA on LSGO problems are easily observable.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:18",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the Royal Road function and the Trap-5 function be used to evaluate the ability of an Estimation of Distribution Algorithm (EDA) to identify and utilize building blocks (BBs)?",
      "topics": [
        "design"
      ],
      "answer": "The Royal Road function, defined as \\(E_{k}\\left(b_{1}, \\ldots, b_{k}\\right)\\), where \\(E_{k} = f\\) if \\(u = k\\) and 0 otherwise, with \\(u = \\sum_{i=1}^{k} b_{i}\\) and \\(f = k\\), assesses the EDA's capability to compose BBs in a non-deceptive environment. Performance on the Royal Road function indicates the EDA's aptitude for solving problems with simple BB structures, where the optimal solution consists of all ones. The Trap-5 function, defined piecewise with \\(f_{\\text {high }}\\) when \\(u=k\\) and \\(f_{\\text {low }}-\\left(\\left(u \\times f_{\\text {low }}\\right) /(k-1)\\right)\\) otherwise, with \\(f_{\\text {high }}>f_{\\text {low }}\\), evaluates the EDA's ability to overcome deceptive landscapes where gradient-based optimizers are misled towards suboptimal solutions composed of zeros, while the global optimum requires all ones. Comparing the EDA's performance on both functions reveals its robustness in handling both simple and deceptive BB structures.",
      "chunk_id": 12059,
      "paper_id": "The use of explicit building blocks in evolutionary computation",
      "paper_title": "The use of explicit building blocks in evolutionary computation",
      "paper_year": "2016",
      "chunk_content": "There are two parts of the experiment. The first part exhibits the behaviour of BBs processing by comparing the BBIC algorithm to the sGA. The second part compares the performance of the BBIC algorithm to a group of competent algorithms. They are sGA-FC, CSM, BOA, and hBOA. The sGA is used as the basic reference. The details of the first part of the experiments are described in the following sections.\nMost of the problems used in the experiment are synthetic functions. The problems are classified into two categories: non-deceptive and deceptive. A deceptive problem lures the algorithm away from the ideal solution. Generally, deceptive problems are more difficult to solve than non-deceptive problems. It is difficult to claim what algorithm is suitable for a particular class of problems. Nevertheless, an experiment can be conducted to support the statement. In  \nthis experiment, the Royal Road function (non-deceptive) (Howard \\& Sheppard, 2004) and the Trap-5 function (deceptive) (Beaudoin, Verel, Collard, \\& Escazut, 2006) were used. These two functions belong to the class of additively decomposable functions (ADFs).  \nThe Royal Road function was designed to test the ability of GAs to compose BBs. The general $k$-bit Royal Road is defined as  \n$$\nE_{k}\\left(b_{1}, \\ldots, b_{k}\\right)= \\begin{cases}f ; & \\text { if } u=k \\\\ 0 ; & \\text { otherwise }\\end{cases}\n$$  \nwhere $b_{i}$ is in $\\{0,1\\}, u=\\sum_{i=1}^{k} b_{i}$, and $f=k$.\nADFs denoted by $E_{m \\times k}$ are defined as  \n$$\nE_{m \\times k}\\left(k_{1} \\ldots k_{m}\\right)=\\sum_{i=1}^{m} E_{k}\\left(k_{i}\\right), \\quad k_{i} \\in\\{0,1\\}^{k}\n$$  \nVariables $m$ and $k$ are varied to produce a number of test functions. This problem is difficult because a hint about the BBs is not provided. The optimal solution is composed of all ones. This problem is representative of problems that have a simple BB structure.  \nThe well-known Trap functions were designed to study BBs and linkage problems in GAs. The general $k$-bit trap functions are defined as  \n$$\n\\begin{aligned}\n& E_{k}\\left(b_{1}, \\ldots, b_{k}\\right) \\\\\n& \\quad= \\begin{cases}f_{\\text {high }} & ; \\text { if } u=k \\\\\nf_{\\text {low }}-\\left(\\left(u \\times f_{\\text {low }}\\right) /(k-1)\\right) & ; \\text { otherwise }\\end{cases}\n\\end{aligned}\n$$  \nwhere $b_{i}$ is in $\\{0,1\\}, u=\\sum_{i=1}^{k} b_{i}$, and $f_{\\text {high }}>f_{\\text {low }}$. Usually, $f_{\\text {high }}$ is set to $k$ and $f_{\\text {low }}$ is set to $k-1$. The Trap problem is defined using Equation (2).  \nThe Trap functions fool the gradient-based optimisers to favour zeros, but the optimal solution is composed of all ones.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:21",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the improved method for positional collision repairing in the context of protein folding, and how does it differ from the traditional backtracking-based approach?",
      "topics": [
        "search"
      ],
      "answer": "The primary objective of the improved method is to reduce the computational cost associated with repairing positional collisions, especially for long-sequence proteins. Unlike the traditional backtracking-based method, which searches all empty positions within invalid closed areas, the improved method introduces a feasibility detection procedure before selecting the direction for the next residue. This detection, utilizing a search approach similar to Floodfill, aims to avoid entering invalid closed areas, thereby saving computational time.",
      "chunk_id": 7611,
      "paper_id": "A Hybrid EDA for Protein Folding Based on HP Model. IEEJ",
      "paper_title": "A Hybrid EDA for Protein Folding Based on HP Model",
      "paper_year": "2010",
      "chunk_content": "method In Ref. 8, a backtracking algorithm was introduced to repair the positional collisions. It utilizes backtracking strategy to search the feasible positions for collision residues in the folding procedure. This method has been shown to be a simple and efficient means of positional collision repairing for protein folding. But in practice, we found that the computational cost of repairing is very high for long-sequence instances of more than 50 residues.  \nFor a long-sequence protein, there are many closed areas in the 2-D folding procedure (or closed spaces in the 3-D circumstance). Taking the 2-D circumstance as example, as shown in Fig. 4(a), we assume that there is a closed area formed by residues 1 to $n$. If the folding procedure selects right (R) as the next direction for the $n+1$ residue, it will enter the closed area. Thus, even if the size of this closed area cannot satisfy the length of the remaining residues (called as an invalid closed area), the traditional backtracking-based method will still search all empty positions in the closed area by the backtracking operation. This will lead to a large wastage of computational time. According to our experiment, this phenomenon takes place with a high probability in repairing procedures for long-sequence proteins.\n4.2. Improved method To solve the above problem, in the improved method, a detection for feasibility is introduced. The detection procedure is implemented before selecting the direction for the next residue to avoid entering an invalid closed area. The main idea of the proposed detection procedure is described as follows:  \n1. The current boundaries in the lattice are defined as shown in Fig. 4(a); the scale of the boundary coordinates is larger than the current filled area and will change with the current folding procedure. They can be used to check whether the folding procedure enters a closed area. If the detection meets the current boundaries, the folding procedure will not enter a closed area.\n2. Before selecting a certain direction for next residue, the folding procedure utilizes a search approach, similar to the Floodfill strategy, to detect empty positions connected to this direction, i.e. those empty positions that could be arrived through this direction.\n[IMAGE_3]  \nFig. 4. (a) Illustration of closed-area detection. (b) The situation that need to implement backtracking",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:22",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms (EDAs), how does the algorithmic mechanism of replacing the explicit population representation with a probability distribution fundamentally differ from Genetic Algorithms (GAs) in generating new candidate solutions?",
      "topics": [
        "optimization"
      ],
      "answer": "In Genetic Algorithms (GAs), a population of candidate solutions is maintained as an array of objects, such as bit strings or vectors of real numbers. New candidate solutions are generated by combining and modifying existing solutions stochastically, but the underlying probability distribution of these new solutions is usually not explicitly specified. In contrast, Estimation of Distribution Algorithms (EDAs) replace this explicit population representation with a probability distribution over the choices available at each position in the vector that represents a population member. A population in EDA is approximated with a probability distribution, and new candidate solutions are obtained by sampling this distribution, enabling EDA to solve nonlinear variable coupling problems for complex optimization, a capability that traditional GAs may lack.",
      "chunk_id": 1213,
      "paper_id": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
      "paper_title": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
      "paper_year": "2014",
      "chunk_content": "Reliability is the ability of software system to perform its required functions under stated conditions for a specified period of time, and it is an important characteristic inherent in the concept of software quality. It is intimately connected with defects and faults. As more and more faults are encountered, the software reliability will decrease. Software reliability generally changes with time, and these changes can be treated as a time series process.  \nArtificial neural networks (ANN) have general nonlinear mapping capabilities, and have increasingly attracted attention in the field of time series predicting [1-3]. In [4], the reliability of the systems can be predicted by feed-forward multi-layer ANN and radial basis function ANN respectively. The ANN technology has better prediction performance than the autoregressive integrated moving average (ARIMA) approach. In [5], ANN has contributed significantly to software reliability prediction, and which achieved better prediction performance than traditional statistical models. In [6], the counter-propagation and back-propagation ANN models were used to estimate parameters of a reliability distribution with only a small dataset. The experimental results show that the  \n[^0]proposed approach improves the accuracy of reliability predicting. In [7], the system reliability may be predicted by a hybrid learning neural fuzzy system. Numerical results demonstrate that the proposed model achieved more accurate predicting results than ARIMA and generalized regression ANN model (GRNN). However, the ANN suffers from a number of weaknesses, e.g., it is based on gradient descent, and it is easy to local minima.  \nRecently, support vector machines (SVMs) [8-11] have been widely applied to solve nonlinear predicting problems in many fields. With the introduction of $\\varepsilon$-insensitive loss function, it has been also extended to solve nonlinear regression estimation problems, such as new techniques known as support vector regression (SVR) [12]. In [13], the SVM was used to solve financial time series problems. The experimental results demonstrate that SVM forecasts better than back propagation (BP) algorithm. In [14], a two-step kernel learning method based on SVR was proposed for predicting financial time series. The results confirm the advantage of SVR. However, although SVR has very good learning performance and generalization ability, there is no structured way to determine the parameters of SVR.  \nEstimation of distribution algorithms (EDA) [15], sometimes called probabilistic model-building genetic algorithm (GA) [16], have emerged as a generalization of GA, for overcoming the two main problems: poor performance in certain deceptive problems and the difficulty of mathematically modeling a huge number of algorithm variants [17]. In GA, a population of candidate solutions  \n[^0]:     Corresponding author. Tel.: +86 02788664026.  \nE-mail address: jincong@mail.ccnu.edu.cn (C. Jin).  \nto a problem is maintained as part of the search for an optimum solution. This population is typically represented explicitly as an array of objects. Depending on the specifics of the GA, the objects might be bit strings, vectors of real numbers or some custom representation. In EDA, this explicit representation of the population is replaced with a probability distribution over the choices available at each position in the vector that represents a population member. Moreover, in GA, new candidate solutions are often generated by combining and modifying existing solutions in a stochastic way. The underlying probability distribution of new solutions over the space of possible solutions is usually not explicitly specified. In EDA, a population may be approximated with a probability distribution and new candidate solutions can be obtained by sampling this distribution. Compared with traditional GA, EDA can solve nonlinear variable coupling problems for complex optimization.",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:24",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an online order-batching algorithm using an S-Shape route in a warehouse, how should practitioners determine when to release a batch given that there is no information about the quantity or characteristics of future orders, and that the splitting of an order into multiple batches is prohibited?",
      "topics": [
        "routing"
      ],
      "answer": "The implementation must form and release batches without complete information on future orders' characteristics and arrival times. Since splitting orders is prohibited, the algorithm must respect the capacity of the picking device. A batch is released when the device's capacity is exhausted or when a decision is made to process existing orders without considering future arrivals, based on factors like minimizing the average turnover time of all customer orders. The start time of an order is the same as the start time of the batch to which the order is assigned, and once a picker starts a tour, it must be completed without interruption.",
      "chunk_id": 12092,
      "paper_id": "Finding Interactions or Relationships Between Customer Orders for Building Better Batches by Means of an Estimation of Distribution Algorithm-based approach for the Online Order Batching Problem",
      "paper_title": "Finding Interactions or Relationships Between Customer Orders for Building Better Batches by Means of an Estimation of Distribution Algorithm-based approach for the Online Order Batching Problem",
      "paper_year": "2016",
      "chunk_content": "Below is an explanation of the online order-batching problem based on [12]. During the picking process, which is being analyzed in this paper, the operators (pickers) start at a depot, and the picker normally walks through the warehouse and picks up  \narticles from different storage locations. Afterwards, the picker returns to the depot and hands over the picked articles. The picker uses an S-Shape route to find and collect articles. There is no limitation if we consider the S-Shape route for this research because this route has been widely used in industrial environments and it is easy to implement and understand. In addition, the S-Shape route has been recognized as a benchmark in the related literature. Figure 1 demonstrates the straightforward character of the routing scheme for a set of articles to be picked. The black rectangles symbolize the corresponding locations where articles have to be picked (pick locations). We note that from a theoretical-planning point of view it would be desirable to solve the order batching and the picker routing problems simultaneously. However, practically, this appears to be unrealistic due to the complexity and the size of the problem analyzed. A decision on the S-Shape route has already been made, which will serve as input for a subsequent order batching decision.  \nPicking devices are generally used to complete the order picking process. Consequently, different orders can be combined until the capacity of the device is exhausted. The splitting of an order into two or more batches is prohibited, as it would result in an additional unacceptable sorting effort. It would increase the activities in the warehouse for the pickers and, consequently, the service time of the supply chain would increase. Finally, if the picker has already started a tour, it must be completed without interruption.  \nIn online batching there is no information given about the quantity or the characteristics of the orders that will arrive. The decision about which orders should be processed directly has to be made without considering information about future incoming orders. The point in time when an order becomes available is called arrival time. The start time (release time) of a batch is the point when an order picker starts to process this batch. The start time of an order is the same as the start time of the batch to which the order is assigned. The point in time when the order picker returns to the depot after collecting all articles is called the completion time of a batch or of an order. The customer order waiting time can be determined as the length of the time between the arrival time and the start time of an order. The turnover time (response time) is the amount of time that an order stays in the system, i.e., the time period between the completion and the start time of an order. This measure can be seen as an indicator of the service level, which can be defined as the number of orders that can be processed in a given period of time. If the number of arriving orders is too large for processing each customer order separately in an appropriate amount of time, customer orders must be combined into batches. This paper focuses on situations of grouping customer orders into batches such that the average turnover time of all customer orders is minimized as well as discussing the situation where there is a single order picker and all batches must be processed one after another,. Although here it is analyzed for academic purposes, a single order picker is relevant in order to consider idle time situations while customer orders are arriving in the warehouse. Furthermore, a single order picker is necessary in order to be consistent within the results detailed below.  \nAny algorithm for the online order-batching problem has to form and release batches without having complete information on the characteristics and arrival times of future orders.\n[IMAGE_0]  \nFigure 1. Example of an S-Shape route in a single-block warehouse.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:26",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of comparing algorithms, what are the drawbacks of using the number of generations or the number of solution evaluations as comparison criteria for Estimation of Distribution Algorithms (EDAs)?",
      "topics": [
        "comparison"
      ],
      "answer": "Using the number of generations as a comparison criterion overlooks the possibility that some methods, particularly EDAs, may perform additional, computationally costly operations in each generation. Similarly, comparing by the number of solution evaluations can be unreliable because different solution representations (such as those used by Evolutionary Algorithms/EDAs and Variable Neighborhood Search (VNS)) may have varying computational costs per evaluation.",
      "chunk_id": 7077,
      "paper_id": "Estimation of Distribution Algorithms for the Firefighter Problem",
      "paper_title": "Estimation of Distribution Algorithms for the Firefighter Problem",
      "paper_year": "2017",
      "chunk_content": "Table 1. Median value of the saved nodes obtained in the experiments.\nTable 2. Median value of the saved nodes obtained in the experiments.\nThe comparison with respect to the running time of the algorithms was chosen because of a large variety of methods used for comparison (the same approach was used in the paper on VNS [11]). Two other commonly used comparison criteria, the number of generations and the number of solution evaluations, are not well-suited for the comparisons made in this paper. Comparison by the number of generations overlooks the fact that certain methods may perform additional, costly computations in each generation, which is not uncommon in the EDAs. Comparison by the number of solution evaluations suffers from the same problem and also may not be reliable in the case of different solution representations (e.g. those used by the EA/EDA and the VNS).  \nFrom the results presented in the tables it can be seen, that for smaller graphs the VNS is very effective, but for larger graphs the State-Position EDA performs best. The tables contain also the value of the Family-Wise Error Rate for the hypothesis that the median values produced by the best performing method for a given $N_{v}$ are statistically different than those produced by the other methods. This FWER value was calculated as $1-\\prod_{i}\\left(1-v_{i}\\right)$, where $v_{i}$ are p -values obtained in pairwise comparisons between the best performing method and each of the other methods. The calculated value is the upper bound for the probability that at least one of the comparison methods attains the same median values as the best-performing one. For graph sizes of $N_{v}=1250$ and  \nmore the calculated FWER values are at most $1.04 \\cdot 10^{-2}$. This shows that the difference between the State-Position EDA with the Square function and the other methods is statistically significant. For $N_{v}=1000$ the State-Position EDA still produced the best result, but because of the small difference from the results produced by the VNS the FWER is high, so the statistical significance cannot be confirmed. For $N_{v}=500$ and 750 the State-Position EDA was outperformed by the VNS, with the difference statistically significant in both cases.  \nThe results produced by the algorithms for $N_{v}=2500$ with respect to the running time are shown in Fig. 1. Note, that in case when multiple variants or parametrizations of one method were tested, only one variant is presented in the figure, the one that produced the best result at $T_{\\max }=900 \\mathrm{~s}$. The algorithms presented in the figure are the ACO, the EA using the OBX crossover, the Simple Mallows, the EH-PBIL with $P_{\\text {unif }}=0.4$, the State-Position EDA with the Square function and the VNS.\n[IMAGE0]  \nFig. 1. Results produced by the algorithms for $N_{v}=2500$ with respect to the running time. Note, that in case when multiple variants or parametrizations of one method were tested, only one variant is presented in the figure, the one that produced the best result at FORMULA_246.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:28",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the Bayesian Optimization Algorithm (BOA) differ from traditional genetic algorithms in generating new solutions?",
      "topics": [
        "genetic"
      ],
      "answer": "BOA, as an Estimation of Distribution Algorithm (EDA), replaces traditional genetic operators like crossover and mutation with a probabilistic model learned from promising solutions. This learned Bayesian network (BN) is then sampled to generate new candidate solutions for the next population. The BN represents the joint probability distribution of random variables, where the probability of a variable depends on its parents, as described by the formula: p(x1, x2, ..., xn) = product from i=1 to n of p(xi | parents(xi)).",
      "chunk_id": 9733,
      "paper_id": "A novel approach to solve AI planning problems in graph transformations",
      "paper_title": "A novel approach to solve AI planning problems in graph transformations",
      "paper_year": "2020",
      "chunk_content": "simulation results confirm that PMCO can outperform PSO in terms of the numerical accuracy and the computational time. CBA also presents a graph communication topology and a consensus protocol used in BA to share the velocity information of the bats. Experimental results on several benchmarks show the faster convergence rate of CBA compared with the original BA.\nBayesian Optimization Algorithm (BOA) is one type of EDA that builds a Bayesian network (BN) through the joint distribution of good partial solutions (Pelikan et al., 2003). EDA belongs to evolutionary algorithms which have found optimum solutions for some hard optimization problems such as Capacitated Vehicle Routing Problems (Tsutsui and Wilson, 2004), Software Testing (Sagarna and Lozano, 2006), Protein Folding (Santana et al., 2008) and Searching the Optimum Path in 3D Spaces (Yuan et al., 2007). In EDA, instead of the traditional genetic operators like crossover and mutation, a probabilistic model is learned from the promising solutions. The learned model is then used to generate new solutions to participate in the next population. BN is a graphical probabilistic model which includes (1) a set of random variables specifying the nodes of the network. (2) A set of directed links between all pairs X and Y of nodes determining conditional dependencies between them. (3) For each node, a table specifying a conditional probability according to the different values of its parents. Formally, a BN represents the Joint Probability Distribution (JPD) of $n$ random variables. Formula (1) shows how to compute every entry in the JPD through the information in the BN:  \n$$\np\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} p\\left(x_{i} \\mid \\text { parents }\\left(x_{i}\\right)\\right)\n$$  \nThe details of a BN may be determined by a domain expert or learned from data using machine learning algorithms. There are many approaches such as Bayesian methods, quasi-Bayesian methods, and non-Bayesian methods to learn variables and conditional dependencies between them. Moreover, one method to learn conditional probabilities is to use relative frequencies observed in the data based on the maximum likelihood hypothesis.  \nBOA produces the initial population randomly. To generate the next population, BOA performs the following operations: (1) it evaluates the current population by the fitness function. (2) It selects a set of most promising solutions and learns a BN through these solutions. (3) It samples the learned BN to generate new candidate solutions and incorporates them into the population using a replacement approach. If the termination criteria such as observing an optimum solution or reaching to a maximum number of iterations are not satisfied, BOA generates again the next population (Pelikan et al., 2003).",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:30",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the $\\varepsilon$-SVR algorithm described, what data structures are required to efficiently manage the Lagrange multipliers and kernel function calculations, considering the constraints and optimization problem?",
      "topics": [
        "complexity"
      ],
      "answer": "The implementation requires data structures to store and manipulate the Lagrange multipliers $\\alpha_{i}$ and $\\alpha_{i}^{*}$, subject to the constraints $0 \\leq \\alpha_{i} \\leq C$ and $0 \\leq \\alpha_{i}^{*} \\leq C$, along with the equality constraint $\\sum_{i=1}^{n}(\\alpha_{i} - \\alpha_{i}^{*}) = 0$. Efficient storage of the kernel function $K(x_{i}, x_{j}) = \\phi(x_{i}) * \\phi(x_{j})$ is also crucial, potentially using a kernel matrix to avoid redundant computations during the maximization of the dual function $R(\\alpha_{i}, \\alpha_{i}^{*})$ and the evaluation of the decision function $f(x, \\alpha_{i}, \\alpha_{i}^{*}) = \\sum_{i=1}^{n}(\\alpha_{i} - \\alpha_{i}^{*}) K(x, x_{i}) + b$.",
      "chunk_id": 1215,
      "paper_id": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
      "paper_title": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
      "paper_year": "2014",
      "chunk_content": "The performance of SVR depends on the rational optimization of parameters, and the optimization of these parameters is important to predict accurately. The traditional methods of optimizing parameters are: experience selection method (ESM), gradient descent method (GDM), and Bayesian method (BM). However, these methods have their own disadvantages. For example, ESM requires a large amount of experience and domain knowledge in order to obtain the appropriate parameters, and otherwise it is difficult to obtain the appropriate parameters. GDM is very sensitive to the initial point. In addition, GDM is a linear search method, and it is easy to fall into local minimum. Disadvantage of BM is to need some priori knowledge of parameter space for optimizing parameters, and it also needs more computation and computational complexity. In addition, this technique does not guarantee the outcome of better parameters. In fact, some researches have studied how to apply intelligence method to optimize parameters of SVR [18-20].  \nSuppose $\\left\\{\\left(x_{1}, d_{1}\\right),\\left(x_{2}, d_{2}\\right), \\ldots,\\left(x_{n}, d_{n}\\right)\\right\\} \\subset R^{\\mathrm{m}} \\times R$ is training set, where $R^{\\mathrm{m}}$ is the space of the input features $x_{i}$, and $d_{i}$ is the phenomenon under investigation, i.e., the actual value. In $\\varepsilon$-SVR [19], the goal is to find a function $f(x)$ whose deviation from each target $d_{i}$ is at most $\\varepsilon$ for all training data, and at the same time, is as \"flat\" as possible. For the sake of clarity, we consider the following objective function in the linear case, i.e., $F: R^{\\mathrm{m}} \\rightarrow R$, such that\n$y=f(x)=w \\phi_{i}(x)+b$\nwhere $\\phi_{i}(x)$ is the input features, and $w$ and $b$ are coefficients. The coefficients ( $w$ and $b$ ) are estimated by minimizing the following regularized risk function:\n$R_{\\text {SVR }}(C)=R_{\\text {emp }}+\\frac{1}{2}\\|w\\|^{2}=C \\frac{1}{n} \\sum_{i=1}^{n} L_{c}\\left(d_{i}, y_{i}\\right)+\\frac{1}{2}\\|w\\|^{2}$\n$L_{c}(d, y)= \\begin{cases}|d-y|-\\varepsilon, & \\text { if }|d-y| \\geq \\varepsilon \\\\ 0, & \\text { otherwise }\\end{cases}$\nwhere $R_{\\text {SVR }}$ and $R_{\\text {emp }}$ represent the regression and empirical risk, respectively, $C$ and $\\varepsilon$ are two parameters. In Eq. (2), $L_{c}(d, y)$ is called the $\\varepsilon$-insensitive loss function. $\\|w\\|^{2} / 2$ is used as a measure of the flatness of the function.  \nTwo positive slack variables $\\xi$ and $\\xi^{*}$, which represent the distance from actual values to the corresponding boundary values of $\\varepsilon$-tube, are introduced. Then, Eq. (2) is transformed into the following convex optimization problem:\n$\\operatorname{Min} R_{\\text {SVR }}\\left(w, \\xi, \\xi^{*}\\right)=C \\sum_{i=1}^{n}\\left(\\xi_{i}+\\xi_{i}^{*}\\right)+\\frac{1}{2}\\|w\\|^{2}$\ns.t. $\\begin{cases}w \\phi\\left(x_{i}\\right)+b_{i}-d_{i} \\leq \\varepsilon+\\xi_{i}^{*}, \\\\ d_{i}-w \\phi\\left(x_{i}\\right)-b_{i} \\leq \\varepsilon+\\xi_{i}, \\quad i=1,2, \\ldots, n \\\\ \\xi_{i}, \\xi_{i}^{*} \\geq 0 .\\end{cases}$\nBy introducing Lagrange multipliers and exploiting the optimality constraints, the decision function given by Eq. (1) has the following explicit form [21]\n$f\\left(x, \\alpha_{i}, \\alpha_{i}^{*}\\right)=\\sum_{i=1}^{n}\\left(\\alpha_{i}-\\alpha_{i}^{*}\\right) K\\left(x, x_{i}\\right)+b$\nwhere $K\\left(x_{i}, x_{j}\\right)$ is called the kernel function, $\\alpha_{i}$ and $\\alpha_{i}^{*}$ are the socalled Lagrange multipliers. In Eq. (6), they satisfy the equality $\\alpha_{i} *$ $\\alpha_{i}^{*}=0 . \\alpha_{i}$ and $\\alpha_{i}^{*}$ are calculated by maximizing the dual function of Eq. (4), and the maximal dual function in Eq. (4), which has the following form:  \n$$\n\\begin{aligned}\n\\operatorname{Max} R\\left(\\alpha_{i}, \\alpha_{i}^{*}\\right)= & \\sum_{i=1}^{n} d_{i}\\left(\\alpha_{i}-\\alpha_{i}^{*}\\right)-\\varepsilon \\sum_{i=1}^{n}\\left(\\alpha_{i}+\\alpha_{i}^{*}\\right) \\\\\n& -\\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n}\\left(\\alpha_{i}-\\alpha_{i}^{*}\\right)\\left(\\alpha_{j}-\\alpha_{j}^{*}\\right) K\\left(x_{i}, x_{j}\\right)\n\\end{aligned}\n$$  \nunder the constraints, $\\sum_{i=1}^{n}\\left(\\alpha_{i}-\\alpha_{i}^{*}\\right)=0 ; \\quad 0 \\leq \\alpha_{i} \\leq C, i=$ $1,2, \\ldots, n ; \\quad 0 \\leq \\alpha_{i}^{*} \\leq C, i=1,2, \\ldots, n$.  \nThe value of the kernel is the inner product of the two vectors $x_{i}$ and $x_{j}$ in the feature space $\\phi\\left(x_{i}\\right)$ and $\\phi\\left(x_{j}\\right)$, so $K\\left(x_{i}, x_{j}\\right)=\\phi\\left(x_{i}\\right) * \\phi\\left(x_{j}\\right)$.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:32",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measures are proposed to quantify the performance differences between the AAVS-EDA algorithm and other Estimation of Distribution Algorithms (EDAs) on the CEC2014 benchmark functions?",
      "topics": [
        "search"
      ],
      "answer": "The performance differences between AAVS-EDA and other algorithms are quantified using Cohen's $d$ effect size to determine if the performance of an algorithm is worse than, better than, or similar to AAVS-EDA. Additionally, the Friedman test is used to rank the algorithms based on their performance across the benchmark functions.",
      "chunk_id": 11067,
      "paper_id": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_title": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_year": "2018",
      "chunk_content": "3) Hybrid functions $f_{17}-f_{32}$ : It is obvious that AAVS-EDA performs best among six algorithms on this group of test functions. The results it obtained are all not worse than the ones obtained by the other five algorithms except that HHSPSO-GDS achieves a better solution for $f_{19}$. Especially, AAVS-EDA reduces the mean of FEVs for $f_{18}$ by at least two orders of magnitude.  \nTable 1. The mean and the standard deviation (mean_standard deviation) of FEVs obtained by 6 algorithms over 25 independent runs on 30 CEC2014 benchmark functions with 30D\n\"-\",\" \" and \" $*$ \" respectively denote that the performance of the corresponding algorithm is worse than, better than or similar to that of AAVS-EDA according to Cohen's $d$ effect size.  \n4) Composition functions $f_{23}-f_{30}$ : The components of these composition functions are so sophisticated that it is hard to find even the near optimal solutions. In spite of this, AAVS-EDA demonstrates superior performance. It performs not worse than $\\mathrm{EMNA}_{g}$, AMaLGaM and CPI-JADE on all the eight functions, and is defeated by IPOP-CMAES and HHSPSO-GDS on only three functions. It is notable that the solutions for $f_{29}$ and $f_{30}$ obtained by AAVS-EDA are not only better but also more stable than the ones obtained by the other five algorithms.  \nThe last row of Table 1 lists the number of functions on which AAVS-EDA performs better than, similarly to or worse than each of its competitors. This result demonstrate that AAVS-EDA shows significant advantages over $\\mathrm{EMNA}_{g}$, AMaLGaM and CPI-JADE, and slight advantages over IPOP-CMAES and HHSPSO-GDS. In addition, we analyzed the differences between AAVS-EDA and the other five algorithms with Friedman test. Table 2 lists the ranking of the six algorithms obtained by the Friedman test, from which it can be concluded that AAVS-EDA performs best, followed by IPOP-CMAES; HHSPOSGDS, AMaLGaM and CPI-JADE show similar performance to each other, whereas $\\mathrm{EMNA}_{g}$ is definitely defeated by the other five algorithms. This conclusion is basically consistent with the one drawn according to Cohen's $d$ effect size.  \nTable 2. Ranking of 6 algorithms according to the Friedman test.  \nAs a whole, AAVS-EDA is very competitive compared with its competitors which contain four state-of-the-art EAs. This mainly profits from the effectiveness of AAVS which can adaptively adjust the search  \nscope and directions of AAVS-EDA. Considering AAVS-EDA possesses a simple algorithmic framework and only three parameters which are easy to set, it can be viewed as an efficient and practical EA.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:34",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically concerning the population update and solution improvement?",
      "topics": [
        "heuristic"
      ],
      "answer": "The algorithmic approach aims to evolve a population of solutions by generating new solutions using a probability model built from the top N solutions, where N equals PS * R (R being a value between 0 and 1, and PS being the population size). The CRI operator repairs and improves these new solutions before replacing the worst solutions in the current population. A rule-based heuristic, acting as a deterministic greedy algorithm based on \\(v_{k} q_{j k} p_{j j}(t)\\) values, is used to generate an initial solution.",
      "chunk_id": 5418,
      "paper_id": "An Estimation of Distribution Algorithm with Efficient Constructive RepairImprovement Operator for the Dynamic Weapon-Target Assignment",
      "paper_title": "An Estimation of Distribution Algorithm with Efficient Constructive Repair/Improvement Operator for the Dynamic Weapon-Target Assignment",
      "paper_year": "2012",
      "chunk_content": "The procedure of the proposed EDA is presented as follows:\nRandomly generate $P S-1$ solutions with $p\\left(z_{k}=1\\right)=0.5(k=1,2, \\cdots, L)$ and use the CRI operator to repair and improve the initial solutions. Use the rule-based heuristic proposed in [7] to generate a solution and add it into the population. Record the best solution in the whole population.  \nRemark 2. The rule-based heuristic in [7] is de facto a deterministic greedy algorithm which chooses AAPs according to their $v_{k} q_{j k} p_{j j}(t)$ values.\nSort the $P S$ solutions in the descending order of their objective values. Select the $N=P S * R(R \\in(0,1))$ top solutions to build the probability model [see (6)].\nUse the constructed model to generate $P S-N$ new solutions, and use the CRI operator to repair and improve them. Replace the worst FORMULA_121 solutions in the current population by the new solutions. Update the so-far-best solution.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:36",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the update of category probabilities in the CF-based probabilistic model, specifically how do the counters $a_k$ and $b_k$, representing satisfactory and evaluated items respectively, influence the category probability $\\hat{P}^{r}{_k}$?",
      "topics": [
        "search"
      ],
      "answer": "In the CF-based probabilistic model update, the category probability $\\hat{P}^{r}{_k}$ is altered using the formula $\\hat{P}_{k}^{r} \\leftarrow \\frac{\\text {len}_{k}-a_{k}}{\\text {len}_{k} * \\hat{P}_{k}-a_{k}-b_{k}}$, where $\\text{len}_k$ represents the length of the category list for category $k$, $a_k$ is the number of satisfactory items from category $k$ (items with a rating higher than the threshold $r_{\\text{threshold\\_target}}$), and $b_k$ is the number of all evaluated items of category $k$. This formula adjusts the initial category probability $\\hat{P}_{k}$ based on the observed performance of items within that category during the evaluation process. Subsequently, the probabilities $p_j$ for items $j$ within the category $k$ are calculated as $p_{j}=\\hat{P}^{r}{_k} * e^{\\hat{r}_{j}} / \\sum_{1}^{\\left|L_{\\text {search }, k}\\right|} e^{\\hat{r}_{j}}$, where $\\hat{r}_{j}$ is the estimated rating of item $j$ and $L_{\\text{search}, k}$ is the list of items in category $k$. This equation normalizes the probabilities based on the exponential of the estimated ratings, effectively weighting items with higher predicted ratings more heavily within the adjusted category probability.",
      "chunk_id": 7731,
      "paper_id": "PM-IEDA- Dual probabilistic Model Assisted Interactive Estimation of Distribution Algorithm for Personalized Search",
      "paper_title": "DPM-IEDA: Dual probabilistic Model Assisted Interactive Estimation of Distribution Algorithm for Personalized Search",
      "paper_year": "2019",
      "chunk_content": "Input: estimated category probability $\\hat{P}_{k}$, categorized lists $\\{\\ldots, L_{\\text {search }, k}, \\ldots\\}$, evaluated items per iteration $\\left(i, r_{i}\\right)$, $i \\in s_{e, t-m: t}$, threshold $r_{\\text {threshold_target }}$ used to distinguish targets from other items, len $_{k}, a_{k}, b_{k}$\nOutput: CF-based probabilistic model $\\boldsymbol{p}=\\left(\\ldots, p_{j}, \\ldots\\right), j \\in$ $L_{\\text {search }}$ and $k \\in\\{1,2, \\ldots, \\mathrm{~K}\\}$\nfor $i \\in s_{e, t-m: t}$ do\nget category $k$ of evaluated item $i$\nreomove item $i$ from $L_{\\text {search }, k}$\nif $r_{i}>=r_{\\text {threshold_target }}$ then\n$a_{k} \\leftarrow a_{k}+1$\nend if\n$b_{k} \\leftarrow b_{k}+1$\nend for\nfor $k=1 \\rightarrow K$ do\n$\\hat{P}_{k}^{r} \\leftarrow \\frac{\\text { len }_{k}-a_{k}}{\\text { len }_{k} * \\hat{P}_{k}-a_{k}-b_{k}}$\nfor $j \\in L_{\\text {search }, k}$ do\n$p_{j}=\\hat{P}^{r}{ }_{k} * e^{\\hat{r}_{j}} / \\sum_{1}\\left|L_{\\text {search }, k}\\right| e^{\\hat{r}_{j}}$\nend for\nend for\n3. Probabilistic Model Initialization: In lines 8-15, the probabilistic vector $\\boldsymbol{p}=\\left(\\ldots, p_{j}, \\ldots\\right), j \\in L_{\\text {seacrch }, k}$ and $k \\in\\{1,2, \\ldots, \\mathrm{~K}\\}$ is constructed by considering category probabilities $\\hat{P}_{k}$ and estimated ratings $\\hat{r}_{j}$. First, items in the same category share the $\\hat{P}_{k}$. Moreover, a non-linear map is used to depict the relation between  \nAlgorithm 3 Content-Based Probabilistic Model Initialization\nInput: population pop indexed by $l \\in\\{1,2, \\ldots,|\\text { pop }|\\}$, pretrained $\\operatorname{SVR}(\\cdot)$\nOutput: content-based probabilistic model $\\boldsymbol{p}=$ $\\left(\\ldots, p_{l}, \\ldots\\right), l \\in$ pop\nfor $l=1 \\rightarrow|\\operatorname{pop}|$ do\n$\\hat{r}_{l} \\leftarrow \\operatorname{SVR}\\left(p o p_{l}\\right)$\n$p_{l} \\leftarrow e^{\\hat{r}_{l}} / \\sum_{1}^{|p o p_{l}} e^{\\hat{r}_{l}}$\nend for  \nAlgorithm 4 Content-Based Probabilistic Model Update\nInput: population pop indexed by $l \\in\\{1,2, \\ldots,|\\text { pop }|\\}$, $\\operatorname{SVR}(\\cdot)$ to retrain, evaluated items per iteration $\\left(i, r_{i}\\right), i \\in$ $s_{e, t}$, iteration $t$\nOutput: content-based probabilistic model $\\boldsymbol{p}=$ $\\left(\\ldots, p_{l}, \\ldots\\right), l \\in$ pop\nfor $i \\in s_{e, t}$ do\nremove item $i$ from pop\nend for\nretrain $\\operatorname{SVR}(\\cdot)$ with the help of newly evaluated items $\\left(i, r_{i}\\right)$\nfor $l=1 \\rightarrow|\\operatorname{pop}|$ do\n$\\hat{r}_{l} \\leftarrow \\operatorname{SVR}\\left(p o p_{l}\\right)$\n$p_{l} \\leftarrow e^{\\hat{r}_{l}} / \\sum_{1}^{|p o p_{l}} e^{\\hat{r}_{l}}$\nend for\nthe estimated rating $\\hat{r}$ and its shares of the category probability. Additionally, lengths of category lists are stored, and $a_{k}$, the number of satisfactory items from category $k$ and $b_{k}$ recording the number of all evaluated items of category $k$ are reset.\nThe CF-based probabilistic model update is presented in Algorithm 2, and its main components are explained as follows.  \n1. Evaluation-Assisted Category Update: Line 2 gets the index $k$ of the evaluated item $i$ based on which category it belongs to; then, line 3 removes it from its corresponding category. If its rating is higher than threshold $r_{\\text {threshold_target }}$, counter $a_{k}$ is updated. $b_{k}$ always increases by 1 .\n2. Probability Update: In line 10, category probability $\\hat{P}^{r}{ }_{k}$ is altered with the updated counters $a_{k}$ and $b_{k}$. In lines 11-13, items of category FORMULA_145 share the revised category probability, and their estimated ratings determine ratios. The same non-linear map to that of Algorithm 1 is used here.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:39",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within HMPSO, how should practitioners update the distribution vector P, which represents the historical memory for each component?",
      "topics": [
        "selection"
      ],
      "answer": "To update the distribution vector P in HMPSO, which contains \\(p^{d}\\) for each component \\(d\\), practitioners should update the mean \\(p_{m}^{d}\\) and standard deviation \\(p_{s}^{d}\\) using the formulas \\(p_{m}^{d}(t+1)=\\left(1-m_{\\lambda}\\right) \\times p_{m}^{d}(t)+m_{\\lambda} \\times \\widetilde{p}_{m}^{d}(t+1)\\) and \\(p_{s}^{d}(t+1)=\\left(1-\\operatorname{Var}_{\\lambda}\\right) \\times p_{s}^{d}(t)+\\operatorname{Var}_{\\lambda} \\times \\widetilde{p}_{s}^{d}(t+1)\\), where \\(\\widetilde{p}_{m}^{d}(t+1)\\) and \\(\\widetilde{p}_{s}^{d}(t+1)\\) are the mean and standard deviation of the current selected promising pbests, calculated as \\(\\widetilde{p}_{m}^{d}(t+1)=\\frac{\\sum_{i=1}^{N} \\text { pbest }_{i}^{d}}{N}\\) and \\(\\widetilde{p}_{s}^{d}(t+1)=\\sqrt{\\frac{\\sum_{i=1}^{N}\\left(\\text { pbest }_{i}^{d}-\\widetilde{p}_{m}^{d}(t+1)\\right)^{2}}{N}}\\) respectively. The parameters \\(m_{\\lambda}\\) and \\(\\operatorname{Var}_{\\lambda}\\) control the balance between historical memory and current pbests, with values between 0 and 1.",
      "chunk_id": 4281,
      "paper_id": "Composite Particle Swarm Optimizer With Historical Memory for Function Optimization",
      "paper_title": "Composite Particle Swarm Optimizer With Historical Memory for Function Optimization",
      "paper_year": "2015",
      "chunk_content": "Historical memory $H$ is decided as follows.  \n1) Generate randomly a swarm of $Q$ particles from a search space and calculate their fitness values, and then obtain all particles' pbests and swarm's gbest.\n2) Select $N$ promising pbests from the swarm according to their fitness values by using a selection procedure, e.g., a tournament procedure.\n3) Adopt EDA to estimate the distribution of good regions in the search space based on the selected\npromising pbests. Population-based incremental learning (PBIL) [41] is used to model the distribution of the selected promising pbests and construct historical memory. So there is a distribution vector $\\mathbf{P}=$ $\\left(p^{1}, p^{2}, \\ldots, p^{d}, \\ldots, p^{D}\\right), \\quad 1 \\leq d \\leq D$, in which $p^{d}$ is used to characterize the $d$ th component's distribution of the selected promising pbests in the search space, and it is learned and updated from the distribution of historical selected promising pbests' memory and current selected promising pbests. Here, the distribution vector $\\mathbf{P}$ is considered as the historical memory for every component. New offspring are generated by sampling the updated distribution model. Let $\\widetilde{p}^{d}$ be a distribution of the $d$ th component by estimating current selected promising pbests. In HMPSO, we assume that the distribution of each component follows a normal distribution, thereby demanding EDA to estimate and preserve two parameters only, i.e., mean and standard deviation, expressed as $\\widetilde{p}_{m}^{d}$ and $\\widetilde{p}_{s}^{d}$, respectively. That is, $\\widetilde{p}^{d}=\\left\\{\\widetilde{p}_{m}^{d}, \\widetilde{p}_{s}^{d}\\right\\}$ and $p^{d}=\\left\\{p_{m}^{d}, p_{s}^{d}\\right\\}$. The initial value $\\widetilde{p}^{d}(1)$ is calculated in (7) and (8) when $t=0$ and is treated as the initial value of $p^{d}$. The updating formulas of $p_{m}^{d}, p_{s}^{d}, \\widetilde{p}_{m}^{d}$, and $\\widetilde{p}_{s}^{d}$ at time $t+1$ are as follows:  \n$$\n\\begin{aligned}\n& p_{m}^{d}(t+1)=\\left(1-m_{\\lambda}\\right) \\times p_{m}^{d}(t)+m_{\\lambda} \\times \\widetilde{p}_{m}^{d}(t+1) \\\\\n& p_{s}^{d}(t+1)=\\left(1-\\operatorname{Var}_{\\lambda}\\right) \\times p_{s}^{d}(t)+\\operatorname{Var}_{\\lambda} \\times \\widetilde{p}_{s}^{d}(t+1) \\\\\n& \\widetilde{p}_{m}^{d}(t+1)=\\frac{\\sum_{i=1}^{N} \\text { pbest }_{i}^{d}}{N} \\\\\n& \\widetilde{p}_{s}^{d}(t+1)=\\sqrt{\\frac{\\sum_{i=1}^{N}\\left(\\text { pbest }_{i}^{d}-\\widetilde{p}_{m}^{d}(t+1)\\right)^{2}}{N}}\n\\end{aligned}\n$$  \nwhere $p_{m}^{d}$ and $p_{s}^{d}$ can be regarded as the distribution of mean and standard deviation for modeling the particles' historical promising pbests. $m_{\\lambda}$ and $\\operatorname{Var}_{\\lambda} \\in[0,1]$ are the learning parameters of mean and standard deviation, respectively. They are used to balance the contributions between historical memory and the information extracted from the current particles' pbests. The bigger $m_{\\lambda}$ and $\\operatorname{Var}_{\\lambda}$, the greater contribution of current particles' pbests; while the smaller $m_{\\lambda}$ and $\\operatorname{Var}_{\\lambda}$, the greater contribution of historical memory. Thus, the setting of learning parameters $m_{\\lambda}$ and $\\operatorname{Var}_{\\lambda}$ has a direct impact on exploration and exploitation abilities. For example, if $m_{\\lambda}$ and $\\operatorname{Var}_{\\lambda}$ are 0 , there is no exploitation and the offspring solutions are sampled based on cumulative historical memory completely. As $m_{\\lambda}$ and FORMULA_64 increase, the exploitation ability increases, while the exploration ability to search the portions of historical memory in a problem space diminishes.",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:42",
      "generation_style": "practical_application"
    },
    {
      "question": "In the described probabilistic fragment-based algorithm, how are fragments indexed and retrieved, and what constraint is imposed on the insertion windows to ensure unique fragment identification?",
      "topics": [
        "algorithm"
      ],
      "answer": "Fragments are indexed using a key calculated as `key = i * Nb_fragments + rank_fragment`, where `i` is the residue position in the insertion window, `Nb_fragments` is the number of fragments per window, and `rank_fragment` is the fragment's rank within the library, ranging from 0 to `Nb_fragments - 1`. The reverse operation to retrieve the fragment's rank and residue position is given by `rank_fragment = key mod Nb_fragments` and `i = (key - rank_fragment) / Nb_fragments`. To ensure these keys are unique, the size of the insertion windows must be constant.",
      "chunk_id": 5193,
      "paper_id": "A Probabilistic Fragment-Based Protein Structure Prediction Algorithm",
      "paper_title": "A Probabilistic Fragment-Based Protein Structure Prediction Algorithm",
      "paper_year": "2012",
      "chunk_content": "$$\nk e y=i * N b_{\\text {fragments }}+\\operatorname{rank}_{\\text {fragment }}\n$$  \nwhere $i$ is the position of the residue in the insertion window, $N b_{\\text {fragments }}$ the number of fragments per window in the library and $\\operatorname{rank}_{\\text {fragment }} \\in\\left[0 . . N b_{\\text {fragments }}-1\\right]$ the rank of the fragment in the library. The reverse operation is:  \n$$\n\\begin{gathered}\n\\operatorname{rank}_{\\text {fragment }}=k e y \\bmod N b_{\\text {fragments }} \\\\\ni=\\frac{k e y-\\operatorname{rank}_{\\text {fragment }}}{N b_{\\text {fragments }}}\n\\end{gathered}\n$$  \nThe size of the insertion windows must be constant in order for these keys to be unique. In our implementation, we estimate the probabilities on the fragments of size 9 . The main reason for this choice is that using uniform distributions with fragments of size 3 provides another way to maintain diversity in the solution set.  \nThe parameters used in our experiments are reported in table 3. Fragments used during the experiments were generated through the Robetta Server [26]. We generated the fragments with the web interface option for excluding homologs turned on. We then  \nchecked with a local software that no proteins with more than $30 \\%$ sequence identity with the target were used to generate the fragment libraries. 200 fragments of length 9 and 200 fragments of size 3 were generated for each insertion window. The same set of fragments was used for EdaFold and Rosetta predictions.\nWe wish to thank RIKEN, Japan, for an allocation of computing resources on the RIKEN Integrated Cluster of Clusters (RICC) system. We also",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:44",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of using the GUROBI solver compare to the SCIP optimization solver when applied to location-allocation problems, specifically concerning computational time and the characteristics of the problem instances?",
      "topics": [
        "optimization"
      ],
      "answer": "The GUROBI solver was used to find optimal solutions for instances based on real data from the metropolitan region of Chile in the context of ambulance station locations. In contrast, the SCIP optimization solver, implemented with the GAMS modeling language, found optimal solutions for a real scenario in Istanbul and Adana, Turkey, for a location-allocation problem determining the location of capacitated testing facilities, achieving this in less than six hours of computational time. The problem addressed by SCIP included objectives such as minimizing distances to neighborhoods and distances from testing facilities to laboratories, while the GUROBI implementation focused on optimizing a weighted sum of demand coverage based on socio-economic indicators and disease rates.",
      "chunk_id": 3378,
      "paper_id": "The maximal covering location problem with accessibility indicators and mobile units",
      "paper_title": "The maximal covering location problem with accessibility indicators and mobile units",
      "paper_year": "2023",
      "chunk_content": "Recently, location problems have been implemented to foster medical services, testing procedures, and vaccination centers during the COVID-19 pandemic [e.g.,29, in Nigeria]. Moreover, the accessibility of such services is essential due to restrictive conditions such as social distancing and low mobility. For example, Hassan et al. [30] implemented a classic MCLP for Field Hospitals to maximize demand coverage subject to a maximal number of hospitals. Calderon et al. [31] focused on the location of ambulance stations to optimize a weighted sum of demand coverage, where the weights of demand points were defined by combining a socio-economic indicator and a disease rate. The authors assumed a heterogeneous fleet of ambulances assigned to the upper bounds of the stations, ambulances assigned to each station, and ambulances assigned to the entire system. The solver of GUROBI was then used to find optimal solutions for instances based on real data from the metropolitan region of Chile. Another example was the two-stage programming approach of Kuvvetli [32] for a location-allocation problem that determines the location of capacitated testing facilities to detect the COVID-19 disease and the client-facilitylaboratory assignments. The following objectives were considered: (i) maximum accessibility aimed to locate the test sampling facilities centers at minimum distances to the neighborhoods; (ii) number of testing facilities; and (iii) distance from testing facilities to laboratories. The author implemented the GAMS modeling language and the SCIP optimization solver to find optimal solutions for a real scenario in Istanbul and Adana, Turkey using less than six hours of computational time. Finally, [33] defined a bi-objective MCLP to determine FORMULA_13 capacitated vaccination centers maximizing the demand coverage versus minimizing the traveled distance to access the service. The authors assumed that multiple vaccination centers (partial coverage) could satisfy the demand points. They implemented the solver of GUROBI in a lexicographic approach to find optimal solutions for instances based on data from Yogyakarta, Indonesia.  \nTable 1 summarizes the studies in the literature considering different coverage concepts such as classic, cooperative, gradual, or partial coverage. Column 6 indicates the implementation or not of mobile units. Column 7 shows the type of objective function: with a single objective (SO) or multi-objective (MO).  \nIn summary, we propose a novel variant of the MCLP to determine healthcare centers and mobile units that optimize a generalized coverage function in terms of different accessibility indicators. Those indicators are relevant from a social perspective. We implemented our approach in the context of the COVID-19 pandemic to provide good and different opportunities for people to get a COVID-19 testing service.  \nTable 1\nSummarize of literature review.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:46",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model within the `Offs` procedure (Algorithm 3) to generate a new candidate offspring?",
      "topics": [
        "mutation"
      ],
      "answer": "The `Offs` procedure, denoted as `S/M(PR^c, PR^d, r_M, β_min, β_max, x_best)`, first draws a random number `r1` from a uniform distribution between 0 and 1. If `r1` is less than or equal to the mutation parameter `r_M`, then for each continuous variable `i` (from 1 to `Nvar^c`), the variable `x_i` is calculated using equation (15) (not detailed in this excerpt). Otherwise, a bin `j` is selected according to the probability model `PR^c` and a random number `r2`, and `x_i` is assigned a value from a uniform distribution between `p_{i, j-1}` and `p_{i, j}`. Finally, for each discrete variable `m` (from 1 to `Nvar^d`), a value `v` is selected from the set `{lb, ub}` according to the probability model `PR^d` and a random number `r3`.",
      "chunk_id": 1546,
      "paper_id": "An improved Estimation of Distribution Algorithm for Solving Constrained Mixed-Integer Nonlinear Programming Problems",
      "paper_title": "An improved Estimation of Distribution Algorithm for Solving Constrained Mixed-Integer Nonlinear Programming Problems",
      "paper_year": "2022",
      "chunk_content": "```\nAlgorithm 3 Offs \\(\\leftarrow \\mathrm{S} / \\mathrm{M}\\left(P R^{c}, P R^{d}, r{M}, \\beta{\\min }, \\beta{\\max }, x{\\text {best }}\\right)\\)\nInput: the probability models \\(P R^{c}\\) and \\(P R^{d}\\); mutation pa-\nrameters \\(r{M}, \\beta{\\text {min }}, \\beta{\\text {max }}\\)\nOutput: a new candidate offspring \\(\\left[x{i}, x{m}\\right]\\)\n\\(r{1} \\leftarrow \\operatorname{Uniform}(0,1)\\)\nif \\(r{1} \\leq r{M}\\) then\nfor \\(i \\leftarrow 1\\) to \\(N v a r^{c}\\) do\ncalculate variable \\(x{i}\\) by (15)\nend for\nelse\nfor \\(i \\leftarrow 1\\) to \\(N v a r^{c}\\) do\n\\(r{2} \\leftarrow \\operatorname{Uniform}(0,1)\\)\nSelect a bin j according \\(P R^{c}\\) and \\(r{2}\\)\n\\(x{i} \\leftarrow \\operatorname{Uniform}\\left[p{i, j-1}, p{i, j}\\right)\\)\nend for\nend if\nfor \\(m \\leftarrow 1\\) to \\(N v a r^{d}\\) do\n\\(r{3} \\leftarrow \\operatorname{Uniform}(0,1)\\)\nSelect a value \\(v\\) from \\(\\left\\{l{b}, u{b}\\right\\}\\) according \\(P R^{d}\\) and \\(r{3}\\)\nend for\nAlgorithm \\(4 E D A{m v}\\) framework\nInput: \\(N, W, e{b}, G, r{M}, T{c}, c p, \\beta{\\min }, \\beta{\\max }, \\varepsilon{p}\\)\nOutput: The best solution\nInitialize population \\(p\\)\nfor \\(t \\leftarrow 1\\) to \\(G\\) do\nGet the best solution so far \\(x{\\text {best }}\\)\ntemporal \\(\\leftarrow \\varnothing\\)\n\\(P R^{c} \\leftarrow \\operatorname{AWH}\\left(p, W, e{b}\\right)\\)\n\\(P R^{d} \\leftarrow \\operatorname{LBHz}\\left(p, t, \\varepsilon, \\varepsilon{p}\\right)\\)\nfor \\(i \\leftarrow 1\\) to \\(N\\) do\nOffs \\(\\leftarrow \\mathrm{S} / \\mathrm{M}\\left(P R^{c}, P R^{d}, r{M}, \\beta{\\text {min }}, \\beta{\\text {max }}, x{\\text {best }}\\right)\\)\ntemporal \\(\\leftarrow\\) temporal \\(\\cup\\) Offs\nend for\ntemporal \\(\\leftarrow\\) temporal \\(\\cup \\mathrm{p}\\); and clear p\nSelect the best N individuals from temporal by the \\(\\varepsilon\\) constrained method and set to p\nend for",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:49",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output, specifically generated game levels, be measured using the criteria of linearity, density, pattern density, and pattern variation?",
      "topics": [
        "evaluation metrics",
        "EDA",
        "game level generation"
      ],
      "answer": "The quality of generated game levels can be measured using four metrics: Linearity, which quantifies how closely a level structure follows a straight line by finding differences between ground level heights, normalized for level length; Density, which counts the number of distinct design elements (DE) in vertical segments of the level, assigning higher values to levels with more DE present; Pattern density, which counts meso-patterns present in the level similar to the original game, normalized for level length; and Pattern variation, which measures the number of distinct patterns in a level, assigning higher values to levels with more varied meso-patterns.",
      "chunk_id": 2205,
      "paper_id": "Using estimation of distribution algorithm for procedural content generation in video games",
      "paper_title": "Using estimation of distribution algorithm for procedural content generation in video games",
      "paper_year": "2022",
      "chunk_content": "Picking promising individuals of each generation is based on their score obtained from the objective function in Eq. 2. In this step, selected individuals will be used for sampling and building the probabilistic model. At the end of each generation, 40 promising individuals are selected for the purpose of building models and transferring to the next generation.\nAfter transferring 40 promising individuals from the past generation based on their objective function score, 60 new individuals will be generated for the total sum of  \nTable 1 Expressivity metric description (all images taken from [3])  \nLinearity shows how much a level structure follows a straight line, finding the differences between the heights of the ground levels, normalized for level length\nDensity shows how many distinct DE are in a predefined vertical segment of levels, assigning higher values to levels with more DE present in a vertical segment  \nPattern density counts the meso-patterns present in the level that are similar to the original game, normalized for level length  \nPattern variation measures how many distinct patterns are present in a level, assigning higher values to levels that include more varied meso-patterns\n[IMAGE_2]  \n100 chromosomes for the new generation to preserve genetic diversity. Objective function will be applied to 60 new individuals and the evolutionary population of 100 will be sorted again. This replacement approach is continued until the termination criterion is met.",
      "question_type": "evaluation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:51",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of normalizing the vector norms of the Gaussian ($\\mathcal{G}$), isotropic Gaussian ($\\mathcal{G}^{\\text {iso }}$), and isotropic Cauchy ($\\mathcal{C}^{\\text {iso }}$) distributions when applied within the context of Estimation of Distribution Algorithms (EDAs)?",
      "topics": [
        "search"
      ],
      "answer": "The vector norms of the \\(\\mathcal{G}\\), \\(\\mathcal{G}^{\\text {iso }}\\), and \\(\\mathcal{C}^{\\text {iso }}\\) distributions are normalized such that the 100\\(\\tau\\)-percentile of their norm distributions equals 1. This normalization is achieved by dividing the \\(\\mathcal{G}\\)-distributed vectors by \\(CDF_{\\chi_{D}}^{-1}(\\tau)\\), the \\(\\mathcal{G}^{\\text {iso }}\\)-distributed vectors by \\(CDF_{\\chi_{1}}^{-1}(\\tau)\\), and the \\(\\mathcal{C}^{\\text {iso }}\\)-distributed vectors by \\(CDF_{\\mathcal{C}}^{-1}(\\frac{1+\\tau}{2})\\), respectively, where \\(CDF\\) denotes the cumulative distribution function and \\(\\tau\\) is a percentile value. This normalization facilitates a controlled comparison of the distributions and their impact on the selection of data points, particularly when used with fitness functions like the sphere function, by ensuring a consistent scale for the global step size.",
      "chunk_id": 5972,
      "paper_id": "Preventing Premature Convergence in a Simple EDA Via Global Step Size Setting",
      "paper_title": "Preventing Premature Convergence in a Simple EDA Via Global Step Size Setting",
      "paper_year": "2008",
      "chunk_content": "[IMAGE2]  \nFig. 2. The distribution of the first coordinate (the histograms) and the distribution of the vector norms (solid line) for $\\mathcal{G}, \\mathcal{G}^{\\text {iso }}$, and $\\mathcal{C}^{\\text {iso }}$, and for the search space dimensions 1,2 , and 10\n[IMAGE3]  \nFig. 3. After selection with sphere function. The distribution of the first coordinate (the histograms) and the distribution of the vector norms (solid line) for $\\mathcal{G}, \\mathcal{G}^{\\text {iso }}$, and $\\mathcal{C}^{\\text {iso }}$, and for the search space dimensions 1,2 , and 10 . Note that the distribution of vector norms (solid line) is cut off at $x=1$ due to the modification of sampling process described in Sec. 3.1.  \nThese distributions were already studied in several works from different points of view. In [17], the local convergence rates of evolutionary algorithms with Gaussian and Cauchy mutations are estimated and compared. In [18], the convergence to a local optimum was studied as well, along with the ability to locate narrow valleys and the influence of the dimensionality on the exploration efficiency. The usefulness of the Cauchy distributions in case of multimodal optimization was explored in [19]. In this article it is studied if these distributions allow for the simple constant setting of the global step size.\nIt was deliberately decided to normalize ${ }^{3}$ the vector norms of all three distributions in such a way, that the $100 \\tau$-percentile of the distribution of norms equals to 1 . This is achieved simply by  \n- dividing the $\\mathcal{G}$-distributed vectors by the value of inverse cumulative distribution function (i.c.d.f) of the $\\chi$ distribution with $D$ degrees of freedom (d.o.f.) at point $\\tau$, i.e. $\\mathbf{x}_{m}=\\mathbf{x} / C D F_{\\chi_{D}}^{-1}(\\tau), \\mathbf{x} \\sim \\mathcal{G}$,\n- dividing the $\\mathcal{G}^{\\text {iso }}$-distributed vectors by the value of the i.c.d.f. of the $\\chi$ distribution with 1 d.o.f. at point $\\tau$, i.e. $\\mathbf{x}_{m}=\\mathbf{x} / C D F_{\\chi_{1}}^{-1}(\\tau), \\mathbf{x} \\sim \\mathcal{G}^{\\text {iso }}$, or by\n- dividing the $\\mathcal{C}^{\\text {iso }}$-distributed vectors by the value of the i.c.d.f. of the standard Cauchy distribution at point $(1+\\tau) / 2$, i.e. $\\mathbf{x}_{m}=\\mathbf{x} / C D F_{\\mathcal{C}}^{-1}\\left(\\frac{1+\\tau}{2}\\right), \\mathbf{x} \\sim \\mathcal{C}^{\\text {iso }}$, respectively.  \nThe distributions of sampled data points and their norms are depicted in Fig. 2. The fact that the $100 \\tau$-percentile of the norm distribution is equal to 1 is demonstrated in Fig. 3 which shows the distributions of selected data points when sphere function is used. The frequency of norms of the selected data points is cut off at value 1 .",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:10:54",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of the provided mathematical model for scheduling between continuous casting and hot rolling processes, how does the algorithmic mechanism ensure that the residence time of each slab `i` in a reheating furnace `g` adheres to both a minimum and maximum duration, as defined by `h_{i}^{\\min}` and `h_{i}^{\\max}`?",
      "topics": [
        "optimization"
      ],
      "answer": "The constraint (17), expressed as `b_{i}+h_{i}^{\\min}<e_{i}<b_{i}+h_{i}^{\\max }`, enforces that the drop-out time `e_{i}` of slab `i` from the reheating furnace must be greater than the feed-in time `b_{i}` plus the minimum residence time `h_{i}^{\\min}`, and less than the feed-in time `b_{i}` plus the maximum residence time `h_{i}^{\\max}`. This ensures that the slab remains within the furnace for an acceptable duration, impacting the objective function which minimizes the total residence time of all slabs, represented by the equation `min f=∑_{i=1}^{n}(e_{i}-b_{i})`.",
      "chunk_id": 2247,
      "paper_id": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_title": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_year": "2022",
      "chunk_content": "Indices:\n$g \\quad$ index of reheating furnaces, and $G$ is the number of reheating furnaces.\nParameters:\n$h_{i}^{\\min } \\quad$ minimum residence time of slab $i$.\n$h_{i}^{\\max } \\quad$ maximum residence time of slab $i$.\n$a_{i, b} \\quad$ position of slab $i$ in cast $b$.\n$U^{H} \\quad$ setup time between two successive slabs in or out reheating furnace.\n$w \\quad$ maximum wait time for roll after slab out from reheating furnace.\n$s_{b, i}^{C} \\quad$ starting time of slab $i$ in cast $b$ at CC stage.\n$s_{p, i}^{R} \\quad$ starting time of slab $i$ in rolling unit $p$ at HR stage.\n$L_{g} \\quad$ capacity of reheating furnace $g$.\n$\\operatorname{big} M$ a large number.\nDecision Variables:\n$b_{i} \\quad$ feed-in time of slab $i$ in reheating stage.\n$e_{i} \\quad$ drop-out time of slab $i$ in reheating stage.\n$x_{i, g} \\quad$ if slab $i$ heating in reheating furnace $g$, then $x_{i, g}=1$, otherwise $x_{i, g}=0$.\n$y_{i, j, g}$ if slab $i$ and slab $j$ are processed by reheating furnace $g$, and $i$ directly precedes $j$, then $y_{i, j, g}=1$, otherwise $y_{i, j, g}=0$.\n$z_{i, j, g}$ if slab $j$ is in the $L_{g}-t h$ position after slab $i$ in the reheating furnace $g$, then $z_{i, j, g}=1$, otherwise $z_{i, j, g}=0$.\nThe mathematical model is formulated as follows.  \n$$\n\\min f=\\sum_{i=1}^{n}\\left(e_{i}-b_{i}\\right)\n$$  \nSubject to  \n$$\n\\begin{gathered}\n\\sum_{g=1}^{G} x_{i, g}=1 \\\\\n\\sum_{i=i, j=j}^{n} y_{i, j, g}=\\sum_{a=b, i=j}^{n} y_{i, j, g}=x_{i, g} \\\\\nb_{i}+U^{H}-\\operatorname{big} M\\left(3-x_{i, g}-x_{j, g}-y_{i, j, g}\\right)<b_{j} \\\\\ne_{i}+U^{H}-\\operatorname{big} M\\left(3-x_{i, g}-x_{j, g}-y_{i, j, g}\\right)<e_{j} \\\\\nb_{i}+h_{i}^{\\min }<e_{i}<b_{i}+h_{i}^{\\max } \\\\\nb_{i}>s_{b, i}^{E}+t^{C} \\\\\ns_{p, i}^{R}-e_{i} \\leq w \\\\\n\\left(b_{i}-e_{j}\\right)+\\operatorname{big} M\\left(3-x_{i, g}-x_{j, g}-z_{i, j, g}\\right) \\geq 0\n\\end{gathered}\n$$  \nThe objective function (12) minimizes the residence time of all slabs. Constraint (13) ensures each slab is heated in one reheating furnace. Constraint (14) ensures there is only one predecessor and only one successor for slabs processed on the same reheating furnace. Constraint (15) and (16) ensure the first in first out principle of reheating furnace. Constraint (17) indicates the residence time in a reheating furnace must in the specified range. Constraint (18) ensures the feed-in time of the reheating stage is after the CC stage. Constraint (19) shows that the slab should be rolled after drop-out from reheating furnace, and the interval should be less than a certain value. Constraint (20) guarantees the number of slabs in a reheating furnace should not exceed its capacity.",
      "question_type": "algorithmic",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:10:56",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using Variable Neighborhood Descent (VND), what specific implementation steps are required for the pipe VND approach, particularly concerning the insert and swap operators?",
      "topics": [
        "search"
      ],
      "answer": "To implement pipe VND within an EDA framework, the process involves iteratively applying insert and swap operators until no further improvement occurs. The insert operator selects a machine and inserts it into a new cell. The swap operator chooses two machines from two different cells and switches their positions. These two operators are applied iteratively in sequence. The neighborhood structure, denoted as $N_{k}$, is defined by applying randomly $k$ insertion moves, where $k$ represents the distance between the current solution $X$ and the new neighbor solution $X^{\\prime}$, defined as the number of differences between vectors $X$ and $X^{\\prime}$. The algorithm continues until no improvement is found by either the insert or swap operation.",
      "chunk_id": 1387,
      "paper_id": "A General Variable Neighborhood Search approach based on a p-median model for cellular manufacturing problems",
      "paper_title": "A General Variable Neighborhood Search approach based on a p-median model for cellular manufacturing problems",
      "paper_year": "2022",
      "chunk_content": "The idea of this phase consists of defining the neighborhood structures that permit us to acquire a distance between the solution $X$ and the new neighbor solution $X^{\\prime}$ that must be equal to $k$. We defined this distance as the number of differences between both vectors $X$ and $X^{\\prime}$. Then, we denoted $N_{k}$ as the number of used neighborhood structures specified by applying randomly $k$ insertion moves.\nThrough local search processes, finding a local minimum following a given neighborhood structure does not necessarily imply that we can reach a local optimum using  \n  \nanother one. Recently, in [21], the authors provided a clear VND survey with its variants and its neighborhood structures classification and applications in deterministic context. In the proposed algorithm, we applied the pipe VND where the insert and the swap operators are used. The first structure tried to select one machine and then insert it in a new cell. Then, the second one aims to choose two machines from two different cells and switch them. The following act is to apply iteratively both structures until there is no chance for the current solution to be improved.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:10:58",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Univariate Marginal Distribution Algorithm (UMDA) applied to the HardJump function, under what mathematical conditions, specifically concerning the initial value of \\(p(t)\\), can convergence to the suboptimum be guaranteed, and how does this relate to the equilibrium points of the dynamical system?",
      "topics": [
        "fitness"
      ],
      "answer": "For the UMDA applied to the \\(HardJump(n, m, \\delta)\\) function, where \\(n\\) is a natural number, \\(0 < \\delta < 1\\), and \\(m \\in \\{0, 1, \\ldots, n-1\\}\\), the algorithm's convergence depends on the initial value \\(p(0)\\), which represents the probability of selecting a 1. The dynamics are governed by the equation \\(p(t+1)=\\alpha+(1-\\alpha) \\frac{1}{\\delta\\binom{n}{\\alpha n}\\left[\\frac{1-p(t)}{p(t)}\\right]^{(1-\\alpha) n}+1}\\), where \\(\\alpha = m/n\\). If \\(p(0) \\in (0, p_r)\\), where \\(p_r\\) is a repelling fixed point of the map \\(p(t) \\mapsto p(t+1)\\), then \\(p(t)\\) converges monotonically to an attractor \\(p_a\\), leading to convergence to a suboptimum. Conversely, if \\(p(0) \\in (p_r, 1]\\), then \\(p(t)\\) converges to 1, which corresponds to the optimum. Therefore, the relative position of \\(p(0)\\) with respect to the repelling point \\(p_r\\) determines whether the algorithm converges to the global optimum or a suboptimum.",
      "chunk_id": 11647,
      "paper_id": "Univariate marginal distribution algorithm dynamics for a class of parametric functions with unitation constraints",
      "paper_title": "Univariate marginal distribution algorithm dynamics for a class of parametric functions with unitation constraints",
      "paper_year": "2011",
      "chunk_content": "We begin this section by defining a new class of parametric functions. This function class is a member of the class of unitation functions, having a maximal value at $(1,1, \\ldots, 1)$ and it is based on jump and related types of functions [18].  \nDefinition 4. The HardJump $(n, m, \\delta)$ function from $\\Omega$ taking non-negative values with $n \\in \\mathbb{N}, 0<\\delta<1$ and $m \\in\\{0,1, \\ldots, n-1\\}$ is defined as  \n$$\n\\operatorname{HardJump}(n, m, \\delta)(x)= \\begin{cases}1, & \\text { if } U(x)=n \\\\ \\delta, & \\text { if } U(x)=m \\\\ 0, & \\text { otherwise }\\end{cases}\n$$  \nand the associated function $H J(n, m, \\delta):\\{0,1, \\ldots, n\\} \\mapsto \\mathbb{R}_{+}$defined as  \n$$\nH J(n, m, \\delta)(u)= \\begin{cases}1, & \\text { if } u=n \\\\ \\delta, & \\text { if } u=m \\\\ 0, & \\text { otherwise }\\end{cases}\n$$  \nThe HardJump function class is also related to other functions used for theoretical analysis, such as flat landscapes and functions where there is a unique optimum and all remaining points are constant (needle-in-the-haystack function) [35]. The main feature of the HardJump function class is that we can tune both the extension of the plateau and the closeness between suboptimal and optimum values. As we will see later, the ratio $\\alpha:=m / n \\in\\{0,1\\}$ is more important than the parameter $m$. Taking $m=\\alpha n \\in \\mathbb{N}$, for $H J(n, \\alpha n, \\delta)$, Eq. (8) becomes  \n$$\np(t+1)=\\alpha+(1-\\alpha) \\frac{1}{\\delta\\binom{n}{\\alpha n}\\left[\\frac{1-p(t)}{p(t)}\\right]^{(1-\\alpha) n}+1}\n$$  \nThe algorithm convergence analysis can be reduced to just the evolution of $p(t)$. Because the maximum is reached at $(1,1, \\ldots, 1)$, the convergence of the algorithm at this point is equivalent to the convergence of $p(t)$ to the value 1 .  \nLet us take a perspective that captures the different facets of the problem. Fig. 1 plots both function $H f(10,4,0.6)$ (circled dots) and the average fitness $W$ (Eq. (3)). Functions $H f(10,4,0.6)$ and $W$ were normalized to be defined in the interval $[0,1]$. We also present the dynamics $p(t) \\mapsto p(t+1)$ analytically expressed by Eq. (9) for the function $H f(10,4,0.6)$.  \nIn general, the plot shape is similar for different values of $\\alpha, \\delta$ and $n$. Apart from the zero point, there are usually three equilibrium points for $p(t) \\mapsto p(t+1)$. As the graph shows, there are two attractors $\\left(p(t)=1\\right.$ and $\\left.p_{a}\\right)$ and a repelling point $p_{r}$.  \nThe graph gives a clear indication of where to look for the answers to some of the most important questions of our analysis. If, at the start, $p(0) \\in\\left(0, p_{r}\\right)$, then $p(t)$ will converge monotonically to $p_{a}$, which implies convergence to the suboptimum. Conversely, if $p(0) \\in\\left(p_{r}, 1\\right]$, then $p(t)$ will converge to the optimum. Therefore, we can predict from the very start whether the algorithm will converge to the maximum of the function. There are some cases in which there is only one equilibrium point, $p(t)=1$ (see, for example, the graph for $\\alpha=0.8, \\delta=0.8$ and $n=10$ in Fig. 2). In such cases, the algorithm will always converge. Another possibility is that the points $p_{r}$ and $p_{a}$ will coincide at a single point $p$. In this case, if at the start $p(0) \\in(0, p]$, then $p(t)$ will converge to $p$. Conversely, if $p(0) \\in(p, 1]$, then FORMULA_175 will converge to 1 .",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:01",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of the EDA-ELM model compare to the GA-ELM, ANFIS, and standard ELM models in drought prediction, based on the information provided?",
      "topics": [
        "performance"
      ],
      "answer": "The EDA-ELM model achieved the best prediction accuracy in drought prediction performance indicators compared to GA-ELM, ANFIS, and standard ELM models. The execution times of the models, however, descended in the order of EDA-ELM, GA-ELM, ANFIS, and standard ELM.",
      "chunk_id": 2121,
      "paper_id": "Drought prediction in the Yunnan-Guizhou Plateau of China by coupling the estimation of distribution algorithm and the extreme learning machine",
      "paper_title": "Drought prediction in the Yunnan-Guizhou Plateau of China by coupling the estimation of distribution algorithm and the extreme learning machine",
      "paper_year": "2022",
      "chunk_content": "In this study, a novel EDA-ELM model based on the capabilities of the EDA algorithm and ELM modeling technique was proposed. The advantages of the model in forecasting the multiscalar monthly SPEI in Yunnan-Guizhou Plateau, China, over GA-ELM, standard ELM, and ANFIS models were evaluated by taking the primary drought driving factors as input variables. The results revealed that the EDA-ELM model achieved the best prediction accuracy in drought prediction performance indicators, followed by GA-ELM, ANFIS, and ELM models. The execution times of the models descended in the order of EDA-ELM, GA-ELM, ANFIS, and standard ELM models, but they are all acceptable. The proposed EDA-ELM model provides a promising method for hydrological systems to predict droughts and a non-engineering measure for rational water resource allocation and drought mitigation to reduce agricultural and economic losses.  \nAuthor contributions Yao Du and Zhennan Liu involved in conceptualization, methodology, software. Qiongfang Li took part in data curation, writing-original draft preparation. Zhengmo Zhou and Guobin Lu involved in writing-reviewing and editing. Qihui Chen took part in software, validation.  \nFunding Financial support is gratefully acknowledged from the National Natural Science Foundation Commission of China under Grant numbers 51879069 and 41961134003, Guizhou Science Foundation-ZK [2021] General 295 and the Jiangsu Provincial Collaborative Innovation Center of World Water Valley and Water ecological civilization, China.\nCompeting interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:02",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the univariate model of Estimation of Distribution Algorithms (EDAs), what data structure considerations are important, given the assumption of variable independence?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Data Structures",
        "Univariate Model"
      ],
      "answer": "Since the univariate EDA model assumes that variables are independent, a developer can represent the probability distribution for each variable separately. This could be achieved using an array of probability mass functions (PMFs), where each element of the array corresponds to a variable, and stores the probabilities for each possible value of that variable. For example, if using population-based incremental learning, the data structure would hold the probability of each value for each variable, which is then incrementally updated based on the selected individuals.",
      "chunk_id": 242,
      "paper_id": "An effective estimation of distribution algorithm for the flexible job-shop scheduling problem with fuzzy processing time",
      "paper_title": "An effective estimation of distribution algorithm for the flexible job-shop scheduling problem with fuzzy processing time",
      "paper_year": "2013",
      "chunk_content": "In the literature, it often assumes that the processing time and completion time are deterministic values. In real-world scheduling, however, the processing time of an operation cannot be known precisely and the completion time can be obtained ambiguously. Thus, it may be more appropriate to consider fuzzy processing time and fuzzy completion time (Sakawa and Kubota 2000). The fuzzy job-shop scheduling problem (fJSP) extends the JSP by considering the processing time or the due-date to be fuzzy variable. Relevant results include following. Sakawa and Mori (1999) presented a GA to maximise the minimum agreement index. Then Sakawa and Kubota (2000) improved the GA (Sakawa and Mori 1999) to maximise the minimum agreement index, to maximise the average agreement index, and to minimise the maximum fuzzy completion time. Lei (2008) designed a Pareto archive PSO for the multi-objective fJSP to obtain a set of Pareto optimal solutions. Gonzalez-Rodriguez, Vela, and Puente (2010) presented a GA to search possible active schedules. Recently, Hu, Yin, and Li (2011) presented a modified differential evolution (DE) algorithm for the fJSP, and Lei (2010b, 2011) presented a random key GA and a swarm-based neighbourhood search with availability constraints.  \nIntroducing fuzzy constraints to the FJSP makes the problem much closer to the real applications, such as the textile industry, automobile assembly and semiconductor manufacturing. The FJSP with fuzzy processing time is regarded as the combination of the FJSP and the fJSP, namely fuzzy flexible job-shop scheduling problem (fFJSP). Lei (2010a) presented an efficient decomposition-integration genetic algorithm (DIGA), in which the main population was decomposed as two sub-populations that evolved independently and the new main population was formed by sub-population integration. Recently, Lei (2012) developed an effective co-evolutionary genetic algorithm (CGA) to minimise the fuzzy makespan. The study on this topic is still in its infancy, and it is important to develop novel algorithms for the problem.  \nAs a novel kind of evolutionary algorithm based on statistical learning, estimation of distribution algorithm (EDA) (Larranaga and Lozano 2002) has gained increasing studies and wide applications during recent years. Due to different kinds of the relationships among variables, the EDA has different models. Accordingly, it can be classified as univariate model, bivariate model or multivariate model. Univariate model assumes that the variables are independent with each other, e.g. the population-based incremental learning (Baluja 1994), the univariate marginal distribution algorithm (Mauhlenbein and Paass 1996) and the compact GA (Harik, Lobo, and Goldberg 1998). Bivariate model assumes that each variable is associated with another one, e.g. the mutual information maximisation for input clustering (De Bonet, Isbell, and Viola 1997), the combining optimisers with mutual information trees (Baluja and Davies 1997) and the bivariate marginal distribution algorithm (Pelikan and Muhlenbein 1999). Multivariate model considers the relationship between all the variables, e.g. the factorised distribution algorithms (Muhlenbein and Mahnig 1999), the extended compact GA (Harik 1999) and the Bayesian optimisation algorithm (Pelikan, Goldberg, and Cantu-Paz 1999). For more details about the EDA, please refer Larranaga and Lozano (2002).",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:04",
      "generation_style": "implementation_focused"
    },
    {
      "question": "For the proposed discrete Quantum-behaved Particle Swarm Optimization (QPSO) based on Estimation of Distribution Algorithm (EDA), what indirect performance indicator is used to demonstrate its effectiveness in solving combinatorial optimization problems?",
      "topics": [
        "search"
      ],
      "answer": "The algorithm's performance is demonstrated by applying it to the unconstrained binary quadratic programming problem, which serves as a benchmark because numerous hard combinatorial optimization problems can be formulated in this way. Superior performance on this problem, relative to other evolutionary algorithms, indicates the EDA's effectiveness.",
      "chunk_id": 5766,
      "paper_id": "Discrete Quantum-Behaved Particle Swarm Optimization Based on Estimation of Distribution for Combinatorial Optimization",
      "paper_title": "Discrete Quantum-Behaved Particle Swarm Optimization Based on Estimation of Distribution for Combinatorial Optimization",
      "paper_year": "2008",
      "chunk_content": "In this paper, a novel discrete QPSO based on EDA is proposed for combinatorial optimization. In the proposed algorithm, firstly, all personal best solutions from the current swarm are selected; then, a probability model is constructed to estimate the distribution of good regions over the search space based on the selected personal best solutions. Then  \n[^0]:    This work was supported in part by the Guangdong Provincial Natural Science Foundation of China (07300630, 06104916), the Specialized Research Fund for the Doctoral Program of Higher Education (20070558052, 20050558017), the Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry (2007-1108), the National Science Foundation of China (60643004, 60573097, 60773198, 60703111), and the Science and Technology Office of Sun Yat-Sen University.  \nJiahai Wang is with the Department of Computer Science, Sun Yatsen University, Guangzhou, 510275, China. (corresponding author to: wjiahai@hotmail.com).  \nYunong Zhang is with the Department of Electronics \\& Communication Engineering, Sun Yat-sen University, Guangzhou, 510275, China. (e-mail: zhynong@mail.sysu.edu.cn).  \nYalan Zhou is with the Department of Computer Science, Sun Yat-sen University, Guangzhou, 510275, China. (e-mail: zhouylan@163.com).  \nJian Yin is with the Department of Computer Science, Sun Yat-sen University, Guangzhou, 510275, China. (e-mail: issijyin@mail.sysu.edu.cn).  \nmainstream point of discrete QPSO is generated by sampling the constructed probability distribution model, which increases the diversity of the swarm and can lead the swarm to escape from local optima. Moreover, in the proposed algorithm, one part of a solution generated by the original discrete QPSO, the other part of a solution is sampled in the search space from the constructed probability distribution model. Therefore, a solution generated by the offspring generation scheme of the proposed algorithm is based on the local information and the global statistical information. Thus, the proposed algorithm makes use of both the local information of solutions found so far and the global information about the search space. The local information of solutions found so far is helpful for exploitation, while the global information can guide the search for exploring promising areas. In order to keep the diversities in the population, a bit flip mutation operator is also incorporated into the proposed algorithm. To demonstrate the performance of the proposed algorithm, experiments are carried out on the unconstrained binary quadratic programming problem which numerous hard combinatorial optimization problems can be formulated as. The results show that the EDA can significantly improve the performance of discrete QPSO and discrete QPSO based on EDA have superior performance to other evolutionary algorithms.  \nThe rest of the paper is organized as follows. Section 2 briefly reviews the SPSO, QPSO and DQPSO. In Section 3, the EDA is first briefly introduced, and then a novel discrete QPSO based on EDA is proposed. The experimental simulation results are reported in Section 4. Section 5 concludes this paper.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:06",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs that incorporates Variable Neighborhood Search (VNS) when addressing the protein side chain placement problem?",
      "topics": [
        "analysis"
      ],
      "answer": "The primary purpose is to enhance the exploration of the search space by defining $k$-neighborhoods based on the Goldstein elimination criterion and the protein's adjacency matrix, thereby reducing the search space. The VNS schemes, employing either exhaustive or randomized local searches within these constrained neighborhoods, aim to efficiently optimize the fitness function by considering only interacting variables to improve side chain placement.",
      "chunk_id": 5604,
      "paper_id": "Combining variable neighborhood search and estimation of distribution algorithms in the protein side chain placement problem",
      "paper_title": "Combining variable neighborhood search and estimation of distribution algorithms in the protein side chain placement problem",
      "paper_year": "2008",
      "chunk_content": "In this section, we introduce two different VNS schemes in the context of EDAs to solve the protein side chain placement problem.  \nA crucial element of the VNS algorithm is the definition of the neighborhood. The neighborhood will be defined only for the points represented by those variables and values that remained after applying the Goldstein elimination criterion. As explained in Sect. 4.1, the Goldstein elimination criterion allows the number of variables and the range of values for each variable to be reduced. For the side chain placement problem, we define the $k$-neighborhood of a solution $\\mathbf{x}$ as the set of solutions that are different from solution $\\mathbf{x}$ in exactly $k$ variables. More formally,  \n$$\n\\mathcal{N}_{k}(\\mathbf{x})=\\left\\{\\mathbf{x}^{\\prime} \\mid n-\\sum_{i=1}^{n} I\\left(x_{i}, x_{i}^{\\prime}\\right)=k\\right\\}\n$$  \nwhere $I$ is the indicator function, equal to one if both values are equal.\nClearly, given a point $\\mathbf{x}$, for all $j \\neq k, \\mathcal{N}_{j}(\\mathbf{x}) \\cap \\mathcal{N}_{k}(\\mathbf{x})=\\emptyset$. Additionally, we use the protein structure information to constrain the neighborhood. Particularly, we use the information contained in the adjacency matrix. In the analysis of the $k$-neighborhood $(k>1)$, we only consider those sets of $k$ variables for which each pair of variables has a non-zero entry in the adjacency matrix. This connection constraint naturally arises from the pairwise nature of the fitness function. Variables whose corresponding residues are not connected in the graph do not contribute together to the fitness  \nfunction. The independent contribution of the variables to the fitness function is covered by the 1-neighborhood.  \nIn the 1-neighborhood of $\\mathbf{x}$, all the values for each of the variables are tried in the exploration of the neighborhood. For $k>1$, the algorithm calculates all possible sets of $k$ variables with non-zero entries in the adjacency matrix. Each possible configuration of each set that is different in all $k$ variables from $\\mathbf{x}$ defines a neighbor solution. By requiring that the solution has to be different in all $k$ variables, we guarantee that the neighborhoods do not overlap. On the other hand, by reducing the search of $k$-size sets to those interacting in the protein structure, the algorithm critically reduces the search space.  \nGiven this neighborhood, we propose two alternative ways to define local search step 8 of Algorithm 1. Exhaustive and randomized procedures can be employed.  \nTo select $\\mathbf{x}^{\\prime \\prime}$ in the exhaustive schema, the $\\mathcal{N}_{k}\\left(\\mathbf{x}^{\\prime}\\right)\\left(k=1, \\ldots, k_{\\max }\\right)$ is completely searched to find a point where the fitness function is locally optimized. In the randomized scheme, point FORMULA_98 is selected using a random strategy. A local search is conducted by randomly selecting a solution in the neighborhood and moving to this solution if fitness is improved. A parameter, maxtries, defines the maximum number of points of the neighborhood that will be searched.  \nObviously, the exhaustive search can be more computationally costly than the randomized one. However, in the second case, the cost depends on maxtries. To reduce the computational cost of the exhaustive scheme, we can constrain the set of neighborhood structures.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:09",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs for flowshop scheduling problems, how does the algorithmic mechanism of constructing a probabilistic model using parameters like $\\eta_{fg}$ and $\\mu_{f[g-1]}$ influence the generation of new family sequences, and what role does the set $\\Omega_{g}^{f}$ play in this process?",
      "topics": [
        "scheduling"
      ],
      "answer": "The EDA constructs a probabilistic model to generate new family sequences by considering the parameters $\\eta_{fg}$, which represents the number of times family $f$ is located before or on position $g$ in the selected sequences, plus a constant $\\delta_{1}^{f}$. This parameter indicates the importance of the order of families. The parameter $\\mu_{f[g-1]}$ represents the number of times family $f$ comes after the family on position $f^{\\prime}-1$ in the selected sequences, plus $\\delta_{2}^{f}$, highlighting the importance of similar blocks of families. The set $\\Omega_{g}^{f}$ represents the families not already scheduled until position $g$. The probability $\\pi_{f g}$ of locating family $f$ on position $g$ is calculated as $\\pi_{f g}=\\frac{\\eta_{f g} \\times \\mu_{f[g-1]}}{\\sum_{i \\in \\Omega_{g}} \\eta_{f g} \\times \\mu_{f[g-1]}},$ thus $\\Omega_{g}^{f}$ constrains the summation to only consider unscheduled families, ensuring a valid permutation.",
      "chunk_id": 6914,
      "paper_id": "Hybrid Estimation of Distribution Algorithm for permutation flowshop scheduling problem with sequence dependent family setup times",
      "paper_title": "Hybrid Estimation of Distribution Algorithm for permutation flowshop scheduling problem with sequence dependent family setup times",
      "paper_year": "2009",
      "chunk_content": "The section discusses the framework of our proposed EDA for solving the flowshop scheduling problem with sequence dependent family setup times under the minimization of the makespan criterion.\nIn this chapter each solution is represented by two permutations. The first permutation represents the family vectors where the $f^{\\mathrm{t}} h$ case indicates the family located on the position $f$ in the family sequence. The second one represents the permutation of jobs within each family, where the $j^{\\mathrm{t}} h$ number denotes the job located on position $j$. In order to grant the diversification of the algorithm, the $P$ individuals of the initial population are generated randomly.\nThe procedure of selection adopted in our algorithm consists of two phases. First, the individuals of the initial population are sorted, in an increasing order, according to their\nobjective functions. Second, $M$ individuals are selected from the subset of $20 \\%$ of best individuals from the sorted list.\nIn order to generate new individual, the EDA constructs a probabilistic model based on the selected individuals. We propose to build a probabilistic model for generating both the family sequence and the job sequence. As in [11] our estimated probabilities depend on the structure of sequences of selected individuals. Therefore, both the order of the family (job) and the similar blocks of families (jobs) are greatly considered. First we create the new family sequence by using the following parameters:  \n- $\\eta_{f g}$ be the number of times where the family $f$ is located before or on the position $g$ in the subset of the selected sequences plus a constant $\\delta_{1}^{f}$. Thus, $\\eta_{f g}$ indicates the importance of the order of the families in the family sequence.\n- $\\mu_{f[g-1]}$ be the number of times where the family $f$ come after the family on the position $f^{\\prime}-1$ in the subset of the selected sequences plus $\\delta_{2}^{f}$. $\\mu_{f[g-1]}$ highlights the importance of the similar blocks of families in the family sequences. In such way, we prefer to conserve the similar blocks as much as possible.\n- $\\Omega_{g}^{f}$ is the set of families not already scheduled until position $g$.\nThus, the probability for locating the family $f$ on the position $g$ in the sequence of new individual is calculated as follows:  \n$$\n\\pi_{f g}=\\frac{\\eta_{f g} \\times \\mu_{f[g-1]}}{\\sum_{i \\in \\Omega_{g}} \\eta_{f g} \\times \\mu_{f[g-1]}}\n$$  \nThen, given the resulted family sequence, we create the new job sequences by a similar way. Therefore, we redefine the same parameters as above $\\left(\\eta_{j k}, \\delta_{1}^{j}, \\mu_{j[k-1]}, \\delta_{2}^{j}\\right.$ and $\\left.\\Omega_{k}^{j}\\right)$ while modifying family sequence by job sequence. So, within each family $f$, the estimated probability of selection the job $j$ on the $k^{\\mathrm{t}} h$ position in the new job sequence is obtained following this formula:  \n$$\n\\pi_{j k}=\\frac{\\eta_{j k} \\times \\mu_{j[k-1]}}{\\sum_{i \\in \\Omega_{k}} \\eta_{i k} \\times \\mu_{i[k-1]}}\n$$",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:11",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm (EDA) that deals with permutation-based problems, how should practitioners adapt the solution representation when the classical sampling method becomes time-consuming due to the need for updating probabilities at each step?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "permutation-based problems",
        "inversion vector representation",
        "Lehmer vectors"
      ],
      "answer": "When classical sampling for permutations in EDAs becomes inefficient, practitioners should consider using an inversion vector representation of permutations, equivalent to Lehmer vectors. Given a permutation $\\sigma$, the inversion vector $I=(I(1), \\ldots, I(n-1))$ is defined where $I(i)=\\sum_{j>i} \\mathbb{I}[\\sigma(i)>\\sigma(j)]$, with $\\mathbb{I}$ being the indicator function. This representation avoids the mutual exclusivity constraint and allows extracting different summary statistics from the sample. For example, the permutation $\\sigma=(3,1,4,2)$ is represented by the inversion vector $I=(2,0,1)$, where $I(1) = 2$ indicates that there are two values lower than 3 to its right in $\\sigma$. The last item of the inversion vector is omitted, thus for a permutation of length $n$, the inversion vector is of length $n-1$.",
      "chunk_id": 9933,
      "paper_id": "Alternative Representations for Codifying Solutions in Permutation-Based Problems",
      "paper_title": "Alternative Representations for Codifying Solutions in Permutation-Based Problems",
      "paper_year": "2020",
      "chunk_content": "When representing solutions in permutation-based problems, the usual and natural option is to use the permutation representation. A permutation $\\sigma$ is formally defined as a bijection from the set of natural numbers $[n]=\\{1, \\ldots, n\\}$ onto $[n]$ and is usually represented as an ordered list of the set $[n]$. We denote by $\\sigma(i)=j$ that item $j$ is in the $i$-th position of permutation $\\sigma$. Alternatively, we say that $\\sigma^{-1}$ is  \n[^0]:    ${ }^{1}$ The terms codification and representation will be used interchangeably throughout the paper.  \n[IMAGE0]  \nFig. 1: Illustration of the sampling step in the UMDA\nthe inverse of $\\sigma$, if and only if, $\\sigma(i)=j$ and $\\sigma^{-1}(j)=i$ for all $i, j=1, \\ldots, n$. For instance, the inverse permutation of $\\sigma=(2,4,3,1)$ is $\\sigma^{-1}=(4,1,3,2)$.  \nEven though permutations are intuitive and apparently the obvious representation for permutation-based problems, when considering classical EDAs some issues arise.  \nGiven a permutation $\\sigma$ of length $n$, the only possible items are $\\{1, . ., n\\}$, and these cannot be repeated. In the previous section we have seen that the classical sampling method for vectors has to be adapted to sample permutations. Although the first order marginal of the sample is maintained, some problems emerge. For example, the need of updating the probabilities at each step is time consuming. Moreover, the information of the first order marginals might not be relevant for the problem at hand. Therefore, we propose to use a different representation for permutations for which the mutual exclusivity constraint does not arise. Furthermore, this representation allows us to extract different summary statistics from the sample.  \nAlternatively to the classical representation, other types of numeric vectors that codify permutations have also been reported in the literature [3], [12]. In this paper, we focus on the inversion vector representation of permutations, equivalent to Lehmer vectors [20].  \nGiven a permutation $\\sigma$, its inversion vector is $I=(I(1), \\ldots, I(n-1))$ where $I(i)=\\sum_{j>i} \\mathbb{I}[\\sigma(i)>\\sigma(j)]$, being $\\mathbb{I}$ the indicator function. In other words, each item $I(i)$ in the inversion vector $I$ counts the number of items lower than $\\sigma(i)$ at its right. For a permutation of length $n$, its inversion representation is a vector of length $n$, however, by definition, the last item of the inversion vector is always zero, thus we will omit this item and consider the inversion vector of length $n-1$. For instance, given a permutation $\\sigma=(3,1,4,2)$, its inversion vector representation is defined as $I=(2,0,1)$. Following its definition, having $I(1)=2$ and $\\sigma(1)=3$ means that there are two values lower than 3 in $\\sigma$ on its right. Likewise, $I(2)=0$ indicates that there are no values lower than $\\sigma(2)$ on its right in $\\sigma$.  \nThe algorithm to decode an inversion vector FORMULA_65 to its per-",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:14",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of scheduling jobs on unrelated parallel machines with periodic maintenance (UPMSP), what are the two objective functions being minimized, and how are they mathematically defined?",
      "topics": [
        "constraints"
      ],
      "answer": "The two objective functions being minimized are makespan ($f_1$) and total tardiness ($f_2$). Makespan, denoted as $C_{max}$, is defined as the maximum completion time among all jobs: $f_{1}=C_{\\max }=\\max \\left\\{C_{j} \\mid j=1,2, \\cdots, n\\right\\}$, where $C_j$ is the completion time of job $J_j$. Total tardiness is defined as the sum of the maximum of the difference between the completion time and due date of each job, and zero: $f_{2}=\\sum_{j=1}^{n} \\max \\left\\{C_{j}-d_{j}, 0\\right\\}$, where $d_j$ is the due date of job $J_j$.",
      "chunk_id": 7741,
      "paper_id": "A Novel Imperialist Competitive Algorithm With Multi-Elite Individuals Guidance for Multi-Object Unrelated Parallel Machine Scheduling Problem",
      "paper_title": "A Novel Imperialist Competitive Algorithm With Multi-Elite Individuals Guidance for Multi-Object Unrelated Parallel Machine Scheduling Problem",
      "paper_year": "2019",
      "chunk_content": "UPMSP with PM and SDST can be described as follows. Suppose $n$ independent jobs $J_{1}, J_{2}, \\cdots, J_{n}$ can be processed on $m$ unrelated parallel machines $M_{1}, M_{2}, \\cdots, M_{m}$. Each job is available at time zero. $p_{i j}$ is the processing time of job $J_{j}$ on machine $M_{i} . d_{j}$ indicates the due date of $J_{j}$.  \nJobs can be processed in an interval between two consecutive maintenance activities. The interval is called the processing one and its time length is $u_{i} . w_{i}$ is the period of each maintenance. Thus, the maintenance periodic recycle of machine $M_{i}$ is $T_{i}=w_{i}+u_{i}$. We use $J_{0}$ to denote maintenance activities [12].  \nThe setup time is dependent on sequence and machine. $s_{i j k}$ is the setup time for processing job $J_{k}$ just after job $J_{j}$ on machine $M_{i}, s_{i j k}$ indicates the setup time of machine $M_{i}$ to process the first job $J_{k}$ after a maintenance activity, and $s_{i j 0}$ is the setup time of machine $M_{i}$ to perform a maintenance activity just after the job $J_{j}$.  \nThere are some constraints on jobs and machines:  \n1) Each job can be processed on only one machine at a time.  \n2) Operations cannot be interrupted.\n3)If the processing of a job cannot be completed in a processing interval, the job can't be processed in the current interval and should be moved to the next interval for processing etc.  \nThe goal of UPMSP with PM and SDST is to minimize the following two objectives simultaneously:  \n$$\n\\begin{aligned}\n& \\min f_{1}=C_{\\max }=\\max \\left\\{C_{j} \\mid j=1,2, \\cdots, n\\right\\} \\\\\n& \\min f_{2}=\\sum_{j=1}^{n} \\max \\left\\{C_{j}-d_{j}, 0\\right\\}\n\\end{aligned}\n$$  \nwhere the first objective $f_{1}$ is makespan and the second objective $f_{2}$ is total tardiness. $C_{j}$ indicates the completion time of job $J_{j}$.  \nWe give an example with two machines and six jobs. $w_{1}=37, w_{2}=4, u_{1}=70, u_{2}=86$. Due dates of six jobs are $4,89,46,35,98,45$, respectively. $p m$ is the processing time matrix, $S_{1}$ is the setup times matrix on machine 1 , and $S_{2}$ indicates the setup times matrix on machine 2 .  \n$$\n\\begin{aligned}\np m & =\\left[\\begin{array}{llllll}\n1 & 87 & 28 & 32 & 38 & 9 \\\\\n4 & 21 & 68 & 17 & 43 & 48\n\\end{array}\\right] \\\\\nS_{1} & =\\left[\\begin{array}{llllllll}\n0 & 2 & 2 & 3 & 9 & 7 & 9 \\\\\n6 & 0 & 1 & 8 & 1 & 3 & 9 \\\\\n1 & 4 & 0 & 7 & 3 & 7 & 8 \\\\\n3 & 7 & 3 & 0 & 2 & 3 & 5 \\\\\n4 & 3 & 8 & 3 & 0 & 5 & 2 \\\\\n8 & 8 & 3 & 7 & 9 & 0 & 5 \\\\\n1 & 8 & 8 & 1 & 2 & 2 & 0\n\\end{array}\\right] \\\\\nS_{2} & =\\left[\\begin{array}{llllllll}\n0 & 3 & 7 & 3 & 7 & 6 & 3 \\\\\n2 & 0 & 5 & 1 & 6 & 1 & 7 \\\\\n3 & 6 & 0 & 7 & 7 & 6 & 2 \\\\\n4 & 7 & 6 & 0 & 9 & 6 & 9 \\\\\n3 & 3 & 7 & 3 & 0 & 1 & 7 \\\\\n8 & 5 & 8 & 5 & 6 & 0 & 9 \\\\\n4 & 7 & 4 & 1 & 7 & 9 & 0\n\\end{array}\\right]\n\\end{aligned}\n$$",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:16",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the global information, as measured by PCA angles, of the GA model compare to the PBIL model when using Trunc20 selection on the 1D checkerboard problem?",
      "topics": [
        "selection"
      ],
      "answer": "Based on the provided figures, the GA model's mean global information versus PCA angles on the 1D checkerboard problem with Trunc20 selection (Figure A1(a)) can be visually compared to the PBIL model's performance under the same conditions (Figure A3(a)). The comparison focuses on the relative values and trends of global information as the algorithms progress, rather than specific numerical values, as the figures themselves are not provided in a numerical format.",
      "chunk_id": 4098,
      "paper_id": "Towards explainable metaheuristics Feature extraction from trajectory mining",
      "paper_title": "Towards explainable metaheuristics: Feature extraction from trajectory mining",
      "paper_year": "2023",
      "chunk_content": "[IMAGE21]  \nFIGURE A1 GA global information versus PCA angles on 1D checkerboard by selection. (a) GA 1DChecker Trunc20 mean global (b) GA 1DChecker Trunc50 mean global (c) GA 1DChecker tour mean global.\n[IMAGE22]  \nFIGURE A2 GA global information versus PCA on royal road by selection. (a) GA royal road Trunc20 mean global (b) GA royal road Trunc50 mean global (c) GA royal road tour mean global.\n[IMAGE23]  \nFIGURE A3 PBIL global information versus PCA angles on 1D checkerboard by selection. (a) PBIL 1DChecker Trunc20 mean global (b) PBIL 1DChecker Trunc50 mean global (c) PBIL 1DChecker tour mean global.  \n[IMAGE24]  \nFIGURE A4 PBIL global information versus PCA angles on royal road by selection. (a) PBIL royal road Trunc20 mean global (b) PBIL royal road Trunc50 mean global (c) PBIL royal road tour mean global.\n[IMAGE25]  \nFIGURE A5 GA local information versus PCA angles on checker by selection. (a) GA 1DChecker Trunc20 mean local (b) GA 1DChecker Trunc50 mean local (c) GA 1DChecker tour mean local.\n[IMAGE26]  \nFIGURE A6 GA local information versus PCA angles on royal road by selection. (a) GA royal road Trunc20 mean local (b) GA royal road Trunc50 mean local (c) GA royal road tour mean local.\n[IMAGE27]  \nFIGURE A7 PBIL local information versus PCA angles on 1D checkerboard by selection. (a) PBIL 1DChecker Trunc20 mean local (b) PBIL 1DChecker Trunc50 mean local (c) PBIL 1DChecker tour mean local.\n[IMAGE28]  \nFIGURE A8 PBIL local information versus PCA angles on royal road by selection. (a) PBIL royal road Trunc20 mean local (b) PBIL royal road Trunc50 mean local (c) PBIL royal road tour mean local.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:18",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To reduce the memory usage of the sig-cGA, a condensed history storage is proposed. What are the precise steps for maintaining the list of blocks, ensuring logarithmic space complexity relative to the full history length?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "sig-cGA",
        "memory optimization",
        "data structures"
      ],
      "answer": "The condensed history storage maintains a list of blocks, each storing the number of 1s in an interval of length equal to a power of two. When a new item is stored, a block of size 1 is appended to the list. Then, the list is traversed in backward direction. If three consecutive blocks of the same size are found, the two earliest blocks are merged into a new block of twice the size. This ensures that for each power $2^{k}$, there are between one and two blocks of length $2^{j}$ for all $j \\in [0..k]$, leading to a logarithmic number of blocks and enabling access to historic intervals with length in $[2^{j}, 2^{j+1}-1]$ in amortized constant time.",
      "chunk_id": 10974,
      "paper_id": "Significance-based Estimation-of-Distribution Algorithms",
      "paper_title": "Significance-based Estimation-of-Distribution Algorithms",
      "paper_year": "2018",
      "chunk_content": "In order to reduce the number of operations performed (computational cost) of the sig-cGA, we only check significance in historic data of lengths that are a power of 2 . By saving the whole history but precomputing the number of 1 s in the power-of-two intervals, a significance check can be done in time logarithmic in the history length; the necessary updates of this data structure can be done in logarithmic time (per bit-position) as well. With this implementation, the main loop of the sig-cGA has a computational cost of $O\\left(\\sum_{i=1}^{n}\\left|H_{i}\\right|\\right)$. Since the histories are never longer than the run time (number of fitness evaluations; twice the number of iterations), we see that the computational cost is at most $O(n T \\log T)$, when the run time is $T$. Since for most EAs working on bit string representations of length $n$ the computational cost is larger than the run time by at least a factor of $n$, we see that our significance approach is not overly costly in terms of computational cost.  \nWhat appears unfavorable, though, is the memory usage caused by storing the full history. For this reason, we now sketch a way to condense the history so that it only uses space logarithmic in the length of the full history. This approach will not allow to access exactly the number of 1 s (or 0 s ) in all power-of-two length histories. It will allow, however, for each $\\ell \\in\\left[\\left|H_{i}\\right|\\right]$, to access the number of 1 s in some interval of length $\\ell^{\\prime}$ with $\\ell \\leq \\ell^{\\prime}<2 \\ell$. For reasons of readability, we shall in the subsequent analyses nevertheless regard the original sig-cGA, but it is quite clear that the mildly different accessibility of the history in the now-proposed condensed implementation will not change the asymptotic run times shown in this work.  \nFor our condensed storage of the history, we have a list of blocks, each storing the number of 1 s in some discrete interval $\\left[t_{1} . . t_{2}\\right]$ of length equal to a power of two (including 1). When a new item has to be stored, we append a block of size 1 to the list. Then, traversing the list in backward direction, we check if there are three consecutive blocks of the same size, and if so, we merge the two earliest ones into a new block of twice the size. By this, we always maintain a list of blocks such that, for a certain power $2^{k}$, there are between one and two blocks of length $2^{j}$ for all $j \\in[0 . . k]$. This structural property implies both that we only have a logarithmic number of blocks (as we have $k=O\\left(\\log \\left|H_{i}\\right|\\right)$ ) and that we can (in amortized constant time) access all historic intervals consisting of full blocks, which in particular implies that we can access an interval with length in $\\left[2^{j}, 2^{j+1}-1\\right]$ for all FORMULA_238.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:20",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What advantage does the use of former information of superior probability model provide when building a superior probability model in Estimation of Distribution Algorithms (EDAs)?",
      "topics": [
        "performance"
      ],
      "answer": "The use of former information of the superior probability model improves the loss of population diversity and prevents premature convergence, which greatly improves the performance of basic EDAs.",
      "chunk_id": 1197,
      "paper_id": "Estimation of Distribution Algorithm using Variety of Information",
      "paper_title": "Estimation of Distribution Algorithm using Variety of Information",
      "paper_year": "2014",
      "chunk_content": "5. CONCLUSION\n\nThe algorithm proposed utilize the the former information of superior probability model when building superior probability model in EDA, and utilize the information of inferior solutions of population to filter the individuals generated by sampling from superior probability model,and validate the efficiency of proposed algorithm by simulation on knapsack problem.\n\nThe use of former information of superior probability model improves the loss of population diversity and prevents premature convergence, improves the performance of basicEDA greatly; the use of the information of inferior solutions further improves the performance of algorithm. when $P_{\\text {inferior }}(g)$ is built without former information of inferior probability model, operator B improved optimization ability of the basicEDA+A to some extend; when $P_{\\text {inferior }}(g)$ is built with former information of probability model, there is no significant improvement for the optimization results of basicEDA+A, but accelerates the convergence speed..\n\n6. ACKNOWLEDGMENTS\n\nThis work was supported by the National Natural Science Foundation of China under Grant No. 61271143 and No. 60871080",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:22",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in the context of multi-speed gearbox synthesis, and how does it compare to other global search methods?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to optimize the configuration of a multi-speed gearbox by decomposing the outer problem into sub-tasks and applying an Estimation of Distribution Algorithm (EDA) for global search. The EDA's performance is then compared to simulated annealing and best-first search, revealing that a three-stage decomposition coupled with best-first search performs well on small-size problems, and outperforms other techniques on larger problems when coupled with an EDA.",
      "chunk_id": 9913,
      "paper_id": "Multi-speed Gearbox Synthesis Using Global Search and Non-convex Optimization",
      "paper_title": "Multi-speed Gearbox Synthesis Using Global Search and Non-convex Optimization",
      "paper_year": "2020",
      "chunk_content": "Chiara Piacentini ${ }^{2(\\boxtimes)}\\left(\\mathbb{D}\\right.$, Hyunmin Cheong ${ }^{1(\\boxtimes)}$, Mehran Ebrahimi ${ }^{1}$, and Adrian Butscher ${ }^{1}$${ }^{1}$ Autodesk Research, 661 University Avenue, Toronto, ON M5G 1M1, Canada\\{hyunmin.cheong, mehran.ebrahimi, adrian.butscher\\}@autodesk.com2 Augmenta Inc., 106 Front St E, Toronto, ON M5A 1E1, Canadachiara@augmenta.ai\nWe consider the synthesis problem of a multi-speed gearbox, a mechanical system that receives an input speed and transmits it to an outlet through a series of connected gears, decreasing or increasing the speed according to predetermined transmission ratios. Here we formulate this as a bi-level optimization problem, where the inner problem involves non-convex optimization over continuous parameters of the components, and the outer task explores different configurations of the system. The outer problem is decomposed into sub-tasks and optimized by a variety of global search methods, namely simulated annealing, best-first search and estimation of distribution algorithm. Our experiments show that a three-stage decomposition coupled with a best-first search performs well on small-size problems, and it outmatches other techniques on larger problems when coupled with an estimation of distribution algorithm.  \nKeywords: Global search $\\cdot$ Best-first search $\\cdot$ Stochastic search $\\cdot$ Evolutionary algorithms FORMULA_8 Non-convex optimization.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:23",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of employing a probabilistic model to sample neuron states in Mutation Hopfield Neural Networks (MHNN) contribute to overcoming limitations associated with conventional Hopfield Neural Networks (HNN) in $k$ Satisfiability programming?",
      "topics": [
        "mutation"
      ],
      "answer": "Estimation of Distribution Algorithms (EDAs) address the limitations of Hopfield Neural Networks (HNN), which suffer from a lack of interpretability and variation in their output. The key algorithmic mechanism involves using a probabilistic model to sample the neuron state. This sampling aims to explore various optimal neuron states and move toward diverse locations of global minimum energy. In the proposed Mutation Hopfield Neural Network (MHNN), this EDA-driven sampling of neuron states is intended to improve performance in $k$ Satisfiability programming, outperforming conventional HNN in various performance metrics.",
      "chunk_id": 7955,
      "paper_id": "k Satisfiability Programming by using Estimation of Distribution Algorithm in Hopfield Neural Network_removed",
      "paper_title": "<i>k</i> Satisfiability Programming by using Estimation of Distribution Algorithm in Hopfield Neural Network",
      "paper_year": "2020",
      "chunk_content": "Norul Fazira Ahmad Rasli ${ }^{1, a)}$, Mohd Shareduwan Mohd Kasihmuddin ${ }^{2, b)}$, Mohd. Asyraf Mansor ${ }^{3, c)}$, Md Faisal Md Basir ${ }^{4, d}$ ) and Saratha Sathasivam ${ }^{5, e)}$${ }^{1,2,3}$ School of Mathematical Sciences, Universiti Sains Malaysia, 11800 Minden, Pulau Pinang, Malaysia${ }^{3}$ School of Distance Education, Universiti Sains Malaysia, 11800 Minden, Pulau Pinang, Malaysia${ }^{4}$ Department of Mathematical Sciences, Faculty of Science, Universiti Teknologi Malaysia, 81310 Johor Bahru, Johor, Malaysia${ }^{\\text {b) }}$ Corresponding author: shareduwan@usm.my${ }^{a}$ norulfazira95@gmail.com${ }^{c}$ asyrafman@usm.my${ }^{d}$ mfaisalmbasir@utm.my${ }^{e}$ saratha@usm.my\nHopfield Neural Network (HNN) is a sort of neural network that is strongly dependent to energy minimization of solution. Although HNN managed to solve various optimization problem, the output of HNN suffered from a lack of interpretability and variation. This has severely limited the practical usability of HNN in doing logic programming. Inspired by random neuron perturbation, Estimation of Distribution Algorithm (EDA) has been proposed to explore various optimal neuron state. EDAs employs a probabilistic model to sample the neuron state in order to move toward the various optimal location of global minimum energy. In this paper, a new Mutation Hopfield Neural Network (MHNN) will be proposed to do $k$ Satisfiability programming. Based on the experimental result, the proposed MHNN has outperformed conventional HNN in various performance metric.  \nKeywords: Estimation of Distribution Algorithm, Hopfield Neural Network, Satisfiability Logic Programming, Probabilistic Model, Mutation",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:25",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners initialize the population?",
      "topics": [
        "initialization",
        "EDA"
      ],
      "answer": "When implementing an EDA, the initial population, denoted as P(t) where t is the current generation, should be initialized randomly.",
      "chunk_id": 8937,
      "paper_id": "Differential Evolution with Estimation of Distribution for Worst-Case Scenario Optimization",
      "paper_title": "Differential Evolution with Estimation of Distribution for Worst-Case Scenario Optimization",
      "paper_year": "2021",
      "chunk_content": "The basic flowchart of the EDA is shown in Figure 3. The general steps of the EDA algorithm are the following:  \n1. Initialization: A population is initialized randomly.\n2. Selection: The most promising individuals $S(t)$ from the population $P(t)$, where $t$ is the current generation, are selected.\n3. Estimation of the probabilistic distribution: A probabilistic model $M(t)$ is built from $S(t)$.\n4. Generate new individuals: New candidate solutions are generated by sampling from the $M(t)$.\n5. Create new population: The new solutions are incorporated into $P(t)$, and go to the next generation. The procedure ends when the termination criteria are met.  \n[IMAGE2]  \nFigure 3. Basic flowchart of the estimation of distribution algorithm (EDA).",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:27",
      "generation_style": "practical_application"
    },
    {
      "question": "In the RMM algorithm, which utilizes multiple populations and probabilistic models similar to HIS, how are the average ($\\mu_{i}$) and variance ($\\sigma_{i}^{2}$) parameters initialized for each probabilistic model, and what is the significance of this initialization in the context of real-coded EDAs?",
      "topics": [
        "design"
      ],
      "answer": "In RMM, for each probabilistic model, the average ($\\mu_{i}$) is initialized to be equal to the design variable of the best search point within the corresponding population. The variance ($\\sigma_{i}^{2}$) is initialized as the squared size of 1/4 of the domain. This initialization leverages the normal distribution $N(\\mu_{i}, \\sigma_{i}^{2})$ within PBILc, which RMM refers to, to guide the initial search based on the best-performing individuals and a predefined exploration range controlled by the variance. By setting the variance to a fraction of the domain size, the algorithm balances exploitation around the best initial solutions with exploration of the broader search space.",
      "chunk_id": 11422,
      "paper_id": "Real-coded Estimation of Distribution Algorithm by Using Probabilistic Models with Multiple Learning Rates",
      "paper_title": "Real-coded Estimation of Distribution Algorithm by Using Probabilistic Models with Multiple Learning Rates",
      "paper_year": "2011",
      "chunk_content": "In general EDA, only one population and one probabilistic model are used. Therefore, if the population has been converged and the global optimum is outside the population range, it is difficult to find the global optimum. HIS[12] is another type of EDA that uses multiple populations $\\left(X_{1}, \\cdots, X_{L}\\right)$ and probabilistic models $\\left(p_{1}(x), \\cdots, p_{L}(x)\\right)$ with different diversities. HIS searches using all populations and probabilistic models, and is designed that some populations are converged and others are not. Thus, HIS performs not only to find good solutions quickly but also to avoid converging into the local optimum.  \nHIS has two main operators, which are performed repeatedly sampling and estimation. In sampling, all probabilistic models create search points independently (Fig. 1). In estimation, all the populations are merged into one pool from $X_{l}, X_{l+1}$ and $X_{l-1}$. Then, new probabilistic models are built from the good search points, which are selected from the merged pool (Fig. 2).  \nIn HIS, the diversity of the new created population has to be determined and the target distribution $\\left(q_{1}(x), \\cdots, q_{L}(x)\\right)$ of the probabilistic model should be settled for each model. The target distribution is designed as a model the diversity of which is changed sequentially. In HIS, when a new probabilistic model is created, the number of selected search points is not determined but the target distribution is fixed. Therefore, search points should be selected to build a new probabilistic model that has the target distribution. Thus, the number of selected points is small when the diversity of the target model is small, and conversely the number of selected points is large when the diversity of the target model is large.  \nThis section described several mechanisms of HIS. These mechanisms help HIS to control the diversity of populations. Therefore, HIS can search effectively.\nIn this section, RMM that uses multiple populations and probabilistic models similar to HIS is proposed. RMM refers to a probabilistic model and method for generating search points of PBILc[9]. PBILc uses a simple rule for updating the probabilistic model based on the normal distribution $\\left(N\\left(\\mu_{i}, \\sigma_{i}^{2}\\right)\\right.$, $i$ is a dimension number) in real-coded EDAs, and we feel that facilitates to investigate a effectiveness of using multiple probabilistic models.  \n1. Generate search points using uniform distribution in each population $\\left(X_{1}, \\cdots, X_{L}\\right)$.\n2. Calculate the function values of all search points in populations.\n3. Initialize average $\\left(\\mu_{i}\\right)$ and variance $\\left(\\sigma_{i}^{2}\\right)$ in each probabilistic model. The $\\mu_{i}$ is equal to the design variable of the best search point in the population. The $\\sigma_{i}^{2}$ is set as a squared size of $1 / 4$ of domain.\n4. do $\\{$  \nFor $l=1$ to $L$\n(1) Select good search points from $X_{l-1}, X_{l}, X_{l+1}$.\n(2) Update probabilistic model $p_{l}$ according to eq. 3,4 and learning rate $\\beta_{l}$.\n(3) Generate next population from probabilistic model $p_{l}$.\n(4) Replace population $X_{l}$ with the generated population.\n]until(stopping criterion reached)  \nFigure 3: Pseudo Code  \nThe proposed algorithm has a mechanism to alter the learning rate used for updating each probabilistic model to generate various populations. PBILc uses variance $\\left(\\sigma_{i}^{2}\\right)$ in a probabilistic model, and the value of variance can be controlled by the learning rate.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:29",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the Gene Estimated Gene Expression Programming (GEGEP) approach modify the gene structure of standard Gene Expression Programming (GEP), and what is the computational rationale for this modification?",
      "topics": [
        "evolutionary"
      ],
      "answer": "GEGEP modifies the GEP gene structure by dividing the original gene head into a head and a body. The head contains only functions, while the body contains both functions and terminals. The length of the tail is calculated as tail $=($ head + body $) \")*(\"(\"n\"-\"1\")+\"1, where 'n' represents the maximum arity (number of arguments) of a function. This structure aims to improve the learning mechanism and searching ability, as well as enhance learning ability and convergence rate through the introduction of Estimation of Distribution Algorithm (EDA) principles.",
      "chunk_id": 6284,
      "paper_id": "A new algorithm of automatic programming GEGEP",
      "paper_title": "A new algorithm of automatic programming: GEGEP",
      "paper_year": "2006",
      "chunk_content": "Gene Expression Programming(GEP) was first proposed by Candida Ferreira [1]. In this new syste- m , the complex computer programs (the phenotype) evolved by GEP are totally encoded in simple strings of fixed length (the genotype) .  \nGEP is the inheritance and development of GA and GP, it synthesizes the merits of basic GA and traditional GP and has stronger ability of solving problems [2][3]. However, the learning procedure of GEP can be improved upon when dealing with complex problems with respect to both time efficiency and solution quality. The biological evolutionary process has revealed the principle of evolving from a self-contained functional  \nsingle cell to a well- developed entity with numerous specialized components [4]. We are naturally inspired to assume that solutions to complex problems might be built up incremen- tally from simpler elements. Although the phenotype of expression trees in GEP has retained the struct- ural representation from GP, the linear representation of the genotype conforms to Karva notation, under which the genotype-phenotype mapping mechanism does not guarantee that the levels of functional complexity in the phenotype are also directly reflected in the genotype. Since it is the genotype that is subject to the different genetic operations, it is difficult to follow the approach of incrementally forming solutions with the original GEP. Moreover, an evolved good functional structure is very likely destroyed in the subsequent generations not only by mutations but also by recombination and transpositions, which may require much additional computation to recover before an optimal solution is found. In view of this weakness, we propose a Gene Estimated Gene Expression Programming ( GEGEP), it combines EDA with GEP . Compared with GEP, it mainly has the following characteristics: First, improve the gene expression structure, original gene structure is divided the head of chromosomes into a head and a body, which can be used to introduce the learning mechanism. Second, the homeotic gene which is also composed of a head, a body and a tail is used which can increase its searching ability. Third, the idea of EDA is introduced, which can enhance its learning ability and accelerate the convergence rate. We believe GEGEP benefits the evolution in terms of the convergence of a good functional structure.  \nThe other parts of this article is organized as follows. Section2 explains GEGEP algorithm; Section3 proves the validity of the GEGEP algorithm through experiments; Section 4 presents some conclusions and ideas for future work.\nIn GEGEP, gene head in GEP is divided into a head and a body. The head contains only functions, the body like the head of GEP contains symbols representing both functions and terminals, whereas the length of the tail is a function of head, body and the number of arguments of the function with more arg- uments n(also called maximum arity) and is evaluated by the equation: tail $=($ head + body $) \\times(\\mathrm{n}-1)+1$.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:31",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the hybrid approach for robot reachability assessment, what are the precise algorithmic steps for combining forward and inverse kinematics, as described?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "forward kinematics",
        "inverse kinematics",
        "hybrid approach"
      ],
      "answer": "The hybrid approach first involves randomly sampling robot configurations and using forward kinematics to compute end-effector positions. Then, for target points not reached during the forward kinematics step, inverse kinematics is applied to determine if those points are reachable. The percentage of target points with inverse kinematics solutions indicates reachability for the points not covered by forward kinematics.",
      "chunk_id": 9281,
      "paper_id": "Optimal Design of Continuum Robots With Reachability Constraints",
      "paper_title": "Optimal Design of Continuum Robots With Reachability Constraints",
      "paper_year": "2021",
      "chunk_content": "As shown in [22], to estimate the reachability of a robot, one could randomly sample a large number of robot configurations and use forward kinematics to compute the end-effector position for each configuration. Then, the set of end-effector positions is compared against the set of target points in the workspace to estimate the reachability. Note that computing forward kinematics is quite fast and therefore one could sample a large number of configurations within a given time budget. With a large enough sample size, a reasonable estimate of the reachability could be obtained.  \nOn the other hand, one could employ inverse kinematics to assess the reachability of a robot. For instance, for each target point in the workspace, one could solve for the robot configuration that would result in the end-effector position coinciding with the target point. The percentage of the target points for which solutions are found would then indicate the reachability. While this approach can provide a more accurate assessment of the reachability, computing inverse kinematics for all target points can take a significant amount of time.  \nThe current work therefore uses a hybrid approach. First, random sampling of robot configurations with forward kinematics is performed. Then, for target points that have not been reached during this first step, inverse kinematics is used to check whether those points can actually be reached or not. In this section, we present the forward and inverse kinematic models employed, while the exact implementation of the hybrid approach is described in the Experiments section.  \nWe assume that a robot consists of several non-extensible mutually tangent constant-curvature arcs that can spatially deform. Each joint is composed of a base, top and spine as depicted in Fig. 1. The base and top sections are straight and rigid links,\nwhereas the spine can bend about two orthogonal axes, thus giving each joint two degrees of freedom (DOF). Depending on the joint design, one may need to model the spine as a spatial beam including its longitudinal, bending and torsional deformations altogether [34].  \nGiven the robot's base position $\\vec{r}_{b}$, tangent $\\vec{t}_{b}$ and normal $\\vec{n}_{b}$ (Fig. 2 a and Fig. 2 b), the robot kinematics can be fully configured using its joints' radius of curvature $R(R>0)$ and rotation $\\theta(0 \\leq \\theta \\leq 2 \\pi)$. The latter specifies the rotation of a joint with respect to its respective base normal, so it determines the bending plane of each joint. These parameters, also called state variables, are illustrated in Fig. 2. In order to assess the reachability of a robot, one needs to solve the forward and inverse kinematic equations laid out as follows.  \n1) Forward Kinematics: In a forward kinematic (FK) problem, the goal is to find the spatial position and orientation at different points on the robot, particularly the end-effector, given a set of state variables (i.e. joint radii and rotations). Employing the parametrization introduced earlier and utilizing the Rodrigues' rotation formula [35], the vectors $\\vec{t}_{i}$ and $\\vec{h}_{i}$ depicted in Fig. 2(c) for Joint $i(i \\geq 2)$ read  \n$$\n\\begin{aligned}\n& \\vec{t}_{i}=\\vec{t}_{i-1} \\cos \\left(\\phi_{i-1}\\right)+\\vec{n}_{i-1} \\sin \\left(\\phi_{i-1}\\right) \\\\\n& \\vec{h}_{i}=\\vec{n}_{i-1} \\cos \\left(\\phi_{i-1}\\right)-\\vec{t}_{i-1} \\sin \\left(\\phi_{i-1}\\right)\n\\end{aligned}\n$$  \nin which $\\phi_{i-1}=l_{s, i-1} / R_{i-1}$; and $l_{b, i}, l_{s, i}$ and $l_{t, i}$ represent base, spine and top lengths of Joint $i$, respectively. Therefore, referring to Fig. 2(c) and using (4) one can express $\\vec{n}_{i}$ by  \nFORMULA_36",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:33",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of hybrid algorithms incorporating Estimation of Distribution Algorithms (EDAs) for solving optimization problems, what specific measures are used to evaluate the quality of solutions obtained when addressing the BQP problem and AODV routing optimization in VANETs?",
      "topics": [
        "genetic"
      ],
      "answer": "The quality of solutions for the BQP problem and AODV routing optimization in VANETs is evaluated based on obtaining 'best results' which are determined by assessing the 'quality of solutions' and 'computational speed' achieved by the hybrid algorithm.",
      "chunk_id": 452,
      "paper_id": "Master-Slave Asynchronous Evolutionary Hybrid Algorithm and ITS Application in VANETs Routing Optimization",
      "paper_title": "Master-Slave Asynchronous Evolutionary Hybrid Algorithm and its Application in VANETs Routing Optimization",
      "paper_year": "2014",
      "chunk_content": "Said Mohamed SaidInformation Engineering DepartmentUniversity of the Ryukyus1 Senbaru, Nishihara, Okinawa 903-0213 JAPANsaidy87@hotmail.com  \nMorikazu NakamuraInformation Engineering DepartmentUniversity of the Ryukyus1 Senbaru, Nishihara, Okinawa 903-0213 JAPANmorikazu@ie.u-ryukyu.ac.jp\nHybrid algorithms incorporated with parallel processing techniques are very powerful tools for efficiently solving very complex optimization problems. We present asynchronous parallel computer architecture adaptation based on hybridization of Genetic Algorithms (GAs) and Estimation of Distribution Algorithms (EDAs). In this master-slave formulation, slaves perform evolutionary computation independently using GAs, while master supervises and controls the searching process. Master's role is to probabilistically study the characteristics of solution space and directs the slaves on good searching spots. This study reports some few findings on the ability of our hybrid algorithm to solve some instances of BQP problem as well as AODV routing optimization in VANETs. For both problems our hybrid algorithm has obtained best results in terms of quality of solutions as well as computational speed.  \nKeywords-Hybrid algorithms, Estimation of Distribution Algorithm, Genetic Algorithms, Synchronous algorithms, Asynchronous algorithms, Parallel processing, Master-Slave, FORMULA_0-means clustering, BQP, VANETs, AODV, NS-2;",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:34",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs using the MIMIC learning algorithm with copulas, and how does it address the challenge of selecting an optimal variable permutation?",
      "topics": [
        "mutation"
      ],
      "answer": "The primary objective is to adapt the $MIMIC_{C}^{G}$ algorithm, incorporating copulas to model dependencies without Gaussian assumptions, to enhance Estimation of Distribution Algorithms. This involves finding a permutation \\(\\pi\\) that maximizes the mutual information \\(J_{\\pi}(\\boldsymbol{X})\\), which is equivalent to minimizing the Kullback-Leibler divergence between the true density function \\(f(\\boldsymbol{x})\\) and the proposed density function \\(f_{\\pi}(\\boldsymbol{x})\\). A greedy algorithm is employed to efficiently estimate mutual information \\(\\widetilde{I}\\) and select the variable permutation, prioritizing variable pairs exhibiting the highest mutual dependence as measured by copula entropy.",
      "chunk_id": 6883,
      "paper_id": "Using Copulas in Estimation of Distribution Algorithms",
      "paper_title": "Using Copulas in Estimation of Distribution Algorithms",
      "paper_year": "2009",
      "chunk_content": "In order to show how a probabilistic model based on copulas can be used in EDAs we proposed an adaptation of the $M I M I C_{C}^{G}[11,13]$ with no Gaussian  \nTable 1. Bivariate copulas used in this paper  \nassumption over univariate and bivariate density functions. Next, for completeness sake, we describe the principles of the $M I M I C_{C}^{G}$ learning algorithm.  \nGiven a permutation of the numbers between 1 and $n, \\pi=\\left(i_{1}, i_{2}, \\ldots, i_{n}\\right)$ we define a class of density functions, $f_{\\pi}(\\boldsymbol{x})$ :  \n$$\nf_{\\pi}(\\boldsymbol{x})=f\\left(x_{i_{1}} \\mid x_{i_{2}}\\right) \\cdot f\\left(x_{i_{2}} \\mid x_{i_{3}}\\right) \\cdots f\\left(x_{i_{n-1}} \\mid x_{i_{n}}\\right) \\cdot f\\left(x_{i_{n}}\\right)\n$$  \nOur goal is to choose the permutation $\\pi$ that minimizes the Kullback-Leibler divergence between the true density function $f(\\boldsymbol{x})$ and the proposed density function $f_{\\pi}(\\boldsymbol{x})$ :  \n$$\nD_{K L}(f(\\boldsymbol{x}) \\| f_{\\pi}(\\boldsymbol{x}))=E_{f(\\boldsymbol{x})}\\left[\\log \\frac{f(\\boldsymbol{x})}{f_{\\pi}(\\boldsymbol{x})}\\right]\n$$  \nIt is well known that conditional entropy $H(X \\mid Y)$ and mutual information $I(X, Y)$ are related in the following way:  \n$$\nH(X \\mid Y)=-I(X, Y)+H(X)\n$$  \nwhere $H(X)=-E_{f(x)}[\\log f(x)]$ denotes the entropy of the continuous random variable $X$ with density $f(x)$. The Kullback-Liebler divergence can be written  \nas:  \n$$\n\\begin{aligned}\nD_{K L}(f(\\boldsymbol{x}) \\| f_{\\pi}(\\boldsymbol{x})) & =-H(\\boldsymbol{X})+\\sum_{k=1}^{n-1} H\\left(X_{i_{k}} \\mid X_{i_{k+1}}\\right)+H\\left(X_{i_{n}}\\right) \\\\\n& =-H(\\boldsymbol{X})+\\sum_{k=1}^{n} H\\left(X_{i_{k}}\\right)-\\sum_{k=1}^{n-1} I\\left(X_{i_{k}}, X_{i_{k+1}}\\right)\n\\end{aligned}\n$$  \nThe first two terms in the divergence do not depend on $\\pi$. Therefore, minimize the Kullback-Leibler is equivalent to maximize  \n$$\nJ_{\\pi}(\\boldsymbol{X})=\\sum_{k=1}^{n-1} I\\left(X_{i_{k}}, X_{i_{k+1}}\\right)\n$$  \nwhere  \n$$\nI\\left(X_{i_{k}}, X_{i_{k+1}}\\right)=E_{f\\left(x_{i_{k}}, x_{i_{k+1}}\\right)}\\left[\\log \\frac{f\\left(x_{i_{k}}, x_{i_{k+1}}\\right)}{f\\left(x_{i_{k}}\\right) \\cdot f\\left(x_{i_{k+1}}\\right)}\\right]\n$$  \nAccording to [6], the optimal permutation $\\pi$ is the one that equivalently produces the highest pairwise mutual information with respect to the true distribution. But due to computational efficiency reasons we will employ the greedy algorithm originally proposed by [6] and adapted by [11]. Thus, the MIMIC learning algorithm is based on a dependence test, and this is measured through mutual information. In this paper we will use the following fact (see [5]) between copula entropy and mutual information:  \n$$\n\\begin{aligned}\n-E_{c\\left(u_{1}, u_{2}\\right)}\\left[\\log c\\left(u_{1}, u_{2}\\right)\\right] & =-E_{f\\left(x_{1}, x_{2}\\right)}\\left[\\log \\frac{f\\left(x_{1}, x_{2}\\right)}{f\\left(x_{1}\\right) \\cdot f\\left(x_{2}\\right)}\\right] \\\\\nH\\left(U_{1}, U_{2}\\right) & =-I\\left(X_{1}, X_{2}\\right)\n\\end{aligned}\n$$  \nwhere $U_{1}=F\\left(X_{1}\\right)$ and $U_{2}=F\\left(X_{2}\\right)$.\nOur proposed EDA uses two different dependence functions: a Frank copula and a Gaussian copula. These copulas are chosen because their dependence parameter have associated all range values of Kendall's tau. This means that negative and positive dependence between the marginals are considered in both copulas. However, they differ in the way they model extreme and centered values [25]. For instance, a Frank copula is mostly appropiate for data that exhibit weak dependence between extreme values and strong dependence between centered values. The proposed EDA estimates the copula entropy between each pair of variables in order to calculate the mutual information. The pair of variables with the largest mutual information are selected as the two first variables of the permutation $\\pi$. The following variables of $\\pi$ are chosen according to their mutual information with respect to the previous variable. Algorithm 2 shows a straightforward greedy algorithm to find a permutation $\\pi$.  \n```\nAlgorithm 2. Greedy algorithm to pick a permutation \\(\\pi\\)\nchoose \\(\\left(i{n}, i{n-1}\\right)=\\arg \\max {j \\neq k} \\widetilde{I}\\left(X{j}, X{k}\\right)\\), where \\(\\widetilde{I}()\\) is an estimation of the mutual\ninformation between two variables.\nchoose \\(i{k}=\\arg \\max {j} \\widetilde{I}\\left(X{i{k+1}}, X{j}\\right)\\), where \\(j \\neq i{k+1}, \\ldots, i{n}\\) and\n\\(k=n-1, n-2, \\ldots, 2,1\\).",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:36",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of CM-MEDA utilize the Covariance-Matrix to evolve a population, specifically detailing the transformations between coordinate spaces?",
      "topics": [
        "representation"
      ],
      "answer": "CM-MEDA uses the Covariance-Matrix, denoted as C, of selected samples to estimate the marginal distribution of the problem in a transformed space. This transformed space is the characteristic space of C. The algorithm calculates the matrix P, which defines the characteristic space. Selected samples, represented as \\(\\bar{x}\\), are transformed to this new space using \\(\\bar{x}^{T}=P^{T} \\cdot \\bar{x}\\). Marginal distributions are then estimated in this new space, and new samples \\(\\overline{\\bar{x}^{\\prime}}\\) are generated. Finally, these new samples are transformed back to the original coordinate space using \\(\\stackrel{\\bar{\\sigma}}{\\bar{x}}=\\left(P^{-1}\\right)^{T} \\cdot \\overline{\\bar{x}^{\\prime}}=P \\cdot \\overline{\\bar{x}^{\\prime}}\\, discarding and resampling any 'illegal' samples that fall outside constraints.",
      "chunk_id": 6005,
      "paper_id": "Linkages Detection in Histogram-Based Estimation of Distribution Algorithm",
      "paper_title": "Linkages Detection in Histogram-Based Estimation of Distribution Algorithm",
      "paper_year": "2008",
      "chunk_content": "We first review several basic and well-known properties of Covariance-Matrix. The Covariance-Matrix of a set of samples is defined as follows:\nGiven a set of $m$ samples $\\bar{x}_{i}$, where $\\bar{x}_{i}=\\left(x_{i 1}, x_{i 2}, \\ldots, x_{i j}\\right)^{T}$\nThe Covariance-Matrix is defined as  \n$$\nC=\\frac{1}{m-1} \\sum_{i=1}^{m}\\left(\\overline{x_{i}}-\\bar{x}_{i}\\right)\\left(\\overline{x_{i}}^{T}-\\bar{x}_{i}^{T}\\right)\n$$  \nAnd it has the following important properties:  \n1. The Covariance-Matrix is real and symmetric, that is:  \n$$\nc_{i j} \\in R(\\forall i, j=1, \\ldots, l) \\text { and } C=C^{T}\n$$  \n2. The Covariance-Matrix is diagonalizable, that is:  \n$$\n\\begin{gathered}\n\\exists Q, \\text { s.t. } C=Q[\\lambda] Q^{-1} \\\\\n\\text { where }[\\lambda]=\\operatorname{diag}\\left(\\lambda_{1}, \\lambda_{2}, \\ldots, \\lambda_{l}\\right)\n\\end{gathered}\n$$  \n3. All the eigenvectors with different eigenvalues are orthogonal with each other.\n4. There exists a matrix $P=\\left(\\overline{p_{1}}, \\overline{p_{2}}, \\ldots, \\overline{p_{l}}\\right)$, which satisfies $C=P[\\lambda] P^{-1}$ and all $\\overline{p_{i}}$ are orthogonal with each other, that is $P^{T}=P^{-1}$.  \nFinally, we formulate some important representations. The space defined in $P$ is the characteristic space of the Covariance-Matrix $C$, and each $p_{i}$ is the basis of the space. Clearly, according to Property 2 and Property 4, we have $C=P^{T}[\\lambda] P$, where $[\\lambda]=\\operatorname{diag}\\left(\\lambda_{1}, \\lambda_{2}, \\ldots, \\lambda_{l}\\right)$.\nThe CM-MEDA is an algorithm which estimates the marginal distribution of the problem on a transformed space: the characteristic space of the Covariance-Matrix of the selected samples.  \nThe algorithm begins with an initialized population that is generated randomly. In each generation, it evaluates the fitness of each sample and selects several promising samples. The above two step has no difference from any other evolutionary algorithms.  \nThen the CM-MEDA calculates the Covariance-Matrix $C$ on the selected samples and then calculates the matrix $P$, which defines the characteristic space of the Covari-ance- Matrix $C$.  \nAfter $P$ is obtained, the selected samples are transformed to the new space by multiplying $P^{T}$, so we can obtain the value on each variable in the new coordinate space. Assuming a selected sample of $x$, this step is finished by $\\bar{x}^{T}=P^{T} \\cdot \\bar{x}$.  \nThe marginal distributions are estimated in the new space. After the marginal distributions of the variables in the new space have been estimated, new $\\overline{\\bar{x}^{\\prime}}$ are sampled according to the estimated distribution in each variable.  \nAt last, we transform the samples back into the initial coordinate space, according to $\\stackrel{\\bar{\\sigma}}{\\bar{x}}=\\left(P^{-1}\\right)^{T} \\cdot \\overline{\\bar{x}^{\\prime}}=P \\cdot \\overline{\\bar{x}^{\\prime}}$.  \nNote that when we transform the samples back, some samples might out of constraints. If that happens, we discard those \"illegal\" samples and resample the new ones. After we have built the new population, we evaluate the fitness and go to the next generation.  \nIn short, the framework of CM-MEDA is as followed:  \n1. Initialize the population\n2. Select the samples with high fitness\n3. Calculate the Covariance-Matrix $C$ of the selected samples and build the matrix $P$\n4. Transform the selected samples onto the characteristic space of the CovarianceMatrix by $\\overline{\\bar{x}^{\\prime}}=P^{T} \\cdot \\bar{x}$\n5. Estimate the marginal models on the new space according to the distribution of the transformed selected samples\n6. Make new samples $\\overline{\\bar{x}}$ according to the marginal models in the transformed space\n7. Transform the new samples from the transformed space back to the original space by FORMULA_107 and check if all the new samples are legal. Resample the illegal samples.\n8. Return to step 2 if not terminated.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:39",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using Restricted Boltzmann Machines (RBM-EDA), how should practitioners leverage the bipartite structure of RBMs to parallelize the training process, specifically when calculating neuron activations during Gibbs sampling?",
      "topics": [
        "search"
      ],
      "answer": "To parallelize RBM-EDA training, practitioners should exploit the independence of neurons within the visible and hidden layers due to the RBM's bipartite structure. During a Gibbs sampling step, for example, when calculating the activation of visible neurons \\(v_i\\) given the hidden layer, the activation of all \\(v_i\\) can be computed using \\(n\\) independent threads, where \\(n\\) is the number of visible neurons. Similarly, when calculating the activation of hidden neurons, the activation of \\(m\\) neurons can be calculated independently. Furthermore, when training with mini-batches of size \\(B\\), the activation of \\(B * m\\) independent neurons needs to be calculated for the \\(V_b \\rightarrow H_b\\) step, and \\(B * n\\) for the \\(H_b \\rightarrow V_b\\) step. This allows for efficient parallel computation using standard libraries without modifying the RBM-EDA model itself.",
      "chunk_id": 1086,
      "paper_id": "An implicitly parallel EDA based on restricted boltzmann machines",
      "paper_title": "An Implicitly Parallel EDA Based on Restricted Boltzmann Machines",
      "paper_year": "2014",
      "chunk_content": "It is simple and efficient to parallelize the training and sampling of RBM-EDA. Also, parallelization can be achieved without changes to the model itself. The reason is that, due to their bipartite structure, RBMs are implicitly parallel. Furthermore, the actual implementation can use standard libraries for most of the computational steps.\nThe RBM's bipartite structure factorizes the distributions of both visible and hidden layer. That is, a visible neuron $v_{i}$ is independent of all other visible neurons $v_{j \\neq i}$, given the activation of the $m$ neurons of the hidden layer, and vice versa. Hence, the activation of all $v_{i}$ can be calculated by $n$ independent threads. This holds for training and sampling.  \nFurthermore, contrastive divergence, which is used for training, is a stochastic gradient ascent algorithm and usually implemented in a mini-batch fashion. That is, we simultaneously calculate $\\Delta w_{i j}$ in (4) for each training example in a mini-batch of size $B$, and subsequently use the average to update $w_{i j}$. This reduces sampling noise and makes the gradient more stable $[1,7]$. The initial population in an EDA is usually random. Thus, the signal-to-noise ratio is low and the batch size $B$ can be even larger than in classical, well structured training tasks.  \nHence, when training with mini-batches of batch size $B$, the activation of $B * m$ independent neurons has to be calculated to perform a single Gibbs sampling step $V_{b} \\rightarrow H_{b}$ for all $b=1,2, \\ldots, B$ using Equation 2. Accordingly, to perform a single Gibbs sampling step $H_{b} \\rightarrow V_{b}$, the activation of $B * n$ independent neurons is calculated using (1). Thus, for training, the number of independent neurons grows linearly with the problem size $n$, given that $m$ is some fixed fraction of $n$. When sampling new candidate solutions, all individuals are independent, so $B$ is equal to the number of new individuals. Hence, for sampling, the number of independent neurons grows linearly with the problem size and with the population size.  \nRecall that, unlike other EDA models based on probabilistic graphical models, RBM-EDA does not separate the search for a suitable network structure from parameter estimation. During training, the connectivity of the RBM remains unchanged. Only the strength of the connections are adjusted. Hence, there is no need for mechanisms balancing unequal workloads due to different subproblem sizes.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:41",
      "generation_style": "practical_application"
    },
    {
      "question": "How is the computational complexity of the hierarchical Bayesian Optimization Algorithm (hBOA) analyzed with respect to the number of problem variables and population size, and what are the implications for its scalability?",
      "topics": [
        "genetic"
      ],
      "answer": "The hierarchical Bayesian Optimization Algorithm (hBOA) requires asymptotically $\\mathcal{O}(n \\ell^{3})$ time per generation, where $\\ell$ represents the number of problem variables and $n$ represents the population size. Furthermore, the number of generations required to solve a problem is typically in the order of $\\mathcal{O}(\\sqrt{\\ell})$. This polynomial-time scale-up of population size and number of function evaluations allows hBOA to solve problems with hierarchical dependency structures. However, estimating entire probability distributions requires estimating both a dependency structure and its parameters, and quality-of-fit measures are needed to decide when to stop the greedy learning approach, which increases the complexity of the underlying dependency structure.",
      "chunk_id": 2911,
      "paper_id": "Parameterless Gene-pool Optimal Mixing Evolutionary Algorithms",
      "paper_title": "Parameterless Gene-pool Optimal Mixing Evolutionary Algorithms",
      "paper_year": "2024",
      "chunk_content": "The most advanced EDA in this line is commonly accepted to be the hierarchical Bayesian Optimization Algorithm (hBOA) [33]. Both its predecessor BOA and hBOA itself estimate a Bayesian network every generation using a greedy learning procedure. hBOA however has the ability to store the parameters in this network more efficiently by storing only those combinations of values for dependent variables that actually appear in the population, thereby preventing the need to generate huge probability tables that require the explicit enumeration of all possible value combinations of a set of dependent variables. This, combined with a mechanism (restricted tournament selection) that promotes population diversity, allowed hBOA to be the only EDA capable of solving problems with hierarchical dependency structures while requiring only low-order polynomial-time scale-up of the population size and number of function evaluations Although to a large extent now satisfactorily solving the linkage problem and providing a solid, statistically sound basis for doing so, the overhead required by hBOA is still substantial, requiring asymptotically $\\mathcal{O}\\left(n \\ell^{3}\\right)$ time per generation where $\\ell$ is the number of problem variables and $n$ the population size. Moreover, the number of generations required to solve a problem is typically in the same order as a properly configured GA, which is typically in the order of $\\mathcal{O}(\\sqrt{\\ell})$ [32].  \nAlthough a solid approach to tackling the linkage problem, estimating entire probability distributions comes with the necessity to estimate not only a dependency structure, but also to estimate parameters (e.g., actual probabilities). Moreover, in order to decide what underlying dependency structure is a good one, i.e., not missing key dependencies and not overly complex, quality-of-fit measures need to be computed that decide when to stop the greedy learning approach that iteratively increases the complexity of the underlying dependency structure. These aspects are not necessarily important for tackling the linkage problem, because for that it would suffice to know which variables are (strongly) dependent on which\nother variables. The joint probabilities of entire building blocks do not explicitly need to be computed, as they are stored implicitly in the population. Mixing the information stored in the population therefore automatically follows these probabilities. It is on these foundations that the GOMEA framework is based. GOMEA was first introduced in 2011 [4], posed as a broadened scope of the idea behind the original Linkage Tree Genetic Algorithm (LTGA) introduced in 2010 [39]. LTGA was one of the first algorithms to depart from the EDA principle of estimating entire probability distributions, and thus essentially going back to the notion of genetic algorithm, but still using similar statistical concepts as used in EDAs to detect dependencies. Ultimately this lead to a model-building complexity of an order of magnitude faster FORMULA_4 than hBOA, while being able to capture and exploit both low-order dependencies as well as high-order dependencies at the same time. Moreover, LTGA requires only a handful of generations to find the optimal solution due to much more extensive model exploitation during variation, further reducing the overall required model-building complexity. As later versions of LTGA, including the one presented in this article, are seen as instances of the GOMEA framework, details will be described in subsequent sections. Besides LTGA which we will from now refer to as LT-GOMEA, other non-EDA algorithms that build models to model and exploit linkage information have been proposed of late [24], [9], [17]. These algorithms that can more generally be described as model-based EAs have also been successful at outperforming hBOA.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:43",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How do the feasible domains of the Sickle function and the Koziel and Michalewicz G6 function differ, based on the descriptions provided?",
      "topics": [
        "representation"
      ],
      "answer": "The Sickle function has a feasible domain that is described as not convex. In contrast, both the global minimum and global maximum points of the Koziel and Michalewicz G6 function are unbounded, meaning they are located inside its feasible domain.",
      "chunk_id": 13321,
      "paper_id": "Constrained Optimization Problem Solving Using",
      "paper_title": "Constrained optimization problem solving using estimation of distribution algorithms",
      "paper_year": "2004",
      "chunk_content": "Several numerical experiments have been performed on solving three constrained objective functions. Since graphical representation and animation of the successive populations can provide a valuable insight into how algorithms work, preference has been given to the following test functions of two variables:\n[IMAGE0]  \nFigure 1. Graph of the Sickle function\nThis is a slightly modified version of problem G6 in reference [13] which requires minimizing the function:  \n$$\n\\mathrm{F}\\left(\\mathrm{x}_{1}, \\mathrm{x}_{2}\\right)=\\left(\\mathrm{x}_{1}-20\\right)^{2}+\\left(\\mathrm{x}_{2}-10\\right)^{2}\n$$  \nsubjected to:  \n$$\n\\begin{aligned}\n& \\mathrm{g}_{1}=\\left(\\mathrm{x}_{1}-5\\right)^{2}+\\left(\\mathrm{x}_{2}-5\\right)^{2}-100 \\geq 0 \\\\\n& \\mathrm{~g}_{2}=-\\left(\\mathrm{x}_{1}-5\\right)^{2}-\\left(\\mathrm{x}_{1}-6\\right)^{2}+82.81 \\geq 0\n\\end{aligned}\n$$  \nand the side constraints:  \n$$\n0 \\leq \\mathrm{x}_{1} \\leq 10 \\text { and } 14 \\leq \\mathrm{x}_{2} \\leq 15.5\n$$  \nIn its original form [13], the side constrains were over 10 times wider, making the ratio between the feasible and the infeasible spaces very small and therefore a starting feasible point hard to find. The global minimum point is located at $\\mathrm{x}_{1}=14.095$ and $\\mathrm{x}_{2}=0.84296$ for which the function value is -6961.8139 and both constraints are active. The maximum point, also double bounded, is located at $\\mathrm{x}_{1}=14.095$ and $\\mathrm{x}_{2}=9.15704$ and equals 1206.13556. As shown by the plot in Figure 1, the feasible domain of this function is not convex.\n[IMAGE1]  \nFigure 2. Graph of Koziel and Michalewicz's G6 function\nTest Problem2 - Koziel and Michalewicz G6 function\nThis second problem [13] requires finding the maximum point of:  \n$$\n\\mathrm{F}\\left(\\mathrm{x}_{1}, \\mathrm{x}_{2}\\right)=\\frac{\\sin \\left(2 \\pi \\mathrm{x}_{1}\\right) \\cdot \\sin ^{2}\\left(2 \\pi \\mathrm{x}_{2}\\right)}{\\left(\\mathrm{x}_{1}+\\mathrm{x}_{2}\\right) \\cdot \\mathrm{x}_{2}^{2}}\n$$  \nsubjected to:  \n$$\n\\begin{aligned}\n& \\mathrm{g}_{1}=\\mathrm{x}_{1}-\\mathrm{x}_{2}^{2}-1 \\geq 0 \\\\\n& \\mathrm{~g}_{2}=-\\left(\\mathrm{x}_{1}-4\\right)^{2}+\\mathrm{x}_{2}-1 \\geq 0\n\\end{aligned}\n$$  \nand the side constraints (modified as compared to the original form in [13] for the same reason as before):  \n$$\n3.2 \\leq \\mathrm{x}_{1} \\leq 5.2 \\text { and } 0.9 \\leq \\mathrm{x}_{2} \\leq 2.1\n$$  \nThis multimodal function has its global maximum at $\\mathrm{x}_{1}=1.24539$ and $\\mathrm{x}_{2}=4.2425$ and equals 0.09582504 . The global minimum is located at $\\mathrm{x}_{1}=1.24492$ and $\\mathrm{x}_{2}=3.74154$ where the function value is -0.10363448 . Both the global minimum and the global maximum points are unbounded i.e. they are located inside the feasible domain (Figure 2).\nThe third test problem, due to Keane, also listed as problem G2 in [6], requires minimizing the function:  \n$$\n\\mathrm{F}\\left(\\mathrm{x}_{1} \\ldots \\mathrm{x}_{n}\\right)=\\frac{\\left|\\sum_{i=1}^{n} \\cos ^{4}\\left(\\mathrm{x}_{i}\\right)-2 \\prod_{i=1}^{n} \\cos ^{2}\\left(\\mathrm{x}_{i}\\right)\\right|}{\\sqrt{\\sum_{i=1}^{n} i \\cdot \\mathrm{x}_{i}^{2}}}\n$$  \nsubjected to:  \n$$\n\\begin{aligned}\n& \\mathrm{g}_{1}=\\sum_{i=1}^{n} \\mathrm{x}_{i}-7.5 n \\leq 0 \\\\\n& \\mathrm{~g}_{2}=0.75-\\prod_{i=1}^{n} \\mathrm{x}_{i} \\leq 0\n\\end{aligned}\n$$  \nand to the side constrains:  \n$$\n0 \\leq \\mathrm{x}_{i} \\leq 10 \\text { for } 1 \\leq i \\leq n\n$$  \nThis is a highly multimodal function that has its global minimum constrained by $\\mathrm{g}_{2}$. For $n=2$ its optimum equals $-0.36497974$ and occurs for $\\mathrm{x}_{1}=1.60086$ and $\\mathrm{x}_{2}=0.468498$. According to [6], for $n=20$ the minimum value found so far equals -0.8036 .\n[IMAGE2]  \nFigure 3. Graph of Keane's function with FORMULA_53",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:44",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, specifically the PBIL algorithm, when it's used for parameter self-adaptation in a metaheuristic like Differential Evolution (DE), considering the two levels of design variables?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Parameter Adaptation",
        "Differential Evolution",
        "PBIL",
        "Coding Heuristic"
      ],
      "answer": "The code should implement two levels of design variables: a high-level design variable \\(\\mathbf{x}_{h}\\) and a low-level design variable \\(\\mathbf{x}_{l}\\). The high-level variable \\(\\mathbf{x}_{h}\\) represents the control or optimization parameters for DE, such as \\(F_{\\text{scheme}}\\), \\(F_1\\), \\(F_2\\), \\(C_R\\), and \\(I_{\\text{reprod}}\\). These parameters are used to generate the low-level design variable \\(\\mathbf{x}_{l}\\), which represents the design variables of the optimization problem being solved by DE. The PBIL algorithm iteratively estimates the parameters in \\(\\mathbf{x}_{h}\\), while DE searches for the best design solutions using \\(\\mathbf{x}_{l}\\). The code must ensure that the decoding of \\(\\mathbf{x}_{h}\\) into \\(\\mathbf{x}_{l}\\) mirrors the reproduction process of DE, and that all variables are properly bounded.",
      "chunk_id": 1449,
      "paper_id": "Multiobjective meta-heuristic with iterative parameter distribution estimation for aeroelastic design of an aircraft wing",
      "paper_title": "Multiobjective meta-heuristic with iterative parameter distribution estimation for aeroelastic design of an aircraft wing",
      "paper_year": "2022",
      "chunk_content": "It has long been found that optimisation parameter settings for MHs such as crossover and mutation rates in GA greatly affect their performance. Meta-heuristics with parameter adaptation, also known as self-adaptive MHs, are usually more powerful than their constant-parameter counterparts. Self-adaptive MHs are optimisers that can automatically tune the values of their key parameters for any optimisation problem being solved. There have been several concepts used for parameter adaptation such as SaNSDE-WEE [43], SHADE [44], and fuzzy logics [45]. Self-adaptive strategies for MHs are a simple type of learning algorithms, which can be roughly grouped as strategies for control or optimisation parameters settings and that for selection reproduction operators. For the first group, the probability of using a particular value of a control parameter is based on the history of its successful/failed use. Generation of optimisation parameter can be based on randomisation with a particular type of statistical distribution [43, 44, 46], interval selection [47], fitness-based adaptation [48], and fuzzy logic decision making [49]. The self-adaptive selection of reproduction operators, on the other hand, can be carried out using a statistical outlier detection method [50], and a history-based approach $[43,44,46]$. To our knowledge, there has never been a study on using an estimation of distribution algorithm (EDA), one of the learning algorithms, for parameter self-adaptation of MHs. This work is probably the first paper to investigate this issue. EDA used herein is PBIL which works on the\nbinary searching spaces. The algorithm is embedded into the main search of differential evolution while the dominancebased approach is used for dealing with multiple objective functions.  \nThe proposed multiobjective optimiser, as it is named, exploits and modifies part of the reproduction of differential evolution (DE) for population generation while PBILM is used to iteratively estimate DE parameters. Modified multiobjective DE (MODE) and PBILM are operated in parallel whereas MODE searches for the best design solutions of the original design problem but PBILM searches for a set of acceptable optimisation parameters successfully used by MODE. As a result, two (high and low) levels of design variables will also be used. The design variables for the high-level denoted as $\\mathbf{x}_{h}$ will have elements representing the control or optimisation parameters similar to those used for generating a design vector in DE procedures. For this study, the high-level design variables consist of:\n$\\mathbf{x}_{h}=\\left\\{F_{\\text {scheme }}, F_{1}, F_{2}, C_{R}, I_{\\text {reprod }}\\right\\}^{T}$\nwhere $F_{\\text {scheme }}$ is the choices for creating the value of a scaling factor $F . F_{1}$ and $F_{2}$ will be used for generating the scaling factor. $C_{R}$ is used for generating the value of a binomial crossover parameter $\\left(C_{R}\\right) . I_{\\text {reprod }}$ is the choices for a reproduction scheme. The elements of the high-level design vector will be used to create a vector of low-level design variables denoted by $\\mathbf{x}_{l}$, which is the design variables of  \nthe optimisation problem being solved. These two types of variables are coupled in such a way that the high-level design variable controls the reproduction of the low-level design variables. All the variables in Eq. (5) will be properly bounded. The decoding of $\\mathbf{x}_{\\mathbf{0}}$ into $\\mathbf{x}$ or $\\mathbf{x}_{\\mathbf{j}}$ is carried out in a similar manner to the reproduction of DE. In this work as our first study, the number of schemes for generating $F$ will be\n$F=\\left\\{\\begin{array}{l}n \\operatorname{rand}\\left(F_{1}, F_{2}\\right) ; F_{\\text {scheme }}=1 \\\\ \\operatorname{rand}\\left(F_{2}, F_{1}\\right) ; F_{\\text {scheme }}=2\\end{array}\\right.$",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:47",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metric is used to evaluate the performance of the four algorithms (DE, DEeEDA, GA, and PSO) when analyzing the effect of the number of jobs, layers, workstations, and machines on their performance?",
      "topics": [
        "optimization"
      ],
      "answer": "The \\$\\delta\\$ average is the specific metric used to evaluate the performance of the algorithms. This metric is plotted on the vertical axis in figures illustrating the effect of the number of jobs, number of layers, number of workstations, and number of machines on the performance of the four algorithms.",
      "chunk_id": 10946,
      "paper_id": "A hybrid differential evolution algorithm with estimation of distribution algorithm for reentrant hybrid flow shop scheduling problem",
      "paper_title": "A hybrid differential evolution algorithm with estimation of distribution algorithm for reentrant hybrid flow shop scheduling problem",
      "paper_year": "2018",
      "chunk_content": "The GA and the PSO are of canonical procedure with the encoding and decoding schemes the same as the ones proposed in this paper. For the GA, the main procedures are selection, crossover and mutation. In this paper, we use roulette wheel selection, partial mapped crossover and swap mutation. The parameters are also set by using a medium-sized problem with $N=30, L_{i}=[1,2], J_{i}=[5,7]$ and $M_{j}=8$. The experiment trials are carried out consisting of three levels of popsize (50, 80 and 110), three levels of crossover probability $p_{\\mathrm{c}}(0.5,0.7$ and 0.9$)$ and three levels of mutation probability $p_{\\mathrm{m}}(0.15,0.2$ and 0.25$)$. A good choice of parameter combination for the GA is suggested as popsize $=80, p_{\\mathrm{c}}=0.5$ and $p_{\\mathrm{m}}=0.15$. As for the PSO, each particle flies in the multi-dimensional search space of the optimization problem looking for optimal solutions, while its position and velocity are updated by learning from its own experience and the performance of its peers. The parameters are also set by using a mediumsized problem the same as the GA. The experiment trials are carried out consisting of three levels of popsize (40, 70 and 100). A good choice of parameter is popsize $=70$. Other parameters are set as follows: learning factors $c_{1}=c_{2}=0.2$, and inertia weight $w$ is initially set as 0.9 and then linearly decreased to 0.4 according to the number of iterations, where the parameters are set according to general conditions. The number of iterations for the GA and the PSO is set as 200.  \nTable 3 depicts that the DE performs the worst among the four algorithms with the least CPU time. The DEeEDA greatly improves the performance of the DE, while its CPU time is still satisfactory. It validates that the incorporation of the idea of the EDA with the ensemble model into the DE is very effective for improving the performance of the DE.  \nBesides, compared with the GA and the PSO, the DEeEDA achieves the best solutions among the three algorithms. This is because DE-eEDA embeds the probabilistic model in the mutation operators to exploit the solution  \nTable 2 Comparing $\\delta$ average in different algorithms  \nTable 2 continued\nTable 3 Comparing $\\delta$ average in different algorithms  \nTable 3 continued\n[IMAGE1]  \nFig. $3 \\delta$ average in different number of jobs\n[IMAGE2]  \nFig. $4 \\delta$ average in different number of layers\nspace with collective information in global scope,especially the information of the similar blocks of jobs in the selected sequences, which has been verified to provide important information for evolution [33-35], while GA and PSO are updated using no such information. It can also be known that in order to collect and process the global information, the CPU time of the DE-eEDA is a little more than that of the GA and the PSO, which is still within a few seconds though. Thus, DE-eEDA can be applied to solve the RHFS problem and is usually true for its outperformance.  \nTo further analyze the data, we tested the effect of number of jobs, number of layers, number of workstations and number of machines on the performance of the four algorithms, respectively. The results are shown in Figs. 3, 4,5 and 6 . The vertical axis represents the $\\delta$ average.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:49",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in the context of image registration using the Full variate Gaussian model-based RM-MEDA?",
      "topics": [
        "performance"
      ],
      "answer": "The primary purpose is to improve image registration by using a multi-objective estimation model solved by a Full variate Gaussian model-based RM-MEDA (FRM-MEDA), an Estimation of Distribution Algorithm, to reduce computational overhead and the possibility of false registration, especially when dealing with a large number of feature points, which is a drawback of methods like RANSAC.",
      "chunk_id": 11954,
      "paper_id": "A novel Multi-objective Optimization-based Image Registration Method",
      "paper_title": "A Novel Multi-objective Optimization-based Image Registration Method",
      "paper_year": "2016",
      "chunk_content": "Meifeng ShiCollege of ComputerScience, Chongqing Univ. Chongqing 400044, China $+8613983701748$ shishating@163.com  \nZhongshi HeCollege of ComputerScience, Chongqing Univ. Chongqing 400044, China $+8613062356757$ zshe@cqu.edu.cn\nThe RANSAC is widely used in image registration algorithms. However, the RANSAC becomes computationally expensive when the number of feature points is large. And also, its high errormatching ratio caused by the large number of iterations always raises the possibility of false registration. To deal with these drawbacks, a novel multi-objective optimization-based image registration method is proposed, named MO-IRM. In MO-IRM, a multi-objective estimation model is built to describe the feature matching pairs (data set), with no need for the pre-check process that is necessary in some improved RANSAC algorithms to eliminate the error-matching pairs. Moreover, a full variate Gaussian model-based RM-MEDA without clustering process (FRM-MEDA) is presented to solve the established multi-objective model. FRM-MEDA only requires a few iterations to find out a correct model. FRM-MEDA can not only greatly reduce the computational overhead but also effectively decrease the possibility of false registration. The proposed MO-IRM is compared with RMMEDA, NSGA- $\\square$ and the RANSAC based registration algorithm on the Dazu grottoes image database. The experiment results demonstrate that the proposed method achieves ideal registration performances on both two images and multiple images, and greatly outperforms the compared algorithms on the runtime.  \nKeywords: Multi-objective Optimization, Full variate Gaussian Model, Estimation of Distribution Algorithm, Image Registration, RANSAC\nImage mosaic method has become popular in the fields of image processing, computer vision and computer graphics so far. Feature based mosaic methods include five steps: feature extraction, feature description, feature matching, model estimation and image fusion. The first four steps are referred as image registration. Image registration has a significant impact on the performance of image mosaic and thus is the key and core of image mosaic.  \nFor image registration, feature extraction, feature description and feature matching have been widely explored but the model estimation is not studied well. Generally speaking, there are many inevitable mismatching feature points in the feature matching step.  \n[^0]PRang Zhang College of Computer Science, Chongqing Univ. Chondqing 400044, China FORMULA_3 chenziyu@cqu.edu.cn",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:50",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the Hybrid Multiobjective Estimation of Distribution Algorithm (HMEDA), how do the algorithmic mechanisms of Local Linear Embedding (LLE) and the sparse individual clonal algorithm (SICA) interact to balance exploration and exploitation during the search and optimization process, and what is the resulting time complexity?",
      "topics": [
        "complexity"
      ],
      "answer": "HMEDA combines LLE, an Estimation of Distribution Algorithm (EDA) that extracts global information to build an orthogonal sample model, with SICA, which focuses on less-crowded regions to offset LLE's potential loss of independent behavior of promising individuals. LLE's worst-case time complexity is \\(O(m N^{2})\\), where \\(N\\) is the population size and \\(m\\) is the number of objectives. SICA identifies nondominated individuals with time complexity \\(O(N^{2})\\) and performs nondominated spare individual selection with complexity \\(O(N_{1} \\log (N_{1}))\\), where \\(N_1\\) is the clone population size. The overall worst-case time complexity of one generation of HMEDA is \\(O(m N^{2})\\), reflecting the dominance of the LLE component in the algorithm's computational cost.",
      "chunk_id": 6571,
      "paper_id": "Hybrid multiobjective estimation of distribution algorithm by local linear embedding and an immune inspired algorithm",
      "paper_title": "Hybrid Multiobjective Estimation of Distribution Algorithm by Local Linear Embedding and an Immune Inspired Algorithm",
      "paper_year": "2009",
      "chunk_content": "It can be seen that HMEDA uses two kinds of optimization methodologies. The EDA is based on a well-known manifold learning algorithm, local linear embedding. It explicitly extracts globally information from the current population and builds an orthogonal sample model in the manifold space. The EDA is expected to find the common intrinsic characteristics of current population, however, the independent behavior of promising individuals may be lost. In order to offset the shortcoming of EDA, a sparse individual clonal algorithm that pays more attention to the less-crowded regions of the current tradeoff front is introduced to the EDA. Some of the offspring are generated by LLE, while the rest ones are from SICA. Therefore, a tradeoff between the exploration ability of the EDA and the exploitation ability of SICA is maintained, which is often crucial to the success of the search and optimization process.\nIn this section, we will present the computational complexity of HMEDA. Assuming the size of population is $N_{i}$ and $m$ is the number of objectives. The size of active population is $e$, the clone population size is $N_{L}$, and the maximum number of nearest neighbors is $k$. The time complexity of one generation for the algorithm can be  \ncalculated as follows:\nIn Algorithm 3, the worst time complexity of LLE is $O\\left(m N^{2}\\right)$; computing nearest neighbors scales as $O\\left(m N^{2}\\right)$ in the worst case; the worst time complexity of computing the reconstruction weights is $O\\left(n N K^{3}\\right)$; the time complexity of nondominated sorting is $O\\left(m N^{2}\\right)$.  \nIn Algorithm 2, the time complexity for identifying nondominated individuals in population is $O\\left(N^{2}\\right)$; the worst time complexity for nondominated spare individual selection is $O\\left(N_{1} \\log \\left(N_{1}\\right)\\right)$; the time complexity for cloning, recombination and mutation operation are $O\\left(N_{1}\\right)$.  \nAccording to the operational rules of the symbol $\\boldsymbol{O}$, the worst time complexity of one generation for HMEDA can be simplified as $O\\left(m N^{2}\\right)$.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:53",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners address the trade-off between capturing statistical dependencies and avoiding spurious correlations when learning the probabilistic model, specifically when using Tree-EDA?",
      "topics": [
        "comparison"
      ],
      "answer": "When using Tree-EDA, practitioners should consider analyzing the tree structures learned in the initial generations. The rationale is that as the EDA evolves, population diversity decreases, leading to spurious correlations due to sampling. Focusing on the first generation allows for capturing problem information from the data generated along the evolution, such as interactions within the original contact graph, before the loss of diversity compromises the learned statistical dependencies. For example, when analyzing protein instances, one could construct contact matrices from edges appearing frequently (e.g., at least 50 times out of 1000 runs) in the trees learned during the first generation to identify significant statistical dependencies.",
      "chunk_id": 6378,
      "paper_id": "The role of a priori information in the minimization of contact potentials by means of estimation of distribution algorithms",
      "paper_title": "The role of a priori information in the minimization of contact potentials by means of estimation of distribution algorithms",
      "paper_year": "2007",
      "chunk_content": "As an initial experiment, we investigated if there was any mapping between the statistical dependencies learned by the tree learning algorithm and the structure of the problem. We stored the tree structures learned in the first generation of Tree-EDA for protein instances pdb4clg-A and pdb1aoo (see footnote 1). The algorithm was run 1000 times for each instance. We counted the number of times each edge appeared in the trees. Figure 1a) and 1b) show the contact matrices constructed for edges that were in at least 50 of the 1000 trees learned. The similarity between the structures learned and the original contact matrices of the graphs (Figures 1c) and 1d)) is remarkable.  \nThe decision of analyzing only the structures learned in the first generation was motivated by the fact that, as the EDA evolves, diversity in the population is lost and spurious correlations due to sample arise. The possibility of capturing many of the interactions that are in the original contact graph shows that EDAs are able to recover problem information from the protein structure from a statistical analysis of the data generated along the evolution.  \nWe evaluated the performance of EDAs to sample the space of low energy sequences for function TE13. We do not have information about the actual lowest energy sequences. Therefore, the comparison between algorithms can be done only in relative terms. UMDA, Tree-EDA and Tree-EDA ${ }^{r}$ were run on the 61 instances of the protein benchmark. In Table 1, the results of Tree-EDA and Tree-EDA ${ }^{r}$ for each of the instances are presented. The table shows the best value of the fitness ${ }^{4}$ found in all the experiments $(-f)$, the number of times the best solution has been found $(S)$ and the average fitness $(\\bar{f})$ of the solutions. It can seen from the table that, in terms of best solution found and the average  \n[^0]\n[^0]:    ${ }^{4}$ Original fitness values are negative, however notice that the table actually shows their opposite values.  \nTable 1. Results of the Tree-EDA and Tree-EDA ${ }^{r}$  \n| pdb | Tree-EDA |  |  | Tree-EDA ${ }^{r}$ |  | pdb | Tree-EDA |  |  | Tree-EDA ${ }^{r}$ |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  | $-f$ | $S$ | $-f$ | $-f$ | $S$ | $-f$ |  | $-f$ | $S$ | $-f$ | $-f$ | $S$ | $-f$ |\n| 1afp | 1493.46 | 1 | 1458.46 | 1494.83 | 1 | 1468.78 | 1zwd | 658.84 | 1 | 621.14 | 663.07 | 2 | 642.17 |\n| 1apq | 1426.39 | 1 | 1367.53 | 1442.43 | 2 | 1405.37 | 2mrb | 806.87 | 1 | 784.90 | 808.44 | 4 | 797.63 |",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:11:55",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Estimation of Distribution Algorithm (EDA) variants discussed for solving the agent routing problem in multi-point dynamic task (ARP-MPDT), what general adaptability differences were observed between the dual-model EDA (DM-EDA) and a standard permutation Genetic Algorithm (GA)?",
      "topics": [
        "genetic"
      ],
      "answer": "The dual-model EDA (DM-EDA), which employs two probability models, was found to have a stronger adaptability compared to other algorithms tested. However, the permutation Genetic Algorithm (GA) performed better for large-scale instances of the agent routing problem in multi-point dynamic task (ARP-MPDT).",
      "chunk_id": 10051,
      "paper_id": "A comparative study on evolutionary algorithms for the agent routing problem in multi-point dynamic task",
      "paper_title": "A comparative study on evolutionary algorithms for the agent routing problem in multi-point dynamic task",
      "paper_year": "2020",
      "chunk_content": "The agent routing problem in multi-point dynamic task (ARP-MPDT) proposed recently is a novel permutation optimisation problem. In ARP-MPDT, a number of task points are located at different places and their states change over time. The agent must go to the task points in turn to execute the tasks, and the execution time of each task depends on the task state. The optimisation objective is to minimise the time for the agent to complete all the tasks. In this paper, five evolutionary algorithms are redesigned and tried to solve this problem, including a permutation genetic algorithm (GA), a variant of the particle swarm optimisation (PSO) and three variants of the estimation of distribution algorithm (EDA). In particular, a dual-model EDA (DM-EDA) employing two probability models was proposed. Finally, comparative tests confirm that the DM-EDA has a stronger adaptability than the other algorithms though GA performs better for the large-scale instances.  \nKeywords: multi-point dynamic task; estimation of distribution algorithm; EDA; dual-model.  \nReference to this paper should be made as follows: Lu, S., Xin, B., Dou, L. and Wang, L. (2020) 'A comparative study on evolutionary algorithms for the agent routing problem in multi-point dynamic task', Int. J. Automation and Control, Vol. 14, Nos. 5/6, pp.571-592.  \nBiographical notes: Sai Lu received his BS from the Harbin Engineering University, Harbin, China in 2017, and he is currently pursuing his MAEng in Beijing Institute of Technology, Beijing, China. His current research interests include manufacturing scheduling and intelligent optimisation methods.  \nBin Xin received his BS in Information Engineering and PhD in Control Science and Engineering, both from the Beijing Institute of Technology, Beijing, China in 2004 and 2012, respectively. He was an Academic Visitor at the Decision and Cognitive Sciences Research Centre, University of Manchester from 2011 to 2012. He is currently a Professor with the School of Automation, Beijing Institute of Technology. His current research interests include search and optimisation, evolutionary computation, combinatorial optimisation and multi-agent systems. He is an Associate Editor of the Journal of Advanced Computational Intelligence and Intelligent Informatics and the journal Unmanned Systems.  \nLihua Dou received her BS, MS and PhD in Control Theory and Control Engineering from the Beijing Institute of Technology, Beijing, China in 1979, 1987 and 2001, respectively. She is currently a Professor at the Control Science and Engineering at State Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology. Her research interests include multi-objective optimisation and decision, pattern recognition and image processing.  \nLing Wang received his BSc and PhD from the Department of Automation, Tsinghua University, China in 1995 and 1999, respectively. Now, he is a Full Professor at the Department of Automation, Tsinghua University. His research interests include theories and algorithms for intelligent optimisation and scheduling. He has authored five academic books and over 200 refereed papers. He was a recipient of the Outstanding Paper Award at the International Conference on Machine Learning and Cybernetics in 2002, Best Paper Award at International Conference on Intelligent Computing in 2011, Top Cited Article Award by Engineering Applications of Artificial Intelligence (Elsevier), National Natural Science Award (second place) in 2014, Science and Technology Award of Beijing City in 2008, and Natural Science Award (first place in 2003 and second place in 2007) nominated by the Ministry of Education (MOE) of China.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:11:57",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "In the RK-EDA algorithm, how does the calculation of the generational variance, \\(\\sigma_{g}\\), influence the exploration and exploitation trade-off compared to using a fixed variance?",
      "topics": [
        "fitness"
      ],
      "answer": "RK-EDA calculates generational variance, \\(\\sigma_{g}\\), by multiplying the initial variance \\(\\sigma\\) with a cooling rate \\(c\\). The cooling rate \\(c\\) is designed to be higher in early generations and lower in later generations. This means \\(\\sigma_{g}\\) is larger at the start, promoting higher exploration, and smaller as the generation count \\(g\\) increases, leading to more exploitation. A fixed variance would not dynamically adjust the exploration-exploitation balance in this way.",
      "chunk_id": 12300,
      "paper_id": "RK-EDA- A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_title": "RK-EDA: A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "```  \nAs shown in Algorithm 1, RK-EDA requires the initialisation of three parameters which are initial variance $\\sigma$, truncation size $t_{s}$ and population size $p_{s}$. Since the stopping criteria is based on the number of fitness evaluations allowed $(F E s)$, the maximum number of generations $\\operatorname{MaxGen}$ is estimated by dividing $F E s$ by $p_{s}$.  \nA population $P$ of RKs is randomly generated, evaluated and rescaled. The rescaling procedure requires the conversion of RKs to ranks e.g. $[0.12,0.57,0.23$, $0.25,0.99]$ becomes $[1,4,2,3,5]$. The ranks are then rescaled to values between 0 and 1 . This is done by setting $\\operatorname{rescaled} R K_{i}=\\frac{\\operatorname{rank}_{i}-1}{n-1}$ where $\\operatorname{rescaled} R K_{i}$ and $\\operatorname{rank}_{i}$ are respectively the rescaled RK and rank of gene $i$, and $n$ is the problem size. The RK in the previous example therefore becomes $[0.00,0.75,0.25,0.50$, 1.00]. With this approach, another set of RKs $[0.01,0.06,0.03,0.04,0.2]$ which is the same solution as the previous example will have the same rescaled RK value $[0.00,0.75,0.25,0.50,1.00]$. With this approach, we are able to minimise redundancy and improve the information captured by the probabilistic model.  \nThe best $t_{s}$ solutions of the population are selected to generate a population $S$. Also, $\\mu_{S}$ in $\\ln$. (6) is an array $\\mu_{S_{1}}, \\ldots, \\mu_{S_{n}}$ that saves the mean of all RKs at indexes $\\{1 \\cdots n\\}$ in the selected population $S$. Note that $\\mu_{S_{n}}$ refers to the mean of all RKs in the $n^{\\text {th }}$ index of each solution of $S$.  \nCooling Rate $c$ is calculated with respect to the particular generation such that its value is higher for the first few iterations and lower at the last set of iterations. As shown in $\\ln$. (8), $c$ is used to generate generational variance $\\sigma_{g}$. Multiplying $c$ with $\\sigma$ to form $\\sigma_{g}$ makes it possible to achieve higher exploration at the start of the algorithm and more exploitation as $g$ increases.  \nFurthermore, $M$ is defined as a normal distribution $N\\left(\\mu_{S}, \\sigma_{g}\\right)$ and is updated for each generation $g$. Unlike $\\mu_{S}$ which is an array of values, $\\sigma_{g}$ is not an array but a single value. An offspring solution off is generated by sampling $M$. Each gene $i(1 \\leq i \\leq n)$ of off is generated based on $\\sigma_{g}$ and $\\mu_{S_{i}}$, off is repeatedly  \nadded to the offspring population $P_{\\text {new }}$ until its size equals $p_{s}$. At the end of each generation, $P_{\\text {new }}$ completely replaces the parent population $P$.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:11:59",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "In implementing the HPPCM algorithm, what advantage does the inclusion of both the center point-based prediction strategy and the guiding individual-based prediction strategy provide over using only one of these strategies?",
      "topics": [
        "convergence"
      ],
      "answer": "The combination of both strategies in HPPCM offers synergistic benefits. The center point-based prediction strategy promotes population convergence by generating non-dominated solutions closer to new optima. The guiding individual-based prediction strategy accurately predicts the evolution direction in the current environment, adjusting the area where the predicted solution is generated, especially in periodic problems where the evolution direction may change rapidly. Using both strategies mitigates the limitations of each individual strategy, leading to more robust performance across diverse dynamic environments.",
      "chunk_id": 1705,
      "paper_id": "Combining a hybrid prediction strategy and a mutation strategy for dynamic multiobjective optimization",
      "paper_title": "Combining a hybrid prediction strategy and a mutation strategy for dynamic multiobjective optimization",
      "paper_year": "2022",
      "chunk_content": "The proposed framework in this paper has three key components and it has shown competence. Here, we use ablation studies to verify the effectiveness of each component separately. The ablation experiment is similar to the \"controlled variable method.\" Suppose that a certain system used A, B and C, and has achieved good results. We could keep two of the three and remove one to verify whether the deleted one plays a role in the entire system. In this subsection, we modify HPPCM to three variants. The first variant, HPPCM-V1, only discards the center point-based prediction strategy we proposed and retains the guiding individual-based prediction strategy and the precision controllable mutation strategy. It's not difficult to find that HPPCM-V1 is designed to verify whether the center point-based prediction strategy plays a decisive role in HPPCM. The guiding individual-based prediction strategy is switched off to study its importance to the framework in this paper, and this variant is called HPPCM-V2. Similarly, we also deactivate the precision controllable mutation strategy to study the role it plays in our proposed algorithm, resulting in another variant named HPPCM-V3.  \nThese three variants are all compared with the original HPPCM, and their MIGD values on eighteen test instances for $\\left(n_{i}, \\tau_{i}\\right)=(10,30)$ are presented in Table 9. It is evident from the results of the experimental comparison that the overall performance of the original version of HPPCM is better than other variants. This also reflects from the side that each component is indispensable for the overall performance of HPPCM. Removing any of them causes somewhat performance degradation in general. Thus, it is a good way to combine them in one algorithm, as done by HPPCM. It is not surprising to see that HPPCM-V1 performs worse than HPPCM. The reason may be due to the fact that the center point-based prediction strategy in HPPCM would generate many nondominated solutions closer to new optima. The lack of this strategy in HPPCM-V1 is not good for population convergence. For those periodic problems, the evolution direction at a certain time step may be completely opposite to the direction of the previous time step. The guiding individual-based prediction strategy can accurately predict the evolution direction in the current environment, thereby adjusting the area where the predicted solution is generated. This is why the performance of HPPCM-V2 after removing this strategy has significantly decreased on periodic problems such as dMOP1, dMOP2, F5, F6, F7, F9. The precision controllable mutation strategy proposed in this paper is contributed to ensuring the diversity of our algorithm. Thus the lack of this strategy in HPPCM-V3 will definitely make the performance of indicators worse than HPPCM.  \nTable 10\nAverage rankings and adjusted $p$-values obtained of each algorithm through Friedman test on all test problems (HPPCM is the control method whose average ranking is 1.3889 ).\nTable 11\nAverage rankings and adjusted $p$-values obtained of multi-model MOEAs through Friedman test on all test problems (HPPCM is the control method whose average ranking is 1.0 ).  \nTable 12\nAverage rankings and adjusted $p$-values obtained of different HPPCM variants through Friedman test on all test problems (HPPCM is the control method whose average ranking is 1.0 ).",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:01",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model in the context of Networked Control Systems (NCSs)?",
      "topics": [
        "design"
      ],
      "answer": "The effectiveness of the EDA model is evaluated using the mean square error (MSE), overshoot (O.S.), and settling time (S.T.). These metrics are incorporated into a cost function \\(\\boldsymbol{J} = \\lambda_{1} \\boldsymbol{J}_{1}+\\lambda_{2} \\boldsymbol{J}_{2}+\\lambda_{3} \\boldsymbol{J}_{3}\\), where \\(\\boldsymbol{J}_{1}\\) relates to MSE, \\(\\boldsymbol{J}_{2}\\) relates to overshoot, and \\(\\boldsymbol{J}_{3}\\) relates to settling time. The weights \\(\\lambda_{1}\\), \\(\\lambda_{2}\\), and \\(\\lambda_{3}\\) specify the relative importance of each metric.",
      "chunk_id": 6749,
      "paper_id": "Optimal Stabilizing Gain Selection for Networked Control Systems With Time Delays and Packet Losses",
      "paper_title": "Optimal Stabilizing Gain Selection for Networked Control Systems With Time Delays and Packet Losses",
      "paper_year": "2009",
      "chunk_content": "This section is concerned with the optimal stabilizing controller design problem. We will transform the controller design problem into an optimization problem and then solve the optimization problem.  \n$$\n\\begin{aligned}\n& \\boldsymbol{M}_{1}=\\left[\\begin{array}{cccc}\n\\boldsymbol{F}^{\\eta\\left(i_{m}\\right)}+\\sum_{j=0}^{\\eta\\left(i_{m}\\right)-1} \\boldsymbol{F}^{r} \\boldsymbol{G} \\boldsymbol{K} & 0 & 0 \\\\\n\\boldsymbol{I} & 0 & 0 \\\\\n0 & I & 0\n\\end{array}\\right] \\quad \\boldsymbol{M}_{4}=\\left[\\begin{array}{cccc}\n\\boldsymbol{F}^{\\eta\\left(i_{m}\\right)}+\\sum_{j=0}^{\\eta\\left(i_{m}\\right)-3} \\boldsymbol{F}^{r} \\boldsymbol{G} \\boldsymbol{K} & \\boldsymbol{F}^{\\eta\\left(i_{m}\\right)-2} \\boldsymbol{G} \\boldsymbol{K} & \\boldsymbol{F}^{\\eta\\left(i_{m}\\right)-1} \\boldsymbol{G} \\boldsymbol{K} \\\\\n\\boldsymbol{I} & 0 & 0 \\\\\n0 & I & 0\n\\end{array}\\right] \\\\\n& \\boldsymbol{M}_{2}=\\left[\\begin{array}{cccc}\n\\boldsymbol{F}^{\\eta\\left(i_{m}\\right)}+\\sum_{j=0}^{\\eta\\left(i_{m}\\right)-2} \\boldsymbol{F}^{r} \\boldsymbol{G} \\boldsymbol{K} & \\sum_{j=\\eta\\left(i_{m}\\right)-1}^{\\eta\\left(i_{m}\\right)-2} \\boldsymbol{G} \\boldsymbol{F}^{r} \\boldsymbol{G} \\boldsymbol{K} & 0 \\\\\n\\boldsymbol{I} & 0 & 0 \\\\\n0 & I & 0\n\\end{array}\\right]\n\\end{aligned}\n$$\nIn the optimization problem, the optimization variables are the elements of the controller gain matrix $\\boldsymbol{K} \\in \\mathbb{R}^{m \\times n}$. For future use, we transform the optimization variables into a vector  \n$$\n\\tilde{\\boldsymbol{K}}=\\left(\\tilde{K}_{1}, \\tilde{K}_{2}, \\ldots, \\tilde{K}_{\\tilde{S}}\\right)\n$$  \nwhere $\\tilde{S}=m n$ is the dimension of $\\tilde{\\boldsymbol{K}}$.\nDifferent engineering applications have their performance measures, which can be used to construct their cost functions. In this brief, the mean square error, the overshoot, and the settling time are used to evaluate the NCSs' performance. The corresponding cost function is defined as follows:  \n$$\n\\begin{aligned}\n\\boldsymbol{J} & =\\lambda_{1} \\boldsymbol{J}_{1}+\\lambda_{2} \\boldsymbol{J}_{2}+\\lambda_{3} \\boldsymbol{J}_{3} \\\\\n\\boldsymbol{J}_{1} & = \\begin{cases}0, & \\mathrm{MSE} \\leq \\mathrm{MSE}_{\\mathrm{n}} \\\\\n\\left(\\mathrm{MSE}-\\mathrm{MSE}_{\\mathrm{n}}\\right) / \\mathrm{MSE}_{\\mathrm{n}}, & \\mathrm{MSE}<\\mathrm{MSE}_{\\mathrm{n}}\\end{cases} \\\\\n\\boldsymbol{J}_{2} & = \\begin{cases}0, & \\left\\|\\mathrm{O} . \\mathrm{S} .\\right\\| \\leq\\left\\|\\mathrm{O} . \\mathrm{S} ._{\\mathrm{n}}\\right\\| \\\\\n\\left(\\mathrm{O} . \\mathrm{S} .-\\mathrm{O} . \\mathrm{S} ._{\\mathrm{n}}\\right) / \\mathrm{O} . \\mathrm{S} ._{\\mathrm{n}}, & \\left\\|\\mathrm{O} . \\mathrm{S} .\\right\\|<\\left\\|\\mathrm{O} . \\mathrm{S} ._{\\mathrm{n}}\\right\\| \\\\\n\\boldsymbol{J}_{3} & = \\begin{cases}0, & \\mathrm{~S} . \\mathrm{T} . \\leq \\mathrm{S} . \\mathrm{T} ._{\\mathrm{n}} \\\\\n\\left(\\mathrm{~S} . \\mathrm{T} .-\\mathrm{S} . \\mathrm{T} ._{\\mathrm{n}}\\right) / \\mathrm{S} . \\mathrm{T} ._{\\mathrm{n}}, & \\mathrm{~S} . \\mathrm{T} .<\\mathrm{S} . \\mathrm{T} ._{\\mathrm{n}}\\end{cases}\n\\end{aligned}\n$$  \nwhere  \n$$\n\\mathrm{MSE}=\\frac{1}{N} \\sum_{k=0}^{N}(\\boldsymbol{r}(k)-\\boldsymbol{y}(k))^{2}\n$$  \nis the mean square error, $\\mathrm{MSE}_{\\mathrm{n}}$ is the nominal mean square error, O.S. is the overshoot, $\\mathrm{O} . \\mathrm{S}_{\\mathrm{n}}$ is the nominal overshoot, S.T. is the settling time, and S.T. ${ }_{\\mathrm{n}}$ is the nominal settling time. $\\mathrm{MSE}_{\\mathrm{n}}, \\mathrm{O} . \\mathrm{S}_{\\mathrm{n}}$, and $\\mathrm{S} . \\mathrm{T}_{\\mathrm{n}}$ are nominal performance measures that the system should achieve without network in the loop. If the NCS performance meets the nominal performance specifications, we have $\\boldsymbol{J}=0$ because $\\boldsymbol{J}_{i}=0, i=1,2,3$. In (23), $\\boldsymbol{N}$ is the appropriate time index such that the tracking has arrived at the steady state; $\\boldsymbol{r}(k)$ and $\\boldsymbol{y}(k)$ are the reference input and plant output at time index $k$. The cost $\\boldsymbol{J}_{1}$ penalizes poor response time and convergence, the cost $\\boldsymbol{J}_{2}$ penalizes high value of the overshoot, and the cost $\\boldsymbol{J}_{3}$ penalizes long settling time. The problem-dependent weights $\\lambda_{1}, \\lambda_{2}$, and $\\lambda_{3}$ are used to specify the relative significance of $\\boldsymbol{J}_{1}, \\boldsymbol{J}_{2}$, and FORMULA_172, respectively, on the overall system performance.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:04",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for multimodal optimization, and how does Cooperative Clustering contribute to achieving this objective?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective is to locate multiple optima simultaneously, addressing the limitations of classical Evolutionary Algorithms like DE, GA, and PSO which tend to converge to a single dominant candidate. Cooperative Clustering is adopted to help EDA maintain population diversity by partitioning it into subpopulations, reducing sensitivity to parameters compared to other niching techniques like k-means clustering, and enabling the CMEDA algorithm to divide multimodal problems into promising regions where separate optimizers can run independently.",
      "chunk_id": 10524,
      "paper_id": "Multimodal estimation of distribution algorithm based on cooperative clustering strategy",
      "paper_title": "Multimodal Estimation of Distribution Algorithm Based on Cooperative Clustering Strategy",
      "paper_year": "2018",
      "chunk_content": "Multimodal optimization, which seeks multiple optima simultaneously, has attracted more and more attention in recent years [1]. Real-world problems like data mining [2], flowshop schedule [3], holographic design [4], and electromagnetic design [5] require to search more than one optima. However, different from finding just one optimum in single optimization [6], locating local optima simultaneously or multiple global is qualitatively more challenging [1].\nFor these problems, classical and typical evolutionary algorithms (EAs), such as differential evolution (DE) [7], genetic algorithm (GA) [8], and particle swarm optimization (PSO) [9], lose feasibility and effectiveness, because their overall learning and updating makes the population tend to converge toward one dominating candidate [9]. Recently, a new family of EAs-the estimation of distribution algorithm (EDA) [10], has emerged, which gains more attention because of its special mechanism and performance. It generates offspring by sampling from the probability distribution estimated from promising individuals [10].  \n[^0]Unfortunately, EDA loses feasibility and effectiveness in multimodal problems because of premature convergence and the missing of multimodality-specific mechanism [1]. Therefore, to locate multiple optima simultaneously using classical EAs, a multimodality-specific mechanism is necessary. Under this circumstance, niching is adopted to help EDA maintain a diverse population in multimodal optimization, which achieves this by partitioning the whole population into several subpopulations using techniques. However, many of the niching techniques such as clustering, crowding and speciation are either sensitive to parameters or cost a number of fitness evaluations [1]. For instance, [2] shows that k-means clustering is susceptible to cluster number K and [11] describes how crowding is sensitive to the crowding size.\nIn this paper, a new fast clustering strategy, Cooperative Clustering [12], is adopted to offer improved assistance for locating multiple optima based on both decision space and target space information. This strategy not only locates diverse promising solution regions, but also reduces the sensitivity of the used niching methods to the cluster size [12]. In order to take advantage of the new strategy, multimodal estimation of distribution algorithm based on cooperative clustering strategy (CMEDA) is proposed. In this algorithm multimodal problems are divided into certain promising regions automatically and then each cluster independently runs a separate optimizer individually. By  \n[^0]:    This work is supported by the company's self-financing technology projects under Grant 5246DR180002.  \nthis means a more accurate multimodal model is built and global optimal solutions are gained so that the balance between exploration and exploitation is achieved. The simulation results based on CEC2013 niching methods for multimodal function optimization [13] validate that CMEDA outperforms the previously existing similar algorithm.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:06",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the selection of copulas in copula-based EDAs, specifically regarding the trade-off between modeling dependence and computational efficiency?",
      "topics": [
        "algorithm"
      ],
      "answer": "In copula-based EDAs, the algorithmic mechanism for selecting a copula involves evaluating evidence of dependence between variables. When there is no evidence of dependence, using a product copula is preferred. The theoretical basis for this preference lies in the fact that when variables are independent, the product copula accurately models the joint distribution without introducing unnecessary parameters. Conversely, if dependence exists, a copula other than the product copula should be employed to capture the dependencies. However, the algorithm must then accurately determine the parameters of the selected copula, which requires larger populations and a greater number of function evaluations. Therefore, the selection process is governed by the principle of parsimony: only use more complex copulas when the evidence of dependence justifies the additional computational cost.",
      "chunk_id": 1117,
      "paper_id": "copulaedas An R Package for Estimation of Distribution Algorithms Based on Copulas",
      "paper_title": "copulaedas: An R Package for Estimation of Distribution Algorithms Based on Copulas",
      "paper_year": "2014",
      "chunk_content": "A general result of this empirical study is that copula-based EDAs should use copulas other than the product only when there is evidence of dependence. Otherwise, the EDA will require larger populations and hence a greater number of function evaluations to accurately determine the parameters of the copulas that correspond to independence.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:08",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to minimize the makespan ($Cmax$) in a scheduling problem, how should practitioners utilize the binary variable $X_{i, j, k}$ to represent job sequencing on machines?",
      "topics": [
        "algorithm"
      ],
      "answer": "When implementing an EDA for scheduling, the binary variable $X_{i, j, k}$ should be set to 1 if job $J_j$ is processed immediately after job $J_i$ on machine $M_k$, and 0 otherwise. Similarly, $X_{0, j, k}$ should be set to 1 if job $J_j$ is the first job processed on machine $M_k$, and $X_{j, 0, k}$ should be set to 1 if job $J_j$ is the last job processed on machine $M_k$. These variables are crucial for defining the job sequence and calculating the makespan ($Cmax$).",
      "chunk_id": 12895,
      "paper_id": "A Hybrid Estimation of Distribution Algorithm for Unrelated Parallel Machine Scheduling with Sequence-Dependent Setup Times",
      "paper_title": "A Hybrid Estimation of Distribution Algorithm for Unrelated Parallel Machine Scheduling with Sequence-Dependent Setup Times",
      "paper_year": "2016",
      "chunk_content": "$n$ : the number of jobs to be processed;\n$m$ : the number of machines;\n$J_{i}$ : the $i$-th job;\n$M_{k}$ : the $k$-th machine;\nCmax: the maximum completion time of jobs, i.e., makespan;\n$C_{i}$ : the completion time of $J_{i}$;\n$P_{i, k}$ : the processing time of $J_{i}$ on $M_{k}$;\n$S T_{i, j, k}$ : the setup time of processing $J_{j}$ right after $J_{i}$ on $M_{k}$\n$S T_{0, j, k}$ : the setup time of processing $J_{j}$ first on $M_{k}$;\n$X_{i, j, k}$ : a binary variable that is equal to 1 if $J_{j}$ is right after $J_{i}$ on $M_{k}, 0$ otherwise;\n$X_{0, j, k}$ : a binary variable that is equal to 1 if $J_{j}$ is the first one on $M_{k}, 0$ otherwise;\n$X_{j, 0, k}$ : a binary variable that is equal to 1 if $J_{j}$ is the last one on $M_{k}, 0$ otherwise;\n$V$ : a very large constant;\n$R_{k}$ : the release (completion) time of $M_{k}$;\n$N_{k}$ : the total number of jobs on $M_{k}$;\n$P_{[j], k}$ : the processing time of the $j$-th job on $M_{k}$;\n$S T_{[i],[j], k}$ : the setup time of processing the $j$-th job right after the $i$-th one on $M_{k}$;\n$A P_{i, j, k}$ : the total needed (setup and processing) time for the $j$-th job right after the $i$-th one on $M_{k}$;\n$S T_{[0],[1], k}$ : the setup time of processing the first job on $M_{k}$;\n$A P_{0,1, k}$ : the total needed (setup and processing) time for the first job on $M_{k}$.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:10",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA integrated into the Dandelion Algorithm (DA), what type of historical information feedback models are used to improve the offspring generation process, and how do these models leverage historical data?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms",
        "Dandelion Algorithm",
        "historical information feedback"
      ],
      "answer": "The Dandelion Algorithm (DA) incorporates an estimation-of-distribution algorithm to improve its offspring generation process by exploiting historical information. Specifically, three historical information feedback models are designed: best, worst, and hybrid. These models use historical information to guide the generation of new offsprings, contrasting with the original DA that generates new offsprings without considering historical information. The fitness value of each dandelion in the next generation is calculated by linear prediction and compared with the current best dandelion, with the loser being replaced by a new offspring.",
      "chunk_id": 1847,
      "paper_id": "Competition-Driven Dandelion Algorithms With Historical Information Feedback",
      "paper_title": "Competition-Driven Dandelion Algorithms With Historical Information Feedback",
      "paper_year": "2022",
      "chunk_content": "Shoufei Han ${ }^{\\odot}$, Kun Zhu ${ }^{\\odot}$, Member, IEEE, and MengChu Zhou FORMULA_2, Fellow, IEEE\nA Dandelion algorithm (DA) inspired by the seed dispersal process of dandelions has been proposed as a newly intelligent optimization algorithm. For improving its exploration ability as well as reducing the probability of its falling into a local optimum, this work proposes to add a novel competition mechanism with historical information feedback to current DA. Specifically, the fitness value of each dandelion in the next generation, which is calculated by linear prediction, is compared with the current best dandelion, and the loser is replaced by a new offspring. Current DA generates new offsprings without considering historical information. This work improves its offspring generation process by exploiting historical information with an estimation-of-distribution algorithm. Three historical information models are designed. They are best, worst, and hybrid historical information feedback models. The experimental results show that the proposed algorithms outperform DA and its variants, and the proposed algorithms are superior or competitive to nine participating algorithms benchmarked on 28 functions from CEC2013. Finally, the proposed algorithms demonstrate the effectiveness on four real-world problems, and the results indicate that the proposed algorithms have better performance than its peers.  \nIndex Terms--Applications, competition mechanism, dandelion algorithm (DA), estimation-of-distribution algorithm (EDA), historical information, intelligent optimization, linear prediction, machine learning.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:11",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What are the two identified deficiencies of the basic GEDA that RW-GEDA aims to address, and how do these deficiencies manifest in the algorithm's search behavior?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The basic GEDA is described as having two deficiencies: 1) the variance in each degree of freedom decreases rapidly with iterations, and 2) the evolution direction tends to be perpendicular to the descent direction of the objective function value. The first deficiency, rapid variance reduction, leads to a shrinking of the estimated distribution. The second deficiency causes the long axis of the newly estimated probability density ellipsoid to align parallel to the objective function isoline, hindering effective search towards the optimum. These issues collectively reduce the algorithm's search efficiency and can lead to premature convergence, even in sloping regions of the search space.",
      "chunk_id": 7883,
      "paper_id": "A Gaussian Estimation of Distribution Algorithm With Random Walk Strategies and Its Application in Optimal Missile Guidance Handover for Multi-UCAV in Over-the-Horizon Air Combat",
      "paper_title": "A Gaussian Estimation of Distribution Algorithm With Random Walk Strategies and Its Application in Optimal Missile Guidance Handover for Multi-UCAV in Over-the-Horizon Air Combat",
      "paper_year": "2019",
      "chunk_content": "As a model-based evolutionary algorithm, GEDA assumes that the optimal solutions obey a Gaussian probability distribution, and uses the probability distribution estimated from the superior solutions in the current generation to sample new candidates, thus driving the evolution of the algorithm. The basic steps of GEDA are described as follows.  \nStep 1. Set the algorithm parameters and initialize the population.\nStep 2. Evaluate the current solutions according to the objective function.\nStep 3. Select superior solutions to estimate the Gaussian probability distribution model.\nStep 4. Sample the new population according to the Gaussian probability distribution model and evolve the algorithm.\nThus, for the continuous GEDA with an $n$ degree of freedom column vector x , the joint probability density function of the Gaussian probability distribution model can be parameterized by the mean $\\mu$ and the covariance matrix $\\boldsymbol{C}$ as  \n$$\nG_{(\\boldsymbol{\\mu}, \\mathbf{C})}=\\frac{(2 \\pi)^{-\\pi / 2}}{(\\operatorname{det} \\mathbf{C})} \\exp \\left(-(\\mathbf{X}-\\boldsymbol{\\mu})^{\\mathrm{T}}(\\mathbf{C})^{-1}(\\mathbf{X}-\\boldsymbol{\\mu}) / 2\\right)\n$$  \nwhere  \n$$\n\\begin{aligned}\n& \\boldsymbol{\\mu}=\\frac{1}{|\\mathbf{S}|} \\sum_{i=1}^{|\\mathbf{S}|} \\mathbf{s}_{i}, \\quad \\mathbf{s}_{i} \\in \\mathbf{S} \\text { and } \\mathbf{S} \\subset \\mathbf{X} \\\\\n& \\mathbf{C}=\\frac{1}{|\\mathbf{S}|} \\sum_{i=1}^{|\\mathbf{S}|}\\left(\\mathbf{s}_{i}-\\boldsymbol{\\mu}\\right)\\left(\\mathbf{s}_{i}-\\boldsymbol{\\mu}\\right)^{\\mathrm{T}}\n\\end{aligned}\n$$  \n[IMAGE0]  \nFIGURE 1. The change of probability density ellipsoid in basic GEDA.\nThe symbol $\\boldsymbol{S}$ in (2) and (3) represents the set of select superior solution vectors. The new candidate for the $i$ th solution is sampled in each iteration by  \n$$\n\\mathbf{x}_{i}=\\boldsymbol{\\mu}+\\mathbf{y}_{i}, \\mathbf{y}_{i} \\sim N(0, \\mathbf{C})\n$$  \nThe basic GEDA suffers from two deficiencies [17]: 1) The variance in each degree decreases rapidly with the iterations of the algorithm; 2) The evolution direction tends to be perpendicular to the descent direction of the objective function value. These two defects are illustrated in Fig. 1. The equiprobability density surface of the population generated following the multivariate Gaussian distribution is a super ellipsoid. The eigenvector of $\\boldsymbol{C}$ corresponds to the direction of the ellipsoid axis; and the eigenvalue of FORMULA_14 equals the square of the length of each axis, as shown in Fig. 1. The excellent solutions selected by GEDA in each iteration are mainly distributed in the semi-ellipsoid formed by the original probability density ellipsoid cut by the objective function isoline. The long axis of the semi-ellipsoid is parallel to the objective function isoline; accordingly, the long axis of the newly estimated probability density ellipsoid is parallel to the objective function isoline, that is, it tends to be perpendicular to the improved direction of the objective function. On the other hand, there are more samples near the center of the original probability density ellipsoid in the semi-ellipsoid and fewer samples far from the center, and thus, the newly estimated distribution will shrink naturally according to these samples. This characteristic of the traditional GEDA greatly reduces the search efficiency of the algorithm, leading to premature convergence even in the sloping region.  \nThus, we propose our RW-GEDA with a modification of the ill-shaped distribution focusing on three aspects: estimated distribution amending, evolutionary directions adjustment and population diversity enrichment. More details are presented in the next subsection.",
      "question_type": "relationship",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:13",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "Based on the information provided, what key performance characteristic differentiates MEDA/D-PP from MEDA/D-N in the context of multiobjective optimization?",
      "topics": [
        "convergence"
      ],
      "answer": "The convergence speed of MEDA/D-PP is significantly faster than MEDA/D-N. MEDA/D-PP can also produce high-quality solutions at the initial stage of the search, possibly due to the use of prior knowledge.",
      "chunk_id": 669,
      "paper_id": "A Probability Model based Evolutionary Algorithm with Priori and Posteriori Knowledge for Multiobjective Knapsack Problems",
      "paper_title": "A Probability Model based Evolutionary Algorithm with Priori and Posteriori Knowledge for Multiobjective Knapsack Problems",
      "paper_year": "2014",
      "chunk_content": "Table II presents the mean and standard deviation of the hypervolume values of the final approximations obtained by each algorithm among 30 runs for each test instance. We can see from Table II that MEDA/D-PP and MOEA/D-ACO perform better than MEDA/D-N on all the test instances. It also shows that the final approximations obtained by MEDA/D-PP are a little worse than those obtained by MOEA/D-ACO.  \nFig. 1 shows the run time performances of MEDA/D-N and MEDA/D-PP on 2 and 3 objectives test instances. It shows that convergence speed of MEDA/D-PP is much faster than that of MEDA/D-N on all the test instances. We can also find that MEDA/D-PP can produce high quality solutions at the initial stage of the search. The reason might be that the use of priori knowledge makes contributions.  \nFig. 2 plots the comparison between the final approximations of MEDA/D-N and MEDA/D-PP with the lowest hypervolume value among 30 runs for each 2-objective test instance. The 'Relaxed PF' is the upper approximations obtained by Jaszkiewicz [15]. From Fig. 2, we can find that there is significant difference between the final approximations by MEDA/D-N and MEDA/D-PP, MEDA/D-PP being much better than MEDA/D-N.  \nFig. 3 plots the comparison between the final approximations of MOEA/D-ACO and MEDA/D-PP with the lowest hypervolume value among 30 runs for each 2-objective test instance. Fig. 3 shows that the final approximations by MEDA/D and MOEA/D-ACO are very close to the relaxed PF\nand there is little difference between the final approximations by MEDA/D and MOEA/D-ACO. It is difficult to distinguish them visually. Thus the proposed algorithm can obtain similar performance as MOEA/D-ACO while uses smaller number of parameters (see Table I). We can also see from Fig. 3 that the numbers of solutions in the two ends of the final approximations by MEDA/D-PP are smaller than those by MOEA/D-ACO and this might explain why MEDA/D is slightly worse than MOEA/D-ACO in terms of hypervolume metric statistics.  \nTABLE II\nHYPERVOLUME METRIC VALUES OF THE APPROXIMATIONS FOUND BY MEDA/D-N, MEDA/D-PP AND MOEA/D-ACO ON THE NINE TEST\nINSTANCES OVER 30 RUNS",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:15",
      "generation_style": "implementation_focused"
    },
    {
      "question": "When evaluating the complexity of the Hill Climbing (HC) algorithm within Semiparametric Bayesian Networks (SPBNs), what factors influence the overall computational cost?",
      "topics": [
        "complexity"
      ],
      "answer": "The complexity of the HC algorithm for SPBN is \\(\\mathcal{O}(Oi\\lambda KT)\\), where \\(i\\) represents the number of tabu lists reinitialized, \\(O\\) denotes the size of the set of operators defined for the HC, \\(\\lambda\\) signifies the patience in Algorithm 1, \\(K\\) is the number of folds, and \\(T\\) is the cost of learning the parameters and evaluating the loglikelihood. In the context of Gaussian Bayesian Networks (GBNs) the complexity is \\(\\mathcal{O}(Oi\\lambda T)\\), where \\(O = O_{SPBN} - 1\\) because the node type operator is not needed.",
      "chunk_id": 2446,
      "paper_id": "Semiparametric Estimation of Distribution Algorithms for Continuous Optimization",
      "paper_title": "Semiparametric Estimation of Distribution Algorithms for Continuous Optimization",
      "paper_year": "2024",
      "chunk_content": "```  \nor CKDE CPDs is not as complex [13]. To compute the local score of a variable $X_{i}$ with parents $\\boldsymbol{P a}_{i}$, the former complexity (for Gaussians) is $\\mathcal{O}\\left(k J\\left|\\boldsymbol{P a}_{i}\\right|^{2}\\right)$, where $J$ is the number of training samples on each fold and $K$ is the number of folds, and the latter complexity (for CKDE CPDs) is $\\mathcal{O}\\left(N J\\left|\\boldsymbol{P a}_{i}\\right|^{2}\\right)$ where $N$ is the total number of samples. Then, the HC algorithm for SPBN complexity is $\\mathcal{O}(O i \\lambda K T)$, where $i$ is the number of tabu lists reinitialized, $i=1$ is the best of the cases, $O=O_{\\text {SPBN }}$ the size of the set of operators defined for the HC, and $\\lambda$ is the patience in Algorithm 1.  \nThus, considering the SPBN complexity, learning a KDEBN implies that $T$ will always cost the CKDE learning, $\\mathcal{O}\\left(N J\\left|\\boldsymbol{P a}_{i}\\right|^{2}\\right)$, which is more expensive than learning a Gaussian CKDE, and $O=O_{\\text {SPBN }}-1$, as the node type operator is not further needed. In the worst case, the SPBN will learn all the nodes as CKDE, and then, it will be more expensive to learn the SPBN than a KDEBN.  \nIn the case of GBNs, the score function used during the learning process has a complexity of $\\mathcal{O}(T)$, where $T$ is the cost of learning the parameters and evaluating the loglikelihood (4). The complexity of the HC algorithm for GBN is $\\mathcal{O}(O i \\lambda T)$, where $O=O_{\\text {SPBN }}-1$, as the node type operator is not needed.\nInput: Population size $N$, selection ratio $\\alpha$, cost function $g$\nOutput: Best individual $\\boldsymbol{x}^{\\prime}$ and cost found $g\\left(\\boldsymbol{x}^{\\prime}\\right)$\n$1: G_{0} \\leftarrow N$ individuals randomly sampled\n2: for $t=1,2, \\ldots$ until stopping criterion is met do\n3: Evaluate $G_{t-1}$ according to $g(\\cdot)$\n4: $\\quad G_{t-1}^{S} \\leftarrow$ Select top $\\lfloor\\alpha N\\rfloor$ individuals from $G_{t-1}$\n5: $\\quad f_{t-1}(\\cdot) \\leftarrow$ Learn a probabilistic model from $G_{t-1}^{S}$\n6: $\\quad G_{t} \\leftarrow$ Sample $N$ individuals from $f_{t-1}(\\cdot)$\n7: end for",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:17",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs involving the interplay between HMEC, HEFT, GmTskLst, GmRscLst, IFBSS, and LBCAS?",
      "topics": [
        "termination"
      ],
      "answer": "The algorithmic approach aims to iteratively improve a solution $ch_0$ by generating candidate individuals $ch$ using HMEC and HEFT heuristics initially, then refining them through the $GmTskLst$ function, which leverages the $SPM$ and a vector of probabilities $\\eta_{i}$ derived from $ur_{i}$ and $mur$. Diversification is achieved via the $DivDcd$ function. Furthermore, the $GmRscLst$ function refines the solution based on $MPM$. Finally, $IFBSS$ and $LBCAS$ are applied to the top individuals in $Pop$, and $MPM$ and $SPM$ are updated based on the best solution found, $ch_0$, until the termination conditions are met in both stages.",
      "chunk_id": 4164,
      "paper_id": "A Two-Stage Estimation of Distribution Algorithm With Heuristics for Energy-Aware Cloud Workflow Scheduling",
      "paper_title": "A Two-Stage Estimation of Distribution Algorithm With Heuristics for Energy-Aware Cloud Workflow Scheduling",
      "paper_year": "2023",
      "chunk_content": "input: $W M, R M$;\noutput: the best individual/solution $c h_{0}$;\n1: initialize $M P M, S P M$ according to (18)-(19);\n2: calculate $u r_{i}$ according to (11)-(12); $m u r \\leftarrow \\max \\left\\{u r_{i}, \\cdots, u r_{l}\\right\\}$;\n3: generate two individuals $c h^{\\prime}, c h^{\\prime \\prime}$ according to the HMEC and the HEFT;\n4: $c h_{0} \\leftarrow$ the best of $c h^{\\prime}, c h^{\\prime \\prime} ;$ Pop $\\leftarrow \\varnothing$;\n5: while the termination condition of stage 1 is not met do\n6: $\\eta_{i} \\leftarrow\\left(u r_{i} / m u r\\right)^{\\alpha_{1} \\cdots \\alpha_{l}^{(m)}}, i=1, \\cdots, I$;\n7: while $|\\operatorname{Pop}|<N$ do\n8: $\\quad c h \\leftarrow G m T s k L s t\\left(S P M,\\left\\{\\eta_{1}, \\ldots, \\eta_{l}\\right\\}\\right)$;\n9: $\\operatorname{Div} \\operatorname{Dcd}(c h) ;$ Pop $\\leftarrow \\operatorname{Pop} \\bigcup_{i}\\{c h\\}$;\n10: if $c h$ is better than $c h_{0}$ then\n11: $\\left\\lfloor c h_{0} \\leftarrow c h\\right.$;\n12: update $M P M$ and $S P M$ according to $c h_{0} ;$ Pop $\\leftarrow \\varnothing$;\n13: while the termination condition of the TSEDA is not met do\n14: $\\eta_{i} \\leftarrow\\left(u r_{i} / m u r\\right)^{\\alpha_{1} \\cdots \\alpha_{l}^{(m)}}, i=1, \\cdots, I$;\n15: while $|\\operatorname{Pop}|<N$ do\n16: $\\quad c h \\leftarrow G m T s k L s t\\left(S P M,\\left\\{\\eta_{1}, \\ldots, \\eta_{l}\\right\\}\\right) ; G m R s c L s t(c h, M P M)$;\n17: $\\operatorname{Dcd}(c h) ;$ Pop $\\leftarrow \\operatorname{Pop} \\bigcup_{i}\\{c h\\}$;\n18: if $c h$ is better than $c h_{0}$ then\n19: $\\left\\lfloor c h_{0} \\leftarrow c h\\right.$;\n20: for $c h \\in$ top $\\left\\lceil\\mathrm{Np}_{i}\\right\\rceil$ individuals in $P o p$ do\n21: IFBSS $(c h) ;$ LBCAS $(c h)$;\n22: update $M P M$ and $S P M$ according to $c h_{0} ;$ Pop $\\leftarrow \\varnothing$;\n23: return $c h_{0}$;\ntasks of the tasks assigned to $v m_{3}\\left(t_{5}\\right.$, namely $\\left.S T_{3}=\\{5\\}\\right)$ are found. Finally, because there is only an element in $S T_{3}$, this task $\\left(t_{5}\\right)$ is selected and reassigned to $v m_{3}$. Thus its TRM is improved from $\\{2,1,2,2,2,2,3,1\\}$ to $\\{2,1,2,2,3,2,3,1\\}$, correspondingly, the makespan and EC are reduced from 89.5 and 2620.1 to 77.5 and 2421.7.",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:19",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of updating the probability vector \\(P^{(g)}\\) in PBIL, as shown in the formula \\(p_{i}^{(g+1)}=(1-\\alpha) \\cdot p_{i}^{(g)}+\\alpha \\cdot \\frac{1}{M} \\cdot \\sum_{j=1}^{M} X_{k_{j}}^{i}\\), influence the search for optimal solutions?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The formula \\(p_{i}^{(g+1)}=(1-\\alpha) \\cdot p_{i}^{(g)}+\\alpha \\cdot \\frac{1}{M} \\cdot \\sum_{j=1}^{M} X_{k_{j}}^{i}\\) updates the probability vector \\(P^{(g)}\\) in PBIL by considering both the previous probability \\(p_{i}^{(g)}\\) and the contribution from \\(M\\) optimal solutions \\(X_{k_{j}}^{i}\\). The parameter \\(\\alpha\\), the learning rate, controls the influence of the optimal solutions on the updated probability. A larger \\(\\alpha\\) means the optimal solutions have a greater impact on updating \\(P^{(g)}\\), potentially leading to faster convergence but also increasing the risk of getting stuck in local optima. The algorithm TDG-EDA calculates \\(\\alpha\\) according to the formula \\(\\alpha=r_{0} \\times \\frac{\\left[t / t_{0}\\right]}{N_{\\max }}+r_{1} \\times(-1)^{T \\bmod 10}\\), where \\(r_0\\) and \\(r_1\\) are benchmarks, \\(N_{\\max }\\) is the maximum iteration number, \\(t\\) is the evolutionary algebra, \\(t_0\\) is the interval algebra of evolution, and \\(T\\) is an algebra in which the population optimal individuals are continuously not improved. The term \\((-1)^{T \\bmod 10}\\) introduces a fluctuating learning factor based on the degree of evolution.",
      "chunk_id": 2659,
      "paper_id": "Test Data Generation for Mutation Testing Based on Markov Chain Usage Model and Estimation of Distribution Algorithm",
      "paper_title": "Test Data Generation for Mutation Testing Based on Markov Chain Usage Model and Estimation of Distribution Algorithm",
      "paper_year": "2024",
      "chunk_content": "$$\np_{i}^{(g+1)}=(1-\\alpha) \\cdot p_{i}^{(g)}+\\alpha \\cdot \\frac{1}{M} \\cdot \\sum_{j=1}^{M} X_{k_{j}}^{i}\n$$  \nwhere $i=1,2, \\cdots, 1$ and $\\alpha \\in(0,1]$ is the learning rate.\nBecause $\\alpha$ not only affects the convergence speed of PBIL, but also affects the search ability of the global optimal solution of PBIL. Therefore, we give Formula (9) to determine the size of $\\alpha$ [33].  \n$$\n\\alpha=r_{0} \\times \\frac{\\left[t / t_{0}\\right]}{N_{\\max }}+r_{1} \\times(-1)^{T \\bmod 10}\n$$  \nwhere $a_{1}=r_{0} \\times \\frac{\\left[t / t_{0}\\right]}{N_{\\max }}$ is a learning factor that changes with evolutionary algebras, $a_{2}=r_{1} \\times(-1)^{T \\bmod 10}$ is a learning factor that changes with the degree of evolution, $r_{0}$ and $r_{1}$ are the benchmarks for $a_{1}$ and $a_{2}, N_{\\max }$ is the maximum iteration number of the algorithm, $t$ is the evolutionary algebra, and $t_{0}$ is the interval algebra of evolution, $T$ is an algebra in which the population optimal individuals are continuously not improved, $\\bmod$ is a modular operation, and $\\left[t / t_{0}\\right]$ is the largest integer not greater than $t / t_{0}$.\n2) Generating Test Data for Covering Extended Paths based on EDA: After the above preparations, we propose a method, namely TDG-EDA, to generate test data for covering\nInput: The set $\\Phi$ of extended paths\nOutput: The set $\\Psi$ of test data  \n1: Set $g=0, T_{0}=20$ and $|\\Phi|_{\\text {unused }}=|\\Phi|$\n2: Initialize the probability vector $P^{(g)}$ and the population size $N_{\\text {size }}$\n3: while $|\\Phi|_{\\text {unused }} \\neq 0$ do\n4: Select an extended path from $\\Phi$ without repetition\n5: while $g<N_{\\max }$ do\n6: Get the $g$-th generation population from $P^{(g)}$\n7: Obtain test data (individuals) by the decoding method\n8: Calculate the fitness Fit from formula (7)\n9: if $F i t=0$ then\n10: Add the optimal solution (test data) to $\\Psi$\n11: else\n12: Obtain stable algebra $T$ based on Fit\nif $T=T_{0}$ then\n14: Break\n15: else\n16: Get $N_{\\text {best }}\\left(N_{\\text {best }}<N_{\\text {size }}\\right)$ optimal solutions\n17: Calculate $\\alpha$ according to Formula (9)\n18: Update $P^{(g)}$ from Formula (8)\n19: $g \\leftarrow g+1$\n20: end if\n21: end if\n22: end while\n23: $|\\Phi|_{\\text {unused }} \\leftarrow|\\Phi|_{\\text {unused }} \\cdot|\\Phi|_{\\text {used }}$\n24: end while\nextended paths. The specific steps of TDG-EDA are shown in Algorithm 3.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:23",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to solve the 2D knapsack problem with guillotine constraint, how should practitioners utilize probability estimation and sampling techniques in place of traditional recombination and mutation evolutionary operators?",
      "topics": [
        "Estimation of Distribution Algorithm",
        "2D knapsack problem",
        "guillotine constraint",
        "probability estimation",
        "sampling techniques"
      ],
      "answer": "Practitioners should replace recombination and mutation operators with probability estimation and sampling techniques. The Estimation of Distribution Algorithm (EDA) works with two probability models to improve solution quality. The specific implementation details of these models and sampling techniques are not provided, but the EDA uses these models in conjunction with local search procedures.",
      "chunk_id": 8049,
      "paper_id": "An EDA for the 2D knapsack problem with guillotine constraint",
      "paper_title": "An EDA for the 2D knapsack problem with guillotine constraint",
      "paper_year": "2019",
      "chunk_content": "Istvan Borgulya ${ }^{1}$ (D)  \nPublished online: 24 May 2018\n(c) Springer-Verlag GmbH Germany, part of Springer Nature 2018\nIn this paper we present an evolutionary heuristic for the 2D knapsack problem with guillotine constraint. In this problem we have a set of rectangles and there is a profit for each rectangle. The goal is to cut a subset of rectangles without overlap from a rectangular strip of width $W$ and height $H$, so that the total profit of the rectangles from the subset is maximal. The sides of the rectangles are parallel to the strip sides and every cutting is restricted by orthogonal guillotine-cuts. A guillotinecut is parallel to the horizontal or vertical side of the strip and cuts the strip into two separated rectangular strips. Our algorithm is an estimation of distribution algorithm (EDA), where recombination and mutation evolutionary operators are replaced by probability estimation and sampling techniques. Our EDA works with two probability models. It improves the quality of the solutions with local search procedures. The algorithm was tested on well-known benchmark instances from the literature.  \nKeywords Cutting-packing $\\cdot$ Knapsack $\\cdot$ Guillotine-cut $\\cdot$ EDA",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:24",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Copula-based Estimation of Distribution Algorithm (CEDA) discussed, how does the algorithm leverage copula functions to reduce computational cost compared to traditional multiobjective evolutionary algorithms (MOEAs) when generating alternative Pareto optimal solutions for many-objective problems?",
      "topics": [
        "search"
      ],
      "answer": "CEDA constructs a Copula, which describes the dependence structure of random variables, by selecting the best individuals from an initial population using a MOEA. This constructed Copula is then used to generate new populations without re-running the MOEA for each request for alternative solutions. Traditional MOEAs require costly objective function evaluations and sorting in every generation to approximate the Pareto front. By using the Copula to generate new samples with a joint probability distribution, CEDA avoids these repeated objective function evaluations and sorting steps, thus reducing the computational cost when alternative solutions are needed. Furthermore, one-class SVM is used to classify the generated solutions, providing a mechanism to filter solutions that do not meet the Decision Maker's needs, further optimizing the search process.",
      "chunk_id": 12208,
      "paper_id": "Fast Solutions Enhancing using a Copula-based EDA and SVM for many-objective problems",
      "paper_title": "Fast Solutions Enhancing using a Copula-based EDA and SVM for many-objective problems",
      "paper_year": "2016",
      "chunk_content": "In many fields of science and engineering a Decision Maker ( DM ) have to pick a number of best options from a very high number of choices, those choices are solutions of a given problem which have a number of criteria or objectives to satisfy. The solutions should satisfy all objectives in same time, this condition results that a solution from the choice space can't get better without detriment of another objective, and by considering this we arrive at a very important consequence; in this type of problem there is no single optimal solution but rather a set of optimal solutions (called Pareto solutions PS).\nThe evolutionary algorithms (EAs) are commonly used to resolve this class of problems Zhou et al. (2011). The complexity of resolving those problems repose in the fact that for every objective function of the problem have to be evaluated in every generation of the EA, thus if the number of objectives increases the search process get more and more complex. By definition, if the number of the objectives of the problem are equal or more than four the multiobjective problem is called Manyobjective problem, numerous multiobjective evolutionary algorithms (MOEA) was used to deal with many-objective problems Von Lucken et al. (2014).\nThe techniques used for solving a multiobjective problem have evolved over time and those based on Evolutionary Algo-\nrithms (EA) are among the best suited ones such as MOEA/D, NSGA2, SPEA2, etc. Among the EA techniques, Estimation of Distribution Algorithms (EDA) is a novel class which has good searching ability and explicitly model the statistical distribution of the solutions.  \nWhere a probabilistic model linking the interactions between the solutions is constructed and then used to generate new solutions. Specifically, we base our solution on Copulas for their ability to generate new solutions without the need for running the solving algorithms each time a newer solution is needed.  \nThis is so because typical algorithms used to solve the MOPs are based on evolutionary algorithms where finding a solution involves starting with a population and evaluating its closeness to Pareto front each step and run again until a satisfactory solution is found. Each step solutions are sorted and involves costly objective function evaluations and sorting.  \nCopula functions describe the dependence structure of two or more random variables associated by a joint probability distribution function. In other words, they provide a scale-free description of how a number of random variables are distributed. Once the copula is unveiled, the whole joint probability distribution function can be found. Moreover, we can use the copula function to generate new samples with such a joint probabil-  \nity distribution. Briefly, this is achieved by the way CEDA (Copula-base EDA) operates, which starts by selecting the best individual using a MOEA (Multi Objective Evolutionary Algorithm) Deb et al. (2002); Zitzler et al. (2002) from a population generated randomly. Then, CEDA uses the selected individuals to estimate their distribution using a Copula. The constructed Copula is used to generate a new population. CEDA continues with generating and selecting the best individuals until the stop condition is met. When CEDA stops, the latest generated individuals are considered to be Pareto optimal solutions and the last Copulas can be used in a later calls of CEDA to generate alternative optimal solutions and using one-class SVM to classify the generated solutions, if those generated do not satisfy the needs of the Decision Maker. This design saves CEDA the need of running an MOEA every time alternative solutions are requested by a Decision Maker when the found solutions are not satisfactory.  \nThe main contributions of this paper are the following:",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:26",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between the EDA approaches of RegEDA-LARS-OR and RegEDA-LARS-AND?",
      "topics": [
        "optimization"
      ],
      "answer": "RegEDA-LARS-OR and RegEDA-LARS-AND are selected because they strike a compromise between computational time requirements and the quality of the estimated models, considering both structural accuracy and negative log-likelihood (NLL).",
      "chunk_id": 172,
      "paper_id": "Regularized continuous estimation of distribution algorithms",
      "paper_title": "Regularized continuous estimation of distribution algorithms",
      "paper_year": "2013",
      "chunk_content": "So far we have studied some of the properties of the regularized model estimation methods in two approaches. The results of these analyses can be used as a guideline for employing these methods in EDAs. The regularized EDA (RegEDA) proposed in this paper utilizes the regularized model estimation methods in the course of optimization, trying to obtain a better estimation of the distribution of the problem solutions, in order to improve performance.  \nThe constraints on time and computational resources, restrict the number of different regularized estimation methods that can\n[IMAGE10]  \nFig. 10. Average model-building time (left) and negative log-likelihood of the bivariate Gaussian distribution (right) obtained for the graphical LASSO method with different regularization parameter $(\\lambda)$ values.  \nbe tested and compared. For the experiments in the rest of the paper, some of the methods discussed in the previous sections were selected for use in RegEDA. We selected the LARS-OR and LARS-AND methods from the first approach. They appear to strike a better compromise between the computational time requirements and the quality of the estimated models, from both the structural accuracy and NLL points of view. The resulting algorithms are called \"RegEDA-LARS-OR\" and \"RegEDA-LARS-AND\", respectively. From the second approach, both the shrinkage estimation and graphical LASSO methods were selected to respectively build the \"RegEDAShr\" and \"RegEDA-GL\" algorithms. The properties of both these methods merit further investigation regarding optimization. In the next section, we examine the performance of these four versions of RegEDA in function optimization.\nIn this section, the proposed RegEDAs are applied for continuous function optimization in order to investigate how regularized model estimation affects the optimization behavior and performance of EDAs when applied in a high-dimensional setting. The optimization results of these four versions of RegEDA are compared against another four Gaussian distribution-based EDAs. These four algorithms are:  \n- Continuous Univariate Marginal Distribution Algorithm (UMDA) [30].\n- Estimation of Gaussian (Bayesian) Network Algorithm (EGNA) [30].\n- Estimation of Multivariate Normal (distribution) Algorithm (EMNA) [2].\n- Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES) [69].\nAll of the algorithms are implemented in Matlab. The implementation of the LARS technique in RegEDA-LARS-OR and RegEDA-LARS-AND algorithms, is provided by K. Sjostrand. ${ }^{1}$ The implementations of the covariance shrinkage method and the graphical LASSO algorithm are provided by K. Murphy ${ }^{2}$ and by H. Karshenas, ${ }^{3}$ respectively.  \nThe Matlab implementations of UMDA and EMNA provided in MATEDA-2.0 ${ }^{4}$ [70] are used in the experiments. EGNA is implemented using the Gaussian-Bayesian network learning code provided by M. Schmidt and K. Murphy. ${ }^{5}$ Since the PLS algorithm is used to sample the learnt Bayesian network, the algorithm is referred to as \"EGNA-PLS\" in the results presented in this section. Finally, the implementation of CMA-ES is provided by N. Hansen. ${ }^{6}$",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:28",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What programming techniques are suggested to optimize the EDA's performance when updating frequencies, specifically concerning the number of frequencies at 1/2?",
      "topics": [
        "selection"
      ],
      "answer": "To optimize the EDA's performance, the implementation should consider that during $O(n \\\\log n)$ iterations, the algorithm checks for significance in 1s in parallel for all frequencies. The code needs to efficiently manage the scenario where \\\\( \\\\ell \\\\) represents the number of frequencies at 1/2, and \\\\(n - \\\\ell\\\\) frequencies are at 1 - 1/n. A key optimization involves focusing on positions \\\\(i \\\\in [n]\\\\) where \\\\(\\tau_{i} = 1/2\\\\), updating them to 1 - 1/n within \\\\(O(\\\\ell \\\\log n)\\\\) iterations if they sample 1s significantly more often by a factor of \\\\(\\Theta(1 / \\\\sqrt{\\\\ell})\\\\). The implementation should efficiently calculate and compare probabilities of saving a 1 based on whether the number of 1s in offspring differs by at least two (event A) or not (event \\\\(\\bar{A}\\\\)), using probabilities 1/2 and 5/8 respectively, to determine \\\\(Pr[O]\\\\), the probability to save a 1 at position i.",
      "chunk_id": 10978,
      "paper_id": "Significance-based Estimation-of-Distribution Algorithms",
      "paper_title": "Significance-based Estimation-of-Distribution Algorithms",
      "paper_year": "2018",
      "chunk_content": "Proof. As in the proof of Theorem 3.4, we start by showing that the run time holds with high probability. For this, we condition on the event that no frequency decreases during $O(n \\log n)$ iterations. This can be argued in the same way as in the aforementioned proof.  \nThe main idea of this proof is to show that, for any frequency at $1 / 2, O(n \\log n)$ iterations are enough in order to detect a significance in 1 s . This happens in parallel for all frequencies. For our argument to hold, it is only important that all the other frequencies are at $1 / 2$ or $1-1 / n$, which we condition on.  \nFormally, during any of the $O(n \\log n)$ iterations, let $\\ell \\in[n]$ denote the number of frequencies at $1 / 2$. Then $n-\\ell$ frequencies are at $1-1 / n$. Further, consider a position $i \\in[n]$ with $\\tau_{i}=1 / 2$. We show that such a position will sample 1 s significantly more often than the hypothesis by a factor of $\\Theta(1 / \\sqrt{\\ell})$. Then $\\tau_{i}$ will be updated to $1-1 / n$ within $O(\\ell \\log n)$ iterations.  \nIn order to show that 1 s are significantly more often saved than assumed, we proceed as follows: we consider that all bits but bit $i$ of both offspring during any iteration have been sampled. If the number of 1 s of both offspring differs by more than one, bit $i$ cannot change the outcome of the selection process - bit $i$ will be 1 with probability $1 / 2$. However, if the number of 1 s differs by at most one, then the outcome of bit $i$ in both offspring has an influence on whether a 1 is saved or not, i.e., this introduces a bias toward saving a significant amount of 1 s .  \nLet $O$ denote the event to save a 1 at position $i$ this iteration, and let $A$ denote the event that the numbers of 1 s (excluding position $i$ )\nof both offspring differ by at least two during that iteration. Then the probability to save a 1 , conditioned on $A$, is $1 / 2$.  \nIn the case of $\\bar{A}$, we make a case distinction with respect to the absolute difference of the number of 1 s of both offspring, excluding position $i$. If the difference is zero, then a 1 will be saved if not both offspring sample a 0 , which happens with probability $1-$ $(1 / 2)^{2}=3 / 4$. If the absolute difference is one, then a 1 will be saved if the winner (with respect to all bits but bit $i$ ) samples a 1 (with probability $1 / 2$ ) or if it samples a 0 , the loser samples a 1 , and the loser is chosen during selection, which happens with probability $(1 / 2)^{3}=1 / 8$. Overall, the probability that a 1 is saved is at least $1 / 2+1 / 8=5 / 8$ in the case of $\\bar{A}$.  \nCombining both cases, we see that $\\operatorname{Pr}[O] \\geq \\operatorname{Pr}[A] \\cdot \\frac{1}{2}+\\operatorname{Pr}[\\bar{A}] \\cdot \\frac{5}{8}$, which can be lower-bounded by determining a lower bound for FORMULA_388, according to Lemma 3.3.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:31",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach is outlined to assess the impact of uncertainty in wind power generation on power system reliability, particularly given the limited research in this area?",
      "topics": [
        "search"
      ],
      "answer": "A common sequential Monte Carlo Simulation (MCS) framework is utilized to compute extreme weather events affecting energy transmission. This approach is applied in the context of cascading failure simulation models, which are coupled with extreme weather events to assess system vulnerability.",
      "chunk_id": 1972,
      "paper_id": "Reliability evaluation of a composite power system in the presence of renewable generations",
      "paper_title": "Reliability evaluation of a composite power system in the presence of renewable generations",
      "paper_year": "2022",
      "chunk_content": "[IMAGE_1]  \nFig. 1. Discretized wind speed PDF.\nrandom variables with multinomial distribution. In [26], a MCS-based decision support system framework is implemented to enable fast calculation of loss of load expectation (LOLE) as a risk measure in a power system consisting various sources of renewable and conventional power. In order to enable wind energy to be distributed to consumers, dynamic thermal rating (DTR) system is utilized to alleviate the congestion of power system. In line with purpose, the authors of Ref [27]. have presented the reliability modeling of battery energy storage system along with the DTR technologies for the first time. The authors of [28] have presented the conception of a framework for the modeling and the simulation of the SHyFTA which is able to combine dynamic fault tree with the deterministic model of the system process. The proposed framework in this reference is realized based on a hybrid Discrete Event-Time Driven iteration engine at the base of the MCS.  \nA large amount of uncertainty entered into power systems may affect the system vulnerability to cascading failures. To cascade a failure simulation model, authors of Ref [29]. have outlined a coupled extreme frame weather event. Then, a common sequential MCS framework has been utilized to compute extreme weather events affecting energy transmission. Nevertheless, many works in the literature have addressed the effects of wind power generations on power system reliability, and few researches have explored the variability and uncertainty of wind power generation [30].  \nWith the development of smart grid infrastructure, a hierarchical model comprising a layered fault tree and continuous-time Markov chains is introduced in [31] to model a smart grid system aiming to find the weak parts of the system and to improve the system design. In [32], the effect of small-size energy storage operating along with the local PV-based microgrids in smart grids has been examined to improve reliability performance and attain financial benefits for the system operator and their owners.",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:32",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the AAVS-EDA compared to other evolutionary algorithms like EMNA${}_{g}$, AMaLGaM, IPOP-CMAES, CPI-JADE, and HHSPSO-GDS in continuous optimization?",
      "topics": [
        "optimization"
      ],
      "answer": "AAVS-EDA demonstrates competitive performance, particularly excelling on hybrid functions where it often achieves superior results compared to EMNA${}_{g}$, AMaLGaM, IPOP-CMAES, CPI-JADE and HHSPSO-GDS, while showing comparable or slightly weaker performance on simple multimodal functions when contrasted with IPOP-CMAES and CPI-JADE.",
      "chunk_id": 11066,
      "paper_id": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_title": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_year": "2018",
      "chunk_content": "4.3 Comparison with other state-of-the-art EAs  \nTo evaluate the performance of AAVS-EDA, this section compares it with EMNA ${ }_{g}$ [4], AMaLGaM [19], IPOP-CMAES [26], CPI-JADE [45] and HHSPSO-GDS [46]. CPI-JADE is a new variant of DE, it  \nimproves the performance of classic JADE [47] by implementing the crossover operator in both the original coordinate space and the eigen coordinate space, where the latter is established by decomposing the covariance matrix which is estimated from the cumulative population distribution information with the covariance matrix adaptation strategy developed in CMA-ES. In this sense, CPI-JADE has suitable comparability with AAVS-EDA. HHSPSO-GDS integrates the harmony search algorithm and the global dimension selection strategy into PSO to enhance its exploration and exploitation abilities. Experimental results revealed that HHSPSO-GDS possesses superior performance over many other PSO variants [46]. In short, AMaLGaM, IPOP-CMAES, CPI-JADE and HHSPSO-GDS can be viewed as the state-of-the-art of four kinds of EAs for continuous optimization, i.e., EDA, ES, DE and PSO, respectively. Table 1 reports the mean and standard deviation of FEVs obtained by the 6 algorithms on 30 benchmark functions, where the results of CPI-JADE and HHSPSO-GDS are directly taken from their original papers. Cohen's $d$ effect size [48] is adopted to judge the performance difference between AAVS-EDA and its five competitors. Cohen's $d$ effect size is a popular statistical method for quantifying the difference between two groups of data. It is independent of the sample size and is generally considered \"small\", \"medium\", and \"large\" if its absolute value belongs to $[0.2,0.3),[0.3,0.8)$ and $[0.8,+\\infty)$, respectively. From Table 1, it can be observed that:  \n1) Unimodal functions $f_{1}-f_{5}$ : AAVS-EDA obtains the global optima for three unimodal functions, so do AMaLGaM, IPOP-CMAES and CPI-JADE. The results show that the combination of AAVS and the global monitor results in fine search performance for AAVS-EDA. As for the other two algorithms, HHSPSO-GDS shows better performance than $\\mathrm{EMNA}_{g}$, but they both are outperformed by AAVS-EDA on all the three test functions.\n2) Simple multimodal functions $f_{4}-f_{16}$ : Among these 13 functions, AAVS-EDA has an edge over AMaLGaM, IPOP-CMAES, CPI-JADE and HHSPSO-GDS on 9, 4, 4 and 7 functions, respectively, but is defeated by them on 2, 7, 8 and 6 functions, respectively. As a whole, AAVS-EDA performs a little worse  \nthan IPOP-CMAES and CPI-JADE on this group of functions, but achieves better performance than EMNA $_{8}$, AMaLGaM and HHSPSO-GDS.\n3) Hybrid functions $f_{17}-f_{32}$ : It is obvious that AAVS-EDA performs best among six algorithms on this group of test functions. The results it obtained are all not worse than the ones obtained by the other five algorithms except that HHSPSO-GDS achieves a better solution for $f_{19}$. Especially, AAVS-EDA reduces the mean of FEVs for $f_{18}$ by at least two orders of magnitude.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:34",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms, how does the algorithmic mechanism of the LA-rBOA differ from the IrBOA and the mIDEA in how they utilize selected solutions for constructing Bayesian networks, and what impact does this difference have on performance, particularly on functions with global optima on bounds?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Bayesian networks",
        "LA-rBOA",
        "IrBOA",
        "mIDEA",
        "global optima",
        "bounds"
      ],
      "answer": "The LA-rBOA, IrBOA, and mIDEA are all Estimation of Distribution Algorithms. The IrBOA and the mIDEA use selected solutions directly for building the Bayesian network. However, the LA-rBOA uses the selected solutions only in the learning rule of Learning Automata (LAs) to update 'FORMULA_175'. Because of this difference, for Schwefels problem 2.6 (function F5), which has a global optimum on bounds, the LA-rBOA obtains worse results than the IrBOA and the mIDEA. For Ackleys function (function F8) with global optimum on bounds, the results of the IrBOA and mIDEA are better than LA-rBOA.",
      "chunk_id": 715,
      "paper_id": "A new real-coded Bayesian optimization algorithm based on a team of learning automata for continuous optimization",
      "paper_title": "A new real-coded Bayesian optimization algorithm based on a team of learning automata for continuous optimization",
      "paper_year": "2014",
      "chunk_content": "Table 2 Numerical results for the LA-rBOA, the IrBOA and the mIDEA  \nTable 3 The results of statistical test for the LA-rBOA, the IrBOA and the mIDEA\nsuperior to the LA-rBOA; because they use the selected solutions for building the Bayesian network directly; but we use them only in the learning rule of LAs to update FORMULA_175; hence, for this function LA-rBOA obtains worse result. Function F5 is Schwefels problem 2.6 with global optimum on bounds. For this function, the proposed algorithm is superior to the IrBOA and the mIDEA.  \nFunctions F5 through F25 are multi-modal functions. The results for functions F6-F25 are listed in Table 4. For each function the mean error value and the standard deviation of the obtained fitness values on the 50 independent runs are presented. Also, the statistical test between the experiments obtained with the LArBOA and two other algorithms for functions F6-F25 are shown in Table 5. Function F6 is shifted Rosenbrocks function, a problem between uni-modal and multi-modal function. For this function, the result for the LA-rBOA is better than the IrBOA and the mIDEA. Function F7 is shifted rotated Griewanks function without bounds, only the initialization range is given. Griewanks function is more difficult with low dimension and it is difficult to achieve the global optimum. The LA-rBOA obtains better result in comparison to the IrBOA and the mIDEA. Function F8 is shifted rotated Ackleys function with global optimum on bounds, which has a very narrow global basin and half of the dimensions of this basin are on the bounds. Hence, the search is almost like seeking a needle in a haystack. For this function, the results of the IrBOA and mIDEA are better than LA-rBOA. Functions F9 and F10 are shifted Rastrigins function and shifted rotated Rastrigins function, respectively. These two of functions have a huge number of local optima. The results demonstrate good performance of the LA-rBOA in comparison to the mIDEA and the IrBOA. Function F11 is shifted rotated Weierstrass function and Function F12 is Schwefels problem. For function F11 the mIDEA gets better  \nTable 4 Numerical results for the LA-rBOA, the IrBOA and the mIDEA\nsolution in compare two other algorithms but for function F12 the LA-rBOA outperforms the IrBOA and the mIDEA. As mentioned before, our test suite contains uni-modal and multi-modal functions; so, according to the obtained results it is reasonable to say that the LA-rBOA presents evidences to perform better than the IrBOA and the mIDEA.",
      "question_type": "algorithmic difference",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:36",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within Gene Expression Programming (GEP), specifically using the Gene Estimation of Gene Expression Programming (GEGEP) algorithm, how should practitioners calculate the mutation probability $p_{j}^{\\omega}$ for an operator $\\omega$ at position $j$ within the head or body of a gene?",
      "topics": [
        "crossover"
      ],
      "answer": "To calculate the mutation probability $p_{j}^{\\omega}$ in GEGEP, first determine the fitness value $f_i$ of each chromosome $G_i$ in the population. Then, calculate $p_{i}$ for each chromosome as $p_{i} = \\frac{f_{i}}{\\sum_{j=1}^{n} f_{j}}$, ensuring that $\\sum_{i=1}^{n} p_{i}=1$. Next, for each position $j$ in the head or body ($j \\in H$) and for each operator $\\omega$ in the function set $F$, define $Z_{ij}^{\\omega}$ as 1 if the $k$th position of $G_i$ is operator $\\omega$, and 0 otherwise. Finally, compute $p_{j}^{\\omega}$ as $p_{j}^{\\omega} = \\sum_{i=1}^{n} Z_{i j}^{\\omega} \\cdot p_{i}$. This probability is then used to mutate the operator at position $j$ within the gene.",
      "chunk_id": 5521,
      "paper_id": "Asynchronous Distributed Parallel Gene Expression Programming Based on Estimation of Distribution Algorithm",
      "paper_title": "Asynchronous Distributed Parallel Gene Expression Programming based on Estimation of Distribution Algorithm",
      "paper_year": "2008",
      "chunk_content": "Gene structure of traditional GEP has some deficiencies, take single gene chromosome for example, if the first symbol of head of gene is a terminator, then the chromosome has no value, because the expression corresponding to the gene is only a terminator. So we use improved gene structure [3], the gene head in GEP is divided into a head and a body. This structure is benefit to introduce learning mechanism and solve more complex problem.  \nThe head contains only functions, the body contains symbols representing both functions and terminals, whereas the length of the tail is a function of head, body and the number of arguments of the function with more arguments n (also called max arity) and is evaluated by the equation: tail $=($ head + body $)(\\mathrm{n}-1)+1$.  \nHomeotic genes have exactly the same kind of structure as conventional genes and are built using an identical process. Homeotic gene is used to connect conventional genes.  \nIn order to improve the convergence speed of GEP, the idea of EDA is introduced into GEP, Gene Estimation of Gene Expression Programming(GEGEP) [3] algorithm is proposed. Considering time and space cost, Univariate EDA Model is used. The GEGEP algorithm is as follows:  \nPROCEDURE GEGEP algorithm\nbegin\nInitialize $\\mathrm{P}(0)$;\nEvaluate every individual's fitness of $\\mathrm{P}(0)$ and build probability table of estimation of distribution;\n$\\mathrm{t}:=0$;\nrepeat\n$\\mathrm{Pm}(\\mathrm{t}):=$ mutation $\\{\\mathrm{P}(\\mathrm{t})\\}$ according to probability table of estimation of distribution;\n$\\mathrm{Pc}(\\mathrm{t}):=$ crossover $\\{\\mathrm{P}(\\mathrm{t})\\}$;\n$\\mathrm{Pt}(\\mathrm{t}):=$ transpose $\\{\\mathrm{Pc}(\\mathrm{t})\\}$;\n$\\mathrm{P}(\\mathrm{t}+1):=$ selection $\\{\\mathrm{P}(\\mathrm{t})\\} ;$\nRenew probability table of estimation of distribution;\n$\\mathrm{t}:=\\mathrm{t}+1$;\nuntil termination condition;\noutput solution of Pbest;\nend\nThis main idea of GEGEP mutation is to carry on statistics to each operator of head and body of conventional genes  \nTable 1. Probability of estimation of distribution\nand homeotic gene, extract its statistical probability, and then mutate according to its statistical probability as Table1. For example, if $k \\in H$ and the $k$ th position of $G_{i}$ is operator $\\omega$, then mutates with probability $p_{k}^{\\omega}$, else mutates randomly. Here $H$ contains head and body part. Take a single gene as an example: Let $\\mathrm{h}=2, \\mathrm{~b}=3$, the number of statistical component (the head and body of gene) is $\\mathrm{H}=\\{1,2,3,4,5\\}$, Function Set $\\mathrm{F}=\\{+,-,+, /\\}, \\omega \\in F$ the fitness value of chromosome $G_{i}$ is $f_{i}$, then $p_{i}=\\frac{f_{i}}{\\sum_{j=1}^{n} f_{j}}$, $\\sum_{i=1}^{n} p_{i}=1$; if the kth position of $G_{i}$ is operator $\\omega$, then $Z_{i j}^{\\omega}$ is 1 , else $Z_{i j}^{\\omega}$ is $0 . p_{j}^{\\omega}=\\sum_{i=1}^{n} Z_{i j}^{\\omega} \\cdot p_{i}, j \\in H, \\omega \\in F$ ,Obviously FORMULA_35",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:39",
      "generation_style": "practical_application"
    },
    {
      "question": "How is the computational complexity of the fitness evaluation step handled in the described evolutionary algorithm, specifically concerning the distribution of individuals across processors?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The computational complexity of the fitness evaluation, which involves diffusion calculations for each individual in the population, is addressed using parallelization with the MPI Library. If there are $N$ individuals in the population and $S$ SLAVE processors, each SLAVE processor is assigned the task of evaluating the fitness of $(N / S)$ individuals. This division of labor aims to reduce the overall time required for fitness evaluation across the entire population in each generation.",
      "chunk_id": 6637,
      "paper_id": "Optimization of Thorium loading in fresh core of Indian PHWR by evolutionary algorithms",
      "paper_title": "Optimization of Thorium loading in fresh core of Indian PHWR by evolutionary algorithms",
      "paper_year": "2009",
      "chunk_content": "The evolutionary algorithms (GA and EDA) evolve population of candidate solutions. They take a great amount of computational time. The most time consuming part is the evaluation of \"fitness\" corresponding to each individual of the population. This requires full core simulation by diffusion calculation from which objective function or \"fitness\" given by Eq. (1) can be computed. Hence, these diffusion calculations for different individuals in the population were carried out in parallel. The parallelization was achieved using the MPI Library functions (Pacheco, 1997) as follows: The rank 0 processor is called here as MASTER processor and others are SLAVE processors. The MASTER will generate population containing $N$ individuals. If there are $S$ SLAVE processors, each SLAVE is assigned the job of evaluating the fitness of $(N / S)$ individuals by diffusion calculations. The results are returned to the MASTER. The MASTER will generate new population and send ( $N / S$ ) individuals to each slave for fitness evaluation. This is continued for all the generations. The computer code DOLP has been written to execute this using standard message passing interface (MPI) library functions in FORTRAN. The distributed memory parallel computer systems (Apte et al., 2008) AMEYA/AJEYA at BARC were used.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:41",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "According to the details in the chunk, what advantages does ACSEDA with the proposed cross-generation individual selection strategy have over ACSEDA-O, ACSEDA-OP, and ACSEDA-OA on the 50-D CEC 2014 benchmark problems?",
      "topics": [
        "search"
      ],
      "answer": "Based on the Friedman test results, ACSEDA using the proposed cross-generation individual selection strategy achieves a smaller averaged rank and a larger number of problems where it obtains the best results compared to ACSEDA-O (which directly utilizes the generated offspring as the parent population), ACSEDA-OP (which combines the parent population and offspring to select the best half), and ACSEDA-OA (which maintains an archive of historical individuals combined with offspring). This suggests that the proposed strategy helps ACSEDA avoid generating crowded individuals, thus preserving high search diversity during evolution.",
      "chunk_id": 9368,
      "paper_id": "An Adaptive Covariance Scaling Estimation of Distribution Algorithm",
      "paper_title": "An Adaptive Covariance Scaling Estimation of Distribution Algorithm",
      "paper_year": "2021",
      "chunk_content": "At last, we conduct experiments to verify the usefulness of the proposed crossgeneration individual selection strategy for the parent population. To this end, we first develop three other ACSEDA variants by using some existing typical selection strategies for the parent population. The first is to directly utilize the generated offspring as the parent population, such as in some traditional EDAs [20,21,28,30]. This variant of ACSEDA  \nis denoted as \"ACSEDA-O\". The second is to combine the parent population in the last generation and the generated offspring and then, select the best half of the combined population as the parent population for the next generation, as in some EDA variants [51,68]. This variant of ACSEDA is represented as \"ACSEDA-OP\". The last one is to maintain an archive I in some EDA variants [37] to store the historical useful individuals and then they are combined with the generated offspring to select the best half of the combined population as the parent population. This ACSEDA variant is denoted as \"ACSEDA-OA\".  \nAfter the preparation of the compared methods, we conduct experiments on the 50-D CEC 2015 benchmark problems to compare the ACSEDA with the proposed crossgeneration individual selection strategy and the ones with the above mentioned three compared strategies. Table 8 presents the comparison results among these different variants of ACSEDA.  \nTable 8. Comparison among ACSEDA with different selection strategies for the parent population on the 50-D CEC 2014 benchmark problems. The best results are highlighted in bold in this table.\nFrom Table 8, we can see that, from the perspective of the averaged rank obtained from the Friedman test and the number of problems where the algorithm achieves the best results, the ACSEDA with the proposed cross-generation individual selection strategy obtains the best overall performance. In particular, not only is the averaged rank is much smaller than those of the compared methods but the number of problems where the proposed ACSEDA achieves the best results is also much larger than those of the compared methods.  \nThe above observations demonstrate that the proposed cross-generation individual selection strategy for the parent population is very helpful for ACSEDA to obtain promising  \nperformance. This is because, by combining the generated offspring in the last generation and in the current generation, this strategy is less likely to generate crowded individuals for the parent population in the next generation and could, thus, aid ACSEDA to preserve high search diversity during the evolution, as analyzed in Section 3.3.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:43",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing the BEDA for the RJSSPST, how does the active decoding scheme optimize the makespan, and what specific programming steps are involved in handling sequence-dependent setup times during the decoding process?",
      "topics": [
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "The active decoding scheme aims to minimize the makespan by strategically inserting operations into the schedule. Specifically, before appending an operation at the end of the current schedule, the algorithm checks for any possible idle intervals. If an idle interval exists before the last operation, the algorithm inserts the new operation into that interval. The key programming step involves calculating the start and completion times of each operation, considering the sequence-dependent setup times. This requires maintaining a data structure that stores the setup time between any two operations on each machine. The algorithm must then iterate through the schedule, updating the start and completion times based on the chosen operation sequence and the corresponding setup times, ensuring that no machine processes more than one job at any given time.",
      "chunk_id": 1207,
      "paper_id": "A Bayesian Statistical Inference-Based Estimation of Distribution Algorithm for the Re-entrant Job-Shop Scheduling Problem with Sequence-Dependent Setup Times",
      "paper_title": "A Bayesian Statistical Inference-Based Estimation of Distribution Algorithm for the Re-entrant Job-Shop Scheduling Problem with Sequence-Dependent Setup Times",
      "paper_year": "2014",
      "chunk_content": "The above mathematical model is only used to depict the characteristics of RJSSPST. The following statement is utilized to code and decode each sequence or individual in the proposed BEDA. The RJSSPST has the following usual assumptions. There are $m$ machines, $n$ jobs and $L$ times re-entrant in the production system. The problem size can be denoted by $n \\times m \\times L$. Each job consists of a set of operations that have to be processed in a specified sequence. Each operation has to be processed on a definite machine and has a processing time and a setup time which are deterministically known. Moreover, each job should be processed on each machine $L$ times and the setup times of operations on each machine are sequence dependent. Once an operation is started, it must be completed without any interruption. At any time, each machine can process at most one job.  \nDenote $\\pi=\\left[\\pi_{1}, \\pi_{2}, \\ldots, \\pi_{\\text {seven } L}\\right]$ the sequence or schedule of operations to be processed. The RJSSPST with the makespan criterion is to find a schedule $\\pi^{*}$ in the set of all schedules $\\Pi$ such that  \n$$\n\\pi^{*}=\\arg \\left(C_{\\max }\\right) \\rightarrow \\min , \\quad \\forall \\pi \\in \\Pi\n$$\nIn this section, we will present BEDA after explaining the solution representation, decoding scheme, population initialization, probabilistic model and updating mechanism, new population generation method and new probabilistic model construction strategy.\nBased on the properties of RJSSPST, we adopt the operation-based solution representation, that is, every individual of the population is a feasible solution of the  \nRJSSPST, for example, $\\left[\\pi_{1}, \\pi_{2}, \\ldots, \\pi_{3 \\times 2 \\times 2}\\right]=[1,2,1,3,2,1,3,3,1,2,3,2]$ is an individual when the problem's scale $n \\times m \\times L$ is set to $3 \\times 2 \\times 2$.\nDue to the constraints of RJSSPST, we can improve the solution to minimize the makespan criterion by converting the semi-active schedule to the active one. Thus, when decoding we check the possible idle interval before appending an operation at the last position, and fill the first idle interval before the last operation (called active decoding). The details of active decoding scheme used in this paper are very similar to that used in [13]. The difference between the two schemes only lies in the treatment of the setup times. In [13], the setup times of each operation are not considered.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:45",
      "generation_style": "implementation_focused"
    },
    {
      "question": "For the described Estimation of Distribution Algorithm (EDA) used in the portfolio replication problem, what parameters are set to evaluate its performance across different search spaces?",
      "topics": [
        "optimization"
      ],
      "answer": "To evaluate the EDA's performance, the following parameters are specified: Parents' population size ($N_{p}=100$), Offspring population size ($N_{o}=200$), Elitist rate (0.1), the number of bins ($H=100$), Generation size (100), and Algorithm run (10). These parameters are used in conjunction with 11 benchmark portfolios (BP1 through BP11) as optimal solutions located on different spaces.",
      "chunk_id": 4467,
      "paper_id": "Equality constraint-handling technique with various mapping points  The case of portfolio replication problem",
      "paper_title": "Equality Constraint-handling Technique with Various Mapping Points: The Case of Portfolio Replication Problem",
      "paper_year": "2015",
      "chunk_content": "Our technique can transform the part of equality constrained search space to the unconstrained search space. The $\\boldsymbol{x}^{*}$ is the partial space on the constrained space $\\boldsymbol{x}$ mapped from the unconstrained space $\\boldsymbol{\\theta}$. In a word, our technique cannot find an optimal solution if the optimal solutuion is located on the space $\\boldsymbol{x} \\backslash \\boldsymbol{x}^{*}$. To investigate the power of our technique, we compare some case studies that the optimal solution is located on the different space of $\\boldsymbol{x}$.\nAs described in Section IV, the real optimal solution is the benchmark portfolio for the portfolio replication problem. The benchmark portfolio consists of the proportion-weighted combination of $N$ assets (variables). In the numerical experiments, we employ $N$ assets with high turnover on the Tokyo Stock Exchange. Each training phase consists of $T=20$ days data from 2005 to 2010. We call them Phase 1 through Phase 14, respectively.  \nThe setting of the optimization problem was as follows.  \n- The number of variables for individual $\\boldsymbol{\\theta}: M=2$\n- $\\quad$ The number of variables for solution $\\boldsymbol{x}: N=2^{M}=4$\n- Parameter of the equation (46): $\\rho=1.0 E-08$  \nWhen the number of variables of solution is $N=4$, we have 24 kinds of different search spaces between $\\boldsymbol{x}_{1}^{*}$ and $\\boldsymbol{x}_{24}^{*}$ given by the equations (16) $\\sim(39)$ for our EDA. For each of 24 spaces, the parameters of the EDA were set as follows.  \n- Parents' population size: $N_{p}=100$\n- Offspring population size: $N_{o}=200$\n- Elitist rate: 0.1\n- The number of bins: $H=100$ (The width of bin is set to $\\pi / H$.)\n- Generation size: 100\n- Algorithm run: 10  \nWe adopt the following 11 kinds of benchmark portfolios as the optimal solutions located on the different spaces of FORMULA_141. In this paper, we call them BP1 through BP11, respectively. The proportion-weighted combination of from BP1 to BP11 are shown in Table I and Fig. 2.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:47",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when applied to controlling a Khepera robot for wall-following, and how does the PMBGNP-AC algorithm achieve this?",
      "topics": [
        "optimization"
      ],
      "answer": "The primary objective is to control the Khepera robot's behavior for a reinforcement learning task, specifically wall-following. The PMBGNP-AC algorithm achieves this by evolving graph structures, using a reward function that considers both the robot's speed ($v_R$ and $v_L$ representing the right and left wheel speeds, respectively) and its proximity to the wall (represented by the sensor values). The fitness function aims to maximize the reward over a predefined number of steps, $S_{max}$, while penalizing collisions (represented by the variable C). The algorithm's performance is compared against Standard GNP, PMBGNP, PBILc, and Sarsa-Learning.",
      "chunk_id": 5138,
      "paper_id": "A continuous estimation of distribution algorithm by evolving graph structures using reinforcement learning",
      "paper_title": "A Continuous Estimation of Distribution Algorithm by Evolving Graph Structures Using Reinforcement Learning",
      "paper_year": "2012",
      "chunk_content": "Different from most of conventional EDAs doing function optimization problems, PMBGNP-AC is applied to controlling the behaviors of an autonomous robot - Khepera robot [25], which can be classified to a kind of Reinforcement Learning (RL) problems [23].  \nKhepera robot (Fig. 3) [25] is a wheeled mobile robot with 8 distance sensors allowing the robot to detect the proximity of objects around it by reflection. Each sensor returns a continuous value ranging from 0 to 1023 ( 0 means that there is no object around the sensor, while 1023 means that an object is very close to the sensor). Two motors corresponding to the left and right wheel can take speed values ranging from -10 to +10 , where different combinations of the two speeds would control the robots for different moving behaviors.  \nThe following algorithms are selected for comparisons:  \n1) Standard GNP: both of node connections and continuous variables of nodes are evolved by crossover and mutation.\n2) PMBGNP [4]: discretization is used to transfer the continuous variables into discrete values, where the value of each node remains unchanged during evolution. In this case, only $P_{\\mathrm{nc}}$ is constructed to evolve the node connections by SarsaLearning.\n3) PBILc: $\\mu$ and $\\sigma$ of continuous PMBGNP are evolved like those of PBILc [15].\n4) Sarsa-Learning (Sarsa) [23]: A classical RL metod, SarsaLearning in which the continuous state and action space is defined as the discrete space. $\\epsilon$-greedy policy is used for action selection.\n5) PMBGNP-AC: the proposed algorithm.  \nThe experiments are done by controlling Khepera robot to solve the wall-following problem. The reward and fitness functions are designed based on [27] and shown as follows  \n$$\n\\begin{gathered}\n\\text { Reward }=\\frac{v_{R}+v_{L}}{20}\\left(1-\\sqrt{\\frac{\\left|v_{R}-v_{L}\\right|}{20}}\\right) C \\\\\n\\text { Fitness }=\\frac{\\sum_{s t e p=1}^{S_{\\max } \\epsilon} \\text { Reward }}{S_{\\max }}\n\\end{gathered}\n$$  \nwhere,\n$v_{R}, v_{L}$ : the speed of right and left wheels,\n$S_{\\max }$ : the user predefined steps controlling the robot's running time, which is equivalent to the problem size.  \n$$\nC=\\left\\{\\begin{array}{ll}\n1, & \\text { all the sensor values are less than } 1000 \\\\\n0, & \\text { and at least one of them is more than } 100 \\\\\n0, & \\text { otherwise }\n\\end{array}\\right.\n$$  \nFigure 3 shows the environment used in this paper, where the size of the simulated environment is $1 \\mathrm{~m} \\times 1 \\mathrm{~m}$. The aim of the fitness evaluation is to control the robot to move following the wall as fast as and as straight as possible until the predefined steps $S_{\\max }$ reaches. $S_{\\max }$ is set at $\\{100,200$, $300,400,500\\}$ to define the problems from simple cases to complex ones.  \n[IMAGE2]  \nFig. 3. Khepera robot and simulation environment.\n[IMAGE3]  \nJudgment node $i$\nset the wheel speed to $x_{i}$\n[IMAGE4]  \nProcessing node FORMULA_169  \nFig. 4. Roles of continuous variables in judgment/processing nodes.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:49",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the $C$ metric, used for evaluating the relative quality of non-dominated sets, relate to the performance comparison between MCEDA and algorithms such as NSGA-II, MMOIG, KCA, and MOWSA?",
      "topics": [
        "comparison"
      ],
      "answer": "The $C$ metric, as used in the comparison, serves as a quantitative measure of the relative quality of non-dominated sets produced by different multi-objective algorithms, including MCEDA, NSGA-II, MMOIG, KCA, and MOWSA. Specifically, the statistical results of the coverage metric $C$ are reported in tables to show the performance of MCEDA compared with NSGA-II, MMOIG, KCA, and MOWSA on benchmark sets of different sizes, providing a basis for assessing the effectiveness of MCEDA relative to these other algorithms when applied to the energy-efficient distributed assembly permutation flow-shop scheduling problem.",
      "chunk_id": 2312,
      "paper_id": "A matrix cube-based estimation of distribution algorithm for the energy-efficient distributed assembly permutation flow-shop scheduling problem",
      "paper_title": "A matrix cube-based estimation of distribution algorithm for the energy-efficient distributed assembly permutation flow-shop scheduling problem",
      "paper_year": "2022",
      "chunk_content": "To further validate the effectiveness of the proposed algorithm, MCEDA is compared with four state-of-the-art multi-objective algorithms, i.e., NSGA-II, MMOIG, KCA, and MOWSA. Then, the relative quality of the non-dominated sets yielded by each algorithm is measured and evaluated on the $C$ metric, respectively. To the best of our knowledge, no algorithms are recently presented in the literature to tackle the considered EEDAPFSP. Since these high-performing compared algorithms are not directly designed for the EEDAPFSP, we reimplement these four algorithms and adjust their objective evaluation functions in the original literature to make them be able to solve this problem. Notice that all of these algorithms are adapted to the sequence-based model, so they can be easily extended and participated in comparisons. All algorithms are performed on the same experiment environment which has same CPU power available. Each algorithm independently runs 30 and 5 replicates on two benchmark sets of different problem sizes. The Pareto reference set of each instance is jointly composed of all non-dominated sets obtained by all algorithms. The computational results are grouped according to different numbers of factories and jobs, denoted by $F \\times n$, where 60 instances per average for each group of the small-scale benchmark set and 90 instances per average for each group of the large-scale benchmark set.  \nThe statistical results of the coverage metric of the proposed MCEDA with NSGA-II, MMOIG, KCA and MOWSA on two benchmark sets of different sizes are reported in Tables 8 to 9 , respectively. As seen from",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 12:12:51",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm in a wireless sensor network, how should practitioners address the challenge of reducing greenhouse gas emissions during the sensor network design and manufacturing phases?",
      "topics": [
        "design"
      ],
      "answer": "To reduce greenhouse gas emissions in the sensor network design and manufacturing phases, practitioners should focus on energy-efficient resource allocation. This involves using computing machines that consume less electricity and minimizing electronic waste. Reducing electricity consumption directly lowers carbon dioxide emissions, and minimizing electronic waste lessens the environmental impact of waste disposal, both contributing to a more energy-efficient and low-carbon deployment and operation of the WSN.",
      "chunk_id": 113,
      "paper_id": "Estimation of Distribution Algorithm for Resource Allocation in Green Cooperative Cognitive Radio Sensor Networks",
      "paper_title": "Estimation of Distribution Algorithm for Resource Allocation in Green Cooperative Cognitive Radio Sensor Networks",
      "paper_year": "2013",
      "chunk_content": "Wireless sensor networks (WSN) play an important role in many industrial [1], health [2] and body monitoring systems [3,4], seismic vibration sensing [5], ad-hoc systems [6] and spectrum sensing [7] applications. Almost all modern applications and services require some form of sensors. Due to the rapid increase in WSN applications and services, in the future, the limited frequency spectrum available for WSN applications will be extremely crowded [8]. With the rapid growth and dense deployment of WSN, in the field of information and communication technologies (ICTs) they play a significant role on the global environment [9]. According to the International Telecommunication Union report [10], the primary sources of greenhouse gases are electricity generation, transport vehicles, buildings, electronic waste (e.g., batteries, small electric cells, etc.) and agricultural by-products. A vast portion of electricity is generated with thermal- or coal-operated turbines. The process of electricity generation is a major contributor to the emissions of green house gases. With the rapid growth and demand of WSN, future WSNs' will face three major challenges: (1) the wireless spectrum availability, (2) the demand for high data rate transmission and (3) the reduction in greenhouse gases to cope with global warming.  \nFigure 1. WSN life cycle.\n[IMAGE0]  \nA large portion of green house gases is composed of carbon dioxide $\\left(\\mathrm{CO}_{2}\\right)$ emissions. For WSN, the term green refers to an energy-efficient and a low carbon deployment and operation. For reducing green house gases, particularly carbon dioxide emissions, an energy-efficient resource allocation plays a significant role and has a direct impact on the lifecycle of WSN. The lifecycle of WSN is shown in Figure 1. WSN are composed of the following phases: sensor network design, manufacturing, transportation, deployment and recycling. Each phase has its role in global warming-e.g., sensor network design and the manufacturing phase require highly sophisticated computing machines that not only use ample amounts of electricity, but also produce electronic waste. Both the generation of electricity and electronic waste has a direct impact on global warming. The sensor network application, e.g., multiple tracking, traffic monitoring, spectrum sensing or any other commercial/military  \napplication, requires a dense deployment of sensors. In the deployment, maintenance and recycling phases, the use of transportation is the major source of global warming.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 12:12:53",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding an \\(\\mathcal{H}\\)-invariant \\(n\\)-Bernoulli-\\(\\lambda\\)-EDA, as defined with update scheme \\(\\varphi\\), what relationship does Lemma 5 establish between the family of bijections \\(\\mathcal{H}\\) and the frequency vectors \\(\\boldsymbol{p}^{(t)}\\) at any time step \\(t\\), within the probability space \\(P^{(t)}(A)\\)?",
      "topics": [
        "proof"
      ],
      "answer": "Lemma 5 states that for an \\(\\mathcal{H}\\)-invariant \\(n\\)-Bernoulli-\\(\\lambda\\)-EDA, for all \\(h \\in \\mathcal{H}\\), all time steps \\(t\\), and all frequency vectors \\(\\boldsymbol{p}^{(t)} \\in P^{(t)}(A)\\), it holds that \\(h(\\boldsymbol{p}^{(t)}) \\in P^{(t)}(A)\\). This means that applying any bijection \\(h\\) from the family \\(\\mathcal{H}\\) to the frequency vector \\(\\boldsymbol{p}^{(t)}\\) at time step \\(t\\) results in a new frequency vector that is still within the probability space \\(P^{(t)}(A)\\) at that same time step. The proof uses induction, establishing a base case where \\(\\boldsymbol{p}^{(0)} = \\mathbf{1} / \\mathbf{2}\\), which is a fixed point for all \\(h \\in \\mathcal{H}\\), and then showing that if \\(h(\\boldsymbol{p}^{(t)}) \\in P^{(t)}(A)\\), then \\(h(\\boldsymbol{p}^{(t+1)}) \\in P^{(t+1)}(A)\\) also holds, using the \\(\\mathcal{H}\\)-invariance property of the EDA's update scheme \\(\\varphi\\).",
      "chunk_id": 8369,
      "paper_id": "Unbiasedness of estimation-of-distribution algorithms",
      "paper_title": "Unbiasedness of estimation-of-distribution algorithms",
      "paper_year": "2019",
      "chunk_content": "Definition 4. Let $A$ be an $n$-Bernoulli- $\\lambda$-EDA with update scheme $\\varphi$, and let $\\mathcal{H}$ be a family of bijections over $[0,1]^{n}$ with fixed point $\\mathbf{1} / \\mathbf{2}$ such that for all $h \\in \\mathcal{H}, h^{-1} \\in \\mathcal{H}$. We say that $A$ is $\\mathcal{H}$-invariant if and only if, for all $h \\in \\mathcal{H}$, all fitness functions $f$, all possible frequency vectors $\\boldsymbol{p} \\in P(A)$, and all offspring populations $D$ that can be sampled by $\\boldsymbol{p}$,  \n$$\nh\\left(\\varphi\\left(\\boldsymbol{p},(\\boldsymbol{x}, f(\\boldsymbol{x})_{x \\in D}\\right)\\right)=\\varphi(h(\\boldsymbol{p}),(h(\\boldsymbol{x}), f(\\boldsymbol{x})_{x \\in D})\n$$  \nNote that the right-hand side of this equation can be written as $\\varphi\\left(h(\\boldsymbol{p}),\\left(\\boldsymbol{x},\\left(f \\circ h^{-1}\\right)(\\boldsymbol{x})\\right)_{x \\in h(D)}\\right)$, that is, $h(\\boldsymbol{p})$ can sample $h(D)$ (since $\\boldsymbol{p}$ can sample $D$ ). In the following, if $\\mathcal{H}$ is the class of all permutations, we call an $\\mathcal{H}$-invariant $n$-Bernoulli- $\\lambda$-EDA A permutation-invariant. If $\\mathcal{H}$ is the class of all complementations, we call $A$ complementation-invariant. And if $\\mathcal{H}$ is the class of all isometric automorphisms, we call $A$ automorphism-invariant. Note that any function in any of these families has $\\mathbf{1} / \\mathbf{2}$ as a fixed point. This is important in order to ensure that $A$ has an initial distribution that is equally fair to any function $h \\in \\mathcal{H}$.  \nLemma 5. Let $A$ be an $\\mathcal{H}$-invariant $n$-Bernoulli- $\\lambda$-EDA. Then, for all $h \\in \\mathcal{H}$, all time steps $t$, and all $\\boldsymbol{p}^{(t)} \\in P^{(t)}(A)$,  \n$$\nh\\left(\\boldsymbol{p}^{(t)}\\right) \\in P^{(t)}(A)\n$$  \nProof. Let $h$ be any function of $\\mathcal{H}$. We prove this lemma by induction over $t$.\nFor the base case, we have $\\boldsymbol{p}^{(0)}=\\mathbf{1} / \\mathbf{2}$, which is equal to $h(\\mathbf{1} / \\mathbf{2})$, since $\\mathbf{1} / \\mathbf{2}$ is a fixed point for any $h \\in \\mathcal{H}$. Hence, $h\\left(\\boldsymbol{p}^{(0)}\\right) \\in P^{(0)}(A)$.  \nFor the inductive step, we assume that $h\\left(\\boldsymbol{p}^{(t)}\\right) \\in P^{(t)}(A)$ holds. We now show that $h\\left(\\boldsymbol{p}^{(t+1)}\\right) \\in P^{(t+1)}(A)$ holds.\nDue to the definition of an $n$-Bernoulli- $\\lambda$-EDA, we have that $\\boldsymbol{p}^{(t+1)}=\\varphi\\left(\\boldsymbol{p}^{(t)},(\\boldsymbol{x}, f(\\boldsymbol{x})_{x \\in D}\\right)$. And since $A$ is $\\mathcal{H}$-invariant, it holds that  \n$$\nh\\left(\\varphi\\left(\\boldsymbol{p}^{(t)},(\\boldsymbol{x}, f(\\boldsymbol{x})_{x \\in D}\\right)\\right)=\\varphi\\left(h\\left(\\boldsymbol{p}^{(t)}\\right),(h(\\boldsymbol{x}), f(\\boldsymbol{x})_{x \\in D}\\right)\n$$  \nThus, $h\\left(\\boldsymbol{p}^{(t+1)}\\right)=\\varphi\\left(h\\left(\\boldsymbol{p}^{(t)}\\right),(h(\\boldsymbol{x}), f(\\boldsymbol{x})_{x \\in D}\\right)$. Due to the induction hypothesis, it holds that $h\\left(\\boldsymbol{p}^{(t)}\\right) \\in P^{(t)}(A)$. By definition of an update, it follows that $\\varphi\\left(h\\left(\\boldsymbol{p}^{(t)}\\right),(h(\\boldsymbol{x}), f(\\boldsymbol{x})_{x \\in D}\\right) \\in P^{(t+1)}(A)$, which completes the proof.  \nLemma 5 shows how heavily the update scheme of an $n$-Bernoulli- $\\lambda$-EDA is already restricted when assuming that it is invariant. We now state our main theorem, which characterizes when an $n$-Bernoulli- $\\lambda$-EDA is unbiased. Recall that we defined $\\widehat{\\alpha}$ to be the unique extension of a Hamming automorphism FORMULA_439 after Lemma 2.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 12:12:57",
      "generation_style": "theoretical_foundation"
    }
  ]
}