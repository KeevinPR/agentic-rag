{
  "metadata": {
    "generation_date": "2025-06-07 21:24:17",
    "total_questions": 50,
    "generation_method": "chunk_based",
    "statistics": {
      "successful": 50,
      "failed_generation": 0,
      "total_questions": 50
    }
  },
  "questions": [
    {
      "question": "How does the algorithmic mechanism of gene pool recombination in Estimation of Distribution Algorithms (EDAs), specifically in algorithms like UMDA, relate to the principle of maximum entropy?",
      "answer": "The UMDA algorithm, an EDA based on gene pool recombination and linkage equilibrium, can be modeled using the principle of maximum entropy. When order-1 schema families are used, the sampling step is equivalent to gene pool recombination, and in this case, linkage equilibrium corresponds to maximum entropy. This means the algorithm's state can be reduced to frequencies of schemata, allowing a coarse-grained model based on these frequencies instead of individual strings.",
      "chunk_id": 13277,
      "paper_id": "An Estimation of Distribution Algorithm Based on Maximum Entropy",
      "paper_title": "An Estimation of Distribution Algorithm Based on Maximum Entropy",
      "paper_year": "2004",
      "chunk_content": "A major advantage of the approach of this paper is the potential for modeling algorithms based on maximum entropy. The sampling step of the algorithm framework (step 5) depends only on the frequencies of the schemata in the schema collection (and on the outcome of random number generation). Thus, a model of the algorithm can be based on these frequencies rather than the frequencies of all strings. This means that the model is naturally coarse-grained.  \nThis can be illustrated by existing models of algorithms based on gene pool recombination and linkage equilibrium, such as the UMDA algorithm. One analysis of the UMDA, based on quantitative genetics, appears in [11]. Fixed point analysis is used to explore the phenomenon of bistability in the UMDA with mutation in [16]. Both of these analyses use the fact that the population is in linkage equilibrium after gene pool recombination. When order-1 schema families are used, step 5 of our algorithm framework is gene pool recombination, and in this case, linkage equilibrium is equivalent to maximum entropy. In our algorithm that uses contiguous order- 2 schema families, the state of the population  \nis reduced to the frequencies of the schemata in these families, and a model of the algorithm can be based on keeping track only of these frequencies.  \nIn conclusion, we have presented a novel paradigm based on maximum entropy for constructing estimation of distribution algorithms. Preliminary experiments with an algorithm based on this idea using order- 2 schemata on deceptive trap functions (Figure 1) and NK landscapes (Figure 2) are promising. Further work on using higher order schemata should be done.  \nAcknowledgements. CRS is grateful for support from DGAPA project IN100201 and Conacyt project 41221-F. AW, RP and WBL are grateful for hospitality of the Instituto de Ciencias Nucleares, where this work was initiated, and to the above grants for financial support.",
      "question_type": "definition",
      "complexity": "basic",
      "topics": [
        "mutation"
      ],
      "generated_at": "2025-06-07 21:24:20",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "In which scenarios does the Net Benefit of Relocation (NBR) heuristic algorithm outperform Simulated Annealing when minimizing total tardiness, and what are the key implementation differences?",
      "answer": "The Net Benefit of Relocation (NBR) heuristic algorithm is reportedly better than other heuristics for minimizing total tardiness. A later version, M-NBR, expands upon NBR. For implementation, NBR focuses on relocating jobs to reduce tardiness. In contrast, Simulated Annealing, as proposed by Ben-Daya and AlFawzan, explores the solution space probabilistically, accepting worse solutions with a certain probability to escape local optima. The choice depends on the problem instance; if the problem structure allows for effective relocation-based improvements, NBR may be more efficient. However, Simulated Annealing might be better for complex instances where escaping local optima is crucial. Further, for single-machine total weighted tardiness problems with sequence-dependent setups, a variable neighborhood search may be more appropriate.",
      "chunk_id": 673,
      "paper_id": "Improved estimation of distribution algorithm for the problem of single-machine scheduling with deteriorating jobs and different due dates",
      "paper_title": "Improved estimation of distribution algorithm for the problem of single-machine scheduling with deteriorating jobs and different due dates",
      "paper_year": "2014",
      "chunk_content": "Before Du and Leung (1990), the problem of minimizing the total tardiness had been considered in some prior research. But, Du and Leung (1990) firstly proved that it is NP complete problem to minimize the total tardiness problem with different due dates and processing times for all jobs and gave a pseudo-polynomial algorithm for solving the problem. Following it, many literatures consider the related problem from the different aspects. Holsenback and Russell (1992) presented a heuristic algorithm Net Benefit of Relocation (NBR) for solving the problem, which is better than other heuristic algorithms. Later, Russell and Holsenback  \n(1997) proposed M-NBR through expanding the NBR for the problem. Ben-Daya and AlFawzan (1996) proposed a simulated annealing approach for the problem. Later, lots of extended problems are also studied in recent years. Bozejko (2010) used the parallel path relinking method for the single-machine total weighted tardiness problem with sequencedependent setups. Mazdeh et al. (2010) developed a linear programming formulation and three algorithms for solving the problem of minimizing total weighted tardiness with drop dead dates in single-machine scheduling. Akker et al. (2010) studied the problem of minimizing total weighted tardiness on a single machine with release dates and equal-length jobs and formulate it as a time-indexed integer linear programming. And then they showed several special cases for the problem can be solved in polynomial time. Akturk and Ilhan (2011) proposed a DP-based heuristic to solve the problem of single-computer numerical-controlled machines scheduling with controllable processing times to minimize total weighted tardiness. Kirlik and Oguz (2012) used a variable neighborhood search for minimizing total weighted tardiness with sequence-dependent setup times on a single machine.  \nIn recent years, some papers mentioned minimizing the total tardiness with deteriorating jobs. Toksan and Guner (2009) considered a parallel machine earliness/tardiness scheduling problem with different penalties with learning and deterioration under the condition that all jobs have common due date. They proposed a mathematical model for the problem and algorithm and lower bound procedure to solve larger test problems. Meng et al. (2012) considered the problem of scheduling deteriorating jobs with a common due window on a single machine and propose an optimal algorithm-CDW for solving the problem of minimizing costs for earliness, tardiness, earliest due date assignment and due window size penalties.  \nHowever, the above-mentioned studies assume that the due dates of jobs are common or have some special conditions. This paper studies the single-machine deteriorating jobs scheduling problem with different due dates when the objective is minimizing the total tardiness. Since the problem with normal processing times of jobs has been proved to be NP complete by Du and Leung (1990), the problem with deteriorating jobs is still NP complete.  \nOur contribution is that: we consider the real problem in steel industry as the special problem of single-machine deteriorating jobs with different due date; a mixed integer programming model is given; and an improved estimation of distribution algorithm (EDA) is addressed to find good near optimal solutions for the large size of the problem.  \nThe rest of this paper is organized as follows. In Sect. 2, problem is described and a mixed integer programming model is given. Then, two special cases that can be solved in polynomial time are considered in Sect. 3, namely, the case with common normal processing times and the case with identical due dates. In Sect. 4, an improved EDA is proposed for solving the problem in this paper. Section 5 is the numerical experiments, followed by the conclusion in the last section.",
      "question_type": "comparison",
      "complexity": "medium",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:24:23",
      "generation_style": "practical_application"
    },
    {
      "question": "Considering an algorithm that utilizes a sampling probability parameter, denoted as $p_{\\text{samp}}$, how does alternating between $p_{\\text{samp}} = 1$ and $p_{\\text{samp}} = 0$ across multiple runs affect the expected runtime complexity, and what are the theoretical implications for convergence guarantees compared to a fixed value of $p_{\\text{samp}}$?",
      "answer": "Alternating between $p_{\\text{samp}} = 1$ and $p_{\\text{samp}} = 0$ introduces a form of randomized exploration. While it doesn't directly offer a closed-form expression for runtime complexity improvement, it can be analyzed in terms of expected runtime. If a single run with $p_{\\text{samp}} = 1$ has runtime $T_1$ and a run with $p_{\\text{samp}} = 0$ has runtime $T_0$, then the expected runtime over $n$ runs, with $n/2$ runs each, is $(n/2)T_1 + (n/2)T_0$. The convergence guarantee depends on the specific algorithm; without knowing the algorithm it is not possible to give a specific convergence condition. However, such a strategy could potentially help to escape local optima, but without further information about the optimization method, no theoretical bound can be given.",
      "chunk_id": 8067,
      "paper_id": "An EDA for the 2D knapsack problem with guillotine constraint",
      "paper_title": "An EDA for the 2D knapsack problem with guillotine constraint",
      "paper_year": "2019",
      "chunk_content": "Because the best $p_{\\text {samp }}$ probability depends on the instances we decided to use both $p_{\\text {samp }}=1$ and $p_{\\text {samp }}=0$. During the test the algorithm ran 10 times on each test instance. We modified to use of the $p_{\\text {samp }}$ parameter during the 10 runs the following way: $p_{\\text {samp }}=1$ in 5 runs and $p_{\\text {samp }}=0$ in 5 runs.  \nFor the time limit we found different values in the papers: the method of Wei and Lim (2015) allowed duration of 120 CPU seconds for each test problem (except the gcut13 from set2, where the time limit was 365 s ), but the other methods (e.g. Bortfeldt and Winter 2009) did not give a time limit. We allowed duration of 300 CPU seconds for each test problem.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "topics": [
        "algorithm"
      ],
      "generated_at": "2025-06-07 21:24:26",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantages does the Univariate Marginal Distribution Algorithm (UMDA) have over genetic algorithms in terms of computational performance?",
      "answer": "The UMDA algorithm exhibits better performance than genetic algorithms regarding speed, memory consumption, and accuracy of solutions. UMDA also explores unknown parts of the search space more effectively through probability vector sampling.",
      "chunk_id": 11759,
      "paper_id": "Univariate Marginal Distribution Algorithm in Combination with Extremal Optimization (EO",
      "paper_title": "Univariate Marginal Distribution Algorithm in Combination with Extremal Optimization (EO, GEO)",
      "paper_year": "2011",
      "chunk_content": "Mitra Hashemi ${ }^{1}$ and Mohammad Reza Meybodi ${ }^{2}$${ }^{1}$ Department of Computer Engineering and Information Technology, Islamic Azad University Qazvin Branch, Qazvin, IranMitra.hash@yahoo.com${ }^{2}$ Department of Computer Engineering and Information Technology, Amirkabir University of Technology, Tehran, Iranmmeybodi@aut.ac.ir\nThe UMDA algorithm is a type of Estimation of Distribution Algorithms. This algorithm has better performance compared to others such as genetic algorithm in terms of speed, memory consumption and accuracy of solutions. It can explore unknown parts of search space well. It uses a probability vector and individuals of the population are created through the sampling. Furthermore, EO algorithm is suitable for local search of near global best solution in search space, and it dose not stuck in local optimum. Hence, combining these two algorithms is able to create interaction between two fundamental concepts in evolutionary algorithms, exploration and exploitation, and achieve better results of this paper represent the performance of the proposed algorithm on two NP-hard problems, multi processor scheduling problem and graph bi-partitioning problem.  \nKeywords: Univariate Marginal Distribution Algorithm, Extremal Optimization, Generalized Extremal Optimization, Estimation of Distribution Algorithm.",
      "question_type": "advantage",
      "complexity": "basic",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:24:29",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What data structures are required to implement the best elitism replacement strategy within Estimation of Distribution Algorithms (EDAs) for protein side chain configuration, and how does the homogeneity check influence the algorithm's termination?",
      "answer": "To implement the best elitism replacement strategy, you'll need data structures such as arrays or lists to store the population at generation t and t+1, along with their corresponding fitness values. A priority queue or sorted list can efficiently maintain the best individuals found so far. The homogeneity check, which terminates the algorithm if no more than 10 different individuals are present in the selected population, requires a data structure like a set or hash table to efficiently track unique individuals and their counts. This check ensures the algorithm stops when the population converges, preventing unnecessary computations after the search space has been sufficiently explored, even if the maximum number of generations (500) has not been reached.",
      "chunk_id": 5663,
      "paper_id": "Adding Probabilistic Dependencies to the Search of Protein Side Chain Configurations Using EDAs",
      "paper_title": "Adding Probabilistic Dependencies to the Search of Protein Side Chain Configurations Using EDAs",
      "paper_year": "2008",
      "chunk_content": "To test our algorithms, we started with a protein dataset of 493 X-ray crystal structures ${ }^{2}$ with a resolution better than or equal to $2 \\AA$, an $R$ factor below $20 \\%$, and a mutual sequence identity lower than $50 \\%$. Each protein consisted of 1-4 chains and up to 1000 residues. As a pre-processing step, we determined the instances in which the Goldstein criterion [5] eliminated all configurations but one, and those instances in which the inference-based algorithm for structure prediction (SPRINT) 23] converged.  \nSPRINT is one of the state-of-the-art algorithms for protein side chain placement. In 23], the energies obtained by SCWRL 36] (version 2.9) were reported to be strictly higher than those found by SPRINT in the small class of instances. Unfortunately, the SCWRL (version 3.0) implementation does not provide the energy values corresponding to solutions calculated by the algorithm. Proteins that were solved using the Goldstein criterion and those for which SPRINT converged were removed from the original database. The number of the remaining instances, which were used for our experiments, was 50 . They serve as an appropriate testbed to focus the investigation of EDAs on a representative set of difficult instances were other efficient algorithms have failed.\nTo work, EDAs require the definition of several parameters. We have used the same settings for all instances of the problems treated. The quality of the results achieved by the algorithms will depend on these settings. Since, in this paper, we focus on the role played by dependencies, no attempt has been made to tune the parameters to achieve an optimal performance. The parameters of the EDAs have been set as follows. The population size was set at 5000 . The maximum number of generations is 500 . Truncation selection with parameter $T=0.15$ has been used. In this selection scheme, the best $T \\cdot N$ individuals of the population are selected to construct the probabilistic model. By setting a rather low value of truncation, a strong selection pressure is induced, forcing the algorithm to discard poor solutions as a faster pace.  \nWe apply a replacement strategy called best elitism in which the selected population at generation $t$ is incorporated into the population of generation $t+1$, keeping the best individuals found so far and avoiding to revaluate their fitness function. The algorithm stops when the maximum number of generations  \n[^0]\n[^0]:    ${ }^{2}$ These instances have been obtained from Chen Yanover's page: http://www.cs.huji.ac.il/ cheny/proteinsMRF.html  \nis reached or the selected population has become too homogeneous (no more than 10 different individuals).  \nEDAs incorporate an additional problem reduction step to decrease the number of variables and their number of values. This step starts from the application of a dead-end elimination step [5], based on the iterative use of the Goldstein elimination criterion, which establishes a sufficient condition for rotamer configuration FORMULA_52 to be absent from the optimal solution. When no condition that further eliminates rotamers can be established, the algorithm stops. This step considerably contributes to reduce the dimension of the search space, but the search space remains huge.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "topics": [
        "selection"
      ],
      "generated_at": "2025-06-07 21:24:32",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measures quantify the performance of a Mixture of Factor Analyzers (MFA) when estimating the distribution of candidate solutions in continuous optimization problems, specifically focusing on the accuracy of parameter estimation during the EM algorithm?",
      "answer": "The performance of an MFA can be quantified by examining the convergence and stability of its parameter estimates, $\\left\\{\\left(\\boldsymbol{\\mu}_{j}, \\boldsymbol{\\Lambda}_{j}, \\pi_{j}\\right)_{j=1}^{M}, \\boldsymbol{\\Psi}\\right\\}$, obtained through the EM algorithm. Key measures include monitoring the change in the complete data log-likelihood, $L_{c}=\\sum_{i=1}^{N} \\sum_{j=1}^{M} d_{i j} \\ln \\left\\{\\pi_{j} p\\left(\\mathbf{x}_{i}, \\mathbf{z}_{i j}\\right)\\right\\}$, across iterations. Additionally, evaluating the accuracy of estimating the probabilities $h_{i j}$ (the probability with which component $j$ generates data point $i$) and the expected values of latent variables, $E\\left\\{\\mathbf{z}_{i j} \\mid \\mathbf{x}_{i}\\right\\} = \\boldsymbol{\\beta}_{j}\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right)$ and $E\\left\\{\\mathbf{z}_{i j} \\mathbf{z}_{i j}^{\\mathrm{T}} \\mid \\mathbf{x}_{i}\\right\\} = \\mathbf{I}-\\boldsymbol{\\beta}_{j} \\boldsymbol{\\Lambda}_{j}+\\boldsymbol{\\beta}_{j}\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right)\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right)^{\\mathrm{T}} \\boldsymbol{\\beta}_{j}^{\\mathrm{T}}$, provides insights into the model's ability to capture the underlying data structure. Assessing the stability of the re-estimated parameters, such as $\\pi_{j}^{\\text {new }} = \\frac{1}{N} \\sum_{i=1}^{N} h_{i j}$, $\\tilde{\\mathbf{A}}_{j}^{\\text {new }} = \\left[\\sum_{i=1}^{N} h_{i j} \\mathbf{x}_{i} E\\left\\{\\tilde{\\mathbf{z}}_{i j} \\mid \\mathbf{x}_{i}\\right\\}^{\\mathrm{T}}\\right]\\left[\\sum_{i=1}^{N} h_{i j} E\\left\\{\\tilde{\\mathbf{z}}_{i j} \\tilde{\\mathbf{z}}_{i j}^{\\mathrm{T}} \\mid \\mathbf{x}_{i}\\right\\}\\right]^{-1}$, and $\\boldsymbol{\\Psi}^{\\text {new }} = \\frac{1}{N} \\operatorname{diag}\\left[\\sum_{i=1}^{N} \\sum_{j=1}^{M} h_{i j}\\left(\\mathbf{x}_{i}-\\tilde{\\mathbf{A}}_{j}^{\\text {new }} E\\left\\{\\tilde{\\mathbf{z}}_{i j} \\mid \\mathbf{x}_{i}\\right\\}\\right) \\mathbf{x}_{i}^{\\mathrm{T}}\\right]$, across EM iterations is also crucial. Furthermore, metrics like the Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC) can be used to compare different MFA models with varying numbers of components $M$ to determine the optimal model complexity.",
      "chunk_id": 13174,
      "paper_id": "Evolutionary optimization by distribution estimation with mixtures of factor Analyzers",
      "paper_title": "Evolutionary optimization by distribution estimation with. mixtures of factor Analyzers",
      "paper_year": "2002",
      "chunk_content": "In a mixture of $M$ factor analyzers indexed by $j=$ $1, \\ldots, M$, we consider the following mixture distribution  \n$$\np(\\mathbf{x})=\\sum_{j=1}^{M} \\pi_{j} p(\\mathbf{x} \\mid j)=\\sum_{j=1}^{M} \\int p(\\mathbf{x} \\mid \\mathbf{z}, j) p(\\mathbf{z} \\mid j) p(j) d \\mathbf{z}\n$$  \nwhere $p(\\mathbf{x} \\mid \\mathbf{z}, j)$ is a single factor analyzer model, therefore it can represent the covariance structure in a different part of data space with a Gaussian distribution $\\mathcal{N}\\left(\\Lambda_{j} \\mathbf{z}+\\boldsymbol{\\mu}_{j}, \\boldsymbol{\\Psi}\\right)$ and $\\pi_{j}=p(j)$ is the corresponding mixing proportion which satisfies the constraint $\\sum_{j=1}^{M} \\pi_{j}=$ 1. As in a single factor analysis, the factors are all assumed to be distributed according to $\\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, thus $p(\\mathbf{z} \\mid j)=p(\\mathbf{z})$.  \nWe can estimate the parameters $\\left\\{\\left(\\boldsymbol{\\mu}_{j}, \\boldsymbol{\\Lambda}_{j}, \\pi_{j}\\right)_{j=1}^{M}, \\boldsymbol{\\Psi}\\right\\}$ of a MFA with the EM algorithm similarly to FA. In this case, however, there is another missing information as well as the values of latent variables. That is, we cannot know which model is responsible for generating each data point $\\mathbf{x}_{i}$. By using indicator variable $d_{i j}$ that denotes whether $\\mathbf{x}_{i}$ originates from the component density $j$, the complete data log-likelihood in the EM algorithm for MFA can be formulated as the following form  \n$$\nL_{c}=\\sum_{i=1}^{N} \\sum_{j=1}^{M} d_{i j} \\ln \\left\\{\\pi_{j} p\\left(\\mathbf{x}_{i}, \\mathbf{z}_{i j}\\right)\\right\\}\n$$  \nNow, in the E-step, we compute the expectation of $L_{c}$ with observed data and previous values of the parameters. Then the probability $h_{i j}$ with which the component $j$ generates data point $i$ is calculated as  \n$$\n\\begin{aligned}\nh_{i j} & =E\\left\\{d_{i j} \\mid \\mathbf{x}_{i}\\right\\}=\\frac{\\pi_{j} p\\left(\\mathbf{x}_{i} \\mid j\\right)}{\\sum_{l=1}^{M} \\pi_{l} p\\left(\\mathbf{x}_{i} \\mid l\\right)} \\\\\n& =\\frac{\\pi_{j}\\left|\\mathbf{C}_{j}\\right|^{-1 / 2} \\exp \\left\\{-\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right)^{\\mathrm{T}} \\mathbf{C}_{j}^{-1}\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right) / 2\\right\\}}{\\sum_{l=1}^{M} \\pi_{l}\\left|\\mathbf{C}_{l}\\right|^{-1 / 2} \\exp \\left\\{-\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{l}\\right)^{\\mathrm{T}} \\mathbf{C}_{l}^{-1}\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{l}\\right) / 2\\right\\}}\n\\end{aligned}\n$$  \nwhere $\\mathbf{C}_{j}=\\boldsymbol{\\Psi}+\\boldsymbol{\\Lambda}_{j} \\boldsymbol{\\Lambda}_{j}^{\\mathrm{T}}$. We can also obtain the expected value of latent variables  \n$$\n\\begin{aligned}\nE\\left\\{\\mathbf{z}_{i j} \\mid \\mathbf{x}_{i}\\right\\} & =\\boldsymbol{\\beta}_{j}\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right) \\\\\nE\\left\\{\\mathbf{z}_{i j} \\mathbf{z}_{i j}^{\\mathrm{T}} \\mid \\mathbf{x}_{i}\\right\\} & =\\mathbf{I}-\\boldsymbol{\\beta}_{j} \\boldsymbol{\\Lambda}_{j}+\\boldsymbol{\\beta}_{j}\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right)\\left(\\mathbf{x}_{i}-\\boldsymbol{\\mu}_{j}\\right)^{\\mathrm{T}} \\boldsymbol{\\beta}_{j}^{\\mathrm{T}}\n\\end{aligned}\n$$  \nwhere $\\boldsymbol{\\beta}_{j}=\\boldsymbol{\\Lambda}_{j}^{\\mathrm{T}}\\left(\\boldsymbol{\\Psi}+\\boldsymbol{\\Lambda}_{j} \\boldsymbol{\\Lambda}_{j}^{\\mathrm{T}}\\right)^{-1}$.\nNext, in the M-step, we re-estimate the values of parameters as in the following equations  \n$$\n\\begin{aligned}\n& \\pi_{j}^{\\text {new }}=\\frac{1}{N} \\sum_{i=1}^{N} h_{i j} \\\\\n& \\tilde{\\mathbf{A}}_{j}^{\\text {new }}=\\left[\\sum_{i=1}^{N} h_{i j} \\mathbf{x}_{i} E\\left\\{\\tilde{\\mathbf{z}}_{i j} \\mid \\mathbf{x}_{i}\\right\\}^{\\mathrm{T}}\\right]\\left[\\sum_{i=1}^{N} h_{i j} E\\left\\{\\tilde{\\mathbf{z}}_{i j} \\tilde{\\mathbf{z}}_{i j}^{\\mathrm{T}} \\mid \\mathbf{x}_{i}\\right\\}\\right]^{-1} \\\\\n& \\boldsymbol{\\Psi}^{\\text {new }}=\\frac{1}{N} \\operatorname{diag}\\left[\\sum_{i=1}^{N} \\sum_{j=1}^{M} h_{i j}\\left(\\mathbf{x}_{i}-\\tilde{\\mathbf{A}}_{j}^{\\text {new }} E\\left\\{\\tilde{\\mathbf{z}}_{i j} \\mid \\mathbf{x}_{i}\\right\\}\\right) \\mathbf{x}_{i}^{\\mathrm{T}}\\right]\n\\end{aligned}\n$$  \nwhere $\\tilde{\\mathbf{z}}_{i j}=\\left[\\begin{array}{ll}\\mathbf{z}_{i j} & 1\\end{array}\\right]^{\\mathrm{T}}$ is an augmented column vector of factors and FORMULA_75 is a new augmented factor loading matrix. In order to find more detailed derivations of above equations, see [13].\nIn the continuous optimization problems, candidate solutions are usually represented as real vectors. Most evolutionary algorithms for this problems maintain the population of these vectors to search for the optimal point. In this section, we describe how MFAs are applied to estimate the distribution of current population and to generate new offspring from the estimated distribution.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:24:37",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of parallel Bayesian Optimization Algorithm (pBOA) ensure acyclicity when adding edges in parallel, and what is the theoretical basis for using a random permutation to compensate for forced independence?",
      "answer": "The parallel BOA implementation uses a predetermined topological ordering of nodes to ensure acyclicity. At the beginning of each generation, a random permutation of numbers \\{0, 1, ..., n-1\\} is created, where 'n' is the number of variables. An edge from $X_{j}$ to $X_{i}$ is allowed only if $\\operatorname{perm}[j] < \\operatorname{perm}[i]$. The variable $X_{i}$ with $\\operatorname{perm}[i] = 0$ has no predecessor and is forced to be independent. To compensate for this, a new permutation is used for each generation, ensuring that no variable is consistently forced to be independent across generations. The BD metric, which is separable and written as a product of 'n' factors, guides the edge addition process based on the influence of edges ending in variable $X_{i}$.",
      "chunk_id": 6591,
      "paper_id": "Theoretical and Empirical Analysis of a GPU Based Parallel Bayesian Optimization Algorithm",
      "paper_title": "Theoretical and Empirical Analysis of a GPU based Parallel Bayesian Optimization Algorithm",
      "paper_year": "2009",
      "chunk_content": "Although BOA can be parallelized in different ways, we will discuss a widely used parallel implementation proposed by Jiri et al. [8]. As $95 \\%$ of the overall execution time of BOA goes into the calculation of BD metrics and BN construction, therefore, we will concentrate only on the parallelization of the BN construction step of BOA. Jiri et al. [8] suggest that BD metric is separable and can be written as a product of $n$ factors, where the $i^{\\text {th }}$ factor expresses the influence of edges ending in the variable $X_{i}$. It is possible to use up to $n$ processors, each processor corresponds to one variable and it examines only edges leading to this variable (it has its own local copy of parent population). As the addition of edges is parallel, so an additional mechanism is required to keep the network acyclic. Jiri et al. propose to predetermine the topological ordering of nodes in advance. At the beginning of each generation, the random permutation of numbers $\\{0,1, \\ldots, n-1\\}$ is created. Each processor generates the same permutation. The direction of all edges in the network should be consistent with the ordering, so the addition of an edge from $X_{j}$ to $X_{i}$ is allowed only if $\\operatorname{perm}[j]<\\operatorname{perm}[i]$. The variable $X_{i}$ with $\\operatorname{perm}[i]=0$ has no predecessor and is forced to be independent. To compensate this phenomenon a new permutation needs to be used for each generation. The algorithm for parallel computation of BD is given in Fig. 4.\nJiri et al. [8] and other pBOA algorithms in literature were designed either for clusters or shared memory multicore processors. GPU, on the other hand, is a completely different environment, and therefore, using a conventional pBOA algorithm over a GPU will seriously underutilize the resources. An algorithm designed for such an environment must be able to exploit the memory hierarchy and SIMD/SIMT features of a  \nGPU. To the best of author's knowledge, there is no significant research done for implementation of BOA over commodity GPUs.  \nA simple implementation of pBOA would assign BD metric calculation of the $i^{\\text {th }}$ variable to the FORMULA_24 thread of the GPU. Therefore, the total number of threads will be equal to the total number of variables. Although this may work for the shared memory multicore architectures, but in case of GPUs this implementation will not be able to use coalesced reads from global memory of the device and therefore will create some serious memory bottle-necks. Moreover, it will not be able to use the SIMD features of GPU as each thread in a warp will follow a unique instruction path. Also the temporary memory required by each thread will not fit in the shared memory of the thread block and this will further reduce the performance.",
      "question_type": "theory",
      "complexity": "basic",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:24:40",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "Under what mathematical conditions does the iterative process of updating individual positions in Particle Swarm Optimization, specifically using only position updates without velocity considerations, guarantee convergence to a global optimum when integrated into the selection step of an Estimation of Distribution Algorithm?",
      "answer": "The convergence of the hybrid algorithm, combining Particle Swarm Optimization (PSO) for selection within an Estimation of Distribution Algorithm (EDA), hinges on the properties of the normal distribution model established using the mean \\(\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\) and variance \\(\\hat{\\sigma} = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}}\\).  Specifically, if the sequence of \\(gbest(i)\\) values converges to a fixed point as \\(k \\rightarrow \\infty\\), and the sampling process \\(x = \\mu + \\sigma\\left(-2 \\ln u_{1}\\right)^{1 / 2} \\cos 2 \\pi u_{2}\\) maintains sufficient exploration, then convergence is probable.  However, without velocity updates in the PSO component, the algorithm's ability to escape local optima depends critically on the variance \\(\\hat{\\sigma}\\) of the normal distribution; a vanishing variance may lead to premature convergence.  A rigorous proof would require bounding the rate at which \\(\\hat{\\sigma}\\) decreases and demonstrating that the sampling process retains ergodicity despite the lack of velocity-driven exploration.",
      "chunk_id": 11233,
      "paper_id": "A new Algorithm based on the Gbest of Particle Swarm Optimization algorithm to improve Estimation of Distribution Algorithm",
      "paper_title": "A new Algorithm based on the Gbest of Particle Swarm Optimization algorithm to improve Estimation of Distribution Algorithm",
      "paper_year": "2018",
      "chunk_content": "This paper mainly introduces an improved estimation of distribution algorithm. The main idea of this algorithm is to apply particle swarm optimization in the \"selection\" operation of the estimation of distribution algorithm. Different from the parallel hybrid evolutionary algorithm of PSO and EDA[18] introduced in paper [18], this paper introduces the optimization of the population of each iteration through the location update of each iteration of PSO, The optimal individuals of generation are selected as the objects of the estimation of distribution algorithm. The optimal population of individuals generated by each iteration can quickly locate the optimal solution range, so as to speed up the optimization and improve the convergence of the algorithm. Particle swarm optimization (PSO) is to optimize the \"micro\" level of the optimal solution by updating the position and velocity of each individual in the  \npopulation. The estimation of distribution algorithm is based on the probability model and random sampling of the evolutionary trend of the entire population. The \"macro\"level describes the optimization algorithm. Through the effective combination of the two algorithms, not only the numerical accuracy at the microscopic level can be guaranteed, but also the convergence at the macroscopic level can be realized quickly, and the optimization of the distribution estimation algorithm can be realized. Particle swarm optimization algorithm in the selection of outstanding groups in the process, this article only to update the location of the individual, do not take the velocity update into account. Specific steps are as follows:  \nStep 1 Initialize the population and randomly generates N individuals ( $\\mathrm{i}=1,2 \\ldots \\mathrm{~N}$ ) In the range of $[-1,1]$;  \nStep 2 Calculate the fitness of the population, find the optimal individual optimal pbest and optimal population gbest using formulas (3) and (4), and update the individual's position with formula (5):  \nStep 3 Iterate k times $(\\mathrm{k}<\\mathrm{T})$ and saves gbest (i), $(\\mathrm{i}=$ $1,2, \\ldots, \\mathrm{k})$.  \nStep 4 Establish the normal distribution model by calculating the mean $\\mathrm{E}(\\mathrm{x})=$ and the variance $\\mathrm{D}(\\mathrm{x})=$ of k excellent individuals through formula (6)and formula(7).  \n$$\n\\begin{gathered}\n\\hat{\\mu}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\\\\n\\hat{\\sigma}=\\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}}\n\\end{gathered}\n$$  \nStep 5 Use formula (8) to randomly sample from the constructed normal distribution to generate a new population.  \n$$\nx=\\mu+\\sigma\\left(-2 \\ln u_{1}\\right)^{1 / 2} \\cos 2 \\pi u_{2}\n$$  \nStep 6 If the algorithm reaches the termination condition, end it, otherwise, return to Step2.  \nThe pseudo code is as follows:\n$\\mathrm{T}=0$;\nFor $\\mathrm{I}=1$ to N\nInitialize $\\mathrm{X}_{\\mathrm{i}}(\\mathrm{t})$ and $\\mathrm{V}_{\\mathrm{i}}(\\mathrm{t})$;\nInitialize pbest and g best;\nFOR $i=1$ to K\nSelect gbest(i), (i=1,2,...k)\nEND FOR  \nFORMULA_28  \nEND FOR\nIf meet the condition\nEND IF",
      "question_type": "evaluation",
      "complexity": "advanced",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:26:50",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What convergence guarantees exist for the EA/G algorithm when hybridized with Genetic Algorithms (GAs) to form EA/G-GA, and how does this hybridization theoretically impact the algorithm's ability to escape local optima compared to Adaptive EA/G, considering the role of population diversity?",
      "answer": "While specific convergence rates are not explicitly provided, the hybridization of EA/G with GAs aims to improve population diversity, which is theorized to enhance the ability to escape local optima. The EA/G-GA leverages genetic operators to generate more diversified chromosomes, contrasting with Adaptive EA/G, which primarily adjusts parameters. This increased diversity is hypothesized to lead to better performance across various stopping criteria by preventing premature convergence, a known limitation of EDAs like EA/G when used in isolation. The theoretical implication is that the meta-heuristic component contributes to a broader exploration of the search space, mitigating the risk of being trapped in suboptimal solutions, although a formal proof of convergence rate improvement is not given.",
      "chunk_id": 11889,
      "paper_id": "EA:G-GA for Single Machine Scheduling Problems with Earliness:Tardiness Costs",
      "paper_title": "EA/G-GA for Single Machine Scheduling Problems with Earliness/Tardiness Costs",
      "paper_year": "2011",
      "chunk_content": "The result indicates that both the performances of EA/G-GA and Adaptive EA/G are better than those of ACGA and EA/G on a majority of stopping criteria because the former algorithms maintain better population diversity than the latter ones. Therefore, all algorithms outperform the original EA/G at the end of generations. In addition, the research outcome also demonstrates that EA/G-GA is significantly better than Adaptive EA/G because the genetic operators might produce more diversified chromosomes than the algorithms that merely change the parameters. The implication shows the greater the diversity of an algorithm, the better it can achieve performance, which is an important direction for researchers to conduct further studies.  \nFigure 3. Average Objective values under different stopping criteria.\n[IMAGE2]  \nTwo figures provided below support the evidence of the performance representation and they can display performance changes graphically. For example, in terms of the average objective value plot (See Figure 3), EA/G-GA performs well by all stopping criteria while the ACGA is greatly improved  \nwhen we employ more examined solutions. The convergence plot (See Figure 4) depicts that EA/G converges very fast before 150 generations. Other algorithms, nonetheless, gradually enhance the solution quality through the evolutionary progress. Thus, EA/G does not outperform either the EA/G-GA or Adaptive EA/G.  \nFigure 4. Compare the convergency of Adaptive EA/G and EA/G-SGA with other algorithms.\n[IMAGE3]\nThe feature of EDAs is to characterize the search space and then to sample new solutions from the probabilistic models. This feature has the benefit of not disrupting good gene structures; however, it causes the premature convergency of EDAs so that EDAs no longer generate diversified solutions. Even when we spend more computational efforts, EDAs can not improve the solution quality as indicated by our prior research [1]. Consequently, this paper utilizes an important guideline in [1], which hybridizes the EDAs with other meta-heuristics techniques. The advantage of the hybrid framework is to let EDAs gain more population diversity via the meta-heuristic. We use one of the famous EDAs, EA/G, to cooperate with GAs. The proposed algorithm is named \"EA/G-GA\", which is used to solve the NP-Hard single machine scheduling problems.  \nThrough the extensive experiments, we have compared EA/G-GA with some algorithms such as the ACGA, Adaptive EA/G, and EA/G described in other literature. In terms of statistical significance, EA/G-GA is found to have better performance than other algorithms by different stopping criteria. The results indicate that the EA/G-GA is not only superior to other algorithms but also proves to be a robust algorithm when different stopping criteria are applied (i.e., various CPU times). When we compare the differences between the EA/G-GA and Adaptive EA/G, the former algorithm is much more powerful than the latter one. It is meaningful that meta-heuristics provide more diversified solutions than we just change the parameters of an algorithm, which is a very important implication for EDAs researchers.  \nConsequently, researchers could incorporate EDAs with other meta-heuristics in solving hard problems if they want to increase the population diversity to obtain better solution quality.  \nFinally, although we decide to alternate the EA/G with GAs in this research, there is no limitation on the selection of algorithms. For the future research, researchers may test different EDAs and meta-heuristics to solve various problems.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "topics": [
        "genetic"
      ],
      "generated_at": "2025-06-07 21:26:53",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs exist between Estimation of Distribution Algorithms (EDAs) and Genetic Algorithms (GAs) in the context of the HP protein folding model?",
      "answer": "EDAs, unlike GAs, construct an explicit probability model, \\(p(\\mathbf{x})\\), of selected solutions to capture probabilistic dependencies among problem variables. This model factorizes as \\(p(x_{1}, \\ldots, x_{k+1}) \\prod_{i=k+2}^{n} p(x_{i} | x_{i-1}, x_{i-2}, \\ldots, x_{i-k})\\), where \\(k\\) is a parameter determining dependency on previous variables. While this allows EDAs to generate new solutions based on learned dependencies, it introduces the computational overhead of estimating and maintaining the joint probability distribution, a step not present in GAs.",
      "chunk_id": 13243,
      "paper_id": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_title": "Protein folding in 2-dimensional lattices with estimation of distribution algorithms",
      "paper_year": "2004",
      "chunk_content": "We study the suitability of EDAs as a non-deterministic search procedure for the HP model. A main difference between EDAs and GAs is that the former constructs an explicit probability model of the solutions selected. This model can capture, by means of probabilistic dependencies, relevant interactions among the variables of the problem. The model can be conveniently used to generate new promising solutions. The main scheme of the EDA approach is shown in algorithm 1. Although the introduction of EDAs is relatively new, there already exists a number of succesful applications of EDAs in computational biology [2, 18 .  \nEDAs differ in the type of models that they use and the corresponding factorizations of the probability that these models determine. For the protein folding problem, we define a probability model that assumes that proteins adjacent in the sequence are related in their lattice positions. The probability model then encodes the dependencies between the move of a residue and the moves of the previous residues in the sequence. This information is used in the generation of solutions.  \nLet $p(\\mathbf{x})$ be the probability distribution of random variable $\\mathbf{X}$. Our probability model considers that the configuration of variable $X_{i}$ depends on the configuration of the previous $k$ variables, where $k \\geq 0$ is a parameter of the model. $p(\\mathbf{x})$ can be factorized as follows:  \n$$\np(\\mathbf{x})=p\\left(x_{1}, \\ldots, x_{k+1}\\right) \\prod_{i=k+2}^{n} p\\left(x_{i} \\mid x_{i-1}, x_{i-2}, \\ldots, x_{i-k}\\right)\n$$  \nThe learning phase of our EDA will only comprise a parametric learning of the parameters in contrast to some state-of-the-art EDAs that make structural  \n```\nAlgorithm 1: Main scheme of the EDA approach\n\\(1 \\quad D{0} \\leftarrow\\) Generate \\(M\\) individuals (the initial population) randomly\n\\(2 l=1\\)\ndo \\(\\{\\)\n\\(D{l-1}^{s} \\leftarrow\\) Select \\(N \\leq M\\) individuals from \\(D{l-1}\\) according to a selection method\n\\(p{l}(\\boldsymbol{x})=p\\left(\\boldsymbol{x} \\mid D{l-1}^{s}\\right) \\leftarrow\\) Estimate the joint probability of selected individuals\n\\(D{l} \\leftarrow\\) Sample \\(M\\) individuals (the new population) from \\(p{l}(\\boldsymbol{x})\\)\n\\} until A stop criterion is met",
      "question_type": "relationship",
      "complexity": "basic",
      "topics": [
        "selection"
      ],
      "generated_at": "2025-06-07 21:26:55",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the algorithmic steps for calculating the fitness of a candidate solution in the Hierarchical TRAP (HTRAP) function, and how does the penalizing factor, K, impact the fitness calculation in the knapsack problem?",
      "answer": "For HTRAP, the algorithmic steps involve traversing a k-ary tree where k >= 3. Each group of k children is evaluated: if all are 0, the interpretation is 0; if all are 1, it's 1; otherwise, it's a null symbol. A trap function, trap(x), is applied at each node (except leaves), returning a value between 0 and 1. This function uses parameters f_high and f_low, which are set to bias the optimum. The contribution of traps at each level i is multiplied by k^i. In the knapsack problem, if a configuration exceeds the capacity, a penalizing factor, K, is applied, where K = min(wi) / ((sum(wi) - capacity)), and wi represents the weight of the i-th element in the bag. This K factor reduces the fitness of solutions exceeding capacity.",
      "chunk_id": 6583,
      "paper_id": "Avoiding premature convergence in estimation of distribution algorithms",
      "paper_title": "Avoiding premature convergence in Estimation of Distribution Algorithms",
      "paper_year": "2009",
      "chunk_content": "We also use the known knapsack problem, in which we have a bag with a limited capacity and the goal is to put into it as many objects as possible which give us the maximum benefit but without going beyond the bag limit. We have selected the software developed by David Pisinger [18] which generates instances of this problem. Specifically we consider a instance with 64 elements whose values for weight and utility are in the rage $0-100$ and they are not correlated. The total capacity of the bag is 101 . We use a penalizing factor, $K$, in the case a configuration exceed the maximum capacity which multiply its fitness:  \n$$\nK=\\frac{\\min \\left(w_{i}\\right)}{\\left(\\left(\\sum_{i=0}^{i=n} w_{i}\\right)-\\text { capacity }\\right)}\n$$  \nwhere $w_{i}$ is the weight of the $i$ element in the bag.\nThis function (Hierarchical TRAP) [7] is also hierarchical like HIFF. In this case, the structure is a balanced $k$-ary tree instead of a binary tree, where $k \\geq 3$, so the input string is of size $k^{l}$. Every group of $k$ children is interpreted in a similar way as in HIFF function: if they all are 0 the interpretation is 0 , if all are 1 the interpretation is 1 , and the null symbol otherwise. In the implementation used here the leaves do not contribute to the global fitness. The contribution to the fitness for every group is measure by a version of the TRAP function whose difference is that return values in the range $[0,1]:$  \n$$\n\\operatorname{trap}(\\mathbf{x})= \\begin{cases}f_{\\text {high }} & \\text { if } u=k \\\\ f_{\\text {low }} \\cdot \\frac{k-1-u}{k-1} & \\text { otherwise }\\end{cases}\n$$  \nIf in the input of this function there is a null symbol it returns 0 whatever were the other values. For all nodes $x$ but the root the trap function is applied with $f_{\\text {high }}=1$ and $f_{\\text {low }}=$ $1+0.1 / l$, which biases the optimum to a string with $k 0$ 's. For the root node, $f_{\\text {high }}=1$ and $f_{\\text {low }}=0.9$, which biases the optimum to a string full of 1 's. Thus the global optima is the string with all bits equal to 1 , while the local optima is the string with all bits to 0 .  \nTo make to overall contribution at each level of the same magnitude, the contributions of traps on the $i-t h$ level from the bottom up to the root are multiplied by $k^{i}$.\n$\\square$\nFor all functions we have chosen a configuration in order to have a problem representation with strings of 64 bits. Therefore, for HIFF function we have set the number of levels to $l=$ and for HTRAP function the trap size is $k=4$ and the number of levels $l=3$.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "topics": [
        "representation"
      ],
      "generated_at": "2025-06-07 21:26:58",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measures quantify the performance of GHEA compared to EA/G, ACO, and multi-start Hopfield algorithms on DIMACS benchmark problems, and how are differences in execution time and solution quality assessed?",
      "answer": "The performance of GHEA is quantified by the average maximum clique found with the corresponding standard error, overall maximum clique size, and average execution time over 30 runs. Statistical superiority is assessed by comparing these measures to those of EA/G, ACO, and multi-start Hopfield algorithms on DIMACS benchmark instances such as C500.9, C1000.9, and MANNa45. For example, the standard error for GHEA on large instances C1000.9 and MANNa45 is compared to that of EG/A, with improvements of approximately 14% and 45% respectively indicating better stability. Execution time differences are also considered, accounting for hardware differences by summarizing EA/G execution time in the same experimental environment.",
      "chunk_id": 1230,
      "paper_id": "A guided Hopfield evolutionary algorithm with local search for maximum clique problem",
      "paper_title": "A Guided Hopfield Evolutionary Algorithm with Local Search for Maximum Clique Problem",
      "paper_year": "2014",
      "chunk_content": "In this section, we study GHEA experimentally and compare it with EA/G, the state-of-the-art algorithm in evolutionary field, on the DIMACS benchmark problems. We also compare the performance of GHEA with ant colony optimization (ACO) algorithm and multi-start Hopfield algorithm on these test problems. Our experiments were compiled by Matlab and were executed on an Intel 2.5 GHz machine with 4 GB RAM. In order to make comparison impartially, hardware differences are taken into account. We realized EA/G algorithm by ourselves, and summarized its execution time in our experimental environment. The clique sizes found by EA/G are adopted as same as the values in [3].  \nTo discuss effect of different parameters and settings in GHEA, we compared the results obtained by differential instances of GHEA. On solving MCP C500.9 instance, we built different test versions of GHEA through modifying individual parameter in every running time. Fig. 2 shows the comparison results on the clique size gotten by different instances of  \nTABLE I. Comparison Among multi-start Hopfield, EA/G, ACO, and GHEA for SPECIFIC MCP instances.  \nGHEA. Fig. 2 indicates that GHEA is not seriously sensitive to those parameters. Every GHEA instance can find good solutions, and the only difference is the consuming time. In detail, from Fig. 2, it is illustrated that GHEA with formal settings has the best execution on the aspect of average clique size in one running process. Although GHEA v3 can get better cliques earlier, its stability is too poor to search more valuable solutions in the following epochs. Other algorithms instances also have their visible drawbacks in the process. Therefore, in our simulations the parameters in GHEA v1 were adopted. In the simulation, the parameters of GHEA with formal settings are set as follows: $\\Delta=1, p_{v}=0.6, \\beta=0.5, \\mu=0.5$.  \nIn simulations, different type of MCP instances are tested to reveal GHEA performance. The set of algorithm column reports the average maximum clique found(with the corresponding standard error), the overall maximum and the average execution time for 30 runs or the reference time of original literature. Some data with bold face mean the best results found in our experiments. The results show that GHEA has a significant superiority to EG/A in the aspect of average size and standard error. In the case of dense random graph C500.9, GHEA ever found a better clique with 57 nodes. And for large instances C1000.9 and MANNa45, the standard error is about $14 \\%$ and $45 \\%$ better than EG/A. For the small instances, EG/A, GHEA and ACO can always locate the maximum clique. The multi-start Hopfield deployed just with random initial positions gained the worst results among four algorithms. It illustrates the probability model and local search strategy guided the evolutionary procedure to provide appropriate initial inputs for Hopfield net in GHEA. The probability model of EDA produces prohibition effect to restrain GHEA from searching the areas already searched. Local search strategies can help more effectively determine the position of a new starting point for Hopfield net in GHEA. The multi-start Hopfield lacks the two parts, therefore its performance is worse. In a word, our algorithm has superior performance in the experiments and shows the guided searching capability of local search strategy.",
      "question_type": "comparison",
      "complexity": "advanced",
      "topics": [
        "optimization",
        "evaluation metrics"
      ],
      "generated_at": "2025-06-07 21:27:01",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of the modified Univariate Marginal Distribution Algorithm (UMDA) differ from that of a Genetic Algorithm (GA) in the context of the 3D Bin Packing Problem, specifically regarding population generation?",
      "answer": "The modified UMDA generates a new population by estimating the distribution of promising solutions, while a GA uses crossover and mutation. In this case, the GA applies a crossover method and then mutation with probability $pm$ to arrays representing bin assignments and rotations. The UMDA, by contrast, directly models the distribution of these assignments. Both algorithms maintain a population size $P$, but the GA directly adds $E$ best individuals to the next generation, a strategy not explicitly detailed for the modified UMDA.",
      "chunk_id": 136,
      "paper_id": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_title": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_year": "2013",
      "chunk_content": "In the following experimental study, we compared our algorithm with a GA approach and the CPLEX solver. The GA approach uses the same representation  \nstrategy with our EDA and employs the crossover method mentioned in 6. After the crossover is done, we conduct mutation operation to the number sequences. For every number in array $\\{$ bin $\\}$ and $\\{$ rotation $\\}$, it is switched position with another randomly selected number with probability $p m$. For every number in array \\{rotation\\}, it is changed to its another possible value with probability pm. Each population contains $P$ individuals. Before generating the next population, $E$ best individuals are directly added to the next population. In the experiment, the parameters for GA and modified UMDA are set as: $p m=0.01, P=100, E=10$, gen $=100$. The meaning of $p m, P, E$ is in the above algorithm description. gen stands for generation which we repeat gen times of generating new population until we stop. The instances we use are from a transportation company. Each instance is tested for 10 times. The data shown in the Table 1 is the space utilization rate, which is calculated by space $_{\\text {items }} /\\left(\\right.$ space $_{\\text {items }}+$ space FORMULA_144 ). A larger value of the rate indicates a better quality of the solution. The time limit we set for CPLEX is 1800 seconds. If CPLEX failed to get a solution in 1800 seconds, we use a \"-\" to denote it.  \nTable 1. Comparison of space utilization percentage among three approaches  \nFrom the experimental data, the following observations can be concluded: (1) For small instances with 12 items, CPLEX and GA are very likely to solve to optimal; modified UMDA can achieve optimal solution but its performance is not very stable. (2) For medium instances with 20 items, CPLEX can not find a good solution in 1800s. Both GA and modified UMDA can find a good solution. GA has a better \"average solution\" and modified UMDA has a better \"best solution\". (3) For large instances with 50 or 78 items, CPLEX failed to find a solution. Both GA and modified UMDA are able to find a solution. Modified UMDA has a better \"average solution\" and \"best solution\".  \nFrom the observations, it can be seen that the modified UMDA is a good choice for large instances. For small and medium instances, although the modified UMDA do not perform very stable, we can still get a solution better than or at least as good as GA and CPLEX by repeating the algorithm on the same instance for several times and pick out the best solution.\nIn this paper, bin packing problems with various bin sizes are investigated. The mathematical formulation and an estimation of distribution algorithm for the problem are proposed and experimentally studied. In the proposed algorithm, a packing method for multi bins is used for representation and a modified univariate marginal distribution algorithm is used for generating new population. The experiment results show that our proposed method seems to be a good optimizer for 3DBPP with various bin sizes, especially for a large instance with 50 or more items to pack.",
      "question_type": "process",
      "complexity": "basic",
      "topics": [
        "comparison"
      ],
      "generated_at": "2025-06-07 21:27:04",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "How should practitioners implement an adaptive Global Estimation of Distribution Algorithm (GEDA) to mitigate premature convergence, specifically concerning the covariance matrix?",
      "answer": "To implement an adaptive GEDA and prevent rapid variance reduction, adjust the covariance matrix dynamically based on the number of iterations. Algorithm 1 outlines the process: initialize the population P with size PS, select [PS * sr] elite individuals to form the set D_elite, and then update the mean (μ) and covariance matrix (C) of the population distribution using equations such as Eq. 12 and Eq. 13. This scaling of the covariance matrix in different directions helps the algorithm better capture the optimization problem's structure and avoid local optima.",
      "chunk_id": 3872,
      "paper_id": "An Adaptive Evolutionary Multi-Objective Estimation of Distribution Algorithm and Its Application to Multi-UAV Path Planning",
      "paper_title": "An Adaptive Evolutionary Multi-Objective Estimation of Distribution Algorithm and Its Application to Multi-UAV Path Planning",
      "paper_year": "2023",
      "chunk_content": "Input: population size $P S$, selection ratio $s r$;\n1: Initialize the number of iterations $t=0$, initialize the population $P^{(t)}$;\n2: Record the global optimal solution Gbest;\n3: repeat\n4: Select $[P S \\cdot s r]$ promising individuals from population $P^{(t)}$ to form the elite set $D_{\\text {elite }}^{(t)}$;\n5: Update the mean $\\mu^{(t)}$ and covariance matrix $C^{(t)}$ of the population distribution based on the elite set $D_{\\text {elite }}^{(t)}$ according to Eq.12, Eq.13;\n6: Randomly generate a new population whose population size is $P S$ by sampling from Gaussian distributions according to Eq.14;\n7: Update the global best solution Gbest;\n8: $t=t+1$;\n9: until the stopping criterion is met;\nOutput: the global best solution Gbest.  \nAlgorithm 1.  \nFORMULA_88\nA key problem encountered with most existing GEDA during optimization is the rapid reduction in variance (covariance), which can result in a loss of search diversity and premature convergence to a local optimum solution. To address this issue, this paper proposes an adaptive GEDA that adjusts the covariance matrix according to the number of iterations. This approach not only allows the covariance to be scaled in different directions but also enables the algorithm to better capture the optimization problem's structure.",
      "question_type": "practical application",
      "complexity": "medium",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:27:07",
      "generation_style": "practical_application"
    },
    {
      "question": "What convergence guarantees exist for the UMDA, EBNA, and UEBNA, specifically concerning the rate at which the population concentrates around global optima in multimodal problems, and how does the choice of Bayesian network structure (unrestricted BNs vs. TANB models) theoretically impact this convergence rate?",
      "answer": "The UMDA exhibits slower convergence due to gradual genetic drift, necessitating EDAs that encode conditional dependencies or employ niching. While EBNA and UEBNA achieve comparable effectiveness in locating global optima, UEBNA demonstrates faster convergence. This suggests that TANB models for data clustering, as used in UEBNA, lead to faster convergence compared to the unrestricted BNs used in EBNA. However, unrestricted BNs potentially model more complex conditional dependencies. The trade-off is between the modeling power of unrestricted BNs and the faster convergence offered by TANB models, affecting the efficiency of multimodal optimization.",
      "chunk_id": 13140,
      "paper_id": "Globally Multimodal Problem Optimization Via an Estimation of Distribution Algorithm Based on Unsupervised Learning of Bayesian Networks",
      "paper_title": "Globally multimodal problem optimization via an estimation of distribution algorithm based on unsupervised learning of Bayesian networks",
      "paper_year": "2005",
      "chunk_content": "Fig. 7 shows the dynamics of the UMDA, the EBNA and the UEBNA until convergence in one run for $P_{\\text {twoman } 50}$. The histograms summarize the number of solutions (vertical axis) in the population of different generations whose sum of genes is equal to the value of the horizontal axis. As previously stated, the two global optima of the optimization problem are gene-complementary and correspond to the left-most and right-most sides of the histograms. The histograms show that, as problem optimization progresses, the population drifts to one side in the case of the UMDA and to both sides in the case of the EBNA and the UEBNA. Moreover, the individuals of the population of the last gen-  \n[IMAGE3]  \nFigure 7: Dynamics of the UMDA (top row), the EBNA (middle row), and the UEBNA (bottom row) until convergence in one run for $P_{\\text {twoman50 }}$. The horizontal axis of each histogram represents the sum of the genes of a solution, whereas the vertical axis denotes the number of corresponding solutions in the population of different generations.\neration of the EBNA and the UEBNA are almost equally distributed among both global peaks. It can also be seen in the histograms that genetic drift occurs so slowly that the UMDA takes longer than the other two EDAs to converge. This clearly confirms what has been argued in Section 2.3 about the necessity of considering EDAs based on either encoding of conditional dependencies or niching, or both, for effective and efficient globally multimodal problem optimization. Finally, it should also be mentioned that, although the EBNA and the UEBNA perform equally well in terms of effectiveness, they differ in their efficiency: The UEBNA reaches convergence faster than the EBNA. This suggests that TANB models for data clustering are more appropriate than BNs for modelling the joint probability distribution for the individuals selected at each iteration. Note, however, that the EBNA relies on unrestricted BNs, which can potentially model more complex conditional dependencies than TANB models for data clustering. Therefore, this supports that combining model-based data clustering with the ability to model conditional dependencies is more robust and reliable against genetic drift when incorporated into the EDA framework than the ability to model conditional dependencies alone. As discussed in Section 3, this is the main motivation behind the development of the UEBNA.  \n[IMAGE4]  \nFigure 8: Average fitness of the individuals in the population as a function of the number of generations and until convergence for the UMDA, the EBNA and the UEBNA in one run for $P_{\\text {twoman } 100}$ (left), $P_{\\text {catring } 28}$ (middle) and $P_{\\text {catring } 42}$ (right).  \nFig. 8 provides the reader with additional evidence on the efficiency of the UEBNA for globally multimodal problem optimization. Specifically, the figure plots the average fitness of the individuals in the population as a function of the number of generations and until convergence for the UMDA, the EBNA and the UEBNA in one run for $P_{\\text {twoman } 100}, P_{\\text {catring } 28}$ and FORMULA_231. Note that the first optimization problem presents two global optima, the second four and the third six. These curves clearly show that the UEBNA speeds up converge without degrading the quality of the solutions obtained.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "topics": [
        "convergence"
      ],
      "generated_at": "2025-06-07 21:27:09",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the stochastic Back-to-Origin Markov model estimate the number of infectious nodes compared to estimating the infection probability of each node individually when a preference scanning worm spreads?",
      "answer": "The stochastic Back-to-Origin Markov model estimates the number of infectious nodes at each time step, providing a value for (INF CNT). In contrast, a separate model estimates the infection probability of each node at each time step during the spread of a preference scanning worm.",
      "chunk_id": 7801,
      "paper_id": "A probability distribution function for investigating node infection and removal times",
      "paper_title": "A probability distribution function for investigating node infection and removal times",
      "paper_year": "2019",
      "chunk_content": "The structure of the learned network (Figure 7) indicates the dependency relationships between selected features. Figure 7 exploits the conditional dependence property between Infection variable and Inf Path to j, Inf Statj, DST Port, SRC Port, ACK, and Connection to $j$ features. It is notable that DST Port, SRC Port, Inf Statj, Connection to j, and ACK were directly dependent on Infection. As the infection status of a node changes from susceptible to infected (Infection $=1$ ), the values\n[IMAGE4]  \nFIGURE 7 The worm infection probabilistic model  \nof the aforementioned six features may change (there may be an infection path between nodes $i$ and $j$ and the infection status of node $j$ may change). If there was an infection path between $i$ and $j$, the numbers of the following features could change: SRC Port, $A C K, T C P C N T$ and infection. It could also affect the values of Inf Statj and Connection to j variables. Moreover, TCP/IP header features also had dependency relationships with each other, as in Figure 7.  \nAs mentioned at the beginning of this section, a step-by-step approach was used to estimate the infection status of nodes at each time unit. The stochastic Back-to-Origin Markov model FORMULA_216 estimates the number of infectious nodes at each time step when a random scanning worm spreads. The model developed at this step, estimated the infection probability of each node at each time step, when the spread of a preference scanning worm happened. At this point, we could combine the two models and use the stochastic Back-to-Origin Markov model to estimate the number of infectious nodes at each step and use the results as the value for (INF CNT) in Equation (11). This model has been developed in Section 8.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:27:11",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What data structures are required to implement the Particle Swarm Optimization (PSO) algorithm, and what programming techniques optimize particle velocity and position updates?",
      "answer": "Implementing PSO requires data structures to represent particles, including their positions (Xid(k)), velocities (Vid(k)), personal best positions (pbestid), and the global best position (gbest). Arrays or lists are suitable for storing these values for each particle. To optimize velocity updates, clamp velocities to a Vmax to prevent particles from skipping optimal regions. For position updates, use the equation Xid(k+1) = Xid(k) + Vid(k+1). Implement the inertia weight (ω) using ω = ωmax - ((ωmax - ωmin) / itermax) * iter, linearly decreasing it from ωmax to ωmin over the iterations to balance exploration and exploitation. The cognitive constant (α1) and social constant (α2) influence stochastic acceleration terms, typically set such that α1 + α2 = 4, often starting with α1 = α2 = 2.",
      "chunk_id": 5501,
      "paper_id": "Computational intelligence-based energy management for a large-scale PHEV PEV enabled municipal parking deck",
      "paper_title": "Computational intelligence-based energy management for a large-scale PHEV/PEV enabled municipal parking deck",
      "paper_year": "2012",
      "chunk_content": "PSO is an iterative stochastic optimization method. It simulates the behavior of flocks of birds or schools of fish. In 1995, Kennedy and Eberhart presented a new, evolutionary computation algorithm called Particle Swarm Optimization (PSO) [27,28]. In PSO, each solution is a \"bird\" (or, more generally, a \"particle\") in the search space. All of the particles have (1) fitness values (which are evaluated by the fitness function to be optimized) and (2) velocities (which direct the flying of the particles). The particles fly through the search space by following the current optimum particles. At each iteration, each of the particles is updated by following the individual and group bests. Gradually, the particles tend toward the global \"near-optima\" region. A PSO-based control algorithm was put forward in [11] to optimally allocate power to PHEVs at a municipal parking deck. Generally speaking, the principal steps in PSO can be summarized as follows:\n(1) Generate a group of random solutions (particles) in the feasible region. Since we normally have very little information about the global optima, these particles are scattered over the search space as uniformly as possible.\n(2) Evaluate the distance between the new solution and the desired solution based upon a fitness function.\n(3) Compare the fitness value at the current iteration with previous best, and update the individual best (phest) and group best (gbest).\n(4) Update the velocities of the particles according to Eq. (24). Clamp the velocities if $\\left|V_{\\text {id }}(k)\\right|>V_{\\max }$ (where $V_{\\max }$ is the velocity limit). If $V_{\\max }$ is too small, the particles may become trapped in a local region. However, if $V_{\\max }$ is too large, the particles are more likely to skip the best regions. In practice, $V_{\\max }$ is often set at $10-20 \\%$ of the range of the variables over a particular dimension.\n(5) Update the positions of the particles according to Eq. (25).\n(6) Repeat steps 2-5 until the maximum number of iterations or the minimum error criteria is met.  \n$$\n\\begin{aligned}\nV_{\\text {id }}(k+1)= & \\omega \\cdot V_{\\text {id }}(k)+\\alpha_{1} \\cdot \\operatorname{rand}_{1} \\cdot\\left(\\text { pbest }_{\\text {id }}-X_{\\text {id }}(k)\\right) \\\\\n& +\\alpha_{2} \\cdot \\operatorname{rand}_{2} \\cdot\\left(\\text { gbest }_{\\text {id }}-X_{\\text {id }}(k)\\right) \\\\\nX_{\\text {id }}(k+1)= & X_{\\text {id }}(k))+V_{\\text {id }}(k+1)\n\\end{aligned}\n$$  \nwhere $V_{\\text {id }}(k)$ is the velocity of the individual particle at iteration $k$; rand ${ }_{1}$ and rand ${ }_{2}$ are uniform random numbers between 0 and $1 ; X_{\\text {id }}(k)$ is the position of a particle at iteration $k$; gbest is the best value achieved by the individual so far; gbest is the best value of the group; $\\alpha_{1}$ and $\\alpha_{2}$ represent the cognitive constant and social constant respectively. These constants represent the weights for the stochastic acceleration terms. In general, $\\alpha_{1} \\cdot \\alpha_{1}=4$; to begin, $\\alpha_{1}=\\alpha_{1}=2$. Finally, $\\omega$ is the inertia constant that balances the information sharing between an exploratory mode versus an exploitative mode. In practice, $\\omega$ often decreases linearly from 0.9 to 0.4. Initially, a higher value allows particles to move freely throughout the search space to find the global optima. Once a near-optimal region is reached, $\\omega$ is decreased to a lower value in order to more narrowly define the search. Therefore, $\\omega$ is given according to the following equation [29]  \n$$\n\\omega=\\omega_{\\max }-\\frac{\\omega_{\\max }-\\omega_{\\min }}{\\text { iter }_{\\max }} \\cdot \\text { iter }\n$$",
      "question_type": "theory",
      "complexity": "medium",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:27:15",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What metrics should be used to evaluate the performance of EDAPSO relative to PSO, LDWPSO, and CFPSO in solving unconstrained optimization problems, and how do acceleration rates quantify convergence speed differences?",
      "answer": "To evaluate EDAPSO against PSO, LDWPSO, and CFPSO, one should use both Success Rate (SR) and Acceleration Rate (AR). SR measures the robustness, while AR, calculated as $AR_{-} \\frac{PSO}{LDWPSO}$, $AR_{-} \\frac{PSO}{CFPSO}$, and $AR \\frac{PSO}{EDAPSO}$, quantifies the convergence speed differences. A higher average acceleration rate ($AR_{ave}$) indicates a faster convergence speed, allowing for direct comparison of algorithmic efficiency across a benchmark set of functions like Rastrigin's function ($f_{10}$).",
      "chunk_id": 339,
      "paper_id": "Novel Particle Swarm Optimization for unconstrained problems",
      "paper_title": "Novel Particle Swarm Optimization for Unconstrained Problems",
      "paper_year": "2013",
      "chunk_content": "We compare EDAPSO with three classical PSO (basic PSO, LDWPSO and CFPSO). Table 1 shows the results of solving 11 functions. The results of the experiments show NFCs, SR for each function. The last row of the table shows the average success rates and the average acceleration rate over 11 functions. The functions in this section are low dimensional functions. The parameter e is set to be $0.3 \\mathrm{M} / \\mathrm{M}$ is the size of particles in population). Table. 1 is too long. Thus, we divide it into two parts. The average success rates of PSO, LDWPSO, CFPSO and EDAPSO are $0.6483,0.7,0.7363$ and 0.8696 , respectively. The four algorithms fail to solve $f_{10}$ (Rastrigin's function). Basic PSO,LDWPSO and CFPSO all fail to solve $f_{2}$. The comparison of average success rates reveals that EDAPSO has the best robustness among the four algorithms.\n$A R_{-} \\frac{P S O}{L D W P S O}$ is 0.97 , which means the convergence speed of PSO is $3 \\%$ faster than the convergence speed of LDWPSO. $A R_{-} \\frac{P S O}{C F P S O}$ is 1.04 , which means the convergence speed of CFPSO is $4 \\%$ faster than the convergence speed of PSO. $A R \\frac{P S O}{E D A P S O}$ is 9.25 , which means the convergence speed of EDAPSO is $825 \\%$ faster than the convergence speed of PSO.\n$A R_{\\text {ave }} \\frac{L D W P S O}{E D A P S O}=\\frac{A R_{\\text {ave }} \\frac{P S O}{E D A P S O}}{A R_{\\text {ave }} \\frac{P S O}{L D W P S O}}=9.53$, which means the convergence speed of EDAPSO is $853 \\%$ faster than the convergence speed of EDWPSO.\n$A R_{\\text {ave }} \\frac{L D W P S O}{E D A P S O}=\\frac{A R_{\\text {ave }} \\frac{P S O}{E D A P S O}}{A R_{\\text {ave }} \\frac{E D A P S O}{E D W P S O}}=8.89$, which means convergence speed of EDAPSO is $789 \\%$ faster than the convergence speed of CFPSO. The comparisons of average acceleration rate indicate that EDAPSO has the fastest  \nTable1. Comparison of Four Algorithms for Low-dimensional Problems  \nconvergence speed among the four algorithms. The comparison shows that EDAPSO has the best robustness and the fastest convergence among the four algorithms. The optimization ability is the best among the four algorithms on the whole.\nIn this paper, the search idea of EDA has been employed to collect global information. An improved velocity updating equation was used to accelerate the speed of the algorithm. Embedding these two improvements, we proposed EDAPSO.\nPSO, LDWPSO, CFPSO and EDAPSO were compared in terms of robustness and convergence speed. The comparisons for SR (success rates) and AR (accelerate rates) show that EDAPSO has the fastest convergence speed and best robustness among the four algorithms.\nUtilizing the idea of EDA to obtain more global information and improving the solution accuracy of the problems is a new method. Further studies are still required to investigate its advantages, disadvantages and\nlimitations. This paper can be viewed as a first step in this direction. Possible directions for future work include adaptive setting of e (size of elite set) or applying the idea of EDA to other popular algorithms.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:27:18",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of the Estimation of Distribution Algorithm (EDA) differ from that of Iterated Greedy (IG) search when applied to the Unrelated Parallel Machine Scheduling Problem with Sequence-Dependent Setup Times (UPMSP-SDST)?",
      "answer": "The Estimation of Distribution Algorithm (EDA) uses a probability model based on neighbor relations of jobs to sample promising search regions, exploring the solution space by generating new solutions based on this model. In contrast, Iterated Greedy (IG) search exploits the solution space through deconstruction and reconstruction phases, aiming to improve existing solutions by iteratively removing and re-inserting jobs. The EDA focuses on exploration via probabilistic sampling, while the IG search focuses on exploitation through iterative refinement.",
      "chunk_id": 12892,
      "paper_id": "A Hybrid Estimation of Distribution Algorithm for Unrelated Parallel Machine Scheduling with Sequence-Dependent Setup Times",
      "paper_title": "A Hybrid Estimation of Distribution Algorithm for Unrelated Parallel Machine Scheduling with Sequence-Dependent Setup Times",
      "paper_year": "2016",
      "chunk_content": "Ling Wang, Shengyao Wang, and Xiaolong Zheng\nA hybrid estimation of distribution algorithm (EDA) with iterated greedy (IG) search (EDA-IG) is proposed for solving the unrelated parallel machine scheduling problem with sequence-dependent setup times (UPMSP-SDST). For makespan criterion, some properties about neighborhood search operators to avoid invalid search are derived. A probability model based on neighbor relations of jobs is built in the EDA-based exploration phase to generate new solutions by sampling the promising search region. Two types of deconstruction and reconstruction as well as an IG search are designed in the IG-based exploitation phase. Computational complexity of the algorithm is analyzed, and the effect of parameters is investigated by using the Taguchi method of design-of-experiment. Numerical tests on 1640 benchmark instances are carried out. The results and comparisons demonstrate the effectiveness of the EDA-IG. Especially, the bestknown solutions of 531 instances are updated. In addition, the effectiveness of the properties is also demonstrated by numerical comparisons.  \nIndex Terms-Unrelated parallel machine scheduling, sequence-dependent setup time (SDST), estimation of distribution algorithm (EDA), iterated greedy search.\nPARALLEL machine scheduling problem (PMSP) ${ }^{[1]}$ is a typical combinatorial optimization problem existing in many manufacturing systems ${ }^{[2-4]}$. According to the characteristic of machines, PMSP can be classified into three types: identical PMSP ${ }^{[5]}$, where each job has an identical processing time on every machine; uniform PMSP ${ }^{[6]}$, where the processing time of a job is inversely proportional to the processing speed of a machine; and unrelated PMSP (UPMSP) ${ }^{[7]}$, where the processing times of a job on different machines are unrelated. Identical PMSP and uniform PMSP can be regarded as the special cases of UPMSP. As a complex scheduling problem, PMSP is NP-hard even in a two-machine case ${ }^{[8]}$. Therefore, it is important to study PMSP and to develop effective solution algorithms, especially for the most general one, UPMSP.  \nManuscript received February 29, 2016; accepted May 17, 2016. This work was supported by the National Science Fund for Distinguished Young Scholars of China (61525304). Recommended by Associate Editor Yanjun Liu.\nCitation: Ling Wang, Shengyao Wang, Xiaolong Zheng. A hybrid estimation of distribution algorithm for unrelated parallel machine scheduling with sequence-dependent setup times. IEEE/CAA Journal of Automatica Sinica, 2016, 3(3): $235-246$  \nLing Wang, Shengyao Wang, and Xiaolong Zheng are with the Department of Automation, Tsinghua University, Beijing 100084, China (e-mail: wangling@mail.tsinghua.edu.cn; wangshengyao@tsinghua.org.cn; zhengxl11@mails.tsinghua.edu.cn).  \nIn the literature about the UPMSP, it is common to assume that there is no additional time between any two processing operations ${ }^{[7]}$. However, setup times widely exist in practice when preparing machines for the coming jobs FORMULA_8. Setup times are relevant to the job sequences on machines. During recent years, the UPMSP with sequence-dependent setup times (UPMSP-SDST) has been a focus in the area of PMSP. According to the reported research work before 2008, a brief review of the UPMSP-SDST was presented in [10]. Here, we focus on the typical literature after 2008.",
      "question_type": "evaluation",
      "complexity": "basic",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:27:20",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "How should practitioners implement the hybrid decoding mechanism, considering its components of transfer(π) and produce(S), and what is the practical impact of each on the overall time complexity?",
      "answer": "To implement the hybrid decoding mechanism, first implement the transfer(π) operation which has a time complexity of O(n^2). Then, implement the produce(S) operation, ensuring its complexity matches that of the HEFT algorithm, which is O(n^2 * m). The combined complexity of the hybrid decoding mechanism is O(n^2 * m), dominating the transfer(π) component. If an individual is labeled 0 or 2, EFT or OEFT can be used to decode the permutation, reducing the complexity to O(n^2 * m * Q) and O(n^3 * m) respectively, which can significantly improve performance.",
      "chunk_id": 9482,
      "paper_id": "A path relinking enhanced estimation of distribution algorithm for direct acyclic graph task scheduling problem",
      "paper_title": "A path relinking enhanced estimation of distribution algorithm for direct acyclic graph task scheduling problem",
      "paper_year": "2021",
      "chunk_content": "Based on above introduction, our proposed algorithm is summarized in Fig. 12. At first, HEFT and PEFT heuristics are carried out where the best one is chosen to initialize the probability model. After that, EDA is adopted to produce the task processing permutation as the right of Fig. 12. Please refer to the corresponding pseudo codes for the details of the related procedures.  \nAccording to the flowchart, the time complexity of our proposed algorithm is analysed as follows:  \nHybrid decoding mechanism: transfer $(\\pi)$ has an $O\\left(n^{2}\\right)$ complexity and the complexity of produce $(S)$ is the same as HEFT, where HEFT has an $O\\left(n^{2} \\cdot m\\right)$ complexity. It could be summarized that hybrid decoding mechanism complexity is of $O\\left(n^{2} \\cdot m\\right)$;  \nEDA evolution: EDA sampling has an $O\\left(n^{3}\\right)$ complexity and other operator complexity is $O\\left(n^{2}\\right)$;  \nLocal intensification: Path relinking insert operator is carried on elite population, and its complexity turns to $O\\left(n^{3} \\cdot m \\cdot Q\\right)$. Path relinking swap operator is carried on the best individual, and the complexity is $O\\left(n^{4} \\cdot m\\right)$. It is worth mentioned that if the\nindividual is labelled as 0 or 2 , EFT or OEFT is adopted to decode the permutation, its complexity decreases to $O\\left(n^{2} \\cdot m \\cdot Q\\right)$ and $O\\left(n^{3} \\cdot m\\right)$.  \nThus, the complexity of the proposed algorithm is $O\\left(\\left(N \\cdot n^{3} \\cdot\\right.\\right.$ $\\left.m+n^{3} \\cdot m \\cdot Q+n^{4} \\cdot m\\right) G$ ) where $G$ denotes the number of iteration. Considering $N<n$, the total algorithm complexity is of the order $O\\left(n^{4} \\cdot m \\cdot G\\right)$.\nTo evaluate the performance of our proposed algorithm, we compare it with several algorithms: two list scheduling heuristic methods and two evolutionary algorithms tailored for DAG-SP.  \nFor fair comparison, the algorithms are all coded in C++ and run on the same computer with Intel Core i5 CPU/3.20 GHz and 16 GB RAM. For the evolutionary algorithms, the stopping criterions are set the same. In this section, the benchmark datasets, comparison algorithms and parameter settings are introduced at first. Then, the comparison with solutions of Gurobi solver are presented to review our proposed model. In addition, comparison results on randomly generated DAGs and real world instances with different scales of tasks, processors and different values of CCRs demonstrate the effectiveness of the proposed algorithm.",
      "question_type": "practical application",
      "complexity": "medium",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:27:23",
      "generation_style": "practical_application"
    },
    {
      "question": "What convergence guarantees exist for the K-means algorithm in terms of minimizing the Distortion, $D$, and how does the number of clusters, $K$, impact the computational complexity of achieving a local minimum?",
      "answer": "The K-means algorithm iteratively attempts to minimize the Distortion $D = \\sum_{i=1}^{N}\\left[\\min _{k=(1 . . K)} d\\left(x_{i}, c_{k}\\right)\\right]^{2}$, where $d$ is a distance function (typically Euclidean distance), $x_i$ are data points, and $c_k$ are cluster centers. While K-means is guaranteed to converge to a local minimum of $D$, there are no guarantees on the quality of this local minimum relative to the global minimum. The computational complexity of each iteration of K-means is approximately $O(NKDI)$, where $N$ is the number of data points, $K$ is the number of clusters, $D$ is the dimensionality of the data, and $I$ is the number of iterations. The number of clusters, $K$, directly influences the computational cost, and a larger $K$ generally leads to a higher computational burden per iteration and may also affect the number of iterations required to converge.",
      "chunk_id": 5655,
      "paper_id": "Improved Prediction of Nitrogen Oxides Using GRNN with K-Means Clustering and EDA",
      "paper_title": "Improved Prediction of Nitrogen Oxides Using GRNN with K-means Clustering and EDA",
      "paper_year": "2008",
      "chunk_content": "Obviously, the number of smoothing parameter is equal to the number of training samples, as shown in Eq. (1). It is not computationally efficient if the number of training sample is very large. In order to reduce the number of the smoothing parameters, Kmeans clustering was firstly employed to partition the training data into groups. In each group, the smoothing parameter was identical for all training samples. The number of multiple smoothing parameters is then equal to the number of clustering, $K$, rather than the number of total training set, $N$. Therefore, the number of smoothing parameter is reduced compared to the number of training data.  \nThe K-means algorithm attempts to find the cluster centers, $\\left(\\boldsymbol{c}_{1}, \\ldots, \\boldsymbol{c}_{K}\\right)$, such that the sum of the squared distances (this sum of squared distances is termed the Distortion, $D$ ) of each data point $\\left(x_{i}\\right)$ to its nearest cluster centre $\\left(c_{k}\\right)$ is minimized, as shown in Eq. (4), where $d$ is some distance function. Typically $d$ is chosen as the Euclidean distance. A pseudo-code for the K-means algorithm is shown in Algorithm 1[8].  \n$$\nD=\\sum_{i=1}^{N}\\left[\\min _{k=(1 . . K)} d\\left(x_{i}, c_{k}\\right)\\right]^{2}\n$$  \nAlgorithm 1 K-means Algorithm\n(1) Initialize $K$ centre locations.\n(2) Assign each $x_{i}$ to its nearest cluster centre $\\boldsymbol{c}_{k}$.\n(3) Update each cluster center $\\boldsymbol{c}_{k}$ as the mean of all $x_{i}$ that have been assigned as closest to it.\n(4) Calculate $D=\\sum_{i=1}^{N}\\left[\\min _{k=(1 . . k)} d\\left(x_{i}, c_{k}\\right)\\right]^{2}$\n(5) If the value $D$ has converged, then return $\\left(\\boldsymbol{c}_{1}, \\ldots\\right.$, $\\boldsymbol{c}_{K}$ ); else go to Step 2.",
      "question_type": "definition",
      "complexity": "advanced",
      "topics": [
        "algorithm",
        "mathematical analysis"
      ],
      "generated_at": "2025-06-07 21:27:26",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What distinguishes the efficiency of the Estimation of Distribution Algorithm (EDA) from the Genetic Algorithm (GA) in the context of joint variable optimization?",
      "answer": "The Estimation of Distribution Algorithm (EDA) differs from the Genetic Algorithm (GA) by replacing crossing and mutation operations with a probabilistic model for population generation and updating, using a Gaussian normal distribution characterized by mean μ and standard deviation φ to generate new populations from promising individuals.",
      "chunk_id": 6306,
      "paper_id": "Global optimization of motion planning for tip trajectory tracking of a flexible macro-micro manipulator system using Estimation of Distribution Algorithm",
      "paper_title": "Global optimization of motion planning for tip trajectory tracking of a flexible macro-micro manipulator system using Estimation of Distribution Algorithm",
      "paper_year": "2006",
      "chunk_content": "Where  \n$$\n\\boldsymbol{T}_{\\boldsymbol{m}}=\\operatorname{diag}\\left[\\theta_{\\text {m} \\mid \\text { cost }}, \\theta_{\\text {m2cost }}, \\cdots \\theta_{\\text {mncost }}\\right]^{-1}\n$$  \nHere $\\theta_{\\text {micost }}(i=1,2, \\cdots, m)$ denotes the cost of each micro manipulator joint.  \nFrom (21), equality  \n$$\n\\Delta \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{m}}=\\tilde{\\boldsymbol{J}}_{\\delta} \\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}\n$$  \nis derived, where $\\tilde{\\boldsymbol{J}}_{\\boldsymbol{\\delta}}=\\boldsymbol{T}_{\\boldsymbol{m}} \\boldsymbol{J}_{\\boldsymbol{\\delta}} \\boldsymbol{T}_{\\boldsymbol{\\delta}}{ }^{-1}$. To minimize $\\left\\|\\Delta \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{m}}\\right\\|$\nfor any $\\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}$ satisfying $\\left\\|\\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}\\right\\| \\leq 1$, compensability measured by:  \n$$\nI_{c}=\\frac{1}{\\left\\|\\tilde{\\boldsymbol{J}}_{\\delta} \\tilde{\\boldsymbol{J}}_{\\delta}^{\\dagger}\\right\\|}\n$$  \nshould be as small as possible, which serves as the first factor for optimization.\nB. Global Fitness Function  \nDefine a fitness function  \n$$\ng\\left(\\boldsymbol{\\theta}_{M}, \\boldsymbol{\\theta}_{m}\\right)=a_{1} I_{C}+a_{2} I_{e}\n$$  \nwhere $a_{1}$ and $a_{2}$ denotes weight of $I_{C}$ and $I_{e}$ in the\noptimization function respectively. Function $g\\left(\\boldsymbol{\\theta}_{M}, \\boldsymbol{\\theta}_{m}\\right)$\ncan be taken as the fitness function for optimization of each endpoint which locates on the desired tip trajectory. However, it is devoid of consideration for the whole tip trajectory.  \nAccording to the fitness function above, fitness values for subsequent tip points are determined by the selection of the start joint state. Discretize the continuous curve into $n$ individual points at appropriate interval, derive :  \n$$\nf i t\\left(\\boldsymbol{\\theta}_{\\theta}\\right)=\\sum_{i=1}^{n} G\\left(\\boldsymbol{p}_{i}\\right)\n$$  \nwhere $\\boldsymbol{\\theta}_{\\boldsymbol{\\theta}}$ denotes the start joint variables, and $G(\\boldsymbol{p})$ denotes the maximum of the fitness function $g\\left(\\boldsymbol{\\theta}_{\\boldsymbol{M}}, \\boldsymbol{\\theta}_{\\boldsymbol{m}}\\right)$ when the desired tip position is $\\boldsymbol{p}$.\nA new evolution algorithm EDA is adopted here to search for a series of joint variables, best solutions for the global fitness function. Different from the Genetic Algorithm (GA), EDA replace the crossing and mutation operation by utilizing probabilistic model for population generation and updating. New population is generated from updated probabilistic model by promising individuals selected from last generation.  \nGaussian normal distribution is proposed for the probability model and there exist two parameters for the model, mean $\\mu$ and standard deviation $\\varphi, \\mu \\in R^{n}$ and $\\varphi \\in R^{n}, n$ is the dimension of the task space. No covariance is covered between different coordinates of the task space.  \nThe proposed algorithm can be described as below:  \n1. Select a discrete tip point from the desired trajectory.\n2. Give initial values of mean $\\mu$ and standard deviation $\\varphi$ for the model.\n3. While termination condition is not satisfied\na) Sample $S$ individuals from the Gaussian model to generate population;\nb) Calculate fitness values for individuals in the population;\nc) Select FORMULA_90 individuals from the population according to the fitness values;\nd) Update the model parameters using the Q individuals;\nAlgorithm discussed above can be used for joint variables' optimization of every tip points. However, the optimization of each joint state derived by (29), as a whole, does not necessarily lead to the optimization of the whole fitness value calculated by (30). So another outer optimization loop is added by searching for the optimal start point for the whole fitness value.",
      "question_type": "comparison",
      "complexity": "basic",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:27:28",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the algorithmic steps for implementing the BUMDA algorithm, specifically addressing the handling of constraints and the reset mechanism?",
      "answer": "To implement the BUMDA algorithm with constraint handling and a reset mechanism, follow these steps: First, initialize a population $P_0$ using a normal distribution and evaluate its fitness $f(P_0)$. Then, enter a loop that continues as long as the current function evaluations number (NumEval) is less than the maximum value established (NumEvalMax). Inside the loop, truncate the population, calculate parameters $(T, \\beta)$ internally, and determine $\\mu$ and $\\varepsilon$ using their respective equations. Generate a new population $P_t$ using the model $Q(x, t)$, ensuring the best individual (elite individual) is included in each generation to preserve population size. If the variance is larger than a proposed value, use $Q(x, t)$ to produce the new population; otherwise, reinitialize exploration by generating new individuals across the entire search range. Implement a method for handling constraints, use both continuous and discrete variables, and include the reset mechanism to explore the search space intensively and reduce the likelihood of remaining at local optima.",
      "chunk_id": 475,
      "paper_id": "Design and Optimization of Heat-Integrated Distillation Column Schemes through a New Robust Methodology Coupled with a Boltzmann-Based Estimation of Distribution Algorithm",
      "paper_title": "Design and Optimization of Heat-Integrated Distillation Column Schemes through a New Robust Methodology Coupled with a Boltzmann-Based Estimation of Distribution Algorithm",
      "paper_year": "2014",
      "chunk_content": "[IMAGE5]  \nFigure 6. Flow sheet of the BUMDA algorithm.\nis generated by using a normal distribution, it is evaluated $\\left[f\\left(P_{0}\\right)\\right]$ and enters the cycle if proposed. The optimization process is executed if the current function evaluations number (NumEval) is less than the maximum value established (NumEvalMax).  \nAlong the optimization process, the population is truncated and the parameters $(T, \\beta)$ are internally calculated. $\\mu$ and $\\varepsilon$ are determined with the respective equations. Thus, the new generation $\\left(P_{t}\\right)$ is produced by the model $Q(x, t)$ in a quantity of the population size less 1 . One individual is suppressed in order to add the best individual (elite individual) in each generation, thus preserving the size of the population. Also, it is important to mention that when the variance is larger than the value proposed, the new population will be produced using the model $Q(x, t)$. Otherwise, the exploration is reinitialized and each new individual will be generated as in the beginning, considering all the search range.\n2.5. Particular Considerations. In the original context, the BUMDA algorithm was developed to optimize problems on continuous domains, not constrained. Nonetheless, problems in chemical engineering are modeled by multiple variables (continuous and discrete) and constraints that must be met. Therefore, to optimize this kind of problem using optimization tools under intensified searches, this algorithm has undergone some important settings:  \n1. Implementation of a method for handling of constraints.\n2. Use of both continuous and discrete variables.\n3. Inclusion of a reset mechanism.  \nIn particular, there are two goals pursued by the reset mechanism: (a) explore intensively the search space and (b) reduce the possibility of remaining at local optima.",
      "question_type": "process",
      "complexity": "medium",
      "topics": [
        "constraints"
      ],
      "generated_at": "2025-06-07 21:27:32",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What statistical measures quantify the performance of Context-Free Grammar (CFG) models when learning from finite-sized trees, specifically concerning biases introduced by depth limits and necessitating the repair method, and how do proportional frequencies, denoted as $f()$ and $f_{d}()$, factor into this quantification?",
      "answer": "To quantify performance, one must account for biases from finite tree sizes by examining the proportional frequencies $f(A \\rightarrow \\alpha)$ and $f_{d}(A \\rightarrow \\alpha)$, representing the proportional frequency of a production rule and its depth-specific counterpart. These are computed in the infinite population limit to approximate maximum likelihood estimation. The set $M(A, R)$ defines productions in rule set R matching A, crucial for iterating over productions. Performance degradation due to depth limits is assessed by measuring the deviation of observed frequencies from these proportional frequencies, particularly when employing a repair method to handle individuals exceeding the depth limit. Statistical measures, such as Kullback-Leibler divergence between the expected and observed production rule frequencies, can then quantify the impact of these biases on the learned grammar's accuracy.",
      "chunk_id": 12370,
      "paper_id": "Recursion-Based Biases in Stochastic Grammar Model Genetic Programming",
      "paper_title": "Recursion-Based Biases in Stochastic Grammar Model Genetic Programming",
      "paper_year": "2016",
      "chunk_content": "To focus on the biases resulting from finite sized trees in sampling and learning from CFG models, we need to remove other sources of bias. Selection bias is easy to remove: we simply turn off selection. This is the path we follow in most of the subsequent analyses. Other biases that are used to control learning (reintroduction of uniform prior etc.) are also omitted. Sampling noise is more difficult: in theoretical analyses, we eliminate it by assuming infinite populations; in empirical work, we rely on large sample sizes.  \nWhen we come to the focus of this study, the bias arising from finite size limitations, it splits into two parts. The first  \nis the restriction to finite trees: we cannot, even in principle, directly represent randomly sampled infinite trees. If we generate an unbiased infinite sample from a grammar, then use maximum likelihood estimation to learn from it, we will recover the original grammar probabilities. But we have no such guarantee if we eliminate some part (the infinite trees) from the sample. That is one source of bias. The second source arises from depth limits. We cannot in general be certain, as we are generating an individual by ancestral sampling, whether it is going to terminate in a finite depth. So we generally impose a depth limit. But eliminating individuals larger than the limit also changes the distribution, with the effect depending on the way the limit is enforced. Specifically, we focus on the repair method introduced in Section II.\nIn this section, we assume infinite population sizes. Thus the frequencies of symbols and productions are infinite, so we cannot directly compute the relative frequency as the maximum likelihood estimator as in Section II. To resolve this, we instead use the limit of this ratio as the population size tends to infinity. We call it the proportional frequency, denoted as $f()$ in all subsequent sections; as an extension of this notation, we use the notation $f_{d}()$ to denote the proportional frequency of generating an object at a specific depth $d$.  \nIn the infinite population limit, and assuming there is no depth limit, samples will follow the distribution specified in the grammar, and the sampling of a production is independent of how its LHS was derived, so we can derive the proportional frequency of a production as in equation 5 .  \n$$\nf(A \\rightarrow \\alpha)=f(A) p(A \\rightarrow \\alpha)\n$$  \nor for a specific depth  \n$$\nf_{d}(A \\rightarrow \\alpha)=f_{d}(A) p(A \\rightarrow \\alpha)\n$$  \nWe often need to iterate over all productions matching a given LHS; for brevity we define the set $M(A, R)$ of productions in rule set R matching A as equation 7.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "topics": [
        "control"
      ],
      "generated_at": "2025-06-07 21:27:35",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of Bayesian Networks, specifically in the context of Estimation of Distribution Algorithms (EDAs), encode probabilistic dependencies, and what mathematical principles govern the estimation of parameters like $\\theta_{m j k}$ using Maximum Likelihood Estimate (MLE)?",
      "answer": "Bayesian Networks (BNs) in EDAs use a directed acyclic graph (DAG) to represent probabilistic dependencies between variables $\\mathbf{Y} = (Y_1, \\ldots, Y_M)$. The factorization of the probability mass function (pmf) is given by $p(\\mathbf{y}) = \\prod_{m=1}^{M} p(y_m \\mid \\mathbf{pa}_{m}^{B})$, where $\\mathbf{pa}_{m}^{B}$ represents the parents of variable $Y_m$. The parameter $\\theta_{m j k}$ represents the conditional probability $p(y_{m}^{k} \\mid \\mathbf{pa}_{m}^{j, B})$. In Maximum Likelihood Estimate (MLE), the parameter $\\hat{\\theta}_{m j k}$ is estimated as $\\hat{\\theta}_{m j k} = N_{m j k} / N_{m j}$, where $N_{m j k}$ is the number of observations where $Y_m$ takes its $k$-th value given the $j$-th combination of its parents' values, and $N_{m j}$ is related to the number of observations in Pop.",
      "chunk_id": 7032,
      "paper_id": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_title": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_year": "2017",
      "chunk_content": "One of the most general probabilistic models for discrete variables used in EDAs and MOEDAs is the Bayesian Network [3], and we briefly describe it in the next section.  \nA Bayesian Network (BN) is a probabilistic model which topology structure is a directed acyclic graph (DAG) whose nodes represent variables and edges express the probabilistic dependency relationship between them [11]. Let us assume $\\mathbf{Y}=\\left(Y_{1}, \\ldots, Y_{M}\\right)$ as a vector of random variables, where $y_{m}$ is a value of the $m$-th component $\\left(Y_{m}\\right)$ of the vector $\\mathbf{Y}$. The set of conditional dependencies of all variables in $\\mathbf{Y}$ is described by the DAG structure $B . \\mathbf{P a}_{m}^{B}$ represents the set of parents of the variable $Y_{m}$ given by $B$, and the set of local parameters $\\Theta$ contains, for each variable, the conditional probability distribution of its values given different value settings for its parents, according to structure $B$.  \nTherefore, a Bayesian network encodes a factorization for the probability mass function (pmf) as follows:  \n$$\np(\\mathbf{y})=p\\left(y_{1}, y_{2}, \\ldots, y_{M}\\right)=\\prod_{m=1}^{M} p\\left(y_{m} \\mid \\mathbf{p a}_{m}^{B}\\right)\n$$  \nIn discrete domains, we can assume that $Y_{m}$ has $s_{m}$ possible values, $y_{m}^{i}, \\ldots, y_{m}^{s_{m}}$, therefore the particular conditional probability, $p\\left(y_{m}^{i} \\mid \\mathbf{p a}_{m}^{i, B}\\right)$ can be defined as:  \n$$\np\\left(y_{m}^{k} \\mid \\mathbf{p a}_{m}^{j, B}\\right)=\\theta_{y_{m}^{k} \\mid \\mathbf{p a}_{m}^{j, B}}=\\theta_{m j k}\n$$  \nwhere $\\mathbf{p a}_{m}^{j, B} \\in\\left\\{\\mathbf{p a}_{m}^{1, B}, \\ldots, \\mathbf{p a}_{m}^{t_{m}, B}\\right\\}$ denotes a particular combination of values for $\\mathbf{P a}_{m}^{B}$ and $t_{m}$ is the total number of different possible instantiations of the parent variables of $Y_{m}$ given by $t_{m}=\\prod_{Y_{v} \\in \\mathbf{P a}_{m}^{B}} s_{v}$, where $s_{v}$ is the total of possible values (states) that $Y_{v}$ can assume. The parameter $\\theta_{m j k}$ represents the conditional probability that variable $Y_{m}$ takes its $k$-th value $\\left(y_{m}^{k}\\right)$, knowing that its parent variables have taken their $j$-th combination of values $\\left(\\mathbf{p a}_{m}^{j, B}\\right)$. This way, the parameter set is given by $\\Theta=\\left\\{\\boldsymbol{\\theta}_{1}, \\ldots, \\boldsymbol{\\theta}_{m}, \\ldots \\boldsymbol{\\theta}_{M}\\right\\}$, where $\\boldsymbol{\\theta}_{m}=\\left(\\theta_{m 11}, \\ldots, \\theta_{m j k}, \\ldots, \\theta_{m, t_{m}, s_{m}}\\right)$.  \nBN's are often used for modeling multinomial data with discrete variables [11] generating new solutions using the particular conditional probability described in Equation (2) (direct sampling method).  \nGenerally, the parameters in the whole set $\\Theta$ are unknown, and their estimation process is based on the current data Pop with $N$ observations (instantiations) of $\\mathbf{Y}$.  \nThere are two approaches to estimate each $\\theta_{m j k}$ parameter: Maximum Likelihood Estimate (MLE) and Bayesian Estimate.  \nWith MLE, we expect to find a vector in $\\Theta$ that maximizes the likelihood. We can denote this vector as $\\hat{\\boldsymbol{\\theta}}$. In MLE, each\n$\\hat{\\boldsymbol{\\theta}} \\in \\Theta$ is a point estimation, not a random variable. Therefore, MLE does not consider any priori information, and the estimation is is calculated according to $\\hat{\\theta}_{m j k}=N_{m j k} / N_{m j}$, where $\\hat{\\theta}_{m j k}$ is the MLE estimated parameter for $\\theta_{m j k}, N_{m j k}$ is the number of observations in Pop for which $Y_{m}$ assumes the $k$-th value given the $j$-th combination of values from its parents and $\\mathbf{N}_{m j}=\\left\\{N_{m j 1}, \\ldots, N_{m j s_{m}}\\right\\}$.",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "topics": [
        "algorithm"
      ],
      "generated_at": "2025-06-07 21:27:38",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "How should practitioners implement a hybrid genetic algorithm for the 3D Bin Packing Problem, specifically concerning the crossover method and constraints related to carton rotations?",
      "answer": "To implement a hybrid genetic algorithm for the 3D Bin Packing Problem, first represent each potential packing arrangement as a chromosome. A key step is designing a crossover method that effectively combines parent chromosomes while respecting the problem's constraints. When generating new offspring, ensure that each carton is placed completely within a bin, with no overlaps. Account for the six possible rotations (l, w, h), (l, h, w), (w, l, h), (w, h, l), (h, w, l), (h, l, w) for each carton, and ensure that the selected rotation is encoded within the chromosome and adhered to during the decoding process for evaluation. The objective function should minimize the total wasted space, calculated as the bin volume minus the sum of carton volumes within that bin. Consider integrating a local search or Tabu Search component to further refine the solutions generated by the genetic algorithm.",
      "chunk_id": 132,
      "paper_id": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_title": "An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin Sizes",
      "paper_year": "2013",
      "chunk_content": "The solution techniques in literature for bin packing problems can be classified into three groups. The first group contains algorithms that use mathematical approach and try to reach an exact optimal solution. Martello et al. 2] discussed the lower bound and presented an exact algorithm to pack items into a single bin. Hifi et al. 1 introduced a mixed-integer linear programming formulation (MILP1) for bin packing problem. Heuristics and approximate algorithms belong to the second type. Lim et al. 3] did a comprehensive review on the heuristics that is used for bin packing problem. Most of them are wall or layer-building of the traditional 3DBPP to pack a selected subset of items into a single bin pursuing least waste space. Meta-heuristics such as genetic algorithm belong to the third type. Lodi et al. [4 presented a general Tabu Search technique for the solution of two- and three-dimensional bin packing problems. Crainic et al. 5 presented a new tabu search-based two-level which separates the search for the optimal number of bins from the optimization of the accommodation of items within bins, resulting into a more flexible procedure than the existing ones. Wang et al. 6 presented a hybrid genetic algorithm and a new crossover method for 3DBPP.\nThe investigated problem comes from a real world application, where a transportation company tries to make full use of their various bins to pack the cartons which is almost all rectangular. Their goal is to minimize the sum of all the waste space in the bins that are used. Wasted space of a bin is denoted as the volume of the bin minus the sum of the volume of all cartons in the bin.\nThere are total $m$ cartons and $N$ boxes, all of which are rectangular. The length, width and height of carton $i$ are denoted as $l_{i}, w_{i}, h_{i}$, while the length, width and height of bin $i$ is denoted as $L_{i}, W_{i}, H_{i}$. All the cartons need to be packed into the bins under three constrains.\n(1) Each carton lies completely in the bin and does not penetrate the bin's boundary surface. (2) No two cartons in the same bin can overlap with each other. (3) Each carton has only six rotations. Let the length of the bin be Xaxis, the width of the bin be the Y-axis and the height of the bin be the Z-axis. Let $(l, w, h)$ means the carton is placed in the way that length of the carton is paralleled to X -axis, width is paralleled to Y -axis and height is paralleled to Z-axis. The six rotation is $(l, w, h),(l, h, w),(w, l, h),(w, h, l),(h, w, l),(h, l, w)$.",
      "question_type": "application",
      "complexity": "medium",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:27:41",
      "generation_style": "practical_application"
    },
    {
      "question": "What theoretical guarantees can be established regarding the statistical significance of performance differences between SHEDA and its variants, given the adoption of Wilcoxon's rank sum test with a significance level of $\\alpha=0.05$?",
      "answer": "The Wilcoxon's rank sum test, when applied with $\\alpha=0.05$, provides a non-parametric assessment of whether two related paired samples originate from the same distribution. Specifically, if SHEDA performs 'significantly better' than a variant, it implies the null hypothesis (no difference in distributions) is rejected at the 5% significance level. This does *not* guarantee a specific magnitude of performance improvement, but rather a statistical confidence that the observed difference is unlikely to have occurred by random chance, based on the ranks of the observed performance metrics such as classification accuracy. This method is used to compare the original SHEDA to variants. The symbols '+', '$\\approx$', and '-' indicate whether SHEDA performs significantly better, similar, or worse than its variants based on this test.",
      "chunk_id": 3781,
      "paper_id": "Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks",
      "paper_title": "Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks",
      "paper_year": "2023",
      "chunk_content": "To show the strength of SHEDA, popular and state-of-the-art deep neural networks (DNNs), including manually designed and automatically found network models, are adopted for comparisons in terms of the classification accuracy, the number of parameters, and GPU days. To be specific, these state-of-the-art methods can be divided into three categories: manually designed, non-EC-based optimization, and EC-based optimization methods.  \nTo be specific, the manually designed methods include the famous network models ResNet [8] with 20, 110, and 1202 depths, DenseNet [10] (a powerful enhanced variant of the ResNet), VGG network [46], Maxout [47], Network in Network [48], Highway Network [49], All-CNN [50], and FractalNet [51]. These manually designed CNNs have shown their effectiveness on classification tasks, and therefore they are suitable for investigating whether the SHEDA can find better network models than these CNNs designed by experienced and skillful researchers. As for the non-EC-based optimization methods, this article adopts the representative automatic algorithms like NAS [11] and MetaQNN [52], and semi-automatic algorithms with partial manually designed procedures like EAS [53] and Block-QNN-S [54], for comparisons. In addition, the EC-based optimization methods include genetic CNN [55], Large-scale Evolution [13], Hierarchical Evolution [14], CGP-CNN [19], CNN-GA using GA [23], AECNN [24], and AE-CNN + E2EPP [25], where AE-CNN + E2EPP is also a surrogate-assisted method. As these EC-based optimization methods have different characteristics, they are ideal for evaluating the advantages of the proposed SHEDA. Considering that the adopted algorithms require expensive computational cost (e.g., NAS requires 22400 GPU days for one run) and the implemented version may produce different results due to the randomness of the initial weights, the best results in their original paper are cited directly in this article for the comparisons. Also, it should be noted that using the classification results from the corresponding papers is a convention in the evolutionary deep learning community for algorithm comparisons [23]. As for the ablation experiment and parameter studies, the Wilcoxon's rank sum test (significant level of $\\alpha=0.05$ ) is adopted to compare the results. According to the Wilcoxon's rank sum test, the symbols \" + \", \" $\\approx$ \", and \" - \" are used to show whether the original SHEDA performs significantly better than, similar to, and significantly worse than its variants, respectively.",
      "question_type": "theory",
      "complexity": "advanced",
      "topics": [
        "genetic"
      ],
      "generated_at": "2025-06-07 21:27:44",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs exist between direct source-to-destination transmission and the two-step decode-and-forward (DF) scheme in an OFDMA system?",
      "answer": "The two-step decode-and-forward (DF) scheme introduces a time-slot division, halving the achievable rate by a factor of 1/2 as shown in the throughput equation \\(C(k, l, n, \\boldsymbol{\\varepsilon}, \\boldsymbol{p})=\\frac{\\varepsilon_{i, k}^{n}}{2} \\log \\left(1+\\min \\left\\{P_{r}^{n}\\left|h_{r l}^{n}\\right|^{2}, P_{r}^{n}\\left|h_{r k}^{n}\\right|^{2}+p_{l}^{n}\\left|h_{m}^{n}\\right|^{2}\\right\\}\\right)\\). Direct transmission avoids this rate reduction but may suffer from lower received signal strength compared to the relayed signal, impacting the log term within the capacity equation.",
      "chunk_id": 11716,
      "paper_id": "EDA-based Joint Power",
      "paper_title": "EDA-based Joint Power, Subcarrier Allocation and Relay Assignment Scheme for Multiuser Relaying in OFDMA-based Cognitive Radio Systems",
      "paper_year": "2011",
      "chunk_content": "$$\n\\sum_{i=1}^{L} \\sum_{n=1}^{N}\\left|h_{m}^{n}\\right|^{2} p_{l}^{n} \\int_{f_{n}}^{f_{c}} \\phi^{n}(f) d f \\leq I_{m}^{\\max } \\quad \\forall m\n$$  \nwhere, $p_{l}^{n} \\phi_{l}^{n}(f)$ is the power spectral density of the $l$ th relay on the $n$th subcarrier [16], where  \n$$\n\\phi_{l}^{n}(f)=T_{c}\\left(\\frac{\\sin \\pi\\left(f-\\frac{(2 n-1) B}{2}\\right) T_{c}}{\\pi\\left(f-\\frac{(2 n-1) B}{2}\\right) T_{c}}\\right)^{2}\n$$  \nIn (2), $T_{c}$ is the symbol duration, $f_{L}$ and $f_{U}$ represent lower and upper limit of the frequency band licensed to the primary user (which is also shared by the secondary users) and $I_{m}^{\\max }$ is the interference limit defined by the regulatory body at each primary user [11].  \nWe now formulate our optimization problem for the case of two-step decode-and-forward (DF) scheme [8] [9] [10]. In such a system, conveyance of each symbol from the source to destination takes place in two time slots. In the first time slot, the source transmits its data symbol for each receiver on the subcarriers assigned to the receiver and its associated relays, and all the relays can receive the signal carrying the symbol. In the second time slot relays will transmit the decoded signal to the receivers using the subcarriers assigned to them. Since the relays transmit the data for each receiver (SU) on a separate subcarrier, their transmissions destined for different receivers are orthogonal to one in accordance with the OFDMA [7] principles. The throughput of reliable information that the $k$ th receiver can receive through the $l$ th relay on $n$th subcarrier and directly from the source can be written [10] as,  \n$$\nC(k, l, n, \\boldsymbol{\\varepsilon}, \\boldsymbol{p})=\\frac{\\varepsilon_{i, k}^{n}}{2} \\log \\left(1+\\min \\left\\{P_{r}^{n}\\left|h_{r l}^{n}\\right|^{2}, P_{r}^{n}\\left|h_{r k}^{n}\\right|^{2}+p_{l}^{n}\\left|h_{m}^{n}\\right|^{2}\\right\\}\\right)\n$$  \nThus we define our optimization problem as given in (4). Constraint C1 ensures that the transmission power of each relay over each subcarrier is non-negative. C2 defines that the sum of all the transmission powers of a particular relay on different subcarriers can't be greater than the maximum allowed limit for that particular relay. C3 makes sure that if a relay doesn't transmit on a subcarrier then its power should be zero. This constraint eliminates some solutions that waste transmission power. C4 ensures the cumulative interference from all relays and through all subcarriers on a particular PU should not be greater than the interference limit set. C5 and C6 ensure that in the second time slot, in which relays can transmit, a particular subcarrier can be used either by one pair of relay and SU or not used at all. This constraint precludes the possibility of multiple relays simultaneously transmitting at the same subcarrier; that is, we consider the system in which a receiver does not have diversity combining capability.\n$\\max \\sum_{k=1}^{K} \\sum_{n=1}^{N} \\sum_{l=1}^{L} C(n, k, l, \\boldsymbol{\\varepsilon}, \\boldsymbol{p})$\n$C 1: p_{i}^{*} \\geq 0 \\quad \\forall(l, n)$\n$C 2: \\sum_{n=1}^{N} p_{i}^{*} \\leq p_{i}^{m \\times 1} \\quad \\forall l$\n$C 3: p_{i}^{*} \\leq \\sum_{k=1}^{K} \\varepsilon_{i, k}^{*} p_{i}^{m \\times 1} \\quad \\forall(l, n), l \\neq 0$\n$C 4: \\sum_{l=1}^{L} \\sum_{n=1}^{N}\\left|h_{l n}^{*}\\right|^{2} p_{i}^{*} \\int_{l_{n}^{*}}^{l_{n}^{*}} \\phi_{i}^{*}(f) d f \\leq I_{m}^{m \\times 1} \\quad \\forall m$\n$C 5: \\sum_{k=1}^{K} \\sum_{l=0}^{L} \\varepsilon_{i, k}^{*} \\leq 1, \\quad \\forall n$\n$C 6: \\varepsilon_{i, k}^{*} \\in\\{0,1\\} \\quad \\forall(l, k, n)$",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:27:47",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What data structures are required to implement the additive epsilon indicator ($I_{\\epsilon+}$) calculation for Pareto set approximations, and how should developers structure the code for creating the reference set $R$ to ensure scalability with increasing objectives?",
      "answer": "To calculate the additive epsilon indicator ($I_{\\epsilon+}$), developers need data structures to represent the approximation set $A$ and the reference set $R$, such as arrays or lists of solution vectors. Each solution vector should store the objective values. The code for creating the reference set $R$ should include functions to identify endpoint solutions (minimum value for one objective and maximum for others) and to calculate the approximate compromise solution (e.g., mean value). The size of $R$ should grow linearly with the number of objectives to maintain practicality for many-objective problems. The MBN-EDA algorithm can then be used to generate Pareto set approximations, and the $I_{\\epsilon+}$ value can be calculated to evaluate its performance.",
      "chunk_id": 886,
      "paper_id": "Multiobjective Estimation of Distribution Algorithm Based on Joint Modeling of Objectives and Variables",
      "paper_title": "Multiobjective Estimation of Distribution Algorithm Based on Joint Modeling of Objectives and Variables",
      "paper_year": "2014",
      "chunk_content": "$$\nI_{\\epsilon+}(A, B)=\\max _{\\epsilon \\in \\mathbb{R}^{+}}\\left\\{A \\preceq_{\\epsilon+} B\\right\\}\n$$  \nwhere  \n$$\nA \\preceq_{\\epsilon+} B \\quad \\Longleftrightarrow \\quad \\forall \\boldsymbol{y} \\in B, \\exists \\boldsymbol{x} \\in A \\mid \\boldsymbol{x} \\preceq_{\\epsilon+} \\boldsymbol{y}\n$$  \nAccording to this definition, the additive epsilon indicator for an approximation $A$ of the Pareto set is obtained using a reference set $R$  \n$$\nI_{\\epsilon+}(A)=I_{\\epsilon+}(A, R)\n$$  \nThis definition implies that smaller values of the epsilon indicator are better. A good choice for the reference set $R$ is an approximation of the Pareto optimal set. However, the size of a good approximation of the Pareto optimal set should increase exponentially with the number of objectives in the MOP to offer a good coverage of the Pareto optimal front. Therefore, this choice of reference set is impractical for manyobjective problems. The reference set considered in this paper is composed of the endpoint solutions, obtained by setting one of the objectives to its minimum value and the others to their maximum value, plus the solution representing an approximate compromise between the values of all objectives (e.g., the mean value in the objectives range). The size of this reference set grows only linearly with the number of objectives, and the inclusion of endpoints favors those Pareto set approximations that result in a more scattered Pareto front.\n2) Results: Fig. 6-8 show the epsilon indicator value obtained for the Pareto set approximations of each of the algorithms, averaged over 20 independent runs. All of the algorithms stop after reaching a maximum number of generations, which is set to 300 . The population size is equal for all algorithms and is gradually incremented as the number of objectives increases according to TABLE II. In each generation, $50 \\%$ of the solutions in the population are selected for reproduction (i.e., $\\tau=0.5$ ).  \nTable III shows the statistical analysis of the results for the algorithms with different ranking methods on each of the MOPs with different numbers of objectives. The nonparametric Friedman test [89] is used to check for the statistical differences of the algorithm performance. When the null hypothesis that all the algorithms have an equal average rank  \nTABLE II\nTHE POPULATION SIZE USED FOR DIFFERENT NUMBER OF OBJECTIVES AND VARIABLES.  \nis rejected for a specific problem configuration with a p-value less than 0.05 , the entry related to the algorithm with the best Friedman rank is shown in bold. The numbers in parentheses show the results of pairwise comparisons using BergmannHommel's post-hoc test with a significance level of FORMULA_240. The first number shows how many algorithms are significantly worse than the algorithm listed in this column, and the second number shows how many algorithms are significantly better.  \nThe objectives in WFG1 are unimodal and biased for specific regions of their input. For this problem, MBN-EDA is able to obtain significantly better Pareto set approximations than the other two algorithms. The performance of the algorithm is very similar when using the different ranking methods tested in these experiments (Fig. 6, left column). Even though there are more interdependencies between the variables in WFG2, MBN-EDA is able to obtain significantly better results for this problem, evidencing the advantage of its probabilistic model for guiding the solution space search. The difference in the optimal front of the MOP problems does not significantly affect MBN-EDA's optimization ability as observed for WFG3, which is very similar to WFG2 except for the shape of the Pareto optimal front. Moreover, approximating the degenerated front in this problem requires good search process exploitation, which, according to the results for this problem, MBN-EDA is better able to do than the other two algorithms.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:27:50",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach best assesses the effectiveness of Building Block Identification with Common and Different Building Blocks (BBIC) algorithm in comparison to methods like mGA, considering the trade-off between exploration and exploitation?",
      "answer": "To assess the BBIC algorithm, benchmark problems should be designed to evaluate the rate of construction versus disruption of Building Blocks (BBs). Metrics should focus on the size and stability of common and different BBs across generations. Specifically, measure the average size of common BBs and different BBs in early, middle, and late generations to quantify knowledge acquisition and diversity preservation. Compare the BBIC algorithm's performance against mGA using metrics such as the number of function evaluations (\")#FEs\") required to reach a predefined solution quality. Additionally, track the ratio of different BBs to common BBs to quantify the algorithm's exploration-exploitation balance.",
      "chunk_id": 12066,
      "paper_id": "The use of explicit building blocks in evolutionary computation",
      "paper_title": "The use of explicit building blocks in evolutionary computation",
      "paper_year": "2016",
      "chunk_content": "The main component of the BBIC algorithm is the BB, which will be summarised in this section. There are two\ntypes of BBs: common and different. Many chromosomes in the selection process will be paired. The common BBs are regarded to have the same bias between two collated chromosomes. The identification procedure prevents the plausible unknown BBs from being disrupted. If the rate of construction of the BBs is higher than the rate of disruption of the BBs, the quality of the solutions will be improved.\n[IMAGE9]  \nFigure 15. Characteristics of the benchmark problems.  \nTable 2. Benchmark parameter settings.\nNote: \\#pop means population and \\#sub means subpopulation or selected chromosomes from the $n$-Best selection method. The bold face indicates the minimum value.  \nTable 3. Benchmark results.\nNote: N/A denotes that the data were not available because the optimal solution cannot be found under the limited number of function evaluations (\\#FEs $\\leq$ $1,000,000)$. The bold face indicates the best value.  \nThis is the main mechanism of the evolutionary process. The results of sGA-FCs and EDAs in several published papers confirm that various types of BBI processes are useful (Larranaga \\& Lozano, 2001; Pelikan, Goldberg, \\& Lobo, 2002; Pelikan et al., 2006). In regard to the use of explicit BBs in GAs, the mGA and its variants (Goldberg et al., 1993; Goldberg et al., 1989) are directly related to our work. The method of mGAs is to improve the performance by increasingly build longer, highly fit strings from shorter BBs. This is similar to how we compose BBs. However, our method is different in the identification of BBs and how BBs are stored and used.  \nThe size of the BBs gives indirect information about the level of knowledge or diversity. If the size of the common BBs is longer, the size of the different BBs is shorter. This means that the evolution process has learned something about the models. The different BBs preserve the unexploited structures or diversity of the search space. In the early generations, the average size of the BBs is small because the diversity is high. Although the common BBs in the early stage are not reliable, the number of different BBs is twice the number of common BBs. The different BBs act as the choices for search space exploration. In the middle generations, the common BBs are more stable and more reliable. The different BBs act as the more distinct and more limited alternatives. In the later generations, the different BBs work as rare mutations because they are too short, and thus they have a very low chance to be selected.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:27:53",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of Bakker's Tagger tag SNP selection algorithm leverage multi-marker haplotype approaches, and what limitations arise from its greedy search strategy in the context of NP-complete tagging SNP selection problems?",
      "answer": "Bakker's Tagger tag SNP selection algorithm combines pairwise tagging methods with multi-marker haplotype approaches to improve tagging efficiency by attempting to replace each tag of the original solution with a multi-marker predictor. However, because this algorithm employs a greedy approach, its performance is heavily dependent on the initial single-marker tagging set. This can lead to the algorithm becoming stuck in local optimal solutions due to the NP-complete nature of the single and multi-marker SNP tagging problems, preventing it from finding the globally optimal multi-marker set.",
      "chunk_id": 7356,
      "paper_id": "Multi-marker tagging single nucleotide polymorphism selection using estimation of distribution algorithms",
      "paper_title": "Multi-marker tagging single nucleotide polymorphism selection using estimation of distribution algorithms",
      "paper_year": "2010",
      "chunk_content": "Disease-gene association consists of the identification of DNA variations which are highly associated with a known disease. The task can be accomplished by statistical genetic variation analysis of single nucleotide polymorphisms (SNPs). The study of complex disease in association studies requires the analysis of more than one locus because single locus methods cannot be used to identify complex patterns. They miss the genetic contribution to the disease of the interactions between loci [1,2]. Therefore, the analysis of multiple sites is required for better disease-gene association studies. Usually, this type of analysis involves genome wide association studies, where the whole genome is searched for the identification of genetic associations with observable traits $[3-5]$.  \nNevertheless, genotyping is complicated and very costly when a large number of candidate SNPs is considered. A possible remedy for this problem is the identification of a subset of representative SNPs or tagging SNPs that allows to reduce the genotyping  \n[^0]overhead. In this way, frequency differences between case and control populations do not need to be measured in all SNPs but only in the subset of tagging SNPs. To this end, more precise mapping of the patterns of linkage disequilibrium is needed. Improved haplotype mapping of the human genome is an important step in this direction [4,5]. The other requirement is the conception of efficient procedures for appropriate selection of tagging SNPs.  \nThe problem of determining a subset of SNPs to genotype from which to recover not genotyped SNPs, involves two different issues. The first one is the problem of selecting (tagging) SNPs. The second one is the problem of predicting the value of unknown or not genotyped SNPs from the ones available. The difference between these two problems has been previously emphasized [6]. In this work we focus on the first problem which is usually formulated as the objective of selecting the lowest number of tagging SNPs so that the remaining (tagged) SNPs are \"covered\". Covering is defined by some statistical criterion (e.g. a high correlation between tagging and tagged SNPs, informativeness measures, etc.). There are two main variants of this problem: When single marker SNPs are used, each tagged SNP can be covered by a single tagging SNP. When multi-marker tags are used, each SNP can be covered by a single SNP or by a subset of tagging SNPs. Multi-  \n[^0]:     Corresponding author. Tel.: +34 913363675; fax: +34 943219306.  \nE-mail address: roberto.santana@upm.es (R. Santana).  \nmarker tags can significantly outperform tagging efficiency with respect to single-marker approaches [7]. However, in the general case, the single and multi-marker SNP tagging problems are NP-complete [8].  \nMinimal tagging SNP selection has been mainly focused on single-marker tagging sets [8-11].  \nIn multi-marker tagging set, some work has been reported: Bakker's Tagger tag SNP selection algorithm [7], available in Haploview [12], combines the simplicity of pairwise tagging methods with the efficiency benefits of multimarker haplotype approaches. The search is carried out trying to replace each tag of the original solution with a specific multi-marker predictor (on the basis of the remaining tags) to improve efficiency. The result of this greedy approach will depend mostly on the closeness of the initial single-marker tagging set to the optimal multi-marker set. Therefore, the algorithm is likely to get stuck in local optimal solutions.",
      "question_type": "definition",
      "complexity": "basic",
      "topics": [
        "analysis"
      ],
      "generated_at": "2025-06-07 21:27:56",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "In which scenarios does Scatter Search outperform Estimation of Distribution Algorithms in evolutionary software testing, and what implementation steps are crucial for maximizing Scatter Search's effectiveness in achieving branch coverage?",
      "answer": "Scatter Search and Estimation of Distribution Algorithms can be used independently or collaboratively in evolutionary testing. For pure Scatter Search, implementation involves defining a reference set and applying methods for subset generation, solution combination, and improvement. To maximize branch coverage, ensure the objective function accurately reflects the distance to uncovered branches. When using a Scatter Search-Estimation of Distribution Algorithm collaboration, the key is to properly integrate the probabilistic modeling of Estimation of Distribution Algorithms into the Scatter Search framework, potentially using the Estimation of Distribution Algorithms to generate diverse starting populations for Scatter Search or to guide the combination of solutions within Scatter Search. The choice depends on the specific test landscape; Scatter Search may excel in problems where solution combination effectively explores the search space, while Estimation of Distribution Algorithms might be preferred when probabilistic modeling can efficiently identify promising regions.",
      "chunk_id": 6246,
      "paper_id": "Scatter Search in software testing",
      "paper_title": "Scatter Search in software testing, comparison and collaboration with Estimation of Distribution Algorithms",
      "paper_year": "2006",
      "chunk_content": "Ramon Sagarna *, Jose A. LozanoDepartment of Computer Science and Artificial Intelligence, University of the Basque Country, Paseo Manuel Lardizabal 1, 20018 San Sebastian, Guipuzcoa, Spain  \nReceived 29 July 2003; accepted 22 January 2004\nOne of the main tasks software testing includes is the generation of the test cases to be used during the test. Due to its expensive cost, the automatization of this task has become one of the key issues in the area. The field of Evolutionary Testing deals with this problem by means of metaheuristic search techniques.  \nAn Evolutionary Testing based approach to the automatic generation of test inputs is presented. The approach developed involves different possibilities of the usage of two heuristic optimization methods, namely, Scatter Search and Estimation of Distribution Algorithms. The possibilities comprise pure Scatter Search options and Scatter Search-Estimation of Distribution Algorithm collaborations. Several experiments were conducted in order to evaluate and compare the approaches presented with those in the literature. The analysis of the experimental results raises interesting conclusions, showing these alternatives as a promising option to tackle this problem.  \n(c) 2004 Elsevier B.V. All rights reserved.  \nKeywords: Evolutionary computations; Software testing; Branch coverage; Scatter search; Estimation of Distribution Algorithms",
      "question_type": "comparison",
      "complexity": "medium",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:27:59",
      "generation_style": "practical_application"
    },
    {
      "question": "What theoretical bounds constrain the exploration-exploitation balance achieved by the cooling scheme within the Random Key based Estimation of Distribution Algorithm (RK-EDA) when applied to permutation problems?",
      "answer": "The cooling scheme in RK-EDA aims to control the variance in its probabilistic model. While the provided text does not give precise mathematical bounds, the intention is to modulate the exploration-exploitation trade-off. Specifically, the cooling scheme's variance parameter affects the probability of sampling diverse solutions (exploration) versus focusing on solutions near the current best (exploitation). Without a specified variance reduction schedule or convergence proof, it is difficult to provide concrete theoretical bounds on the algorithm's convergence rate or the quality of the solution obtained for Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, or Travelling Salesman Problems. The performance hinges on how well the cooling scheme adapts the FORMULA_4 univariate model's parameters to the specific permutation problem instance. A rigorous analysis would require bounding the change in variance and relating it to the expected change in the objective function value over iterations of the EDA.",
      "chunk_id": 12297,
      "paper_id": "RK-EDA- A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_title": "RK-EDA: A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "Mayowa Ayodele ${ }^{(\\boxtimes)}$, John McCall, and Olivier Regnier-CoudertRobert Gordon University, Aberdeen, UK\\{m.m.ayodele,j.mccall, o.regnier-coudert\\}@rgu.ac.uk\nThe challenges of solving problems naturally represented as permutations by Estimation of Distribution Algorithms (EDAs) have been a recent focus of interest in the evolutionary computation community. One of the most common alternative representations for permutation based problems is the Random Key (RK), which enables the use of continuous approaches for this problem domain. However, the use of RK in EDAs have not produced competitive results to date and more recent research on permutation based EDAs have focused on creating superior algorithms with specially adapted representations. In this paper, we present RK-EDA; a novel RK based EDA that uses a cooling scheme to balance the exploration and exploitation of a search space by controlling the variance in its probabilistic model. Unlike the general performance of RK based EDAs, RK-EDA is actually competitive with the best EDAs on common permutation test problems: Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.  \nKeywords: Estimation of distribution algorithm $\\cdot$ Random key $\\cdot$ Permutation problems $\\cdot$ Cooling scheme FORMULA_4 Univariate model",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:28:02",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantages does the hybrid EDA exhibit over GA and EP in the context of spacecraft attitude control using momentum wheel actuators?",
      "answer": "The hybrid EDA demonstrates a better optimal solution and convergence rate compared to GA and EP when applied to spacecraft attitude control. Specifically, for the given example, the hybrid EDA, with a population size of 100 and an evolutionary generation limit of 500, achieves superior results relative to GA and EP.",
      "chunk_id": 6934,
      "paper_id": "Hybrid EDA-based optimal attitude control for a spacecraft in a class of control task",
      "paper_title": "Hybrid EDA-based Optimal Attitude Control for a Spacecraft in a Class of Control Task",
      "paper_year": "2009",
      "chunk_content": "Matlab has been used to implement the hybrid EDA. We consider an example appeared in [2]. There is a rigid spacecraft with no control torque about the third principal axis and two control torques, generated by momentum wheel actuators, are applied about the other two principal axes. Thus, the vectors $\\mathbf{b}_{1}$ and $\\mathbf{b}_{2}$ are defined as $(1,0,0)^{T}$ and $(0,1,0)^{T}$. Moreover,  \nThen, the inertial matrix $\\mathbf{J}$ appeared in Eq. (2) is:  \n$$\n\\mathbf{J}=\\operatorname{diag}(86.663039,85.518039,114.461078) \\mathrm{kg} \\cdot \\mathrm{~m}^{2}\n$$  \nThe initial and final configurations of spacecraft system described by Carden angle are: $\\mathbf{q}_{0}=(0,0,0)^{T}$ and $\\mathbf{q}_{f}=(0,0, \\pi / 6)^{T}$. Namely, the final configuration is a rotation from the initial configuration about the third axis without a wheel [8]. Let $N$ be 10 . Select 10 terms of the orthonormal Fourier basis for $L_{2}([0, T])$, where $T=5 \\mathrm{~s}$. The first 5 basis elements are:  \n$$\n\\begin{aligned}\n& e_{1}=(0.5,0)^{T} e_{2}=(\\sin t, 0)^{T} e_{3}=(\\cos t, 0)^{T} \\\\\n& e_{4}=(\\sin 2 t, 0)^{T} e_{5}=(\\cos 2 t, 0)^{T}\n\\end{aligned}\n$$  \nThe remaining 5 terms can be obtained by permuting rows of the above elements.  \nFor this example, we use Newton iteration method mentioned in [3], GA mentioned in [4], EP mentioned in [5], and the proposed algorithm to find the optimal solution, respectively. In the hybrid EDA, we assume the population size is 100 , the upper limit value of evolutionary generation is 500 . The simulation results can be found in Table 1.  \nBy checking the Table 1, we find the optimal solution obtained by using hybrid EDA is better than the existing results obtained by using the other three algorithms. In addition, the convergence rate of hybrid EDA is better than that of EP and GA.  \nIn order to confirm the validity of optimal solution, we also give the relation curves of optimal solutions. Fig. 3 shows the optimal control inputs ( $u_{1}$ and $u_{2}$ ) for the angles velocity of rotation of two wheels about the principal axes.\nA class of control task for spacecraft is analyzed in this paper. That is, the optimal attitude control of a rigid spacecraft using only two control torques supplied by momentum wheel actuators. Under the restriction that the total angular momentum vector of the spacecraft system is zero, the dynamic system is controllable. Then, this nonlinear control problem can be converted to the nonholonomic motion planning problem of a drift-free system. The hybrid EDA is presented by combing the idea of DES to achieve optimal attitude control task for the spacecraft using two momentum wheel actuators. By comparing the proposed algorithm with existing Newton iteration method, GA, and EP, the simulation results show that the accuracy and efficiency of the hybrid EDA.\nThis work was jointly supported by National Natural Science Foundation of China under Grant 60604010, 90716021, 60736023, and 60773073 and Foundation of National Laboratory of Space Intelligent Control of China under Grant SIC07010202.",
      "question_type": "advantage",
      "complexity": "basic",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:28:04",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the algorithmic steps for implementing the improved Univariate Marginal Distribution Algorithm (UMDA) with a transfer model to address dynamic optimization problems?",
      "answer": "The improved UMDA involves these key steps: 1. Initialize the population. 2. Introduce a transfer model to increase population diversity, which helps maintain exploration capabilities in dynamic environments. 3. Use current information to guide the search process, avoiding local optima. 4. Evaluate the fitness of each individual in the population. 5. Select the best individuals based on their fitness. 6. Update the univariate marginal distribution based on the selected individuals. 7. Repeat steps 2-6 until a termination condition is met, adapting to changes in the dynamic environment.",
      "chunk_id": 5918,
      "paper_id": "An Improved Estimation of Distribution Algorithm in Dynamic Environments",
      "paper_title": "An Improved Estimation of Distribution Algorithm in Dynamic Environments",
      "paper_year": "2008",
      "chunk_content": "Xiaoxiong LiuCollege of AutomationNorthwestern PolytechnicalUniversity, Xi'an 710072, Chinanwpulxx@163.com  \nYan WuSchool of Science XidianUniversity Xi'an 710071, Chinayanerch@163.com  \nJimin YeSchool of Science XidianUniversity Xi'an 710071, Chinajmye@mail.xidian.edu.cn\nIn dynamic environments, the optimal solution changes over time. To track the solution, an improved univariate marginal distribution algorithm(UMDA) is proposed. A transfer model is introduced to increase the diversity of population. The current information is used to avoid being trapped into the local optimization for dynamic optimization problems. The scheme is illustrated through simulations applying dynamic moving peaks benchmark. The results show that the proposed algorithm is effective and can accommodate the dynamic environments rapidly.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:28:07",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What metrics should be used to evaluate the effectiveness of the Enhanced Estimation of Distribution Algorithm (EEDA) compared to the Gurobi solver for distributed no-wait flowshop group scheduling problems, particularly focusing on instances where the MILP model struggles to find feasible solutions within acceptable CPU time?",
      "answer": "To evaluate EEDA against the Gurobi solver, one should primarily use the Relative Percentage Increase (RPI) to compare solution quality, calculated based on the makespan achieved by each algorithm relative to the optimal solution. Additionally, assess the Number of Binary Variables (NBVs) and Number of Constraints (NCs) handled by each method, alongside CPU time, to understand scalability. For instances where Gurobi fails to find feasible solutions, compare the best makespan found by Gurobi within the time limit against the makespan achieved by EEDA within a defined CPU time limit, such as $300 \\times m \\times S$ milliseconds, where 'm' is a parameter and 'S' is the number of families. Statistical significance can be determined by running EEDA multiple times (e.g., 10 times) and comparing the distribution of RPI values against the single result from Gurobi, considering the trade-off between solution quality and computational cost.",
      "chunk_id": 3073,
      "paper_id": "An enhanced estimation of distribution algorithm with problem-specific knowledge for distributed no-wait flowshop group scheduling problems",
      "paper_title": "An enhanced estimation of distribution algorithm with problem-specific knowledge for distributed no-wait flowshop group scheduling problems",
      "paper_year": "2024",
      "chunk_content": "Table 8\nThe levels of parameters.\nTable 9\nResults of ANOVA for parameters calibration.  \nNote: All $F$-ratios are based on the residual mean square error.\nobtained solutions and the optimal solutions within the time limit, which can be calculated as the value of the RPI. Obviously, smaller gap values suggest higher solution quality. The correctness of the MILP model is validated by using the Gurobi solver (version 9.5.0) to tackle 36 different small-scale and medium-scale instances within a time limit of 3600 s . If no optimal solution is found within this timeframe, the best solution found is returned. The computational results of the MILP model for these instances, including NBVs, NCs, and CPU time, are reported in Table 10. It is observed from Table 10 that the Gurobi solver can achieve the best makespan for relatively small-scale instances, ranging from sFG24211 to sFG215231, and several medium-scale instances are also tested as a comparison. Detailed results for large-scale instances are available upon request. However, for relatively large-scale instances, the MILP model may fail to find any feasible solution within an acceptable CPU time. This is because the Gurobi solver tackles MILP models by default using the branch-and-cut method, which integrates cut-plane and branch-and-bound (B\\&B) methods, depending mainly on the size of the solved problem. As instance scale increases, the branch-and-cut strategy becomes significantly challenging in dealing with MILP models due to the increased constraints (i.e., NCs), decision variables (i.e., NBVs and NCVs), and enlarged solution spaces, leading to difficulties in branching, seeking new bounds, and cutting subspace. Obviously, it is undeniable that the Gurobi solver can effectively solve small-scale instances to optimality, but it is not efficient in solving relatively large-scale instances. As a basis in comparison to calculate RPI values, EEDA is run independently 10 times for each instance, with the maximum CPU time set to $300 \\times m \\times S$ milliseconds. With the increased number of families $S$, setup times for more families and processing times for more jobs have to be considered, so the problem's complexity significantly increases. As demonstrated in Table 10, NBVs, NCs, and CPU times of the MILP model notably increase as problem complexity escalates, while solution quality does not significantly improve. Nevertheless, when compared with results from EEDA and other metaheuristics (i.e., $\\mathrm{TIG}_{\\mathrm{v} 1}$ [24], TIG $_{\\mathrm{v} 2}$ [49], CCEA [3], and DIWO [68]), as shown in Table 13, although the MILP model requires more CPU time to solve the problem at hand, the RPI values of the solutions obtained by the MILP model are much larger. With the scale increases, EEDA achieves more satisfactory results than the MILP solver, and the runtime of the metaheuristic is quite lower than that of the MILP solver. This implies that the proposed EEDA outperform Gurobi solver, making it easier to obtain high-quality solutions compared to several state-of-the-art MILP solvers, thereby rendering EEDA more suitable for solving DNFGSPSDSTs.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "topics": [
        "bounds"
      ],
      "generated_at": "2025-06-07 21:28:10",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of EDA/L, as applied to test function $f_7$, navigate the landscape of numerous local minima, and what theoretical foundation explains why it might outperform the orthogonal genetic algorithm in this context?",
      "answer": "EDA/L, an Estimation of Distribution Algorithm, addresses optimization problems by building and sampling from probabilistic models of promising solutions. When applied to $f_7$, which possesses 100! local minima, EDA/L's probabilistic modeling attempts to capture the structure of the search space, guiding the search away from entrapment in local optima. The orthogonal genetic algorithm, while also designed for global optimization, may rely more heavily on crossover and mutation operators that might struggle to efficiently escape the dense local minima of $f_7$, potentially explaining EDA/L's superior performance.",
      "chunk_id": 13335,
      "paper_id": "Hybrid estimation of distribution algorithm for global optimization",
      "paper_title": "Hybrid Estimation of Distribution Algorithm for Global Optimization",
      "paper_year": "2004",
      "chunk_content": "We use $f_{2}, f_{7}$ and $f_{10}$ as the test functions to compare the performances of these three algorithms and our proposed algorithm. The results are listed in Tables II-IV.  \nSince all the algorithms adopted the same framework and stopping condition, it is hardly surprising that all these algorithms require the same number of function evaluations. EDA/L outperforms other algorithms in terms of solution quality. These results indicate that we can have positive answers to the earlier three questions.\nWe have tested EDA/L on $f_{1} \\cdot f_{10}$. Table V shows the experimental results.\nWe can see that the means of the smallest function value found are equal or close to the globally minimal function values. At the first glance, one may judge that the performance of EDA/L is poor on $f_{7}$. The mean of the smallest function found to $f_{7}$ is about 4.9 per cent above the global minimal function value. However, there are 100! local minima for this function in its feasible region.  \nTherefore, it is extremely hard to find the global minimum. To our best knowledge, only the orthogonal genetic algorithm was tested on $f_{7}$ with 100 variables (Leung and Wang, 2001). In the following comparison, we will see that our algorithm is better than the orthogonal genetic algorithm on this problem.",
      "question_type": "theory",
      "complexity": "basic",
      "topics": [
        "performance"
      ],
      "generated_at": "2025-06-07 21:28:13",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "How should practitioners implement the bisection method within REMEDA to determine the appropriate population size as a function of the intrinsic dimension, and what stopping criteria should be used?",
      "answer": "To implement the bisection method for determining population size in REMEDA, start with a large population size that can solve the problem within a predetermined budget, and a small population size that cannot. Use binary search between these limits to find the optimal population size. Specifically, the algorithm should aim to find the population size that results in the lowest number of function evaluations required to reach a pre-determined fitness gap value to reach (VTR). A suitable stopping criterion is reaching a VTR of 10^-5, 10^-3, 10^2, or 10^3, with a maximum of 6 x 10^3 fitness evaluations. The intrinsic dimensionality of the problem ($d_i$) can be varied within a range, such as [2, 50], to assess the scalability. Repeat the bisection process 25 times and average the results for statistical robustness.",
      "chunk_id": 12295,
      "paper_id": "REMEDA- Random Embedding EDA for Optimising Functions with Intrinsic Dimension",
      "paper_title": "REMEDA: Random Embedding EDA for Optimising Functions with Intrinsic Dimension",
      "paper_year": "2016",
      "chunk_content": "The bar chart in the leftmost plot of Fig. 2 shows an example of the fitness gaps achieved at convergence with consecutive values of $d$. The error bars show one standard error from 25 independent repetitions. In the rightmost plot we show the evolution of the best fitness. Superimposed, we also show the trajectories of competing state of the art methods: EDA-MCC [5], RP-EDA [9], and tRP-EDA [12]. All use the same budget and same population size (Table 3). For all the $d$ tried, we plot their concatenated trajectories in such a way that the next starts from the end of the current one.  \nFrom Fig. 2 we can see that REMEDA attains a fitness value close to the optimum efficiently, while the other methods are not able to achieve the same within the same budget. We also superimposed an idealised version of plain EDA - that is a plain EDA that receives the $d_{i}$-dimensional version of the problem - and we see that REMEDA is nearly as good.\n[IMAGE1]  \nFig. 2. Finding $d$ (left) and evolution of best fitness (right) for REMEDA, 3 competing methods, and a $d_{i}$-dimensional EDA on the idealised problem. Results are averaged over 25 independent runs. All methods use the same population size.  \nTable 3. Comparing REMEDA with other state of the art methods.\nFunction evaluation is costly in most practical problems. Here we study what is the required budget of function evaluations to reach a specified value of the fitness gap.  \nBefore running these scalability experiments, we carried out some experiments to determine the required population size as a function of the intrinsic dimension of the problem, so that we can vary the latter and set the population size automatically. For this we use a bisection method as in [2]. To find the population size that results in the lowest number of evaluations required to reach a pre-determined fitness gap value to reach (VTR), we start from a very large population size that can solve the problem within a large predetermined  \nbudget and then search for a small population size that cannot solve the problem anymore. In between these limits we use binary search to find the optimal population size. We repeated this 25 times and took the average.  \nWe fix the value to reach (VTR) to $10^{-5}$, and vary the intrinsic dimensionality of the problem $d_{i} \\in[2,50]$. We count the number of fitness evaluations needed for our proposed REMEDA to reach the VTR. The same experiment was repeated for three other choices of VTR: $10^{-3}, 10^{2}$ and $10^{3}$ in order to make sure that the conclusions will not be specific to a particular choice of the VTR. In all these experiments the maximum fitness evaluations was fixed to $6 \\times 10^{3}$, so the algorithm stops when the budget is exhausted.  \nFigure 3 shows the average number of function evaluations as computed from the successful runs out of 25 independent repetitions for each problem, with each intrinsic dimension tested. From the figure, we observe a linear fit on the scalability measurements.\n[IMAGE2]  \nFig. 3. Number of function evaluations taken by successful runs of REMEDA to reach a pre-specified value to reach (VTR) as the problem intrinsic dimensionality is varied in FORMULA_148. The markers represent averages computed from 25 independent repetitions.",
      "question_type": "implementation",
      "complexity": "medium",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:28:17",
      "generation_style": "practical_application"
    },
    {
      "question": "What convergence guarantees exist for the described Estimation of Distribution Algorithm (EDA) when integrated with Policy Improvement with Path Integrals ($\\mathrm{PI}^{2}$), specifically concerning the selection of the $M$ best policies and the subsequent construction of Gaussian models? How do the properties of the Receptive Field Weighted Regression (RFWR) model, with its Gaussian basis functions $\\Psi_{i}$ parameterized by $c_i$ and $h_i$, influence the convergence rate and the avoidance of local optima?",
      "answer": "While the integration of EDA and $\\mathrm{PI}^{2}$ aims to improve exploration and mitigate local optima convergence, formal convergence guarantees depend heavily on the properties of the selected stochastic models and the exploration-exploitation balance. The selection of the $M$ best policies at each iteration ensures monotonic improvement in cost, but does not guarantee convergence to a global optimum. The RFWR model, with its Gaussian basis functions $\\Psi_{i} = \\exp(-h_{i}(\\frac{x}{\\theta}-c_{i})^{2})$, introduces hyperparameters $h_i$ and $c_i$ that influence the shape of the learned policy. The choice of these parameters impacts the smoothness of the policy and the ability to escape local optima. Without further assumptions on the cost function landscape and a rigorous analysis of the exploration strategy induced by the EDA, it is difficult to provide tight theoretical bounds on the convergence rate or guarantee global optimality. Specifically, bounding the suboptimality gap after $T$ iterations would require analyzing the concentration properties of the Gaussian models and the impact of the RFWR on the smoothness of the learned policy.",
      "chunk_id": 696,
      "paper_id": "Integration of evolutionary computing and reinforcement learning for robotic imitation learning",
      "paper_title": "Integration of Evolutionary Computing and Reinforcement Learning for Robotic Imitation Learning",
      "paper_year": "2014",
      "chunk_content": "At step $a$, we select the $M$ \"best\" policies by finding the paths with the smallest cost values. (Please be noticed that we have $K$ candidate policies.) This step guarantee that the improvement of the policies when iterations happen. At step $b$, the means and the standard deviations of the parameters are computed to construct Gaussian models. We want to point out that this step is the basic essence of EDA. Instead of putting a group of candidate policies here, the idea of EDA is to represent these policies as specific probabilistic models. However, the selection of the stochastic models is flexible. Researchers could use any models that could fit the problem domain.  \nStep $c$ and step $d$ are used to evaluate the estimation or learning results in iterations using a noiseless roll-out generated by using the means of the probabilistic models of the parameters. Similar to step $f$ and step $g$ in part 1, any criterion satisfied signal would terminate the iterations.  \nFrom the explanation above, it is obvious that $\\mathrm{PI}^{2}$ and EDA are integrated to provide a probabilistic exploratory searching in reinforcement learning algorithms. One important modification of EDA in this method is to extend the estimation of distribution over bits to individuals. This extension can save time spending on computing and moreover release the problem of converging at local optimum point.  \nThis method could be applied to not only the robotic imitation learning domain but also other domains which can describe systems in equation, which is well accepted.  \nApplying this method in robotic imitation learning require developing a nonlinear system following the form of equation (2), which can generate motion paths.  \nIn this paper, we choose Dynamic Movement Primitive (DMP) which perfectly math the form of equation (2). DMP is proposed by Ijspeert in 2002 [8].  \nThe formulation of the DMP algorithm is shown as differential equations:  \n$$\n\\begin{aligned}\n& \\tau \\dot{z}=\\alpha_{z}\\left(\\beta_{z}(g-y)-z\\right) \\\\\n& \\tau \\dot{y}=z+f\n\\end{aligned}\n$$  \n$f$ is a Receptive Field Weighted Regression (RFWR) model [16]:  \n$$\nf=\\frac{\\sum_{i=1}^{N} \\psi_{i} \\theta_{i} v}{\\sum_{i=1}^{N} \\psi_{i}}\n$$  \nwhere  \n$$\n\\Psi_{i}=\\exp \\left(-h_{i}\\left(\\frac{x}{\\theta}-c_{i}\\right)^{2}\\right)\n$$  \n$\\Psi_{i}$ are Gaussian basis function with a center $c_{i}$ and a bandwidth $h_{i} . \\theta_{i}$, also considered as primitive in policies, is the parameter we want to teach the robot to learn. Given a demonstration, robot needs to learn these parameterized policies through iterations.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "topics": [
        "selection"
      ],
      "generated_at": "2025-06-07 21:28:21",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What distinguishes the efficiency of sampling a new point using the Generative Topographic Mapping (GTM) model, specifically regarding the latent variable range extension compared to previous approaches?",
      "answer": "The GTM sampling method extends the range of the latent variables by 20%, sampling from [-1.1, 1.1]^(m-1) to explore more ranges, while previous approaches used a smaller range, [-1, 1]^(m-1), potentially limiting the coverage of the Pareto Set. This range extension in GTM sampling aims to improve exploration along the central manifold.",
      "chunk_id": 6209,
      "paper_id": "Modelling the population distribution in multi-objective optimization by generative topographic mapping",
      "paper_title": "Modelling the population distribution in multi-objective optimization by generative topographic mapping",
      "paper_year": "2006",
      "chunk_content": "The population in a MOEA for (1) will hopefully approximate to the PS and be uniformly distributed around the PS as the search goes on. Therefore, we can envisage the solutions in the population as independent observations of a random vector whose center is an approximation of the PS of (1). Since the PS is a piecewise continuous $(m-1)$  \n[^0]\n[^0]:    ${ }^{1}$ The source codes are from http://www.ncrg.aston.ac.uk/GTM  \ndimensional manifold, a promising solution $x$ can be regarded as an observation of the following $n$-D random vector:  \n$$\n\\xi=\\xi_{1}+\\xi_{2}\n$$  \nwhere $\\xi_{1}$ is uniformly distributed along a $(m-1)$ dimensional manifold $\\Phi . \\xi_{2}$ is a random noise vector. $\\Phi$ is called the central manifold of $\\xi$ in this paper. For simplicity, we assume that $\\xi_{1}$ and $\\xi_{2}$ are independent of each other.  \nUnder the above assumption, the modeling of promising solutions consists of two tasks: the modeling of the central manifold $\\Phi$ and noise $\\xi_{2}$.\nGiven a population, which is a data set in $R^{n}$, we apply the GTM with $(m-1)$ latent variables to it (where $m$ is the number of objectives) and obtain the values of $W$ and $\\beta$. In GTM training procedure, we set the range of the latent variable $v=\\left(v_{1}, \\ldots, v_{m-1}\\right)$ as:  \n$$\n-1 \\leq v_{i} \\leq 1 \\quad i=1,2, \\ldots, m-1\n$$  \nSince the population often can not cover the whole PS thus the central manifold found can only approximate part of the PS. To overcome this problem and explore more ranges, in [13], [14] and [15], the search range is extended along the center manifold when we do sampling. In this paper, this idea is implemented by extending the range of the latent variables by $20 \\%$.  \nSampling a new point $x$ from the model built by the GTM is quite straightforward. We can do it in the following way:  \nStep 1: Uniformly and randomly select a $v$ from $[-1.1,1.1]^{m-1}$. Set $x^{1}=y(v, W)$.\nStep 2: Sample $x^{2}$ from $N\\left(0, \\frac{1}{\\beta} I\\right)$.\nStep 3: Set $x=x^{1}+x^{2}$.\nwhere $m$ is the objective number, $I$ is a $n \\times n$ identity matrix and FORMULA_81 is the variable dimension.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "topics": [
        "objectives"
      ],
      "generated_at": "2025-06-07 21:28:23",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What data structures are required to implement an Incremental Support Vector Machine (ISVM) for a binary classification problem, and how are they used to maintain Karush-Kuhn-Tucker (KKT) conditions during incremental learning?",
      "answer": "To implement ISVM, you'll need data structures to represent the training data {x₁, ..., xN} and learning objective {y₁, ..., yN}, where yi ∈ {1, -1}. Specifically, you need to maintain sets for margin support vectors (S where gc = 0), error support vectors (E where gc ≤ 0), and remaining vectors (R where gc > 0), based on the KKT conditions. These sets are updated incrementally as new examples are added, ensuring that the dual parameters {α, b} continue to minimize the objective function W = (1/2) Σᵢⱼ αᵢ Qᵢⱼ αⱼ - Σᵢ αᵢ + b Σᵢ yᵢ αᵢ, where Qᵢⱼ = yᵢ yⱼ K(xᵢ, xⱼ) and K(xᵢ, xⱼ) is the kernel function.",
      "chunk_id": 8202,
      "paper_id": "Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine",
      "paper_title": "Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine",
      "paper_year": "2019",
      "chunk_content": "Support Vector Machine ( SVM ) [7] was proposed in 1964 , developed rapidly after the 1990s and spawned a series of improved and extended algorithms. The SVM becomes a wellknown learning method used for classification problems [8], and it is a generalized linear classifier for binary classification of data in supervised learning. Its decision boundary is the maximum-margin hyperplane that is solved for learning samples. Incremental Support Vector Machine (ISVM) is the combination of Online learning technology and the SVM. Incremental technology has been developed to facilitate bulk SVM learning [9] on very large data sets and has been widely used in the SVM community.  \nGiven the training data $\\left\\{x_{1}, \\cdots, x_{N}\\right\\}$ and learning objective $\\left\\{y_{1}, \\cdots, y_{N}\\right\\}$ in the classification problem, where each sample of training data contains multiple features and thus constitutes a feature space. The learning objective is a binary variable $y_{i} \\in\\{1,-1\\}$ representing negative class and positive class. A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane, which can be described as:  \n$$\n\\mathbf{w}^{\\mathbf{T}} \\times x+b=0\n$$  \nwhere $\\mathbf{w} \\in \\mathbb{R}^{l}$ and $b \\in \\mathbb{R}$.\nIn linear inseparable problems, the use of SVM with hard margins will generate classification errors, so a new optimization problem can be constructed by introducing loss function\non the basis of maximizing margins. The optimization problem of soft margin SVM is shown as follows [10]:  \n$$\n\\begin{gathered}\n\\operatorname{Minimize}_{(\\mathbf{w}, \\mathbf{b})} \\frac{1}{2}\\|\\mathbf{w}\\|^{2}+l \\cdot \\sum_{i=1}^{N} \\varepsilon_{i} \\\\\n\\text { subj. to : } y_{i}\\left(\\mathbf{w} \\times x_{i}+b\\right) \\geq 1-\\varepsilon_{i}, i=i \\cdots N\n\\end{gathered}\n$$  \nWhere $l$ is a constant and the second term of Equation (2) provides an upper bound for the error in the training data, and the first term makes maximum margin of separation between classes.\nwhen learning nonlinear SVMs, to simplify matters and then this quadratic program is typically expressed in its dual form:  \n$$\n\\min _{0 \\leq \\alpha_{i} \\leq l} W=\\frac{1}{2} \\sum_{i, j=1}^{N} \\alpha_{i} Q_{i j} \\alpha_{j}-\\sum_{i=1}^{N} \\alpha_{i}+b \\sum_{i=1}^{N} y_{i} \\alpha_{i}\n$$  \nWhere $Q_{i j}=y_{i} y_{j} K\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right), K\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right)=\\varphi\\left(x_{i}\\right) \\cdot \\varphi\\left(x_{j}\\right)$ is the given kernel function which to implicitly map into a higher (possibly infinite) dimensional feature space.  \nThe Karush-Kuhn-Tucker (KKT) condition uniquely defines the solution of dual parameters $\\{\\alpha, b\\}$, and minimizes the form (2):  \n$$\n\\begin{aligned}\n& g_{i}=\\frac{\\partial W}{\\partial \\alpha_{i}}=\\sum_{j=1}^{N} Q_{i j} \\alpha_{j}+y_{i} b-1= \\begin{cases}>0 & \\alpha_{i}=0 \\\\\n=0 & 0<\\alpha_{i}<l \\\\\n<0 & \\alpha_{i}=l\\end{cases} \\\\\n& h=\\frac{\\partial W}{\\partial b}=\\sum_{j=1}^{N} y_{j} \\alpha_{j}=0\n\\end{aligned}\n$$  \nThe KKT conditions partition the training data into three parts:\n$g_{c}=0$, the set $S$ of margin support vectors;\n$g_{c} \\leq 0$, the set E of error support vectors;\n$g_{c}>0$, the set R of the remaining vectors.\nWhen we increment the unlearned examples into the solution, our goal will be to keep all previously seen training data in KKT conditions simultaneously [5].",
      "question_type": "implementation focused",
      "complexity": "medium",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:28:26",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What benchmarking approach best assesses the effectiveness of a new scheduling algorithm against established heuristics like Johnson's rule, the longest processing time (LPT) rule, the shortest processing time (SPT) rule, and the first in first out (FIFO) rule for minimizing makespan in a two-stage flowshop?",
      "answer": "To benchmark a new scheduling algorithm against Johnson's rule, LPT, SPT, and FIFO, one should compare the makespan achieved by each algorithm on a common set of two-stage flowshop instances.  Specifically, for each instance, the makespan obtained by the new algorithm should be compared to the makespan obtained by Johnson's rule (optimal for makespan minimization in a two-stage flowshop with discrete machines), LPT (sequences jobs in descending order of processing times), SPT (sequences jobs in ascending order of processing times), and FIFO (sequences jobs based on ready times). Statistical measures, such as the average relative percentage deviation (ARPD) from the best solution found by any of the algorithms, should be used to quantify the performance differences.  Furthermore, statistical tests, such as the t-test or ANOVA, should be employed to determine if the differences in makespan are statistically significant across the benchmark instances.",
      "chunk_id": 12106,
      "paper_id": "Minimizing makespan in a no-wait flowshop with two batch processing machines using estimation of distribution algorithm",
      "paper_title": "Minimizing makespan in a no-wait flowshop with two batch processing machines using estimation of distribution algorithm",
      "paper_year": "2016",
      "chunk_content": "The job sequence-based representation is widely used in the literature for two-stage flowshop scheduling problems (Muthuswamy et al. 2012; Chen et al. 2014). Therefore, it is also adopted in our EDA. In this representation, the $i$ th number of the sequence denotes the job placed at position $i$. A numerical example is illustrated in Table 2.  \nIn order to guarantee the initial population with a certain quality and diversity, we construct the initial population in two ways. Firstly, some prior rules, including Johnson's rule, the longest processing time (LPT) rule, the shortest processing time (SPT) rule and the first in first out (FIFO) rule, are employed to generate initial individuals. Johnson's rule is one of the well-known heuristics in the literature and it provides an optimal solution for makespan minimisation in a two-stage flowshop with discrete machines. The LPT rule sequences the jobs in descending order of the sum of their processing times on both the machines and the SPT rule sequences the jobs in ascending order of the sum of their processing times on the machines. The FIFO rule is applied to the jobs based on their ready times. Secondly, the rest of the individuals in the initial population is generated randomly. Finally, a population with FORMULA_69 individuals is created.",
      "question_type": "comparison",
      "complexity": "advanced",
      "topics": [
        "evaluation metrics",
        "benchmarking procedures and experimental design",
        "statistical measures for algorithm comparison"
      ],
      "generated_at": "2025-06-07 21:28:30",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of binary transmission state (BTS) encoding in genetic algorithms (GAs) reduce the solution space compared to binary link state (BLS) encoding when minimizing network coding resources?",
      "answer": "The binary transmission state (BTS) encoding approach in genetic algorithms (GAs) represents the state of each transmission link, while the binary link state (BLS) encoding represents the state of each link. Because BTS focuses on transmission states, it inherently constrains the search space to valid transmission configurations, leading to a much smaller solution space compared to BLS. This reduction in solution space allows the GA to converge to better solutions more efficiently when minimizing network coding resources, as demonstrated by simulations comparing BTS and BLS encoding.",
      "chunk_id": 5197,
      "paper_id": "A compact genetic algorithm for the network coding based resource minimization problem",
      "paper_title": "A compact genetic algorithm for the network coding based resource minimization problem",
      "paper_year": "2012",
      "chunk_content": "In most of the previous research in network coding, coding is performed at all coding-possible nodes. However, to obtain an expected multicast throughput, coding may only be necessary at a subset of those nodes [9-11]. Figure 2 illustrates two network-coding-based data transmission schemes that could both achieve the maximum multicast throughput. Source $s$ expects to transmit two bits ( $a$ and $b$ ) to four sinks, $t_{1}, t_{2}, t_{3}$ and $t_{4}$. Scheme A adopts two coding-possible nodes, namely node $m$ and node $n$, as shown in Fig. 2(a). Nevertheless, the same throughput can also be obtained by scheme B in Fig. 2(b), where cod-\ning only occurs at node $w$. Due to the mathematical operations involved, network coding not only incurs additional cost such as computational overhead and transmission delay, but also consumes public resources, e.g. buffering and computational resources [12]. It is therefore important that the number of coding operations is kept minimized while the benefits of network coding are warranted. Unfortunately, this problem is NP-hard [9-11].  \nAlthough a large amount of research has been conducted on multicast routing problems by using advanced algorithms including evolutionary algorithms and local search based algorithms [13-17], a limited number of algorithms have been proposed in the literature of network coding based multicast. Most of these algorithms are based on either greedy methods or evolutionary algorithms. Langberg et al. [12] and Fragouli et al. [18] proposed different network decomposition methods and two greedy algorithms to minimize coding operations. However, the optimization of these algorithms depends on the traversing order of links. An inappropri-  \nate link traversal order leads to a deteriorated performance. Kim et al. investigated evolutionary approaches to minimize the required network coding resources [9-11]. In [9], a genetic algorithm (GA) working in an algebraic framework has been put forward. However, it is applied to acyclic networks only. This has been extended to a distributed GA to significantly reduce the computational time in [10]. In [11], the authors compare and analyse GAs with two different genotype encoding approaches, i.e. the binary link state (BLS) and the binary transmission state (BTS). Simulations show that compared to BLS encoding, BTS encoding has much smaller solution space and leads to better solutions. Besides, their GA-based algorithms perform outstandingly better than the two greedy algorithms in [12] and [18] in terms of the best solutions achieved. Nevertheless, as we observed in our present work, GAs (e.g. [11]) have still shown to be weak in global exploration, even though a greedy sweep operator follows the evolution to further improve the best individual. In our previous work [8], an improved quantuminspired evolutionary algorithm (QEA) has been developed to minimize the amount of coding operations. Simulation results demonstrate that the QEA outperforms simple GAs in many aspects including fast convergence. However, we observe in this paper that the improved QEA sometimes finds decent solutions at the cost of additional computational time. Recently, we also put forward a population based incremental learning (PBIL) to find the optimal amount of coding operations [19]. However, its main concern is how to apply network coding in delay sensitive applications. An extended compact genetic algorithm has thus been developed in this work to solve the highly constrained problems being concerned.",
      "question_type": "process",
      "complexity": "basic",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:28:32",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What implementation steps are required for the Estimation of Bayesian Networks Algorithm (EBNA) when using the 'score + search' method with the BIC score, and how does Algorithm B contribute to this process?",
      "answer": "Implementing EBNA with the 'score + search' method using the BIC score involves these steps: First, define the BIC score to evaluate how well a Bayesian network structure, denoted by S, represents the probability distribution of the selected individuals. Second, employ Algorithm B, a greedy search algorithm, to find the Bayesian network that maximizes the BIC score. Algorithm B starts with an arc-less structure and iteratively adds the arc that provides the maximum score improvement at each step. The algorithm terminates when no arc addition improves the score. Finally, calculate the parameters of the Bayesian network using maximum likelihood estimation based on the learned structure.",
      "chunk_id": 13000,
      "paper_id": "Average time complexity of estimation of distribution algorithms",
      "paper_title": "Average time complexity of estimation of distribution algorithms",
      "paper_year": "2005",
      "chunk_content": "```  \nFig. 1. Pseudocode for the EDA approach  \nUMDA. The Univariate Marginal Distribution Algorithm (UMDA) was proposed by Muhlenbein [4]. UMDA uses the simplest model to estimate the joint probability distribution of the selected individuals at each generation, $p_{l}(\\mathbf{x})$. This joint probability distribution is factorized as a product of independent univariate marginal distributions, which are usually calculated by maximum likelihood estimation.  \nTREE. Baluja and Davies [5] proposed an algorithm called COMIT. This algorithm uses a probabilistic model that considers second-order statistics. The dependency structure between the variables forms a tree. The tree structure of the probability distribution of the individuals selected at each generation is estimated using the algorithm proposed by Chow and Liu. The parameters, given the structure, are calculated by maximum likelihood estimation. In the original work, COMIT applied a local optimizer to each individual generated. We have eliminated this step in order to carry out a fair comparison. In other words, this paper refers to TREE as an algorithm that does not apply a local optimizer.  \nEBNA. The Estimation of Bayesian Networks Algorithm (EBNA) was introduced by Larranaga et al. [6]. This algorithm allows statistics of unrestricted  \norder in the factorization of the joint probability distribution. This distribution is encoded by a Bayesian network that is learned from the database containing the individuals selected at each generation. Formally, a Bayesian network is a pair, $(S, \\boldsymbol{\\theta})$, representing a graphical factorization of a probability distribution. The structure, $S$, is a directed acyclic graph which reflects the set of conditional (in)dependencies among the variables, while $\\boldsymbol{\\theta}$ is a set of parameters for the local probability distributions associated with each variable.  \nIn EBNA learning the probabilistic model at each generation of the algorithm means learning a Bayesian network from the individuals selected. There are different strategies to learn the structure of a Bayesian network. Here the 'score + search' method is used. In this method, given a database, $D$, and a Bayesian network whose structure is denoted by $S$, a value which evaluates how well the Bayesian network represents the probability distribution of FORMULA_7 is assigned. Different EBNA algorithms can be obtained by using different scores. In this work we have used the BIC score (based on penalized maximum likelihood).  \nAfter defining the score, we have to set a search process to find the Bayesian network that maximizes the score given the set of individuals selected. As we need to find an adequate model structure as quickly as possible, a simple algorithm which returns a good structure, even if not optimal, is preferred. An interesting algorithm with these characteristics is Algorithm B. Algorithm B is a greedy search which starts with an arc-less structure and, at each step, adds the arc with the maximum score improvement. The algorithm finishes when there is no arc whose addition improves the score. The parameters of the Bayesian network are calculated by maximum likelihood.",
      "question_type": "practical application",
      "complexity": "medium",
      "topics": [
        "comparison"
      ],
      "generated_at": "2025-06-07 21:28:35",
      "generation_style": "practical_application"
    },
    {
      "question": "What mathematical properties ensure that the entropy-based on-demand evaluation strategy (ODES) converges to an optimal solution, and how does the computational complexity of ODES, when combined with algorithms like the Bayesian optimization algorithm (BOA) or extended compact genetic algorithm (ECGA), scale with the problem size, especially considering the inherent randomness of the EA population?",
      "answer": "The convergence of ODES depends on the properties of the search landscape and the ability of entropy to accurately reflect optimization progress. Monotonically decreasing entropy can indicate convergence, while fluctuating entropy may signal promising building blocks. The computational complexity of ODES, when integrated with BOA or ECGA, involves calculating the entropy value of evolutionary populations. The complexity of this calculation depends on the population size and the model used to compute entropy. Furthermore, the overall complexity is also influenced by the frequency of fitness function evaluations, which ODES aims to reduce. A rigorous analysis would require bounding the number of fitness evaluations needed to reach a satisfactory solution, considering the trade-off between the cost of entropy computation and the savings from reduced fitness evaluations. For example, if the entropy calculation has complexity O(n log n) and reduces the number of fitness evaluations from O(n^2) to O(n), the overall complexity could be improved, but this depends on the specific characteristics of the problem and the implementation details of BOA or ECGA.",
      "chunk_id": 4937,
      "paper_id": "Entropy-based efficiency enhancement techniques for evolutionary algorithms",
      "paper_title": "Entropy-based efficiency enhancement techniques for evolutionary algorithms",
      "paper_year": "2012",
      "chunk_content": "Conveniently, a large corpus of efficiency enhancement techniques (EETs) exists for EAs. In fact, Sastry [41] mentions a classification of EETs, known as the Illinois Decomposition, which categorizes various techniques into four groups: parallelization, hybridization, time continuation/utilization, and evaluation relaxation. Parallelization [6] manages multiple processors at the same time to distribute computational cost (e.g., processing time or power) according to some topologies (e.g., master-slave, fine-grained, coarse-grained, or hierarchical). Hybridization [12,43] combines effective global-search EAs with some efficient local-search methods by taking advantage of domain-specific knowledge to speed up the optimization process. Time continuation [11,46] considers the optimal usage of computational resources to obtain acceptable solutions; for example, practitioners can choose between an EA that has a small population for many generations and an EA that has a large population for a few generations. Evaluation relaxation methods [13,42,44] try to partially replace accurate, but expensive, fitness functions with estimation/approximation models that are more error-prone, but also more economical. Notably, Jin [18] conducted a comprehensive survey of fitness approximations in EAs; however, a more detailed discussion of the aforementioned methods is beyond the scope of this paper.  \nIn this paper, we analyze the inherent randomness of the EA population. More specifically, we discuss the variation tendency of the entropy value of a population, calculated with respect to some model. The entropy observation, combined with the characteristics of the building block structure of the problem at hand, can be used to develop several strategies that enhance the performance of the evolutionary optimization process. This paper demonstrates that there are different types of entropy variations, depending on the search landscape. In some cases, where the entropy value of the population has been monotonically reduced, it can be used to indicate the optimization progress (e.g., initialization, stabilization, or convergence). For other cases, in which the randomness of a population has fluctuated, the entropy value can still be used to signal the existence of an individual with promising or unpromising building blocks. Based on these entropy computations, we can design an on-demand evaluation strategy (ODES) to recognize which individuals should be evaluated by the fitness function and which individuals can be selected without requiring exact evaluations. Note that some of our preliminary research on this topic has been published elsewhere [29,30], but in this paper, we generalize the method, and conduct extensive experiments in terms of both theoretical and real-world problems. In addition, we emphasize three advantages of our method: first, the entropy value of evolutionary populations is an inherent characteristic of an EA itself; thus, ODES can be used without requiring any external approximation function. Second, because the entropy measurement reflects the current status of the optimization process, our method can adapt to changes in the population. Third, since ODES has a wide applicability to different types of EAs, from traditional GAs to advanced EDAs, such as Bayesian optimization algorithm (BOA [36]) or extended compact genetic algorithm (ECGA [14]), this research is useful to many fields.  \nNote that the proposed technique is categorized as an evaluation relaxation method. Thus, it can be combined with other EETs to accelerate the algorithm's performance. For instance, ODES can be incorporated with a local searcher to effectively estimate the fitness values of individuals in the neighborhood of a candidate solution. More details on this issue; however, are beyond the scope of this work.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:28:38",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What distinguishes the efficiency of activity-based policies versus resource-based policies in the context of the stochastic resource-constrained project scheduling problem (SRCPSP)?",
      "answer": "In the SRCPSP, activity-based and resource-based policies serve as heuristics. Resource-based policies, when viewed as functions mapping activity durations to start times, lack monotonicity and continuity. This characteristic has led most researchers to avoid resource-based policies in favor of activity-based approaches.",
      "chunk_id": 4695,
      "paper_id": "An estimation of distribution algorithm and new computational results for the stochastic resource-co",
      "paper_title": "An estimation of distribution algorithm and new computational results for the stochastic resource-constrained project scheduling problem",
      "paper_year": "2015",
      "chunk_content": "The stochastic resource-constrained project scheduling problem (SRCPSP) is concerned with scheduling a set of precedence related activities with stochastic durations subject to scarce resources, such that the expected duration of the project (makespan) is minimized (see, e.g., Herroelen and Leus 2005). In case of deterministic activity durations the SRCPSP reduces to the RCPSP. The latter has  \n[^0]\n[^0]:    C. Fang $\\cdot$ L. Wang $\\cdot$ C. Mu  \nTsinghua National Laboratory for Information Science and Technology (TNList), Department of Automation, Tsinghua University, Beijing 100084, China\nR. Kolisch ( $\\square$ )  \nTUM School of Management, Technische Universitat Munchen, Arcisstr. 21, 80333 Munich, Germany\ne-mail: rainer.kolisch@tum.de  \nbeen shown by Blazewicz et al. (1983) to be NP-hard. Research on the RCPSP has long been employed and its outcome is comprehensive (see for example Brucker et al. 1999; Neumann et al. 2003; Kolisch and Hartmann 2006 as well as Hartmann and Briskorn 2010). However, solving the RCPSP is of limited use for the SRCPSP due to the following reasons. Firstly, a schedule which provides a start time for each activity cannot be employed in the case of stochastic activity durations. Secondly, Heller (1981) shows that project duration is systematically underestimated if the RCPSP is solved for expected activity durations instead of obtaining the expected project duration, subject to the distribution of the activity durations, i.e. $C_{\\max }\\left(E\\left(d_{1}\\right), \\ldots, E\\left(d_{J}\\right)\\right) \\leq E\\left(C_{\\max }\\left(d_{1}, \\ldots, d_{J}\\right)\\right)$. The difference between $C_{\\max }$ $\\left(E\\left(d_{1}\\right), \\ldots, E\\left(d_{J}\\right)\\right)$ and $E\\left(C_{\\max }\\left(d_{1}, \\ldots, d_{J}\\right)\\right)$ may become arbitrarily large with increasing number $J$ of activities and increasing variances of activity durations. Thirdly, project planners are not only interested in the expected project makespan but in more informative measures such as the entire distribution of the project makespan or value at risk measures. Hence, there is a legitimate interest in conducting research on the SRCPSP. Nevertheless, research on this topic is still limited.  \nFor solving the SRCPSP, one has to resort to so-called scheduling policies (see Mohring et al. 1984) to which we will also refer simply as policies in the following. The latter transforms a scenario, which for each activity yields a duration drawn from the distribution function of that activity into a schedule, i.e. a start time for each activity. Stork (2000) provides a survey of different classes of policies including information on dominance relationships. For heuristics, two policy classes-neither of which predominates-are most common: Activity-based policies and resource-based policies. Stork (2001) has shown that when interpreted as a function which maps a vector of activity durations into a vector of activity start times resource-based policies are neither monotone nor continuous. As a consequence, the majority of researchers have refrained from employing resource-based policies.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "topics": [
        "scheduling"
      ],
      "generated_at": "2025-06-07 21:28:40",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What data structures are required to implement the link selection process in the Steiner tree algorithm, considering the influence of parameters alpha and beta on edge selection probability?",
      "answer": "To implement the link selection process, you'll need data structures to represent the graph topology, such as adjacency lists or matrices. Specifically, for calculating the probability p(i, j) = alpha1 * exp[l(i, j) / (beta1 + max l)], you need to store the Euler distance l(i, j) between nodes i and j, and the maximum Euler distance max l. The values of alpha1 and beta1, which control the number of total links and short links respectively, must also be stored. When alpha is large, you should prioritize edges used more frequently, while when beta is large, prioritize edges with lower cost. These priorities can be implemented using priority queues or sorted lists to efficiently select the next link to add to the solution.",
      "chunk_id": 4692,
      "paper_id": "An improved EDA for solving Steiner tree problem",
      "paper_title": "An improved EDA for solving Steiner tree problem",
      "paper_year": "2015",
      "chunk_content": "How to select a new link and add it to the current solution plays an important role in the developed algorithm. In Equation 2, when $\\alpha$ goes large, mean edge used more frequency probability which dominated the link selection. Otherwise, the link cost value has a greater impact when $\\beta$ goes large enough. The orthogonal experimental design has already been used in many fields. This method makes use of the mathematical statistics which selects representative experimental points from quantities of experiments.  \nThe topology of 50 nodes was used in this experiment. The group member was set to take up to $15 \\%$ of the total number of topology nodes, and all the group members are selected randomly. We selected part of the parameter values out of $\\alpha$ and $\\beta$ to conduct the experiment. In Table I, taking the cost value and time into account, we set $\\alpha=0.9$ and $\\beta=0.1$.\nThe topology generated every two nodes $i$ and $j$ which have the probability $p(i, j)=\\alpha 1 \\times \\exp \\left[\\frac{l(i, j)}{\\beta 1+\\max l}\\right]$ to be connected. $l(i, j)$ represents the Euler distance between the node $i$ and $j$, and $\\max l$ is the maximum value of $l(i, j) . \\alpha 1$ controls the number of the total links, and $\\beta 1$ controls the number of short links. We use the two kinds of topologies which is good for testing the algorithm in many aspects.  \nFigures 7 and 8 illustrate the solution cost and iteration time with different number of destination node in the topology of 100 nodes. It is obvious that the more the destination nodes the higher the cost of the Steiner tree as shown in Figure 7. With the increase of the number of destination nodes, iteration of the algorithm does not rise according to a linear way. Owing to the more destination nodes, the fewer the candidate Steiner trees cover all the destination nodes, and the easier the algorithm converges. However, the time increases significantly to find a candidate Steiner tree covering all the destination nodes. The iteration does not increase continuously. Figure 8 shows that  \nTable I. orthogonal experiments of the algorithm parameters.  \n[IMAGE6]  \nFigure 7. Comparison of tree cost with different node scales.\n[IMAGE7]  \nFigure 8. Comparison of iteration with different node scales.\nthe number of iterations reaches its maximum value of 20 when the number of destination is 50 , i.e. FORMULA_130 of the total node number.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "topics": [
        "design"
      ],
      "generated_at": "2025-06-07 21:28:43",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How should experimental evaluation of the CAEA algorithm's performance be conducted, considering the interplay between copula EDA and Alopex operations?",
      "answer": "To evaluate CAEA, one must measure its ability to minimize complex functions, focusing on convergence speed and precision. Key steps involve initializing a population with parameters like population size and variable dimension. The algorithm's performance is then assessed by sorting function values in ascending order, selecting a promising solution set using truncation selection, and estimating Gaussian marginal distributions with average value $\\mu_{i}$ and standard deviation $\\bar{\\sigma}_{i}$. Statistical measures must quantify the impact of generating new solutions via sampling $v \\sim$ $F=L S^{-1}[\\varphi^{-1}]$ and updating the population with a replacement rate $r$. The evaluation must include the calculation of annealing temperature $T^{k}$ and probability $P_{0}^{k}$, alongside the walking step $\\Delta_{g}^{k}$, to assess the algorithm's exploration of the search space, in comparison to the original AEA algorithm.",
      "chunk_id": 4726,
      "paper_id": "A modified Alopex-based evolutionary algorithm and its application on parameter estimation",
      "paper_title": "A modified Alopex-based evolutionary algorithm and its application on parameter estimation",
      "paper_year": "2015",
      "chunk_content": "Though the AEA algorithm performs well in some optimization domains, it is evident that the algorithm exposes some problems such as falling into local minima, converging too early and so on. Further research has been done to produce candidates more reasonably based on the mechanism of AEA.  \nIn AEA, two different individuals are chosen randomly, Alopex operation is executed and the newly individual is generated, substitute or reserve the old individual depends on which performs better. In this paper, more excellent individuals can be acquired as an elitist set by a novel idea that an estimation of distribution algorithm based on copula is embedded into AEA. In the newly algorithm (CAEA), EDA based on copula theory is used to generate more prominent candidate population, which is then passed to AEA for related calculation, with more global search information provided. In the point of evolutionary strategy, both of the two algorithms have an impact on the evolutionary direction of population and the characters of CAEA. CAEA not only takes advantage of rapid convergence of copula EDA, and its unique simplified handling model for complex construction of variables on the macro level, but has the merits of strong local searching ability and high searching precision of AEA on the micro level.  \nIn this paper, the minimization of function is focused on, and the detailed implementation procedures of CAEA can be described as follows:  \nStep1: Initialize the population randomly within the search scope and parameters such as population size, variable dimension, maximum number of iteration, truncation selection probability and so on. Calculate the value of objective function. Set $k=1$.\nStep2: Sort the function value in ascending order, select promising solution set $s$ by truncation selection. Estimate Gaussian marginal distribution of each variable based on the promising solution set $s_{o}$ : Calculate average value $\\mu_{i}$ and standard deviation $\\bar{\\sigma}_{i}$ of each variable in $s$ according to Eq. (9).\nStep3: Generate new solutions: Firstly, sample $v \\sim$ $F=L S^{-1}\\left[\\varphi^{-1}\\right]$; Secondly, sample $y_{i} \\sim U(0,1)$, and the vector $\\left(u_{1} \\mu_{2}, \\ldots \\mu_{n}\\right)$ is calculated by $u_{1}=$ $\\varphi^{-1}\\left(\\ln \\left(y_{1}\\right) / v\\right)$; Lastly, the newly individuals are generated by calculating $x_{i}=F_{i}^{-1}\\left(u_{i}, \\bar{\\mu}_{i}, \\bar{\\sigma}_{i}\\right)$.\nStep4: Make judgments on whether it is beyond the feasible region or not for individuals in the set, make some corrections if necessary. Update the old population by the replacement of the new individuals with the rate of $r$ and the newest population $P_{i}$ is acquired.\nStep5: Population $P_{i}$ is generated as follows: Suppose that the individuals in population $P_{i}$ have a sequence number from 1 to $u$, choose an integer $w$ within [2, $u$ ], then rearrange the individual order in population $P_{i}$  \naccording to the sequence $[w, w+1, \\ldots, u, 1,2, \\ldots, w-1]$ to form the population $P_{t}$.\nStep6: In population $P_{t}$ and $P_{s}$, calculate the difference of the two objective function values. And $C_{0}^{k}$, annealing temperature $T^{k}$ and the probability $P_{0}^{k}$ is available according to Eq.(1)-Eq.(3).\nStep7: Figure out the walking step $\\Delta_{g}^{k}$, generate a trial variable $\\left(\\chi_{0}^{\\mathrm{K}}\\right)^{\\prime}$ in $P_{t}$ successively, from Eq. (4) to Eq. (6). The changed population $P_{t}$ is renamed as FORMULA_84.",
      "question_type": "implementation",
      "complexity": "advanced",
      "topics": [
        "evolutionary"
      ],
      "generated_at": "2025-06-07 21:28:46",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "How does the algorithmic mechanism of the Estimation of Distribution Algorithm (EDA) use probability distributions to explore the solution space when estimating stock returns?",
      "answer": "The EDA uses dynamic populations to explore the solution space, driven by a propagation mechanism based on differences between the best individuals. To preserve diversity, the algorithm employs normal probability distributions to sample new solutions. The fitness function is defined by the error between the model's output and the actual time series of the stock's returns. This allows the algorithm to relate the values of variables, such as temporal variables associated with volatility, to the estimation of stock returns.",
      "chunk_id": 4828,
      "paper_id": "Daily Ecopertrol Stock Performance Estimate by Using Estimation of Distribution Algorithms (EDAs)",
      "paper_title": "Daily Ecopertrol Stock Performance Estimate by Using Estimation of Distribution Algorithms (EDAs)",
      "paper_year": "2012",
      "chunk_content": "De acuerdo con los principios de los EDA's, la estructura de solucion o individuo, posee una serie de genes que permiten relacionar los valores de las variables que conforman el precio de la accion, con la estimacion de sus rendimientos, y en donde la funcion de aptitud, esta definida en terminos del error obtenido por el modelo frente a la estimacion de los valores que conforman la serie de tiempo de los rendimientos de la accion. Para la transformacion de las posibles soluciones o individuos, el Algoritmo EDA propuesto, incorpora tres poblaciones dinamicas que exploran el espacio de solucion del problema, mediante un mecanismo propagador de las diferencias entre los mejores individuos, y el cual posee una estrategia orientada a preservar la diversidad de las poblaciones por medio de distribuciones de probabilidad\nnormales. Los resultados obtenidos por el modelo propuesto, permitieron proyectar en el corto plazo, valores futuros de la serie temporal de los rendimientos de la accion de Ecopetrol, a partir de una serie de variables temporales asociadas, las cuales aportaron informacion relevante sobre la posible volatilidad, y el comportamiento de la accion. Finalmente, se presentan una serie de conclusiones y recomendaciones, que permiten identificar una serie de tendencias de desarrollo en esta area del conocimiento, y que permitiran extender este tipo de modelos, a otros comportamientos observados para diferentes acciones, tanto en el mercado colombiano, como en el mercado internacional, dando una mayor confiabilidad a la toma de decisiones en los mercados financieros.",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "topics": [
        "optimization"
      ],
      "generated_at": "2025-06-07 21:28:49",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "How should practitioners implement a Voronoi-based initialization method for distributed Estimation of Distribution Algorithms (EDAs) to improve search space coverage?",
      "answer": "To implement Voronoi-based initialization for distributed EDAs, first partition the initial search space into Voronoi cells, isolating each island's search region. Then, apply a heuristic method to uniformly cover each Voronoi region, emphasizing search in these starting regions during early generations. Reduce interaction between islands, as excessive individual exchange dilutes the benefits of the Voronoi configuration. This approach improves performance by reducing the modality of constrained regions and enhancing convergence speed, particularly for EDAs influenced by the initial population.",
      "chunk_id": 11729,
      "paper_id": "A new initialization procedure for the distributed estimation of distribution algorithms",
      "paper_title": "A new initialization procedure for the distributed estimation of distribution algorithms",
      "paper_year": "2011",
      "chunk_content": "This paper presents a new initialization method for the distributed estimation of distribution algorithms. The proposed initialization is based on Voronoi cells that isolate the initial search space of each island and uses a heuristic method for uniformly covering each region of the search space. Several parameter values have been tested on the standard CEC'05 continuous benchmark suite. To analyze the results, non-parametrical tests were applied. The obtained results show that the best overall performance is  \n[^0]\n[^0]:    ${ }^{2}$ The evolution of the average scores in most of the other functions follows a similar pattern.  \nFig. 3 Evolution of the average score for the $f 20$ function\n[IMAGE_3]  \nTable 6 Number of individuals exchanged between the best configurations  \nobtained with Voronoi configurations and that, in general, the Voronoi configurations tend to improve the results of the traditional initialization method. The partition of the search space reduces the modality of the constrained regions and offers the possibility, at least in the earliest generations, to emphasize the search in the starting regions. Thus, the search for the optimal solutions is more effective. The analysis also discovered that the best Voronoi configurations need less interaction between the islands than the best uniform configuration. With a greater exchange of individuals, the beneficial properties of the proposed initialization get diluted. The Voronoi configurations also outperformed their equivalent population-sized (both global and island population sizes) sequential EDAs. This approach has been proposed for EDAs, since they are more influentiated by the initial population than other evolutionary algorithms with more explorative mechanisms. However, this procedure could also improve the performance of other evolutionary algorithms by reaching a higher score or helping them to improve their convergence speed.  \nAcknowledgments This work was supported by the Madrid Regional Education Ministry and the European Social Fund and financed by the Spanish Ministry of Science TIN2007-67148. The authors thankfully acknowledge the computer resources, technical expertise and assistance provided by the Centro de Supercomputacion y Visualizacion de Madrid (CeSViMa) and the Spanish Supercomputing Network. We would also like to thank the reviewers for their suggestions.",
      "question_type": "practical application",
      "complexity": "medium",
      "topics": [
        "search"
      ],
      "generated_at": "2025-06-07 21:28:53",
      "generation_style": "practical_application"
    }
  ]
}