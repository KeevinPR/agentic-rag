{
  "metadata": {
    "generation_date": "2025-06-27 00:44:10",
    "target_questions": 200,
    "total_questions": 200,
    "generation_method": "chunk_based",
    "statistics": {
      "successful": 200,
      "failed_generation": 0,
      "duplicate_skipped": 1,
      "total_attempts": 201
    }
  },
  "questions": [
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of evaluating antibody diversity, using antibody concentration T, contribute to the algorithm's ability to avoid convergence direction deviation?",
      "topics": [
        "convergence"
      ],
      "answer": "The algorithm evaluates antibody diversity by calculating the antibody concentration T, which is expressed as the proportion of similar antibodies in the population with the total number of antibodies Q. By suppressing antibodies with high concentrations and low fitness, and promoting antibodies with low concentrations and high fitness, the algorithm aims to avoid the convergence direction deviation caused by a single antibody, thus ensuring the accuracy of the prediction results. This process jointly determines the expected reproduction rate R of the antibody, based on individual fitness fI(a) and the antibody concentration T.",
      "chunk_id": 3510,
      "paper_id": "Research on gas emission quantity prediction model based on EDA-IGA",
      "paper_title": "Research on gas emission quantity prediction model based on EDA-IGA",
      "paper_year": "2023",
      "chunk_content": "In order to make the prediction results accurate, the model does not deviate in a single direction, and the diversity of the population is evaluated. The measures are as follows: The diversity evaluation of the antibody is carried out by Eq. (3), and the expected\n[IMAGE5]  \nFig. 6. Flow chart of gas emission quantity prediction model.  \nreproduction rate R of the antibody is jointly determined by the individual fitness $\\mathrm{f}_{\\mathrm{I}(\\mathrm{a})}$ and the antibody concentration T . Based on this, the algorithm suppresses antibodies with high concentrations and low fitness, and promotes antibodies with low concentrations and high fitness, and evaluates the diversity of the population at one time.  \nThe expression of antibody concentration T is expressed by the proportion of similar antibodies in the population with the total number of antibodies Q .  \nFORMULA_38  \nEvaluating the diversity of antibodies in the model to avoid the convergence direction deviation caused by a single antibody, so as to ensure that the prediction results of the model are sufficiently accurate.",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:12",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm (EDA) for biped gait generation using the EDASQ approach, what specific steps are involved in formulating the probability distribution functions for conjoint poses, especially when prior knowledge is limited?",
      "topics": [
        "convergence"
      ],
      "answer": "When formulating probability distribution functions for conjoint poses in EDASQ with limited prior knowledge, the approach involves using a spline-based probability function. Specifically, Catmull-Rom cubic spline function $f_{c}$ is used, defined for $v_{j} \\[CDATA[\\leq]]> x \\leq v_{j+1}$ as \\begin{equation*} f_{c}(x)= \\sum_{i=1}^{N} \\alpha_{i}\\left|x-v_{i}\\right|^{3} \\end{equation*}, where $\\alpha_{i}$ are coefficients and $v_{i}$ are interpolation samples.  To reproduce the interval $\\left[v_{j}, v_{j+1}\\right]$, four control points $W_{1}, W_{2}, W_{3}, W_{4}$ are set such that $w_{x_{2}}=v_{j}$ and $w_{x_{3}}=v_{j+1}$, with $\\Delta x = v_{j+1} - v_{j}$. The function $f_{c}(x)$ is then calculated using these control points as shown in the equations, which ensures the spline function approximates the optimal cubic spline.",
      "chunk_id": 5591,
      "paper_id": "Estimating Biped Gait Using Spline-Based Probability Distribution Function With Q-Learning",
      "paper_title": "Estimating biped gait using spline-based probability distribution function with Q-learning",
      "paper_year": "2008",
      "chunk_content": "There are two factors that affect the learning quality of EDA: the probability model and the updating rule. In this paper, we look at both factors to develop a new EDA with splinebased probability function and Q-learning-based updating rule (EDASQ), which is able to more efficiently generate and optimize dynamically stable and low energy cost biped gaits. To deal with the relationship between the parameters of conjoint poses, their probability distribution functions are formulated without prior knowledge. Q-learning operates as a very efficient updating rule to improve the distribution function with simple rewards. By means of the proposed EDASQ, desired biped gaits are generated and optimized with acceptable convergence time. Some suggestions on working scope for motors at joints can also be achieved through analyzing the conditional probability functions.  \nThe experimental results show that the proposed EDASQ is significantly better than traditional EDA in terms of convergence speed to achieve dynamically stable and energy-efficient biped gaits. The generated gaits can also be used to drive our  \nhumanoid soccer robot, RE, which is one of the foremost leading soccer-playing humanoid robots in the RoboCup Humanoid League. To the best of our knowledge, the proposed EDASQ is the first such kind of work in the framework of EDA and biped gait generation and optimization.  \nBased on the results of this paper, the body dynamics of the mechanical robot will be studied with transition probability models in future work. Our research challenge lies in the interpretation of transition probability models for biped locomotion so that we can progress toward a better understanding of human locomotion and extend the results to better control of humanoid robots.\nCatmull-Rom cubic spline function $f_{c}$ is a suboptimal realization of the cubic spline function $f_{\\mathrm{s}}$ obtained by regularization theory.  \nFor $v_{j} \\leq x \\leq v_{j+1}, 1 \\leq j<N$,  \n$$\n\\begin{aligned}\nf_{c}(x)= & \\sum_{i=1}^{N} \\alpha_{i}\\left|x-v_{i}\\right|^{3} \\\\\n= & \\alpha_{1}\\left|x-v_{1}\\right|^{3}+\\cdots+\\alpha_{j-1}\\left|x-v_{j-1}\\right|^{3} \\\\\n& +\\alpha_{j}\\left|x-v_{j}\\right|^{3}-\\alpha_{j+1}\\left|x-v_{j+1}\\right|^{3} \\\\\n& -\\alpha_{j+2}\\left|x-v_{j+1}\\right|^{3}-\\cdots-\\alpha_{N}\\left|x-v_{N}\\right|^{3}\n\\end{aligned}\n$$  \nwhere $\\alpha_{i}$ are coefficients and $v_{i}$ are interpolation samples. $i=1, \\ldots, N, N$ is the number of samples. Collecting the terms of equal degree, $f_{\\mathrm{s}}$ can be expressed as  \n$$\nf_{\\mathrm{s}}(x)=A x^{3}+B x^{2}+C x+D\n$$  \nTo reproduce the interval $\\left[v_{j}, v_{j+1}\\right]$ with Catmull-Rom cubic spline, four control points $W_{1}, W_{2}, W_{3}, W_{4}$ are set on the curve equally as $\\Delta x=v_{j+1}-v_{j}, w_{x_{2}}=v_{j}, w_{x_{3}}=v_{j+1}$. Thus  \n$$\n\\begin{aligned}\nf_{c}(x)= & \\frac{1}{2}\\left(-w_{y_{1}}+3 w_{y_{2}}-3 w_{y_{3}}+w_{y_{4}}\\right)\\left(\\frac{x-v_{j}}{\\Delta x}\\right)^{3} \\\\\n& +\\frac{1}{2}\\left(2 w_{y_{1}}-5 w_{y_{2}}+4 w_{y_{3}}-w_{y_{4}}\\right)\\left(\\frac{x-v_{j}}{\\Delta x}\\right)^{2} \\\\\n& +\\frac{1}{2}\\left(-w_{y_{1}}+w_{y_{3}}\\right)\\left(\\frac{x-v_{j}}{\\Delta x}\\right)+w_{y_{2}} \\\\\n= & \\bar{A} x^{3}+\\bar{B} x^{2}+\\bar{C} x+\\bar{D} \\\\\n= & f_{\\mathrm{s}}(x)\n\\end{aligned}\n$$  \nThese calculations show that Catmull-Rom spline with properly chosen control points is equivalent to the optimal cubic spline everywhere between $v_{j}$ and FORMULA_216.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:15",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the branch-and-bound (B\\&B) algorithms used for robotic assembly line balancing (RALB), how does the computational complexity scale with problem size, and what specific limitations arise in terms of storage space and computation time when solving large-scale RALB-1 problems, where the objective is to minimize the number of workstations with a given cycle time?",
      "topics": [
        "optimization"
      ],
      "answer": "The frontier-search based branch-and-bound (B\\&B) algorithm, when applied to the RALB-1 problem, faces limitations in scalability due to the exponential growth of the search space. Although heuristic rules are incorporated to reduce the search space, the storage space required to maintain the search frontier and the computation time needed to explore the branching tree increase rapidly with problem size. This exponential scaling of storage and computation renders the B\\&B based method impractical for solving large-scale RALB-1 problems, as the resources required become prohibitively large.",
      "chunk_id": 9665,
      "paper_id": "An estimation of distribution algorithm with branch-and-bound based knowledge for robotic assembly line balancing",
      "paper_title": "An estimation of distribution algorithm with branch-and-bound based knowledge for robotic assembly line balancing",
      "paper_year": "2021",
      "chunk_content": "During recent years, advanced automation techniques have been applied to assembly systems to improve flexibility and productivity. One of the most successful applications is the robotic assembly line, which uses robots to replace human labors. Compared to manual assembly line, the robotic assembly line can speed up the assembly process and reduce the work stress of workers [1]. Moreover, it provides more favorable conditions for decision-makers to design and manage the assembly line.  \n[^0]Assembly line balancing (ALB) problem is a typical problem in the design and management of assembly lines. It aims to balance the workload among different workstations by appropriately determining the task assignments subject to operational constraints. The ALB problem can be classified into four types according to the objectives, i.e. ALB-1, ALB-2, ALB-E and ALB-F [2, 3]. The objective of ALB-1 is to minimize the number of workstations with a given cycle time, while ALB-2 minimizes the cycle time with a predetermined workstation number. ALB-E attempts to maximize the line efficiency by minimizing the cycle time and workstation number simultaneously. ALB-F is a feasibility problem to figure out whether a feasible solution exists with a given combination of cycle time and workstation number. The most basic version of ALB is known as simple assembly line balancing (SALB) problem [2], which considers straight manual assembly lines with deterministic task time. The robotic assembly line balancing (RALB) problem can be regarded as the extension of SALB. Different  \n[^0]:    1) Ling Wang\nwangling@tsinghua.edu.cn\nBin-qi Sun\nsbq17@mails.tsinghua.edu.cn\n1 Department of Automation, Tsinghua University, Beijing 100084, China  \nfrom SALB, the decisions of RALB include not only the task assignment but also the robot assignment, which makes the problem more challenging.  \nSo far, some mathematical models and model-based optimization algorithms have been proposed for RALB with different objectives and problem assumptions. In Rubinovitz and Bukchin [4], the RALB was considered as a RALB-1 to minimize the workstation number with a given cycle time. They proposed a frontier-search based branch-and-bound (B\\&B) algorithm to solve the problem. Although some heuristic rules were incorporated to reduce the search space, the storage space and computation time of the B\\&B based method are still too large to solve large scale problems. Bukchin and Tzur [5] considered a flexible assembly line designing problem to minimize total equipment costs with a given cycle time. They developed a B\\&B algorithm to solve small scale problems and proposed a B\\&B based heuristic to solve large scale problems. However, the performance of the heuristic is sensitive to the algorithm parameter, which is hard to calibrate when solving practical problems with different scales. Tsai and Yao [6] developed a line-balancebased capacity planning heuristic, which determines the type and number of robots required in each workstation to minimize the deviation of the workstation output rate. In the heuristic, an integer programming model is developed to generate an initial solution. Then, special heuristic rules are designed to identify the bottleneck workstation and improve the initial solution by making task adjustments to the bottleneck workstation. However, the proposed heuristic was only tested on ten small scale instances. Kim and Park [7] developed an integer programming model for a special type of RALB and solved it using a cutting plane algorithm. However, the assignment of robots was considered to be fixed for each workstation instead of decision variables in the model.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:17",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How is the accuracy of the hypothetical parameters 'g' assessed using the relative error function, and what do the variables \\(t_u\\), \\(r_v\\), and \\(s_w\\) represent in this calculation?",
      "topics": [
        "optimization"
      ],
      "answer": "The accuracy of hypothetical parameters 'g' is assessed by minimizing the relative error function \\(G(g)\\), which compares the measured electric field intensity \\(E^{\\text{meas}}\\) with the computed electric field intensity \\(E^{\\text{comp}}\\). The variables \\(t_u\\), \\(r_v\\), and \\(s_w\\) represent the incident element, receiver element, and sample point in the frequency domain, respectively. The variables \\(n_t\\), \\(n_r\\), and \\(n_s\\) are the total number of incident, receivers and frequencies, respectively.",
      "chunk_id": 5269,
      "paper_id": "An Improved Population-Based Incremental Learning Method for Objects Buried in Planar Layered Media",
      "paper_title": "An Improved Population-Based Incremental Learning Method for Objects Buried in Planar Layered Media",
      "paper_year": "2012",
      "chunk_content": "while the incident magnetic vector potential is  \n$$\nA_{\\text {inc }}^{m p}(r)=j \\omega \\mu_{m} \\int G^{m p}\\left(r, r^{\\prime}\\right) \\cdot \\chi\\left(r^{\\prime}\\right) D\\left(r^{\\prime}\\right) d r^{\\prime}\n$$  \nAt this point, the scattered field $E_{\\mathrm{sc} t}^{m i}(r)$ still cannot be obtained because $D(r)$, thus $\\chi\\left(r^{\\prime}\\right) D\\left(r^{\\prime}\\right)$ inside the integrand in (3), remains unknown. However, substituting (2) and (3) into (1), we can obtain yields  \n$$\n\\begin{aligned}\nE_{\\text {inc }}^{m p}(r)=\\frac{D(r)}{\\tilde{\\varepsilon}_{m}}-\\left(k_{m}^{2}\\right. & \\left.+\\nabla \\nabla \\cdot\\right) \\frac{1}{\\tilde{\\varepsilon}_{m}} \\\\\n& \\times \\int_{V} G^{m i}\\left(r, r^{\\prime}\\right) \\cdot \\chi\\left(r^{\\prime}\\right) D\\left(r^{\\prime}\\right) d r^{\\prime}\n\\end{aligned}\n$$  \nEquation (7) is valid everywhere.\nSolve this Sommerfeld integral equation, we can obtain the electric flux density $D(r) . D(r)$ can then be used to find the induced current density inside the scattering object according to  \n$$\nJ_{\\mathrm{eq}}(r)=j w \\chi(r) D(r)\n$$  \nOnce the induced current is known, the scattered electric field at any location can be easily obtained from (2) and (3). Then, we can obtain  \n$$\n\\begin{aligned}\nE_{\\mathrm{sc} t}^{m i}(r)=-j \\omega\\left[I+\\frac{1}{k_{m}^{2}} \\nabla \\nabla \\cdot\\right] A_{\\mathrm{sc} t}^{m i}(r) \\int G^{m i} & \\left(r, r^{\\prime}\\right) \\\\\n& \\cdot J_{\\mathrm{eq}}\\left(r^{\\prime}\\right) d r^{\\prime}\n\\end{aligned}\n$$  \nA relative error function with respect to the electromagnetic parameters is defined as  \n$$\n\\begin{aligned}\n& G(g) \\\\\n& =\\frac{\\sum_{u=1}^{n_{t}} \\sum_{v=1}^{n_{r}} \\sum_{w=1}^{n_{s}}\\left|E^{\\text {meas }}\\left(t_{u}, r_{v}, s_{w}\\right)-E^{\\text {comp }}\\left(t_{u}, r_{v}, s_{w} ; g\\right)\\right|^{2}}{\\sum_{u=1}^{n_{t}} \\sum_{v=1}^{n_{r}} \\sum_{w=1}^{n_{s}}\\left|E^{\\text {meas }}\\left(t_{u}, r_{v}, s_{w}\\right)\\right|^{2}}\n\\end{aligned}\n$$  \nwhere $E^{\\text {meas }}$ is the result of measured electric field intensity at the observation points, and $E^{\\text {comp }}$ is the result of the hypothetical parameters $g$ computed by forward model. $t_{u}, r_{v}$, and $s_{w}$ are the incident element, receiver element, and sample point in the frequency domain respectively. $n_{t}, n_{r}$, and $n_{s}$ are the total number of incident, receivers and frequencies, respectively.  \nThe relative error function gives a measurement on how close the inverted results approach the true profile. The inverse problem can therefore be cast into an optimization problem by minimizing the relative error function. In order to convert it into a maximization problem, a fitness function is defined as  \nFORMULA_59",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:19",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model when it is hybridized with the Simulated Annealing Algorithm (SAA) to solve the job-shop scheduling problem?",
      "topics": [
        "optimization"
      ],
      "answer": "The hybrid EDA-SAA algorithm proceeds in two main phases. First, the EDA is executed to perform a global search of the solution space, rapidly identifying optimal or near-optimal solutions. Second, the SAA is applied to exploit local information, refining the solutions found by the EDA. The SAA attempts to jump out of local optima to seek better solutions in the neighborhood of those identified by the EDA.",
      "chunk_id": 7757,
      "paper_id": "An Enhanced Estimation of Distribution Algorithm for Energy-Efficient Job-Shop Scheduling Problems with Transportation Constraints",
      "paper_title": "An Enhanced Estimation of Distribution Algorithm for Energy-Efficient Job-Shop Scheduling Problems with Transportation Constraints",
      "paper_year": "2019",
      "chunk_content": "Due to the strongly NP-hard nature of the job-shop scheduling problem (JSP), many optimization approaches such as meta-heuristic algorithms have been developed to obtain optimal and suboptimal solutions. It should be noted that although meta-heuristic approaches have been shown to be effective in solving the JSP with the consideration of energy efficiency [17,18,30], the solution quality will become less satisfactory, especially when transportation constraints are added to the scheduling model. The estimation of distribution algorithm (EDA), as an evolutionary algorithm, has received increasing interest in solving many complex optimization problems such as production scheduling problems [31-33].  \nIn this section, an enhanced hybrid algorithm based on a combination of estimation of the distribution algorithm (EDA) and simulated annealing algorithm (SAA) is developed for solving the problem. In the literature, a variety of meta-heuristic algorithms have been used to solve JSP, including the genetic algorithm (GA), simulated annealing algorithm (SAA), estimation of distribution algorithm (EDA), particle swam optimization (PSO), etc. Among these algorithms, the EDA has the ability of global exploration and can quickly approach the optimization solution, but a fatal shortcoming is that its local exploitation ability is limited. Fortunately, SAA has a strong exploitation ability and can jump out of the local optimization to search for the best solution. Therefore, this paper proposes to incorporate the advantages of the SAA into the EDA. The EDA based on global information search is developed to rapidly obtain optimal or near-optimal solutions in the solution space, and then the SAA based on local information search is employed to seek better ones in terms of the solutions.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:21",
      "generation_style": "implementation_focused"
    },
    {
      "question": "Where can the code for the Estimation of Distribution Algorithm be found?",
      "topics": [
        "optimization"
      ],
      "answer": "The code is available in the EDAspy Python package, accessible at https://github.com/ VicentePerezSoloviev/EDAspy and downloadable from Pypi.",
      "chunk_id": 9525,
      "paper_id": "Quantum-Inspired Estimation Of Distribution Algorithm To Solve The Travelling Salesman Problem",
      "paper_title": "Quantum-Inspired Estimation Of Distribution Algorithm To Solve The Travelling Salesman Problem",
      "paper_year": "2021",
      "chunk_content": "The code will be uploaded to EDAspy Python package. The package can be found at https://github.com/ VicentePerezSoloviev/EDAspy and downloaded from Pypi.",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:22",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when using Pareto-based ranking and crowding distance for fitness assignment in a multi-objective optimization problem?",
      "topics": [
        "representation"
      ],
      "answer": "The primary objective is to reassign fitness to candidate solutions since objective values from objective functions cannot be directly used as fitness values. Pareto-based ranking assigns rank based on domination, and crowding distance promotes diversity by preferring solutions with greater distance to their neighbors, especially boundary solutions assigned infinite distance, during binary tournament selection.",
      "chunk_id": 11439,
      "paper_id": "Evolutionary algorithms for solving multi-objective travelling salesman problem",
      "paper_title": "Evolutionary algorithms for solving multi-objective travelling salesman problem",
      "paper_year": "2011",
      "chunk_content": "The chromosome is represented by a set of sequenced cities, as shown in Fig. 2. Each chromosome (ch1 and ch2) encodes a complete solution. Integer value is used to represent the cities, where 1 means the first city. The gene of a chromosome will therefore consist of different integer values ranging from 1 to $n$ (where $n$ is the maximum number of city to be visited). The sequence of the cities to be visited is denoted by the sequence which it appears in the chromosome.\nIn multi-objective optimization, no single point is an optimal solution. Instead, the optimal solution is made up of a set of non-dominated individuals. Under this  \nFig. 2 Integer number representation\n[IMAGE_1]\ncondition, the objective values derived from the objective functions cannot be directly used as the fitness values.  \nTherefore, a way to reassign the fitness to the candidate solutions is required. Through literature review, it is seen that the Pareto-based ranking and crowding distance is one of the favorite fitness assignment operators (Deb et al. 2002). Under this scheme, solution A is fitter than solution B if and only if all the objective values of the solution A are smaller than those of the solution B (for the case of minimization problems). Solution A and solution B are incomparable if and only if the objective values of the solution A are not all smaller than those of the solution B. By applying this concept, the solutions are ranked according to their rank of domination. Solutions that are not being dominated by any other solutions are ranked as one, while solutions which are only dominated by the solutions in rank one are ranked as two, and so forth. In this case, the solutions in smaller rank are fitter than those in higher rank. This ranking mechanism is illustrated in Fig. 3. By applying natural selection pressure, the chances of selecting solutions in smaller rank are higher than solutions in higher rank. In the implementation, binary tournament selection (Miller and Goldberg 1996) is being used. Under this selection scheme, two chromosomes are randomly selected to undergo tournament selection by comparing their rank of domination. The solution with the smaller rank is preferred, and thus it will survive to the next generation. However, if two solutions are located at the same rank, then the one that has the greater crowding distance is preferred. Crowding distance of a solution is calculated by summing over its two nearest neighbors. The procedure, illustrated in Fig. 4, calculates the crowding distance of solution A by the summation of L1 to L4. The crowding distance for solutions at the boundary location (solutions B and C in Fig. 4) is set to an infinite value, and this leads to the increase in the possibility of these solutions to survive a tournament selection infinitely. This procedure aims to increase the capability of the algorithm to evolve a set of diverse solutions. The Pareto-based ranking and crowding distance serve as the fitness assignment operator in all algorithms. This fitness assignment operator may produce a set of trade-off solutions with good proximity and diversity.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:23",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the proposed deadlock-free local search algorithm, what mathematical principles govern the selection probability of a chromosome \\(\\Gamma_{j}\\) in the roulette wheel-based acceptance criterion (RW-AC), and how does this relate to the algorithm's search efficiency?",
      "topics": [
        "search"
      ],
      "answer": "Within the roulette wheel-based acceptance criterion (RW-AC), the selection probability \\(P(\\Gamma_{j})\\) of a chromosome \\(\\Gamma_{j}\\) is determined by the formula \\(P(\\Gamma_{j})=f(\\Gamma_{j}) / \\sum_{i=1}^{2 \\beta} f(\\Gamma_{i})\\), where \\(f(\\Gamma_{j})=\\left(\\max \\left\\{\\gamma\\left(\\Gamma_{k}\\right) \\mid k \\in \\mathbb{N}_{2 \\beta}\\right\\}-\\gamma\\left(\\Gamma_{j}\\right)+1\\right) /\\left(\\max \\left\\{\\gamma\\left(\\Gamma_{k}\\right) \\mid k \\in \\mathbb{N}_{2 \\beta}\\right\\}-\\min \\left\\{\\gamma\\left(\\Gamma_{k}\\right) \\mid k \\in \\mathbb{N}_{2 \\beta}\\right\\}+1\\right)\\). Here, \\(\\Gamma_{j}\\) represents a chromosome in the set of all chromosomes \\(\\left\\{\\Gamma_{j} \\mid j \\in \\mathbb{N}_{2 \\beta}\\right\\}\\), \\(\\beta\\) denotes the population size, and \\(f(\\Gamma_{j})\\) is a fitness function that depends on \\(\\gamma(\\Gamma_{k})\\), which evaluates chromosome \\(\\Gamma_{k}\\). The PD-AC is designed to accept chromosomes with both diversity and optimality, avoiding repeated searches and achieving high search efficiency, while RW-AC's efficiency is based on the proportional fitness values.",
      "chunk_id": 10552,
      "paper_id": "Deadlock-Free Scheduling of Flexible Assembly Systems Based on Petri Nets and Local Search",
      "paper_title": "Deadlock-Free Scheduling of Flexible Assembly Systems Based on Petri Nets and Local Search",
      "paper_year": "2018",
      "chunk_content": "The proposed deadlock-free local search algorithm is implemented in $\\mathrm{C}++$. The size of the code file is 26 KB . It is compiled by MSBuild 4.0 and run on a $1.7-\\mathrm{GHz}$ personal computer with 8 GB RAM. The operating system of the computer is Windows 7 Ultimate. The APNS in Fig. 1 is used to test the performance of the proposed algorithm. Suppose that the numbers of type-1 4 parts are all 10. Let $[1,10],[11,20],[21,30]$, and $[31,40]$ denote the codes of type-1 4 parts, respectively. The processing time is randomly distributed in the range of $[15,40]$ for all manufacturing and assembly activities, as shown in Table I. The experimental data and main bodies of the code are available at https://github.com/luojianchao/ILS4FAS. The performance of the proposed deadlock-free local search algorithm may be affected by the size of the population, the maximum number of generations, $\\zeta_{p}, \\zeta_{l}, \\mathrm{AC}$, and perturbation policy. Generally speaking, the larger the population size or the maximum number of generations is, the better the algorithm's performance. Thus, the effectiveness of the population size and the maximum number of generations is certain. They are fixed as 20 and 2000, respectively. To test the effectiveness of the other factors, the following experiments are conducted.  \nIn order to compare PD-AC with existing ACs, we implement another two ACs, i.e., roulette wheel-based AC (RWAC) [25] and the better AC (B-AC) [49]. Let $\\left\\{\\Gamma_{j} \\mid j \\in \\mathbb{N}_{2 \\beta}\\right\\}$ be the set of all chromosomes in the incumbent population and newly generated one. In RW-AC, the selection probability of a chromosome $\\Gamma_{j}\\left(j \\in \\mathbb{N}_{2 \\beta}\\right)$ is $P\\left(\\Gamma_{j}\\right)=f\\left(\\Gamma_{j}\\right) / \\sum_{i=1}^{2 \\beta} f\\left(\\Gamma_{i}\\right)$, where $f\\left(\\Gamma_{j}\\right)=\\left(\\max \\left\\{\\gamma\\left(\\Gamma_{k}\\right) \\mid k \\in \\mathbb{N}_{2 \\beta}\\right\\}-\\gamma\\left(\\Gamma_{j}\\right)+1\\right) /\\left(\\max \\left\\{\\gamma\\left(\\Gamma_{k}\\right) \\mid\\right.\\right.$ $\\left.k \\in \\mathbb{N}_{2 \\beta}\\right\\}-\\min \\left\\{\\gamma\\left(\\Gamma_{k}\\right) \\mid k \\in \\mathbb{N}_{2 \\beta}\\right\\}+1$ ).  \nTo test effectiveness of $\\zeta_{p}, \\zeta_{l}$, and AC , a design-ofexperiment (DOE) [54] method is used. They all have three levels, as shown in Table II. Thus, a DOE with size $L_{9}\\left(3^{4}\\right)$ is selected. The proposed algorithm runs ten times at each factor combination. The average makespan is taken as an evaluation index. The final orthogonal experiment table is shown in Table III, and the range and rank of $\\zeta_{p}, \\zeta_{l}$, and AC are given in Table IV.  \nSince $\\zeta_{p}$ owns the biggest range, it affects the performance of the proposed algorithm most. If it is too small, all chromosomes search toward the best chromosomes. The algorithm is easy to premature. If it is too big, the search direction is  \nTABLE III\nOrthogonal Table and Average MAKEsPan  \nTABLE IV\nResponse Table  \nTABLE V\nSimulation Results Under Different Perturbation Policy  \ntoo random. The algorithm performs like a random search. AC ranks second. Since PD-AC accepts chromosomes with both diversity and optimality, it can avoid repeated search to some extent, and thus achieves high search efficiency. Comparing with $\\zeta_{p}$ and $\\mathrm{AC}, \\zeta_{l}$ affects the performance of the algorithm least. However, a reasonable factor selection can help the algorithm perform better. Based on the previous analysis, they are selected as: $\\zeta_{p}=0.4, \\zeta_{l}=0.05$, and FORMULA_883.",
      "question_type": "algorithmic principles",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:26",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using an Evolutionary Bayesian Classifier-based Optimization Approach (EBCOA), how should practitioners determine the classes used for building the Bayesian classifier in step 3, specifically regarding the selection of individuals from $D_{l}^{K}$ to create $D_{l}^{C}$?",
      "topics": [
        "convergence"
      ],
      "answer": "When constructing $D_{l}^{C}$ in the EBCOA approach, practitioners should select from $D_{l}^{K}$ a subset of classes $|C|$ such that $|C| \\leq |K|$, where $|K|<R$ is the number of labels assigned to individuals based on their fitness values in the population $D_{l}$ of size $R$. The selection should prioritize at least the best and worst classes of individuals. The remaining classes in $D_{l}^{K} \\backslash D_{l}^{C}$ can be discarded to enhance the differences between the most distant classes, which aims to facilitate the learning of the Bayesian classifier.",
      "chunk_id": 6192,
      "paper_id": "Evolutionary Bayesian classifier-based optimization in continuous domains",
      "paper_title": "Evolutionary Bayesian classifier-based optimization in continuous domains",
      "paper_year": "2006",
      "chunk_content": "Another example of a Bayesian classifier that is able to take into account different dependencies between variables than the previous seminaive approach is the tree augmented naive Bayes classifier [4]. Its name comes from the fact that the structures obtained as a result of its learning approach have the form of a tree. This algorithm constitutes an adaptation of the Chow-Liu algorithm [3] for predictor continuous variables by estimating the mutual information between two univariate normal distributions.  \nFigure 1(c) shows the type of structures that could be obtained when applying the tree augmented naive Bayes algorithm for a problem similarly as for the two previous Bayesian classifiers. Following this particular example, an individual $\\boldsymbol{x}=$ $\\left(x_{1}, x_{2}, x_{3}, x_{4}\\right)$ will be assigned to the class  \n$$\nc^{*}=\\arg \\max _{c} p(c) f\\left(x_{1} \\mid c, x_{2}\\right) f\\left(x_{2} \\mid c\\right) f\\left(x_{3} \\mid c, x_{4}\\right) f\\left(x_{4} \\mid c, x_{2}\\right)\n$$  \nNote that in this case the calculation of $f\\left(x_{i} \\mid c, x_{k(i)}\\right)$-where $X_{k(i)}$ represents the predictor parent variable of variable $X_{i}$ in case that this parent exists- can be computed as  \n$$\nf\\left(x_{i} \\mid c, x_{k(i)}\\right)=\\frac{p(c) \\cdot f\\left(x_{i}, x_{k(i)} \\mid c\\right)}{p(c) \\cdot f\\left(x_{k(i)} \\mid c\\right)}=\\frac{f\\left(x_{i}, x_{k(i)} \\mid c\\right)}{f\\left(x_{k(i)} \\mid c\\right)}\n$$\nThis approach combines Bayesian classifiers such as the ones presented in the previous section and evolutionary computation to solve optimization problems. The main idea is that having a population of solutions for the optimization problem, we will evolve to a next population of fitter individuals by constructing a Bayesian classifier that will represent the main characteristics between the fittest and the least fit individuals. The EBCOA approach contains the following steps:  \n1. Firstly, the initial population $D_{0}$ of $R$ individuals is generated. This initial population is generated similarly as EDAs, usually by assuming an uniform distribution on each variable. Each of the created individuals is evaluated.\n2. Secondly, each of the individuals in $D_{l}$ are given a label $|K|<R$ to classify them following their respective fitness value. This is the supervised classification step, as each of the $R$ individuals is assigned a $k$ label, and as a result the class variable $K$ is created in the database, forming $D_{l}^{K}$.\n3. Thirdly, $D_{l}^{C}$ is created by selecting from $D_{l}^{K}$ only the $|C| \\leq|K|$ classes that will be used for building the Bayesian classifier, usually taking into account at least the best and worst classes of individuals uniquely. A similar scheme of selecting individuals with extreme fitness know as Stabilizing Selection is presented in [2]. The rest of the classes in $D_{l}^{K}$ could be discarded to facilitate the learning by enhancing the differences between the most distant classes. The individuals which are in $D_{l}^{K} \\backslash D_{l}^{C}$ are simply ignored.\n4. A Bayesian classifier is build based on $D_{l}^{C}$ by applying techniques such as the ones described in the previous section. This classifier estimates the probability distribution $p_{l}(c \\mid \\boldsymbol{x}) \\propto p_{l}(c) f_{l}(\\boldsymbol{x} \\mid c)$ which represents the probability of any individual $\\boldsymbol{x}$ to be classified in the any of the different possible $|C|$ classes.\n5. Finally, the new population $D_{l+1}$ constituted by the $R$ new individuals is obtained by carrying out the simulation of the probability distribution $p_{l}(c) f_{l}(\\boldsymbol{x} \\mid c)$. This step can be performed very similarly as in $\\mathrm{EDAs}^{2}$.  \nSteps 2, 3, 4 and 5 are repeated until a stopping criterion is satisfied. Examples of stopping conditions are: achieving a fixed number of populations or a fixed number of different evaluated individuals, uniformity in the generated population, and the fact of not obtaining an individual with a better fitness value after a certain number of generations.  \nThe step of learning the Bayesian classifier is the most critical one regarding the performance of EBCOAs in terms of convergence speed and computation time.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:28",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Restricted Boltzmann Machine (RBM) discussed as an energy-based stochastic binary neural network, how does the energy function, denoted as E(v, h), relate to the probability distribution p(v, h) when the RBM has converged to the equilibrium state?",
      "topics": [
        "optimization"
      ],
      "answer": "When the Restricted Boltzmann Machine (RBM) has converged to the equilibrium state, the probability distribution of any global state, denoted as p(v, h), is determined by the energy function E(v, h) according to the equation p(v, h) = exp(-E(v, h)) / (sum_{x, y} exp(-E(x, y))). Here, E(v, h) = -sum_{i} sum_{j} v_{i} h_{j} w_{i j} - sum_{i} v_{i} b_{i} - sum_{j} h_{j} d_{j}, where v represents the visible units, h represents the hidden units, w_{ij} is the weight between the i-th visible unit and the j-th hidden unit, b_{i} is the bias for the i-th visible unit, and d_{j} is the bias for the j-th hidden unit. The probability p(v, h) is proportional to the exponential of the negative energy of that particular state, normalized by the sum of the exponential of the negative energy of all global states (x, y).",
      "chunk_id": 345,
      "paper_id": "An Energy-Based Sampling Technique for Multi-Objective Restricted Boltzmann Machine",
      "paper_title": "An Energy-Based Sampling Technique for Multi-Objective Restricted Boltzmann Machine",
      "paper_year": "2013",
      "chunk_content": "RBM [17]-[21], [43] is an energy-based stochastic binary neural network. The training of the network is based on unsupervised learning. The network consists of two layers of neurons (input and hidden layers) and the layers are connected through weights and biases. The RBM is similar to the classical Boltzmann machine [44], [45], except that no connection is allowed between the neurons within the same layer. Visible units serve as data vectors and hidden units act as latent variables. Since connections are prohibited between the neurons in the hidden layer, the hidden units are conditionally independent. Furthermore, the visible units can be updated in parallel given the hidden states. The input and hidden units can be modeled in both binary and Gaussian states. The indices of the visible and hidden units are denoted by $i$ and $j$, respectively. $w_{i j}$ is the weight of the connection between the $i$ th visible unit and the $j$ th hidden unit, $b_{i}$ is the bias for the $i$ th visible unit, and $d_{j}$ is the bias for the $j$ th hidden unit. The network's weights are symmetrical. The architecture of the network is shown in Fig. 1. The weights and biases of an RBM define the energy function of the network. The energy function is given as follows:  \n$$\nE(v, h)=-\\sum_{i} \\sum_{j} v_{i} h_{j} w_{i j}-\\sum_{i} v_{i} b_{i}-\\sum_{j} h_{j} d_{j}\n$$  \nWhen the RBM has converged to the equilibrium state at the end of the training process, the probability distribution of any global state can be determined according to the following equation:  \n$$\np(v, h)=\\frac{\\exp (-E(v, h))}{\\sum_{x, y} \\exp (-E(x, y))}\n$$  \nThe numerator is defined by the energy of that particular state, while the denominator is defined by the energy of all the other global states. By summing all the configurations of the hidden units, the marginal probability distribution of a visible unit is determined as shown in the following equation:  \n$$\np(v)=\\frac{\\sum_{h} \\exp (-E(v, h))}{\\sum_{x, y} \\exp (-E(x, y))}\n$$  \nContrastive divergence learning [17], [19], [46], [47] is used to train the network. Two phases are carried out in the learning\n[IMAGE0]  \nFig. 1. Network architecture of an RBM.\nprocess. In the first phase, the data vectors are input into the visible units. Subsequently, the hidden states are updated. In the second phase, the reverse procedure, where the visible states are reconstructed given the hidden states, is carried out. The same procedure is repeated until the stopping criterion is fulfilled. This training procedure is illustrated in Fig. 2. After the training process, the weights are updated according to the following equation:  \n$$\n\\Delta w_{i j}=\\epsilon\\left(<v_{i} h_{j}>_{0}-<v_{i} h_{j}>_{S}\\right)\n$$  \nwhere $<v_{i} h_{j}>_{0}$ is the average value of $v_{i} h_{j}$ at the start of the training process ( 0 -step reconstruction) and $<v_{i} h_{j}>_{S}$ is the average value of $v_{i} h_{j}$ after FORMULA_20-step reconstruction.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:31",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between the first order EDAs (PBIL, UMDA, cGA) and second order EDAs (MIMIC, KFMIMIC, BMDA) in terms of variable dependencies?",
      "topics": [
        "search"
      ],
      "answer": "First order EDAs like PBIL, UMDA, and cGA treat variables as independent. Second order EDAs such as MIMIC, KFMIMIC, and BMDA consider relationships between pairs of variables. Considering these relationships requires more time and space complexity compared to the independent variable assumption made by first order EDAs, especially as problem complexity increases.",
      "chunk_id": 6963,
      "paper_id": "Estimation of Distribution Algorithm based on copula theory",
      "paper_title": "Estimation of Distribution Algorithm Based on Copula Theory",
      "paper_year": "2009",
      "chunk_content": "ESTIMATION of Distribution Algorithm (EDA) has caught many researchers' eyes since proposed in 1996[1]. There are two important steps in EDAs which are explicitly modeling the probability distribution of the good solutions found so far and sampling new solutions by use of the constructed model. Many kinds of EDAs are proposed such as first order EDAs (PBIL[2], UMDA[3], $\\mathrm{cGA}[4]$ ) who take the variables as independent with each other, second order EDAs (MIMIC[5], KFMIMIC[6], BMDA[7]) who only consider the relationship between pairs of variables, high order EDAs(ECGA[8], FDA[9], BOA[10]) and EDAs in continuous search spaces(PBILc[11], UMDAc[12], PPCA[13], ENGA[14]).  \nEDAs are extended into continuous optimization problems recently. Gaussian distribution $N(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma})$ is used mainly for the estimation of the selected population in those continuous EDAs. The ways of setting parameters of Gaussian distribution are approximately the following.  \n[^0]1. The combination of the sample average or the sample variance [11], [13], [15], [16];\n2. Linearly changing the parameters according to the distribution of the selected population [11], [17];\n3. Using a constant value [11];\n4. Using a self-adjust way [11], [18].  \nIt has been proved in theory that EDAs are global converged if the population size is infinite and the constructed probability model can reflect exactly the probability distribution of the selected population, no matter which selection operator is used such as proportional selection, truncation selection or 2 -agents tournament selection [19], [20]. However, both infinite population size and exact probability model are hard to realize, especially when the optimization problem is very large. For example, the algorithms proposed in [10] and [15] need to find the optimal network, and the finding work for a given dataset is a NP-complete problem. In other words, enormous time is required for the modeling work when the optimization problem size is large.  \nCopula theory proposed in 1960's [21] is developed quickly until recent years. The research productions on copula theory are available mainly in statistics [21]-[23], [26] and finance [24], [25] at present, we cannot find its available results in evolutionary computations. According to copula theory, a joint probability distribution can be decomposed into FORMULA_3 marginal probability distributions and a copula function. So the marginal distributions and their dependency can be studied separately. The probability distribution of the selected population will be modeled in EDAs. Some available EDAs considered the variables are independent; others considered the relations between variables which need more time and spaces. Furthermore, the spent on learning the probability distribution increases quickly as the problem is more and more complex. It is easier to model the probability distribution of univariate compared with the joint probability distribution of multivariate. According to copula theory, the joint probability distribution of multivariate can be constructed utilizing a copula function and the marginal probability distributions of every variable. Therefore, an Estimation of Distribution Algorithms based on copula theory (copula-EDA) is proposed in this paper. This algorithm learns the probability distribution of promising population and samples agents on the ground of copula theory. This algorithm is simple and easy to realize.  \nThe paper is organized as follows. In section II, the copula theory is introduced briefly firstly, and then the copula-EDA is produced, finally 2-D Gaussian copula-EDA is",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:33",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the GCB approach to maximize a submodular monotone set function \\(f\\) under a cost constraint \\(B\\), specifically addressing the approximation of the cost function \\(c\\) using \\(\\tilde{c}\\) and the role of \\(K_c\\) in determining the search space?",
      "topics": [
        "performance"
      ],
      "answer": "To implement the GCB approach, the code should first define functions to calculate \\(f(X)\\) and \\(c(X)\\). The approximation \\(\\tilde{c}(X)\\) of the cost function must also be computed, ensuring \\(c(X) \\leq \\tilde{c}(X) \\leq \\psi(n) c(X)\\), where \\(\\psi(n)\\) is the approximation rate of the TSP solver. Next, calculate \\(K_c\\), the maximum size of a feasible solution, as \\(K_{c}=\\max _{X \\subseteq S}\\{|X| \\mid c(X) \\leq B\\}\\). The core of the GCB implementation involves searching for a set \\(X\\) that maximizes \\(f(X)\\) subject to the constraint \\(c(X) \\leq B \\frac{\\alpha_{\\tilde{c}}\\left(1+\\alpha_{c}^{2}\\left(K_{c}-1\\right)\\left(1-\\kappa_{c}\\right)\\right)}{\\psi(n) K_{c}}\\), where \\(\\alpha_c\\) and \\(\\alpha_{\\tilde{c}}\\) are the submodularity ratios of \\(c\\) and \\(\\tilde{c}\\), respectively, and \\(\\kappa_c\\) is the total curvature of \\(c\\). The search should efficiently explore subsets \\(X\\) of the ground set \\(S\\) to find the \\(\\tilde{X}\\) that satisfies the cost constraint and yields a high value of \\(f(X)\\).",
      "chunk_id": 2959,
      "paper_id": "Maximal coverage problems with routing constraints using cross-entropy Monte Carlo tree search",
      "paper_title": "Maximal coverage problems with routing constraints using cross-entropy Monte Carlo tree search",
      "paper_year": "2024",
      "chunk_content": "This subsection shows theoretical guarantees of submodular and approximated submodular approaches. Since the routing cost is not submodular, submodularity ratio is adopted to analyze the theoretical bounds of GCB.  \nDefinition 2 [Submodularity Ratio (Zhang and Vorobeychik, 2016)] Given a non-negative set function $f$, the submodularity ratio of $f$ is defined as:\n$\\alpha_{f}=\\min _{S_{A} \\subseteq S_{B}, s \\notin S_{B}} \\frac{f\\left(S_{A} \\cup s\\right)-f\\left(S_{A}\\right)}{f\\left(S_{B} \\cup s\\right)-f\\left(S_{B}\\right)}$\nThe two properties of $\\alpha_{f}$ holds:  \n1. $0 \\leq \\alpha_{f} \\leq 1$.\n2. $f$ is submodular if and only if $\\alpha_{f}=1$.  \nFor example, the coverage function $f$ is submodular and $\\alpha_{f}=1$.  \nBefore introducing the lower bounds of GCB and EAMC for submodular functions, some definitions are as follows:  \nDefinition 3 [Total Curvature (Conforti and Cornuejols, 1984)] Let $f$ be a monotone submodular function, the total curvature of $f$ is defined as:\n$\\kappa_{f}=1-\\min _{s \\in S: f(\\{s\\} \\gg 0} \\frac{f(S)-f(S \\backslash\\{s\\})}{f(\\{s\\})}$\nThe total curvature $\\kappa_{f}$ characterizes how close a monotone submodular function $(f)$ is to modularity. Moreover, $\\frac{1}{\\alpha_{f}} \\geq$ $1-\\kappa_{f} \\geq 0$ can be derived directly from Definition 2.  \nDefinition 4 [The largest size of feasible solution $K_{c}$ (Zhang and Vorobeychik, 2016)] Given a ground set $S$ and cost function $c, K_{c}$ is defined as:\n$K_{c}=\\max _{X \\subseteq S}\\{|X| \\mid c(X) \\leq B\\}$\nwhere $B$ is a cost constraint.\n$K_{c}$ represents the solution with the largest set size satisfying the constraint.  \nTheorem 1 [Lower bound of GCB (Zhang and Vorobeychik, 2016; Qian et al., 2015)] Given a submodular monotone set function $f$ and a monotone set function $c$, the GCB approach is to maximize $f$ subject to the cost constraint B. The GCB performance of a set $X$ is\n$f(X) \\geq \\frac{1}{2}\\left(1-\\frac{1}{e}\\right) f(\\tilde{X})$,\nwhere\n$\\tilde{X}=\\operatorname{argmax}_{X}$  \n$$\n\\left\\{f(X) \\mid c(X) \\leq B \\frac{\\alpha_{\\tilde{c}}\\left(1+\\alpha_{c}^{2}\\left(K_{c}-1\\right)\\left(1-\\kappa_{c}\\right)\\right)}{\\psi(n) K_{c}}\\right\\}\n$$  \nand $c$ and $\\tilde{c}$ represent the cost function and the approximation cost function, respectively. $K_{c}$ is defined in Definition 4. $\\psi(n)$\nis the approximation rate of the TSP solver, where $c(X) \\leq$ $\\tilde{c}(X) \\leq \\psi(n) c(X)$ and $\\psi(n) \\geq 1$.  \nSince $0 \\leq \\alpha_{\\tilde{c}}, \\alpha_{c} \\leq 1$ and $\\frac{1}{\\alpha_{f}} \\geq 1-\\kappa_{f} \\geq 0$, therefore, $\\frac{\\alpha_{\\tilde{c}}\\left(1+\\alpha_{c}^{2}\\left(K_{c}-1\\right)\\left(1-\\kappa_{c}\\right)\\right)}{\\psi(n) K_{c}} \\leq 1$. The special case is that the cost function $c$ is cardinality. Since $c$ is submodular, $\\alpha_{c}=1$. As $c$ can be computed in $O(1), \\alpha_{\\tilde{c}}=\\psi(n)=1$, In the other words, $\\alpha_{c}=\\alpha_{\\tilde{c}} . c$ is modular, so $\\kappa_{c}=0$. Hence, $\\frac{\\alpha_{\\tilde{c}}\\left(1+\\alpha_{\\tilde{c}}^{2}\\left(K_{c}-1\\right)\\left(1-\\kappa_{c}\\right)\\right)}{\\psi(n) K_{c}}=1$ and $f(\\tilde{X})=f(O P T)$ under cost constraint FORMULA_108.  \nLemma 1 [Lower bound of marginal gain(Qian et al., 2017)]",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:36",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model on the benchmark instances?",
      "topics": [
        "search"
      ],
      "answer": "The EDA's performance is evaluated using the best solution found (Best), the average solution (AVG), the standard deviation (SD) of the solutions, and the average running time. These metrics are recorded over 50 independent runs for each instance in the Kacem (case 1-5) and BRdata (MK1-MK10) benchmark sets.",
      "chunk_id": 4993,
      "paper_id": "An Estimation of Distribution Algorithm for the Flexible Job-Shop Scheduling Problem",
      "paper_title": "An Estimation of Distribution Algorithm for the Flexible Job-Shop Scheduling Problem",
      "paper_year": "2012",
      "chunk_content": "With the design above, the procedure of the HEDA is illustrated in Fig. 3.\n[IMAGE2]  \nFig. 3. The framework of the EDA  \nIn summary, in the initial stage of evolution, the promising area of the solution space may be found by using the EDA based estimating and sampling. Then, local search strategy is performed in the \"good\" region to obtain better solutions. The benefits of the EDA and the local search are combined to balance global exploration and local exploitation. The algorithm stops when the maximum number of generations Gen is satisfied.\nTo test the performance of the proposed EDA, numerical simulations are carried out with two well-studied benchmark sets including five Kacem instances (case 1 case 5) [9] and ten BRdata instances (MK1 MK10) [10]. The algorithm is coded in C++ and run on a 3.2 GHz Intel Core i5 processor.  \nFor each instance, the algorithm is run 50 times independently. We set $P=n \\times m$, FORMULA_97 and test the performance of the EDA and compare it with KBACO [5] and TSPCB [6]. The results are listed in Table 1, including the best solution (Best), average solution (AVG) and standard derivation (SD) as well as the average running time of the EDA.  \nTable 1. Comparisons of EDA with KBACO and TSPCB  \nFrom Table 1, it can be seen that the EDA is better than KBACO and no worse than TSPCB in term of solution quality. As for the average performance, the EDA is the best one except only four instances. In addition, the standard derivation of EDA is smaller than KBACO for almost all the instance. Moreover, it can be seen that the average running time of EDA is acceptable, even for relatively larger-scale instances. So, the conclusion is that our EDA is effective and robust in solving the FJSP.\nThis was the first report work to apply EDA for solving the FJSP. We designed a probability model with the superior population for the EDA to solve the FJSP by generating new individuals via sampling based on the probability model. With an updating mechanism for the probability model and local search based on critical path, the EDA was effective and efficient in solving the FJSP, which was demonstrated by simulation results and comparisons. The future work is to design effective EDA for the multi-objective FJSP.  \nAcknowledgments. This work was supported by the National NSFC (70871065 and 60834004), Program for New Century Excellent Talents in University (NCET-100505) and Doctoral Program Foundation of Institutions of Higher Education of China (20100002110014).",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:37",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically regarding the determination of transmission ratios within a Ravigneaux planetary gear system?",
      "topics": [
        "algorithm"
      ],
      "answer": "The algorithmic approach aims to determine the optimum number of gear teeth to best fulfill imposed transmission ratios ($i_1$, $i_2$, and a third ratio represented by FORMULA_14) within a Ravigneaux planetary gear system. This involves analyzing the kinematic relationships between sun gears, ring gears, and planet carriers to derive equations for these transmission ratios based on the number of teeth ($N_0$, $N_1$, $N_2$, $N_3$, $N_4$, $N_6$) and angular velocities ($\\omega_2$, $\\omega_c$, $\\omega_6$, $\\omega_4$) in each gear.",
      "chunk_id": 6356,
      "paper_id": "Teeth-Number Synthesis of a Multispeed Planetary Transmission Using an Estimation of Distribution Algorithm",
      "paper_title": "Teeth-number synthesis of a multispeed planetary transmission using an estimation of distribution algorithm",
      "paper_year": "2006",
      "chunk_content": "Figure 1 shows a planetary transmission of the Ravigneaux type with three forward and one reverse gears used in automobiles [36,37]. A kinematic diagram of the transmission is available in Fig. 2, where the broad planet gear is shown as two compound gears 2 and 3 . Based on the clutch/brake activation required in each gear (Table 1), it can be shown that in the first and reverse gears, the planet carrier is immobile and the equivalent transmission is a fixed-axle one with the following transmission ratios  \n$$\ni_{1}=N_{0} / N_{4}\n$$  \nand  \n$$\ni_{R}=-\\left(N_{2} N_{6}\\right) /\\left(N_{1} N_{3}\\right)\n$$  \nIn the third gear, the planet carrier, sun gears, and ring gear rotate together as a whole  \n$$\ni_{3}=1\n$$  \ni.e., a direct drive, which ensures an increased mechanical efficiency of the transmission.  \nThe second gear configuration is the only case when the transmission works as a planetary gear set. Considering the planet carrier $c$ immobile, three basic transmission ratios can be defined as follows  \n$$\ni_{16}^{\\prime}=-\\frac{N_{0} N_{6}}{N_{1} N_{3}} \\quad i_{46}^{\\prime}=\\frac{N_{0}}{N_{4}} \\quad i_{14}^{\\prime}=-\\frac{N_{2} N_{4}}{N_{1} N_{3}}\n$$  \nThrough motion inversion, which converts the planetary gear into a fixed axle transmission, the following additional relations between the angular velocities of the sun gears 1 and 4 , ring gear 6 , and planet carrier $c$ can be written as  \n$$\ni_{16}^{\\prime}=\\frac{\\omega_{2}-\\omega_{c}}{\\omega_{6}-\\omega_{c}} \\quad i_{46}^{\\prime}=\\frac{\\omega_{4}-\\omega_{c}}{\\omega_{6}-\\omega_{c}} \\quad i_{14}^{\\prime}=\\frac{\\omega_{1}-\\omega_{c}}{\\omega_{4}-\\omega_{c}}\n$$  \nEliminating $\\omega_{c}$ between any two of the above equations and for $\\omega_{4}=0$, the sought-for transmission ratio of the second gear can be obtained  \n$$\ni_{2}=\\frac{N_{0}\\left(N_{1} N_{3}+N_{2} N_{4}\\right)}{N_{1} N_{3}\\left(N_{6}-N_{4}\\right)}\n$$  \n[IMAGE0]  \nFig. 1 Ravigneaux planetary gear [36]: 1 small sun gear; 2-3 broad planet gear; 4 large sun gear; 5 narrow planet gear; 6 ring gear\n[IMAGE1]  \nFig. 2 Kinematic diagram of a $3 \\times 1$ transmission ratios Ravigneaux planetary transmission. Note that the broad planet 2-3 consists now of two distinct gears  \nThe expressions of the transmission ratios $i_{1}, i_{2}$, and FORMULA_14 previously derived will be further used in formulating the problem of finding the optimum number of gear teeth for which imposed transmission ratios are best fulfilled.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:39",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the FBP Estimation of Distribution Algorithm, what fundamental properties explain why utilizing two different stepsize values, specifically 1 and 0.3, in the linear prediction model for predicting non-dominated solutions contributes to its effectiveness, as opposed to using a range of stepsize values from 0.1 to 0.7, as explored in variants FBPS1-FBPS3?",
      "topics": [
        "optimization"
      ],
      "answer": "The FBP algorithm employs a linear prediction model with two different stepsizes: 1 and 0.3 for predicting non-dominated solutions. The experimental results indicate that fixing one stepsize (step FORMULA_165, though its specific form is not provided in the text) and varying the other from 0.1 to 0.7 (in variants FBPS1-FBPS3) leads to ineffective algorithms when the step is too large, as suggested by t-test values. The FBP algorithm outperforms these variants on a majority of functions, suggesting that the specific combination of stepsizes 1 and 0.3 allows the algorithm to reasonably balance exploration and exploitation in the search space, leading to improved performance compared to using a single fixed stepsize or a range of larger stepsizes.",
      "chunk_id": 8999,
      "paper_id": "Solving dynamic multi-objective problems with a new prediction-based optimization algorithm",
      "paper_title": "Solving dynamic multi-objective problems with a new prediction-based optimization algorithm",
      "paper_year": "2021",
      "chunk_content": "5.1.2 Curve fitting-based strategy. It is not difficult to observe from the results that FBP outperforms the modified variant FBPV2 on most of the test functions. This means that the curve fitting-based strategy indeed helps improve the quality of population in varying environments. The reason may originate from the fact that the curve fitting-based strategy is designed by considering interlinks between variables, which helps to generate promising solutions to some extent.  \nThe comparison between the three different variants and the proposed FBP illustrates that each part has an significant effect on the performance of FBP, and removing any of them reduces performance. Therefore, it is important to combine them together as in the FBP strategy.\n5.1.3 Sampling strategy. All the results illustrate that FBP performs much better than FBPV2 for almost all test problems, although FBP is slightly weaker than FBPV3 for DF14 problem. Thus, the designed sampling technique is able to improve the search ability of population in each varying environment clearly and can further improve the effectiveness of the proposed dynamic multiobjective optimization algorithm.\nAs described before, the linear prediction model employs two different stepsizes, which are set to 1 and 0.3 for predicting non-dominated solutions, respectively. Here, to study whether the step values are well configured, step FORMULA_165 is fixed as it has proven effective in many prediction algorithms, and the other step is set to an increment of 0.2 from 0.1 to 0.7 (FBPS1-FBPS3). Numerical results in Table 14 for the fourteen functions shows that the algorithms become ineffective when step is too large shown by t-test values. The results illustrate that FBP outperforms other three versions on a majority of functions, although the differences between us are not very large on some cases. Therefore, it can be concluded from the experiment that FBP should utilize two different stepsize values ( 1 and 0.3 ) reasonably.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:42",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm such as the UMDA, how should practitioners account for genetic drift in the marginal probabilities during the optimization process?",
      "topics": [
        "proof"
      ],
      "answer": "To account for genetic drift, practitioners can use a factor R = (1 - )(1 - '), where  < 1 and ' < 1 are positive functions, that controls the size of the deviation in Simple Random Sampling without replacement. This factor is applied when the truncation selection operator deals with different individuals having the same fitness, and it pessimistically assumes that the marginal probability p_{.,j}(x_j^*) is consistently reduced.",
      "chunk_id": 6908,
      "paper_id": "When is an estimation of distribution algorithm better than an evolutionary algorithm",
      "paper_title": "When Is an Estimation of Distribution Algorithm Better than an Evolutionary Algorithm?",
      "paper_year": "2009",
      "chunk_content": "```  \ndeviation in the random sampling processes of the UMDA.\n3) $j \\in\\{i+1, \\ldots, n\\}$ : In our worst-case analysis, at the $i^{\\text {th }}$ phase, we pessimistically consider that the $j^{\\text {th }}$ marginal probability $p_{\\cdot, j}\\left(x_{j}^{*}\\right)(j \\in\\{i+1, \\ldots, n\\})$ will not be affected by the selection pressure. Hence, we should take the genetic drift (the accumulation of random errors) into account. The genetic drift is possible to result in both increase and decrease of the marginal probability $p_{\\cdot, j}\\left(x_{j}^{*}\\right)$, however, in our worstcase analysis, we only consider the case that $p_{\\cdot, j}\\left(x_{j}^{*}\\right)$ is consistently reduced by genetic drift. To demonstrate the impact of genetic drift in the deterministic system, we utilise the factor $R=(1-\\eta)\\left(1-\\eta^{\\prime}\\right)$, where $\\eta<1$ and $\\eta^{\\prime}<1$ are positive functions (of the problem size $n$ ) that controls the size of the deviation in Simple Random Sampling without replacement ${ }^{3}$ when the truncation selection operator of the UMDA is dealing with different individuals with the same fitness (genetic drift).\nOn the other hand, since $\\left\\{\\gamma_{i}\\right\\}_{i=1}^{n}$ de-randomises the whole optimisation process, $T_{1}, \\ldots, T_{n}$ in the above equation are no longer random variables. Consequently, we can define explicitly the deterministic system at the $i^{\\text {th }}$ phase $(i=1, \\ldots, n)$ as follows:  \n$$\n\\begin{gathered}\n\\forall \\hat{T}_{i-1}<t \\leq \\hat{T}_{i} \\\\\n\\hat{\\mathbf{P}}_{t}\\left(\\mathbf{x}^{*}\\right)=\\gamma_{t}^{t-\\hat{T}_{i-1}}\\left(\\hat{\\mathbf{P}}_{\\hat{T}_{i-1}}\\left(\\mathbf{x}^{*}\\right)\\right)\n\\end{gathered}\n$$  \nwhere $\\hat{T}_{i}$ is formally defined as follows:  \n$$\n\\hat{T}_{i}:=\\min \\left\\{t ; \\hat{p}_{t, i}\\left(x_{i}^{*}\\right)=1\\right\\}\n$$  \nGiven the definition of the deterministic system, it is not hard to obtain the following upper bound for $\\hat{T}_{i}(i \\in\\{1, \\ldots, n\\})$ :  \n$$\n\\hat{T}_{i} \\leq \\frac{i \\ln \\frac{s M}{N}-i \\ln (1-c)}{\\ln (1-c)+\\ln \\left(\\frac{N}{M}\\right)}+2 i\n$$  \nSo far we have finished the first step of the approach proposed in [13]. The rest part of the proof will concentrate on estimate the deviation between the deterministic system and the real optimisation process of the UMDA, and the  \n[^0]goal is to show that $T_{n} \\leq \\hat{T}_{n}$ holds with an overwhelming probability (a probability that is super-polynomially close to 1). A feasible idea leading to the goal is by proving that for any $i \\in\\{1, \\ldots, n\\}, T_{i} \\leq \\hat{T}_{i}$ holds with an overwhelming probability. The concrete implementation of the idea is using mathematical induction.  \nFirst we must prove that $\\mathbb{P}\\left(T_{1} \\leq \\hat{T}_{1} \\mid p_{0,1}\\left(x_{1}^{*}\\right)=\\hat{p}_{0,1}\\left(x_{1}^{*}\\right)\\right)$ is an overwhelming probability by linking the value of $T_{1}$ back to the values of random variables $p_{t, 1}\\left(x_{1}^{*}\\right)$ ). In this case, we need to investigate the relation between $p_{t, 1}\\left(x_{1}^{*}\\right)$ and $\\hat{p}_{t, 1}\\left(x_{1}^{*}\\right)$. More precisely, the probability that $p_{t, 1}\\left(x_{1}^{*}\\right)$ is bounded from below by $\\hat{p}_{t, 1}\\left(x_{1}^{*}\\right)$ should be taken into account. This can be carried out by Chernoff bounds, since the random sampling processes of the UMDA (to generate new solutions) can be considered as repeated Bernoulli trials for a specific schemata. Noting that the outputs of Chernoff bounds are in the form of the reciprocal of an exponential function of the problem size $n$, we can expect to obtain an overwhelming probability for the event $p_{t, 1}\\left(x_{1}^{*}\\right) \\geq \\hat{p}_{t, 1}\\left(x_{1}^{*}\\right)$ in consideration, given that $N=\\omega\\left(n^{2+\\beta} \\log n\\right)$ and $0<t \\leq \\hat{T}_{1}$. On the other hand, since $\\hat{T}_{1}=\\Theta(1)$ is relatively small, given any positive integer $t$ that is no larger than $\\hat{T}_{1}$ generations, the probability of the event $\\forall t^{\\prime} \\leq t, t \\in \\mathbb{N}^{+}: p_{t^{\\prime}, 1}\\left(x_{1}^{*}\\right) \\geq \\hat{p}_{t^{\\prime}, 1}\\left(x_{1}^{*}\\right)$ remains overwhelming (super-polynomially close to 1). As a consequence, it is not hard to reach the result that $\\mathbb{P}\\left(T_{1} \\leq \\hat{T}_{1} \\mid p_{0,1}\\left(x_{1}^{*}\\right)=\\hat{p}_{0,1}\\left(x_{1}^{*}\\right)\\right)$ is an overwhelming probability.",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:43",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the copula Estimation of Distribution Algorithm (EDA) discussed, how does the autocorrelation function (ACF) of the time series data, as shown in Figure 2 (bottom), relate to the potential performance improvements of the algorithm?",
      "topics": [
        "performance"
      ],
      "answer": "The time series data, representing daily active power load and irradiance profiles, exhibits significant autocorrelation, as quantified by the autocorrelation function (ACF). The presence of significant autocorrelation suggests that carrying over samples between time steps could potentially improve the performance of the copula EDA. This is because the autocorrelation indicates that past values of the time series are predictive of future values, which the EDA can leverage to refine its probabilistic model and, consequently, its search for optimal solutions.",
      "chunk_id": 2170,
      "paper_id": "Data-Enabled Reactive Power Control of Distributed Energy Resources via a Copula Estimation of Distribution Algorithm",
      "paper_title": "Data-Enabled Reactive Power Control of Distributed Energy Resources via a Copula Estimation of Distribution Algorithm",
      "paper_year": "2022",
      "chunk_content": "We illustrate the effectiveness of the copula EDA on the modified IEEE 123 node test feeder, see Fig. 1. Each node features the same load profile that is multiplied with the node's specific spot load that can be retrieved from [24]. Since the spot loads are relatively large, the PV systems have to be sized accordingly in order to induce voltage violations. The total nominal capacity of the 10 PV systems is therefore 10 MVA and these are placed randomly on the feeder, see Fig. 1.  \n[IMAGE0]  \nFig. 1. The IEEE 123 node test feeder. Squares indicate placement of the PV systems on nodes $18,48,56,66,79,83,95,250,300$ and 450 with nominal capacities $588 \\mathrm{kVA}, 1176 \\mathrm{kVA}, 1681 \\mathrm{kVA}, 420 \\mathrm{kVA}, 756 \\mathrm{kVA}, 1344 \\mathrm{kVA}$, $1681 \\mathrm{kVA}, 1176 \\mathrm{kVA}, 504 \\mathrm{kVA}$ and 672 kVA , respectively.\n[IMAGE_1]  \nFig. 2. Top: Daily load and PV profiles. The solid lines are 10 spatially and temporally correlated PV power profiles, generated using the model introduced in [23]. The sunrise and sunset times for the clear sky profile differ from the partly cloudy day, because it is a different day. Bottom: Autocorrelation function (ACF) of the respective time series.  \nWe consider single-phase connections and leave the study of voltage unbalance and neutral-point shifting for future work. However, we note that considering three-phase connections allows for load balancing, which has been shown to be effective in mitigating voltage violations [25].  \nFigure 2 (top) presents the daily active power load and irradiance profiles for the numerical analysis that have been normalized min-max scaling and then upscaled by multiplying with the spot loads and DER capacities presented in Fig. 1, respectively. These profiles form the basis of our case study: spatially and temporally correlated profiles are assigned to each PV system to emulate cloudy conditions with lower correlation. The irradiance profiles are generated by transforming points in time and space to points in a propagating cloud field, which allows for realistic spatially and temporally correlated irradiance profile generation based on cloud field velocity and hourly average clear-sky index trained on the pyranometer network in Oahu, Hawaii and applied to measurements at the  \nUniversity of California, San Diego on 14 July 2011 [23], [26].\nFigure 2 (bottom) presents the autocorrelation function (ACF) of the time series presented in the upper part of the figure. All time series contain significant autocorrelation, which is why it is reasonable to assume that carrying over samples between time steps could improve the performance of the copula EDA. We show the efficacy of carrying the samples forward in time in Section IV-D.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:45",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Based on the information provided, how does the convergence efficiency of standard Estimation of Distribution Algorithms (EDAs) compare to Parallel EDAs (PEDAs), and what impact do different migration strategies have on PEDA's performance?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Parallel EDAs",
        "Convergence Efficiency",
        "Migration Strategies",
        "Performance Comparison"
      ],
      "answer": "The text indicates that standard EDAs converge quickly without migration, typically around 50 generations. However, PEDAs, regardless of migration strategy, exhibit an average convergence generation of around 100 and generally improved convergence values. Among migration strategies in PEDA, MDR (migrate an individual in i-th subpopulation to four neighbors) is noted as the best, achieving the global optimal solution of 204.8 three times out of five tests, while the convergence values are almost above 198. The standard EDAs show quick convergence but PEDAs have better convergence values.",
      "chunk_id": 13076,
      "paper_id": "Parallel island-based estimation of distribution algorithms for wireless network planning",
      "paper_title": "Parallel island-based estimation of distribution algorithms for wireless network planning",
      "paper_year": "2005",
      "chunk_content": "In this paper, PBCM model and simulation method discussed in section 2 are used to simulate wireless network planning. In the test, the $C$ value is 111 , and thus the size of solution space is $2^{160}=1.461 \\times 10^{48}$. Firstly, let Popsize be 1280, subNum be 8, $r$ be 0.5 and $P$ select be 0.7 and then we discuss the convergence with parameter variations. The 5 tests are implemented on fixed parameters and results are shown as table 1.\n[IMAGE3]  \nFigure 4. Types of migration. (a) ODR: migrate an individual in $\\mathrm{i}^{\\text {th }}$ subpopulation to $(\\mathrm{i}+1)^{\\mathrm{th}}$; (b) DDR: migrate an individual in $\\mathrm{i}^{\\text {th }}$ subpopulation to $(\\mathrm{i}+1)^{\\text {th }}$ and $(\\mathrm{i}-1)^{\\text {th }}$; (c) MDR: migrate an individual in $i^{\\text {th }}$ subpopulation to four neighbors.  \nTABLE I\nConvergence Generation And Value OF Different Methods\n(a) Convergence generations with different migration using GA ${ }^{a}$  \n(b) Convergence generations with different migration using EDA  \n(c) Convergence values with different migration using GA ${ }^{a}$  \n(d) Convergence values with different migration using EDA  \nNote: ${ }^{a}$ : Uniform crossover is used as well as in [4], in which crossover rate is 0.7 , mutation rate is 0.1 and other parameters are as same as ones in EDA. ${ }^{\\mathrm{b}}$ : NM, short for Non-migration, doesn't adopt island-based parallel model. ${ }^{c}$ : uses the island-based parallel model.  \nTable (a) and (c) show that the convergence time of standard GAs without migration is long. The best convergence generation is 302 and worst 727 . Meanwhile, the convergence values are bad, between 167.7 and 174.8. The convergence efficiency has been improved much when island-based model is adopted, with the best convergence generation 58, best convergence value 203.44 and worst convergence value 192.1. This is consistent with $[2,4]$. The difference of convergence efficiency is insignificant when employing different migration methods. Moreover, we find that convergence efficiency and values are not stable when using standard GAs. For instance, the best convergence generation is 58 , but the worst is 920 using MDR migration strategy. For convergence values, the best is 203.44 , but worst is 192.1 . On the other hand, table (b) and (d) show that convergence is very quick in EDA without migration. Generally, the convergence generation is about 50. The convergence values have been improved much compared to standard GAs. When PEDA is adopted, the convergence generation is stable for five tests regardless of migration strategies. The average convergence generation is around 100 and the convergence values are almost above 198. On the whole, PEDA performs better than standard EDA and PGAs on convergence efficiency. In PEDA, MDR strategy is the best among all migration strategies; as table (d) shows global optimal solution 204.8 can be gained three times in five tests.  \nIn order to see the effect of parameter $r$ on convergence result in PEDA, we examine the convergence generation and values with different $r$ (see Table 2).  \nFrom Table 2, we can observe that global optimal solution can be gained for different $r$, which has little effect on convergence efficiency.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:48",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model, specifically the Variable Neighborhood Search (VNS) algorithm for moving one operation, as described?",
      "topics": [
        "search"
      ],
      "answer": "The VNS algorithm for moving one operation involves the following steps: L1: Identify a critical path $P$ for a given incumbent solution $S$. L2: Set $r$ to be the first operation of $P$. Then, repeat steps L3-L5: L3: Delete operation $r$ from the disjunctive graph $\\mathcal{G}$ of $S$ to get $\\mathcal{G}^{-}$. This is done by removing the disjunctive arc from and to $r$, connecting $PM(r)$ to $S M(r)$ with a dashed arc and setting the processing time of node $r$ to '0'. L4: Search for an assignable time interval for $r$ in $\\mathcal{G}^{-}$. L5: If no assignable interval is found, set $r$ to be the next operation of $P$. The algorithm terminates when an assignable interval is found and $r$ is allocated in that interval; otherwise, $S$ is considered a local optimum for moving one operation.",
      "chunk_id": 7025,
      "paper_id": "Effective multiobjective EDA for bi-criteria stochastic job-shop scheduling problem",
      "paper_title": "Effective multiobjective EDA for bi-criteria stochastic job-shop scheduling problem",
      "paper_year": "2017",
      "chunk_content": "(b) Variable neighbourhood algorithm: The idea of the neighbourhood based moving algorithm VNS is straightforward: when the local optimum of moving one critical operation, the solution may be further improved by moving two operations. Simultaneously, at least one operation is critical.  \nMoving one operation Firstly, moving an operation on the critical path is considered in VNS. The purpose of moving an operation $r$ is to delete the operation from the current position and to insert it at another feasible position of the disjunctive graph $\\mathcal{G}$. Operation $r$ is deleted from $\\mathcal{G}$ by removing the disjunctive arc from and to $r$. Then, it is to connect $P M(r)$ to $S M(r)$ with a dashed arc and set the processing time of node $r$ equals to ' 0 '. Let $G^{-}$be the disjunctive graph obtained from $\\mathcal{G}$ when an operation is removed (the superscript ${ }^{\\cdots}$, refers to the situation after the removal of an operation). Let $C_{M}(\\mathcal{G})$ be the makespan of the solution graph $\\mathcal{G}$. Since $\\mathcal{G}^{-}$ is obtained by deleting one operation from $\\mathcal{G}$, it is obvious that the makespan of $\\mathcal{G}^{-}$is no larger than $C_{M}(\\mathcal{G})$. The basic scheme for local search of moving one critical operation is presented in Fig. 6.  \nMoving two operations When the local optimum of moving one operation is found, there is a critical path $P$ that cannot be broken by moving one of the operations. That is; no assignable time interval can be found for any operation  \nFig. 5 The disjunctive graph and Gantt chart of a feasible solution shown in Fig. 3\n[IMAGE3]  \nVNS:Moving one operation\nInput:\n$S$ : the feasible schedule of S-JSP.\nbegin\nStep L1: Identify a critical path $P$ for a given incumbent solution $S$.\nStep L2: Set $r$ to be the first operation of $P$.\nrepeat\nStep L3: Delete $r$ from disjunctive graph $\\mathcal{G}$ of $S$ to get $\\mathcal{G}^{-}$;\nStep L4: Search for an assignable time that is assignable for $r$ in $\\mathcal{G}^{-}$;\nStep L5: If no assignable interval for $r$ is found, set $r$ to be the next operation of $P$;\nuntil (an assignable interval is found, allocate $r$ in the interval.\nOtherwise, $S$ is a local optimum of moving one operation);\nend\n$r \\in P$ in the disjunctive graph $\\mathcal{G}^{-}$. Deleting an additional operation from $\\mathcal{G}^{-}$brings more idle time, and may create time interval assignable for FORMULA_200, Fig. 7 shows the basic scheme for VNS based local search of moving two operations.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:50",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output, specifically ECGA, be measured using the criteria of cluster validity, and what distinguishes it from other metaheuristic algorithms in this context?",
      "topics": [
        "optimization"
      ],
      "answer": "The quality of ECGA's output can be measured using Silhouette analysis as a cluster validity index, which assesses the consistency within clusters by calculating a silhouette index for each sample. This index, ranging from -1 to 1, indicates how well-clustered a sample is based on its average dissimilarity to other samples in the same cluster (a(i)) and its average dissimilarity to samples in the closest cluster (b(i)). ECGA distinguishes itself by delivering insights into how it achieves solutions through probabilistic models, grouping the population to highlight trending candidates, unlike GA and PSO algorithms.",
      "chunk_id": 3182,
      "paper_id": "Metaheuristic-based time series clustering for anomaly detection in manufacturing industry",
      "paper_title": "Metaheuristic-based time series clustering for anomaly detection in manufacturing industry",
      "paper_year": "2023",
      "chunk_content": "$$\nR_{k}(\\vec{x}, \\vec{y})=\\left\\{\\begin{array}{lr}\n\\sum_{i=1}^{m-k} x_{i+k} \\cdot y_{i}, & k \\geq 0 \\\\\nR_{-k}(\\vec{y}, \\vec{x}), & k<0\n\\end{array}\\right.\n$$  \nThen, SBD can be derived as:  \n$$\nS B D(\\vec{x}, \\vec{y})=1-\\max _{w}\\left(\\frac{C C_{w}(\\vec{x}, \\vec{y})}{\\sqrt{R_{0}(\\vec{x}, \\vec{x}) \\cdot R_{0}(\\vec{y}, \\vec{y})}}\\right)\n$$  \nAfter computing clustering results, the proposed method finds the optimal number of clusters in each given clustering result using Silhouette analysis as cluster validity index [46]. Silhouette index is a method used for validating consistency within clusters of data. The silhouette value is a measure of\nhow similar an object is to its own cluster in comparison to other clusters. This can be achieved by calculating silhouette index for each sample, average silhouette index for each cluster, and overall average index for a dataset. The coefficient is calculated by utilizing mean intra-cluster distance (a) and the mean nearest-cluster distance $(b)$ for each sample.  \nSilhoutte index $=\\frac{b(i)-a(i)}{\\max \\{a(i), b(i)\\}}$\nThe silhouette index is defined as equation (10) which $a(i)$ is the average dissimilarity of $i^{t h}$ sample to all other samples in the same cluster and $b(i)$ is the average dissimilarity of $i^{t h}$ sample with all samples in the closest cluster. The index value lies between $[-1,1]$. If the value is close to 1 , the sample is well-clustered; if the value is close to 0 , the sample can be assigned to a different cluster; and if the value is close to -1 , the sample is in the wrong cluster. By using silhouette width as cluster validity index, the proposed method finds and collects cluster centroids in order to make candidate references for optimal clusters.  \nBased on the collected candidate cluster references, the proposed method searches for the most optimal cluster centroid combinations through metaheuristics. By considering given candidate centroids for the population pool, metaheuristic algorithms search for the best cluster combination through a binary encoded chromosome. In other words, the size of the population is $2^{n}$, where n is the length of cluster references that may differ based on previous clustering results. Accordingly, clusters represented as \" 1 \" are considered for fitness value calculation, and clusters represented as \" 0 \" are neglected for fitness value calculation. Both the length of the chromosome and the number of each clustering method in the chromosome vary according to the clustering results from the previous step.  \nFor metaheuristic optimization, this paper employed GA, CGA, BPSO, and ECGA based on binary encoded chromosomes with tournament selection and average-max fitness function to find the most well-clustered centroid combinations. As mentioned in Section 2.2, many uses of metaheuristics in time series clustering techniques are focused on GA and PSO algorithms, and the use of EDAs such as CGA and ECGA in time series clustering is considered to be very few. Compared to other algorithms, ECGA holds a distinctive characteristic delivering how the algorithm has achieved such solutions by grouping population through probabilistic models which highlight trending as well as relevant candidates in population pool.  \nECGA induces the search process in every generation cycle to find least complicated and most closely related probabilistic model structure on population space to partition  \nselected population and fit parameters. In other words, as the chromosome is considered to be the collected references of diverse time series clustering results, by searching optimal combinations and providing logical bases, enhancing performances and having explainable relationships among clusters are feasible simultaneously. This feature of EDA, concretely ECGA, draws logical solutions for data analysis.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:51",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when applied to the H.261 video codec design problem, particularly concerning mode-identity constraints?",
      "topics": [
        "constraints"
      ],
      "answer": "The algorithmic approach aims to optimize the hardware implementation of the H.261 video codec, modeled as a MOM-IRCPSP-MS-RI problem. A key aspect involves addressing mode-identity constraints, where the executing mode of certain communication activities depends on the modes of connecting function activities. The objective includes simplifying the project by removing activities with negligible durations, such as input/output operations and communication activities related to motion compensation vectors, to streamline the AoN network.",
      "chunk_id": 1185,
      "paper_id": "Solving system-level synthesis problem by a multi-objective estimation of distribution algorithm",
      "paper_title": "Solving system-level synthesis problem by a multi-objective estimation of distribution algorithm",
      "paper_year": "2014",
      "chunk_content": "DPFM, which can accelerate the speed of reading data from DPFM. The RISC and DSP can execute any tasks of H.261. DSP is faster but more expensive, while RISC is slower but cheaper. Other hardware modules can only deal with specific tasks. For example, the DCTM modules can only deal with DCT, IDCT, and IDCTD. The number in the brackets on each hardware module in Fig. 16 is the corresponding hardware cost.  \nBased on the modeling methodology described in Section 3, the design problem of H. 261 video codec can be modeled as a MOM-IRCPSP-MS-RI. The corresponding project information, such as executing mode, renewable resource requirements, and duration, are illustrated in Table 3.  \nNote that the problem has the mode-identity constraints. The executing mode of some communication activities depends on the two connecting function activities. Those with mode-identity constraints are activities $27-32,34-36,41,43-45$. For example, the activity 27 must be executed in mode 4 if activity 2 and 4 are both executed in mode 2 .\n[IMAGE16]  \nFig. 18. The hardware implementation for solution $(350,22)$.  \n[IMAGE17]  \nFig. 19. The Gantt chart for solution (350,22).\nCompared to other operations, the executing times of input/ output operations (IN, OUT, IND, and OUTD) are smaller. So, it assumes that the corresponding durations are zero. Since the data of motion compensation vector is smaller than macroblock, it assumes that the duration of communication activity 40 is zero. Accordingly, we can delete activities FORMULA_208 from the AoN network to simplify the project. The simplified AoN network is illustrated in Fig. 17.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:53",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms, what fundamental properties distinguish UMDA$_{v}$ from CEGNA$_{\\text {BG }}$ and CEGDA, particularly in relation to handling interdependencies between variables and model assumptions about the data distribution?",
      "topics": [
        "evolutionary"
      ],
      "answer": "UMDA$_{v}$ is an Estimation of Distribution Algorithm that, according to the provided text, does not consider any interdependencies between variables. In contrast, CEGNA$_{\\text {BG }}$ and CEGDA are algorithms that utilize clustering techniques. For unimodal functions, the single Gaussian distribution assumption is more suitable than the mixture of Gaussian model used by CEGNA$_{\\text {BG }}$ and CEGDA. The initial cluster number for CEGNA$_{\\text {BG }}$ and CEGDA is set to 2. Furthermore, the threshold value used with RPCL (used with CEGNA$_{\\text {BG }}$ and CEGDA) for deciding which cluster can be discarded is set to 5% of the size of whole data set.",
      "chunk_id": 12958,
      "paper_id": "Clustering and Learning Gaussian Distribution for Continuous Optimization",
      "paper_title": "Clustering and learning Gaussian distribution for continuous optimization",
      "paper_year": "2005",
      "chunk_content": "Four EDA approaches, which are UMDA $_{v}$ [12], EGNA $_{\\text {BG }}$ [12], CEGNA $_{\\text {BG }}$ and CEGDA, and classical EP (CEP) [24] are used on the test functions for comparison purpose.  \nFor each algorithm, the settings are unchanged through all experiments. All mean results were averaged over 30 independent runs. The initial population is generated uniformly at random in the domain specified in the description of each function. The detailed settings are listed in Table II.  \nIn Table II, Population is the number of individuals in each generation, Selection is the number of promising solutions selected from all the individuals in the population based on some predefined selection scheme, and $\\alpha_{v}$ and $\\alpha_{r}$ are initial learning and de-learning rates used with RPCL.\nThe experimental results are summarized in Tables III-IX. All results have been averaged over 30 independent runs, and the maximal evaluation number for unimodal and multimodal functions are $2 \\times 10^{5}$ and $4 \\times 10^{5}$, respectively. All the EDA algorithms use truncate selection, while CEP uses tournament selection with tournament size equals to 10 . Specially for $\\mathrm{CEGNA}_{\\text {BG }}$ and CEGDA, the initial cluster number is set to 2 . Also, the threshold value used with RPCL for deciding which cluster can be discarded is set to $5 \\%$ of the size of whole data set.  \nThe analysis is divided into four parts based on different points of view.  \nTABLE III\nEXPERIMENTAL RESULTS FOR THE SPHERE FUNCTION  \nTABLE IV\nEXPERIMENTAL RESULTS FOR THE SUMCAN FUNCTION  \nTABLE V\nEXPERIMENTAL RESULTS FOR THE TWOPEAKS FUNCTION  \nTABLE VI\nEXPERIMENTAL RESULTS FOR THE THREEPEAKS FUNCTION  \nTABLE VII\nEXPERIMENTAL RESULTS FOR THE SHEKEL FUNCTION\nWith Five Local Optima ( $\\mathrm{D}=4$ )  \n1) Easy Unimodal Problem: Sphere model has only one global optimum without any local optimum and the variables are independent of each other. Basically it appears rather easy for nearly any evolutionary algorithms. From Table III, it appears that $\\mathrm{CEGNA}_{\\text {BG }}$ and CEGDA can both perform well on the Sphere function. Actually, because of simplicity, all the test algorithms can find a very good solution at the end. It can  \nTABLE VIII\nExperimental Results for the Shekel Function\nWith Five Local Optima $(D=30)$  \nTABLE IX\nEXPERIMENTAL RESULTS FOR THE SCHWEFEL FUNCTION  \nbe noticed that among the EDAs, the algorithms with single Gaussian distribution assumption outperform the new proposed algorithms using clustering techniques. Specifically, UMDA $_{\\mathrm{c}}$, which does not consider any interdependencies, performs far better than the others. The reason is that for unimodal functions, the single Gaussian distribution assumption is more suitable than the mixture of Gaussian model; moreover, this particular function nicely accords with the no interdependencies assumption. Also, all the algorithms based on distribution estimation have better performance than CEP, which mainly depends on random search.\n2) Problem With Strong Interdependencies: The SumCan function is a unimodal function with very strong interdependencies between the variables, and was used in [12] to show the advantage of algorithm EGNA $_{\\text {BGc }}$ over UMDA $_{\\mathrm{c}}$ and $\\mathrm{MIMIC}_{\\mathrm{c}}$.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:44:55",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within the RWDE-EDA framework, what specific steps are taken after an individual's fitness value falls below the threshold ?",
      "topics": [
        "search"
      ],
      "answer": "Once the fitness value of an individual in RWDE-EDA is less than , the Estimation of Distribution Algorithm (EDA) is conducted to further refine the individual. The random walk mutation, using probability selection to choose $x_{k 1}, x_{k 2}$, and $x_{k 3}$, is used in earlier phases to explore promising regions. As iterations increase, difference vectors become smaller, leading to individuals collecting in the same region. EDA is then applied to improve the quality of the roots found.",
      "chunk_id": 7944,
      "paper_id": "Random Walk Mutation-based DE with EDA for Nonlinear Equations Systems",
      "paper_title": "Random Walk Mutation-based DE with EDA for Nonlinear Equations Systems",
      "paper_year": "2019",
      "chunk_content": "- From Fig 4, RWDE-EDA succeeds in obtaining all the roots of NESs at $i t e r=500$. The success is mainly attributed to the fact that: 1) the diversity population can be maintained due to random walk mutation; 2) probability selection is able to provide suitable parent individuals to generate the offsprings; 3) EDA is integrated into RWDE for enhancing the quality of roots.\nThe multiple-problem Wilcoxon's test result reports in Table II. From Table II, it shows that RWDE-EDA obtains better result than RWDE-RS and RWDE-PS since RWDE-EDA\nyields the higher $R^{+}$than $R^{-}$value in all cases. Additionally, the Friedman's test result demonstrates in Table III, which shows that RWDE-EDA achieves the best ranking. One should take care to note that RWDE-PS achieves the better result than RWDE-RS due to probability selection.  \nFrom Algorithm 2, random walk mutation is used in the earlier phases to explore different promising regions. $x_{k 1}, x_{k 2}$, and $x_{k 3}$ are selected according to the probability selection. The difference vector may be large and the algorithm is able to increase the probability of searching various regions. In what follows, the similar individuals gradually collect in the same region due to the fact that difference vectors become small with the increase of iteration. Once the fitness value of individual is less than $\\eta$, EDA is conducted to further refine the individual. The statistical results have demonstrated that utilizing RWDE-EDA can be advantageous for locating multiple roots.  \nTABLE II\nREAULTS ORAINED BY THE WILCUSION TEST IN TERMS OF $R R$ AND $S R$ BETWEEN THE DIFFERENT RANDOM WALK BASED DE VARIANTS.  \nTABLE III\nAVERAGE RANKINGS OF RWDE-EDA, RWDE-RS, AND RWDE-PS OPTAINED BY THE FRIEDMAN TEST FOR BOTH $R R$ AND $S R$.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:44:57",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, what distinguishes the RK-EDA approach from other Random Key (RK) based EDAs, and how does this difference contribute to its competitiveness on permutation test problems?",
      "topics": [
        "scheduling",
        "Estimation of Distribution Algorithm",
        "Random key",
        "Permutation problems",
        "Cooling scheme",
        "Univariate model"
      ],
      "answer": "The RK-EDA utilizes a cooling scheme to balance exploration and exploitation of the search space by controlling the variance in its probabilistic model. This is unlike the general performance of RK based EDAs, which have not produced competitive results to date. The RK-EDA achieves competitiveness with the best EDAs on common permutation test problems such as Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.",
      "chunk_id": 12297,
      "paper_id": "RK-EDA- A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_title": "RK-EDA: A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "Mayowa Ayodele ${ }^{(\\boxtimes)}$, John McCall, and Olivier Regnier-CoudertRobert Gordon University, Aberdeen, UK\\{m.m.ayodele,j.mccall, o.regnier-coudert\\}@rgu.ac.uk\nThe challenges of solving problems naturally represented as permutations by Estimation of Distribution Algorithms (EDAs) have been a recent focus of interest in the evolutionary computation community. One of the most common alternative representations for permutation based problems is the Random Key (RK), which enables the use of continuous approaches for this problem domain. However, the use of RK in EDAs have not produced competitive results to date and more recent research on permutation based EDAs have focused on creating superior algorithms with specially adapted representations. In this paper, we present RK-EDA; a novel RK based EDA that uses a cooling scheme to balance the exploration and exploitation of a search space by controlling the variance in its probabilistic model. Unlike the general performance of RK based EDAs, RK-EDA is actually competitive with the best EDAs on common permutation test problems: Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.  \nKeywords: Estimation of distribution algorithm $\\cdot$ Random key $\\cdot$ Permutation problems $\\cdot$ Cooling scheme FORMULA_4 Univariate model",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:44:58",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the Gaussian Copula Estimation of Distribution Algorithm (GCEDA) perform in terms of computational time and function evaluations based on the provided information?",
      "topics": [
        "optimization"
      ],
      "answer": "Based on a single run, GCEDA achieves its best function evaluation of 8.48383e-07 after 33 generations, requiring 6600 function evaluations and 7.895 seconds of CPU time.",
      "chunk_id": 1108,
      "paper_id": "copulaedas An R Package for Estimation of Distribution Algorithms Based on Copulas",
      "paper_title": "copulaedas: An R Package for Estimation of Distribution Algorithms Based on Copulas",
      "paper_year": "2014",
      "chunk_content": "```\nR> gceda  gceda@name  set.seed(12345)\nR> result  show(result)  \nResults for Gaussian Copula Estimation of Distribution Algorithm\nBest function evaluation 8.48383 e-07\nNo. of generations 33\nNo. of function evaluations 6600\nCPU time 7.895 seconds  \nDue to the stochastic nature of EDAs, it is often useful to analyze a sequence of independent runs to ensure reliable results. The edaIndepRuns function supports performing this task. To avoid generating lot of unnecessary output, we first disable reporting progress information on each generation by setting edaReport to edaReportDisabled and then we invoke the edaIndepRuns function to perform 30 independent runs of GCEDA.  \nR> setMethod(\"edaReport\", \"EDA\", edaReportDisabled)\n$R>$ set.seed(12345)\n$R>$ results  show(results)  \nAlso, the summary method can be used to generate a table with a statistical summary of the results of the 30 runs of the algorithm.  \nR> summary(results)",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:00",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model EBNA for Feature Subset Selection (FSS), as described, and what data structure is central to its operation?",
      "topics": [
        "genetic",
        "algorithms",
        "data structures"
      ],
      "answer": "The EBNA model, used within the FSS-EBNA algorithm, avoids traditional genetic recombination operators. Instead, it explicitly discovers feature relationships by factorizing the probability distribution of the best individuals in each generation. This factorization is achieved using a Bayesian Network (BN) induced by a local search mechanism. The BN data structure is central, as it captures dependencies among features, guiding the search process by representing the joint probability distribution of selected features. The algorithm iteratively updates the BN based on the best solutions found in each generation, effectively learning the underlying structure of the feature space.",
      "chunk_id": 6096,
      "paper_id": "Feature subset selection by Bayesian networks  a comparison with genetic and sequential algorithms",
      "paper_title": "Feature subset selection by Bayesian networks:: a comparison with genetic and sequential algorithms",
      "paper_year": "2001",
      "chunk_content": "In this work, we have performed a comparison among FSS-EBNA, a randomized and population-based evolutionary algorithm, and two genetic and other two sequential classic search algorithms in the FSS task. In FSS-EBNA, the FSS problem, stated as a search problem, uses the EBNA search engine, a variant of the EDA approach. The EDA paradigm is born from the roots of the GA community in order to explicitly discover the relationships among the features of the problem and not disrupt them by genetic recombination operators. The EDA paradigm avoids the use of recombination operators and it guarantees the evolution of solutions and the discovery of these relationships by the factorization of the probability distribution of best individuals in each generation of the search. In EBNA, this factorization is carried out by a BN induced by a cheap local search mechanism. As another attractive effect, with the use of FSS-EBNA we avoid the tuning of genetic parameters, still an open problem on GA literature.  \nUsing a wrapper approach, we have searched for the subset of features that optimizes the predictive accuracy of the NB supervised classifier. We have carried out a comparison in a set of tasks among two well-known sequential search engines algorithms (SFS and SBE) and GAs with one-point and uniform crossover operators. FSS-EBNA has demonstrated a robust behaviour, obtaining the best average accuracy respect to all the tasks, the best in all except one dataset and a large reduction in the number of selected features respect the full feature set. We have noted the tendency of SFS to get trapped on local accuracy minima and the incapacity of SBE to perform an acceptable feature reduction. We have also noted the capacity of FSS-EBNA to arrive to similar or better fitted solutions faster than both GA approaches. BNs, which  \nfactorize the probability distribution of best solutions in each generation, are able to capture the underlying structure of the problems faster than GA approaches. On the other hand, the GA's crossover operator frequently disrupts the dependencies among related features: this is the cause of the slower discovery by GAs of solutions of the same level as FSS-EBNA.  \nAs future work, we consider lengthening the works already done using the BNs for the Feature Weighting problem in Nearest Neighbor Algorithm [23] and for the representation of the behaviour of Data Mining classifiers [24]. Continuing the work within the EDA approach for FSS, in order to deal with domains with much larger numbers of features ( FORMULA_122 ), future work should address the use of simpler probability models to factorize the probability distribution of best individuals, models which assume fewer or no dependencies between the variables of the problem (see [26] for a medical application). Other interesting possibility is the use of parallel algorithms to induce BNs in these tasks of high dimensionality [53,60]. Another way of researching will be the employment of a metric which fixes for each domain the number of individuals needed to reliably learn [17] the parameters of the BN.\nThis work is partially supported by the University of the Basque Country and by the Department of Education, University and Research of the Basque Government under grants 9/UPV/EHU/ 00140.226-12084/2000 and PI 1999-40 respectively.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:02",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the Discrete-Vine-Copula based EDAs (DVCEDA) be measured when applied to permutation-based problems, specifically concerning its ability to model the joint probability distribution?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The quality of the Discrete-Vine-Copula based EDAs (DVCEDA) can be assessed by determining whether copula-based models serve as an efficient approach to permutation-representation problems. This involves comparing its performance to other evolutionary algorithms and evaluating if the results observed in continuous domains hold true in the permutation domain. The DVCEDA uses a Discrete Vine-Copula (DVC) model to represent distributions in the permutation representation, and its quality relates to how well it captures the interaction between the univariate marginal distributions.",
      "chunk_id": 7951,
      "paper_id": "Optimizing Permutation-Based Problems With a Discrete Vine-Copula as a Model for EDA",
      "paper_title": "Optimizing Permutation-Based Problems With a Discrete Vine-Copula as a Model for EDA",
      "paper_year": "2019",
      "chunk_content": "Abdelhakim CherietKasdi Merbah UniversityOuargla, Algeriaabdelhakim.cheriet@univ-ouargla.dz\nIn this paper, we introduce a copula-based EDA that uses a Discrete Vine-Copula (DVC) model. This model is particularly suited to represent distributions in the permutation representation. To demonstrate the effectiveness of the proposed Discrete-Vine-Copula based EDAs (DVCEDA), we perform a set of experiments on instances of the known TSP problems. The results obtained are promising to extend the work on other class of problems.\n- Mathematics of computing $\\rightarrow$ Combinatorial optimization: Probabilistic algorithms, Discrete optimization; $\\cdot$ Theory of computation FORMULA_2 Discrete optimization; Evolutionary algorithms.\nOptimization, permutation-based problem, estimation of distribution algorithm, copula, vine-copula, evolutionary algorithm.\nAbdelhakim Cheriet and Roberto Santana. 2019. Optimizing PermutationBased Problems With a Discrete Vine-Copula as a Model for EDA. In Genetic and Evolutionary Computation Conference Companion (GECCO '19 Companion). July 13-17, 2019, Prague, Czech Republic. ACM, New York, NY, USA, 2 pages. https://doi.org/10.1145/3319619.3321961\nRecently, estimation of distribution algorithms (EDAs), a class of EAs that learn a probabilistic model of the best solutions have been extended to deal with permutation-based problems [1]. In this paper, we investigate the used of copula-based models [5] for representing problems with a permutation representation. Copulas are functions that allow defining a joint probability distribution in terms of its univariate marginal distributions. This independence between the way marginal distributions are defined and the function (copula) used to specify the interaction between the marginal distributions, provides great flexibility for modeling.  \nOur EDA is based on a variant of vines that allows to model discrete variables [3]. Our goal is twofold, firstly, we want to determine whether copula-based models serve as an efficient approach  \n[^0]\nto permutation-representation problems in comparison to other evolutionary algorithms. Secondly, we would like to know whether the promising results reported for copula-based EDAs in the continuous domain hold also in the permutation domain.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:04",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of applying data mining algorithms, such as classification, within an Intrusion Detection System, as it relates to securing computer systems?",
      "topics": [
        "complexity"
      ],
      "answer": "The primary objective is to discover useful knowledge from large audit data sets that describes user or program behavior, thereby enabling the identification of intrusions by detecting deviations from normal usage patterns or recognizing well-defined attack patterns. Techniques such as Neural Networks, Support Vector Machines, and Decision Trees are employed to analyze system activity and identify potential security breaches.",
      "chunk_id": 6365,
      "paper_id": "Estimation of distribution algorithm for optimization of neural networks for intrusion detection system",
      "paper_title": "Estimation of distribution algorithm for optimization of neural networks for intrusion detection system",
      "paper_year": "2006",
      "chunk_content": "Attacks on the nation's computer infrastructures are becoming an increasingly serious problem. Computer security is defined as the protection of computing systems against threats to confidentiality, integrity, and availability [1]. Confidentiality (or secrecy) means that information is disclosed only according to policy, integrity means that information is not destroyed or corrupted and that the system performs correctly, availability means that system services are available when they are needed. Computing system refers to computers, computer networks, and the information they handle. Security threats come from different sources such as natural forces (such as flood), accidents (such as fire), failure of services (such as power) and people known as intruders. There are two types of intruders: the external intruders who are unauthorized users of the machines they attack, and internal intruders, who have permission to access the system with some restrictions. The traditional prevention techniques such as user authentication, data encryption, avoiding programming errors and firewalls are  \nused as the first line of defense for computer security. If a password is weak and is compromised, user authentication cannot prevent unauthorized use, firewalls are vulnerable to errors in configuration and ambiguous or undefined security policies. They are generally unable to protect against malicious mobile code, insider attacks and unsecured modems. Programming errors cannot be avoided as the complexity of the system and application software is changing rapidly leaving behind some exploitable weaknesses. Intrusion detection is therefore required as an additional wall for protecting systems. Intrusion detection is useful not only in detecting successful intrusions, but also provides important information for timely countermeasures. Intrusion detection is classified into two types: misuse intrusion detection and anomaly intrusion detection. Misuse intrusion detection uses well-defined patterns of the attack that exploit weaknesses in system and application software to identify the intrusions. Anomaly intrusion detection identifies deviations from the normal usage behavior patterns to identify the intrusion.  \nWe have two options to secure the system completely, either prevent the threats and vulnerabilities which come from flaws in the operating system as well as in the application programs or detect them and take some action to prevent them in future and also repair the damage. It is impossible in practice, and even if possible, extremely difficult and expensive, to write a completely secure system. Transition to such a system for use in the entire world would be an equally difficult task. Cryptographic methods can be compromised if the passwords and keys are stolen. No matter how secure a system is, it is vulnerable to insiders who abuse their privileges. There is an inverse relationship between the level of access control and efficiency. More access controls make a system less user-friendly and more likely of not being used. An Intrusion Detection system is a program (or set of programs) that analyzes what happens or has happened during an execution and tries to find indications that the computer has been misused. An Intrusion detection system does not eliminate the use of preventive mechanism but it works as the last defensive mechanism in securing the system. Data mining approaches are a relatively new technique for intrusion detection. There are a wide variety of data mining algorithms drawn from the fields of statistics, pattern recognition, machine learning, and databases. Previous research of data mining approaches for intrusion detection model identified several types of algorithms as useful techniques. Classification is one of the data mining algorithms, which have been investigated as a useful technique for intrusion detection models.  \nVarious intelligent paradigms namely Neural Networks [2], Support Vector Machine [3, Neuro-Fuzzy systems [4, Linear Genetic Programming [5, Flexible Neural Tree [6] 7] [8, ensemble of intelligent paradigms [22] 23] and Decision Trees [10] have been used for intrusion detection. Various data mining techniques have been applied to intrusion detection because it has the advantage of discovering useful knowledge that describes a user's or program's behavior from large audit data sets.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:06",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of probability learning contribute to solving ground delay problems, specifically in comparison to conventional methods like First Come First Served (FCFS)?",
      "topics": [
        "optimization"
      ],
      "answer": "Estimation of Distribution Algorithms (EDAs) address ground delay problems by employing a probability learning mechanism. Unlike First Come First Served (FCFS), which is a conventional method, EDAs do not rely on a fixed order of service. Instead, they involve problem-specific modeling, probability learning, and new solutions sampling. The probability learning component allows the algorithm to learn the distribution of promising solutions within the search space, guiding the sampling of new solutions towards more optimal regions, which is a key feature distinguishing it from FCFS.",
      "chunk_id": 7891,
      "paper_id": "Research Survey and Application on Ground Holding Policy",
      "paper_title": "Research Survey and Application on Ground Holding Policy",
      "paper_year": "2019",
      "chunk_content": "Yongjie YanState Key Laboratory of Air Traffic Management System and Technology The 28th Research Institute of China Electronics Technology Group Corporation Nanjing, Chinayanyongjie41403@sina.com  \nYan ZhangThe 28th Research Institute of China Electronics Technology Group Corporation Nanjing, Chinazylavender2010@163.com  \nJing Tian\nState Key Laboratory of Air Traffic Management System and Technology The 28th Research Institute of China Electronics Technology Group Corporation Nanjing, China\nmooky@qq.com\nThis paper introduces the origination, concept of ground holding policy and research literature review firstly. Next, three types of models are built for single airport ground holding problem (SAGHP), multi airport ground holding problem (MAGHP) and dynamic single airport ground holding problem (dSAGHP). For solving algorithms, two conventional methods of First Come First Served (FCFS) and dynamic Sequencing Window are explained briefly, then one heuristic algorithm named Estimation of Distribution Algorithm (EDA) is illustrated in detail to solve the ground delay problems, including problem-specific modeling, probability learning and new solutions sampling. Finally, experiment results based on simulation instances and discussions are given.  \nKeywords-Air Traffic Flow Management, Single Airport Ground Holding Problem, Multi-objective Optimization, Estimation of Distribution Algorithm\nWith the development of social economy and the continual growth of civil aviation, military aviation and general aviation, the pressure for air traffic management (ATM) becomes larger and aviation safety has raised more concern than ever. In order to ensure the flights safety, ATM department has to further utilize airspace resource with the novel technologies, by using the flow control measures, to control the aircraft flow under the capacity of airspace and controllers, and guarantee the safety of air traffic operations. However, till now, \"flow control\" in China is lack of information support, technology support and decision making support, meanwhile, decision making depends on the experience of controllers, without collaboration with other stakeholders in ATM. The output policies given by controllers are not stable but with high randomness. Therefore, it becomes one critical problem that how to realize flow control scientifically and reasonably. This paper aims to investigate effective solutions, based on the systematic study on one common and popular ATFM measure Ground Delay Program (GDP), which is a typical ATFM measure of ground holding.\nIn 1960s, national airspace system could not satisfy the rapid increase of transportation. In order to issue the problem of delay caused by air holding, FAA proposed arrival measure program, and converted arrival delay into en route, with the cooperation of en route measure program. These two\ntechnologies compose the initial flight flow management method in USA.  \nLater, with the increase of air traffic flow, a lot of researches on ground delay approach were conducted, with the idea of transferring arrival delay into departure delay. Due to arrangement of traffic flow, capacity change by weather, local airspace congestion could make flights hold in the air, which increases fuel consumption and influences flight safety. In order to cover the situation, it becomes one important ATFM policy that postpones some flights later than their scheduled departure time, to realize balancing the traffic flow and capacity of airport and airspace. The essence of ground delay is to transfer from air holding with high cost to ground delay with lower cost. If all the delay flights could be controlled before departure, both economic and social benefits will be very high.",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:07",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm with a Basic Variable Neighborhood Search (BVNS) to avoid local optima, how should practitioners configure the modified server-change neighborhood structure, specifically concerning the selection probability of values within a solution?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Variable Neighborhood Search",
        "Local Optima",
        "Neighborhood Structures",
        "Probability Models"
      ],
      "answer": "When using the modified server-change neighborhood structure within a BVNS-enhanced EDA, practitioners should monitor the selection probabilities of possible values for each position in the solution. If, during the iterative process, the selection probability for a specific value at a given position exceeds 0.5 (meaning it's greater than the sum of probabilities of all other possible values for that position), the algorithm should randomly change the value at that position to a different possible value. This step, detailed in Table 2, aims to prevent the EDA from prematurely converging to a local optimum by ensuring continued exploration of the solution space. The process involves randomly generating a number to choose between examination or treatment server solutions, extracting a position, assessing selection probabilities, and then randomly changing the value if the probability threshold is exceeded.",
      "chunk_id": 10142,
      "paper_id": "A patient flow scheduling problem in ophthalmology clinic solved by the hybrid EDA-VNS algorithm",
      "paper_title": "A patient flow scheduling problem in ophthalmology clinic solved by the hybrid EDA-VNS algorithm",
      "paper_year": "2020",
      "chunk_content": "Since EDA algorithm may fall into local optimum, a basic variable neighborhood search (BVNS) algorithm is applied to improve the solutions by changing the neighborhood as it is an improved local search algorithm. It uses the neighborhood structure composed of different shakes to search alternately. Neighborhood structures are utilized to create new individuals by searching for neighborhood solutions. There are many papers about the modified VNS. Adibi and Shahrabi (2014) combined the VNS algorithm with the k-means algorithm as a modified VNS algorithm. Some papers modify the neighborhood structures to improve the efficiency of the VNS. Kong et al. (2019) proposed a reduced VNS algorithm with multiple random mutations neighborhood structures to solve the composition problem for Distributed Virtual Manufacturing Network. Puerto et al. (2014) used new neighborhood structures to make a more efficient encoding. We use three neighborhood structures to solve the problem of server allocation, including server-change neighborhood structure, server-swap neigh-  \n[IMAGE6]  \nFig. 7 A simple example for server-change neighborhood structure\n[IMAGE7]  \nFig. 8 A simple example for server-swap neighborhood structure\nborhood structure and a modified server-change neighborhood structure (Figs. 7, 8, 9). The server-change neighborhood structure is to randomly select the examination servers or treatment servers and randomly change the one patient's server allocation for this type of server. The server-swap neighborhood structure is to randomly select the examination servers or treatment servers and randomly swap two patients' server allocation of this type of server. The modified server-change neighborhood structure is  \n[IMAGE_8]  \nFig. 9 A simple example for modified server-change neighborhood structure  \nTable 2 Procedures of modified server-change neighborhood structure\nProcedures of modified server-change neighborhood structure\nStep 1. Randomly generate a number 0 or 1,0 represents the examination server solution, 1 represents the treatment server solution\nStep 2. Randomly extract one position from the solution, for each possible value of this position, obtain the selection probability\nStep 3. If the selection probability of one possible value exceeds that of all other possible values, record the value and compare it with the value of the position\nStep 4. If the value is equal to the value of the position, change the value of the position randomly until the two values are not equal\ndesigned according to the probabilistic models of the EDA algorithm. In the iterative process of probability model, there may be a situation that the probability of some values is increasingly getting larger, so it will fall into local optimum. If the probability of taking a certain value has exceeded the sum of the probabilities of other values, the value will be changed randomly. Because the probability sum of all possible values is 1 , when the probability of a certain value is higher than 0.5 , the value is randomly changed to other possible values. The main steps of the modified server-change neighborhood structure are as shown in Table 2. Figure 10 shows the pseudocode of VNS.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:10",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Restricted Boltzmann Machine (RBM) used as a generative model, what is the mathematical definition of the probability of turning a hidden unit 'on' given the visible units, and how are the weights and biases involved in this calculation?",
      "topics": [
        "optimization"
      ],
      "answer": "The probability of turning a hidden unit 'on' in the binary RBM, given the visible units, is defined as \\(p(h_{i} | \\mathbf{v})=\\frac{1}{1+e^{-z_{j}}}\\), where \\(z_{j}=b_{j}+\\sum_{i} v_{i} \\cdot w_{i j}\\). Here, \\(w_{i j}\\) represents the weight of the connection between the \\(i\\)-th visible unit and the \\(j\\)-th hidden unit, \\(b_{j}\\) is the bias of the \\(j\\)-th hidden unit, and \\(v_{i}\\) is the state of the \\(i\\)-th visible unit.",
      "chunk_id": 969,
      "paper_id": "Evolution Strategies with an RBM-Based Meta-Model",
      "paper_title": "Evolution Strategies with an RBM-Based Meta-Model",
      "paper_year": "2014",
      "chunk_content": "Combining tractable models (such as Gaussian) to a mixture seems to be beneficial, because the mixture can approximate complex objective functions much better than individual models, especially in a multimodal case. However, mixtures of models seem to be inefficient in high-dimentional spaces [12].  \nAnother way of combining models is by taking the product of individual models followed by renormalisation. If the models are Gaussians with one or more latent variables, then their product becomes a powerfull tool for modelling complex distributions with nearly arbitrary shape and sharpness, and the sharpness is not limited by the width of each individual kernel [13]. A well-know example of such a product is a restrictred Boltzmann machine (RBM). RBMs and their modifications have been excessively studied for the last decade, and they have been shown to be very efficient in many classification, recognition and dimensionality reduction tasks [14-22].  \nGenerally speaking, a binary RBM is a two-layer network of visible and hidden units that are bi-directionally connected to each other with no lateral connections within layers, Fig. 1. An RBM layout. The units make stochastic decisions about whether to be \"on\" or \"off\" with probability defined by their net input [12, 23].\n[IMAGE0]  \nFig. 1. An RBM layout\nSpecifically, the probability of turning a unit \"on\" is:  \n$$\n\\begin{aligned}\n& p\\left(h_{i} \\mid \\mathbf{v}\\right)=\\frac{1}{1+e^{-z_{j}}} \\\\\n& z_{j}=b_{j}+\\sum_{i} v_{i} \\cdot w_{i j}\n\\end{aligned}\n$$  \nwhere $w_{i j}$ is the weight of the connection between the $i$-th visible and $j$-th hidden units, $b, c$ are visual and hidden units' biases respectively.  \nThe binary RBM could be extended to encode real-valued variables in few different ways [16]. In our implementation we have used an RBM with Gaussian visible and binary hidden units [24, 25], where Gaussian units denote linear units with added Gaussian noise.  \nUnder this real-valued model, the conditional probabilities become:  \n$$\n\\begin{gathered}\np\\left(v_{i} \\mid h\\right)=\\mathcal{N}\\left(c_{i}+\\sum h_{j} w_{i j}, \\sigma^{2}\\right) \\\\\np\\left(h_{j} \\mid v\\right)=\\frac{1}{1+\\exp \\left(-\\frac{z_{j}}{\\sigma^{2}}\\right)}\n\\end{gathered}\n$$  \nwhere $\\mathcal{N}\\left(m, \\sigma^{2}\\right)$ denotes Gaussian noise with mean $m$ and variance $\\sigma^{2}$.\nThe model is trained to minimise the joint probability of visible and hidden units $P(\\boldsymbol{v}, h)$. For improving the efficiency of ES, we want to learn $P(\\boldsymbol{v}, h)$ in a way that makes it as close as possible to the target function.  \nIn [12] has been proposed a fast method of trining RBMs, namely contrastive divergence (CD), where the weight are updated according to the following equation:  \n$$\n\\Delta w_{i j}=\\left\\langle v_{i} h_{j}\\right\\rangle^{\\text {data }}-\\left\\langle v_{i} h_{j}\\right\\rangle^{\\text {equilibrium }}\n$$  \nIn this equation, $\\left\\rangle^{\\text {data }}\\right.$ denotes the expected value of the input multiplied with the inferred hidden states while the input is clamped on the data points, and $\\left\\rangle{ }^{\\text {equilibrium }}\\right.$ is the expectation of $v_{i} h_{j}$ when the alternating Gibbs sampling of the hidden and visible units was (infinitely) iterated to get samples from the equilibrium distribution. Fortunately, it was shown that the learning could be acceptably efficient even if the Gibbs sampling chain has been stopped after the first update.  \nImportantly, an RBM is a generative model. That is, by alternating Gibbs sampling steps until equilibrium state [26], it is possible to obtain an unbiased exemplar from the model's probability density distribution [16] that allows efficiently produce offspring for ES. Similarly to the learning stage, the Gibbs sampling chain in practice could be stopped after a few iterations.",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:12",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between the OCAT algorithm and a fitness-value-based correspondence method when aligning heterogeneous optimization tasks?",
      "topics": [
        "optimization"
      ],
      "answer": "OCAT, when applied to tasks like the shifted Sphere function and shifted Rastrigin's one, aims to establish ideal correspondences between individuals from different tasks, avoiding the 'chaotic matching' seen in fitness-value-based methods. The time complexity of OCAT is \\(O(K \\cdot NS^{2} \\cdot D_{tn}) + O(K \\cdot NS \\cdot D_{tn}^{2})\\), where \\(K\\) is the number of iterations, \\(NS\\) relates to the sample sets, and \\(D_{tn}\\) relates to the dimension. The complexity arises from constructing correspondences and deriving the affine transformation, with singular value decomposition contributing to the \\(O(K \\cdot NS \\cdot D_{tn}^{2})\\) term.",
      "chunk_id": 3435,
      "paper_id": "Aligning heterogeneous optimization problems with optimal correspondence assisted affine transformation for evolutionary multi-tasking",
      "paper_title": "Aligning heterogeneous optimization problems with optimal correspondence assisted affine transformation for evolutionary multi-tasking",
      "paper_year": "2023",
      "chunk_content": "Algorithm 2 provides the whole pseudocode of OCAT. Lines $1-2$ describe the generation of the promising individual sets $\\mathbf{E}_{a}$ and $\\mathbf{E}_{b}$. The parameter $\\rho$ is the selection ratio varying in $(0,1]$, which determines the quantity and quality of $\\mathbf{E}_{a}$ and $\\mathbf{E}_{b}$. We will experimentally investigate its influence in Section 4.3. Then after some initializations in line 3 and the calculation of the contractive matrix $\\mathbf{S}_{a b}$ in line 4 , lines $5-14$ detail the iteration process of OCAT. During each iteration, the correspondences between the individuals in $\\mathbf{E}_{a}$ and $\\mathbf{E}_{b}$ are first built in lines $8-11$. Afterwards, the parameters $\\mathbf{R}_{a b}^{0}$ and $\\mathbf{t}_{a b}^{k}$ are calculated in lines 12 and 13 , respectively. The whole iteration process continues until the intertask SSR value remains unchanged. Finally, $\\mathbf{S}_{a b}$ and the last $\\mathbf{R}_{a b}^{0}$ and $\\mathbf{t}_{a b}^{k}$ are output to generate the final intertask alignment transformation.  \nFig. 4 presents a practical application of OCAT on two heterogeneous optimization tasks, i.e., the one-dimensional shifted Sphere function $\\left(T_{u}\\right)$ and the shifted Rastrigin's one $\\left(T_{b}\\right)$. Different from the fitness-value-based correspondence method that causes chaotic matching (shown in Fig. 4(a)), OCAT successfully locates the ideal correspondences between the individuals from the two composite tasks (shown in Fig. 4(b)). On that condition, the derived affine transformation enhances knowledgeable transfer from $T_{a}$ to $T_{b}$, which helps explore the potential region of $T_{b}$ effectively (shown in Fig. 4(c)).  \nThe complexity of OCAT mainly comes from the construction of the correspondences between the sample sets and the derivation of affine transformation. Suppose that the whole number\nof iterations in OCAT is $K$, then the correspondence construction process has a time complexity of $O\\left(K \\cdot N S^{2} \\cdot D_{t n}\\right)$ in total. As for the derivation process, its complexity is mainly from the singular value decomposition operator, and thus the total time complexity is $O\\left(K \\cdot N S \\cdot D_{t n}^{2}\\right)$. Therefore, the cumulative time complexity of OCAT is $O\\left(K \\cdot N S^{2} \\cdot D_{t n}\\right)+O\\left(K \\cdot N S \\cdot D_{t n}^{2}\\right)$.  \nAs an intertask alignment algorithm, OCAT can be seamlessly embedded into existing EMTO algorithms. Taking the classic MFEA shown in Algorithm 1 as an example, OCAT can be integrated with the intertask crossover process (Lines 10 and 11). Specifically, with the learned alignment transformation between $T_{\\tau_{1}}$ and $T_{\\tau_{2}}$, the individual from $T_{\\tau_{1}}$ is first transformed into the domain of $T_{\\tau_{2}}$ before its crossover with the individual therein. The generated offspring will be also transformed back into $T_{\\tau_{1}}$ if it is assigned the skill factor $\\tau_{1}$. As a result, the genetic materials between heterogeneous tasks are smoothly exchanged. Besides, OCAT can be also exploited to design fresh EMTO algorithms. This study attempts to combine it with EDA to solve many-tasking optimization problems.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:14",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model using the mean shift method with adaptive bandwidth, specifically detailing how a new coordinate value is calculated?",
      "topics": [
        "search"
      ],
      "answer": "The mean shift based EDA model involves iteratively updating the solution coordinate 'x' to converge towards local density maxima. The core steps are:\n\n1.  **Initialization**: Start with an initial solution 'x' in the d-dimensional Euclidean space.\n2.  **Kernel Density Estimation**: Implicitly estimate the density function using a kernel function. The provided Gaussian kernel is g(u) = (1/(2)) * e^(-(1/2)*u^2), where u represents the squared norm distance between points.\n3.  **Adaptive Bandwidth Calculation**: Calculate the adaptive bandwidth 's' using the formula s = ( (1/d) * (p^j - q^j)^2 ), where 'd' is the dimensionality, and 'p' and 'q' are the maximum and minimum values of all solutions in the current population along dimension 'j'.\n4.  **Coordinate Update**: Update the coordinate value of 'x' to 'x_new' using the formula x_new = ( (x_i * g(||(x - x_i) / s||^2)) ) / ( (g(||(x - x_i) / s||^2)) ), where 'x_i' are the data points, 'g' is the kernel function, and 's' is the adaptive bandwidth. The summation is performed over 'm' points.\n5.  **Iteration**: Repeat steps 3 and 4 until 'x' converges, meaning the change in 'x' between iterations falls below a predefined threshold.",
      "chunk_id": 12336,
      "paper_id": "An Estimation of Distribution Algorithm Guided by Mean Shift",
      "paper_title": "An Estimation of Distribution Algorithm Guided by Mean Shift",
      "paper_year": "2016",
      "chunk_content": "Mean shift is a non-parametric feature-space analysis technique for locating the maxima of a density function. There is no need to calculate the values of estimation functions when we use mean shift to search optimal solutions. We have proved in [23] that the maximization of the density of a distribution equals to the maximization of a corresponding objective. In this section, we propose a local search strategy based on mean shift.  \nAs proposed in [21], the mean shift algorithm assumes that the data points in a $d$-dimensional Euclidean space $R^{d}$ are independent and identically distributed samples taken from a population with an unknown density function $\\hat{f}(x)$. The kernel density estimation at the location $x$ can be calculated as follows:  \n$$\n\\hat{f}_{h, K}(x)=\\frac{1}{n h^{d}} \\sum_{i=1}^{N} K\\left(\\left\\|\\frac{x-x_{i}}{h}\\right\\|^{2}\\right)\n$$  \nwith the bandwidth parameter $h>0$ and the scalar kernel function $K$ under the conditions given in [21].  \nTo maximize $\\hat{f}(x)$, the gradient of the density estimator is formulated by exploiting the linearity of (2):  \n$$\n\\hat{\\nabla} f_{h, K}(x)=\\frac{1}{n h^{d}}\\left[\\sum_{i=1}^{N} g\\left(\\left\\|\\frac{x-x_{i}}{h}\\right\\|^{2}\\right)\\right] m_{h, g}(x)\n$$  \nwhere  \n$$\nm_{h, g}(x)=\\frac{\\sum_{i=1}^{N} x_{i} g\\left(\\left\\|\\frac{x-x_{i}}{h}\\right\\|^{2}\\right)}{\\sum_{i=1}^{N} g\\left(\\left\\|\\frac{x-x_{i}}{h}\\right\\|^{2}\\right)}-x\n$$  \nand  \n$$\ng(x)=-K^{\\prime}(x)\n$$  \nIn order to obtain the direction of the point with maximum density, the value in (3) should equal to zero. Hence, we can attain the new coordinate value of $x$ as follow:  \n$$\nx_{\\text {new }}=\\frac{\\sum_{i=1}^{N} x_{i} g\\left(\\left\\|\\frac{x-x_{i}}{h}\\right\\|^{2}\\right)}{\\sum_{i=1}^{N} g\\left(\\left\\|\\frac{x-x_{i}}{h}\\right\\|^{2}\\right)}\n$$  \nIt is obvious that $x$ will converge at a nearby point where the multivariate kernel density estimator has zero gradient after sufficient iterations. Fig. 1 illustrates the idea of applying the mean shift method on searching for the local density maxima. The initial point keeps moving to the new mean location along the direction of the nearest stationary point.  \nIn standard method, the bandwidth is a constant value, which means it might not have much impact on the procedure of density estimation when the distances of all data points are very small. So, we provide a method to update the bandwidth adaptively and make some improvements in (6):  \n$$\nx_{\\text {new }}=\\frac{\\sum_{i=1}^{m} x_{i} \\varrho\\left(\\left\\|\\frac{x-x_{i}}{\\pi}\\right\\|^{2}\\right)}{\\sum_{i=1}^{m} \\varrho\\left(\\left\\|\\frac{x-x_{i}}{\\pi}\\right\\|^{2}\\right)}\n$$  \nwhere $\\|x\\|^{2}$ is $L_{2}$ norm of $x, m$ is the number of points that are used to calculate the coordinate value of new solution, $s$ is the adaptive bandwidth of searching window calculated as\nfollow:  \n$$\ns=\\sqrt{\\frac{1}{d} \\sum_{j=1}^{d}\\left(p^{j}-q^{j}\\right)^{2}}\n$$  \nwhere $p$ and $q$ is the maximum and the minimum values of all the solutions in the current population.  \nIt should be noted that the kernel function in the mean shift process essentially imposes additional weights on the data points according to their distances to the shifting mean [24]. Cheng [22] described two main types of kernel functions that have frequently been used in the mean shift research, namely flat and Gaussian kernel. Compared to Gaussian kernels, flat kernel gives these points that close to the initial point the same weights, which ignores the influence of the distance between  \nTABLE II\nMEDIAN,STD. VALUES OF THE RESULTS OBTAINED BY THE TWO COMPARISON ALGORITHMS AFTER 500, 1000, AND 1500 GENERATIONS OVER 20 RUNS FOR ALL THE TEST INSTANCES.  \n[IMAGE0]  \nFig. 1. Illustration of the search procedure of a mean shift\ntwo points. In the paper, we use the following Gaussian kernel.  \n$$\ng(u)=\\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2}(u)^{2}}\n$$  \nwhere  \nFORMULA_55",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:17",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when hybridized with Particle Swarm Optimization (PSO) for water distribution network optimization?",
      "topics": [
        "convergence"
      ],
      "answer": "The effectiveness of the EDA model, when hybridized with PSO, is evaluated by tracking the fitness and diversity of the populations. Additionally, the average number of evaluations needed to achieve the minimum cost for the water distribution network is used as a performance indicator. The literature record minimum cost achieved for benchmark water distribution networks is also used as a metric.",
      "chunk_id": 12007,
      "paper_id": "Estimation of distribution algorithm enhanced particle swarm optimization for water distribution network optimization",
      "paper_title": "Estimation of distribution algorithm enhanced particle swarm optimization for water distribution network optimization",
      "paper_year": "2016",
      "chunk_content": "Xuewei Q1 ${ }^{1}$, Ke LI ( $\\boxtimes)^{2}$, Walter D. POTTER ${ }^{3}$1 Department of Electrical and Computer Engineering, University of California, Riverside, CA 92507, USA2 College of Engineering, University of Georgia, Athens, GA 30605, USA3 Institute of Artificial Intelligence, University of Georgia, Athens, GA 30605, USA  \n(c) Higher Education Press and Springer-Verlag Berlin Heidelberg 2015\nThe optimization of a water distribution network (WDN) is a highly nonlinear, multi-modal, and constrained combinatorial problem. Particle swarm optimization (PSO) has been shown to be a fast converging algorithm for WDN optimization. An improved estimation of distribution algorithm (EDA) using historic best positions to construct a sample space is hybridized with PSO both in sequential and in parallel to improve population diversity control and avoid premature convergence. Two water distribution network benchmark examples from the literature are adopted to evaluate the performance of the proposed hybrid algorithms. The experimental results indicate that the proposed algorithms achieved the literature record minimum ( 6.081 M\\$) for the small size Hanoi network. For the large size Balerma network, the parallel hybrid achieved a slightly lower minimum $FORMULA_4. The average number of evaluations needed to achieve the minimum is one order smaller than most existing algorithms. With a fixed, small number of evaluations, the sequential hybrid outperforms the parallel hybrid showing its capability for fast convergence. The fitness and diversity of the populations were tracked for the proposed algorithms. The track record suggests that constructing an EDA sample space with historic best positions can improve diversity control significantly. Parallel hybridization also helps to improve diversity control yet its effect is relatively less significant.  \nKeywords particle swarm optimization (PSO), diversity control, estimation of distribution algorithm (EDA), water distribution network (WDN), premature convergence, hybrid strategy  \n[^0]",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:18",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "Based on the text, what is the main conclusion regarding the performance of the EDA models RK-EDA, GM-EDA, PGS-EDA, and NHBSA when solving permutation-based problems with varying numbers of machines and jobs?",
      "topics": [
        "analysis"
      ],
      "answer": "The RK-EDA algorithm demonstrates superior performance as the number of machines increases, achieving the minimum ARPD for instances of 100 jobs and 20 machines. While GM-EDA is a strong second, PGS-EDA shows the highest probability of winning across instances with 20, 50, and 100 jobs based on Bayesian performance analysis, with RK-EDA closely following. NHBSA's performance varies, but it maintains competitiveness in certain scenarios and has a non-negligible probability of being among the top three algorithms.",
      "chunk_id": 4074,
      "paper_id": "An Estimation of Distribution Algorithm for Permutation Flow-Shop Scheduling Problem",
      "paper_title": "An Estimation of Distribution Algorithm for Permutation Flow-Shop Scheduling Problem",
      "paper_year": "2023",
      "chunk_content": "occur by random chance, and there is no strong evidence to support the claim that one algorithm performs better than the other in this specific scenario.  \nTable 4. The ARPD of 100 jobs and 5, 10, and 20 machines of Taillard's benchmarks.  \nIn the subset of instances with 10 machines, we observe a slight decrease in the performance of PGS-EDA and NHBSA compared to RK-EDA and GM-EDA. However, it is important to note that PGS-EDA and NHBSA remain competitive in terms of ARPD. Specifically, RK-EDA outperforms the other algorithms in three out of the five instances, demonstrating its effectiveness. Additionally, GM-EDA achieves the minimum ARPD in the remaining two instances, showcasing its strong performance as well. Overall, while there is a variation in performance among the algorithms in this particular subset, PGS-EDA and NHBSA still demonstrate their competitiveness in terms of ARPD. However, when the number of machines increases, the RK-EDA algorithm outperforms all other algorithms and achieves the minimum ARPD among all five instances of $100 \\times 20$. GM-EDA, as the second successful algorithm, outperforms PGS-EDA and NHBSA. Regarding the average value of ARPD, PGS-EDA ranked at position three with 1.471 after RK-EAD and GM-EDA with 0.624 and 0.954 , respectively. These findings highlight the importance of considering the specific problem characteristics and the potential impact of varying parameters, such as the number of machines, when comparing and selecting appropriate algorithms for solving permutation-based problems.  \nThe results of the BPA for instances of size 100, which illustrate the probability of each algorithm being the top, are shown in Figure 4. Based on these results, we can conclude that the RK-EDA has the highest probability of being the best algorithm, with an empirical probability of approximately 0.8 . Following closely behind are GM-EDA and PSG-EDA, both with a probability of 0.4 .\n[IMAGE3]  \nFigure 4. The probability of each algorithm being the best in instances of size 100.  \nTo conclude the statistical analysis, we conducted a Bayesian performance analysis to compare the performance of all the considered algorithms on instances with 20, 50, and 100 jobs. The results, shown in Figure 5, indicate that PGS-EDA has the highest probability of winning, with a probability exceeding $50 \\%$. The second-best algorithm is RK-EDA, followed by GM-EDA and NHBSA, respectively. The remaining algorithms have lower probabilities, below 0.05 .\n[IMAGE4]  \nFigure 5. The probability of each algorithm being the best in all instances.\nFigure 6 provides insights into the probabilities of each method being among the top two and top three algorithms, as determined by Bayesian performance analysis. The analysis encompassed all instances of size 20, 50, and 100 jobs. The results further validate our previous findings, highlighting the strong performance of PGS-EDA and RK-EDA, which are the most probable algorithms to rank among the top two. This suggests that these algorithms are likely to be the most effective in solving this type of problem. Additionally, when considering the top three algorithms, PGS-EDA maintains its high confidence level, while RK-EDA and GM-EDA closely follow. Notably, NHBSA also exhibits a probability of approximately 0.4 of being among the top three algorithms.\n[IMAGE_5]  \nFigure 6. The probability of each algorithm being in the top two and top three in all instances of size 20,50 , and 100 .",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:20",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of switching the probabilistic distributions of two assets with a strong correlation of their returns, as implemented in the described EDA, aim to improve the replication portfolio's ability to mimic the return of a benchmark portfolio, particularly in long-short portfolio replication problems?",
      "topics": [
        "performance"
      ],
      "answer": "The described EDA addresses the challenge of long-short portfolio replication, which requires not only mimicking the return of a benchmark portfolio but also replicating the proportion-weighted combination. The algorithmic mechanism involves switching the probabilistic distributions of two assets that exhibit a strong correlation in their returns. This switching mechanism is designed to find better replication portfolios compared to those obtained by a traditional EDA. The goal is to create a replication portfolio whose returns closely match those of the benchmark portfolio, even in future periods, by adopting past data for optimizing the replication portfolios. Numerical experiments demonstrate that this EDA can achieve this goal, suggesting that switching the probabilistic distributions of correlated assets enhances the EDA's ability to model and replicate the complex dynamics of long-short portfolios.",
      "chunk_id": 111,
      "paper_id": "EDA with Switching Distributions for Long-Short Portfolio Replication Problems",
      "paper_title": "EDA with Switching Distributions for Long-Short Portfolio Replication Problems",
      "paper_year": "2013",
      "chunk_content": "The results of Figs. 3 and 4 suggest that EDA1 can make the replication portfolio whose returns are almost the same as the returns of benchmark portfolio, but cannot replicate the benchmark portfolio.  \nIn order to improve the replication portfolios' performances in the future periods, we optimize the replication portfolio by using EDA1 in the past period consisting of longer days data $T=90$ than $T=10$. For each phase, for $T=10$ and $T=90$, the error sum of squares of returns between replication and benchmark portfolios in the future period are shown in Table II, respectively.  \nTable II says that, through all the phases, the error sum of squares in the future period for $T=90$ is lower than those for $T=10$ except Phase 9. The replication portfolios obtained by EDA1 has a good ability to mimic the return of benchmark portfolio even in the future periods when we can adopt much past data for optimizing the replication portfolios.\nThe long-short portfolio replication problem is a very difficult problem that it's required to not only mimic the return to the benchmark portfolio but also replicate the proportionweighted combination.  \nFor solving such a problem, we have proposed the new EDA switching the probabilistic distributions of two assets with a strong correlation of their returns in this paper.  \nTABLE II. ERROR SUM OF SQUARES OF RETURNS IN THE Future Period  \nIn the numerical experiments, we showed that our EDA works well to find the better replication portfolios than those of the traditional EDA. In addition, we clarified that our EDA can make the replication portfolio whose returns are the same as those of benchmark portfolio even in the future period.\nThis research was partially supported by Grant-in-Aid for Young Scientists (B) \\#25730148 and \\#24700234 from Japan Society for the Promotion of Science (JSPS).",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:22",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to solve the MAX-SAT problem, how should practitioners represent truth assignments for clauses, and what function needs to be maximized?",
      "topics": [
        "evolutionary"
      ],
      "answer": "When implementing an Estimation of Distribution Algorithm for MAX-SAT, truth assignments should be represented as strings or vectors over a binary alphabet containing 0 and 1. The function to be maximized is f(x) = the sum from i=1 to c of S_i(x), where S_i(x) is 1 if clause i is satisfied by assignment x and 0 otherwise, and 'c' represents the number of clauses.",
      "chunk_id": 739,
      "paper_id": "MAX-SAT problem using evolutionary algorithms",
      "paper_title": "MAX-SAT Problem using Evolutionary Algorithms",
      "paper_year": "2014",
      "chunk_content": "Boolean Satisfiability (SAT) is the problem of deciding if a Boolean formula in conjunctive normal form (CNF) has a satisfying truth assignment. As usual, formulas are constructed from a set of $n$ Boolean variables, $x_{1}$ through $x_{n}$, with connectives for conjunction $(\\wedge)$, disjunction $(\\vee)$, and negation $(\\bar{x})$. An SAT instance, or CNF formula, is a conjunction of clauses, where each clause is a disjunction of literals and each literal, $l$ is an affirmation $\\left(x_{i}\\right)$ or negation $\\left(\\bar{x}_{i}\\right)$ of a variable $x_{l} \\in\\left[x_{1}, \\ldots, x_{n}\\right]$. A solution for a CNF formula is an assignment mapping each of its variables to true (1) or false $(0)$, in such a way that at least one literal in each clause is made true. An example of CNF is:  \n$$\n\\left(x_{1} \\vee \\overline{x_{2}}\\right) \\wedge\\left(x_{2} \\vee \\overline{x_{3}}\\right) \\wedge\\left(x_{2} \\vee x_{4}\\right) \\wedge\\left(x_{4} \\vee \\overline{x_{1}}\\right)\n$$  \nA satisfying assignment for the above CNF formula is: $x_{1}=$ $1, x_{2}=1, x_{3}=0$, and $x_{4}=1$. A CNF formula may have zero, one or more satisfying assignments.\nThe Maximum Satisfiability (MAX-SAT) problem is an optimization variant of SAT. In MAX-SAT, the problem is to find a truth assignment that maximizes the number of true  \n[^0]clauses. We can view truth assignments as strings or vectors over a binary alphabet containing 0 and 1. MAX-SAT is then the problem of finding string that maximizes the following function:  \n$$\nf(x)=\\sum_{i=1}^{c} S_{i}(x)\n$$  \nIn the above equation, $S_{i}(x)$ is true (1) if $i$ is satisfied by assignment, FORMULA_20, and false ( 0 ) otherwise. If a literal of the clause is true then the clause true.\nA large variety of NP-hard problems can be modeled or represented as SAT or MAX-SAT, and solving other problems by reduction to one of these is widely studied. Problems frequently solved this way include model-checking of finite state systems, design debugging, AI planning, routing, scheduling, bio-informatics [1-3], etc.  \nThe literature contains a variety of algorithms for MAX-SAT, which can be characterized as providing either exact solutions or approximate solutions. Among algorithms intended for practical use, the exact algorithms are mainly based on branch and bound (BnB) algorithm [3], and differ from each other in variable selection heuristics, inference rules, etc. The approximate techniques do not guarantee the optimal solution, but these approaches can provide reasonably good quality results with limited resources (i.e., time, memory, computation, etc.). Evolutionary computation is one of the popular approximation techniques for obtaining good quality solutions in with limited resources. In the past, Genetic Algorithm (GA) or variant of GA such as GASAT and pEvoSAT have been evaluated on different MAX-SAT problems [16]. In this study, we evaluate several recently proposed evolutionary algorithms on MAX-SAT instances: the Artificial Bee Colony Algorithm (ABC), Immune Quantum Evolutionary Algorithm (IQEA), Quantum Inspired Evolutionary Algorithm (QEA) and Estimation of Distribution Algorithm (EDA) [6-9].\nIn this study, our benchmark instances are formulas produced by the sgen (Standard Generator) formula generator. Sgen aims to generate small and difficult benchmark instances for SAT, and has been used elsewhere for MAX-SAT evaluations well. This software has been presented in the annual SAT competition 2011, and it fulfills input requirements for that competition.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:24",
      "generation_style": "practical_application"
    },
    {
      "question": "In the context of the MFEA paradigm, which considers K optimization tasks concurrently, how is the scalar fitness \\(\\varphi^{\\Pi}\\) of an individual \\(\\Pi\\) mathematically defined, and what does it represent in terms of the individual's performance across the K tasks?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The scalar fitness \\(\\varphi^{\\Pi}\\) of an individual \\(\\Pi\\) in MFEA is calculated based on its best factorial rank over the \\(K\\) tasks. Specifically, it is given by \\(\\varphi^{\\Pi}={ }^{1} / \\min _{i=1,2, \\ldots, K}\\left\\{r_{i}^{\\Pi}\\right\\}\\), where \\(r_{j}^{\\Pi}\\) represents the factorial rank of individual \\(\\Pi\\) on task \\(T_{j}\\), indicating its position in the population sorted by factorial cost with respect to task \\(T_{j}\\). A higher scalar fitness indicates that the individual has a better (lower) best factorial rank across the \\(K\\) tasks, signifying a better overall performance in at least one of the tasks. The factorial cost \\(f_{j}^{\\Pi}\\) of individual \\(\\Pi\\) measures the fitness value with respect to the \\(K\\) tasks, where \\(j \\in\\{1,2, \\ldots, K\\}\\).",
      "chunk_id": 3686,
      "paper_id": "Using an Estimation of Distribution Algorithm to Achieve Multitasking Semantic Web Service Composition",
      "paper_title": "Using an Estimation of Distribution Algorithm to Achieve Multitasking Semantic Web Service Composition",
      "paper_year": "2023",
      "chunk_content": "MFEA is a new evolutionary paradigm that considers $K$ optimization tasks concurrently, where each task affects the evolution of a single population. In MFEA, a unified representation for the $K$ tasks allows a unified search space made for all the $K$ tasks. This unified representation of solutions can be decoded into solutions of the individual tasks. The following definitions are also given in [27] and capture the key attributes associated with each individual $\\Pi$. For simplicity, we assume that all the tasks are maximization problems (see details in Section III-B).  \nDefinition 1: The factorial cost $f_{j}^{\\Pi}$ of individual $\\Pi$ measures the fitness value with respect to the $K$ tasks, where $j \\in\\{1,2, \\ldots, K\\}$.  \nDefinition 2: The factorial rank $r_{j}^{\\Pi}$ of individual $\\Pi$ on task $T_{j}$, where $j \\in\\{1,2, \\ldots, K\\}$, is the position of $\\Pi$ in the population sorted in descending order according to their factorial cost with respect to task $T_{j}$.  \nDefinition 3: The scalar fitness $\\varphi^{\\Pi}$ of individual $\\Pi$ is calculated based on its best factorial rank over the $K$ tasks, which is given by $\\varphi^{\\Pi}={ }^{1} / \\min _{i=1,2, \\ldots, K i\\}^{n}}$.  \nDefinition 4: The skill factor of individual $\\Pi$ denotes the most effective task of the $K$ tasks, and is given by $\\tau^{\\Pi}=$ $\\operatorname{argmin}_{j}\\left\\{r_{j}^{\\Pi}\\right\\}$, where $j \\in\\{1,2, \\ldots, K\\}$.  \nBased on the scalar fitness, evolved solutions in a population can be compared across the $K$ tasks. In particular, an individual associated with a higher scalar fitness is considered to be better. Therefore, multifactorial optimality is defined as follows.  \nDefinition 5: An individual $\\Pi^{\\star}$ associated with factorial cost $\\left\\{f_{1}^{\\star}, f_{2}^{\\star}, \\ldots, f_{K}^{\\star}\\right\\}$ is optimal iff $\\exists j \\in\\{1,2, \\ldots, K\\}$ such that $f_{j}^{\\star} \\geq$ $f_{j}(\\Pi)$, where $\\Pi$ denotes any feasible solution on task FORMULA_178.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:27",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the EDA algorithm used within the Territory Defining Evolutionary Algorithm compare to Simulated Binary Crossover in terms of offspring generation, specifically considering the probabilities PEDA and PC?",
      "topics": [
        "evolutionary",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The Territory Defining Evolutionary Algorithm uses an EDA algorithm with a probability PEDA to generate offspring based on estimated distributions. Alternatively, with a probability PC, Simulated Binary Crossover is used in conjunction with Polynomial Mutation. The algorithm dynamically chooses between these offspring generation methods based on random numbers R1 and R2 compared against PEDA and PC respectively, suggesting a trade-off between distribution-based exploration and crossover-based exploitation.",
      "chunk_id": 12354,
      "paper_id": "A Hybrid Territory Defined evolutionary algorithm approach for closed loop green supply chain network design",
      "paper_title": "A Hybrid Territory Defined evolutionary algorithm approach for closed loop green supply chain network design",
      "paper_year": "2016",
      "chunk_content": "In Estimation of Distribution based Territory Defining Evolutionary Algorithm we use the estimation of the distribution of various decision variable using the information from the best of chromosomes in the solution. Larranaga and Lozano (2002) developed Estimation of distribution algorithms for evolutionary com-\nputation. Pan and Ruiz (2012) proposed an estimation of distribution algorithm for lot-streaming flow shop problems with setup times. It is assumed that the decision variables are independent and normally distributed. The parameters of the distribution are estimated by using the information in the top MX of chromosomes in the population. Now these distributions are used to generate a proportion of high quality solutions. After this step  \nTable 5\nSGA II algorithm result crossover probability 0.8 mutation probability 0.3 .  \nTable 6\nNSGA II algorithm result crossover probability 0.9 mutation probability 0.4 .  \nTerritory Defining Evolutionary Algorithm is applied to get the pareto-optimal front. A Territory Defining Multi objective Evolutionary Algorithms and Preference Incorporation was proposed by Karahan and Oksalan (2010). In subsequent section we define each step of the algorithm in detail (see Fig. 4).\nInitialize Population $P(0)$ generated randomly, by selecting a value between upper and lower limit\nNon-Dominated Sorting of $P(0)$\nInitialize Archive Population A(0) set of initial population $P(0)$ lying in first non-dominated front\nRepeat until stopping condition is reached\nGenerate a random number R1 between 0 and 1\nIf R1 is less than PEDA (probability of using EDA algorithm)  \nGenerate offspring using EDA Algorithm Else\nGenerate a random number R2 between 0 and 1\nIf R2 is less than PC (probability of crossover)\nGenerate offspring using Simulated Binary crossover algorithm\nGenerate offspring using Polynomial Mutation algorithm\nEnd\nMark all chromosomes in $P(t)$ that dominates the generated offspring\nIf Offspring is dominated by any chromosome in $P(t)$ Reject offspring\nCheck stopping condition\nElse\nMark all chromosomes in $A(t)$ dominated by offspring Remove all marked chromosomes from $A(t)$ Calculate scaled rectilinear distance of Offspring from each chromosome in $A(t)$  \nCalculate maximum scaled absolute objective difference between offspring and chromosome in $A(t)$ having minimum scaled rectilinear distance  \nIf maximum scaled absolute objective difference is greater than territory size Accept offspring in $A(t)$ Else",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:28",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned, what data structures are required to represent the 'Random Key' (RK) representation for permutation problems?",
      "topics": [
        "scheduling",
        "Estimation of Distribution Algorithm",
        "Random Key"
      ],
      "answer": "The 'Random Key' (RK) representation, as used in the RK-EDA, requires data structures suitable for continuous approaches. While the text doesn't specify the exact data structure, it implies the need for a data structure that can hold continuous values, such as floating-point numbers, to represent the keys. These keys are then used to derive a permutation for problems like Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.",
      "chunk_id": 12297,
      "paper_id": "RK-EDA- A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_title": "RK-EDA: A Novel Random Key Based Estimation of Distribution Algorithm",
      "paper_year": "2016",
      "chunk_content": "Mayowa Ayodele ${ }^{(\\boxtimes)}$, John McCall, and Olivier Regnier-CoudertRobert Gordon University, Aberdeen, UK\\{m.m.ayodele,j.mccall, o.regnier-coudert\\}@rgu.ac.uk\nThe challenges of solving problems naturally represented as permutations by Estimation of Distribution Algorithms (EDAs) have been a recent focus of interest in the evolutionary computation community. One of the most common alternative representations for permutation based problems is the Random Key (RK), which enables the use of continuous approaches for this problem domain. However, the use of RK in EDAs have not produced competitive results to date and more recent research on permutation based EDAs have focused on creating superior algorithms with specially adapted representations. In this paper, we present RK-EDA; a novel RK based EDA that uses a cooling scheme to balance the exploration and exploitation of a search space by controlling the variance in its probabilistic model. Unlike the general performance of RK based EDAs, RK-EDA is actually competitive with the best EDAs on common permutation test problems: Flow Shop Scheduling, Linear Ordering, Quadratic Assignment, and Travelling Salesman Problems.  \nKeywords: Estimation of distribution algorithm $\\cdot$ Random key $\\cdot$ Permutation problems $\\cdot$ Cooling scheme FORMULA_4 Univariate model",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:30",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the evaluation of objective function values used within the described Estimation of Distribution Algorithm (EDA)?",
      "topics": [
        "crossover"
      ],
      "answer": "The objective function value of each individual, represented as $\\mathbf{F}^{g}=\\left(f\\left(\\mathbf{x}_{1}^{g}\\right), f\\left(\\mathbf{x}_{2}^{g}\\right), \\ldots, f\\left(\\mathbf{x}_{N P}^{g}\\right)\\right)$, is evaluated for the population $\\mathbf{P}^{g}=\\left(\\mathbf{x}_{1}^{g}, \\mathbf{x}_{2}^{g}, \\ldots, \\mathbf{x}_{N P}^{g}\\right)$. This evaluation occurs in each iteration to assess the fitness of individuals, where $NP$ is the size of the population and $g$ is the iteration counter. The algorithm then selects $\\theta \\times NP$ promising individuals based on this evaluation.",
      "chunk_id": 12729,
      "paper_id": "An Operation Optimization Method Based on Improved EDA for BOF End-point Control",
      "paper_title": "An Operation Optimization Method Based on Improved EDA for BOF End-point Control",
      "paper_year": "2016",
      "chunk_content": "Set the iteration counter $g=0$\n1 Set the maximum iteration number $g_{\\max }$, and initialize the values of parameters such as the size of population $N P$, the dimension $D$ of individuals, the selective rate $\\theta$ of superior individuals, the random generated rate $\\eta$, the mutation factor $F$ and the crossover probability $C R$.\n2 Set the individuals as $\\mathbf{P}^{g}=\\left(\\mathbf{x}_{1}^{g}, \\mathbf{x}_{2}^{g}, \\ldots, \\mathbf{x}_{N P}^{g}\\right), \\mathbf{x}^{g}=\\left(x_{2}^{g}, x_{i, 2}^{g}, \\ldots, x_{N P}^{g}\\right)$, $i=1, \\ldots, N P$, and each individual is uniformly distributed in the range $[L, U]$.\n3 Evaluate the objective function value of each individual $\\mathbf{F}^{g}=\\left(f\\left(\\mathbf{x}_{1}^{g}\\right), f\\left(\\mathbf{x}_{2}^{g}\\right), \\ldots, f\\left(\\mathbf{x}_{N P}^{g}\\right)\\right)$.\n// Selection\nWhile ( $g_{\\max }$ is not satisfied) do\nSelect $\\theta \\times N P$ promising individuals from FORMULA_85.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:33",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "Based on the presented data, what is the key takeaway about the performance of the CMBO-PG algorithm compared to versions without leader or follower flocks in the context of Estimation of Distribution Algorithms on functions f3, f7, f8, f25, and f28?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The CMBO-PG algorithm, employing a co-evolutionary method with both leading and following flocks, achieves a balance between exploration and exploitation when estimating the distribution of individual fitness values, as evidenced by its performance on functions f3, f7, f8, f25, and f28, compared to versions lacking either the leader or follower flock mechanisms.",
      "chunk_id": 4019,
      "paper_id": "A co-evolutionary migrating birds optimization algorithm based on online learning policy gradient",
      "paper_title": "A co-evolutionary migrating birds optimization algorithm based on online learning policy gradient",
      "paper_year": "2023",
      "chunk_content": "[IMAGE51]  \nFig. 21a. Distribution of individual fitness values on the $f 3$ function (WITHOUT FOLLOWER).\n[IMAGE52]  \nFig. 21c. Distribution of individual fitness values on the $f 3$ function (CMBO-PG).\n[IMAGE53]  \nFig. 22a. Distribution of individual fitness values on the $f 7$ function (WITHOUT LEADER).  \n[IMAGE54]  \nFig. 22b. Distribution of individual fitness values on the $f 7$ function (WITHOUT FOLLOWER).\n[IMAGE55]  \nFig. 22c. Distribution of individual fitness values on the $f 7$ function (CMBO-PG).\n[IMAGE56]  \nFig. 23a. Distribution of individual fitness values on the $f 8$ function (WITHOUT LEADER).\n[IMAGE57]  \nFig. 23b. Distribution of individual fitness values on the $f 8$ function (WITHOUT FOLLOWER).\n[IMAGE58]  \nFig. 23c. Distribution of individual fitness values on the $f 8$ function (CMBO-PG).\n[IMAGE59]  \nFig. 24a. Distribution of individual fitness values on the $f 25$ function (WITHOUT LEADER).  \n[IMAGE60]  \nFig. 24b. Distribution of individual fitness values on the $f 25$ function (WITHOUT FOLLOWER).\n[IMAGE61]  \nFig. 24c. Distribution of individual fitness values on the $f 25$ function (CMBO-PG).\n[IMAGE62]  \nFig. 25a. Distribution of individual fitness values on the $f 28$ function (WITHOUT FOLLOWER).\n[IMAGE63]  \nFig. 25b. Distribution of individual fitness values on the $f 28$ function (WITHOUT FOLLOWER).\nbalances the exploration and exploitation well by the co-evolutionary method of the leading flock and the following flock.",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:35",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of learning a Gaussian Bayesian network in each iteration, as used in the described approach, differ from the method employed by EMNA which learns a multivariate Gaussian distribution, and how do these differences relate to the optimization process in comparison to PSO which does not consider dependencies among variables?",
      "topics": [
        "optimization"
      ],
      "answer": "The described approach learns a Gaussian Bayesian network in each iteration (lines 6-7 of Alg 1). EMNA, on the other hand, learns a multivariate Gaussian distribution from where it is sampled. PSO updates its parameters in each iteration to minimize the cost function but does not consider dependencies among variables. The key difference lies in how dependencies among variables are handled: the Gaussian Bayesian network explicitly models these dependencies, the multivariate Gaussian distribution captures them implicitly, while PSO disregards them entirely. This difference in handling dependencies affects the exploration of the search space and the ability to find optimal solutions. The text indicates that for likelihood consideration ($\\alpha \\rightarrow 1$), EMNA and PSO find better solutions than the approach using Gaussian Bayesian networks but with high values of standard deviation, while for low values of likelihood consideration ($\\\\\\alpha \\rightarrow 0$) the approach seems to find better solutions than EMNA.",
      "chunk_id": 2357,
      "paper_id": "Estimation of distribution algorithms using Gaussian Bayesian networks to solve industrial optimization problems constrained by environment variables",
      "paper_title": "Estimation of distribution algorithms using Gaussian Bayesian networks to solve industrial optimization problems constrained by environment variables",
      "paper_year": "2022",
      "chunk_content": "similar pseudo-code as our approach but instead of learning a Gaussian Bayesian network in each iteration of the evolutionary algorithm, it learns a multivariate Gaussian distribution from where it is sampled (lines 6-7 of Alg 1). PSO in each iteration updates its parameters in order to minimize the cost function but not considering dependencies among variables. This way, we compare the difference between using Gaussian Bayesian networks and not using them during the optimization process.  \nThe results are shown in Fig. 8 and in Tables 1, 2 and 3. If we analyze each of the experiments individually, it can be seen that the behavior of our approach is as expected. For low values of $\\alpha$ it finds very cheap solutions, and the cost increases with $\\alpha$, until the cost settles to the value determined by expert knowledge for $\\alpha \\rightarrow 1$, shaping a curve with a logarithmic profile. However, the behaviour of the EMNA and PSO is not as predictable as our approach for different values of $\\alpha$. For $\\alpha \\rightarrow 0$ our approach seems to find better solutions than EMNA. However, for $\\alpha \\rightarrow 1$, EMNA and PSO find better solutions than our approach, but always very far from the costs provided by the experts and with high values of standard deviation. EMNA and PSO are not learning the patterns found in data and thus, they are converging to solutions  \nTable 3 Mean and standard deviation for each of the four designed experiments and different values of $\\alpha$ executed by the PSO approach (Fig. 8)\nTable 4 Mean and standard deviation of the number of iterations and runtime until convergence for our approach, EMNA and PSO after 20 simulations\nThis experiment has been carried out with population size $N=100$ and $\\alpha=0.6$. The number of fitness evaluations would be $N Q$, where $Q$ is the number of iterations until convergence. All the results have been normalized taking as reference the results of our approach. The experiment was conducted on a Windows 10 machine with an Intel i7-5820K processor and 16 Gb of RAM\nthat are cheaper but are not of interest for the company when fully considering the likelihood of solutions in the historical data (Eq. (3)). Facing an industrial solution, when our approach considers the likelihood completely, the laboratory technicians will obtain solutions which they are accustomed to, and as $\\alpha$ is decreased, solutions that are somewhat more risky and therefore cheaper will be obtained, but they still take into account the patterns found in the data. It is interesting how the results obtained by the PSO approach when the likelihood is not considered $(\\alpha=0)$ outperforms the ones obtained by EMNA and by our approach, and the small standard deviations observed in Table 3 for $\\alpha>0$. From this, we conjecture that PSO is falling in local optima solutions which seems to have been avoided by EMNA and our approach.  \nThe set of experiments shows how in general experiments 2 and 3 are cheaper than the others, which makes sense because in both experiments we lead to solutions in which the final product is closer to a solid than to a liquid, and therefore it is not necessary to dissolve the substance as much as in experiments 1 and 4.  \nTable 4 shows a quantitative comparison of the EMNA, PSO and our approach analyzing the number of fitness evaluations and computation time until convergence. All the approaches have been evaluated under the same conditions. We can observe how our approach takes the larger runtime compared to the two other algorithms. This is due to the GBN learning in each iteration, which is a characteristic that makes our",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:37",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to optimize via placement in circuit routing, how should practitioners establish the topological graph G=(V, E) representing the circuit, specifically detailing the rules for defining vertices, edges, and edge weights?",
      "topics": [
        "routing"
      ],
      "answer": "To establish the topological graph G=(V, E) for via optimization, practitioners should follow these rules: a) The vertex set V represents the intersection points in the circuit routing diagram, with n being the total number of intersection points (e.g., n=12). b) The edge set E represents connections between intersection points. A weighted edge exists between vertices i and j if there is a direct connection between intersection points i and j; otherwise, there is no edge (or the edge has a weight of 0). c) The edge weight w_{i,j} represents the number of vias on the direct connection. If there are no vias, w_{i,j} = -1; if there is one via, w_{i,j} = 1. d) For \"T\"-shaped circuits with a via in the middle, if intersection points i and j are on the same layer, w_{i,j} = -1/2; if they are on different layers, w_{i,j} = 1/2. For example, if intersection points 5, 8, and 9 form a \"T\" shape with a via, then w_{5,8} = w_{5,9} = 1/2, and w_{8,9} = -1/2.",
      "chunk_id": 8212,
      "paper_id": "Study of Via Optimization Problem Based on Estimation of Distribution Algorithm",
      "paper_title": "Study of Via Optimization Problem Based on Estimation of Distribution Algorithm",
      "paper_year": "2019",
      "chunk_content": "All the intersection points in the circuit routing diagram shown in Fig. 2 were sequentially marked (12 intersection points in all), and the circuit routing diagram with the marked intersection points is shown in Fig. 3.\nA topological graph of the via optimization problem (undirected weighted map) was established on the basis of Fig. 3. Assume that the topological graph that was required to be established was $G=(V, E)$, where $V=\\{1,2, \\cdots, n\\}$ denotes\n[IMAGE2]  \nFig. 3 Circuit routing diagram with marked intersection points\nthe set of the largest vertices, $E \\subseteq V \\times V$ represents the set of edges. Further, $w_{i, j}$ indicates the weight of the edge connecting vertex $j$ and vertex $j$. The establishment rules of the topological graph $G=(V, E)$ were as follows:\na) The vertices set of the topological graph $V=\\{1,2, \\cdots, n\\}$ is the set of intersection points in the circuit routing diagram. For Fig. 3, $n=12$.\nb) The edges set of the topological graph $E \\subseteq V \\times V$ characterizes the connections among the intersection points in the circuit routing diagram.If there is a direct connection between intersection point $i$ and intersection point $j$, then there is a weighted edge between the corresponding vertex $i$ and vertex $j$. Otherwise, there is no weighted edge (or the edge has a weight of 0 ). As shown in Fig. 3, there is a direct connection between intersection point 1 and intersection point2, and thus, there is a weighted edge between the corresponding vertices 1 and 2 . In contrast, there is no direct connection between intersection point 1 and intersection point3, and thus, there is no weighted edge between the corresponding vertices 1 and 3 .\nc) The weight of edge $w_{i, j}$ represents the number of vias on the direct connection between the intersection points. If there is no via on the direct connection between intersection point $i$ and intersection point $j$, then the weight between the corresponding vertices $i$ and $j, w_{i, j}=-1$. If there is one via on the direct connection between intersection point $i$ and intersection point $j$, then $w_{i, j}=1$.\nd) For a \" T \"-shaped circuit with a via in the middle, if the direct connection between intersection point $i$ and intersection point $j$ is on the same layer of the board, then the weight between the corresponding vertices $w_{i, j}=-1 / 2$. If the direct connection between intersection point $i$ and intersection point $j$ is on different layers of the board, then the weight between the corresponding vertices, $w_{i, j}=1 / 2$. In Fig. 3, as intersection points 5, 8, and 9 forma \" T \"-shaped  \ncircuit with one via in the middle, the weights between the corresponding vertices $w_{5,8}=w_{5,9}=1 / 2, w_{8,9}=-1 / 2$.  \nAccording to the above rules, the topological graph of the via optimization problem established from Fig. 3, $G=(V, E)$, is shown in Fig. 4.\n[IMAGE3]  \nFig. 4 Topological graph of the via optimization problem",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:40",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the $n$-Bernoulli-$\\lambda$-EDA framework, what can be inferred about the rate at which the frequency of a neutral bit position approaches the boundaries, as discussed in Sections IV and V, and how does Section VI extend these results to bit positions with preference?",
      "topics": [
        "search"
      ],
      "answer": "Sections IV and V detail the speed at which the frequency of a neutral bit position approaches the boundaries within the $n$-Bernoulli-$\\lambda$-EDA framework. Section VI then extends the lower bound results established in Section IV to encompass bit positions that are not only neutral but also exhibit some degree of preference. The specifics of these rates and the nature of the extension are further elaborated in those sections.",
      "chunk_id": 9993,
      "paper_id": "Sharp Bounds for Genetic Drift in Estimation of Distribution Algorithms",
      "paper_title": "Sharp Bounds for Genetic Drift in Estimation of Distribution Algorithms",
      "paper_year": "2020",
      "chunk_content": "The remainder of this article is organized as follows. Section II briefly introduces PBIL and the cGA under the umbrella of the $n$-Bernoulli- $\\lambda$-EDA framework proposed in [19]. Our notation for our results is fixed in Section III. Sections IV and V discuss how fast the frequency of a neutral bit position approaches the boundaries. Section VI extends the lower bound results of Section IV to bit positions that are neutral or have some preference. Finally, in Section VII\n  \nwe argue how our results allow to interpret existing research results and how they give hints on how to choose the parameters of these EDAs.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:42",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is a key difference between EDAs that modify EDAs originally designed for integer spaces to handle permutations and EDAs that search in a continuous space?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Permutations",
        "Probabilistic Models"
      ],
      "answer": "EDAs that modify EDAs from integer spaces adjust the sampling procedure to guarantee feasible solutions where each value appears once, because they do not estimate the probabilistic model over the permutation space. In contrast, EDAs searching in a continuous space decode an n-dimensional real vector as a permutation, which can make it difficult to translate the relations between variables from the permutation space to the continuous space.",
      "chunk_id": 11929,
      "paper_id": "A Preliminary Study on EDAs for Permutation Problems Based on Marginal-based Models",
      "paper_title": "A Preliminary Study on EDAs for Permutation Problems Based on Marginal-based Models",
      "paper_year": "2011",
      "chunk_content": "Problabilistic Models, Permutations, Estimation Distribution Algorithms, Marginals, Optimization\nEstimation of Distribution Algorithms (EDAs) [17, 12, 18] are a set of methods that belong to the field of Evolutionary  \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.\nGECCO'11, July 12-16, 2011, Dublin, Ireland.\nCopyright 2011 ACM 978-1-4503-0557-0/11/07 ...\\$10.00.  \nComputation. Similarly to Genetic Algorithms [7], EDAs initialize a random set of individuals and, applying different operators, these individuals are modified to obtain optimal solutions. However, instead of using crossover and mutation operators to generate new individuals, EDAs use probabilistic models, taking advantage of the interrelations between the different variables that represent the individuals. Introduced in [17], they have attracted the interest of the Evolutionary Algorithms research community, which has developed a wide set of different algorithms and techniques in the last decade. EDA approaches have been able to successfully solve different artificial and real-world problems, both in the discrete and continuous domains [13, 14, 19, 20, 25].  \nIn this work, we are interested in the solution of a specific subset of NP-hard optimization problems. We refer to those problems whose solutions can be naturally represented as a permutation. Examples of this kind of problems are: Traveling Salesman Problem (TSP), Quadratic Assignment Problem (QAP), Linear Ordering Problem (LOP), Flow Shop Scheduling Problem (FSSP), etc. In order to apply EDAs, a new challenge has to be dealt with: the codification of a probability distribution over the space of permutations. Unfortunately, representing and learning a probability distribution over a set of permutations is much more difficult than doing the same over integer or real-valued spaces.  \nDifferent approaches have been given in the literature to deal with permutation problems by means of EDAs. Most of the approaches propose modifying EDAs designed originally for integer spaces to deal with permutations $[4,23,24,16$, 21]. In order to guarantee feasible solutions, that is, each value appears once and only once in the solution, the sampling procedure is modified accordingly. This change is necessary because these EDAs do not estimate the probabilistic model over the permutation space but over the integer space. Other EDAs carry out a search in a continuous space [5, 23, 16]. Each $n$-dimensional real vector is decoded as a permutation. These proposals also present several drawbacks, the main one being the difficulty to translate the relations between the variables in the permutation space to the continuous space and vice versa.  \nA couple of approaches which take into account the real nature of permutations by setting a probabilistic model over the permutation space are those of Tsutsui et al. [28, 29, 30]. Basically the authors consider 1-order and 2-order marginals over that space. Inspired by this concept, we propose a new EDA that implements a probabilistic model which learns $k$ order marginal probabilities between the variables $(k \\geq 1)$.  \nThese models should be able to identify better the relations (dependencies) between the variables of the problem as FORMULA_6 increases.",
      "question_type": "compare",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:44",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model described to generate the next population, specifically addressing the Gaussian model generation and individual selection?",
      "topics": [
        "analysis"
      ],
      "answer": "To generate the next population, the algorithm first selects the top 0.5*$n$ individuals from the current population. Then, for each variable of the selected individuals, a Gaussian model is constructed using statistical analysis. Subsequently, 1.5*$n$ new individuals are sampled according to this Gaussian model. Finally, the algorithm calculates the fitness values, denoted as *F* values, for these 1.5*$n$ new individuals and selects the *n* individuals with the best *F* values to form the next generation population.",
      "chunk_id": 1217,
      "paper_id": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
      "paper_title": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
      "paper_year": "2014",
      "chunk_content": "Step 1. Generate $m$ initial values $x_{1}, x_{2}, \\ldots, x_{m}$ randomly in the interval $(0,1)$. Let $X_{0}=\\left(x_{1}, x_{2}, \\ldots, x_{m}\\right)$ be an initial point of logistic map, and $m$ is the number of parameters to be optimized.  \nStep 1.1 Many researchers have demonstrated [24,25] that, for logistic map\n$X_{t+1}=\\lambda \\cdot X_{t}\\left(1-X_{t}\\right)$\nwhen the parameter $\\lambda$ satisfying $3.5699 \\leq \\lambda \\leq 4$, after $n$ times iteration, the generated $n$ individuals $X_{1}, X_{2}, \\ldots, X_{n}$ by Eq. (8) is a chaotic sequence. Let $X=\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ be a matrix with $n$ rows and $m$ columns, representing the initial population:\n$X=\\left(\\begin{array}{c}x_{1} \\\\ \\dot{x}_{2} \\\\ \\vdots \\\\ \\dot{x}_{n}\\end{array}\\right)=\\left(\\begin{array}{cccc}x_{11} & x_{12} & \\ldots & x_{1 m} \\\\ x_{21} & x_{22} & \\ldots & x_{2 m} \\\\ \\ldots & \\ldots & \\ldots & \\ldots \\\\ x_{n 1} & x_{n 2} & \\ldots & x_{n m}\\end{array}\\right)$\nStep 1.2 The initial population $X$ is extended to the range of the solution space, and the $i$ th variable of the $j$ th individual can be expressed as follows:\n$x_{j i}=l o w+($ high $-l o w) x_{j j}$\nwhere low and high are the lower and upper limits of the solution space, respectively.  \nStep 2. Calculate fitness value for each individual of the current population. For individual $X_{j}$, its fitness value is calculated as follows\n$F\\left(X_{j}\\right)=\\frac{1}{n} \\sum_{j}^{n} \\sum_{1}^{m}\\left(d_{j i}-y_{j i}\\right)^{2}$\nwhere, $d_{j i}$ is the $i$ th actual output value of the $j$ th individual, $y_{j i}$ is the $i$ th predict output value of the $j$ th individual. For Eq. (9), $F(\\cdot)$ is as small as possible.  \nStep 3. Select individuals according to the mutation probability $p_{m}<1$ to realize chaotic mutation. We calculate the mutation radius of selected individual. The mutation radius of $i$ th variable $x_{j i}$ of the individual $X_{j}$ is calculated according to the following equation\n$R_{j i}=\\frac{v_{i}\\left(i\\left(1-F\\left(X_{j}\\right)\\right)\\right.}{\\max _{1 \\leq i \\leq n} F\\left(X_{i}\\right)}$\nwhere $v(i)=\\left(2\\left(\\max x_{<i}-\\min x_{<i}\\right) / n\\right)$. And, $i$ th variable of the individual $X_{j}$ after mutation can be expressed as $x_{j i}^{\\prime}=x_{j i}+2 R_{j i}(1-$ $\\left.x_{j i}\\right)$. After mutating each selected individual, we calculate the fitness value $F$ of each new individual. If the fitness value $F$ of new individual is less than $F$ value of old individual, then new individuals replace old individuals, and we can obtain the new population, go to Step 4. Otherwise maintain the population not to change, go to Step 5.  \nStep 4. Determine whether to meet the stop criterion of the algorithm, if met, the output current the best individual, otherwise go to Step 5.  \nStep 5. Generate next population.\nStep 5.1 Select the first 0.5 n individuals from the current population. After statistical analysis of selected individuals, build a Gaussian model for each variable of the individual.  \nStep 5.2 Sample 1.5 n new individuals accordance to the Gaussian model.  \nStep 5.3 Calculate $F$ values of these 1.5 n new individuals, and compare their $F$ values, then choose $n$ better individuals as the next generation population.\n[IMAGE0]  \nFig. 1. Framework of IEDA model.  \nStep 6. Determine whether to meet the stop criterion of the algorithm, if met, the output current the best individual, otherwise go to Step 3.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:45",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of minimizing the objective function F for integrated production scheduling, how is the performance of assigning linkage modes $k$ to slabs $i$ evaluated, considering the objective weight coefficient $\\lambda_{1}$ and the starting times $s_{p, i}^{R}$ and $s_{b, i}^{C}$?",
      "topics": [
        "algorithm"
      ],
      "answer": "The performance is evaluated by minimizing the objective function $F = (\\lambda_{1} \\sum_{i=1}^{n} k \\cdot z_{i, k} + \\sum_{i=1}^{n}(s_{p, i}^{R} - s_{b, i}^{C} - t^{C}))$. This function considers both the weighted sum of linkage modes $k$ assigned to slabs $i$ (indicated by $Z_{i, k}$), and the difference between the starting time of slab $i$ in rolling unit $p$ ($s_{p, i}^{R}$) and the starting time of slab $i$ in cast $b$ ($s_{b, i}^{C}$), adjusted by the processing time $t^{C}$ of each slab in the CC stage. Minimizing $F$ thus aims to optimize linkage mode assignments and reduce the time interval between continuous casting and hot rolling.",
      "chunk_id": 2245,
      "paper_id": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_title": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_year": "2022",
      "chunk_content": "Indices:\n$m \\quad$ index of continuous casting machines (CCMs), and $M$ is the number of CCMs.\n$b, d \\quad$ index of casts, and $n^{C}$ is the number of casts.\n$i, j \\quad$ index of slabs, and $n$ is the number of slabs.\n$p, q \\quad$ index of rolling units, and $n^{R}$ is the number of rolling units.\nParameters:\n$a_{i, b} \\quad$ position of slab $i$ in cast $b$.\n$a_{i, p} \\quad$ position of slab $i$ in rolling unit $p$.\n$t^{C} \\quad$ processing time of each slab in CC stage.\n$t^{R} \\quad$ processing time of each slab in HR stage.\n$T_{b}^{C} \\quad$ processing time of cast $b$ in CC stage.\n$T_{p}^{R} \\quad$ processing time of rolling $p$ in HR stage.\n$U^{C} \\quad$ setup time between two successive casts in a machine.\n$U^{R} \\quad$ setup time between two successive rolling units.\n$k \\quad$ linkage mode, 1 for DHCR, 2 for HCR, 3 for CCR.\n$T_{b}^{\\min } \\quad$ minimum time interval for slabs in a process assigned with linkage mode $k$.\n$T_{b}^{\\max } \\quad$ maximum time interval for slabs in a process assigned with linkage mode $k$.\n$\\lambda_{1} \\quad$ objective weight coefficient, determined according to manual experience.\n$\\operatorname{big} M$ a large number.\nDecision Variables:\n$\\alpha_{p} \\quad$ weight coefficient of linkage mode for rolling unit $p$.\n$X_{b, m} \\quad$ if cast $b$ is arranged on $\\mathrm{CCM} m, X_{b, m}=1$, otherwise $X_{b, m}=0$.\n$Y_{b, d, m}$ if cast $b$ and cast $d$ are processed by CCM $m$, and $b$ directly precedes $d$, then $Y_{b, d, m}=1$, otherwise $Y_{b, d, m}=0$.\n$Y_{p, q} \\quad$ if rolling unit $p$ directly precedes $q, Y_{p, q}=1$, otherwise $Y_{p, q}=0$.\n$Z_{i, k} \\quad$ if linkage mode $k$ is assigned with slab $i, Z_{i, k}=1$, otherwise $Z_{i, k}=0$.\n$s_{b}^{C} \\quad$ starting time of cast $b$ at CC stage.\n$s_{b, i}^{C} \\quad$ starting time of slab $i$ in cast $b$ at CC stage.\n$s_{p}^{R} \\quad$ starting time of rolling unit $p$ at HR stage.\n$s_{p, i}^{R} \\quad$ starting time of slab $i$ in rolling unit $p$ at HR stage.\n$v_{i} \\quad$ interval between CC-HR of slab $i$.\nThe mathematical model is formulated as follows.  \n$$\n\\min F=\\left(\\lambda_{1} \\sum_{i=1}^{n} k \\cdot z_{i, k}+\\sum_{i=1}^{n}\\left(s_{p, i}^{R}-s_{b, i}^{C}-t^{C}\\right)\\right)\n$$  \nSubject to  \nFORMULA_64",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:48",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when addressing permutation problems such as the Traveling Salesman Problem?",
      "topics": [
        "genetic"
      ],
      "answer": "The overall purpose is to develop Estimation of Distribution Algorithms that can effectively handle permutation problems by learning and modeling probability distributions directly over the space of permutations, rather than relying on integer or continuous space representations. The approach involves implementing a probabilistic model that learns $k$-order marginal probabilities between variables to better identify dependencies within the problem.",
      "chunk_id": 11929,
      "paper_id": "A Preliminary Study on EDAs for Permutation Problems Based on Marginal-based Models",
      "paper_title": "A Preliminary Study on EDAs for Permutation Problems Based on Marginal-based Models",
      "paper_year": "2011",
      "chunk_content": "Problabilistic Models, Permutations, Estimation Distribution Algorithms, Marginals, Optimization\nEstimation of Distribution Algorithms (EDAs) [17, 12, 18] are a set of methods that belong to the field of Evolutionary  \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.\nGECCO'11, July 12-16, 2011, Dublin, Ireland.\nCopyright 2011 ACM 978-1-4503-0557-0/11/07 ...\\$10.00.  \nComputation. Similarly to Genetic Algorithms [7], EDAs initialize a random set of individuals and, applying different operators, these individuals are modified to obtain optimal solutions. However, instead of using crossover and mutation operators to generate new individuals, EDAs use probabilistic models, taking advantage of the interrelations between the different variables that represent the individuals. Introduced in [17], they have attracted the interest of the Evolutionary Algorithms research community, which has developed a wide set of different algorithms and techniques in the last decade. EDA approaches have been able to successfully solve different artificial and real-world problems, both in the discrete and continuous domains [13, 14, 19, 20, 25].  \nIn this work, we are interested in the solution of a specific subset of NP-hard optimization problems. We refer to those problems whose solutions can be naturally represented as a permutation. Examples of this kind of problems are: Traveling Salesman Problem (TSP), Quadratic Assignment Problem (QAP), Linear Ordering Problem (LOP), Flow Shop Scheduling Problem (FSSP), etc. In order to apply EDAs, a new challenge has to be dealt with: the codification of a probability distribution over the space of permutations. Unfortunately, representing and learning a probability distribution over a set of permutations is much more difficult than doing the same over integer or real-valued spaces.  \nDifferent approaches have been given in the literature to deal with permutation problems by means of EDAs. Most of the approaches propose modifying EDAs designed originally for integer spaces to deal with permutations $[4,23,24,16$, 21]. In order to guarantee feasible solutions, that is, each value appears once and only once in the solution, the sampling procedure is modified accordingly. This change is necessary because these EDAs do not estimate the probabilistic model over the permutation space but over the integer space. Other EDAs carry out a search in a continuous space [5, 23, 16]. Each $n$-dimensional real vector is decoded as a permutation. These proposals also present several drawbacks, the main one being the difficulty to translate the relations between the variables in the permutation space to the continuous space and vice versa.  \nA couple of approaches which take into account the real nature of permutations by setting a probabilistic model over the permutation space are those of Tsutsui et al. [28, 29, 30]. Basically the authors consider 1-order and 2-order marginals over that space. Inspired by this concept, we propose a new EDA that implements a probabilistic model which learns $k$ order marginal probabilities between the variables $(k \\geq 1)$.  \nThese models should be able to identify better the relations (dependencies) between the variables of the problem as FORMULA_6 increases.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:49",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs for optimizing deep neural networks, how does the algorithmic mechanism of an EDA-based approach overcome the disadvantage of gradient dependence, as compared to layer-wise pre-training with gradient-based training algorithms?",
      "topics": [
        "search"
      ],
      "answer": "The provided text suggests that EDA-based algorithms can be used for the optimization of deep neural networks and achieve the same performance as layer-wise pre-training schemes. The core advantage highlighted is that the EDA algorithm can overcome the disadvantage of gradient dependence. The specific algorithmic mechanism by which the EDA achieves this is not detailed, but the text implies that EDAs offer an alternative optimization strategy that does not rely on gradient information, unlike gradient-based training algorithms.",
      "chunk_id": 8547,
      "paper_id": "EDA based Deep Neural Network Parameter Optimization",
      "paper_title": "EDA based Deep Neural Network Parameter Optimization",
      "paper_year": "2019",
      "chunk_content": "According to the simulation, the proposed scheme is valid for the optimization of deep neural network. The layer-wised pretraining is carried out for the gradient based training algorithms. For the EDA based algorithm, we can see that the optimization of the whole deep neural has the same performance as the layerwised pre-training scheme. Therefore, the EDA algorithm can be used for the optimization of deep neural network conveniently, which also can overcome the disadvantage of gradient dependence.\nThis work was supported by the National Natural Science Foundation of China under Grants (61603214, 61573213, 61673245, 61803227), National Key Research and Development Plan of China under Grant 2017YFB1300205, Shandong Province Key Research and Development Plan under Grants (2018GGX101039,2016ZDJS02A07), China Postdoctoral Science Foundation under Grant 2018M630778 and Independent Innovation Foundation of Shandong University under Grant 2018ZQXM005.",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:51",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for camera self-calibration, how should practitioners configure the EMNA${}_{\\text{global}}$ algorithm to optimize camera parameters, given the constraint of a visible horizontal ground plane and a known approximate range of the camera height?",
      "topics": [
        "search"
      ],
      "answer": "When configuring the EMNA${}_{\\text{global}}$ algorithm, practitioners should represent camera parameters as variables to be optimized within the EDA framework. The algorithm then iteratively refines a multivariate normal distribution based on promising solutions sampled from the distribution. Given the constraint of a visible horizontal ground plane with at least three different locations not on the same straight line observable and a known approximate range of camera height, the algorithm searches for optimal parameters by minimizing the average reprojection error on the ground plane. Parallel computation can be adopted in sampling the population at each generation to improve efficiency.",
      "chunk_id": 12854,
      "paper_id": "Camera self-calibration from tracking of moving persons",
      "paper_title": "Camera Self-Calibration from Tracking of Moving Persons",
      "paper_year": "2016",
      "chunk_content": "Although self-calibration from object tracking has been studied for years, it is still facing many challenges. In all the above methods, the performance of self-calibration is highly dependent on the accuracy of extracted head and foot locations, which is related to the robustness of segmentation and tracking approach. Furthermore, it is common to adopt RANSAC to eliminate outlier points in the estimation of $V_{T}$ and $L_{H}[7,10-11]$, however, due to noise in measurement, the number of outliers can overwhelm inliers in some scenarios, which will lead to failure of this method. And the threshold of RANSAC needs to be fine-tuned every time as well. Last but not least, Mohedano and Garcia [12] analyze and conclude that complete selfcalibration based on estimated $V_{T}$ and $L_{H}$ cannot be achieved if more than one of the intrinsic parameters is unknown. That is why all the mentioned works [6-11] assume that the focal length is the only parameter to be estimated in the intrinsic parameter matrix. This ambiguity in computation will lead to increasing reprojection error. Other limitations also prohibit the development of this area. The work in [6-7] requires accurate detection of leg-crossing for calibration. Hence, it cannot work well when the angle between the object moving direction and the principal axis of the camera is small. In [8], they need to assume that the objects are moving at a constant velocity, and the noise model of measurements is known. The work in [11] assumes that the variation of relative pedestrian heights in the camera's field of view (FOV) is sufficiently low. These are generally not the cases in real world.  \n[IMAGE0]  \nFig. 1. Overview flow chart of the proposed system.\nIn this paper, we propose to use a robust object segmentation and tracking system to achieve accurate head/foot localization. Besides, mean shift clustering is applied to estimate $V_{T}$, so that the method is less affected by large number of outliers. Also, we adopt Laplace linear regression to formulate the fitting of $L_{H}$ into a convex optimization problem. In this way, there is no need to set the threshold parameter to indicate inliers like RANSAC. Moreover, we formulate the problem of optimization based on minimizing the average reprojection error on the ground plane. In this innovative formulation, we do not need to know the actual heights of all walking humans, but only a rough range of the camera height. Fig. 1 shows the overview flow chart of our proposed camera self-calibration scheme.  \nOur method first employs the estimation of distribution algorithm (EDA) to search for the optimal parameters in camera calibration. This type of search algorithms is based on probabilistic modeling of promising solutions combined with the simulation of the induced models to guide the search. Among the category of EDAs, we adopt the Estimation of Multivariate Normal Algorithm - global (EMNA ${ }_{\\text {global }}$ ) [13] to optimize all camera parameters simultaneously. In this way, the assumptions of prior knowledge in intrinsic parameters can be relaxed. In our work, we only assume that the people are walking on a visible horizontal ground plane with at least three different locations not on the same straight line observable, and an approximate range of the camera height is known. Therefore, our self-calibration algorithm can be applied widely in video surveillance systems. The advantages of EDAs against most of other metaheuristics are discussed in detail in the review paper [14], including ability to adapt their operators to the structure of the problem, reduced memory requirements, etc. Because parallel computation can be adopted in sampling the population at each generation, the efficiency of EDA can be much higher compared to many other nonlinear optimization approaches.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:53",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the quadratic fitness function, defined as $\\max \\left(\\sum_{i=1}^{n} f\\left(x_{2 i-1}, x_{2 i}\\right)\\right)$ where $x_{2 i-1}, x_{2 i} \\in{0,1}$ and $f(u, v)=0.9-0.9(u+v)+1.9 u v$, what is the optimal solution and its corresponding fitness value?",
      "topics": [
        "fitness"
      ],
      "answer": "The optimal solution for the quadratic fitness function is a string with ones on all positions, where $x_{2i-1} = 1$ and $x_{2i} = 1$. In this case, $f(1, 1) = 1$. The maximum fitness value is achieved when all pairs of bits are equal to one.",
      "chunk_id": 7525,
      "paper_id": "Hybrid sampling on mutual information entropy-based clustering ensembles for optimizations",
      "paper_title": "Hybrid sampling on mutual information entropy-based clustering ensembles for optimizations",
      "paper_year": "2010",
      "chunk_content": "The quadratic fitness function used for comparisons in this section is defined as\n$\\max \\left(\\sum_{i=1}^{n} f\\left(x_{2 i-1}, x_{2 i}\\right)\\right) \\quad x_{2 i-1}, x_{2 i} \\in\\{0,1\\}$\nwhere\n$f(u, v)=0.9-0.9(u+v)+1.9 u v$\nWith both arguments equal to zero we get $f_{2}(0,0)=0.9$. With different arguments we get $f_{2}(0,1)=f_{2}(1,0)=0$. With both\n[IMAGE2]  \nFig. 3. Convergent velocity on Onemax Function.  \n[IMAGE3]  \nFig. 4. Convergent process on Onemax Function.\n[IMAGE4]  \nFig. 5. Convergent reliability on Quadratic Function.\narguments equal to one we get $f_{2}(1,1)=1$. The optimum is clearly in the string with ones on all positions.  \nThe experimental results on Quadratic function are shown in Figs. 5, 6 and 7, respectively.\nDeceptive function is often used for comparisons of different optimization methods for its being deceptive. With deceptive problems, the average fitness of low order schemata present in optimum is lower than the average fitness of alternative ones. The fitness function is defined as,\n$\\max \\sum_{i=1}^{\\frac{n}{2}} f\\left(x_{3 i-2}, x_{3 i-1}, x_{3 i}\\right) \\quad x_{i} \\in\\{0,1\\}$\nwhere\n$u=x_{3 i-2}+x_{3 i-1}+x_{3 i}$\n[IMAGE5]  \nFig. 6. Convergent velocity on Quadratic Function.\n[IMAGE6]  \nFig. 7. Convergent process on Quadratic Function.\nand\n$f(u)= \\begin{cases}0.9 & \\text { if } u=0 \\\\ 0.8 & \\text { if } u=1 \\\\ 0.0 & \\text { if } u=2 \\\\ 1.0 & \\text { otherwise }\\end{cases}$\nThis problem is a hard deceptive problem which has a large number of local optimal solutions. The input string is first partitioned into independent groups of 3 bits each. And this partitioning is unknown to the algorithm and it does not change during the run. The deceptive-3 function has one global optimum for all ones and a deceptive attractive to all zeros. The corresponding experimental results on this problem are also displayed in Figs. 8, 9 and 10.\nThe general k-bit trap functions are defined as\n$F_{k}\\left(b_{1}, \\ldots, b_{k}\\right)= \\begin{cases}f_{\\text {high }} & \\text { if } u=k \\\\ f_{\\text {low }}-\\left(u \\times f_{\\text {low }}\\right) /(k-1) & \\text { otherwise }\\end{cases}$  \n[IMAGE7]  \nFig. 8. Convergent reliability on Deceptive Function.\n[IMAGE8]  \nFig. 9. Convergent velocity on Deceptive Function.\n[IMAGE9]  \nFig. 10. Convergent process on Deceptive Function.  \nWhere $b_{i}$ is in $0,1, u=\\sum_{i=1}^{k} b_{i}$ and $f_{h g h}>f_{b w}$. Usually, $f_{h g h}$ is set at $k$ and $f_{b w}$ is set at $k-1$. The Trap functions denoted by $F_{m+k}$ are defined as\n$F_{m+k}\\left(k_{1}, \\ldots, k_{m}\\right)=\\sum_{i=1}^{m} F_{k}\\left(k_{i}\\right), k_{i} \\in\\{0,1\\}^{k}$\nThe $m$ and $k$ are varied to produce a number of test functions. In all trails, FORMULA_109 was set to 5 . The Trap function fool the gradientbased optimizers to favor zeros, but the optimal solution is composed of all ones. We also do the same experiments by using four different algorithm to test the solutions on the Trap function. The following Figs. 11, 12 and 13 shows the experiment results.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:45:55",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What are the key algorithmic differences between MN-FDA and MN-EDA in how they model dependencies within the population, and how does this impact accuracy?",
      "topics": [
        "optimization"
      ],
      "answer": "MN-FDA uses a junction graph derived from a Markov network, which is refined by deleting edges to manage clique size, potentially removing necessary dependencies. MN-EDA, on the other hand, employs a Kikuchi approximation of energy, which covers a higher number of dependencies without adding new edges, leading to potential accuracy gains compared to MN-FDA. MN-EDA also utilizes Gibbs sampling for its sampling portion.",
      "chunk_id": 12553,
      "paper_id": "MICPSO  A method for incorporating dependencies into discrete particle swarm optimization",
      "paper_title": "MICPSO: A Method for Incorporating Dependencies into Discrete Particle Swarm Optimization",
      "paper_year": "2016",
      "chunk_content": "1) Introduction to EDAs: Estimation of Distribution Algorithms are somewhat semantically related to ICPSO in that they are based on the idea of building a probability distribution to reflect desirable candidate solutions [2]. The general EDA procedure begins by randomly generating an initial population of solutions. Some subset of these solutions are selected based on their fitness, similar to the selection procedure in a genetic algorithm. Then, the algorithm constructs a probabilistic model using these selected solutions. In some cases, this includes structure as well as parameter learning; in others, the structure is known beforehand and fixed. This model is then sampled to create more candidate solutions, which replace some portion of the previous generation's population, and the process repeats. Over multiple iterations, this should lead to a population with increasing average fitness.  \nOften the probabilistic model used in an EDA is a Bayesian network. However, Bayesian networks are restricted to be\ndirected acyclic graphs. In the case of a constrained optimization problem, this can be a restriction on the representational power of the model as constraints can be bidirectional and cyclic in nature. Thus, we focus our review of literature on the class of discrete EDAs that use an undirected model, a Markov network, which permits cycles. Additionally, we are interested primarily in EDAs that can represent higherorder interactions between variables, rather than univariate or bivariate EDAs. Univariate models assume problem variables are independent, and bivariate models similarly restrict the allowable number of interdependencies between variables, limiting the representational power of the model. Given that our algorithm does not place a restriction on the number of interdependencies in the model, we chose to compare to EDAs that had similar representational power.\n2) Markov Network Factored Distribution Algorithm (MNFDA): MN-FDA is an EDA that uses a junction graph as the underlying probabilistic model [9]. The algorithm uses independence tests to learn a Markov network structure from the population. The network structure can also be given as an input, rather than being learned by the algorithm. This network is then modified by incrementally deleting edges between nodes that have degree larger than some specified maximum, in order to decrease the density of the graph. This refinement is necessary to manage the size of the resulting cliques; however, it also has the potential to remove dependencies from the graph beyond what is necessary. The algorithm then uses this network to construct a junction graph from which additional points are sampled.  \nWhile earlier EDAs based on undirected models generally used a junction tree to represent factorizations, the use of a junction graph allows cycles and thus extends the representational power of the model. This means that the junction graph can more closely fit the underlying distribution [10].\n3) Markov Network Estimation of Distribution Algorithm (MN-EDA): Santana proposed MN-EDA as a novel method to approximate and sample probability distributions [11]. The learning portion of MN-EDA is accomplished through the use of a modified version of the Kikuchi approximation of energy from statistical physics, and the sampling portion of the algorithm relies on Gibbs sampling. The Kikuchi approximation was chosen because it has a number of properties that are particularly useful in an EDA context. When compared to MN-FDA and its reliance on junction graphs, MN-EDA's use of the Kikuchi approximation covers a higher number of dependencies, which can result in accuracy gains. Additionally, these dependencies can be captured without adding new edges to the underlying graph, making this a preferable choice to procedures like triangulation algorithms.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:45:57",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model that samples from the BBP model, as described, including the handling of the group order and clique construction?",
      "topics": [
        "search"
      ],
      "answer": "The procedure for sampling from the BBP model involves the following steps: First, initialize the Clique to an empty set, denoted as $\\mathbb{D}$. Reorder the group $I$ into a new order $J$ such that the weights $W$ of the vertices in $J$ are in descending order (i.e., $W(j_1) \\geqq W(j_2) \\geqq \\dots \\geqq W(j_m)$). Then, iterate $M$ times, where $M$ is not defined within the provided content. In each iteration $i$, sample a vertex $V_{ij}$ from group $I(j_i)$ according to the probability distribution given by equation (2) (equation not shown in the provided content). After sampling each vertex, update the Clique by combining the sampled vertex, $V_{ij}$, using the unspecified FORMULA_98. Finally, output the constructed Clique.",
      "chunk_id": 5759,
      "paper_id": "A Bi-level Blocked Estimation of Distribution Algorithm with Local Search for Maximum Clique Problems",
      "paper_title": "A Bi-level Blocked Estimation of Distribution Algorithm with Local Search for Maximum Clique Problems",
      "paper_year": "2008",
      "chunk_content": "BBP model gives the estimation of the distribution of optimal vertices. By sampling from BBP model, a clique in promising area can be generated. A vertex-adding construction is used in sampling, which selects a vertex from group to group in the order $J$ according to a probability distribution in (2).  \nThe cliques generated in this way are all feasible solutions to MCP. Moreover, due to the unused vertex is assigned to a high $f\\left(v_{0}\\right)$ value, new and promising areas of the search space can be explored. The procedure of sampling from BBP model is as follows:  \nInput: $I, W, B$;\nClique $=\\mathbb{D}$;\n$\\mathrm{J}=$ reorder group $I$ such that $W\\left(j_{1}\\right) \\geqq W\\left(j_{2}\\right) \\geqq \\oplus$\n$W\\left(j_{m}\\right)$;\nFor $i=1: M$\nSample a vertex $V_{i j}$ from group $I\\left(j_{i}\\right)$ according to the probability distribution given by equation (2).  \nClique $=$ Clique FORMULA_98;\nEnd For\nOutput: Clique\nIn this section, the local search methods in BBEDA are described at first. Then the updating method of BBP model during the local search is present. Based on them, the outline of BBEDA algorithm for MCP is given.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:45:59",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the PAUMDA and PAPBIL algorithms in the context of filter implementation?",
      "topics": [
        "analysis"
      ],
      "answer": "The effectiveness of the PAUMDA and PAPBIL algorithms is evaluated using the fractional bit-width of coefficients $a$ ($\\mathrm{FB}_{a}$), coefficients $b$ ($\\mathrm{FB}_{b}$), intermediate variables ($\\mathrm{FB}_{i v}$), the input signal ($\\mathrm{FB}_{x}$), and the output signal ($\\mathrm{FB}_{z}$). The required error ($E_{\\text {req }}$) is also a key metric, with values such as 0.9, 0.1, and 0.01 used in the evaluation.",
      "chunk_id": 2158,
      "paper_id": "Precision Analysis for an Optimal Parallel IIR Filter s Implementation",
      "paper_title": "Precision Analysis for an Optimal Parallel IIR Filter's Implementation",
      "paper_year": "2022",
      "chunk_content": "- Required error : $E_{\\text {req }}=0.1$;\n- Input signal: $x \\in[-100,100]$.  \nFor PAUMDA algorithm:  \n- Number of individuals in the initial population: $M=20$;\n- The best individuals selected at each iteration : $S=10$.  \nFor PAPBIL algorithm:  \n- Learning rate : $\\alpha=0.1$;\n- Number of individuals in the initial population: $M=20$.  \nTable 1 Experimental results: comparison to [36]  \nNext, we introduce the second type of precision analysis method. In this part, we apply our approach (PAPBIL) using the algorithm proposed in 2012 by Sarbishei et al. [37] which offers an MFB for the input signals as well as the intermediate signals of the IIR filter. Subsequently, we compare the results obtained by applying the approach proposed in [37] for the parallel structure with the results obtained by applying our approach. Unlike the latter, our approach proposes a different FB for each block of the filter (\" $i$ \" is used to differentiate between blocks in the different tables); for example, for the first benchmark, the approach presented in [37] proposes an identical FB for all feedback coefficients of all filter blocks $\\left(\\mathrm{FB}_{a}=14\\right)$, while our approach proposes a different FB for the feedback coefficients of each block $\\left(\\mathrm{FB}_{a_{1}}=10\\right.$ and $\\left.\\mathrm{FB}_{a_{2}}=14\\right)$.  \nFor this analysis method, the cost reduction reaches $19.88 \\%$. For the simulation, we keep the same input variables as in the first experiment. The results are summarized in Table 2 as follows :  \n- $\\mathrm{FB}_{a}$ : Fractional bit-width of coefficients $a$;\n- $\\mathrm{FB}_{b}$ : Fractional bit-width of coefficients $b$;\n- $\\mathrm{FB}_{i v}$ : Fractional bit-width of the intermediate variables;\n- $\\mathrm{FB}_{x}$ : Fractional bit-width of the input signal;\n- $\\mathrm{FB}_{z}$ : Fractional bit-width of the output signal.  \nTo visualize the behavior and the performance of the proposed methods, we carry out an analysis while varying the value of the required error of the filter. In this analysis, we use the BWO method proposed in 2018 by Lamini et al. [20] to calculate the integer part (IB) and fractional part (FB) of all interconnections and filter block coefficients. Unlike the first heuristic [36], this method provides an MFB for interconnections and filter coefficients.  \nWe choose this method for its optimized complexity, as it gives an effective solution compared to the other methods proposed in the literature [19, 36, 37]. The robustness, efficiency, and speed of problem resolution with this method are due to the proposed error analysis and the adopted data width allocation process.  \nFirst, we propose an equitable partition of the required error on different blocks of the filter and then we compare the results obtained by this partition with the results of the partitions obtained by applying our two approaches. The results of the simulations are shown in Table 3, such as:  \nTable 2 Experimental results: comparison to [37]  \n- Column 1: presents the five labels of benchmarks used for the simulations;\n- Column 2: illustrates the different required error used $\\left(E_{\\text {req }}=\\{0.9 ; 0.1 ; 0.01\\}\\right)$;\n- Column 3: presents the three types of partition proposed for this analysis. First, there is the equitable partition, then a partition according to the PAUMDA algorithm and finally a partition according to the PAPBIL algorithm;",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:01",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs when applied to the Flexible Job Shop Problem (FJSP)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to enhance the efficiency of EDAs in solving the FJSP by constructing a probability model based on the frequency of neighboring operations. This model aims to capture the characteristics of the FJSP, allowing the algorithm to partition optimal individuals into independent sub-blocks, which are then adjusted as a whole to avoid redundant searches and accelerate the optimization process, ultimately leading to improved solutions for the FJSP.",
      "chunk_id": 11913,
      "paper_id": "An New Estimation of Distribution Algorithm Based Edge Histogram Model for Flexible Job-Shop Problem",
      "paper_title": "An New Estimation of Distribution Algorithm Based Edge Histogram Model for Flexible Job-Shop Problem",
      "paper_year": "2011",
      "chunk_content": "Xiaojuan $\\mathrm{He}^{1,2}$, Jianchao Zeng ${ }^{2}$, Songdong Xue ${ }^{2}$, Lifang Wang ${ }^{2}$${ }^{1}$ College of Electrical and Information Engineering, Lanzhou University of Technology, Lanzhou, China${ }^{2}$ Complex System and Computational Intelligence Laboratory, Taiyuan University of Science and Technology, Taiyuan, China hexjxian@gmail.com, zengjianchao@263.net, \\{xuesongdong,wlf1001\\}@163.com\nAn estimation of distribution algorithm for flexible job shop scheduling problem was proposed. The probability model was given using frequency information of pair-wise operations neighboring. Then the structure of optimal individual was marked and the operations of optimal individual were partitioned to some independent sub-blocks. Each sub-block was taken as a whole to be adjusted to avoid repeating search in same area and improve search speed. The experimental results show that the proposed algorithm is efficient for Flexible Job-Shop Problems.  \nKeywords: FJSP, Estimation of Distribution Algorithms, Neighboring Operations, Probability Model.\nThe job-shop scheduling problem is one of the most popular manufacturing optimization models used in practice. Flexible job shop problem (FJSP) is a generalization of the job shop that allows one operation to be processed on any machine from a set of alternative machines. It is closer to the real manufacturing situation. The extension includes two tasks: Assignment operations to appropriate machines and sequencing the operations on each machine. These features of the FJSP obviously increase the complexity of finding optimal solutions even of approximately optimal solutions. So the task is more challenging than the classical job shop[1,2]. In recent years, metaheuristic techniques such as simulated annealing, tabu search and evolutionary algorithms have been adopted to solve the FJSP to find a promise solution and many promising results have been obtained $[3,4,5]$.  \nA new evolutionary algorithm based on probability analysis, i.e., estimation of distribution algorithms (EDAS) has become very popular. The algorithm relies on the construction and maintenance of a probability model that characterizes satisfactory solutions for a problem. And this probabilistic model is used to guide further exploration of search space and realize evolution process. EDAS effectively overcomes the problem of blocks being disrupted, has shown to perform very well on a wide variety  \nof problem that traditional GA difficult to solved, especially on high dimensional complex problems $[6,7]$.  \nIn this paper, we propose an efficient method to solve the flexible job shop problems. The probability model that can well reflect the character of the flexible job shop scheduling problem is built and improves the ability of edas to solve the flexible job shop scheduling problem. This paper is organized as follows: In Section 2, we shortly describe the basic framework of EDAS and FJSP. Section 3 gives a detail description of new proposed algorithm for FJSP. Section 4 discusses the experimental results. Finally, Section 5 summarizes the contribution of this paper.\nEDAS is a class of novel evolutionary algorithms. The algorithms represent relations between the variables by building probability model [6]. Main steps are summarized as follows:  \nStep 1 Generate initial population.\nStep 2 Evaluate population. Select some better individuals as superior population. Construct the probability model according to the information of superior population.  \nStep 3 Sampling from the probability model constructed and generates new population, evaluate new population. Select new superior population.  \nStep 4 Update the probability model.\nRepeatedly do the step 3 and step 4 until the termination criteria is met.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:02",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Estimation of Distribution Algorithms (EDAs) that employ Gaussian models, what fundamental properties distinguish the proposed $\\mathrm{EDA}_{\\text{revers}}$ from conventional EDAs, specifically regarding its mechanisms for addressing premature convergence?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The $\\mathrm{EDA}_{\\text{revers}}$ distinguishes itself from conventional EDAs through two key algorithmic strategies designed to mitigate premature convergence. First, it incorporates a novel probability density estimator that adaptively enlarges the variances. This variance enlargement endows the EDA with more flexible search behavior by preventing the rapid shrinkage of the search range. Second, it introduces a reflecting sampling strategy. This strategy aims to improve search efficiency for the estimated probability density. These two strategies combine to allow $\\mathrm{EDA}_{\\text{revers}}$ to outperform conventional EDAs.",
      "chunk_id": 12154,
      "paper_id": "Enhance Continuous Estimation of Distribution Algorithm by Variance Enlargement and Reflecting Sampling",
      "paper_title": "Enhance Continuous Estimation of Distribution Algorithm by Variance Enlargement and Reflecting Sampling",
      "paper_year": "2016",
      "chunk_content": "Zhigang Ren ${ }^{\\dagger}$, Member IEEE, Chenlong He, Dexing Zhong, Shanshan Huang, and Yongsheng LiangDepartment of Automation Science and Technology, School of Electronic and Information EngineeringXi'an Jiaotong University, Xi'an, China${ }^{\\dagger}$ Email: renzg@mail.xjtu.edu.cn\nEstimation of distribution algorithm (EDA) is a kind of typical model-based evolutionary algorithm (EA). Although possessing competitive advantages in theoretical analysis, current EDAs may encounter premature convergence due to the rapid shrinkage of the search range and the relatively low sampling efficiency. Focusing on continuous EDAs with Gaussian models, this paper proposes a novel probability density estimator which can adaptively enlarge the variances and thus endow EDA with flexible search behavior. For the estimated probability density, a reflecting sampling strategy which can further improve the search efficiency is put forward. With these two algorithmic strategies, a new EDA variant named $\\mathrm{EDA}_{\\text {revers }}$ is developed. Experimental results on a set of benchmark problems demonstrate that $\\mathrm{EDA}_{\\text {revers }}$ outperforms conventional EDAs and can produce superior solutions in comparison with some state-of-the-art EAs.  \nKeywords-estimation of distribution algorithm; premature convergence; probability density; reflecting sampling",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:04",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using the MO-PSO-EDA approach, how should practitioners configure the population sizes and subpopulation number?",
      "topics": [
        "optimization"
      ],
      "answer": "When implementing MO-PSO-EDA, the evolving particle population size, denoted as N, should be set to 100. The external elite population size, denoted as M, should also be set to 100. Furthermore, the subpopulation number, denoted as K, should be set to 5.",
      "chunk_id": 4412,
      "paper_id": "A hybrid multi-objective PSO-EDA algorithm for reservoir flood control operation",
      "paper_title": "A hybrid multi-objective PSO-EDA algorithm for reservoir flood control operation",
      "paper_year": "2015",
      "chunk_content": "In the experimental studies, the proposed MO-PSO-EDA is first tested on some benchmark problems with different characteristics in Section 5.2. Then in Section 5.3, MO-PSO-EDA is applied to flood control operation on Ankang reservoir in Shanxi province of China.\nIn MO-PSO-EDA, the evolving particle population size $N$ and the external elite population size $M$ are both set as 100 . The subpopulation number $K$ is set as 5 .  \nTable 1\nMulti-objective optimization test problems.  \nIn order to evaluate the quality of non-dominated solution sets found by the comparing algorithms, the hyper-volume (HV) performance measure proposed by Zitzler et al. [55] is employed in this work. The HV value corresponds to the non-overlapped volume of all the hyper-cubes formed by a reference point $R$. In this work, the reference point $R$ is set by maximum values of nondominated solutions obtained by the compared algorithms. Note $p$ as a non-dominated solution in the Pareto approximation set $P F_{m}$ of an $m$-dimensional MOP. The hyper-volume performance measure can be mathematically defined as follows:\n$\\mathbf{H V}=\\Lambda\\left(\\bigcup_{p \\in \\mathrm{PF}_{m}}\\{x \\mid p<x<R\\}\\right)$\nIn which, $\\Lambda$ is the Lebesgue measure, $R \\in \\mathbf{R}^{m}$ is the user-defined reference point in the $m$-dimensional objective space, which is dominated by all valid candidate solutions in FORMULA_212.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:05",
      "generation_style": "practical_application"
    },
    {
      "question": "In the described Estimation of Distribution Algorithm (EDA), how are the job sequences $\\sigma^{P}$ and $\\sigma^{E}$ generated, and what role do the position values $\\varphi_{j}(\\sigma^{P})$ and $\\varphi_{j}(\\sigma^{E})$ play in constructing a new individual?",
      "topics": [
        "objectives"
      ],
      "answer": "The EDA initializes by generating two job sequences: $\\sigma^{P}$, which sorts jobs in descending order based on the sums of their processing times, and $\\sigma^{E}$, which sorts jobs in descending order based on the sums of their due dates. Within the main loop, a weight vector $(w_{1}, w_{2})$ is defined, where $w_{1}$ is calculated as $l/(\\text{PS}-1)$ and $w_{2}$ as $1 - (l/(\\text{PS}-1))$, with $l$ ranging from 1 to PS (population size). The weighted sum of job position values, $\\phi_{j} = w_{1} \\times \\varphi_{j}(\\sigma^{P}) + w_{2} \\times \\varphi_{j}(\\sigma^{E})$, is then computed for each job $j$, where $\\varphi_{j}(\\sigma^{P})$ and $\\varphi_{j}(\\sigma^{E})$ represent the position values of job $j$ in the permutations $\\sigma^{P}$ and $\\sigma^{E}$, respectively. These $\\phi_{j}$ values are used to generate a permutation $\\sigma^{0}$ by sorting jobs in ascending order of their weighted position values. This permutation $\\sigma^{0}$ then forms the basis for constructing a new individual $\\pi$ in the population.",
      "chunk_id": 8581,
      "paper_id": "A Pareto-Based Estimation of Distribution Algorithm for Solving Multiobjective Distributed No-Wait Flow-Shop Scheduling Problem With Sequence-Dependent Setup Time",
      "paper_title": "A Pareto-Based Estimation of Distribution Algorithm for Solving Multiobjective Distributed No-Wait Flow-Shop Scheduling Problem With Sequence-Dependent Setup Time",
      "paper_year": "2019",
      "chunk_content": "Output: The initial population POP  \n1: Generate a job sequence $\\sigma^{P}$ by sorting jobs in descending sums of their processing times.\n2: Generate a job sequence $\\sigma^{E}$ by sorting jobs in descending sums of their due date. Let $l=1$.\n3: while $l \\leq \\mathrm{PS}$ do\n4: Set a weight vector $\\left(w_{1}, w_{2}\\right)$ as $(l /(\\mathrm{PS}-1), 1-(l /(\\mathrm{PS}-$ 1))).  \n5: Calculate the weighted sum of job position values $\\phi_{j}=$ $w_{1} \\times \\varphi_{j}\\left(\\sigma^{P}\\right)+w_{2} \\times \\varphi_{j}\\left(\\sigma^{E}\\right)$ for $j=1,2, \\cdots, n$, where $\\varphi_{j}\\left(\\sigma^{P}\\right)$ and $\\varphi_{j}\\left(\\sigma^{E}\\right)$ denote the position values of job $j$ in permutation $\\sigma^{P}$ and $\\sigma^{E}$.\n6: Generate a permutation $\\sigma^{0}$ by sorting jobs in ascending weighted sum of their position values $\\phi_{j}$. Let $\\pi$ represent the new generated individual.\n7: The first $F$ jobs $\\left[\\sigma^{0}(1), \\sigma^{0}(2), \\cdots, \\sigma^{0}(F)\\right]$ of $\\sigma^{0}$ are taken and let $\\pi^{f}(1)=\\sigma^{0}(f), f=1,2, \\cdots, F$.\n8: Take job $\\sigma^{0}(k), k=F+1, F+2, \\cdots, n$, insert it into all possible positions of $\\pi$, and the position resulting in the minimum weighted sum of the two objectives values $f(\\pi)$ is selected. Insert $\\sigma^{0}(k)$ to this position.\n9: $\\quad \\operatorname{POP}(\\mathbf{l})=\\pi, l=l+1$\n10: end while",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:08",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between the PFT heuristic and the NEH heuristic when used within the PFTNEH(x) algorithm?",
      "topics": [
        "complexity"
      ],
      "answer": "The PFTNEH(x) algorithm utilizes both the PFT heuristic to produce an initial solution and the NEH heuristic to improve it. The NEH heuristic involves calculating $(2n - \\lambda + 1)\\lambda / 2$ partial sequences. To mitigate this computational cost, the algorithm employs a fast Insert-based neighbor evaluation method, reducing the complexity of the NEH heuristic from $O(mm^3)$ to $O(mm^2)$. The variable $x$ controls the number of solutions obtained, while $\\lambda$ determines the number of jobs reinserted by the NEH heuristic.",
      "chunk_id": 2036,
      "paper_id": "A matrix-cube-based estimation of distribution algorithm for blocking flow-shop scheduling problem with sequence-dependent setup times",
      "paper_title": "A matrix-cube-based estimation of distribution algorithm for blocking flow-shop scheduling problem with sequence-dependent setup times",
      "paper_year": "2022",
      "chunk_content": "4: Select a job with the smallest $T P$ as the initial job. Set $\\boldsymbol{\\pi}=[\\pi(1)]$.\n5: $U \\leftarrow J-\\{\\pi(1)\\}$. Let job in $U$ be $\\pi_{u}(t), t=1,2, \\ldots,|U|$.\nfor $i=1$ to $n-2$ do\nCompute the departure time $d_{\\pi(i), j}$ for $\\pi=[\\pi(1), \\pi(2), \\ldots, \\pi(i)]$.\nfor $t=1$ to $|U|$ do\nCompute the departure time $d_{\\pi_{u}(t), j}=d_{\\pi(i+1), j}$. If job $\\pi_{u}(t)$ is appended and became the $(i+1)$ th job in partial sequence $\\pi$.\nCompute the sum of idle and blocking time.  \n$$\n\\delta_{\\pi_{u}(t), i}=\\sum_{j=1}^{m}\\left(d_{\\pi(i+1), j}-d_{\\pi(i), j}-p_{\\pi_{u}(t), j}\\right)\n$$  \n11: Select a job resulting in smallest $\\delta_{\\pi_{u}(t), i}$ as the $(i+1)$ th job in $\\pi$. Remove the selected job $\\pi_{u}(t)$ from the unscheduled job set $U$. end for\n13: end for\n14: The last job in $U$ is directly appended to $\\pi$ as the $n$th job of $\\pi$.\n15: return $\\pi$.\nInput: $\\pi, \\tilde{\\boldsymbol{\\Pi}}, x, \\lambda$.\nOutput: The best solution $\\pi$ in $\\tilde{\\boldsymbol{\\Pi}}$.\n1: Initial solution set $\\tilde{\\boldsymbol{\\Pi}}$. Set $\\tilde{\\boldsymbol{\\Pi}} \\leftarrow \\varnothing$.\n2: Initial sequence $\\hat{\\pi}=[\\hat{\\pi}(1), \\hat{\\pi}(2), \\ldots, \\hat{\\pi}(n)]$ is obtained by ascending jobs in unscheduled job set $U$ according to the priority indicator $I(i)$.\nfor $i=1$ to $x$ do\nSelect job $\\hat{\\pi}(i)$ from $\\hat{\\pi}=[\\hat{\\pi}(1), \\hat{\\pi}(2), \\ldots, \\hat{\\pi}(n)]$ as the initial job in $\\pi$.\n5: Perform the PFT heuristic to produce a solution $\\pi$. Set $\\tilde{\\boldsymbol{\\Pi}} \\leftarrow \\tilde{\\boldsymbol{\\Pi}} \\cup \\pi$.\n6: Divide $\\pi=[\\pi(1), \\pi(2), \\ldots, \\pi(n)]$ into two partial sequences by $\\lambda$,\n$\\hat{\\pi}^{\\mathbf{1}}=[\\pi(1), \\pi(2), \\ldots, \\pi(n-\\lambda)], \\hat{\\pi}^{\\mathbf{2}}=[\\pi(n-\\lambda+1), \\pi(n-\\lambda+2), \\ldots, \\pi(n)]$.\nfor $k=n-\\lambda+1$ to $n$ do //NEH heuristic.\nSelect job $\\pi(k)$ from $\\pi$ and reinsert it into $n-\\lambda+1$ possible positions of $\\hat{\\pi}^{\\mathbf{1}}$ to obtain $n-\\lambda+1$ partial sequences.\nSelect a partial sequence resulting in the lowest makespan.\nend for\n11: Obtain a new feasible solution $\\pi^{\\prime}$. Set $\\tilde{\\boldsymbol{\\Pi}} \\leftarrow \\tilde{\\boldsymbol{\\Pi}} \\cup \\pi^{\\prime}$.\n12: end for\n13: return $\\tilde{\\boldsymbol{\\Pi}}$.  \nIn Algorithm 2, the value of $x$ in the first layer loop directly determines the number of solutions obtained in $\\Pi$, and the value of $\\lambda$ in the second loop controls the number of jobs to be inserted by the NEH heuristic. Note that the tie-breaking strategy is utilized in both the ordering and constructing phases if two jobs with the same $I(i)$ or two positions result in the same $n_{i}$. It is clear that there are $(2 n-\\lambda+1) \\lambda / 2$ partial sequences that need to be calculated in the NEH heuristic of the PFTNEH $(x)$. It should be noted that the fast Insert-based neighbor evaluation method explained in Subsection 4.3.1 is employed in the NEH heuristic, and its complexity can be reduced from $O\\left(\\mathrm{~mm}^{3}\\right)$ to $O\\left(\\mathrm{~mm}^{2}\\right)$. Thus, Algorithm 2 has a total complexity of about FORMULA_226.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:10",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What programming considerations are important when implementing the HEDA algorithm described for the Traveling Salesman Problem (TSP), specifically regarding population diversity and local search?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Traveling Salesman Problem",
        "Implementation"
      ],
      "answer": "When implementing the HEDA algorithm, it's important to consider the population size, which is initialized to 100. To maintain diversity, mutation and negative feedback operations are designed. For local exploitation, three Variable Neighborhood Search (VNS) strategies are incorporated into the EDA. If the optimal value is not evolving for 30 generations, local search and variation operations take effect. The algorithm stops when the best solution is found or the maximum number of iterations (5000 generations) is reached.",
      "chunk_id": 754,
      "paper_id": "Solving TSP Problems with Hybrid Estimation of Distribution Algorithms",
      "paper_title": "Solving TSP Problems with Hybrid Estimation of Distribution Algorithms",
      "paper_year": "2014",
      "chunk_content": "In order to verify the effectiveness of the algorithm, we code the procedure on Visual C++ 2012 on Lenovo G480 processor and use the well-known data sets TSPLIB for testing.  \nAs a result of the algorithm running time limit, this paper set up an algorithm obtained that when the best solution provided by TSPLIB or run to maximum the algebra operation stop. All of the following tests' largest number of iterations is set to 5000 generations. $\\partial=0.15$. The Minimum probability is $0.0001 * \\partial / \\mathrm{L}$. The size of initial population is 100 . Advantage of population's size is 30 . The largest probability is $0.9999 * \\partial / \\mathrm{L}$, if the optimal value is not evolution for 30 generations, local search strategy and variation operation will be take effect.  \n[IMAGE2]  \nFig. 3. The best route of pr76\nHEDA find the best route of pr76, which was shown in fig3.\nMake gr24 as the test example, and the algorithm (HEDA) runs 20 times, the results was shown in table 1 . In order to verify the effectiveness of the algorithm, the algorithm is compared with other algorithms in this paper, which include EHBSA algorithm, OX algorithm and eER algorithm from the literature 14; the test data of algorithm (MMIC) and improved algorithm (IMMIC) from the literature 17. The simulation results of the gr48 were shown in table 2. This algorithm is same to gr24 problem in Settings. Table 3 shows the results of the algorithm to solve the some TSP problems, and every case was run 20 times.  \nIn the three tables, Scale means the scale of initial population, Times means the times of simulation run. Best means the best solution provided by TSPLIB. We ran the program 20 times, took the average and the best, Op is the best, Average is the average. Algebra means the number of iterations while Op is equal to Best. The pr136 case' best route is not found  \nTable 1. gr24 test results  \nTable 2. gr48 test results  \nTable 3. The TSP test results\nThrough the test data, we can get the following conclusion:\n(i) Table 1 and table 2 show that the algorithm effective is very good in solving gr24 gr48 problem. The Average is better than other algorithms, which suggest that HEDA has the higher searching ability.\n(ii) The algebra to obtain best route can be seen from table 3. We can see that algorithm has a high search speed, less number of iterations. This suggests that the neighborhood strategy can be very good to speed up the search speed and improve the quality of evolution.\n(iii) According to the three table above, we can see that most of the testing example' best solution can be found and can maintain the stability. This suggests that the algorithm has high global search ability.\nIn this paper, an effective estimation of distribution algorithm based on Bayes probability model is proposed for solving the TSP problem. For local exploitation, three effective Variable Neighborhood Search (VNS) were incorporated into EDA. For global exploration, we design mutation operation and negative feedback operation to improve the diversity of population. The simulation results and comparisons with some existing algorithms demonstrated the effectiveness of the HEDA. The future work is to design EDA based algorithm for the massive TSP problem.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:12",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's output be measured using the weighing factor '' and population size when optimizing the initial core of AHWR-LEU?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The quality of the EDA's output for AHWR-LEU core optimization is sensitive to the weighing factor '' and population size. A very small value of '' with a large population size may lead to unnecessary computations without guaranteeing a well-optimized loading pattern. The optimized loading pattern with a lower population size can sometimes outperform one with a higher population size, indicating that both '' and population size affect the performance and efficiency of the EDA.",
      "chunk_id": 12736,
      "paper_id": "Performance of Estimation of distribution algorithm for initial core loading optimization of AHWR-LEU",
      "paper_title": "Performance of Estimation of distribution algorithm for initial core loading optimization of AHWR-LEU",
      "paper_year": "2016",
      "chunk_content": "[^0]:     Corresponding author.  \nE-mail address: thakur@harc.gov.in (A. Thakur).  \nreactivity is called as Type-2. The AHWR-LEU core consists of 444 fuel lattice locations. By exploiting symmetry of the core, the problem size for AHWR-LEU initial core optimization reduces to $2^{62}$ $\\left(\\sim 10^{16}\\right)$. Simulation of all these loading patterns is not practical in a finite time scale to choose the best loading pattern. The optimization of initial core of AHWR-LEU is a complex combinatorial optimization problem. Population based algorithms are frequently being used for fuel loading pattern optimization problem. Genetic algorithm (GA) (Goldberg, 1989; Parks, 1996; Chapot et al., 1999), simulated annealing (SA) (Stevens et al., 1995) and Ant Colony Algorithm (ACO) (Machado and Schirru, 2002) are few examples of population based evolutionary algorithms which have been successfully applied for core reloading optimization problems of Pressurized water reactors (PWRs). Estimation of distribution algorithm (EDA) (Jiang et al., 2006) has been applied successfully to CONSORT research reactor where five different types of fuels are to be loaded in 24 locations with the objective of maximization of $k$-effective. The typical size in this problem is $\\sim 10^{12}$. Jiang et al. has considered a population size of 50 in each generation along with a very small value of weighing factor ' $\\alpha$ ' ( 0.001 ). It is also observed that Jiang et al. has carried out more than 2000 generations. It is only possible because the objective function considered is maximization of $k$-effective only. And the prediction of $k$ effective is done by Artificial neural network (ANN) (Jiang et al., 2006). By using ANN, a large number of loading patterns can be analyzed for $k$-effective values in very short time. Mishra et al., 2009 has successfully applied EDA to initial core loading optimization of Pressurized heavy water reactors (PHWRs). The problem size in this problem is $\\sim 10^{65}$. They have tried to find the optimized loading pattern with fixed number of Th or depleted U fuel bundles. They have defined objective function based on penalty method and have also used EDA for optimization of initial core of PHWR. Due to the complexity of objective function, a full 3D diffusion calculations are required and which necessitate the use of parallel processing. Mishra et al. (2009) have used earlier experience of (Balakrishnan and Kakodkar, 1994) for fixing the number of Thorium bundles between 18 and 36 and they have tried to search the optimization between these 18 and 36 Thorium bundles. It is also observed (Mishra et al., 2009) that the optimized loading pattern with lower population is better than the optimized loading pattern with higher population size in some cases. In their analysis, they have considered same value of weighing factor ' $\\alpha$ ' ( 0.05 ) for all the population sizes. In the optimization analysis presented in this paper, we have applied EDA to optimize initial core of AHWR-LEU and it is observed that the optimization results are very sensitive to weighing factor ' $\\alpha$ ' and population size of each generation. It is also observed that while choosing a very small value of weighing factor ' FORMULA_29 ' with large population size algorithm may lead to unnecessary computations and may not always lead to a good optimized loading pattern.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:14",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs, specifically concerning the iterative process involving population selection and probability distribution estimation?",
      "topics": [
        "search"
      ],
      "answer": "The algorithmic approach detailed for EDAs aims to iteratively evolve a population by estimating and sampling from a joint probability distribution. In each generation \\(t\\), a subset of \\(M\\) individuals, denoted as \\(\\xi{t}^{(s)}\\), is selected from the \\(N\\) individuals in the current population \\(\\xi{t}\\). A joint probability distribution \\(p(x \\mid \\xi{t}^{(s)})\\) is then estimated based on this selected subset. Subsequently, \\(N\\) new individuals for the next generation \\(\\xi{t+1}\\) are sampled from this estimated probability distribution, effectively guiding the search towards promising regions of the search space. This process repeats until a predefined stopping criterion is met.",
      "chunk_id": 7438,
      "paper_id": "Analysis of Computational Time of Simple Estimation of Distribution Algorithms",
      "paper_title": "Analysis of Computational Time of Simple Estimation of Distribution Algorithms",
      "paper_year": "2010",
      "chunk_content": "T. Chen, K. Tang, and G. Chen are with the Nature Inspired Computation and Applications Laboratory, School of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China (e-mail: cetacy@mail.ustc.edu.cn; ketang@ustc.edu.cn; glchen@ustc.edu.cn). X. Yao is with the Nature Inspired Computation and Applications Laboratory, School of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China, and also with the Center of Excellence for Research in Computational Intelligence and Applications, School of Computer Science, University of Birmingham, Edgbaston, Birmingham B15 2TT, U.K. (e-mail: x.yao@cs.bham.ac.uk). Digital Object Identifier 10.1109/TEVC.2009.2040019  \nTABLE I\nGENERAL PROCEDURE OF EDA\n```\n\\(\\xi{1} \\leftarrow N\\) individuals are generated by the initial probability distribution;\n\\% Beginning of the 0th generation.\n\\(t \\leftarrow 1 ; \\quad \\%\\) End of the 0th generation.\nREPEAT\n\\(\\xi{t}^{(s)} \\leftarrow M\\) individuals are selected from the \\(N\\) individuals in \\(\\xi{t} ;\\)\n\\% Beginning of the \\(t\\) th generation \\((t \\geq 1)\\).\n\\(p\\left(x \\mid \\xi{t}^{(s)}\\right) \\leftarrow\\) The joint probability distribution is estimated from \\(\\xi{t}^{(s)}\\);\n\\(\\xi{t+1} \\leftarrow N\\) individuals are sampled from \\(p\\left(x \\mid \\xi_{t}^{(s)}\\right)\\);\n\\(t \\leftarrow t+1 ; \\quad \\%\\) End of the \\(t h\\) generation.\nUNTIL THE STOPPING CRITERION IS MET.",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:30",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of probability model updating in HyEDA differ between offspring generation and initial population creation, and what is the mathematical basis for this difference?",
      "topics": [
        "genetic"
      ],
      "answer": "In HyEDA, the probability model $p_{ij}$ is initialized differently than how it's updated for offspring generation. For the initial population, $p_{ij}$ is set to $1 / (M * K)$ for all $1 \\leq i \\leq M$ and $1 \\leq j \\leq K$, where $M$ and $K$ likely represent the dimensions of the grid. This means each grid point has an equal probability of being selected initially. For offspring generation at generation $t$, the probability model $p_{ij}$ produced in the 'modeling' stage (not detailed in this context) is directly applied. The selection process then uses a roulette-wheel selection based on these probabilities to pick locations, adjusting probabilities to zero for neighbors within a Tchebycheff norm distance $d_{min}$ to implement an 'Accept-Reject' process, influencing the probability distribution for subsequent selections.",
      "chunk_id": 5532,
      "paper_id": "A HYBRID ESTIMATION OF DISTRIBUTION ALGORITHM FOR CDMA CELLULAR SYSTEM DESIGN",
      "paper_title": "A HYBRID ESTIMATION OF DISTRIBUTION ALGORITHM FOR CDMA CELLULAR SYSTEM DESIGN",
      "paper_year": "2008",
      "chunk_content": "HyEDA employs the same sampling method for both offspring generation and population initialization. To sample for the initial population, the probability model $p_{i j}$ is set to $1 /(M * K)$ for all $1 \\leq i \\leq M$ and $1 \\leq j \\leq K$. To sample new offspring at generation $t$, the probability model $p_{i j}$ produced in the modeling is applied.  \nThe sampling process for a solution is as follows. To locate the $n$ grid points required for the solution, we select locations based on the probability model one by one. In each step, a location is picked from the available grid points proportionally to the probabilities associated with these grid points. For example, to pick the first location, the probability values for all the grid points can be rearranged from $(1,1)$ to $(M, K)$ to form a vector, we can then normalize the vector to proportionally select a location, which is the same as the famous roulette-wheel selection ${ }^{8}$ in genetic algorithm.  \n[^0]where $d$ is taken as the Tchebycheff norm.  \n[^0]:    ${ }^{a} \\mathrm{~A}$ grid point $g$ belongs to a cluster $k$ in the sense that the distance between $g$ and the centroid $c_{k}=\\left(x_{k}^{*}, y_{k}^{*}\\right)$ is the minimum among all distances of $g$ and $c_{i}, 1 \\leq i \\leq n$, i.e.  \n$$\n    k=\\arg \\min _{i} d\\left(g, c_{i}\\right)\n    $$  \n[IMAGE0]  \nFig. 2. The probability assignment used by the proposed probability model.  \nOnce a grid point is picked as a BS location, its neighborhoods of grid points are not considered as the candidates for a next potential BS location any more (here we make use of the specific knowledge of the CDMA cellular system design problem. That is, it is less likely that any two BSs in the system configuration would lie much close to each other. Since EDA can readily use this problem-specific knowldege, we adopt EDA rather than other evolutionary approaches, such as genetic algorithms). We achieve this through setting their probabilities to be zero. The neighborhood set of a grid point $g_{i}$ is defined as $\\mathcal{D}\\left(g_{i}\\right)=\\left\\{z: d\\left(z, g_{i}\\right) \\leq d_{\\min }\\right\\}$, where $d_{\\min }$ is a userdefined parameter and $d\\left(z, g_{i}\\right)$ is the Tchebycheff norm distance between $z$ and $g_{i}$. Such a process is called \"Accept-Reject\" process which has been used in the Monte Carlo simulation. FORMULA_171 For each location picked, it is either accepted if it has enough distance between each of the picked BSs' locations, or rejected if its distance to a certain BS is less than a given distance. From the view of the probability model, the original probability model is changed after each pick of a BS location. Then the same roulette-wheel selection process can be applied again to pick a new location. The process continues until the required number of locations are all assigned.",
      "question_type": "algorithmic",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:32",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners consider the trade-off between solution quality and running time when choosing between the cEDA and MIMIC algorithms, especially in the context of combinatorial optimization problems?",
      "topics": [
        "optimization"
      ],
      "answer": "When choosing between cEDA and MIMIC for combinatorial optimization, practitioners should note that cEDA can significantly reduce running time, particularly for medium-scale and large-scale instances with many jobs. While cEDA may produce solutions of slightly lower quality compared to MIMIC, the reduction in running time generally increases with the number of jobs. For example, when tested on benchmark optimization functions like the Sphere function \\(f_{1}(\\mathbf{x})=\\sum_{i=1}^{n} x_{i}^{2}\\), Ackley function \\(f_{2}(\\mathbf{x})\\), and another function \\(f_{3}(\\mathbf{x})=\\sum_{i=1}^{n}\\left[\\left(x_{1}-x_{i}^{2}\\right)^{2}+\\left(x_{i}-1\\right)^{2}\\right]\\), cEDA outperforms MIMIC in terms of running time. The dimensions \\(n\\) of these functions can be set to 10, 20, or 30. If rapid computation is prioritized, cEDA's simpler structure offers an advantage, accepting a potential minor decrease in solution quality compared to MIMIC.",
      "chunk_id": 10609,
      "paper_id": "Minimizing the resource consumption of heterogeneous batch-processing machines using a copula-based estimation of distribution algorithm",
      "paper_title": "Minimizing the resource consumption of heterogeneous batch-processing machines using a copula-based estimation of distribution algorithm",
      "paper_year": "2018",
      "chunk_content": "From Tables 21 to 25, it can be concluded that the proposed cEDA approach outperforms MIMIC $_{C}$ in small-scale instances in terms of quality of solutions and running time. And in mediumscale and large-scale instances, the proposed cEDA approach can obtain the solutions, which are very close to the solutions produced by MIMIC $_{C}$, in much less time. In other words, the proposed cEDA approach can reduce greatly the running time, at the expense of a little bit of the quality of solutions.  \nFig. 5 illustrates that with the number of jobs increasing, the reduction of RT generally becomes larger. Meanwhile, the quality of solutions cEDA obtained is still very close to MIMIC $_{C}$.  \nTable 20\nPerformance comparisons between the cEDA and PSO for 200 jobs.  \nTable 21\nPerformance comparisons between the cEDA and MIMIC, for 10 jobs.  \nThe benchmarks of well-known shop scheduling problems in Taillard [72] are all combinatorial optimization problems. For demonstrating the effectiveness of cEDA in well-known problems, the cEDA is tested in three benchmark optimization functions, such as Sphere function $\\left(f_{1}\\right)$, Ackley function $\\left(f_{2}\\right)$, etc. And the dimensions of all three functions are set to 10,20 and 30 in this experiment. The definition of the three functions are given in Eq.(35). The experimental results are in Table 26. And the results show that the cEDA outperforms MIMIC ${ }_{c}$. The running time of cEDA can be gret if compared to $M I M I C_{c}$. This result is consistent with the experimental result in this paper. The reduction in the running\ntime of cEDA can be attributed to its simple structure.\n$f_{1}(\\mathbf{x})=f_{1}\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\sum_{i=1}^{n} x_{i}^{2}, \\quad x_{i} \\in[-100,100]$\n$f_{2}(\\mathbf{x})=f_{2}\\left(x_{1}, \\ldots, x_{n}\\right)=-20 e^{-0.2 \\sqrt{\\frac{1}{n}} \\sum_{i=1}^{n} x_{i}^{2}}-e^{\\frac{1}{n} \\sum_{i=1}^{n} \\cos (2 \\pi x_{i})}$\n$+20+e, x_{i} \\in[-5,5]$\n$f_{3}(\\mathbf{x})=f_{3}\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\sum_{i=1}^{n}\\left[\\left(x_{1}-x_{i}^{2}\\right)^{2}+\\left(x_{i}-1\\right)^{2}\\right]$,\n$x_{i} \\in[-10,10]$  \nTable 22\nPerformance comparisons between the cEDA and MIMIC, for 20 jobs.  \nTable 23\nPerformance comparisons between the cEDA and MIMIC, for 50 jobs.\nIn this section, the convergence profiles of cEDA, GA, PSO and MIMIC, on five different scale instances are given. For all instances, the job size comes from the uniform distribution of intervals [1,5], the workload comes from the uniform distribution of intervals [1,8], and the deadline is equal to 20. As can be seen from Fig. 6, compared with cEDA and MIMIC, GA and PSO converge prematurely especially for small-sized instances. Although both cEDA and MIMIC, can maintain the diversity of the population well, the proposed cEDA approach can greatly reduce the running time as we stated before in Section 5.3.4.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:35",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, under what mathematical conditions does the use of Optimal Computing Budget Allocation (OCBA) within the Order-based EDA (OEDA) guarantee an improvement in the identification of superior individuals in the solution space, given the stochastic nature of the problem?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The provided text indicates that OCBA, based on the idea of ordinal optimisation, is used within the OEDA to evaluate solutions and identify superior ones in a random environment. However, it does not explicitly provide mathematical conditions or theorems that guarantee an improvement in the identification of superior individuals. It mentions that OCBA is used to allocate the computing budget, implicitly suggesting that the allocation aims to improve the evaluation process. A probability model describes the probability distribution of the solution space, and an updating mechanism updates this model with superior individuals. The text does not specify the mathematical requirements for OCBA's success within the OEDA.",
      "chunk_id": 4422,
      "paper_id": "An order-based estimation of distribution algorithm for stochastic hybrid flow-shop scheduling problem",
      "paper_title": "An order-based estimation of distribution algorithm for stochastic hybrid flow-shop scheduling problem",
      "paper_year": "2015",
      "chunk_content": "Estimation of distribution algorithm (EDA) (Larranaga and Lozano 2002) is a novel kind of evolutionary algorithm based on statistical learning, which has gained increasing studies and wide applications during recent years. Due to different kinds of the relationships among variables, EDA has different models. Accordingly, it can be classified as univariate model, bivariate model or multivariate model. Univariate model assumes that the variables are independent of each other, e.g., the population-based incremental learning (Baluja 1994), the univariate marginal distribution algorithm (Muhlenbein and Paass 1996) and the compact GA (Harik, Lobo, and Goldberg 1999). Bivariate model assumes that each variable is associated with another one, e.g., the mutual information maximisation for input clustering (De Bonet, Isbell, and Viola 1997), the combining optimisers with mutual information trees (Baluja and Davies 1997) and the bivariate marginal distribution algorithm (Pelikan and Muhlenbein 1999). Multivariate model considers the relationship between all the variables, e.g., the factorised distribution algorithms (Muhlenbein and Mahnig 1999), the extended compact GA (Harik 1999) and the Bayesian optimisation algorithm (Pelikan 2005). So far, EDA has been applied to a variety of academic and engineering problems, such as feature selection (Saeys et al. 2003), inexact graph matching (Cesar et al. 2005), software testing (Sagarna and Lozano 2005), flow-shop scheduling (Jarboui, Eddaly, and Siarry 2009), resource-constrained project scheduling (Wang and Fang 2012), multidimensional knapsack problem (Wang, Wang, and Fang 2012), flexible job-shop scheduling (Wang, Wang, Xu, et al. 2012, 2013b; Wang, Wang, and Liu 2013) and distributed scheduling (Wang et al. 2013a).  \nIn this paper, an order-based EDA (OEDA) is proposed to solve the SHFSP. Due to the stochastic nature of the problem, optimal computing budget allocation (OCBA) technology based on the idea of ordinal optimisation (Chen et al. 2000) is used in the algorithm. To be specific, a probability model is designed to describe the probability distribution of the solution space, and an updating mechanism is provided to update the probability model with the superior individuals. By sampling the probability model, new individuals can be generated to track the search area with promising solutions. Meanwhile, the OCBA technology is used to evaluate solutions and identify the superior ones in the random environment. In addition, the parameter  \nsetting is investigated, and extensive numerical testing results are provided. The comparisons with the existing algorithm demonstrate the effectiveness and robustness of the proposed OEDA.  \nThe remainder of the paper is organised as follows. In Section 2, the SHFSP is described. In Section 3, the basic EDA is introduced briefly and the OEDA for the SHFSP is presented in detail. The influence of parameter setting is investigated in Section 4, and the testing results and comparisons are provided as well. Finally, the paper ends with some conclusions and scope for future work in Section 5.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:37",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is a key algorithmic difference between the selection procedure used in NSGA-II and the selection procedure described, and what is the trade-off of this difference?",
      "topics": [
        "selection"
      ],
      "answer": "The selection procedure is similar to that used in NSGA-II, but it removes solutions from Pop(t+1) one by one and recalculates the crowding distances before deciding which solution should be deleted. This recalculation increases the diversity of the solutions at the cost of extra computation.",
      "chunk_id": 5713,
      "paper_id": "RM-MEDA  A Regularity Model-Based Multiobjective Estimation of Distribution Algorithm",
      "paper_title": "RM-MEDA: A regularity model-based multiobjective estimation of distribution algorithm (vol 12, pg 41, 2008)",
      "paper_year": "2008",
      "chunk_content": "Step 1) Partition $Q \\cup \\operatorname{Pop}(t)$ into different fronts $F_{1}, \\ldots, F_{l}$ by using the fast nondominated sorting approach. Set $\\operatorname{Pop}(t+1)=\\emptyset$ and $k=0$.  \nDo  \n$$\n\\begin{gathered}\nk=k+1 \\\\\n\\operatorname{Pop}(t+1)=\\operatorname{Pop}(t+1) \\cup F_{k} \\\\\n\\text { Until }|\\operatorname{Pop}(t+1)| \\geq N\n\\end{gathered}\n$$  \nStep 2) While $|\\operatorname{Pop}(t+1)|>N$, Do\nFor all the members in $F_{k} \\cap \\operatorname{Pop}(t+1)$, compute their crowding distances in $F_{k} \\cap \\operatorname{Pop}(t+1)$.\nRemove the element in $F_{k} \\cap \\operatorname{Pop}(t+1)$ with the smallest crowding distance from $\\operatorname{Pop}(t+1)$. In the case when there are more than one members with the smallest crowding distance, randomly choose one and remove it.\nThis selection operator selects $N$ members from $Q \\cup \\operatorname{Pop}(t)$ for forming $\\operatorname{Pop}(t+1)$. Step 1 implements an elitism mechanism. The best fronts in $Q \\cup \\operatorname{Pop}(t)$ are added to $\\operatorname{Pop}(t+1)$. After Step 1  \n$$\n\\operatorname{Pop}(t+1)=\\bigcup_{j=1}^{k} F_{j}\n$$  \nthe last front in $\\operatorname{Pop}(t+1)$ is $F_{k}$, the $k$ th front, which contains the \"worst\" solutions in $\\operatorname{Pop}(t+1)$. When $|\\operatorname{Pop}(t+1)|$ is larger than $N,\\left|F_{k}\\right|$ will be larger than $|\\operatorname{Pop}(t+1)|-N$. Step 2 removes $|\\operatorname{Pop}(t+1)|-N$ worst solutions from $\\operatorname{Pop}(t+1)$ to reduce its size to $N$. The crowding distance is used to compare the quality of solutions in Step 2.  \nThis selection procedure is the same as that used in NSGA-II except that we remove solutions from $\\operatorname{Pop}(t+1)$ one by one and we recalculate the crowding distances before deciding which solution should be deleted from $\\operatorname{Pop}(t+1)$, which can increase the diversity of FORMULA_274 at extra computational cost. We noticed that GDE3 [33] uses a very similar selection.\nThe major purpose of this work is to tackle variable linkages in continuous MOPs. The studies conducted in [19] show that PCX-NSGA-II and GDE3 [33] perform better than other algorithms for continuous MOPs with variable linkages. In this paper, we compare RM-MEDA with these two algorithms. Since RM-MEDA is an EDA based on regularity, we also compare it with MIDEA [27], which is an EDA without using  \nTABLE 1\nTEST INSTANCES  \nregularity, to investigate whether or not using regularity can improve the performance of EDAs.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:38",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for weight learning in the context of Fuzzy Cognitive Maps, what programming considerations should be taken into account when representing the causal relationships between concepts?",
      "topics": [
        "Estimation of Distribution Algorithm"
      ],
      "answer": "When implementing the EDA for weight learning, the causal relationships between concepts, denoted as \\(C_i\\) and \\(C_j\\), should be represented using a data structure that efficiently stores the weight \\(w_{ij}\\) of the interrelation. The range of \\(w_{ij}\\) belongs to the interval [-1, 1], where a negative value indicates negative causality, zero indicates no causal relationship, and a positive value indicates positive causality. The inference process, calculated using the formula \\(A_{j}^{t}=f(\\sum_{i=1}^{N} A_{i}^{t-1} w_{i j})\\), where \\(A_{j}^{t}\\) is the value of concept \\(C_{j}\\) at step \\(t\\), requires efficient matrix operations to update concept values based on these weights.",
      "chunk_id": 4769,
      "paper_id": "Unsupervised Dynamic Fuzzy Cognitive Map",
      "paper_title": "Unsupervised Dynamic Fuzzy Cognitive Map",
      "paper_year": "2015",
      "chunk_content": "Boyuan Liu, Wenhui Fan, and Tianyuan Xiao\nFuzzy Cognitive Map (FCM) is an inference network, which uses cyclic digraphs for knowledge representation and reasoning. Along with the extensive applications of FCMs, there are some limitations that emerge due to the deficiencies associated with FCM itself. In order to eliminate these deficiencies, we propose an unsupervised dynamic fuzzy cognitive map using behaviors and nonlinear relationships. In this model, we introduce dynamic weights and trend-effects to make the model more reasonable. Data credibility is also considered while establishing a machine learning model. Subsequently, we develop an optimized Estimation of Distribution Algorithm (EDA) for weight learning. Experimental results show the practicability of the dynamic FCM model. In comparison to the other existing algorithms, the proposed algorithm has better performance in terms of convergence and stability.  \nKey words: Fuzzy Cognitive Map (FCM); Estimation of Distribution Algorithm (EDA); nonlinear relation; machine learning\nComplexity systems such as dynamic social systems and integrated engineering systems have been puzzling decision makers for years, because the large number of highly correlated variables makes it difficult to grasp and manage the internal relationships of such systems. In the scenarios where such interdependencies are unknown, decision makers expect to predict the impact of their decisions. Fuzzy Cognitive Map (FCM) proposed by Kosko ${ }^{[1]}$ is an effective tool that helps decision makers understand such systems. By describing the causal relationships between a set of concepts, FCM is capable of emulating human cognitive process ${ }^{[2]}$. Because of the great application values, FCMs have been successfully applied in various fields such as engineering ${ }^{[3]}$, business ${ }^{[4]}$, medicine ${ }^{[5]}$,  \n[^0]and social sciences ${ }^{[6]}$.\nAn FCM model is composed of nodes and directed lines with weights. A typical graphical representation of FCM is illustrated in Fig. 1.  \nThe nodes represent descriptive concepts, which can be attributes or behaviors of the system. The directed arc connecting two nodes represents a causal relationship between them, and the weight attached to the arc indicates the strength of the relationship between the two nodes. Once an FCM model is established, the inference process can be calculated by the following rule:\n[IMAGE0]  \nFig. 1 An FCM example.  \n[^0]:    - Boyuan Liu, Wenhui Fan, and Tianyuan Xiao are with the Department of Automation, Tsinghua University, Beijing 100084, China. E-mail: liuboyuan@126.com; fanwenhui@tsinghua.edu.cn.\n- To whom correspondence should be addressed. Manuscript received: 2015-01-04; revised: 2015-03-15; accepted: 2015-03-23  \nwhere $t$ is the inference step, $A_{j}^{t}$ is the value of concept $C_{j}$ at step $t, A_{i}^{t-1}$ is the value of concept $C_{i}$ at step $t-1$, and $w_{i j}$ is the weight of the interrelation between concept $C_{i}$ and $C_{j} . f$ is a threshold function, which can squeeze the result of this formulation into the interval $[0,1]$. The range of $w_{i j}$ belongs to the interval $[-1,1]$, and a negative value indicates negative causality from $C_{i}$ to $C_{j}$, which implies the increase in $C_{i}$ leads to a decrease in $C_{j}$, and vice visa. The value zero indicates that there is no causal relationship between them.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:40",
      "generation_style": "implementation_focused"
    },
    {
      "question": "When evaluating the NTBEA's performance in optimizing the parameters of the RHEA agent for Planet Wars, how is the fitness function defined, and what considerations are taken into account due to the nature of this fitness function?",
      "topics": [
        "evolutionary"
      ],
      "answer": "For Planet Wars, the fitness function is defined as +1 for a win, -1 for a loss, and 0 for a draw. Given that this results in an extremely noisy fitness function, the evaluation methodology allows the optimiser to resample a particular point in the search space, i.e., playing multiple games with identical parameter settings, to estimate the win rate. The value of \\(k\\) in the NTBEA, which is relevant to the score distribution, is set to 1.0 for Planet Wars.",
      "chunk_id": 11213,
      "paper_id": "The N-Tuple Bandit Evolutionary Algorithm for Game Agent Optimisation",
      "paper_title": "The N-Tuple Bandit Evolutionary Algorithm for Game Agent Optimisation",
      "paper_year": "2018",
      "chunk_content": "We aim to optimise the parameters of the $R H E A$ agent (described in Section III-A) with NTBEA and two baseline algorithms, Grid Search and a multi-valued version of the Sliding Window compact Genetic Algorithm (SWeGA), an EDA proposed by Lucas et al. [33] recently. ${ }^{2}$ The NTBEA used in the experiments takes into account all the $d 1$-tuples, $\\frac{d(d-1)}{2}$ 2-tuples and the only $d$-tuple.\n1) Fitness Function: In each case the fitness function is based on the outcome of a single game, which leads to noisy fitness functions.\na) Asteroids: The evaluation function is the game score when the game terminates, the higher the better. The calculation of the game score is explained in Section III-B1. The value of $k$ should be set relative to the score distribution; for Asteroids $k$ was set to $5,000$.\nb) Planet Wars: The evaluation function is based on playing a single game, with a value of +1 if the agent wins or -1 for a loss, and 0 for a draw (which is very unlikely to occur). This gives an extremely noisy fitness function. Note that an optimiser can choose to resample a particular point in the search space, i.e., playing multiple games using the agent with an identical parameter setting, in order to get an estimate of win rate. However, with a fixed small evaluation budget, the optimiser will run fewer iterations compared to sampling exactly one.  \nThe NTBEA optimises the parameters of a $R H E A$ agent controlled as player 1, versus a fixed-parameter version of the $R H E A$ with well-chosen parameters based on the authors' experience playing as player 2. The game is symmetric and the planning budget for both players was set to 2,000 game ticks. For Planet Wars, the value of $k$ in the NTBEA was set to 1.0 .\n2) Search Space: The $R H E A$ agent is characterised by the parameters shown in Table II, where each one is given a type and legal values. The parameters have been detailed previously in Section III-A. The mutation probability for a $d$-dimensional problem is calculated by $n b$ MutatedPoints $/ d$.  \n[^0]\n[^0]:    ${ }^{2}$ The original Compact Genetic Algorithm (cGA) and the sliding window version described by Lucas et al. [33] only handled binary strings. The version used in this paper handles integer strings and can use absolute or relative fitness measures; the version used here used absolute fitness measures.  \nTABLE II: Search space of the parameter settings.  \nThe $R H E A$ agent is very flexible and allows any compatible evolutionary algorithm to be plugged in to control the evolutionary process. For these experiments we used a Random Mutation Hill Climber / $(1+1)$-Evolutionary Algorithm (the distinction between the two depends on the parameters chosen by the hyper-parameter optimiser).  \nThe search space of the parameter settings is actually the search space of $R H E A$ instances, while every $R H E A$ given a parameter setting is considered as a distinct instance. As shown in Table II, the size of the search space, in other words, total number of possible FORMULA_111 instances, when playing Asteroids and Planet Wars, is 336 and 240, respectively.",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:42",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of Estimation of Distribution Algorithms (EDAs) in the context of Mixed-Integer Nonlinear Programming (MINLP) problems, particularly when compared to Evolutionary Algorithms (EAs)?",
      "topics": [
        "search"
      ],
      "answer": "Estimation of Distribution Algorithms (EDAs) offer an alternative to Evolutionary Algorithms (EAs) for solving Mixed-Integer Nonlinear Programming (MINLP) problems by sampling probabilistic models to generate new offspring from promising regions, differing from traditional EAs that rely on crossover and mutation operators. While EAs can struggle with discontinuous feasible parts in MINLP problems, EDAs, including those used within Particle Swarm Optimization (PSO), provide a different approach to exploring the search space.",
      "chunk_id": 1537,
      "paper_id": "An improved Estimation of Distribution Algorithm for Solving Constrained Mixed-Integer Nonlinear Programming Problems",
      "paper_title": "An improved Estimation of Distribution Algorithm for Solving Constrained Mixed-Integer Nonlinear Programming Problems",
      "paper_year": "2022",
      "chunk_content": "A large number of engineering optimization problems fall into the category of Mixed-Integer Nonlinear Programming (MINLP) [1], that addresses nonlinear problems including continuous, integer and/or discrete variables. The mathematical model of a MINLP problem can be defined by (1):  \n$$\n\\begin{array}{ll}\n\\operatorname{minimize} & f(\\mathbf{x}, \\mathbf{y}) \\\\\n\\text { subject to: } & g_{i}(\\mathbf{x}, \\mathbf{y}) \\leq 0, \\quad i=1, \\ldots, n \\\\\nh_{j}(\\mathbf{x}, \\mathbf{y})=0, & j=1, \\ldots, m \\\\\nx_{k}^{l b} \\leq x_{k} \\leq x_{k}^{u b}, & k=1, \\ldots, n_{1} \\\\\ny_{q}^{l b} \\leq y_{q} \\leq y_{q}^{u b}: & \\text { integer, } q=1, \\ldots, m_{1} \\\\\n{[\\mathbf{x}, \\mathbf{y}] \\in \\Omega} & \\\\\n&\n\\end{array}\n$$  \nwhere $f(\\mathbf{x}, \\mathbf{y})$ is the objective function, $\\mathbf{x}$ is a vector of continuous variables, $\\mathbf{y}$ is a vector of integer variables, $x_{k}^{l b}$ and $x_{k}^{u b}$ are the lower and upper bounds of $x_{k}$, respectively, $y_{q}^{l b}$ and $y_{q}^{u b}$ are the lower and upper bounds of $y_{q}$, respectively, $\\Omega$ is the decision variable space, $g_{i}(\\mathbf{x}, \\mathbf{y})$ is the $i$ th inequality constraint, and $h_{j}(\\mathbf{x}, \\mathbf{y})$ is the $j$ th equality constraint.  \nIn a MINLP problem, the constraints define the feasible region, whereas the integer restrictions divide the feasible region into discontinuous feasible parts with different sizes [2]. This fact is shown in Fig. 1, where $x$ is a continuous variable, and $y$ is an integer variable. The shaded area is the feasible region defined by the constraints, and the red lines are the discontinuous feasible parts that also satisfy the integer restrictions.  \nDiverse classical methods (branch and bound, cutting planes, outer approximation, among others) have been widely used to solve MINLP problems [3]. However, in the case of non-convex problems, these techniques may cut-off the global optima. Even for large-scale problems the generated tree may be arbitrarily large and the solution time particularly high. [4]. Consequently, stochastic methods such as Evolutionary Algorithms (EAs) have been modified to solve MINLP problems. For this purpose, several integer-handling strategies have been implemented in EAs [5]-[10]. However, these extended algorithms are usually vulnerable to the size of the discontinuous feasible parts. That is, the population tends to enter into the larger discontinuous parts, because the algorithm finds feasible solutions more easily in such regions [2]. As a consequence, the small parts remain poorly explored or ignored. Therefore, if the best known solution is located in a smaller part, the algorithm may converge to the wrong part and get trapped in a local optimal solution.  \nEstimation of Distribution Algorithms (EDAs) are stochastic optimization techniques that explore the search space by  \n[IMAGE0]  \nFig. 1. The shaded area represents the feasible region defined by constraints, the red lines are the discontinuous feasible parts that also satisfy the integer restrictions.\nsampling probabilistic models. The new offspring is generated from the most promising regions detected by the model. EDAs have been proposed for solving MINLP problems [11], [12]. According to [13], EDAs are considered EAs paradigms, because they do not use crossover and mutation operators as in traditional EAs. In [10], [14], EDA operators have been used in the Particle Swarm Optimization algorithm (PSO) and a surrogate model to solve MINLP problems.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:44",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of score-based learning, specifically using the Bayesian Dirichlet (BD)-metric, influence the selection of Bayesian Network (BN) structures?",
      "topics": [
        "search"
      ],
      "answer": "Score-based learning methods, used to learn Bayesian Network (BN) structures, evaluate the quality of different BN structures using a scoring function like the Bayesian Dirichlet (BD)-metric. The BD-metric, defined by the formula \\(p(B \\mid Pop)=p(B) \\prod_{m=1}^{M} \\prod_{j=1}^{t_{m}} \\frac{\\Gamma(\\alpha_{m j})}{\\Gamma(\\alpha_{m j}+N_{m j})} \\prod_{k=1}^{s_{m}} \\frac{\\Gamma(\\alpha_{m j k}+N_{m j k})}{\\Gamma(\\alpha_{m j k})}\\), combines statistical data from a dataset with prior knowledge. In this equation, \\(p(B)\\) represents the prior factor of quality information for network \\(B\\), and \\(\\alpha_{m j k}\\) represents prior information about the number of instances where \\(Y_{m}\\) is set to its \\(k\\)-th value, given that the parents of \\(Y_{m}\\) are instantiated to their \\(j\\)-th combination. The algorithm selects the BN structure that maximizes this BD-metric score. A specific instance of this is the K2 metric where if there is no prior information for B, then p(B) and \\(\\alpha_{m j k}\\) are set to 1.",
      "chunk_id": 7033,
      "paper_id": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_title": "Probabilistic Analysis of Pareto Front Approximation for a Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm",
      "paper_year": "2017",
      "chunk_content": "Regarding to Bayesian estimation, it calculates the posteriori distribution $p(\\Theta \\mid$ Pop, $B)$ considering a priori information $p(\\Theta \\mid B)$. In practice, it is useful to require that the prior for each factor is a conjugate prior. For example, Dirichlet priors are conjugate priors for multinomial factors.  \nThe expected value $E\\left(\\theta_{m j k} \\mid \\mathbf{N}_{m j}, B\\right)$ of $\\theta_{m j k}$ is an estimate of $\\theta_{m j k}$, shown in Equation (3), considering the Dirichlet distribution with hyperparameters $\\alpha_{m j k}$ values as 1 :  \n$$\n\\hat{\\theta}_{m j k}=\\left(1+N_{m j k}\\right) /\\left(s_{m}+N_{m j}\\right)\n$$  \nThere are three main approaches to learn BN structures: score-based learning, constraint-based learning, and hybrid methods. Score-based learning methods evaluate the quality of BN structures using a scoring function, like Bayesian Dirichlet (BD)-metric [12], and selects the best one.  \nMost of the developed structure learning algorithms fall into the score-based approaches. Combining the statistical data from a given data set with prior knowledge about the problem, Equation (4) defines the BD-metric considered in [12].  \n$$\np(B \\mid P o p)=p(B) \\prod_{m=1}^{M} \\prod_{j=1}^{t_{m}} \\frac{\\Gamma\\left(\\alpha_{m j}\\right)}{\\Gamma\\left(\\alpha_{m j}+N_{m j}\\right)} \\prod_{k=1}^{s_{m}} \\frac{\\Gamma\\left(\\alpha_{m j k}+N_{m j k}\\right)}{\\Gamma\\left(\\alpha_{m j k}\\right)}\n$$  \nwhere $p(B)$ is the prior factor of quality information of the network $B$ and the parameter $\\alpha_{m j k}$ stands for prior information about the number of instances that have $Y_{m}$ set to its $k$-th value and the set of parents of $Y_{m}$ is instantiated to its $j$-th combination. The product on $j \\in\\left\\{1, \\ldots, t_{m}\\right\\}$ runs over all combinations of the parents of $Y_{m}$ and the product on $k \\in\\left\\{1, \\ldots, s_{m}\\right\\}$ runs over all possible values of $Y_{m}$.  \nIf there is no prior information for $B, p(B)$ is considered a uniform probability distribution and generally its value is set to 1 , such as parameters $\\alpha_{m j k}$, providing the so-called K2 metric [13] as shown in Equation (5).  \nFORMULA_68  \nUsing the logarithm of the scoring metric prevents factorials in Equation (5) to grow up in an uncontrolled way. The logarithmic version of Equation (5) is the one considered in this paper.  \nTo find the network structure that maximizes the scoring metric, we use the K2 algorithm. It is a greedy local search technique that applies the K2 metric. Initially it assumes that a node, in a (pre-defined) ordered list, does not have any parent, then at each step it gradually adds the edges that increase the scoring metric the most, until no edge increases the metric anymore.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:47",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using random projection ensembles, what specific computational steps are involved in updating the search distribution based on projected points, and how does the algorithm calculate the covariance matrix in the original high-dimensional space?",
      "topics": [
        "search"
      ],
      "answer": "In the random projection ensemble based EDA, after projecting the points into subspaces (step 14), the sample covariance matrix \\(\\boldsymbol{\\Sigma}^{\\boldsymbol{R}_{i}}\\) for each subspace \\(i\\) is computed as \\(\\boldsymbol{\\Sigma}^{\\boldsymbol{R}_{i}}=\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}\\right)\\left(\\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}\\right)\\right)^{\\mathrm{T}}=\\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}}\\), where \\(\\boldsymbol{R}_{i}\\) is the random projection matrix for the \\(i\\)-th subspace, \\(\\boldsymbol{x}_{n}\\) are the original data points, \\(\\boldsymbol{\\mu}\\) is the mean, and \\(N\\) is the number of points. New samples \\(\\boldsymbol{y}_{1}^{\\boldsymbol{R}_{i}}, \\ldots, \\boldsymbol{y}_{N}^{\\boldsymbol{R}_{i}}\\) are then drawn from a Gaussian distribution \\(\\mathcal{N}\\left(\\mathbf{0}, \\boldsymbol{\\Sigma}^{\\boldsymbol{R}_{i}}\\right)\\). To obtain the updated individuals \\(\\boldsymbol{x}_{n}\\) in the original \\(d\\)-dimensional space, the algorithm computes \\(\\boldsymbol{x}_{n}:=\\sqrt{\\frac{d M}{k}}\\left[\\frac{1}{M} \\sum_{i=1}^{M} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{y}_{n}^{\\boldsymbol{R}_{i}}\\right]+\\boldsymbol{\\mu}\\), where \\(M\\) is the number of subspaces and \\(k\\) is the dimension of the projected space. The ensemble covariance in the \\(d\\)-dimensional space is then derived from the summation operation, involving \\(\\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{R}_{i}\\), effectively averaging the covariance estimates from each subspace.",
      "chunk_id": 8159,
      "paper_id": "Large-Scale Estimation of Distribution Algorithms with Adaptive Heavy Tailed Random Projection Ensembles",
      "paper_title": "Large-Scale Estimation of Distribution Algorithms with Adaptive Heavy Tailed Random Projection Ensembles",
      "paper_year": "2019",
      "chunk_content": "We devised new adaptive approaches for highdimensional continuous black-box optimisation which extend and generalize the random projection ensemble based EDA by means of using unconventional random matrices. We analytically showed that this results in enlarging the covariance of the high-dimensional search distribution, which then increases exploration. Hence our adaptive schemes in fact implement novel means of covariance adaptation. We demonstrated superior performance against the original version RP-Ens-EDA on both large and medium budget instances, and with a state-of-the-art performance in comparison with a number of existing methods on 1000-dimensional problems. Future work remains to investigate other aggregation schemes, and to extend the method to multi-objective problems. A very interesting question for future work would be to analyze the dynamics and the running time of such high-dimensional EDA optimisation algorithms.  \nAcknowledgments The authors would like to thank Qi Xu (M.Sc. student at Birmingham) for implementing the AVS method and carrying out part of the experiments for Table 5 and Table 6.\nProof of Proposition 1. Recall from step 14 of Algorithm 1 that the set of projected points in the $i$-th subspace is:  \n$$\n\\boldsymbol{\\mathcal { Y } ^ { R } _ { i } = \\left\\{\\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{1}-\\boldsymbol{\\mu}\\right), \\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{2}-\\boldsymbol{\\mu}\\right), \\ldots, \\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{N}-\\boldsymbol{\\mu}\\right)\\right\\}}\n$$  \nConditionally on $\\boldsymbol{R}_{i}$, the sample covariance matrix of $\\mathcal{Y}^{\\boldsymbol{R}_{i}}$ is:  \n$$\n\\boldsymbol{\\Sigma}^{\\boldsymbol{R}_{i}}=\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}\\right)\\left(\\boldsymbol{R}_{i}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}\\right)\\right)^{\\mathrm{T}}=\\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}}\n$$  \nThereby the samples in step 16 are $\\boldsymbol{y}_{1}^{\\boldsymbol{R}_{i}}, \\ldots, \\boldsymbol{y}_{N}^{\\boldsymbol{R}_{i}} \\sim$ $\\mathcal{N}\\left(\\mathbf{0}, \\boldsymbol{\\Sigma}^{\\boldsymbol{R}_{i}}\\right)$  \nTo find the distribution of the individuals in $\\mathcal{P}^{\\text {new }}$ at step 17 , we look at the $n$-th individual:  \n$$\n\\boldsymbol{x}_{n}:=\\sqrt{\\frac{d M}{k}}\\left[\\frac{1}{M} \\sum_{i=1}^{M} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{y}_{n}^{\\boldsymbol{R}_{i}}\\right]+\\boldsymbol{\\mu}\n$$  \nConditionally on $\\boldsymbol{R}_{i}, i=1: M$, this is a linear combination of independent Gaussian random variables, which is again a Gaussian ${ }^{(2)}$. Hence, $\\boldsymbol{x}_{n}$ is Gaussian distributed, with mean $\\boldsymbol{\\mu}$ (since $\\boldsymbol{y}_{n}^{\\boldsymbol{R}_{i}}$ has zero mean), and we compute its covariance below.  \nIn (7), denote $\\boldsymbol{A}_{i}:=\\sqrt{\\frac{d M}{k}} \\frac{1}{M} \\boldsymbol{R}_{i}^{\\mathrm{T}}$, then we have that $\\boldsymbol{y}_{n}^{\\boldsymbol{R}_{i}} \\sim \\mathcal{N}\\left(\\mathbf{0}, \\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}}\\right)$. Therefore,  \n$$\n\\boldsymbol{A}_{i} \\boldsymbol{y}_{n}^{\\boldsymbol{R}_{i}} \\sim \\mathcal{N}\\left(\\mathbf{0}, \\boldsymbol{A}_{i} \\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{A}_{i}^{\\mathrm{T}}\\right)\n$$  \nfor all $n=1, \\ldots N$. Replacing $\\boldsymbol{A}_{i}$ in (A2), we have the $i$-th summand in (A1):  \n$$\n\\boldsymbol{A} \\boldsymbol{y}_{n}^{\\boldsymbol{R}_{i}} \\sim \\mathcal{N}\\left(\\mathbf{0}, \\sqrt{\\frac{d M}{k}} \\frac{1}{M} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\sqrt{\\frac{d M}{k}} \\frac{1}{M} \\boldsymbol{R}_{i}\\right)\n$$  \nwhich simplifies to  \n$$\n\\mathcal{N}\\left(\\mathbf{0}, \\frac{d}{k M} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{R}_{i} \\boldsymbol{\\Sigma} \\boldsymbol{R}_{i}^{\\mathrm{T}} \\boldsymbol{R}_{i}\\right)\n$$  \nFinally, the summation operation yields the ensemble covariance in the $d$-dimensional search space as stated in (1).",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:50",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the RM-MEDA algorithm, how are the $(m-1)$-D manifolds, denoted as $\\psi_{i}$, constructed, and what parameters influence their boundaries?",
      "topics": [
        "search"
      ],
      "answer": "In RM-MEDA, each $(m-1)$-D manifold $\\psi_{i}$ is constructed using the formula $\\psi_{i}=\\{\\bar{x} \\in R^{n} \\mid \\bar{x}=\\bar{x}_{i}+\\sum_{j=1}^{m-1} \\beta_{j} \\tilde{U}_{j}^{j}, I_{j}^{j}-0.25(u_{i}^{j}-I_{j}^{j}) \\leq \\beta_{j} \\leq u_{i}^{j}+0.25(u_{i}^{j}-I_{j}^{j}), \\quad j=1, \\ldots, m-1\\}$. The boundaries are influenced by $I_{j}^{j}$ and $u_{i}^{j}$, which represent the minimum and maximum projections, respectively, of individuals within cluster $C_{i}$ onto the $j$th principal component $\\tilde{U}_{j}^{j}$ of the covariance matrix $Cov$ of $C_{i}$. The range of these projections is enlarged by 50% to better approximate the $PS$.",
      "chunk_id": 5252,
      "paper_id": "A regularity model-based multiobjective estimation of distribution algorithm with reducing redundant cluster operator",
      "paper_title": "A regularity model-based multiobjective estimation of distribution algorithm with reducing redundant cluster operator",
      "paper_year": "2012",
      "chunk_content": "$\\left(\\bar{x} \\in R^{n}\\right) \\bar{x}=\\bar{x}_{i}+\\sum_{j=1}^{m-1} \\alpha_{j} \\tilde{U}_{j}^{j}, \\alpha_{j} \\in R^{n}, \\quad j=1, \\ldots, m-1\\}$  \nNext, RM-MEDA uses the above clustering results to build the model. RM-MEDA calculates the range of the projections of the individuals of each cluster $C_{i}$ in the first $(m-1)$ principal components:\n$I_{j}^{j}=\\min _{\\bar{x} \\in C_{i}}\\left(\\left(\\bar{x}-\\bar{x}_{i}\\right)^{T} \\tilde{U}_{j}^{j}\\right)$\nand\n$u_{i}^{j}=\\max _{\\bar{x} \\in C_{i}}\\left(\\left(\\bar{x}-\\bar{x}_{i}\\right)^{T} \\tilde{U}_{j}^{j}\\right)$\nwhere $\\bar{x}_{i}$ is the mean, $\\tilde{U}_{j}^{j}$ is the $j$ th principal component of the covariance matrix Cov of $C_{i}$, and $j \\in\\{1, \\ldots, m-1\\}$.  \nThen, each $(m-1)$-D manifold $\\psi_{i}$ is constructed as follows:\n$\\psi_{i}=\\left\\{\\bar{x} \\in R^{n} \\mid \\bar{x}=\\bar{x}_{i}+\\sum_{j=1}^{m-1} \\beta_{j} \\tilde{U}_{j}^{j}, I_{j}^{j}-0.25\\left(u_{i}^{j}-I_{j}^{j}\\right) \\leq \\beta_{j} \\leq u_{j}^{j}\\right.$  \n$$\n+0.25\\left(u_{i}^{j}-I_{j}^{j}\\right), \\quad j=1, \\ldots, m-1\\}\n$$  \nIt is necessary to note that in order to make a better approximation of the $P S$, RM-MEDA enlarges the range of the projections in each direction $\\tilde{U}_{j}^{j}(j=1, \\ldots, m-1)$ by $50 \\%$.  \nIn addition, $\\sigma_{i}$ is set as follows:\n$\\sigma_{i}=\\frac{1}{n-m+1} \\sum_{j=m}^{n} \\lambda_{i}^{j}$\nwhere $\\lambda_{i}^{j}$ is the $j$ th largest eigenvalue of the covariance matrix $C o v$ of $C_{i}$.  \nRemark 1. As pointed out previously, RM-MEDA is a kind of estimation of distribution algorithms, which exploits the distribution  \ninformation of the population to generate the next population. CMA-ES, proposed by Hansen and Ostermeier [26], also incorporates the distribution information of the population into evolution strategy (ES). CMA-ES adopts the following formulation to generate new solutions:\n$\\tilde{x}_{i, t+1}=\\tilde{m}_{t}+\\tilde{\\sigma}_{t} \\times N\\left(\\mathbf{0}, \\mathbf{C}_{i}\\right), \\quad i=1, \\ldots, \\lambda$\nwhere $t$ is the generation number, $\\tilde{x}_{i, t+1}$ is the ith offspring, $N\\left(\\mathbf{0}, \\mathbf{C}_{i}\\right)$ is a multivariate normal distribution with zero mean and covariance matrix $\\mathbf{C}_{i}, \\tilde{m}_{t}$ is the mean value of the search distribution, and $\\tilde{\\sigma}_{t}$ is the overall standard deviation (i.e., the step-size).  \nClearly, both Eqs. (4) and (13) contain two terms. However, there are some significant differences between RM-MEDA and CMA-ES. Firstly, in Eq. (4) $\\tilde{\\boldsymbol{\\xi}}$ is uniformly distributed over some manifolds, while in Eq. (13) $\\tilde{m}_{t}$ is the mean value of the $\\mu$ best individuals at generation $t$. Secondly, when generating the next population, RM-MEDA mainly uses the eigenvectors and eigenvalues of the covariance matrix of the last population, nevertheless, in CME-ES the cumulative evolution path is utilized to update the covariance matrix $\\mathbf{C}_{i}$ and the standard deviation FORMULA_176.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:52",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Considering the constraints outlined for DC power flow, what advantage does the flexibility in adjusting the power injection node for wind power offer during the optimization process, given that conventional generators have fixed locations?",
      "topics": [
        "constraints"
      ],
      "answer": "The adjustable power injection node for wind power, treated as an equivalent generator, allows for adaptive optimization during the power flow calculation. Specifically, the optimal location for wind power injection, a decision variable, is determined dynamically. This contrasts with conventional generators, where the location is fixed. The wind plant's output is constrained between 0 and its predicted wind power value, influencing the power flow vector \\(\\boldsymbol{P}_{i}\\) and potentially reducing the load shed vector \\(\\boldsymbol{R}_{i}\\) or wind power curtailment vector \\(\\boldsymbol{w} \\boldsymbol{i} \\boldsymbol{n}_{i}\\) in the equation \\(\\boldsymbol{A}^{\\dagger} \\boldsymbol{P}_{i}+\\boldsymbol{G}_{i}+\\boldsymbol{R}_{i}+\\boldsymbol{w} \\boldsymbol{i} \\boldsymbol{n}_{i}=\\boldsymbol{D}_{i}\\). This adaptability optimizes the distribution of power injection, potentially improving overall system performance compared to fixed-location generators.",
      "chunk_id": 4565,
      "paper_id": "Transmission Expansion Planning Based on Hybrid EDADE Algorithm Considering Wind Power Penetration",
      "paper_title": "Transmission Expansion Planning Based on Hybrid EDA/DE Algorithm Considering Wind Power Penetration",
      "paper_year": "2015",
      "chunk_content": "Since DC power flow is applied in this paper, there are a few constraints of it as well as the constraint of transmission capacity should be complied with as below.  \n$$\n\\left\\{\\begin{array}{l}\nA^{\\dagger} P_{i}+G_{i}+R_{i}+w i n_{i}=D_{i} \\\\\nP_{i j}=B_{j} \\Delta \\theta_{i j} \\\\\n\\left|P_{i j}\\right| \\leq P_{j \\max } \\\\\n0 \\leq g_{i j} \\leq g_{j \\max }, 0 \\leq r_{i j} \\leq d_{i j}\n\\end{array}\\right.\n$$  \nwhere $\\boldsymbol{A}$ is node-branch incident matrix, $\\boldsymbol{P}_{i}$ is the power flow vector of branches in the $i^{\\text {th }}$ scenario, $\\boldsymbol{G}_{i}$ is the output vector of generators in the $i^{\\text {th }}$ scenario and $\\boldsymbol{D}_{i}$ is the load vector in the $i^{\\text {th }}$ scenario, $\\boldsymbol{R}_{i}$ is the load shed vector in the $i^{\\text {th }}$ scenario, $\\boldsymbol{w} \\boldsymbol{i} \\boldsymbol{n}_{i}$ is the vector of wind power curtailment in the $i^{\\text {th }}$ scenario. $B_{j}$ is the equivalent admittance of the $j^{\\text {th }}$ branch. If there are multi-lines in the $j^{\\text {th }}$ branch, the equivalent admittance is obtained according to the amount of lines). $P_{i j}$ is the transferred power in the $j^{\\text {th }}$ branch, $\\Delta \\theta_{i j}$ is the angle difference between the two sides of the $j^{\\text {th }}$ branch in the $i^{\\text {th }}$ scenario and $P_{j \\text { max }}$ is the maximum transmission capacity of the $j^{\\text {th }}$ branch. $g_{i j}$ is the output of $j^{\\text {th }}$ generator in the $i^{\\text {th }}$ scenario and $g_{j \\max }$ is its upper bound. $r_{i j}$ and $d_{i j}$ are load shed and load for the $j^{\\text {th }}$ node in the $i^{\\text {th }}$ scenario, respectively. And when the failure of the components occurs, constraints in fault states should be obeyed as showed in formula (8).  \n$$\n\\left\\{\\begin{array}{l}\n\\left(\\boldsymbol{A}^{\\prime}\\right)^{T} \\boldsymbol{P}_{i}^{t}+\\boldsymbol{G}_{i}^{\\prime}+\\boldsymbol{S}_{i}+\\boldsymbol{w} \\boldsymbol{i} \\boldsymbol{n}_{i}^{\\prime}=\\boldsymbol{D}_{i} \\\\\nP_{i j}^{\\prime}=B_{j}^{\\prime} \\Delta \\theta_{i j}^{\\prime} \\\\\n\\left|P_{i j}\\right| \\leq P_{j \\max } \\\\\n0 \\leq g_{i}^{\\prime} \\leq g_{j \\max }, 0 \\leq s_{i j} \\leq d_{i j}\n\\end{array}\\right.\n$$  \nwhere the parameters above are referred in a certain fault state response to formula (7), $\\boldsymbol{S}_{i}$ is the column vector of load shedding in the $i^{\\text {th }}$ fault state, and $\\mathrm{s}_{i j}$ is the load shedding in node $j$ under the $i^{\\text {th }}$ fault state.\nThe wind plant is treated as a generator. The minimum output is 0 and the maximum output is the predicted value of wind power, different from the conventional generator. The essence of optimal location for wind power is distributing the optimal node for the power injection of the equivalent generator in power flow calculation. The decision variables of optimal location is adaptive during the process of the optimal program, the optimal location for wind power injection is obtained afterwards.",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:46:55",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model using DSM clustering, and what considerations should be made regarding fitness evaluations during the process?",
      "topics": [
        "search"
      ],
      "answer": "The EDA model execution involves constructing a Design Structure Matrix (DSM) to detect linkage groups, followed by clustering the DSM. The DSM construction phase requires fitness evaluations, specifically to assess pair-wise dependencies. However, fitness function evaluations are not needed during the DSM clustering stage itself. The number of fitness evaluations needed is O(n log(n)), where n is problem size, matching the population size. The time complexity of detecting all linkage groups is O(n^3 log(n)). A key consideration is that the DSM clustering algorithm should not impose significant additional load, as the bottleneck is calculating the pair-wise dependencies. The interaction model is constructed offline, so its accuracy is crucial for successful evolutionary optimization.",
      "chunk_id": 11546,
      "paper_id": "Efficient model building in competent genetic algorithms using DSM clustering",
      "paper_title": "Efficient model building in competent genetic algorithms using DSM clustering",
      "paper_year": "2011",
      "chunk_content": "In this subsection we evaluate the proposed approach while finding an accurate model in different testing problems. The proposed linkage detection algorithm is evaluated by two performance measures: (1) the number of fitness evaluations needed to detect all the linkage groups and (2) the total running time of the algorithm. The fitness evaluations are needed for the DSM construction phase and there is no need to evaluate the fitness function during DSM clustering. Therefore, the running time of the proposed algorithm is reported to provide the possibility of a fair assessment.  \nFigures 18 and 19 (log scale) illustrate the number of fitness evaluations needed by DSM construction that leads to maximum model accuracy of more than $(1-1 / m)$. In our experiments we used three different $m-k$ traps with tight and overlapping linkages: Trap5 $(k=5)$, Trap7 $(k=7)$ and Trap9 $(k=9)$ with different sizes. It should be mentioned that the error rate of the interaction model in all experiments, which are averaged over 30 independent runs, is less than $1 / m$. Empirical results show the scalability of algorithm with respect to the required number of fitness evaluations. Theoretical analysis presented in Section 5 shows that the necessary number of evaluated individuals for extracting an accurate model is $\\mathrm{O}(n \\log (n))$, so does the size of population. Experimental results also match the theory well in all testing problems with tight and even overlapping linkages.  \nFigures 20 and 21 show total running time in seconds for constructing and clustering DSM. The hardware platform used was an Intel Core2 Duo Processor 2.4 GHz with 2 GB RAM. In Section 5, the time complexity of the proposed linkage detection algorithm was analyzed and it was shown that detecting all linkage groups is done in polynomial time $\\mathrm{O}\\left(n^{3} \\log (n)\\right)$. The experiments revealed the scalability of the algo-\n[IMAGE8]  \nFig. 18. The number of fitness evaluations needed to build an accurate interaction model in trap functions with tight linkages.\n[IMAGE9]  \nFig. 19. The number of fitness evaluations needed to build an accurate interaction model in trap functions with overlapping linkages.\n[IMAGE10]  \nFig. 20. Run time of the proposed method for different trap functions with tight linkages.  \n[IMAGE11]  \nFig. 21. Run time of the proposed method for different trap functions with overlapping linkages.\nrithm in problems with different sizes, different orders of difficulty and different linkage cases. It should be noted that the bottleneck of the proposed linkage group detection algorithm is calculating the pair-wise dependencies and the proposed DSM clustering algorithm does not impose any additional load on the whole process.  \nIt seems that it is useful to compare the proposed approach to the model building approach in DSMGA as the closest research to ours. As it was noted in Section 1, DSMGA utilizes a different clustering algorithm. An MDL-based metric was introduced to evaluate the quality of DSM clustering. Then, a GA was suggested, though not used in practice, to find optimal clustering using the MDL-based metric as fitness function. Instead, a simple hill climber was adopted to find appropriate clustering to save computational time. Another important issue is that the model building approach proposed in this paper is offline while in DSMGA, the interaction model is constructed in each generation. In the offline model building, accuracy of the model is very influential as the success of evolutionary optimization completely depends on model accuracy. This issue was addressed completely in the previous subsection.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:46:57",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model when applied to the Firefighter Problem (FFP)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The effectiveness of a solution $\\pi$ in the Firefighter Problem is evaluated by simulating the spread of fire and calculating $e(\\pi)$, which is the sum of the costs $c_{1}(v)$ assigned to nodes $v$ that are not burnt (denoted as $l(v) \\neq t B^{\\prime}$) at the end of the simulation. The cost $c_{1}(v)$ represents a value assigned to each node, such as financial or cultural importance.",
      "chunk_id": 7068,
      "paper_id": "Estimation of Distribution Algorithms for the Firefighter Problem",
      "paper_title": "Estimation of Distribution Algorithms for the Firefighter Problem",
      "paper_year": "2017",
      "chunk_content": "The evaluation of a solution (permutation) $\\pi$ is performed by simulating the spread of fire from the initial state until the fire can no longer spread. During the simulation nodes of the graph $G$ become protected in the order determined by the permutation $\\pi$. In the classical version of the FFP the evaluation of the solution $\\pi$ is equal to the number of nodes not touched by fire (those, that are in one of the states ' D ' or ' U ') when the simulation stops. In the paper [17] the multiobjective version of the FFP was proposed in which there are $m$ values $c_{i}(v), i=1, \\ldots, m$ assigned to each node $v$ in the graph. In the context of fire containment multiple criteria could represent, for example, the financial value $c_{1}(v)$ and the cultural importance $c_{2}(v)$ of the items stored at the node $v$. Multiobjective evaluation can also be useful when preventing the spread of epidemics in livestock. In such scenario we would probably be interested in protecting different species to a certain degree. In this paper a single-objective version of the FFP is studied, in order to start the work on probabilistic models for the FFP, which are naturally less complex in the single-objective case. However, to retain similarity to the multiobjective case, costs are assigned to nodes and solutions are evaluated using these costs. To stick to the formalism used for the multiobjective case, these costs will be denoted as $c_{1}(v)$, even though there are no $c_{i}(v)$ with $i>1$ in this paper. Evaluating a solution $\\pi$ requires simulating how fire spreads when firefighter assignment is done according to $\\pi$. The evaluation of the solution can then be calculated as the sum of the costs assigned to those nodes that are not burnt at the end of the simulation:  \n$$\ne(\\pi)=\\sum_{v \\in V: l(v) \\neq t B^{\\prime}} c_{1}(v)\n$$  \nwhere:\n$c_{1}(v)$ - the cost assigned to the node $v$.\nEstimation of Distribution Algorithms (EDAs) work in a way that bears a certain resemblance to Evolutionary Algorithms (EAs). The algorithm operates in a loop  \n```\nAlgorithm 1. A general structure of an EDA algorithm used in this paper.\nIN: \\(N{\\text {pop }} \\quad\\) - The size of the population\n\\(N{\\text {sample }}\\) - The size of a sample used for probabilistic model update\n\\(P:=\\operatorname{InitPopulation}\\left(N{\\text {pop }}\\right)\\)\n\\(M:=\\operatorname{InitModel}()\\)\n\\(B:=\\emptyset\\)\nwhile not StoppingCondition() do\n// Evaluation\nEvaluate(P)\n// Caching of the best specimen\n\\(B:=\\operatorname{GetBestSpecimens}(\\mathrm{P}, 1)\\)\n// Update of the probabilistic model\n\\(P{\\text {sample }}:=\\operatorname{GetBestSpecimens}\\left(P, N{\\text {sample }}\\right)\\)\n\\(M:=\\operatorname{UpdateModel}\\left(P{\\text {sample }}, M\\right)\\)\n// New population\n\\(P:=\\operatorname{CreateNewSpecimens}\\left(M, N_{\\text {pop }}-1\\right)\\)\n\\(P:=P \\cup B\\)",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:46:59",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when applied to stochastic resource-constrained project scheduling problems (SRCPSPs) under time-varying weather conditions, specifically focusing on the use of climate reduction coefficients (CRCs) and expected makespan?",
      "topics": [
        "performance"
      ],
      "answer": "The primary objective is to evaluate the performance of an improved Estimation of Distribution Algorithm (EDA) on modified benchmark project instances from the J120 dataset, adapted to SRCPSPs by incorporating random activity durations dependent on time-varying weather conditions. The methodology utilizes climate reduction coefficients (CRCs), modeled by a sine wave function $w(t)=0.5+0.2 \\cos (2 \\pi(t / 365-0.5))$, to determine the probability of a workable day, and calculates the expected activity duration $d_{i, t}^{E}$ to minimize the expected makespan.",
      "chunk_id": 9441,
      "paper_id": "Stochastic resource-constrained project scheduling problem with time varying weather conditions and an improved estimation of distribution algorithm",
      "paper_title": "Stochastic resource-constrained project scheduling problem with time varying weather conditions and an improved estimation of distribution algorithm",
      "paper_year": "2021",
      "chunk_content": "The J120 dataset from PSPLIB provides benchmark instances of project scheduling that contains 600 RCPSPs with 120 non-dummy activities (Kolisch \\& Sprecher, 1997). For the numerical study, 60 RCPSPs were randomly selected from the J120 dataset. Then, the 60 RCPSPs were modified to SRCPSPs by assuming random activity durations that depend on time-varying weather conditions. This section evaluates the performance of the improved EDA using modified benchmark project instances. Only the expected makespan was used as the objective function in this section. The algorithms were implemented on a desktop computer with an Intel i9-9900 CPU and 8 GB of memory using MATLAB 2018b.\nSimulated weather conditions were used for the numerical study. The time unit was one day, and the horizon of the weather condition model was one year. The effect of weather conditions on construction operations was described by climate reduction coefficients (CRCs) (Ballesteros-Perez, Smith, Lloyd-Papworth, \\& Cooke, 2018). The CRCs refer to the proportion of workable days during the same time in  \nhistorical years. The sine wave was used to model the CRC data, which is given by\n$w(t)=0.5+0.2 \\cos (2 \\pi(t / 365-0.5)), t \\in\\{1,2,3, \\cdots, 365\\}$\nHere, $\\boldsymbol{w}(t)$ denotes the probability that day $t$ is a workable day. Then, the expected activity duration $d_{i, t}^{E}$ is calculated using Algorithm 6. Further, it was assumed that the activity duration follows a continuous uniform distribution within the interval $\\left[0,2 d_{i, t}^{E}\\right]$.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:01",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of the Hybrid Estimation of Distribution Algorithm (HEDA) described, what mathematical principles govern the influence of the learning speed parameter $(\\alpha)$ and the bias level of initialization parameter $(\\beta)$ on the algorithm's performance, and how does the Taguchi method of design of experiment (DOE) using the orthogonal array $L_{16}(4^{4})$ facilitate the analysis of these parameters?",
      "topics": [
        "search"
      ],
      "answer": "The Hybrid Estimation of Distribution Algorithm (HEDA) utilizes the learning speed $(\\alpha)$ and the bias level of initialization $(\\beta)$ as key parameters influencing its performance. The Taguchi method of design of experiment (DOE), specifically employing the orthogonal array $L_{16}(4^{4})$, is implemented to investigate the effect of these parameters. This orthogonal array, $L_{16}(4^{4})$, signifies that there are 16 total treatments, 4 parameters being studied, and each parameter having 4 factor levels. The 'response value' of each parameter, obtained through the DOE, is used to analyze the significance rank of each parameter, with the results indicating that the bias level of initialization $(\\beta)$ is the second most significant parameter, and its impact is better when it is more than zero. This suggests that the new initialization mechanism of the probability model is efficient. The learning speed $(\\alpha)$ is also analyzed within this framework, although its specific significance rank is not explicitly stated in the provided content. The orthogonal array helps determine the combinations of parameter values for the HEDA runs.",
      "chunk_id": 5344,
      "paper_id": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_title": "An effective hybrid EDA-based algorithm for solving multidimensional knapsack problem",
      "paper_year": "2012",
      "chunk_content": "The proposed HEDA contains several key parameters: the population size of each generation $(P)$, the number of selected individual to update the probability model $(N)$, the learning speed $(\\alpha)$ and the bias level of initialization $(\\beta)$. To investigate the influence of those parameters on the performance of the algorithm, we implement the Taguchi method of design of experiment (DOE) (Montgomery, 2005) by using the problem 100.10.05. Combinations of different values of these parameters are shown in Table 1.  \nFor each parameter combination, the HEDA is run 50 times independently with the maximum number 10,000 of the constructed solutions as the stopping criterion. The average response variable (ARV) value is the average of profit obtained by the HEDA in 50 times. According to the number of parameters and the number of factor levels, we choose the orthogonal array $L_{10}\\left(4^{4}\\right)$. That is, the total number of treatment is 16 , the number of parameters is 4 , and the number of factor levels is 4 . The orthogonal array and the obtained ARV values are listed in Table 2.  \nTable 1\nCombinations of parameter values.\nTable 2\nOrthogonal array and ARV values.\n[IMAGE2]  \nFig. 6. Factor level trend of the HEDA.  \nTable 3\nResponse value.  \nAccording to the orthogonal table, we illustrate the trend of each factor level in Fig. 6. Then, we figure out the response value of each parameter to analyze the significance rank of each parameter. The results are listed in Table 3.  \nFrom Table 3 it can be seen that $P$ is the most significant parameter among the four parameters. In condition of a fixed maximum number of constructed solutions, small population size allows more generations so that it may provide deeper search. In addition, the significant rank of $\\beta$ is the second and the performance of the HEDA is better when $\\beta$ is more than zero, which demonstrates that the new initialization mechanism of the probability model is efficient. A better choose of the parameter combination is: $P=20$, $N=6, \\alpha=0.01$, and $\\beta=0.1$.\nNext, we study the influence of the repair operator in the HEDA. Denote HEDA1 as the HEDA with RO1 and HEDA2 as the HEDA\nwith RO2. We run both HEDA1 and HEDA2 20 times independently by using test set 2 . Since test set 2 has medium or large scale, we set $P=200, N=10, \\alpha=0.01, \\beta=0.1$, and set the maximum number 100,000 of the constructed solutions as the stopping criterion.  \nThe statistical results are summarized in Table 4, where Min.Dev and Ave.Dev represent the minimum and average percentage deviations from the best-known solutions, and Var. Dev denotes the variance of the deviations.  \nFrom Table 4, it can be seen that the performance of HEDA1 is better than that of HEDA2 on the first 8 problems. However, since RO1 depends on solving the LP relaxation problem of the MKP, it is very difficult to solve the problem with LP when the number of $m+n$ is very large. So, HEDA2 can solve another 3 problems with larger scale while HEDA1 cannot solve those problems. The conclusion is that the repair operator is important to improve the performance of the algorithm. Comparing RO2, RO1 is superior to achieve better results but it can only applied to the problems with small or medium size.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:04",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using the IR2 representation for table ordering, what specific steps are required to transform an individual from its IR2 representation into an IR1-type representation for evaluation?",
      "topics": [
        "representation"
      ],
      "answer": "To transform an IR2 individual into an IR1-type representation, the procedure involves processing rows sequentially according to the individual's row ordering $\\boldsymbol{x}=\\left(x_{1}, \\ldots, x_{R}\\right)$. For each row $x_{i}$, columns are rearranged to place all 1s on the left and all 0s on the right. A Boolean vector $\\boldsymbol{B}=\\left\\{B_{1}, \\ldots, B_{C-1}\\right\\}$ is used to assign borders to column orderings, initialized with $B_{b}=0$ for $b=1, \\ldots, C-1$. Borders are activated between columns separating 1s and 0s. Subsequent rows respect these borders, permuting only within column subsets defined by the borders. New borders are activated after rearranging 1s and 0s in each row. This continues until all borders are activated or all rows are processed, resulting in an IR1-type solution.",
      "chunk_id": 11628,
      "paper_id": "Optimal row and column ordering to improve table interpretation using estimation of distribution algorithms",
      "paper_title": "Optimal row and column ordering to improve table interpretation using estimation of distribution algorithms",
      "paper_year": "2011",
      "chunk_content": "We propose a new representation, specifically designed for the table ordering problem. The aim os to get rid of redundant individuals such as the ones generated in IR1.  \nThis new individual representation is a single-path representation in which we define only one permutation of the row ordering. The corresponding column ordering is automatically calculated using an encoding which is unique for each individual. The idea is to use a procedure to infer this column ordering from the row ordering and translate from an IR2 to an IR1 representation. The individual will therefore be evaluated using the same fitness function applicable to IR1.  \nThe procedure for inferring the column ordering and transforming an IR2 individual into IR1 form is described next. An example is shown in Fig. 3. The IR1type solution is built by adding rows one by one in the order described in the individual $\\boldsymbol{x}=\\left(x_{1}, \\ldots, x_{R}\\right)$, that is, by processing the $x_{i}$ th row sequentially for $l=1,2,3, \\ldots, R$. We will also define a Boolean vector $\\boldsymbol{B}=\\left\\{B_{1}, \\ldots, B_{C-1}\\right\\}$, initializing $B_{b}=0, b=1, \\ldots, C-1$, to assign borders to column orderings. As shown in Fig. 3, initially we will take the $x_{i}$ th row (the second row in the original table) and rearrange columns to place all 1 s on the left leaving all 0 s on the right. This will activate a border between the columns separating the two types of values ( $B_{2}$ will be 1) for the consequent rows, although column orders could vary in the following iterations. With the first row processed, and respecting border $B_{2}$ for column orderings which divides columns orders in subsets $(3,6)$ and $(1,2,4,5,7)$, we will move all 1 s as far to the left as possible (see Row 2 in Fig. 3). This could create new column ordering borders ( $B_{5}$ in the example in Fig. 3). For Row 3, borders $B_{2}$ and $B_{5}$ should be  \n[IMAGE2]  \nFig. 3 Example of translating an individual $\\boldsymbol{x}=(2,4,1,3)$ from its IR2 representation into its IR1-type counterpart $\\boldsymbol{x}=(2,4,1,3,3,6,5,7,2,4,1)$, given the original table ordering  \nFig. 4 (a) Table obtained using the representation of individuals IR2; (b) using IR3\n[IMAGE3]\nrespected, and therefore only permutations within column subsets $(3,6),(2,5,7)$ and FORMULA_53 would be allowed-only columns within the same borders-resulting in new borders activated once 1 s and 0 s have been rearranged. This procedure will continue until all borders have been activated or until all rows have been processed, resulting in an IR1-type solution for which the stress measure defined in Sect. 2.1 can be applied.  \nFigure 4(a) shows an example of the type of solution that can be obtained using the IR2 individual representation. Note that, whenever possible, individuals always tend to place the 1 s in the top-left position.",
      "question_type": "practical application",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:06",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the motion planning for tip trajectory tracking, how are the small displacements \\(\\tilde{\\boldsymbol{p}}\\) of the tip vector mathematically related to the Jacobian matrices \\(\\boldsymbol{J}_{\\theta_{M}}, \\boldsymbol{J}_{\\theta_{m}}, \\boldsymbol{J}_{\\delta}\\) and small changes in joint variables \\(\\tilde{\\boldsymbol{\\theta}}_{M}, \\tilde{\\boldsymbol{\\theta}}_{m}\\) and deflections \\(\\tilde{\\boldsymbol{\\delta}}\\), and what does this relationship represent in terms of compensability?",
      "topics": [
        "planning"
      ],
      "answer": "The small displacements \\(\\tilde{\\boldsymbol{p}}\\) of the tip vector are expressed as \\(\\tilde{\\boldsymbol{p}}=J_{\\theta_{M}} \\tilde{\\boldsymbol{\\theta}}_{M}+J_{\\theta_{m}} \\tilde{\\boldsymbol{\\theta}}_{m}+J_{\\delta} \\tilde{\\boldsymbol{\\delta}}\\), where \\(\\boldsymbol{J}_{\\theta_{M}} \\in \\mathrm{R}^{n \\times M}, \\boldsymbol{J}_{\\theta_{m}} \\in \\mathrm{R}^{n \\times m}\\) and \\(\\boldsymbol{J}_{\\delta} \\in \\mathrm{R}^{n \\times e}\\) are Jacobian matrices representing the sensitivity of the tip position \\(\\boldsymbol{p}\\) with respect to changes in the macro manipulator joint variables \\(\\boldsymbol{\\theta}_{\\boldsymbol{M}}\\, the micro manipulator joint variables \\(\\boldsymbol{\\theta}_{\\boldsymbol{m}}\\, and the deflections of flexible links \\(\\boldsymbol{\\delta}\\), respectively. This equation describes how small changes in the joint variables and link deflections contribute to the overall displacement of the tip, which is critical for compensability, as it allows for adjustments to \\(\\boldsymbol{\\theta}_{\\boldsymbol{m}}\\'\\) to counteract the effects of \\(\\tilde{\\boldsymbol{\\delta}}\\) and maintain the desired tip position.",
      "chunk_id": 6305,
      "paper_id": "Global optimization of motion planning for tip trajectory tracking of a flexible macro-micro manipulator system using Estimation of Distribution Algorithm",
      "paper_title": "Global optimization of motion planning for tip trajectory tracking of a flexible macro-micro manipulator system using Estimation of Distribution Algorithm",
      "paper_year": "2006",
      "chunk_content": "To guarantee the accuracy of tip position by motion planning, two conditions (3) and (5) should be satisfied, which provides the search space boundary. One optimal solution can be selected by minimizing the fitness function which considers the compensability and the energy consumption in the process of trajectory tracking.\nA. Compensability  \nThe small displacements $\\tilde{\\boldsymbol{p}}$ of the tip vector can be expressed as  \n$$\n\\tilde{\\boldsymbol{p}}=J_{\\theta_{M}} \\tilde{\\boldsymbol{\\theta}}_{M}+J_{\\theta_{m}} \\tilde{\\boldsymbol{\\theta}}_{m}+J_{\\delta} \\tilde{\\boldsymbol{\\delta}}\n$$  \nwhere $\\boldsymbol{J}_{\\theta_{M}} \\in \\mathrm{R}^{n \\times M}, \\boldsymbol{J}_{\\theta_{m}} \\in \\mathrm{R}^{n \\times m}$ and $\\boldsymbol{J}_{\\delta} \\in \\mathrm{R}^{n \\times e}$ are Jacobian matrices of $\\boldsymbol{p}$ with respect to $\\boldsymbol{\\theta}_{\\boldsymbol{M}}, \\boldsymbol{\\theta}_{\\boldsymbol{m}}$ and $\\boldsymbol{\\delta}$, respectively, and $\\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{M}}, \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{m}}$, and $\\tilde{\\boldsymbol{\\delta}}$ denote small changes in $\\boldsymbol{\\theta}_{\\boldsymbol{M}}, \\boldsymbol{\\theta}_{\\boldsymbol{m}}$ and $\\boldsymbol{\\delta}$ respectively.  \nThe deflection of flexible links $\\tilde{\\boldsymbol{\\delta}}$ can be converted to $\\tilde{\\theta}_{\\delta i}$, the errors of joint variables:  \n$$\n\\tilde{\\theta}_{\\delta i}=\\left\\{\\begin{array}{c}\n\\varepsilon_{1} / l_{1}, i=1 \\\\\n\\alpha_{i-1}+\\varepsilon_{i} / l_{i}, 2 \\leq i \\leq M \\\\\n\\alpha_{M}, i=M+1\n\\end{array}\\right.\n$$  \nSo (6) can be rewritten to:  \n$$\n\\tilde{\\boldsymbol{p}}=J_{\\theta_{M}} \\tilde{\\boldsymbol{\\theta}}_{M}^{\\prime}+J_{\\theta_{m}} \\tilde{\\boldsymbol{\\theta}}_{m}^{\\prime}\n$$  \nwhere  \n$$\n\\tilde{\\theta}_{i}^{\\prime}=\\left\\{\\begin{array}{l}\n\\tilde{\\theta}_{i}+\\tilde{\\theta}_{\\delta i}, 1 \\leq i \\leq M+1 \\\\\n\\tilde{\\theta}_{i}, M+2 \\leq i \\leq M+m\n\\end{array}\\right.\n$$  \nCompared to the physical parameters of the manipulators, tip errors caused by the deformation of the flexible links are small. To compensate such errors, we need adjust the desired joint variables of the micro manipulator:  \n$$\n\\boldsymbol{f}_{\\delta=\\theta}\\left(\\boldsymbol{\\theta}_{M}, \\boldsymbol{\\theta}_{m}^{\\prime}\\right)+\\tilde{\\boldsymbol{p}}=\\boldsymbol{f}_{\\delta=\\theta}\\left(\\boldsymbol{\\theta}_{M}, \\boldsymbol{\\theta}_{m}^{\\prime}\\right)\n$$  \nwhere $\\boldsymbol{\\theta}_{m}{ }^{\\prime}$ denotes the joint variables after adjustment and $\\tilde{p}$ is substituted with  \n$$\n\\tilde{\\theta}_{i}=0,1 \\leq i \\leq M+m\n$$  \nConsidering the adjustment is small for $\\theta_{m}$, so the caused position change $\\Delta f$ would be:  \n$$\n\\boldsymbol{f}_{\\delta=\\theta}\\left(\\boldsymbol{\\theta}_{M}, \\boldsymbol{\\theta}_{m}^{\\prime}\\right)-\\boldsymbol{f}_{\\delta=\\theta}\\left(\\boldsymbol{\\theta}_{M}, \\boldsymbol{\\theta}_{m}\\right)=J_{\\theta_{m}}\\left(\\boldsymbol{\\theta}_{m}^{\\prime}-\\boldsymbol{\\theta}_{m}\\right)\n$$  \nDerived from (8), (9), (10), (11) and (12):  \n$$\n\\begin{aligned}\n\\boldsymbol{\\theta}_{m}^{\\prime} & =\\boldsymbol{\\theta}_{m}-\\boldsymbol{J}_{\\theta_{m}}{ }^{+}\\left(\\boldsymbol{J}_{\\theta_{M}} \\tilde{\\boldsymbol{\\theta}}_{M}^{\\prime}+\\boldsymbol{J}_{\\theta_{m}} \\tilde{\\boldsymbol{\\theta}}_{m}^{\\prime}\\right) \\\\\n& =\\left(\\boldsymbol{\\theta}_{m}-\\tilde{\\boldsymbol{\\theta}}_{\\delta_{m}}{ }^{\\prime}\\right)-\\boldsymbol{J}_{\\theta_{m}}{ }^{+} \\boldsymbol{J}_{\\theta_{M}} \\tilde{\\boldsymbol{\\theta}}_{\\delta_{M}}{ }^{\\prime}\n\\end{aligned}\n$$  \nwhere $\\boldsymbol{J}_{\\theta_{m}}{ }^{+}$denotes pseudo-inverse matrix of $\\boldsymbol{J}_{\\theta_{m}}$, $\\tilde{\\boldsymbol{\\theta}}_{\\delta_{M}}{ }^{\\prime} \\in \\mathrm{R}^{M}$ and $\\tilde{\\boldsymbol{\\theta}}_{\\delta_{m}}{ }^{\\prime} \\in \\mathrm{R}^{m}$ denote the equivalent joint variables alternation of the macro and micro manipulator, respectively, due to the deformation of flexible links of the macro manipulator, they are given as:  \n$$\n\\begin{aligned}\n& \\tilde{\\boldsymbol{\\theta}}_{\\delta_{M}}{ }^{\\prime}=\\left[\\tilde{\\theta}_{\\delta 1}^{\\prime}, \\tilde{\\theta}_{\\delta 2}^{\\prime}, \\cdots, \\tilde{\\theta}_{\\delta M}^{\\prime}\\right]^{T} \\\\\n& \\tilde{\\boldsymbol{\\theta}}_{\\delta_{m}}{ }^{\\prime}=\\left[\\tilde{\\theta}_{\\delta(M+1)}^{\\prime}, 0, \\cdots, 0\\right]^{T}\n\\end{aligned}\n$$  \nDefine  \n$$\n\\Delta \\boldsymbol{\\theta}_{m}=\\boldsymbol{\\theta}_{m}^{\\prime}-\\boldsymbol{\\theta}_{m}\n$$  \nAccording to (13), equality  \n$$\n\\Delta \\boldsymbol{\\theta}_{m}=\\tilde{\\boldsymbol{\\theta}}_{\\delta_{m}}{ }^{\\prime}+\\boldsymbol{J}_{\\theta_{m}}{ }^{+} \\boldsymbol{J}_{\\theta_{M}} \\tilde{\\boldsymbol{\\theta}}_{\\delta_{M}}{ }^{\\prime}\n$$  \nis obtained. From (7) and (14), derived  \n$$\n\\tilde{\\boldsymbol{\\theta}}_{\\delta_{M}}{ }^{\\prime}=\\boldsymbol{T}_{\\varepsilon} \\varepsilon+\\boldsymbol{T}_{\\alpha} \\boldsymbol{\\alpha}\n$$  \nwhere $\\boldsymbol{\\varepsilon}=\\left[\\varepsilon_{1}, \\cdots, \\varepsilon_{M}\\right]^{T}, \\boldsymbol{\\alpha}=\\left[\\alpha_{1}, \\cdots, \\alpha_{M}\\right]^{T}, \\boldsymbol{T}_{\\varepsilon}$ and $\\boldsymbol{T}_{\\alpha}$ are given as:  \n$$\n\\begin{aligned}\n& \\boldsymbol{T}_{\\varepsilon}=\\frac{\\partial \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{\\theta}_{M}}^{\\prime}}{\\partial \\varepsilon}=\\operatorname{diag}\\left[l_{1}, l_{2}, \\cdots l_{M}\\right]^{-1} \\\\\n& \\boldsymbol{T}_{\\alpha}=\\frac{\\partial \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{\\theta}_{M}}^{\\prime}}{\\partial \\boldsymbol{\\alpha}}=\\left[\\begin{array}{cccc}\n0 & 0 & \\cdots & 0 \\\\\n1 & 0 & \\ddots & \\vdots \\\\\n0 & \\ddots & \\ddots & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right]\n\\end{aligned}\n$$  \nLet $\\operatorname{diag}[*]$ denote the diagonal matrix.\nSubstitute (18) to (17),  \n$$\n\\Delta \\boldsymbol{\\theta}_{m}=\\boldsymbol{J}_{\\varepsilon} \\varepsilon+\\boldsymbol{J}_{\\alpha} \\boldsymbol{\\alpha}=\\boldsymbol{J}_{\\delta} \\tilde{\\boldsymbol{\\delta}}\n$$  \nis obtained, where $\\boldsymbol{J}_{\\delta}=\\left[\\begin{array}{ll}\\boldsymbol{J}_{\\varepsilon} & \\boldsymbol{J}_{\\alpha}\\end{array}\\right], \\boldsymbol{J}_{\\varepsilon}=\\boldsymbol{J}_{\\theta_{m}}{ }^{+} \\boldsymbol{J}_{\\theta_{M}} \\boldsymbol{T}_{\\varepsilon}$,  \n$$\n\\boldsymbol{J}_{\\alpha}=\\boldsymbol{J}_{\\theta_{m}}{ }^{+} \\boldsymbol{J}_{\\theta_{M}} \\boldsymbol{T}_{\\alpha}+\\left[\\begin{array}{llll}\n1 & 0 & \\cdots & 0\n\\end{array}\\right]^{T}, \\tilde{\\boldsymbol{\\delta}}=\\left[\\begin{array}{ll}\n\\varepsilon & \\boldsymbol{\\alpha}\n\\end{array}\\right]^{T}\n$$  \nDeformation $\\tilde{\\boldsymbol{\\delta}}$ is normalized to distinguish the weight of each element:  \n$$\n\\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}=\\boldsymbol{T}_{\\delta} \\tilde{\\boldsymbol{\\delta}}\n$$  \nwhere  \n$\\boldsymbol{T}_{\\boldsymbol{\\delta}}=\\operatorname{diag}\\left[\\varepsilon_{1 \\max }, \\cdots, \\varepsilon_{M \\max }, \\alpha_{1 \\max }, \\cdots, \\alpha_{M \\max }\\right]^{-1}$\nHere $\\varepsilon_{i \\max }$ and $\\alpha_{i \\max }(i=1,2, \\cdots, M)$ denotes weight\nof each element of $\\tilde{\\boldsymbol{\\delta}}$. Joint displacement of the micro manipulator $\\Delta \\boldsymbol{\\theta}_{\\boldsymbol{m}}$ for compensation is also normalized to take the cost of each micro manipulator joint into consideration:  \n$$\n\\Delta \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{m}}=\\boldsymbol{T}_{\\boldsymbol{m}} \\Delta \\boldsymbol{\\theta}_{\\boldsymbol{m}}\n$$  \nWhere  \n$$\n\\boldsymbol{T}_{\\boldsymbol{m}}=\\operatorname{diag}\\left[\\theta_{\\text {m} \\mid \\text { cost }}, \\theta_{\\text {m2cost }}, \\cdots \\theta_{\\text {mncost }}\\right]^{-1}\n$$  \nHere $\\theta_{\\text {micost }}(i=1,2, \\cdots, m)$ denotes the cost of each micro manipulator joint.  \nFrom (21), equality  \n$$\n\\Delta \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{m}}=\\tilde{\\boldsymbol{J}}_{\\delta} \\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}\n$$  \nis derived, where $\\tilde{\\boldsymbol{J}}_{\\boldsymbol{\\delta}}=\\boldsymbol{T}_{\\boldsymbol{m}} \\boldsymbol{J}_{\\boldsymbol{\\delta}} \\boldsymbol{T}_{\\boldsymbol{\\delta}}{ }^{-1}$. To minimize $\\left\\|\\Delta \\tilde{\\boldsymbol{\\theta}}_{\\boldsymbol{m}}\\right\\|$\nfor any $\\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}$ satisfying $\\left\\|\\tilde{\\boldsymbol{\\delta}}_{\\text {norm }}\\right\\| \\leq 1$, compensability measured by:  \nFORMULA_71",
      "question_type": "relationship",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:09",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does $\\mathrm{UMDA}_{c}^{G}$ estimate the parameters of the univariate Gaussian distribution $p(x_i | \\mu_i, \\sigma_i^2)$ for continuous EDAs, and what parameters must be specified for its implementation?",
      "topics": [
        "selection"
      ],
      "answer": "$\\mathrm{UMDA}_{c}^{G}$ estimates the mean $\\mu_{i, t}$ and standard deviation $\\sigma_{i, t}$ parameters of the Gaussian distribution $p(x_i | \\mu_i, \\sigma_i^2)$ by setting them as the sample mean and sample standard deviation, respectively, of the selected population at each generation. Specifically, $\\mu_{i, t}$ is calculated as $\\bar{x} = \\frac{1}{M_{\\text {sel }}} \\sum_{j=1}^{M_{\\text {sel }}} x_{i}^{j}$, and $\\sigma_{i, t}$ is calculated as $s = \\sqrt{\\frac{1}{M_{\\text {sel }}} \\sum_{j=1}^{M_{\\text {sel }}}(x_{i, j} - \\bar{x})}$. For implementation, $\\mathrm{UMDA}_{c}^{G}$ requires specification of the population size $M$ and the selection parameter $\\tau$, which represents the fraction of the population with the best objective function values retained for building the search model.",
      "chunk_id": 6503,
      "paper_id": "Bayesian inference in estimation of distribution algorithms",
      "paper_title": "Bayesian inference in estimation of distribution algorithms",
      "paper_year": "2007",
      "chunk_content": "The simplest and most widely developed model in EDAs is a factorized product of univariate marginal distributions  \n$$\np(\\mathbf{x})=\\prod_{i=1}^{m} p\\left(x_{i}\\right)\n$$  \nA number of continuous EDAs $\\left(\\mathbf{x} \\in \\mathbb{R}^{n}\\right)$ have been developed using the factorized probability model given in (2). For the remainder of this paper we focus on continuous EDAs that utilize a univariate Gaussian distribution  \n$$\np\\left(x_{i} \\mid \\mu_{i}, \\sigma_{i}^{2}\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{i}} e^{-\\frac{1}{2}\\left(\\frac{\\mu_{i}-\\mu_{i}}{\\sigma_{i}}\\right)^{2}}\n$$  \nThe learning/model estimation problem in this case requires a method for calculating the mean $\\mu_{i}$ and variance $\\sigma_{i}$ parameters of $p\\left(x_{i}\\right)$. The standard model is to use a different $\\sigma_{i}$ parameter for each search dimension, leading to elliptical contours of equal probability with the constraint that the principal axes of these ellipses must be parallel to one of the coordinate axes of the space.\nThe extension of the Univariate Marginal Distribution Algorithm (UMDA) [9] to continuous search spaces: $\\mathrm{UMDA}_{c}^{G}$ [10], follows the general EDA framework of Table I and employs the model from (3). In $\\mathrm{UMDA}_{c}^{G}$, the mean parameters for the next generation are set as the sample mean of the selected population  \n$$\n\\mu_{i, t}=\\bar{x}=\\frac{1}{M_{\\text {sel }}} \\sum_{j=1}^{M_{\\text {sel }}} x_{i}^{j}\n$$  \nand the standard deviation (variance) parameters are set as the sample standard deviation (variance) of the selected population  \n$$\n\\sigma_{i, t}=s=\\sqrt{\\frac{1}{M_{\\text {sel }}} \\sum_{j=1}^{M_{\\text {sel }}}\\left(x_{i, j}-\\bar{x}\\right)}\n$$  \nAt any given generation, $\\mu_{i, t}$ and $\\sigma_{i, t}$ represent the maximum likelihood estimates for the mean and standard deviation of each marginal distribution $p\\left(x_{i} \\mid \\mu_{i}, \\sigma_{i}^{2}\\right)$.  \nThe initial population $(t=0)$ is generated from a uniform distribution across the feasible search space. In the first generation, $\\mu_{i, 0}$ and $\\sigma_{i, 0}$ are estimated based on selected points from this random population. $\\mathrm{UMDA}_{c}^{G}$ uses truncation selection: a fraction $\\tau$ of the population with the best objective function values are retained for building/adapting the search model ${ }^{1}$. Therefore, only two algorithm parameters must be specified for an implementation of $\\mathrm{UMDA}_{c}^{G}$ : the population size $M$ and the selection parameter FORMULA_74.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:12",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing a Minimum Entropy Controller (MEC) for an ARMAX system, how is the performance assessment index () calculated, and what do the extreme values of this index signify regarding system performance?",
      "topics": [
        "performance"
      ],
      "answer": "The performance assessment index () for an MEC is calculated as  = H(Fv_t) / H(y_t), where H(Fv_t) is the entropy of the output variable with the MEC, and H(y_t) is the entropy of the output variable with the actual controller. An index value close to 1 indicates good performance with regard to the theoretically achievable output minimum entropy, while a value of 0 indicates the worst performance, including unstable control.",
      "chunk_id": 10419,
      "paper_id": "Non-Gaussian Systems Control Performance Assessment Based on Rational Entropy",
      "paper_title": "Non-Gaussian Systems Control Performance Assessment Based on Rational Entropy",
      "paper_year": "2018",
      "chunk_content": "Consider a generic feedback control systems shown in Figure 1, where $r_{t}$ is the set point, $u_{t}$ is the controller output, $v_{t}$ is the unmeasured disturbance. $G_{c}, G_{p}$ and $G_{v}$ denote the transfer functions of the feedback controller, the process and disturbance dynamics, respectively. The set point is set to zero by convenience and the disturbances are assumed to be zero mean.\n[IMAGE0]  \nFigure 1. Generic feedback control system structure.  \nLet the system under consideration be described by an ARMAX model.  \n$$\nA\\left(q^{-1}\\right) y(t)=q^{-\\tau} B\\left(q^{-1}\\right) u(t)+C\\left(q^{-1}\\right) v(t)\n$$  \nwhere $y(t), u(t), v(t)$ are the output, the input and the noise of the ARMAX process, respectively. The disturbance transfer function $G_{v}$ in Figure 1 can be further decomposed as follows by Diophantine equation,  \n$$\nG\\left(q^{-1}\\right)=F\\left(q^{-1}\\right)+q^{-\\tau} R\\left(q^{-1}\\right)\n$$  \nwhere $F\\left(q^{-1}\\right)$ is the impulse response coefficients of $G_{v}$ in $q^{-1}$ with order $\\tau-1$ and $R\\left(q^{-1}\\right)$ is the remaining transfer function that satisfies the Identity (2).  \n$$\ny(t)=F v(t)+L v(t-d)=\\frac{\\left(n_{0}+n_{1} q^{-1}+n_{2} q^{-2}+\\cdots+n_{d-1} q^{-(\\tau-1)}\\right) v(t)}{\\text { feedback-invariant }}+\\frac{\\left(n_{d} q^{-\\tau}+n_{d+1} q^{-(\\tau+1)}+\\cdots\\right) v(t)}{\\text { feedback-varying }}\n$$  \nwhere $L=\\frac{R-F G_{p} G_{v}}{1+q^{-\\tau} G_{p} G_{v}}$. The feedback-invariant terms are not functions of the process model or the controller; they depend only on the characteristics of the disturbance acting on the process. The second term is feedback-varying. This means that of the process output entropy (Equation (3)) depends on the structure and parameters of the controller $\\left(G_{c}\\right)$. The entropy of the output variable can reach the minimum value if $L=0$.  \nFor non-Gaussian variables, unlike Gaussian variables which have the particularity that all distribution information is contained in the first and second moments and the higher moments above the second moment are zero. So, the MVC control that only minimize the second order does not apply to the non-Gaussian systems. Fortunately, the entropy is alternative uncertainty measurement which is more general in representing the system randomness using the probability distribution that all the stochastic information is included. Therefore, all higher order moments including the second one can be optimized using the entropy instead of the mean square error optimization.  \nFor a linear non-Gaussian system, the goal of the minimum entropy controller is to minimize the entropy of the system output variables [25-28]. Like the conventional MVC, the minimum entropy value will be obtained if and only if $L=0$,  \n$$\nH^{\\min }\\left(y_{t}\\right)=H\\left(F v_{t}\\right)\n$$  \nMEC based assessment compares the actual system-output entropy $H\\left(y_{t}\\right)$ to the output entropy $H^{\\min }\\left(y_{t}\\right)$ as obtained using minimum-entropy controller. And the MEC-based CPA index is represented by  \n$$\n\\eta=\\frac{H^{\\min }\\left(y_{t}\\right)}{H\\left(y_{t}\\right)}=\\frac{H\\left(F v_{t}\\right)}{H\\left(y_{t}\\right)}\n$$  \nwhere $H^{\\min }\\left(y_{t}\\right)$ is the entropy of the output variable with MEC and $H\\left(y_{t}\\right)$ is the entropy of the output variable with actual controller. This index is similar to the MVC index will be always within the interval $[0,1]$, where MVC index values close to unity indicate good performance with regard to the theoretically achievable output minimum entropy. \" 0 \" means the worst performance, including unstable control.  \nIn fact, the relative entropy or Kullback-Leibler (KL) divergence [29,30] can reflect the distance between two probability distributions. It is defined as follows.  \n$$\nD_{K L}(P \\| Q)=\\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} d x\n$$  \nThe relative entropy can be also used as a performance assessment index if $p(\\cdot)$ denotes the probability density function (PDF) of the output variable with MEC and $q(\\cdot)$ denotes the PDF of output variable with actual controller.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:14",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the fitness of a conformation evaluated within the Estimation of Distribution Algorithm (EDA) for protein structure prediction, specifically addressing the handling of invalid conformations?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The fitness function in the EDA uses the hydrophobic-polar (HP) model, where the energy level of the protein is determined by multiplying the number of H bonds by -1. Invalid conformations, which occur when two or more amino acids occupy the same lattice site, are penalized by adding a value corresponding to the rate of interference to their fitness function, effectively reducing their chance of selection.",
      "chunk_id": 8270,
      "paper_id": "A novel approach for protein structure prediction based on an estimation of distribution algorithm",
      "paper_title": "A novel approach for protein structure prediction based on an estimation of distribution algorithm",
      "paper_year": "2019",
      "chunk_content": "Random key encoding is a solution that is used EDA in order to produce the initial population. The proposed method creates a sequence of sixfold direction in a random way for the first-generation chromosomes. It is important to mention that the algorithm has a random nature and there is a possibility for the production of invalid conformations in each stage. Invalid conformations are those structures with two or more amino acids located on a common site on the lattice. In other words, a conformation is valid only when each site is occupied by at most one residue. For each invalid conformation, the method defines a penalty corresponding to the rate of interference that is added to their fitness function. Naturally, such manipulation in the value of fitness function reduces the chance for selection of that structure.\nAs mentioned in the introduction section, a lower level of energy shows a closer structure of a protein to its natural form. The proposed method in this study uses the hydrophobicpolar (HP) model whereas multiplying the number of H bonds in -1 gives the energy level of the protein. This multiplication in the HP model is considered as the fitness function in the proposed method.\nIn the first step, the algorithm selects a number of individuals based on the principles of fitness and variety in order to produce an intermediate population. These individuals will be used to update the probabilistic vector in each generation of evolutionary section. Then, a repetitive process of producing offspring is performed based on the produced population. Selection of this medial population, which is the processing population of the algorithm and increases its efficiency, is conducted by the selection operator called tournament. The tournament operator randomly selects $k$ chromosomes from the current population and enters the best chromosome into the intermediate population. This operation is repeated $n$ times, i.e., the size of medial population.\nThe proposed method uses a univariate probability model that could be shown by a vector of possibilities with $3(n-1)$ elements (corresponding to the primary structure of a protein). What is meant by a univariate model is one in which no relationship exists between the variables (here, the directions). The vector of possibilities is initialized with 0.5 based on the Bernoulli distribution principles. For each iteration, the vector is updated according to the selected medial population. The model is factorized as a product of independent univariate marginal distributions. Below formula (Larranaga 2002) shows the update formula for the vector of possibilities.\n$p_{l}(x)=p\\left(x \\mid D_{l-1}^{S_{e}}\\right)=\\prod_{i=1}^{n} p_{l}\\left(x_{i}\\right)$\nEach univariate marginal distribution is estimated from marginal frequencies:\n$\\prod_{i=1}^{n} p_{l}\\left(x_{i}\\right)=\\prod_{i=1}^{n} \\frac{\\sum_{j=1}^{N} \\delta_{j}\\left(X_{i}=x_{i} \\mid D_{l-1}^{S_{e}}\\right)}{N}$  \nTable 2 The selected individuals, $D_{0}^{S_{e}}$, from the initial population and their joint probability  \nFor example, assume that a number of individuals are selected from $D_{0}$ (initial population) using a selection method. $D_{0}^{S_{e}}$ denotes the data file containing the selected individuals. The selected individuals have been characterized by means of the joint probability distribution (see Table 2). Thus, only three parameters are required to specify the model. Each parameter, $p\\left(x_{i} \\mid D_{0}^{S_{e}}\\right) i=1,2,3$, will be estimated from the data file $D_{0}^{S_{e}}$ by means of its corresponding relative frequency, FORMULA_40.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:16",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the selection strategy described in the context of EDAs, considering the combination of scalar fitness and crowding distance?",
      "topics": [
        "fitness"
      ],
      "answer": "The primary objective of the selection strategy, as outlined in Algorithm 4, is to leverage both scalar fitness and crowding distance to guide the selection process within an Estimation of Distribution Algorithm. This approach likely aims to balance solution quality (fitness) with population diversity (crowding distance) to enhance the exploration and exploitation capabilities of the EDA.",
      "chunk_id": 1763,
      "paper_id": "An improved estimation of distribution algorithm for multi-objective optimization problems with mixed-variable",
      "paper_title": "An improved estimation of distribution algorithm for multi-objective optimization problems with mixed-variable",
      "paper_year": "2022",
      "chunk_content": "```  \nSecondly, a selection strategy which combines scalar fitness and crowding distance is proposed. The pseudocode of the selection strategy is shown in Algorithm 4.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:17",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the Extended Compact Genetic Algorithm (EcGA) differ from other Bayesian network-based EDAs in handling multivariate dependencies?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The Extended Compact Genetic Algorithm (EcGA) differs from other Bayesian network-based EDAs because it does not learn a Bayesian network in every generation to obtain an EDA with multivariate dependencies. Instead, in EcGA, the joint probability distribution (JPD) is factorized as a product of probability distributions of varying size, represented as \\(p_{l}(\\mathbf{x})=\\prod_{c \\in C_{l}} p_{l}(\\mathbf{x}_{c})\\). Here, \\(C_{l}\\) denotes the set of groups of variables in the \\(l\\)th generation, and \\(p_{l}(\\mathbf{x}_{c})\\) represents the marginal discrete distribution of variables \\(\\mathbf{X}_{c}\\), which are the variables belonging to the \\(c\\)th group in the \\(l\\)th generation. Each group of variables is assumed to be independent of the others, avoiding the need to learn a full Bayesian network structure.",
      "chunk_id": 2526,
      "paper_id": "Estimation of Distribution Algorithms in Machine Learning A Survey",
      "paper_title": "Estimation of Distribution Algorithms in Machine Learning: A Survey",
      "paper_year": "2024",
      "chunk_content": "Multivariate Dependencies: The vast majority of EDAs that belong to this category are based on learning the Bayesian network that best fits the distribution of the selected individuals in each generation and its subsequent simulation. The pioneering EDAs in this area are listed below.  \n1) The estimation of Bayesian network algorithm (EBNA) [93], [94], where the use of both types of Bayesian network learning algorithms, constraint-based, and score-and-search-based algorithms, is proposed. Among the scores used, the BIC and the K2 scores are the most notable. In each generation, the search procedure for EBNAs starts with the model induced in the previous generation. The EGNA [83] is similar to EBNA although a Gaussian Bayesian network is learned in each generation. Dong et al. [95] adapted the estimation of Gaussian Bayesian network algorithm (EGNA) approach for handling high-dimensional problems by controlling the complexity of the learned models.\n2) The Bayesian optimization algorithm (BOA) [96], which uses the BDe metric to measure the goodness of each structure in combination with a greedy search algorithm that starts from scratch in each generation.\n3) The learned factorized distribution algorithm (LFDA) [97], which controls the complexity of the learned Bayesian network through the BIC in conjunction with a restriction on the maximum number of parents that each variable can have.\n4) The estimation of multivariate normal algorithm (EMNA) [83], which assumes a Gaussian JPD, whose vector of means and covariance matrix are estimated by the maximum-likelihood method. In [98], an EDA based on the eigen analysis of the covariance matrix and its corresponding tuning strategy is proposed. In [99], an archive with a certain number of high-quality solutions from previous generations is preserved, and the evolution direction provided by the individuals in the archive is integrated into the estimation of the covariance matrix of the Gaussian model.\n5) Regularization-based EDAs benefit from likelihood regularization during the Bayesian network structure search in each generation. This allows an initial selection of candidate parents for each variable in the graph [100]. In continuous domains, [101] proposes the  \nuse of regularized model learning of Gaussian Bayesian networks, pursuing sparseness in high-dimensional problems.\n6) The iterated density evolutionary algorithm (IDEA) [102] (and its multiobjective version MIDEA [103]) use Gaussian kernel probability density functions, in contrast to mixtures of Gaussians to cope with multimodal optimization problems [104].\n7) Finally, the extended compact genetic algorithm (EcGA) [105] does not need to learn a Bayesian network in every generation to obtain an EDA with multivariate dependencies. In EcGA, the JPD is factorized as a product of probability distributions of varying size. Each group of variables is assumed to be independent from the others. Therefore, a factorization such as $p_{l}(\\mathbf{x})=\\prod_{c \\in C_{l}} p_{l}\\left(\\mathbf{x}_{c}\\right)$, where $C_{l}$ denotes the set of groups of variables in the $l$ th generation, and $p_{l}\\left(\\mathbf{x}_{c}\\right)$ represents the marginal (discrete) distribution of variables $\\mathbf{X}_{c}$, namely, the variables belonging to the $c$ th group in the FORMULA_122 th generation, is obtained.",
      "question_type": "conceptual deep",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:20",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for graph coloring, how should practitioners handle constraint violations when generating new solutions, and what are the trade-offs between different approaches?",
      "topics": [
        "fitness"
      ],
      "answer": "When implementing an EDA like MOA or MICPSO for graph coloring, practitioners can handle constraint violations by (1) fixing invalid solutions, (2) discarding invalid solutions and resampling, or (3) penalizing the fitness of invalid solutions. Fixing invalid solutions can be computationally expensive, especially for large graphs. Discarding invalid solutions and resampling, as implemented in MOA, avoids the penalty function bias but may lead to infinite loops if the algorithm cannot generate valid samples. The penalty function approach, used initially, applies a penalty of 100 to the fitness if the coloring $C$ of graph $G$ is invalid, modifying the fitness function to $f(C(G))=(\\chi(G)-|C|)-100$ when invalid, where $\\chi(G)$ is the chromatic number and $|C|$ is the number of colors used.",
      "chunk_id": 12559,
      "paper_id": "MICPSO  A method for incorporating dependencies into discrete particle swarm optimization",
      "paper_title": "MICPSO: A Method for Incorporating Dependencies into Discrete Particle Swarm Optimization",
      "paper_year": "2016",
      "chunk_content": "Algorithms were run until the best solution's fitness failed to change over 20 consecutive iterations, at which point the global best was returned. We chose this stopping criterion, rather than a number of fitness evaluations, based on the results from [20]. Given that this is a constrained optimization problem, we had to choose a way to handle the constraints in the methods that did not incorporate them explicitly. Broadly speaking, there are three ways this can be done. When an invalid solution is generated, the algorithm can either (1) fix the solution to make it valid, (2) discard that solution and generate a new one, repeating until a valid solution is produced, or (3) penalize the fitness of the invalid solution so that, ideally, it will not be chosen as a best solution [21].  \nWith a problem as tightly constrained as graph coloring, the first two options could potentially be prohibitively computationally expensive. Employing an auxiliary algorithm to repair an invalid solution could take a long time on the larger graphs, and with highly connected graphs, it might be necessary to generate thousands of solutions before a valid one is produced. Furthermore, it is possible for ICPSO to produce a distribution that is incapable of generating a valid sample at all; therefore, the second option could potentially create an infinite loop. For these reasons, we chose to utilize a penalty function to reduce the fitness of invalid solutions. This penalty, however, was not factored into the reported results for average fitness per iteration or average fitness of the global best solution, as this would have unfairly biased the results. With this penalty in place, our fitness function for a vertex coloring $C$ of graph $G$ is as follows:\n$f(C(G))=\\left\\{\\begin{array}{ll}\\chi(G)-|C| & \\text { if } C \\text { is a valid coloring } \\\\ (\\chi(G)-|C|)-100 & \\text { otherwise. }\\end{array}\\right.$\nMOA presented an interesting problem in terms of constraint enforcement because, while it is Markov network-based like MICPSO, the conditional probabilities of variables' values are computed from the population rather than the network's potential functions. At each iteration of the MOA Gibbs sampler, the probability that variable $X_{i}$ takes on value $x_{i}$ is computed as follows:  \n$$\np\\left(x_{i} \\mid N_{i}\\right)=\\frac{e^{p\\left(x_{i}, N_{i}\\right) / T}}{\\sum_{x_{i}^{\\prime}} e^{p\\left(x_{i}^{\\prime}, N_{i}\\right) / T}}\n$$  \nwhere $T$ is the temperature variable and $p\\left(x_{i}, N_{i}\\right)$ and $p\\left(x_{i}^{\\prime}, N_{i}\\right)$ are calculated from the population [14]. Due to the use of the Boltzmann distribution, the numerator can never go to zero; therefore, it is not possible to have a zero probability even in the case where $X_{i}=x_{i}$ might violate a graph coloring constraint given the assignment to the neighbors FORMULA_78. As such, it was still possible to generate an invalid sample using MOA. In order to mitigate the effects of this and allow for a more fair comparison to MICPSO, we modified MOA to discard invalid samples during the sampling process, re-sampling until an adequate number of valid samples have been produced.",
      "question_type": "application",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:23",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, under what mathematical conditions does the Estimation of Multivariate Normal Algorithm - global (EMNA${}_{\\text{global}}$) converge to an optimal camera parameter configuration, given that the algorithm optimizes all camera parameters simultaneously and assumes people are walking on a visible horizontal ground plane with at least three different locations not on the same straight line observable, and an approximate range of the camera height is known?",
      "topics": [
        "search"
      ],
      "answer": "The provided text does not explicitly state convergence conditions or provide mathematical proofs for the EMNA${}_{\\text{global}}$ algorithm. It mentions that EMNA${}_{\\text{global}}$ is used to optimize all camera parameters simultaneously, relaxing assumptions of prior knowledge in intrinsic parameters. The algorithm operates under the conditions that people are walking on a visible horizontal ground plane with at least three different locations not on the same straight line observable, and an approximate range of the camera height is known. However, specific mathematical theorems or convergence guarantees for EMNA${}_{\\text{global}}$ in this context are not detailed. The text highlights the advantages of EDAs, such as adaptability and reduced memory requirements, and notes that parallel computation can improve efficiency, but does not provide explicit convergence analysis.",
      "chunk_id": 12854,
      "paper_id": "Camera self-calibration from tracking of moving persons",
      "paper_title": "Camera Self-Calibration from Tracking of Moving Persons",
      "paper_year": "2016",
      "chunk_content": "Although self-calibration from object tracking has been studied for years, it is still facing many challenges. In all the above methods, the performance of self-calibration is highly dependent on the accuracy of extracted head and foot locations, which is related to the robustness of segmentation and tracking approach. Furthermore, it is common to adopt RANSAC to eliminate outlier points in the estimation of $V_{T}$ and $L_{H}[7,10-11]$, however, due to noise in measurement, the number of outliers can overwhelm inliers in some scenarios, which will lead to failure of this method. And the threshold of RANSAC needs to be fine-tuned every time as well. Last but not least, Mohedano and Garcia [12] analyze and conclude that complete selfcalibration based on estimated $V_{T}$ and $L_{H}$ cannot be achieved if more than one of the intrinsic parameters is unknown. That is why all the mentioned works [6-11] assume that the focal length is the only parameter to be estimated in the intrinsic parameter matrix. This ambiguity in computation will lead to increasing reprojection error. Other limitations also prohibit the development of this area. The work in [6-7] requires accurate detection of leg-crossing for calibration. Hence, it cannot work well when the angle between the object moving direction and the principal axis of the camera is small. In [8], they need to assume that the objects are moving at a constant velocity, and the noise model of measurements is known. The work in [11] assumes that the variation of relative pedestrian heights in the camera's field of view (FOV) is sufficiently low. These are generally not the cases in real world.  \n[IMAGE0]  \nFig. 1. Overview flow chart of the proposed system.\nIn this paper, we propose to use a robust object segmentation and tracking system to achieve accurate head/foot localization. Besides, mean shift clustering is applied to estimate $V_{T}$, so that the method is less affected by large number of outliers. Also, we adopt Laplace linear regression to formulate the fitting of $L_{H}$ into a convex optimization problem. In this way, there is no need to set the threshold parameter to indicate inliers like RANSAC. Moreover, we formulate the problem of optimization based on minimizing the average reprojection error on the ground plane. In this innovative formulation, we do not need to know the actual heights of all walking humans, but only a rough range of the camera height. Fig. 1 shows the overview flow chart of our proposed camera self-calibration scheme.  \nOur method first employs the estimation of distribution algorithm (EDA) to search for the optimal parameters in camera calibration. This type of search algorithms is based on probabilistic modeling of promising solutions combined with the simulation of the induced models to guide the search. Among the category of EDAs, we adopt the Estimation of Multivariate Normal Algorithm - global (EMNA ${ }_{\\text {global }}$ ) [13] to optimize all camera parameters simultaneously. In this way, the assumptions of prior knowledge in intrinsic parameters can be relaxed. In our work, we only assume that the people are walking on a visible horizontal ground plane with at least three different locations not on the same straight line observable, and an approximate range of the camera height is known. Therefore, our self-calibration algorithm can be applied widely in video surveillance systems. The advantages of EDAs against most of other metaheuristics are discussed in detail in the review paper [14], including ability to adapt their operators to the structure of the problem, reduced memory requirements, etc. Because parallel computation can be adopted in sampling the population at each generation, the efficiency of EDA can be much higher compared to many other nonlinear optimization approaches.",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:25",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the cloud theory-based temperature reduction acceptance criterion in the iterated greedy method (CTBIG) compare to the classical iterated greedy algorithm in the context of the distributed mixed no-idle flowshop (DMNIFSP)?",
      "topics": [
        "search"
      ],
      "answer": "In the context of the DMNIFSP, the cloud theory-based temperature reduction acceptance criterion in the iterated greedy method (CTBIG) performed better than the classical iterated greedy algorithm on the test instances, indicating an enhanced search capability.",
      "chunk_id": 3327,
      "paper_id": "An Estimation of Distribution Algorithm-Based Hyper-Heuristic for the Distributed Assembly Mixed No-Idle Permutation Flowshop Scheduling Problem",
      "paper_title": "An Estimation of Distribution Algorithm-Based Hyper-Heuristic for the Distributed Assembly Mixed No-Idle Permutation Flowshop Scheduling Problem",
      "paper_year": "2023",
      "chunk_content": "Fuqing Zhao and Bo Zhu are with the School of Computer and Communication Technology, Lanzhou University of Technology, Lanzhou 730050, China (e-mail: zhaofq@lut.edu.cn; 1532116227@qq.com).  \nLing Wang is with the Department of Automation, Tsinghua University, Beijing 100084, China (e-mail: wangling@tsinghua.edu.cn).  \nThis article has supplementary material provided by the authors and color versions of one or more figures available at https://doi.org/ 10.1109/TSMC.2023.3272311.  \nDigital Object Identifier 10.1109/TSMC. 2023.3272311  \ndistributed assembly no-idle flowshop scheduling problem (DANIFSP). Zhang et al. [22] proposed a matrix cubebased EDA for the energy-efficient DAPFSP (EEDAPFSP). Huang et al. [23] presented a two-phase evolution algorithm for the multiobjective DAPFSP.  \nPan and Ruiz [24] proposed the mixed no-idle permutation flowshop scheduling problem (MNIPFSP), which is more conform to the realistic scenario than the conventional NIPFSP. Rossi and Nagano [29] built the mathematical model for MNIPFSP and proposed an acceleration method for calculating the insertions. To address the MNIPFSP, the authors designed an effective iterated greedy algorithm and the computational results on a total of 1750 instances show the superiority of the algorithm. Recently, Rossi and Nagano [25], [26], [27] conducted the research on this topic further, including introducing the setup times on regular machines in MNIPFSP. The distributed mixed no-idle flowshop (DMNIFSP) was first studied in [28]. The authors introduced the cloud theory-based temperature reduction acceptance criterion in the iterated greedy method (CTBIG) to enhance the search capability of the algorithm. Compared with the classical iterated greedy algorithm, the CTBIG performed better on the test instances. Rossi and Nagano [29] first attempted to consider the setup times in the DMNIPFSP and they enhanced the quality of the solutions through the newly designed reconstruction strategy.  \nThis article aims to find a promising result for the distributed assembly MNIPFSP (DAMNIPFSP). As a generalization of DANIFSP, the work related to the DAMNIPFSP is very limited. The DAMNIPFSP has strong constraint conditions. First of all, the operation on the job sequence needs to avoid randomness to satisfy the assembly condition of products. Second, the mixed no-idle constraint makes it more difficult to solve the problem than the permutation constraint or no-idle constraint. Finally, the distributed factory makes the problem become difficult. The DAMNIPFSP combines the DMNIPFSP [28] with assembly systems. There are three subproblems to consider: factory assignment, product scheduling, and job scheduling.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:26",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the Sum of Dominated Row Covering (SDRC) heuristic within an Estimation of Distribution Algorithm, how should a developer calculate the probe selection function D(pj), given the modified coverage function C'(pj) and separation function S'(pj)?",
      "topics": [
        "heuristic"
      ],
      "answer": "In the SDRC heuristic, the probe selection function D(pj) is calculated as the maximum value between the modified coverage function C'(pj) and the modified separation function S'(pj), precisely as defined in the original Dominated Row Covering (DRC) heuristic. The formula is D(pj) = max{C'(pj), S'(pj)} for all probes pj, where 1 <= j <= n. The probes with the highest D(pj) values are then selected as candidate probes.",
      "chunk_id": 6976,
      "paper_id": "Bayesian Optimization Algorithm for the Non-unique Oligonucleotide Probe Selection Problem",
      "paper_title": "Bayesian Optimization Algorithm for the Non-unique Oligonucleotide Probe Selection Problem",
      "paper_year": "2009",
      "chunk_content": "As mentioned above, our algorithm applies three heuristics in combination with the BOA. Two of the heuristics are those proposed by Wang et al. [12], namely, Dominated Row Covering (DRC), and Dominant Probe Selection (DPS). A third heuristic has also been used in our experiments, which we named Sum of Dominated Row $\\operatorname{Covering}(S D R C)$. In this heuristic, we modified the definitions of the functions $C\\left(p_{j}\\right)$ (coverage function), and $S\\left(p_{j}\\right)$ (separation function) of DRC.  \n$$\nC\\left(p_{j}\\right)=\\max _{t_{i} \\in T_{p_{j}}}\\left\\{\\operatorname{cov}\\left(p_{j}, t_{i}\\right) \\quad \\mid \\quad 1 \\leq j \\leq n\\right\\}\n$$  \nwhere $T p_{j}$ is the set of targets covered by $p_{j}$.  \n$$\nS\\left(p_{j}\\right)=\\max _{t_{i k} \\in T_{p_{j}}^{2}}\\left\\{\\operatorname{sep}\\left(p_{j}, t_{i k}\\right) \\quad \\mid \\quad 1 \\leq j \\leq n\\right\\}\n$$  \nwhere $T_{p_{j}}^{2}$ is the set of target pairs separated by the probe $p_{j}$.  \nBefore discussing our modifications, we describe the probe selection functions used in DRC (For further information on DPS selection functions, see Wang et al. [12]). Given the target-probe incidence matrix $H$, probe set $P=\\left\\{p_{1}, \\ldots, p_{n}\\right\\}$, and the target set $T=\\left\\{t_{1}, \\ldots, t_{m}\\right\\}$, the function cov and sep have been defined over $P \\times T$ and $P \\times T^{2}$, respectively, as following:  \n$$\n\\begin{gathered}\n\\operatorname{sep}\\left(p_{j}, t_{i k}\\right)=\\left|h_{i j}-h_{k j}\\right| \\times \\frac{s_{\\min }}{\\left|P_{t_{i k}}\\right|}, \\quad p_{j} \\in P_{t_{i k}}, \\quad t_{i k} \\in T^{2} \\\\\n\\operatorname{cov}\\left(p_{j}, t_{i}\\right)=h_{i j} \\times \\frac{c_{\\min }}{\\left|P_{t_{i}}\\right|}, \\quad p_{j} \\in P_{t_{i}}, \\quad t_{i} \\in T\n\\end{gathered}\n$$  \nwhere $P_{t_{i}}$ is the set of probes hybridizing to target $t_{i}$, and $P_{t_{i k}}$ is the set of probes separating target-pair $t_{i k}$.  \nFunction $C$ favors the selection of probes that $c_{\\text {min }}$-cover dominated targets. Target $t_{i}$ dominates target $t_{j}$, if $P_{t_{j}} \\subseteq P_{t_{i}}$. Function $S$ favors the selection of the probes that $s_{\\text {min }}$-separate dominated target pairs. Target pair $t_{i j}$ dominates target pair $t_{k l}$, if $P_{t_{i j}} \\subseteq P_{t_{k l}}$.  \nThe functions $C\\left(p_{j}\\right)$ and $S\\left(p_{j}\\right)$ have been defined as the maximum between the values of the function cov and sep, respectively. The selection function $D\\left(p_{j}\\right)$ which has been defined as follows will indicate the degree of contribution of $p_{j}$.  \n$$\nD\\left(p_{j}\\right)=\\max \\left\\{C\\left(p_{j}\\right), S\\left(p_{j}\\right)\\right\\} \\quad \\mid 1 \\leq j \\leq n\\}\n$$  \nThe probes of highest value of $D\\left(p_{j}\\right)$ will be the candidate probes for the solution probe set. Calculation of the coverage and separation functions are given in Tables 2 and 3 based on DRC definitions in rows $C$ and $S$, respectively [12]. We see, by definition of DRC functions, these four probes have the same score for the coverage of the dominated targets and the same score for the separation of the dominated target pairs, and $D\\left(p_{1}\\right)=D\\left(p_{3}\\right)=D\\left(p_{4}\\right)=D\\left(p_{5}\\right)=\\frac{c_{\\min }}{3}$. Although, it can be noticed from 2 and 3 that each of these probes has a distinct covering and separating property. Therefore, these properties are not reflected by the definitions of current DRC functions. In order to capture this information, we modified the two functions of $C\\left(p_{j}\\right)$ and $S\\left(p_{j}\\right)$ to $C^{\\prime}\\left(p_{j}\\right)$ and $S^{\\prime}\\left(p_{j}\\right)$, respectively, in the $S D R C$ (see Eq. 6 and 7 below). The values of $C^{\\prime}\\left(p_{j}\\right)$ and $S^{\\prime}\\left(p_{j}\\right)$ have also been calculated and presented in Tables 2 and 3. In the $S D R C$, the $D$ score is calculated the same as $D$ function in DRC (see Eq. 5).",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:28",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model ENSHA, and how are these metrics combined within the Taguchi method to optimize parameter settings?",
      "topics": [
        "design"
      ],
      "answer": "The effectiveness of ENSHA is evaluated using three performance metrics: $\\gamma$, $\\Delta$, and $\\Omega$. Within the Taguchi method, these metrics are normalized and summed ($\\operatorname{Sum}_{k}$) to create a single response variable. The Taguchi method then aims to maximize the signal-to-noise ratio ($S/N$), calculated as $S / N=-10 \\log \\left(\\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{Sum}_{i}^{2}\\right)$, using the sums of normalized metrics $\\operatorname{Sum}_{k}$ across multiple runs to find robust parameter settings for ENSHA. Parameters PS, Pc, Pm and $LR$ are tuned using an orthogonal array $L_{16}(4^{4})$.",
      "chunk_id": 8651,
      "paper_id": "An elitist nondominated sorting hybrid algorithm for multi-objective flexible job-shop scheduling problem with sequence-dependent setups",
      "paper_title": "An elitist nondominated sorting hybrid algorithm for multi-objective flexible job-shop scheduling problem with sequence-dependent setups",
      "paper_year": "2019",
      "chunk_content": "To find a suitable parameter combination for ENSHA, three performance metrics (i.e., $\\gamma, \\Delta$ and $\\Omega$ ) should be considered simultaneously because they are all related to ENSHA's performance. In this paper, the Taguchi method is used for parameter tuning [60-63], in which the response is the sum of normalized values of performance metrics and the factors are the parameters of ENSHA. In the Taguchi method, we consider two kinds of\nfactors (i.e., controllable factors $S$ and noise factors $N$ ), and the ultimate goal is to control $N$ and reduce the variation around the response associated with orthogonal arrays. Note that the design that is impressed less by $N$ is selected as the robust design. As suggested by previous works [60-63], the signal to noise ratio $(S / N)$ is used for performing the analysis on experimental results.  \nIn the implementation of the Taguchi method, we carry out the design-of experiment (DOE) [64] based on the instance \"12a\". To be specific, 4 factor levels are considered for parameters PS, Pc, Pm and $L R$ on the performance of ENSHA, as shown in Table 6. The orthogonal array $L_{16}\\left(4^{4}\\right)$ with a total of 16 parameter combinations is adopted, which is generated by IBM SPSS Statistics 20 (the seed value is set to 1), as listed in Table 7. For all combinations, ENSHA is independently run 21 times with the stopping condition MaxFES $=500,000$. After running ENSHA one time, the corresponding metrics $\\gamma, \\Delta$ and $\\Omega$ of each combination is calculated and recorded. The obtained metrics of each combination in the first run are listed in Table 7.  \nAs mentioned earlier, parameter combinations having the larger $\\Omega$ yet the smaller $\\gamma$ and $\\Delta$ indicate better solution quality. However, there may be a large difference among the values of three metrics, so we need to normalize them after each run. To be specific, the best result of certain metrics is assigned to 1 while the other results are assigned among $[0,1]$. It should be noted that some values of metrics may be equal to 0 . Therefore, we set $\\gamma_{k}=\\gamma_{k}+\\delta_{1}, \\Delta_{k}=\\Delta_{k}+\\delta_{2}$ and $\\Omega_{k}=\\Omega_{k}+\\delta_{3}$ $(k=1, \\ldots, 16, \\delta_{1}=\\delta_{2}=\\delta_{3}=0.001$ ). We normalize the values of the performance metrics of Table 7 in Table 8, where $\\operatorname{Sum}_{k=1}$  \n[IMAGE29]\na) $\\gamma$\n[IMAGE30]\nb) $\\Delta$\n[IMAGE31]\nc) $\\Omega$  \nFig. 20. Comparisons of $N B$ associated with Group 2.  \nTable 6\nDifferent combinations of parameters.\nis the sum of normalized metrics in the first run. In terms of 21 runs, the sums of normalized metrics $\\operatorname{Sum}_{k}(k=1, \\ldots, 21)$ for each parameter combination are given in Table 9.  \nTable 7\nOrthogonal array and obtained values of metrics (the first run).\nTable 8\nNormalized values of metrics (the first run).\nThe aim of the Taguchi method is to find the maximum $S / N$. Based on the sum of normalized metrics $\\operatorname{Sum}_{k}(k=1, \\ldots, 21)[60$, 63], $S / N$ can be calculated as\n$S / N=-10 \\log \\left(\\frac{1}{n} \\sum_{i=1}^{n} \\operatorname{Sum}_{i}^{2}\\right)$",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:31",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of using the Taguchi method of design of experiments (DOE) in the context of designing sEDA and EDA-p?",
      "topics": [
        "design"
      ],
      "answer": "The primary objective of using the Taguchi method (DOE) is to determine suitable values for the population size ($N$) and the learning rate ($a$) parameters in both the sEDA and EDA-p algorithms. DOE is employed as a statistical method to investigate the effect of different levels of $N$ and $a$ on the algorithm's performance, ultimately suggesting optimal parameter settings such as $N=30$ and $a=0.05$ for the simulation experiments.",
      "chunk_id": 9178,
      "paper_id": "Hybrid Evolutionary Scheduling for Energy-efficient Fog-enhanced Internet of Things",
      "paper_title": "Hybrid Evolutionary Scheduling for Energy-Efficient Fog-Enhanced Internet of Things",
      "paper_year": "2021",
      "chunk_content": "To compare the performance of the algorithms fairly, the stopping criterion of both algorithms is set as 30 generations. All the parameters in EDA are set the same for both sEDA and EDA-p. As the probability model is updated by the whole AS, the percentage of elite population does not need attention. The other two key parameters of EDA, the population size $(N)$ and the learning rate $(a)$, are determined by the Taguchi method of design-of-experiment method (DOE) [21]. DOE is a statistical method, which is used to investigate the effect of parameters on the performance of the algorithm under different levels. Orthogonal arrays of different parameter levels are used to conduct the experiment with multiple runs. In this experiment, four levels are set for each parameter as shown in Table III and $4^{2}$ full-factorial experiments are employed.  \nTABLE III. FACTOR LEVELS OF PARAMETERS  \nFor each combination of $n \\times C C R(3 \\times 4=12)$, an instance is randomly chosen. For each instance, 16 combinations of $\\eta$ $\\times a$ are tested independently and the obtained $\\mathrm{AS}_{i j}(c i=1$, $2, \\ldots, 16)$ are stored. The final AS (FAS) are obtained by integrating $\\mathrm{AS}_{1}, \\mathrm{AS}_{2}, \\ldots, \\mathrm{AS}_{16}$. Then, the contribution of a certain combination (CON) is counted as $\\operatorname{CON}(c i)=\\left|A S^{\\prime}{ }_{c i}\\right| /$ $|F E|$, where $A S^{\\prime}{ }_{c i}=\\left\\{X_{1} \\in A S_{c i} \\mid \\exists X_{1^{\\prime}} \\in F A S, X_{1}=X_{1^{\\prime}}\\right\\}$. The average CON of each combination is calculated and used as the response value (RV), shown in Table IV.  \nTABLE IV. THE RV VALUE  \nNote: \"RV\" indicates the response value considered in design of experiment.\nThe response values of DOE are listed in Table IV and the main effects plot and the influence trend table is shown in Figure. 5 and Table V. From Table V, the variances of the response value under different levels of $N$ and $a$ have little difference, which means that the effect of $N$ and $a$ on the algorithm performance is nearly the same.  \nTABLE V. INFLUENCE TREND TABLE  \n[IMAGE3]  \nFigure 5. The effect trend of parameters\nFrom Figure 5 and Table V, it is better for $N$ to be set neither too big nor too small. And a small $a$ is suitable for the benchmark instances as the stopping criterion is 30 generations. According to the results, $N=30, a=0.05$ are  \nsuggested as the parameters in the simulation experiments.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:32",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs applied to learning classifier systems, how does the algorithmic mechanism of the pLCSBOA differ from GAssist in terms of match operator execution and what is the theoretical justification for these differences regarding computational cost?",
      "topics": [
        "performance"
      ],
      "answer": "The pLCSBOA and GAssist algorithms differ in how they execute match operators within each generation. GAssist terminates the match operator when the first matched rule in a rule set is detected, using that rule's prediction. In contrast, pLCSBOA compares all rules in a rule set to examples to compute the fitness, adopting the best rule. Although pLCSBOA executes more match operators per generation, approximately twice as many as GAssist, it often requires fewer generations to converge. This leads to a reduction in the total number of match operators and sometimes the overall running time, particularly for problems with more variables and complex structures. However, for simpler problems, the rule evolution via BOA in pLCSBOA introduces more computational costs that may not improve overall performance.",
      "chunk_id": 5033,
      "paper_id": "Effective search for Pittsburgh learning classifier systems via estimation of distribution algorithms",
      "paper_title": "Effective search for Pittsburgh learning classifier systems via estimation of distribution algorithms",
      "paper_year": "2012",
      "chunk_content": "[IMAGE6]  \nFig. 4. Performance comparison on multiplexer problems.  \nTable 5 shows the classification accuracy on the those artificial problems, and Table 6 represents the number of generations, the number of match operators executed, and the running time. According to Table 5, pLCSBOA can deliver solutions with the same or even higher classification accuracy. From Table 6, it is obvious that pLCSBOA converges faster than GAssist in terms of both generation and total match operators for all problems except LadderMP-3-3-6. The two metrics could be generally reduced about $30 \\%$ and $15 \\%$, respectively. It is also noted that the numbers of match operators executed per generation in pLCSBOA are larger than those of GAssist for all problems. Generally, the proposed method performs twice as many match operators as GAssist does in each generation according to the results. The reason behind the phenomenon lies as below. For each rule set in GAssist, match operator terminates when the first matched rule (in the order the rules are placed in the individual) is detected, and the prediction of the rule is treated as the result of the rule set. While in the proposed method, all rules in a rule set are compared to examples with the aim of computing the fitness, and the rule set adopts the best one to solve the problems. Although the computation cost of each generation in pLCSBOA is higher than that in GAssist, however, the total cost has been reduced since the number of generations is decreased remarkably. With respect to the running time, the proposed algorithm takes less than GAsssit to deal with most problems. More specifically, when handling problems with fewer variables and uncomplicated structures (i.e., 11 bits multiplexer problem and its nosy versions), the running time of pLCSBOA is higher than that of GAssist. However, as the number of variables increases and the structure becomes more sophisticated, the advantage of pLCSBOA over GAssist is obvious regarding to the running time. The reason behind the phenomena lies in that the rule evolution via BOA introduces more computational costs. And the additional costs do not improve the overall performance when the problems are easy to be solved.  \nAdditionally, we want to detect significant differences between pLCSBOA and classic GAssist on these artificial problems in terms of accuracy, the number of generations, the number of match operators executed totally and in each generation, as well as the running time. Since the obtained results may present neither normal distribution nor homogeneity of variance, the Wilcoxon paired signed ranks test [32], which is a nonparametric test, is executed in our experiments, according to the recommendations made in [12]. The results are presented in Table 7. For a level of significance $\\alpha=0.05$, it is obvious that  \n[IMAGE7]  \nFig. 5. Performance comparison on noisy multiplexer problems.\npLCSBOA delivers solutions with the same accuracy in fewer generations and taking less time. Although the number of match operators executed in pLCSBOA per generation is higher than that in GAssist, the total number is lower.",
      "question_type": "comparison",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:34",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for close-range space rendezvous trajectory optimization, what parameter settings optimize the trade-off between solution quality and computational cost when interpolating thrust profiles using polynomial schemes?",
      "topics": [
        "selection"
      ],
      "answer": "To optimize the trade-off, practitioners should set the number of interpolation nodes to 18, as experiments indicated that higher node counts did not yield better solutions. For the mapping process, the BS mapping method is the most promising technique. Additionally, the SP polynomial interpolation method should be employed for interpolating the thrust profile, as it is associated with the best solutions.",
      "chunk_id": 3598,
      "paper_id": "Trajectory optimization of space vehicle in rendezvous proximity operation with evolutionary feasibility conserving techniques",
      "paper_title": "Trajectory optimization of space vehicle in rendezvous proximity operation with evolutionary feasibility conserving techniques",
      "paper_year": "2023",
      "chunk_content": "Table 1 contains the parameters for close-range space rendezvous mission considered in the experiments. Note that the specified initial mass, reference area, and the drag coefficient stands for both target and chaser within the simulation. Since the main aim of the experiments is to analyze the robustness of the presented approach and evaluating the practicality of the schemes for interpolation, several initial conditions  \nTable 1\nClose-range space rendezvous mission parameters\nTable 2\nInitial values for state vector.  \nbased on the practicality in real-world operations of the close-range space rendezvous problem are assumed according to Table 2.  \nBased on the proposed approach, each experiment can be conducted with a different choice for variety of parameters and techniques. For each initial condition, these parameters are number of polynomial points for thrust components, type of the mapping technique, and the interpolation method. The number of interpolation nodes is considered as 5 to 24 , which is 20 cases for this parameter. Results will indicate that no solutions with higher quality can be found with number of nodes more than 18 in the experiments. Also, with respect to three options for interpolating the thrust profile (SP, CR and NK) and four options for the mapping process (LD, LS, BD and BS), total number of 240 cases of setup regarding each initial condition is considered. Running the optimization algorithm 10 times for each case results in a vast database of solutions, including 2400 solutions to be analyzed. In each run, the obtained solutions are kept with its corresponding parameter selection. The top ten best obtained solutions are presented in Table 3. Results are separated for each initial condition.  \nAccording to the results, the high quality solutions correspond to 18 number of nodes for interpolating the components of thrust vector. The optimizer found solutions with almost similar quality by considering other number of nodes close to the top solution. Solving the problem with number of nodes higher than the top solution did not end in a better solution. Therefore, it is implied that the optimizer achieved the best available solution up to this point. Analysis of the employed mapping mechanisms in high quality solutions in Table 3 shows that BS mapping method is the most promising technique in finding the majority of the high quality solutions, regardless of the initial condition for this close-range space rendezvous mission. The question that whether the BS method is also the best mapping mechanism for another space rendezvous mission will be answered in the next subsection. According to the best obtained solutions, the time-variation of relative position and velocity with respect to each initial conditions is shown in Fig. 6. In this figure, the variations of relative states are presented and the value of terminal states are shown as the header of each plot. It shows that the best achieved solutions satisfy terminal conditions.  \nFig. 7 shows the variation of spacecraft mass and the magnitude of thrust acted on the chaser spacecraft. As can be inferred, the spacecraft with initial condition $C_{4}$ requires the highest quantity of propellant for reaching the target space vehicle with respect to maximum level of 122.3 N for thrust. On the other hand, assuming the initial condition of $C_{3}$, results the minimum required thrust level of 45.46 N . Moreover, analyzing the interpolation approaches gives important insights regarding the practicality of the employed polynomial schemes. All top solutions are associated with SP polynomial interpolation method. Best solutions  \nTable 3\nHigh quality solutions (top ten) for fuel-optimal transfers in close-range space rendezvous.\n[IMAGE6]  \nFig. 6. Time histories of state vector for different initial conditions.  \n[IMAGE7]  \nFig. 7. Time histories of thrust magnitude $(\\hat{Y})$ and spacecraft overall mass $\\omega_{j}$.",
      "question_type": "parameter selection",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:35",
      "generation_style": "practical_application"
    },
    {
      "question": "For a Genetic Algorithm (GA) using a mask-based crossover operator with probability \\(p_c = 1\\), a bitwise mutation with mutation rate \\(\\chi / n\\) (where \\(\\chi\\) is a fixed constant greater than 0 and \\(n\\) is the problem size), and \\(k\\)-tournament selection, what is the expected runtime on the ONEMAX problem, and under what condition is this runtime guaranteed?",
      "topics": [
        "proof"
      ],
      "answer": "With the specified GA configuration, including mask-based crossover with probability 1, bitwise mutation with rate \\(\\chi / n\\), and \\(k\\)-tournament selection with \\(k \\geq 8(1 + \\delta)e^{\\chi}\\) (where \\(\\delta\\) is any constant greater than 0), the expected runtime on the ONEMAX problem is \\(\\mathcal{O}(n \\lambda)\\), provided that the population size \\(\\lambda\\) satisfies \\(\\lambda \\geq c \\ln n\\) for some sufficiently large constant \\(c\\).",
      "chunk_id": 11137,
      "paper_id": "Level-Based Analysis of Genetic Algorithms and Other Search Processes",
      "paper_title": "Level-Based Analysis of Genetic Algorithms and Other Search Processes",
      "paper_year": "2018",
      "chunk_content": "4) $\\mathcal{O}\\left(n^{2}+n \\lambda \\ln \\lambda\\right)$ on LINEAR if $\\lambda \\geq c \\ln n$;\n5) $\\mathcal{O}\\left((n / \\chi)^{r}+n \\lambda+\\lambda \\ln \\lambda\\right)$ on $\\mathrm{JUMP}_{r}$ if $\\lambda \\geq c r \\ln n$;\n6) $\\mathcal{O}\\left((n / \\chi)^{r} \\ln (n / r)+[(n \\lambda \\ln \\lambda) / r]\\right)$ on ROYALROAD $_{r \\geq 2}$ if $\\lambda \\geq c r \\ln n$\nfor some sufficiently large constant $c$.\nThe proof is in the supplementary materials.\nIn the case of regular use of crossover, i.e., $p_{\\mathrm{c}}=1$, we limit our consideration to mask-based crossovers. Given two parent genotypes $u$ and $v$, such operator consists in first choosing (deterministically or randomly) a binary string $\\tilde{m}=$ $\\left(m_{1}, \\ldots, m_{n}\\right)$ to produce two offspring vectors $x^{\\prime}, x^{\\prime \\prime}$ as  \n$$\nx_{i}^{\\prime}= \\begin{cases}u_{i}, & \\text { if } m_{i}=1 \\\\ v_{i}, & \\text { otherwise, } x_{i}^{\\prime \\prime}= \\begin{cases}v_{i}, & \\text { if } m_{i}=1 \\\\ u_{i}, & \\text { otherwise }\\end{cases}\n$$  \nThen one element of $\\left\\{x^{\\prime}, x^{\\prime \\prime}\\right\\}$ chosen uniformly at random is returned. The well-known uniform crossover and $k$-point crossover are examples of mask-based crossover operators.  \nFor a frequent use of crossover, i.e., $p_{\\mathrm{c}}=1$, [9, Lemma 2], Corollary 3, and Lemma 4 yield the following.  \nTheorem 4: Assume that the GA in Algorithm 2 with $p_{\\mathrm{c}}=$ 1 uses any mask-based crossover operator, a bitwise mutation with mutation rate $\\chi / n$ for any fixed constant $\\chi>0$, and one of the following selection mechanisms:  \n1) $k$-tournament selection with $k \\geq 8(1+\\delta) e^{\\chi}$;\n2) $(\\mu, \\lambda)$-selection with $\\lambda / \\mu \\geq 2(1+\\delta) e^{\\chi}$;\n3) exponential ranking selection with $\\eta \\geq 8(1+\\delta) e^{\\chi}$;  \nfor any constant $\\delta>0$. Then there exists a constant $c>0$, such that the expected runtime of the GA is:  \n1) $\\mathcal{O}(n \\lambda)$ on ONEMAX if $\\lambda \\geq c \\ln n$\n2) $\\mathcal{O}\\left(n^{2}+n \\lambda \\ln \\lambda\\right)$ on LEADINGONES if $\\lambda \\geq c \\ln n$.  \nThe proof can be found in the supplementary materials.\nIn the next sections, we further demonstrate the generality of Theorem 1 through Corollary 2 by deriving bounds on the expected runtime of GAs with $p_{\\mathrm{c}}=1-\\Omega(1)$ to optimize or to approximate the optimal solutions.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:37",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is the key algorithmic difference between the Univariate Marginal Distribution Algorithm (UMDA) and Continuous Population-Based Incremental Learning (PBILc) in how they model the distribution of solutions?",
      "topics": [
        "Estimation of Distribution Algorithms (EDAs)"
      ],
      "answer": "UMDA models a distribution by calculating the average value of each gene representation in its relative position among all selected genotypes, without considering dependencies between variables. In contrast, Continuous PBIL (PBILc) uses a Gaussian distribution to sample the population and updates this distribution based on the population, thereby inheriting memory of good regions of the solution space across generations.",
      "chunk_id": 938,
      "paper_id": "ASYNCHRONOUS PARALLEL ALGORITHMS FOR STRATEGIC HYBRID SEARCHING BASED ON A MIXTURE GAUSSIAN MODEL",
      "paper_title": "ASYNCHRONOUS PARALLEL ALGORITHMS FOR STRATEGIC HYBRID SEARCHING BASED ON A MIXTURE GAUSSIAN MODEL",
      "paper_year": "2014",
      "chunk_content": "2.1. Mathematical notations and function optimization. $X_{i}$ is used to denote a random variable. An instance of $X_{i}$ is denoted by $x_{i} . \\mathbf{X}=\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ denotes an $n$-dimensional random variable, and $\\mathbf{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$ is one of its instances. For a continuous variable $X_{i}$, we denote the density function of $X_{i}$ by $f\\left(X_{i}\\right)$. Since, for our case, all the variables in $\\mathbf{X}$ are continuous, we denote the joint density function by $f(\\mathbf{x})$.  \nIn mathematics and computer science, function optimization is the process of finding the best solution from all feasible solutions to minimize or maximize a specific function. Function optimization can be divided into two categories, depending on whether the variables are continuous or discrete. The case with discrete variables is known as combinatorial optimization; it is continuous function optimization if the variables are continuous. In this paper, we perform minimization of continuous functions; the standard form of optimization is\nMinimize $f(x)$\nSubject to $g_{i}(x) \\leq 0, i=1, \\ldots, m$  \n$$\nh_{i}(x) \\leq 0, i=1, \\ldots, p\n$$  \nwhere  \n- $f(x): \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ is the objective function to be minimized over the variable $x$,\n- $g_{i}(x) \\leq 0$ are called inequality constraints, and\n- $h_{i}(x) \\leq 0$ are called equality constraints.\n2.2. Evolutionary algorithms. GAs are population-based EAs that simulate genetic selection and natural elimination processes of biological evolution. Holland [17] conducted pioneering work in this field. GAs are useful for searching very general or poorly defined spaces [18]. The three main components of GAs are crossover, mutation, and selection. The pseudocode in Figure 1 summarizes the basic structure of GAs.  \nWith recombination operators in GAs, good solutions can be easily destroyed, even with elitism. EDAs, as explained in $[6,19]$, have their theoretical foundation in probability theory. They perform iterative evolutionary computation without using any recombination operators. EDAs work by probabilistic estimation and sampling. The best solutions are selected from the population and a distribution is constructed from the selected solutions. Using the distribution, sampling is done to obtain new members of the population. The pseudocode of EDAs is shown in Figure 2.  \nThe univariate marginal distribution algorithm (UMDA) was described by Muhlenbein in 1997 [20], who provides the theoretical foundation for the field of investigation in general and for the algorithm specifically. UMDA is the simplest model of EDA that does not involve dependency between variables. UMDA models a distribution by just calculating the average value of each gene representation in its relative position among all selected genotypes. Muhlenbein also introduced an incremental version of UMDA (IUMDA) that is described as equivalent to a population-based incremental learning (PBIL) algorithm [21]. The PBIL approach bridges the gap between machine learning and EAs; PBIL explicitly constructs an intensional description of the optima, expressed as a distribution on the solution space. Continuous PBIL (PBILc), as introduced by [22], uses a Gaussian  \ndistribution to sample the population and updates the distribution from the population. By doing so, the memory of good regions of the solution space is inherited from generation to generation.",
      "question_type": "COMPARATIVE EVALUATION",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:39",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned within the data-driven Bayesian assisted optimization algorithm, what programming techniques are suggested to optimize the EDA's performance, particularly concerning the adjustment of key parameters?",
      "topics": [
        "optimization"
      ],
      "answer": "The implementation should incorporate an adaptive adjustment of key parameters based on the estimation of the population distribution. This involves analyzing the current distribution of solutions within the population and dynamically modifying parameters of the EDA to promote exploration in promising regions of the search space and avoid premature convergence. A replacement strategy should also be developed to update the samples of Bayesian optimization for better prediction precision.",
      "chunk_id": 3206,
      "paper_id": "Dispatch of highly renewable energy power system considering its utilization via a data-driven Bayesian assisted optimization algorithm",
      "paper_title": "Dispatch of highly renewable energy power system considering its utilization via a data-driven Bayesian assisted optimization algorithm",
      "paper_year": "2023",
      "chunk_content": "Existing researches clearly show that the stochastic optimization method can well solve the OPSD problem with RE integration. Especially, some work has attempted to reduce the power system operation cost in consideration of the security constraints. For example, Ref. [15] propose a security-constrained stochastic dispatch model to minimize the expected total dispatch cost while the limitation of transmission flow is taken into account. Simulation results indicate that the developed model can help to identify desired dispatching schemes and have a significant reduction on the wind power spillage and daily operation cost. A security constrained unit commitment model with extreme wind scenarios is developed in Ref. [16], in order to solve the operational risk caused by wind power uncertainty. Besides, Ref. [17] presents a novel voltage security constrained stochastic dispatch model for power system with battery, whose main objective is maximizing loading margin of battery. Numerical experiments verify the effectiveness of proposed model in achieving the desired maximal loading margin. However, these dispatch problems are usually established as optimization model with single objective while regarding the security as constraints. In this way, the optimal dispatch under secure operation is ensured but the interaction between power system economy and security is still unknown. Notably, the relationship between wind power curtailment and transmission security has not been comprehensively investigated\nin the form of multi-objective optimization. To this end, it is worth investigating such a relationship in the bi-objective optimization manner with Pareto analysis, and well balancing the maximum wind power utilization and the transmission security under high RE penetration occasions.  \nFurthermore, as for the proposed stochastic dispatch model, traditional mathematical optimization algorithms cannot efficiently solve this non-convex multi-objective optimization problem [18]. Fortunately, the evolutionary algorithm is able to deal with this problem with strong robustness and adaptability [19-21]. For instance, various evolutionary algorithms are introduced to solve the multi-objective optimization problems, including commonly used PSO [22], NSGAIII [23] and differential evolution algorithm [24]. Although evolutionary algorithms could handle this problem to some extent, they still have weakness such as time-consuming and inefficient searching. Generally, a great number of objective evaluations is required for evolutionary algorithms to obtain the optimal solution, which easily leads to a timeconsuming computation especially when the optimization problem is high-dimensional and evaluation expensive. Also, the determination of proper parameter is very important since an unsuitable parameter might lead to inefficient searching and even local optimum. For that reason, the complicated multi-objective dispatch problem calls for a novel data-driven optimization algorithm to promote the searching ability and computational efficiency.  \nTo this end, we conduct the following work, which are also the contributions of this paper.\n(1) We propose a bi-objective stochastic dispatch model for OPSD with high RE penetration. The wind power utilization and the capacity margin of transmission lines are set as objectives, and the dispatch model aims to analyze their relationship. Therein, a gradual curtailment strategy is proposed in this paper to well formulate wind power curtailment objective functions under stochastic scenarios.\n(2) To efficiently solve the proposed bi-objective stochastic dispatch problem, we propose a data-driven Bayesian assisted optimization algorithm based on Bayesian evolutionary optimization and estimation of distribution algorithm. A replacement strategy is developed to update the samples of Bayesian optimization for better prediction precision. Furthermore, an adaptive adjustment of key parameter is achieved based on estimation of the population distribution in this paper.\n(3) We conduct case studies on a modified Midwestern US power system, to verify effectiveness of the proposed stochastic dispatch model and data-driven optimization algorithm. In addition, sensitivity analysis regarding our presented dispatch model and four important parameters is discussed, involving wind power penetration rate, sample distribution, consumption level of user loads and locations of wind farms.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:41",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the probabilistic model matrix updated in the Estimation of Distribution Algorithm based on chromosome quality?",
      "topics": [
        "termination"
      ],
      "answer": "To update the probabilistic model matrix, if two artifacts are located in the same module in the highest quality chromosome but not in the lowest quality chromosome, their probability values are increased by 1/t, where t represents the algorithm iterations. Conversely, if two artifacts are located in the same module in the lowest quality chromosome but not in the highest quality chromosome, their probabilities are reduced by 1/t.",
      "chunk_id": 8228,
      "paper_id": "Multi-objective search-based software modularization- structural and non-structural features",
      "paper_title": "Multi-objective search-based software modularization: structural and non-structural features",
      "paper_year": "2019",
      "chunk_content": "```  \n6) Elitism\n7) Test the termination condition  \nWe illustrate with an example how to create and update a probabilistic model. Suppose a software system consists of five artifacts denoted by F1-F5. Figure 7 shows the initial probabilistic model matrix for this software system so that the values of all elements except the main diagonal are $1 / n$ ( $n$ is the number of artifacts). Also, assume that $a$, $b$ and $t=10$ indicate the chromosome with the highest quality in the initial population, the chromosome with the lowest quality in the initial population, and the algorithm iterations, respectively (Fig. 8). To update the probabilistic model matrix, since two artifacts F1 and F2 are located in the same module in the highest quality chromosome but are not located in the same module in the lowest quality chromosome, hence, their probabilities values are added in the probability matrix by $1 / 10$. In contrast, because two artifacts F3 and F4 are located in the same module in the lowest quality chromosome but are not located in the same module in the highest quality chromosome; hence, their probabilities in the probability matrix are reduced by $1 / 10$. Figure 9 shows the updated probabilistic model matrix.  \nIn the EoD, the new population is sampled as follows: from the probabilistic model, a row is randomly selected. Given the upper triangular part of the probabilistic matrix,  \nFig. 7 A sample initial probability matrix for a software system with five artifacts  \na: the highest quality chromosome\nb: the lowest quality chromosome\nFig. 8 Selecting the highest quality and lowest quality chromosome  \nFig. 9 Updated probability matrix\nfor each element of the selected row, a random number is generated between 0 and 1 ; if this random number is equal to or less than the probability of the element in the row, these two artifacts will be placed in the same module in the new chromosome. This is repeated for all elements in the selected row. If all elements of the selected row in the probability matrix were examined, but the chromosome was not completely modularized, then a new row from the probability model matrix would be randomly selected and, until the chromosome is completed, the random number generation operation is repeated.  \nFor example, consider Fig. 10. In this figure, R1 shows the selected row and F1-F5 represents artifacts. For each element of the selected row, a random number is generated  \nFig. 10 Create a new population using a new probability matrix\n[IMAGE5]  \nFig. 11 Two first generations of distribution estimation algorithm",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:42",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when initializing the population using heuristics?",
      "topics": [
        "scheduling"
      ],
      "answer": "The primary objective is to generate an initial population for the Estimation of Distribution Algorithm by employing two heuristics, each producing N/3 initial solutions, where N represents the population size. Heuristic 1, detailed in Algorithm 1, constructs a scheduling string and a machine assignment string by iteratively calculating and minimizing \\(\\tilde{C}{e, l, i}\\), which represents the cost of inserting a job \\(\\pi{j}\\) into position l of machine M{i}, ultimately aiming to minimize Cmax, the makespan.",
      "chunk_id": 7743,
      "paper_id": "A Novel Imperialist Competitive Algorithm With Multi-Elite Individuals Guidance for Multi-Object Unrelated Parallel Machine Scheduling Problem",
      "paper_title": "A Novel Imperialist Competitive Algorithm With Multi-Elite Individuals Guidance for Multi-Object Unrelated Parallel Machine Scheduling Problem",
      "paper_year": "2019",
      "chunk_content": "In this section, initial population is first produced by two heuristics and a random way, then initial empires are constructed. To hybrid EDA with ICA, probability matrices of EDA are also initialized.  \nHeuristic is often used to generate initial population. In general, a heuristic can only produce a solution. In this study, heuristics 1 and 2 are adopted, each of which produces $N / 3$ initial solutions, where $N$ represents population size.  \nHeuristic 1 is shown in Algorithm 1. For the example, a string $[3,5,1,2,6,4]$ is first randomly obtained. Start with $J_{3}$, we calculate $\\bar{C}_{3,1,1}$ and $\\bar{C}_{3,1,2}$ and obtain $\\bar{C}_{\\min , 3}$ of 31 . $J_{3}$ is allocated to the first position on $M_{1}$. Then for $J_{5}$, $\\bar{C}_{\\text {min }, 5}$ is decided and equal to 49 , and $J_{5}$ is allocated on $M_{2}$. For $J_{1}$, we find that $\\bar{C}_{1,1,1}=\\bar{C}_{1,2,1}=\\bar{C}_{\\text {min }, 1}=39$, so two positions can be selected and position 1 is chosen, so $J_{1}$ is inserted on the left of $J_{3}$ and the scheduling string becomes $[1,3,5,2,6,4]$. The final scheduling string is $[1,6,3,2,5,4]$ and machine assignment string is $\\left[M_{1}, M_{2}, M_{1}, M_{2}, M_{2}, M_{1}\\right] . C_{\\max }$ is 114. Fig.1(b) shows the Gantt chart of the obtained solution.\n```\nRandomly produce a scheduling string \\(\\left[\\pi{1}, \\pi{2}, \\cdots, \\pi{n}\\right]\\)\nfor \\(\\pi{1}\\) to \\(\\pi{n}\\) do\nfor each position \\(l\\) on each machine \\(M{i}, i=1,2, \\cdots\\),\n\\(m\\) do\nCalculate \\(\\tilde{C}{e, l, i}\\) if inserting \\(\\pi{j}\\) into position \\(l\\) of \\(M{i}\\)\nend for\nCompute the minimum value \\(\\tilde{C}{\\text {min,e }}\\) of all possible\n\\(\\tilde{C}{e, l, i}\\).\nDecide all machines and positions meeting \\(\\tilde{C}{e, l, i}=\\) $\\tilde{C}_{\\text {min,e }}$.\nif more than one position has \\(\\tilde{C}{e, l, i}=\\tilde{C}{\\text {min,e }}\\) then\nRandomly choose a machine \\(M{i}^{}\\) and a position \\(l^{}\\).\nelse\nDirectly select the machine \\(M{i}^{}\\) and the position \\(l^{}\\).\nend if\nAllocate \\(\\pi{j}\\) into position \\(l^{}\\) of \\(M{i}^{}\\).\nif \\(l^{}\\) is not the last position on \\(M{i}^{}\\) then\nAdjust the position of \\(\\pi{j}\\) on scheduling string by\ninserting \\(\\pi{j}\\) into the position of \\(J{n}\\), which is pro-\ncessed on position \\(l^{}+1\\) of \\(M{i}^{}\\).\nend if\nend for",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:44",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of an online EDA, designed for solving the real-time Aircraft Arrival Sequencing and Scheduling (ASS) problem, leverage known information to gradually approach an optimal solution in a dynamic airport environment?",
      "topics": [
        "design"
      ],
      "answer": "The online EDA, as applied to the real-time ASS problem, operates by establishing a mathematical model closely aligned with the reality of the airport environment. The core algorithmic mechanism involves solving the ASS problem gradually, incorporating known information as it becomes available within the dynamic environment. The method aims to obtain an optimal solution that is not significantly worse than what could be achieved in a static case. The key aspect of this EDA's mechanism is its efficiency and closer alignment with real-world conditions compared to static algorithms, making it valuable for air traffic control.",
      "chunk_id": 614,
      "paper_id": "An online method for the real-time aircraft arrival sequencing and scheduling problem",
      "paper_title": "An Online Method for the Real-time Aircraft Arrival Sequencing and Scheduling Problem",
      "paper_year": "2014",
      "chunk_content": "In order to solve the real-time ASS problem, a mathematical model which is much closer to the reality is established and an online algorithm based on EDA is designed. A dynamic environment of the airport is also simulated so that the algorithm solves the ASS problem gradually according to the known information. Simulation results show that our method can always get an optimal solution which is not much worse than the static case. Furthermore, this method is far more efficient and much closer to the reality than static algorithms that it shows great application value in the air traffic control.\nThis work was supported in part by the National Key Technology R\\&D Program under Grant 2011BAH24B13, and the National Key Scientific Instrument and Equipment Development Project under Grant 2011YQ040083.",
      "question_type": "conceptual deep",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:47",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to optimize the JumpOffset function, how should practitioners handle the fitness gap defined by the parameters $k$ and $m$, where $k$ represents the start of the gap and $m$ represents its size?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "When implementing an EDA for the JumpOffset function, the fitness gap is defined between $k$ and $k+m$, where $k$ is the starting point of the gap and $m$ is its size. With $k$ fixed at $3n/4$, practitioners should be aware that solutions with a number of one-bits within the interval $(3n/4, 3n/4 + m)$ have a fitness value of $3n/4 + m - |x|_1$, while solutions outside this gap (i.e., $|x|_1 \\leq 3n/4$ or $|x|_1 \\geq 3n/4 + m$) have a fitness value of $m + |x|_1$.",
      "chunk_id": 8818,
      "paper_id": "On Crossing Fitness Valleys with Majority-Vote Crossover and Estimation-of-Distribution Algorithms",
      "paper_title": "On Crossing Fitness Valleys with Majority-Vote Crossover and Estimation-of-Distribution Algorithms",
      "paper_year": "2021",
      "chunk_content": "As motivated above, the aim of this work is to study variants of Jump where\n(a) the fitness gap is not directly adjacent to the all-ones string,\n(b) the optimum is not located at the all-ones string,\n(c) and a combination of both.  \nType (a) of modification gives rise to a class of generalized jump functions with two parameters: the start of the gap $k$ and its size $m$. The function then gives a fitness value of $|x|_{1}+m$ to all search points having at most $k$ and at least $k+m$ one-bits, while search points with a number of ones in $(k, k+m)$ have a fitness of $k+m-|x|_{1}$. If $k=n-m$, we recover the original Jump $_{m}$ function. It is clear that choices of $k$ below $n / 2$ are not very interesting since a uniform search point would then have a good probability of being behind the gap. Since we are mostly interested in the size of the gap that can be overcome and would like to avoid another parameter, we fix $k=3 n / 4$ in this work, i. e., the gap starts half-way between the expected starting point of a random bit string and the global optimum, the all-ones string, and therefore assume $m<n / 4$. Most of the results of this paper can be easily generalized to the case that $k$ has linear distance from both $n / 2$ and $n$, i. e., $k \\in[(1+\\epsilon)(n / 2),(1-\\epsilon) n]$ for some constant $\\epsilon>0$.  \nWith the start of the gap fixed at $3 n / 4$, we obtain our function called JumpOffset for \"Jump with offset\", see Figure 2 for an illustration:  \n$$\n\\operatorname{JumpOffset}_{m}(x)= \\begin{cases}m+|x|_{1} & \\text { if }|x|_{1} \\leq 3 n / 4 \\\\ & \\text { or }|x|_{1} \\geq 3 n / 4+m \\\\ 3 n / 4+m-|x|_{1} & \\text { otherwise. }\\end{cases}\n$$  \nThis function (with a variable start of the gap, i. e., with the two parameters $k$ and $m$ mentioned above) was introduced in [36] to investigate whether self-adjusting, mutation-only algorithm with a memory mechanism would be able to first increase its mutation strength to overcome the gap and to quickly decrease it again afterwards. Independently, this generalization of Jump was proposed in the very recent work [3] to investigate how quickly various\n[IMAGE1]  \nFigure 2: Illustration of JumpOffset; fitness gap between $(3 / 4) n$ and $(3 / 4) n+m$ one-bits and optimum at $n$ one-bits\nmutation-based algorithms overcome a gap that is not adjacent to the global optimum but starts at some value $k=n-o\\left(n^{1 / 3}\\right)$. Crucially different from the present work, we consider smaller $k$ (fixed at $3 n / 4$ in the remainder) and focus on crossover-based algorithms, including the cGA.  \nThe modification (b) mentioned above was essentially the key idea for the so-called Reaijump function proposed in [24]. That function equals the original (non-shifted) Jump $_{m}$ function except for the fact that the global optimum is a single search point $x^{*}$ such that $\\left|x^{*}\\right|_{1}>n-m$. Hence, in a sense, the gap region involves a needle-in-a-haystack problem of dimension $m$, which results in a black-box complexity proportional to the number of search points in the gap region, formally analyzed for constant $m$ in [24]. Due to this needle property, we do not expect very interesting performance differences between the crossover-based EAs and the EDA studied in this paper and do not consider the Reaijump function further.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:48",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the EDA discussed, what characteristics make it suitable for solving configuration design problems, and what advantages does it offer compared to Genetic Algorithms (GAs) in this context?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The EDA is presented as suitable for configuration design problems due to two main reasons. First, it requires fewer function evaluations to find optimal solutions compared to GAs, which is critical because fitness evaluation, involving physics-based simulation, is computationally expensive for mechanical assemblies. Second, EDAs can exploit the structure of the problem, such as dependencies between variables, to generate new solutions at each iteration of the optimization process. This allows incorporating prior knowledge or learning dependencies during optimization. Specific references [4], [5], [7], [11], [12], [14] support the claim of fewer function evaluations compared to GAs, and references [4], [6]-[13] support the claim of exploiting problem structure.",
      "chunk_id": 8662,
      "paper_id": "Configuration Design of Mechanical Assemblies using an Estimation of Distribution Algorithm and Constraint Programming",
      "paper_title": "Configuration Design of Mechanical Assemblies using an Estimation of Distribution Algorithm and Constraint Programming",
      "paper_year": "2019",
      "chunk_content": "A notable trend in engineering is the increasing application of artificial intelligence and computational techniques to automate and improve design and manufacturing workflows. In particular, improving the early-stage design process can lead to significant cost-savings associated with the development and manufacturing of optimally functioning products [1].  \nOne challenging early-stage design problem in mechanical engineering is configuration design [2], defined as follows. Given a fixed set of predefined components and joints, find the optimal combination of components interfaced via joints that exhibits the desired mechanical behavior. An example of such a problem would be to compose a suspension system out of beams, springs, and dampers via fixed or spherical joint types, that would have minimal acceleration at a particular point on the chassis, as illustrated in Fig. 1.  \nThe configuration design problem can be characterized as a discrete, constrained, and black-box optimization problem, which is difficult to solve. First, we can treat the configuration design problem as operating in the space of graphs, where a particular graph represents a mechanical assembly with vertices as joints and edges as components. Each node and edge can be considered as a categorical design variable whose\n[IMAGE_0]  \nFig. 1. Configuration design problem for a mechanical assembly.\nvalues specify the types of components and joints being used in the assembly. Also, several constraints must be satisfied for a given configuration to be considered feasible as a physically realizable and practical mechanical assembly. Moreover, the precise analytical form of the fitness function for a given solution depends on its configuration. Hence, evaluation of each solution requires invoking a physics-based simulation solver with the configuration as input.  \nConsidering the above characterization, the current work applies an evolutionary computation (EC) technique to solve configuration design problems. In particular, this paper investigates using an Estimation of Distribution Algorithm (EDA). EDAs are a class of evolutionary algorithms [3]-[13] that use probability distributions estimated from a pool of candidate solutions to sample new solutions at each iteration of optimization. Reasons for choosing the EDA approach are as follows.  \nFirst, fitness evaluation is expensive for mechanical assemblies, especially for those exhibiting dynamic behaviors. For example, evaluating the fitness of a suspension system requires physics-based simulation of its behavior over a specified time period. Even with the most advanced solvers, it can take in the order of minutes to evaluate a single solution. Hence, it is critical to minimize fitness evaluations as much as possible.  \nSecond, most mechanical assemblies feature dependencies between their constituting components. Such dependencies should be leveraged in solving the problem, either by learning them during the optimization process or being specified by  \nthe designer. If the dependency knowledge is learned, it can be communicated to the designer for better interpretation of the solutions found and exploring alternatives. The knowledge can also be reused for solving similar design problems later.  \nAn EDA is deemed suitable in addressing the above challenges. First, for various EDAs, it has been shown that a fewer number of function evaluations are required to find optimal solutions compared to genetic algorithms (GA) [4], [5], [7], [11], [12], [14]. Second, many EDAs exploit the structure of the problem, e.g., dependencies between variables, to generate new solutions at each iteration of the optimization process [4], [6]-[13]. If the designer has prior knowledge about the problem, this can be introduced in the form of a probability distribution model. Also, most EDAs can learn the problem knowledge as part of optimization, which can be communicated to the designers for their benefit.",
      "question_type": "definition",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:51",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the modified approach of growing clusters directly around leaders chosen from the selection set compare to using the $k$-means algorithm in the context of multi-objective optimization, specifically regarding the drift of cluster means and search effort near Pareto extremes?",
      "topics": [
        "search"
      ],
      "answer": "The modified approach grows clusters directly around leaders to avoid the issue of cluster means drifting \"inwards\" in the selection set, which is observed when using the $k$-means algorithm. This drifting leads to reduced search effort in the vicinity of the Pareto extremes. By directly growing clusters around leaders, the modified approach aims to maintain search effort near the Pareto extremes, whereas $k$-means tends to concentrate the search towards the center of the clusters, potentially missing solutions on the Pareto front.",
      "chunk_id": 729,
      "paper_id": "A novel population-based multi-objective CMA-ES and the impact of different constraint handling techniques",
      "paper_title": "A Novel Population-based Multi-Objective CMA-ES and the Impact of Different Constraint Handling Techniques",
      "paper_year": "2014",
      "chunk_content": "After explicit cluster registration, depending on the optimization algorithm being combined with the framework, the parameters that span multiple generations are updated.\nAn elitist archive is maintained with all currently nondominated solutions. If the objectives are real-valued, there will be infinitely many non-dominated solutions possible. To prevent the archive from growing to extreme sizes, the objective space is discretized into hypercubes. Only one solution per hypercube is allowed in the archive. Newly generated solutions are compared to the solutions in the archive. If a new solution is dominated by any archive solution, it is not entered. If a new solution is not dominated, it is added to the archive if the hypercube that it resides in does not already contain a solution or if it dominates that particular solution. When a new solution is entered all archive solutions that are dominated by it are removed.  \nKeeping elitist solutions in the population can improve convergence. Therefore, each solution in the elitist archive is associated with its nearest cluster. The distance is computed between the cluster mean to the archive solution. For each cluster, at most $\\frac{1}{k}\\lfloor\\tau n\\rfloor$ of its associated elitist solutions are copied to the population. If there are more elitist solutions, the same nearest-neighbor heuristic is used as in selection. Finally, each cluster generates equally many solutions. Depending on how many elitist solutions were copied to the population, at least $n-\\lfloor\\tau n\\rfloor$ new solutions are generated.\nIn this work several changes are made to the optimization framework presented in [6]. The modifications are as follows:  \n- The $k$-means algorithm is not used because the clusters means tend to drift \"inwards\" in the selection set, leading to reduced search effort in the vicinity of the Pareto extremes. Instead, the clusters are grown directly around the leaders chosen from the selection set;\n- The previous framework included $m$ external, independent SO optimizers whose best solutions were infused into the MO population. Instead, FORMULA_65 clusters are added to the MO population that are constructed by selecting solutions from the population in a single-objective manner. This effectively keeps SO pressure on the Pareto extremes while ensuring that this pressure in terms of solutions overlaps with the MO population.  \nWith external SO optimizers there is a larger probability of the Pareto extremes becoming fully disconnected from the population and Pareto front as governed by the MO population;  \n- An adaptive gridding technique was employed for the elitist archive [8]. The main advantage of this is that only a target size for the elitist archive needs to be specified while all the gridding details are automatically handled. Initially, all solutions are accepted in the archive. After an upper bound size is crossed, a grid adaptation process is triggered to ensure that the number of elitist solutions stays in the vicinity of the target size. This method provides the same convergence guarantee as the static grid approach, only potentially losing convergence properties when the grid is redefined. Furthermore, as shown in [8] grid adaptations do not occur often during a run and no loss in performance was observed in experiments;\n- Solutions that share an elitist hypercube and do not dominate the already existing solution found there but further extend the front are accepted. Such solutions were previously discarded. This feature guarantees that the front is always extended since the granularity of the grid plays no part in the process.",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:53",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the Improved Q Learning-Based Estimation of Distribution Algorithm, specifically focusing on the initialization and action selection phases?",
      "topics": [
        "initialization"
      ],
      "answer": "The Improved Q Learning-Based Estimation of Distribution Algorithm begins with initializing the Q-values, Qi(s), as a zero matrix for each agent i. The temperature, denoted as , is initialized to 0, and the probability vector p(1) is set to (0.5, 0.5, ..., 0.5). During each iteration, an action a' is determined. This involves either randomly selecting an action ar with probability  *  or selecting a' = argmax Qi(s', a'') with probability 1 -  * . The temperature  is then updated using a geometric cooling strategy:   , where   (0, 1) is the temperature coefficient.",
      "chunk_id": 11431,
      "paper_id": "The Research of Q Learning-Based Estimation of Distribution Algorithm",
      "paper_title": "The Research of Q Learning-Based Estimation of Distribution Algorithm",
      "paper_year": "2011",
      "chunk_content": "Generate random numbers $\\xi \\mathrm{i} \\in[0,1]$, if $\\xi \\mathrm{i} \\leq \\square$, Randomly selected with equal probability of action a ', otherwise select\n$\\mathrm{a}^{\\prime}=\\operatorname{argmax} \\mathrm{Qi}\\left(\\mathrm{s}^{\\prime}, \\mathrm{a}^{\\prime}\\right)$;\nAccording to equation (0) - (2) and the action a 'corresponds to the formula. Calculate the new probability value pi $(\\mathrm{t}+1)$;\nEnd\n$\\mathrm{t} \\leftarrow \\mathrm{t}+1$;\nEnd\nC Improvement Strategies\nThe algorithm each update probability pi (t) time, Agenti $\\square$-greedy strategy to choose an action, that is, the greater the probability of $1-\\square$ select the maximum Q value of the current state of the corresponding action, but with a smaller probability of randomly selected action $\\square$. As $\\square$-greedy strategy is not always accept the best action, but increased the probability of random selection, thus contributing to Agent explore new knowledge, than the greedy strategy with better results.  \nHowever, the value of using a fixed $\\square$ has some limitations. Especially in the Ageni some time after learning, the current strategy is near optimal, if the probability of $1-\\square$ still randomly choose an action, it will have an impact on the convergence of the algorithm. If you can gradually reduce the evolution $\\square$ values, will further enhance the Q study the performance of estimation of distribution algorithms. The use of simulated annealing (SA) algorithm MetroPolis criteria to be able to do this, it is the way by reducing the temperature to gradually reduce the probability of receiving inferior solution.  \nHere are guidelines for improved use of MetroPolis Q Learning-Based Estimation of Distribution Algorithm Algorithm2: Improved Q Learning-Based Estimation of Distribution Algorithm\nInitialization $\\mathrm{Qi}_{\\mathrm{s}}, \\mathrm{i}=1,2, \\ldots, \\mathrm{~m}$ zero matrix, the temperaturer $=\\tau 0, \\mathrm{p}(1)=(0.5,0.5, \\ldots 0.5), \\mathrm{t}=1$;\nWhile (termination condition is not satisfied algorithm) do\nAccording to p (t) sampled individuals generate $\\mathrm{N}-1$, and $\\mathrm{t}-1$ together constitute the best individual on behalf of the current population;\nCalculation of N individuals of fitness function and sorting;\nM -choose the best and the worst individuals, the frequency of statistics you get a value of gi (t) and bi (t), i $=1,2, \\ldots, \\mathrm{~m}$;\nFor (i-loci associated Agenti, $1 \\leq \\mathrm{i} \\leq \\mathrm{m}$ )\nRecorded before found their $\\mathrm{t}-1$ action on behalf of the state s and a , by gi (t) and bi (t) determine the current state $\\mathrm{s}^{\\prime}$;\nBy (5) calculation of an immediate return, according to equation (4) Update Qi (s, a);\nCome to a ' $=\\operatorname{argmax} \\mathrm{Qi}\\left(\\mathrm{s}^{\\prime}, \\mathrm{a}^{\\prime \\prime}\\right)$, randomly select an action ar, according to the following probability to determine a ':  \n$$\n\\begin{aligned}\n& \\mathrm{P}\\left\\{\\mathrm{a}^{\\prime}=\\mathrm{a}^{*}\\right\\}=\\varnothing \\quad \\tau \\\\\n& \\mathrm{P}\\left\\{\\mathrm{a}^{\\prime}=\\mathrm{a}^{*}\\right\\}=1-\\mathrm{P}\\left\\{\\mathrm{a}^{\\prime}=\\mathrm{a}^{\\prime}\\right\\}\n\\end{aligned}\n$$  \nAccording to equation (0) - (2) and the action a 'new formula to calculate the corresponding probability value pi $(t+1)$;\nEnd\nCool: $\\tau \\leftarrow \\lambda \\tau$;\n$t \\leftarrow t+1$\nEnd\nAlgorithm to geometric cooling strategy $\\tau \\leftarrow \\lambda \\tau$, Where $\\lambda \\in(0,1)$ is the temperature coefficient ${ }_{*}$ As the temperature decreases , Agenti randomly selected probability of action will become increasingly smaller, When the temperature tends to 0 , the strategy is equivalent to the greedy strategy.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:47:55",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the HIDiC column design during each generation of the BUMDA algorithm?",
      "topics": [
        "control"
      ],
      "answer": "The Total Annual Cost (TAC) is computed to evaluate the HIDiC column design. The algorithm also considers constraints within the HIDiC column. The temperature driving forces are the parameters used to compute the quantities of energy to be exchanged stage by stage.",
      "chunk_id": 7188,
      "paper_id": "Design and optimization of heat-integrated distillation configurations with variable feed composition by using a Boltzmann-based estimation of distribution algorithm as optimizer",
      "paper_title": "Design and optimization of heat-integrated distillation configurations with variable feed composition by using a Boltzmann-based estimation of distribution algorithm as optimizer",
      "paper_year": "2017",
      "chunk_content": "The amount of heat integrated at each stage is calculated by means of Eq. (4), using the condenser duty.\n$\\mathrm{Qi}=\\Delta T_{\\mathrm{SR} 0 \\text {-SS1 }}\\left(\\frac{\\mathrm{QC}}{\\sum_{\\mathrm{i}=1} \\Delta \\mathrm{~T}_{\\mathrm{SR} i-\\mathrm{SSI}}}\\right)$\nIn addition, the heat transfer area by stage was calculated by using Eq. (5).\n$\\mathrm{Ai}=\\left(\\frac{\\mathrm{Q}_{\\mathrm{i}}}{\\mathrm{U} \\Delta T_{\\mathrm{SR} i-\\mathrm{SSI}}}\\right)$\nwhere i represents the corresponding stage.\nThe selection of condenser duty as the available energy to be integrated is based on operational principles of a distillation process. As is widely known, conventional distillation columns use energy inefficiently. This behavior is produced because the heat supplied to the reboiler is simply eliminated in the condenser by using cooling water. The energy eliminated in the condenser is usually released to the environment because of its low quality to achieve work. Thus, instead of using the energy in the traditional way, a large portion of the heat to be eliminated in the condenser of the conventional column is integrated in the feasible stages of the HIDiC column. Therefore, the duties of both reboiler and condenser are reduced. As it is observed in the Eq. (4), the temperature driving forces were the parameters used to compute the quantities of energy to be exchanged stage by stage. So, the quality (temperature) controls the amount of heat integrated. In other words, the amounts of available energy to be integrated from the vapor flows of SR (which is the source of heat) to the liquid flows of SS (sink of heat) are constrained by the temperature driving forces. This strategy leads obtaining thermodynamically feasible HIDiC designs, and obeys the structural and economic guidelines to design heat exchangers.  \nEven the structural design is out of the goals of this study, it is important to mention some possibilities to build HIDiC configurations (Aso et al., 1998; Noda et al., 2006; Nakanishi et al., 2008). Among the possible configurations to assemble HIDiC columns the following are worth mentioning: (a) concentric arrangement, (b) compact heat exchanger (plate-fin), (c) configuration type multi-tube heat exchanger, (d) design of external heat transfer panels, among other arrangements.  \n[IMAGE3]  \nFig. 4 - Flowchart of design-optimization of HIDiC columns.\nThe design-optimization procedure of the HIDiC configurations is shown in Fig. 4. The evaluation of each new generation, produced by BUMDA algorithm, starts with the design of the conventional column, followed by the assembling and heat integration of the HIDiC scheme. Henceforward, the accomplishing of constraints in the HIDiC column is performed and the TAC is computed (Fig. 5). As it was explained before, the best individuals of each generation is selected by BUMDA algorithm to produce the next population. So the fitness function is continuously improved.  \nThe factors used to perform the penalization were tuned to take into account the variation of the fitness function and the computing time. The values for these factors were given in the previous study.  \nThe design-optimization process takes place by means of the interface: Excel ${ }^{\\oplus}$-Matlab ${ }^{\\oplus}$-Aspen Plus ${ }^{\\oplus}$. In this strategy, Excel ${ }^{\\oplus}$ has two functions: 1 . performs as a database and 2 . links the BUMDA optimizer programmed in Matlab ${ }^{\\circledR}$ and the simulator Aspen Plus FORMULA_69 to evaluate the design variables and compute the fitness function. In this work, we used a population of 50 individuals and 3000 function evaluations.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:47:56",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs using the level-based theorem to establish bounds on runtime?",
      "topics": [
        "bounds"
      ],
      "answer": "The algorithmic approach leverages the level-based theorem to provide an upper bound on the expected runtime for an Estimation of Distribution Algorithm to find optimal solutions. It does this by partitioning the search space into levels $A_{1}, \\ldots, A_{m+1}$ and establishing conditions (C1, C2, C3) that, when satisfied, guarantee $\\mathbf{E}[T] \\leq \\frac{2}{c \\varepsilon}\\left(m \\lambda(1+\\ln (1+c \\lambda))+\\sum_{j=1}^{m} \\frac{1}{z_{j}}\\right)$, where $T$ is the first time step that optimal solutions appear, $\\lambda$ is the population size, $z_j$ represents the probability of creating an individual at level $j+1$, and $\\delta$, $\\gamma_0$, $\\varepsilon$, and $c$ are parameters influencing the probabilistic conditions and population size requirements.",
      "chunk_id": 4529,
      "paper_id": "Novel Absorber Based on Pixelated Frequency Selective Surface Using Estimation of Distribution Algor",
      "paper_title": "Novel Absorber Based on Pixelated Frequency Selective Surface Using Estimation of Distribution Algorithm",
      "paper_year": "2015",
      "chunk_content": "The level-based theorem assumes that the search space has been partitioned into a sequence of levels $A_{1}, \\ldots, A_{m+1}$, such that the last level contains all the search points that are considered optimal solutions to the problem. If it can be shown that the distribution $D\\left(P_{t}\\right)$ is biased towards higher levels in a way that will be made precise below, the theorem provides upper bounds on the expected time to obtain  \nsolutions in the final level $A_{m+1}$. To simplify the writing, we use $A_{j}^{+}$to denote all levels after $A_{j}$ in the sequence, or $A_{j}^{+}:=\\cup_{i=j+1}^{m+1} A_{i}$.  \nTheorem 1. Given a partition $\\left(A_{1}, \\ldots, A_{m+1}\\right)$ of $\\mathcal{X}$, define $T:=\\min \\left\\{t \\lambda\\left|\\left|P_{t} \\cap A_{m+1}\\right|>0\\right\\}\\right.$ to be the first point in time that elements of $A_{m+1}$ appear in $P_{t}$ of Algorithm 2. If there exist parameters $z_{1}, \\ldots, z_{m}, z_{*} \\in(0,1], \\delta>0$, a constant $\\gamma_{0} \\in(0,1)$ and a function $z_{0}:\\left(0, \\gamma_{0}\\right) \\rightarrow \\mathbb{R}$ such that for all $j \\in[m], P \\in \\mathcal{X}^{\\lambda}, y \\sim D(P)$ and $\\gamma \\in\\left(0, \\gamma_{0}\\right)$ we have\n(C1) $\\operatorname{Pr}\\left(y \\in A_{j}^{+} \\mid\\left|P \\cap A_{j-1}^{+}\\right| \\geq \\gamma_{0} \\lambda\\right) \\geq z_{j} \\geq z_{*}$\n(C2) $\\operatorname{Pr}\\left(y \\in A_{j}^{+} \\mid\\left|P \\cap A_{j-1}^{+}\\right| \\geq \\gamma_{0} \\lambda,\\left|P \\cap A_{j}^{+}\\right| \\geq \\gamma \\lambda\\right)$\n$\\geq z_{0}(\\gamma) \\geq(1+\\delta) \\gamma$\n(C3) $\\lambda \\geq \\frac{2}{n} \\ln \\left(\\frac{16 m}{a \\varepsilon z_{*}}\\right)$ with $a=\\frac{\\delta^{2} \\gamma_{0}}{2(1+\\delta)}$,\n$\\varepsilon=\\min (\\delta / 2,1 / 2)$ and $c=\\varepsilon^{4} / 24$\nthen $\\mathbf{E}[T] \\leq \\frac{2}{c \\varepsilon}\\left(m \\lambda(1+\\ln (1+c \\lambda))+\\sum_{j=1}^{m} \\frac{1}{z_{j}}\\right)$\nInformally, the two first conditions require a relationship between $P$ and the distribution $D(P)$. In condition (C1), the theorem demands a certain probability $z_{j}$ of creating an individual at level $j+1$ when some fixed portion $\\gamma_{0}$ of the population is already at level $j$ (or higher). Condition (C2) requires that in the fixed portion, the number of individuals at levels strictly higher than $j$ (if those exist) tends to increase, e.g. by a multiplicative factor of $1+\\delta$. The last condition (C3) requires a sufficiently large population size. When all the conditions are satisfied, an upper bound on the expected runtime (defined in terms of sampled/evaluated solutions) of the algorithm to reach FORMULA_90 is guaranteed.",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:47:58",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of MIMIC (Mutual Information Maximization for input clustering) estimate the probability distribution for generating new solutions, and what limitation arises from its approach according to the text?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "MIMIC",
        "Probability Distribution",
        "Greedy Algorithm"
      ],
      "answer": "MIMIC, an EDA focusing on bivariate dependency, uses a chain model of probability distribution to estimate pairwise conditional probabilities. It then samples these probabilities to generate the next set of solutions. However, the text states that MIMIC deploys a greedy algorithm to search for the best pairwise interactions, which leads to an approximately inaccurate probability density function.",
      "chunk_id": 7518,
      "paper_id": "Hybrid sampling on mutual information entropy-based clustering ensembles for optimizations",
      "paper_title": "Hybrid sampling on mutual information entropy-based clustering ensembles for optimizations",
      "paper_year": "2010",
      "chunk_content": "Estimation of Distribution Algorithm (EDA) is a branch of evolutionary algorithms where classical genetic operators are replaced by the estimation of a probabilistic model and its simulation in order to generate the next population. Unlike GAs, there are neither crossover nor mutation operators in EDAs. Instead, the new population of individuals is sampled from a probability distribution which is estimated from a database formed by individuals of the former generations. EDAs have been proven to be better suited to some applications than GAs, while achieving competitive and robust results in the majority of tackled problems. Recently, EDAs have attracted more and more researchers'attention, and a wide variety of EDAs using different techniques to estimate and sample the probability distribution have been proposed to solve different kinds of optimization problems FORMULA_8.  \nIn these existing algorithms, a class of EDAs which focus on the bivariate dependency have been applied in the optimization of discrete problems. Mutual Information Maximization for input clustering (MIMIC) proposed by (de Bonet et al., 1997) [8] uses a chain model of probability distribution to estimate the pair wise conditional probabilities and sample them to generate next set of solutions. Since MIMIC deploys a greedy algorithm to search the  \n[^0]best pair wise, the probability density function is approximately not accurate. Combining Optimizers with Mutual Information Trees (COMIT) proposed by Baluja \\& Davies (1997, 1998) [5,6] also uses pair-wise interaction among variables. This model which uses the tree structure to represent the relationships of the variables is more general than the chain model used by MIMIC as two or more variables can have a common parent. But COMIT also has some limitations, since it requires all the nodes (variables) should have father nodes except the root node in the construction of the tree process. The Bivariate Marginal Distribution Algorithm (BMDA) proposed by (Pelikan \\& Muhlenbein, 1999) [22] can be seen as an extension to the COMIT model which uses Pearson's chi-square statistics to detect the interaction between two variables. As BMDA uses a forest structure to denote the relationships of the variables, the space complexity of BMDA is much higher than the aforementioned algorithms. For some benchmark problems, these algorithms perform well where pairwise interaction among variable exists.  \nHowever, there are two problems in the above algorithms. On the one hand, due to the complexity of the variables, it is too difficult and time-consuming to find an appropriate probability structure model, and the above EDAs require much time in the statistic learning process of the pairwise interaction of variables. It definitely reduces the performances of the algorithm and becomes worse while the problem size is increasing. On the other hand, the current probability structure model usually concentrates on the parameter learning, but ignoring the relationships of the variables. The probability structure model is often fixed while  \n[^0]:    E-mail addresses: fengwang@whu.edu.cn (F. Wang). yuany1@aston.ac.uk (Y. Yuan).  \nthe parameters evolving. As a result of this, it requires more time to get a better solution for this one-side evolution.",
      "question_type": "algorithmic",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:00",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the Q Learning-Based Estimation of Distribution Algorithm to update the probability value pi(t+1) for each Agenti, considering the selected action a'?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "Q-learning",
        "Probability update"
      ],
      "answer": "To update the probability value pi(t+1) in the Q Learning-Based Estimation of Distribution Algorithm, first determine the action a' for each Agenti. If the recorded state is 's' and the chosen action at time t-1 is 'a', calculate an immediate return using the formula: ri(t-1) = 1 if |pi(t) - gi(t)| < |pi(t-1) - gi(t-1)|, otherwise ri(t-1) = -1. Then, update the Q value using: Qi(s, a)  Qi(s, a) + [ri(t-1) +  max Qi(s', a') - Qi(s, a)]. Next, generate a random number i. If i  , randomly select an action a' with equal probability; otherwise, select a' = argmax Qi(s', a'). Finally, based on the selected action a', update pi(t+1) according to these rules: if action 1 is selected, pi(t+1) = pi(t); if action 2 is selected, pi(t+1) = 1 - [1 - pi(t)]; and if action 3 is selected, pi(t+1) = pi(t), where 0 <  < 1.",
      "chunk_id": 11430,
      "paper_id": "The Research of Q Learning-Based Estimation of Distribution Algorithm",
      "paper_title": "The Research of Q Learning-Based Estimation of Distribution Algorithm",
      "paper_year": "2011",
      "chunk_content": "(2) $\\mid g i(t)-b i(t)\\left|>\\theta_{\\text {diff }}\\right|$;\n(3) Otherwise does not meet the above criteria.  \nAgent, the first generation of action $t$ set includes the following probability update rules.\n(1) Action 1, the probability decreases\n$\\operatorname{Pi}(\\mathrm{t}+1)=\\beta \\mathrm{pi}(\\mathrm{t})$\n(2) Action 2, the probability increases\n$\\operatorname{Pi}(\\mathrm{t}+1)=1-\\beta[1-\\mathrm{pi}(\\mathrm{t})]$\n(3) Action 3, probability values remain unchanged\n$\\operatorname{Pi}(\\mathrm{t}+1)=\\mathrm{pi}(\\mathrm{t})$\nequation $(0)-(2), \\mathrm{i}=1,2, \\ldots, \\mathrm{~m}, \\beta(\\mathrm{o}<\\beta<1)$ to adjust the rate. Agenti interact with the environment, you can choose to perform the appropriate action to obtain the next generation of probability pi $(\\mathrm{t}+1)$. To store Agenti corresponding to a set of Q , the definition of matrix Qi: $\\mathrm{Q}_{i}=\\left[\\mathrm{Q}_{i}\\left(\\mathrm{~s}_{\\mathrm{i}}, \\mathrm{a}_{\\mathrm{k}}\\right)\\right]_{i>3}$  \nAlgorithm for each iteration, each Agenti $\\square$-greedy strategy selection in accordance with action, according to the rewards and status of their conversions update the corresponding Q values. If the first $\\mathrm{t}-1$ on behalf of the state when the environment Agenti s, choose action $\\alpha$ executed, the first generation of environmental state transition t to $\\mathrm{s}^{\\prime}$, then press the style update $\\mathrm{Qi}(\\mathrm{s}, \\mathrm{a})$ :\nQi (s , a) $\\leftarrow$ Qi (s , a) $+\\alpha\\left[r_{i}(t-1)+\\gamma \\max \\mathrm{Qi}\\left(\\mathrm{s}^{\\prime}, \\mathrm{a}^{\\prime}\\right)-\\mathrm{Qi}\\right.$ (s , a) $]$\n$\\mathrm{r}_{\\mathrm{i}}(\\mathrm{t}-1)=\\left\\{\\begin{array}{l}1 \\downarrow \\mathrm{pi}(\\mathrm{t})-\\mathrm{gi}(\\mathrm{t})|<| \\mathrm{pi}(\\mathrm{t}-1)-\\mathrm{gi}(\\mathrm{t}-1)| \\\\ -1, \\quad \\text { others }\\end{array}\\right\\}$\nWhere, ri (t-1) for the Agenti in t-1 obtained on behalf of an immediate return.  \nQ Learning-Based Estimation of Distribution Algorithm is given below the steps. Algorithm to replace the elitist strategy group to ensure the optimal solution search is not degraded.\nAlgorithm1: Q Learning-Based Estimation of Distribution AlgorithmInitialization Qi, $\\mathrm{i}=1,2, \\ldots, \\mathrm{~m}$ zero matrix, p (1) $==\\left(0.5,0.5, \\ldots, 0.5\\right), \\quad \\mathrm{t}=1$; While (termination condition is not satisfied algorithm) do  \nAccording to p (t) sampled individuals generate $\\mathrm{N}-1$, and $\\mathrm{t}-1$ together constitute the best individual on behalf of the current groups. New individual determination of i-bit value is: generate a random number $\\xi \\in[0,1]$, if $\\xi \\leq$ pi (t) is taken 1 , or take 0 ;\nCalculation of N individuals of fitness function and sorting;\nM -choose the best and the worst individuals, the frequency of statistics you get a value of gi (t) and bi (t), i $=1,2, \\ldots, \\mathrm{~m}$;\nFor (i-loci associated Agenti, $1 \\leq \\mathrm{i} \\leq \\mathrm{m}$ )\nRecorded before found their $\\mathrm{t}-1$ action on behalf of the state s and a , by gi (t) and bi (t) determine the current state s';  \nBy equation (5) calculated an immediate return, according to equation (3.14) update Qi (s, a);\nGenerate random numbers $\\xi \\mathrm{i} \\in[0,1]$, if $\\xi \\mathrm{i} \\leq \\square$, Randomly selected with equal probability of action a ', otherwise select\n$\\mathrm{a}^{\\prime}=\\operatorname{argmax} \\mathrm{Qi}\\left(\\mathrm{s}^{\\prime}, \\mathrm{a}^{\\prime}\\right)$;\nAccording to equation (0) - (2) and the action a 'corresponds to the formula. Calculate the new probability value pi $(\\mathrm{t}+1)$;\nEnd\nFORMULA_45;\nEnd\nC Improvement Strategies",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:03",
      "generation_style": "practical_application"
    },
    {
      "question": "How is the computational complexity of the specific QIEA-PSA algorithm analyzed, particularly considering the nested loops and the RepairGreedy procedure within the main 'while' loop that iterates until MaxIterations is reached?",
      "topics": [
        "algorithm"
      ],
      "answer": "The QIEA-PSA algorithm's computational complexity is influenced by the nested 'for' loops (lines 10-17) which iterate from 0 to \\(n{j}\\) a total of \\(n{j}^2\\) times. Inside these loops, the RepairGreedy procedure is called (line 13) along with the evaluation of \\(P(s)\\) (line 15), whose complexity is not specified in the provided procedure. Furthermore, the algorithm includes ImproveLocal and RandImproveLocal procedures (line 18) for \\(j \\in \\{1, \\ldots, n/2\\}\\) and \\(j \\in \\{n/2, \\ldots, n\\}\\) respectively, adding to the overall complexity. The 'while' loop (line 9) runs until \\(t < \\text{MaxIterations}\\), thus the overall complexity is at least \\(O(\\text{MaxIterations} * n{j}^2 * (\\text{Complexity(RepairGreedy)} + \\text{Complexity(Evaluation)} + \\text{Complexity(ImproveLocal)} + \\text{Complexity(RandImproveLocal)}))\\).",
      "chunk_id": 4555,
      "paper_id": "Solving the 01 Quadratic Knapsack Problem with a competitive Quantum Inspired Evolutionary Algorithm",
      "paper_title": "Solving the 0-1 Quadratic Knapsack Problem with a competitive Quantum Inspired Evolutionary Algorithm",
      "paper_year": "2015",
      "chunk_content": "```\nProcedure QIEA-PSA\n1 Initialize(Nsortorder, Wlambda)\n2 SolveGreedy(GSolution), MultipleSortGreedy(GreedyOrders, Nsortorder)\n3 \\(t \\leftarrow 0, C{\\text {improve }} \\leftarrow C, b \\leftarrow\\) GSolution, we \\(\\leftarrow\\) GSolution, \\(\\mathrm{b} \\in \\leftarrow 0\\)\n4 InitializeGreedy ( \\(q{\\mathrm{j}}^{\\mathrm{t}}\\) GreedyOrders) for each \\(j \\in\\{1, \\ldots, n\\}\\)\n5 InitializeGreedy ( bqbit, GreedyOrders)\n6 Make \\(P(t)\\) from \\(Q(t)\\)\n7 RepairGreedy ( \\(P(t)\\), GreedyOrders)\n8 copy \\(P(t)\\) to \\(B(t)\\)\n9 while ( \\(t<\\) MaxIterations) \\{\n10 for \\(r\\) from 0 to \\(n{j}\\), do\n11 for \\(s\\) from 0 to \\(n{j}\\) do\n12 Make \\(P(s)\\) from \\(Q(t)\\)\n13 RepairGreedy ( \\(P(s)\\), GreedyOrders)\n14 for each \\(\\mathrm{j} \\in\\{1, \\ldots, \\mathrm{n}\\}\\) if (HamDistance( \\(\\left.\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}, \\mathrm{b}\\right)<2\\) ) Mutate( \\(\\left.\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\right)\\)\n15 Evaluate \\(P(s)\\)\n16 for each \\(\\mathrm{j} \\in\\{1, \\ldots, \\mathrm{n}\\}\\) if \\(\\left(\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\right.\\) better than \\(\\left.\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\right)\\) then \\(\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}} \\leftarrow \\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\)\n\\(\\} / / \\) for s//\n\\(18 \\quad\\) for \\(\\mathrm{j} \\in\\{1, \\ldots, \\mathrm{n} / 2\\}\\) ImproveLocal \\(\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}} ;\\) for \\(\\mathrm{j} \\in\\{\\mathrm{n} / 2, \\ldots, \\mathrm{n}\\}\\) RandImproveLocal \\(\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\)\n19 for each \\(\\mathrm{j} \\in\\{1, \\ldots, \\mathrm{n}\\}\\) if \\(\\left(\\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\right.\\) is better than \\(\\left.\\mathrm{b}{\\mathrm{j}}^{\\mathrm{s}}\\right)\\) then \\(\\mathrm{b}{\\mathrm{j}}^{\\mathrm{s}} \\leftarrow \\mathrm{p}{\\mathrm{j}}^{\\mathrm{s}}\\)\n20 for each \\(\\mathrm{j} \\in\\{1, \\ldots, \\mathrm{n}\\}\\) if \\(\\left(\\mathrm{b}{\\mathrm{j}}^{\\mathrm{s}}\\right.\\) is better than \\(\\mathrm{b})\\) then \\(\\mathrm{b} \\leftarrow \\mathrm{b}{\\mathrm{j}}^{\\mathrm{s}}, \\mathrm{bqbit} \\leftarrow \\mathrm{q}_{\\mathrm{j}}^{\\mathrm{s}}\\)",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:06",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "When using the improved MIMIC algorithm for the ATM production line, what is the purpose of decimal encoding, and how does it represent a solution for a problem with 3 jobs and 2 stages?",
      "topics": [
        "encoding"
      ],
      "answer": "In the improved MIMIC algorithm, decimal encoding is used because it is considered more appropriate for this program. For a problem with 3 jobs and 2 stages, an individual such as [[2,1,3],[1,2,3]] represents a processing order where, at the first stage, job 2 is processed first, followed by job 1, and then job 3. At the second stage, job 1 is processed first, followed by job 2, and then job 3.",
      "chunk_id": 4629,
      "paper_id": "Solving Multi-Objective Semiconductor Assembly and Test Manufacturing Scheduling Problem Based on Estimation of Distribution Algorithm",
      "paper_title": "Solving Multi-Objective Semiconductor Assembly and Test Manufacturing Scheduling Problem Based on Estimation of Distribution Algorithm",
      "paper_year": "2015",
      "chunk_content": "In consideration of specificity of the ATM production line, the operation of multi-objective EDA based on classification has its own specificity. This paper uses the improved MIMIC algorithm $[7,8]$, one of the EDA, to simulate.  \n1) The encoding of algorithm should use decimal encoding which is more appropriate for this program, for example, for the problem with 3 jobs and 2 stages, individual $[[2,1,3],[1$, $2,3]]$ is a processing order and a solution which represents that at the first stage job 2 is processed first, next is job 1 , and job 3 is the last job to be processed while at the second stage job 1 is processed first, next is job 2 , and job 3 is the last job to be processed. For the parallel machine at each stage, we will select them according to some rules which derived from the objective we tend to. To decode a sequence is to assign the jobs to the machines at each stage so as to form a feasible schedule. For the ATM schedule problem, the decoding stage is to decide the jobs order and the machines assignment. Initial population of individuals is the sequence of each job at each stage and there is a chain dependency between them as shown in figure 2. For each stage, combined with the actual production, the algorithm should add some certain priori rules to select the machine, such as first come, first processing (FCFS) precedence rules. For another, in order to make the tardiness job zero, we should select the machine processing time of the corresponding parallel machine as early as possible.\n[IMAGE1]  \nFig. 2. An example of bivariate chain dependency\n2) The initialization of populations samples according to the uniform distribution probability matrix $L_{u} \\pi_{w}$. To avoid repetitive sampling, when taken to a job, it is about to set the rest of the elements in the column or row to zero, and then let the matrix normalize. Each individual in the population is then calculated adaptation value which decides $M$ priori individuals would be used to build jobs distribution matrix $C_{u} \\pi_{u}$ according to the number of two adjacent of each job. What need points out is that there is a matrix $C_{u} \\pi_{u}$ at each stage.  \nAmong them, $C_{i j}$ means the number of job $i$ followed job $j$. It's impossible that job $i$ will follow behind itself, so $C_{i j}=0$ if and only if $i=j$.  \nFORMULA_63",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:07",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "When implementing AffEDA and ECGA, how does the time spent in the first generation relate to the complexity of the models learned, and what programming considerations should be taken into account to optimize the sampling process?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "AffEDA",
        "ECGA",
        "algorithmic steps",
        "programming considerations"
      ],
      "answer": "The time spent in the first generation for AffEDA and ECGA is influenced by the complexity of the models they learn. AffEDA's more complex models could be more costly to sample than the models learned by ECGA. To optimize the sampling process, a developer should consider that the total time spent, including both learning and sampling, gives a wider perspective of the differences between the algorithms. The code should account for the fact that AffEDA, while constructing more accurate models in less time, may require more efficient sampling techniques to offset the cost of its complex models, especially when the population size is below a critical value, potentially leading to spurious correlations.",
      "chunk_id": 7554,
      "paper_id": "Learning Factorizations in Estimation of Distribution Algorithms Using Affinity Propagation",
      "paper_title": "Learning Factorizations in Estimation of Distribution Algorithms Using Affinity Propagation",
      "paper_year": "2010",
      "chunk_content": "We investigate in detail the differences between ECGA and AffEDA by looking at the accuracy of the structures they learn and the time spent to learn these structures. For additively decomposable functions, it has been shown that an EDA that uses the perfect structure of the model (i.e., the factorized distribution algorithm) can efficiently solve the function. The efficiency of EDAs that do structural learning of the model is also linked to their ability to recover the problem structure.  \nFor a number of additive functions, and for different population sizes, we compute how many of the original interactions of the problem are captured in the structures learned by AffEDA and ECGA. We also compute how many of other structural dependencies are learned. The first class of dependencies we call \"correct\" and the second  \n[IMAGE7]  \nFigure 8: Number of correct and spurious edges learned in the first generation of AffEDA and ECGA when the population size is increased for functions: (a) $f_{\\text {deceptive } 3}^{6}$ (x), (b) $f_{\\text {deceptive } 4}^{4}(\\mathbf{x})$, and (c) $f_{\\text {deceptive } 5}^{3}(\\mathbf{x})$\nclass we call \"spurious.\" We constrain our analysis to the models learned in the first generation because the algorithms can take different number of generations, making it difficult to analyze and visualize the information of the models learned at different generations.  \nFigure 8 shows the number of correct and spurious edges learned in the first generation of AffEDA and ECGA when the population size is increased from $N=4,800$ to $N=129,600$ for three functions, (a) $f_{\\text {deceptive } 3}^{6}(\\mathbf{x})$, (b) $f_{\\text {deceptive } 4}^{4}(\\mathbf{x})$, and (c) $f_{\\text {deceptive } 5}^{3}(\\mathbf{x})$. The results are the average of 30 independent experiments for each of the functions.  \nIt can be observed that from a high enough value of the population size, both algorithms are able to learn a perfect model of the structure. However, ECGA needs a higher population size for all the problems. The difference is remarkable considering that the population size is increased by 4,800 in each step. There are also differences in the behavior of both algorithms when confronted with a small population size. In these cases, AffEDA learns a high number of spurious edges and ECGA learns very few dependencies. As the population size is incremented, both algorithms move to a model with all correct interactions and without spurious correlations.  \nWe also investigate the time spent by the algorithms in the first generation for the different population sizes. We decided to compute the total time spent in the first generation and not only the time spent by the learning step. This decision was due to the fact that the more complex models learned by AffEDA could be more costly to sample than those learned by ECGA. Therefore, the total time gives a wider perspective of the differences determined by using the two learning algorithms.  \nFigure 9 shows the time spent in the first generation of AffEDA and ECGA when the population size is increased for three functions, (a) $f_{\\text {deceptive } 3}^{6}(\\mathbf{x})$, (b) $f_{\\text {deceptive }}^{4}(\\mathbf{x})$, and (c) $f_{\\text {deceptive } 5}^{3}(\\mathbf{x})$. It can be seen that the time required by AffEDA is less than that of ECGA in all the cases.  \nThe results presented in this section for functions $f_{\\text {deceptive } 3}^{6}(\\mathbf{x}), f_{\\text {deceptive }}^{4}(\\mathbf{x})$, and $f_{\\text {deceptive } 5}^{3}(\\mathbf{x})$ show that the learning algorithm used by AffEDA is able to construct more accurate models than ECGA in less time. The experiments also offer some clues that could explain the premature convergence of AffEDA for other decomposable functions when the population size is below the critical value. We hypothesize that in these cases, the models learned by AffEDA may contain a high number of spurious correlations, misleading the search away from the promising areas.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:10",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the admissible interval, defined by \\(k_{\\min}\\) and \\(k_{\\max}\\), be used as a safeguard in Estimation of Distribution Algorithms (EDAs) that employ an adaptive variance scaling (AVS) approach?",
      "topics": [
        "search"
      ],
      "answer": "In EDAs utilizing adaptive variance scaling (AVS), the admissible interval \\(\\langle k_{\\min }, k_{\\max }\\)\\) serves as a safeguard when the trigger mechanism, responsible for determining whether the population is on a slope or in a valley, makes incorrect decisions. If the trigger incorrectly identifies the population's location, the scaling factor \\(k\\) can be constrained to remain within the \\(\\langle k_{\\min }, k_{\\max }\\)\\) range, preventing excessively large or small variance scaling that could lead to premature convergence or divergence. Specifically, on a slope, the scaling factor can be set to at least \\(k_{\\min }\\), and in a valley, it can be set at most to \\(k_{\\max }\\).",
      "chunk_id": 5975,
      "paper_id": "Preventing Premature Convergence in a Simple EDA Via Global Step Size Setting",
      "paper_title": "Preventing Premature Convergence in a Simple EDA Via Global Step Size Setting",
      "paper_year": "2008",
      "chunk_content": "The adaptive variance scaling approach (AVS) presented in [10] and [11] should work even for the isotropic distributions used in this article. Since it is a dynamic scheme for setting the $k$, it needn't be limited to admissible values of $k$. For the algorithm it is often profitable to set $k>k_{\\max }$ when on slope, or to set $k<k_{\\min }$ when in the valley which ensures faster traversal of slopes and faster convergence to the optimum, respectively. On the other hand, AVS alone is an iterative update scheme and it can take several generations to switch the scaling from slope-style to valley-style or vice versa. That is the reason behind the triggers introduced in [10] and [11] which should decide if the population is on the slope or in the valley and trigger the AVS only on the slope; in the valley, the ML estimate of $\\sigma$ is used without scaling. The right behavior of such an algorithm is largely determined by the ability of the trigger to decide correctly  \nwhether to trigger the scaling. The results of this article can thus be useful for these algorithms in two ways: (1) if the trigger is good, the scaling factor can be set to at least $k_{\\min }$ on the slope, and at most to $k_{\\max }$ in the valley, or (2) if the trigger makes mistakes, the algorithm can use the admissible interval of $\\left\\langle k_{\\min }, k_{\\max }\\right)$ as a safeguard.\nThis article aimed at simple way of preventing premature convergence of a simple EDA. The variance of the distribution estimated from the selected data is increased by the factor (or global step size) $k$ each generation, artificially keeping the sufficient diversity in the population.  \nRecent works have shown that when Gaussian distribution is used, a constant value of $k$ which would ensure a reasonable behaviour of the algorithm on the slopes and in the valleys of the fitness function exists only for low-dimensional spaces.  \nThe situation is much better when isotropic distribution with Gaussian or Cauchy norms is used. Both of these two distributions ensure the existence of the admissible interval for $k$ for a broad range of selection proportions $\\tau$ and search space dimensionalities. Moreover, the ratio $k_{\\max } / k_{\\min }$ stays almost the same for the isotropic distributions, with Cauchy distribution giving larger margin.  \nCompiling a practically appliable heuristic for setting the value of $k$, building a real working optimization algorithm based on these principles, and its comparison with other scaling techniques remain as the future work. It would be also appealing to explore this technique in combination with other selection schemes different from the truncation selection.\nThe project was supported by the Ministry of Education, Youth and Sport of the Czech Republic with the grant No. MSM6840770012 entitled \"Transdisciplinary Research in Biomedical Engineering II\".",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:12",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in integrated continuous casting-hot rolling production scheduling, considering the limitations of individual scheduling methods?",
      "topics": [
        "optimization"
      ],
      "answer": "The overall purpose is to optimize the integrated production scheduling of continuous casting and hot rolling by addressing the limitations of disintegrative scheduling approaches. Traditional methods often model continuous casting scheduling as a mixed-integer linear programming (MILP) problem solved by heuristic methods or evolutionary algorithms, while hot rolling scheduling is modeled via traveling salesman problem (TSP) or vehicle routing problem (VRP) and solved by heuristics. The integrated approach aims to improve energy saving and efficiency increase of production by considering the linkage modes between continuous casting and hot rolling, such as direct hot charging rolling (DHCR), hot charge rolling (HCR), and cold charging rolling (CCR).",
      "chunk_id": 2243,
      "paper_id": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_title": "A bi-level optimization method for integrated production scheduling between continuous casting and hot rolling processes",
      "paper_year": "2022",
      "chunk_content": "Continuous casting-hot rolling (CC-HR) section is the key component in a steel manufacturing system, which includes CC, HR, reheating stage (as shown in Figure 1). In the CC stage, high-temperature molten steel is casted into slabs after steelmaking, the basic production unit is a cast (molten steel continuous casted in a tundish). Then the output slabs from CC stage are transported to reheating furnaces, soaking pit, or slab yard, which results in three linkage modes between CC and HR respectively, namely direct hot charging rolling (DHCR), hot charge rolling (HCR), and cold charging rolling (CCR). No matter which linkage mode is selected, each slab needs to be heated to the rolling temperature in the reheating furnace before HR. In the HR stage, the slabs are rolled into coils. The basic production unit in the HR stage is a rolling unit (slabs continuously rolled between replacement of two adjacent work rollers).  \nTo select appropriate linkage modes between CC and HR can improve production efficiency. The most ideal scheme is to adopt DHCR linkage mode for all slabs, but it may exceed the heating capacity of the reheating furnace and destroy the matching relationship. If all slabs adopt CCR linkage mode, it will increase energy cost because the CCR linkage mode slab need more heating time. The integrated production scheduling mainly includes two parts: one is the optimal CC-HR production planning matching based the selection of linkage mode, and the other one is the optimal reheating furnace  \n[^0]scheduling. Therefore, the integrated production scheduling of CC and HR is of great significance to the energy saving and efficiency increase of production.  \nIn past decades, most practitioners studied scheduling problems across CC to HR stages in a disintegrative way because of their significant difference in production mode. In the CC stage, most studies focused on CC scheduling problems related with the steelmaking process, which were modelled via mixed-integer linear programming (MILP) problem and solved it by heuristic methods or evolutionary algorithms[1-3]. In HR stage, most studies mainly focus on seeking optimal sequence of slabs and minimizing the technological change of slabs. The HR scheduling problems were commonly modelled via traveling salesman problem (TSP), vehicle routing problem (VRP) and their variants, and were commonly solved by heuristic methods[4]. In reheating furnace stage, related works were devoting to solve the machine scheduling problem minimizing the residence time of slabs in reheating furnaces[5-7].  \nAs the integrated production scheduling of CC-HR becoming more and more important, some scholars moved attentions to the IPSP-CCHR. Zhu et al. [8] established a integrated scheduling model including steelmaking, CC, and HR and proposed Lagrangian relaxation-based algorithm to solve it. Mattik et al. [9] addressed the joint scheduling of continuous caster and hot strip mill processes by formulating a MILP model based on the block planning principle. Pan et al. [10] proposed a novel modified extremal optimization algorithm combining an exact mathematical programming on the CC stage and a heuristic algorithm on the HR stage. Tan et al. [11] studied the scheduling problem containing CC, reheating, and HR processes by modeling it as a combination of a CC-HR scheduling subproblem and an reheating scheduling subproblem, then developed a hybrid MIP/CP algorithm to solve each subproblem based on Benders decomposition strategy. Wang et al. [12] proposed a two-stage optimization algorithm combined a genetic algorithm and a linear programming to solve the integrated scheduling problem of steelmaking, CC, and HR aiming at minimizing the energy consumption.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:14",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of updating the population in step 9, denoted as \"$\\mathbf{p o p}^{t+1}=$ concate($\\mathbf{p o p}_{\\text{master}}^{t}, \\mathbf{p o p}_{\\text{part}}^{t}, by=\\text{rows}$)\", contribute to the exploration and exploitation balance within the search process, considering that $\\mathbf{p op}_{\\text{master}}^{t}$ and $\\mathbf{p op}_{\\text{part}}^{t}$ are derived from different selection and sampling procedures?",
      "topics": [
        "algorithm"
      ],
      "answer": "The algorithmic mechanism of updating the population, $\\mathbf{p op}^{t+1}$, by concatenating $\\mathbf{p op}_{\\text{master}}^{t}$ and $\\mathbf{p op}_{\\text{part}}^{t}$ directly impacts the exploration-exploitation balance in this EDA. Specifically, $\\mathbf{p op}_{\\text{master}}^{t}$ is derived from the 'index = sort($\\mathbf{fit}, by = ascending, sele = ms$)' operation, selecting the best $ms$ individuals from the current population $\\mathbf{p op}^{t}$ based on their fitness values, fit. This enforces exploitation by preserving high-quality solutions. Conversely, $\\mathbf{p op}_{\\text{part}}^{t}$ comprises $m-ms$ individuals sampled from a probability vector $\\mathbf{p}^{t}$, which is generated using the calculated mean $\\mu^{t}$ and standard deviation $\\sigma^{t}$ of $\\mathbf{p op}_{\\text{master}}^{t}$. This sampling introduces exploration by generating new individuals based on the distribution learned from the elite population but allowing for variation. The concatenation, 'concate($\\mathbf{p o p}_{\\text{master}}^{t}, \\mathbf{p o p}_{\\text{part}}^{t}, by=\\text{rows}$)', combines the exploited knowledge from $\\mathbf{p op}_{\\text{master}}^{t}$ with the explorative samples in $\\mathbf{p op}_{\\text{part}}^{t}$ to form the next generation, $\\mathbf{p op}^{t+1}$, maintaining a balance between intensifying the search around promising regions and exploring new areas of the search space.",
      "chunk_id": 9718,
      "paper_id": "Local Parameter Optimization of LSSVM for Industrial Soft Sensing With Big Data and Cloud Implementation",
      "paper_title": "Local Parameter Optimization of LSSVM for Industrial Soft Sensing With Big Data and Cloud Implementation",
      "paper_year": "2020",
      "chunk_content": "1: Generate $m \\times n$ Initial population $\\mathbf{p o p}^{t}=\\mathbf{X}^{\\min }+$ rand $*\\left(\\mathbf{X}^{\\max }-\\mathbf{X}^{\\min }\\right)$\n2: For $t=1$ : maxiter  \n1) $\\mathbf{f i t}=\\operatorname{calobj}\\left(\\mathbf{p o p}^{t}\\right)($ size : $m \\times 1)$;\n2) index $=$ sort $(\\mathbf{f i t}, b y=$ ascending, sele $=m s)$ (size : $m s \\times 1$ );\n3) $\\mathbf{X}_{\\text {best }}^{\\prime}=\\mathbf{p o p}^{t}($ index $[0])$, fit $_{\\text {best }}^{t}=\\mathbf{f i t}($ index $[0])$;\n4) $\\mathbf{p o p}_{\\text {master }}^{t}=\\mathbf{p o p}^{t}($ index $)($ size : $m s \\times n)$;\n5) calculate $\\mu^{t}$ and $\\sigma^{t}$ of $\\mathbf{p o p}_{\\text {master }}^{t}$ by (12), (13) $\\left(\\mu^{t}, \\sigma^{t}\\right.$ are $\\left.n \\times 1\\right)$;\n6) utilize $\\mu^{t}, \\sigma^{t}$ to update (11);\n7) generate $m-m s$ probability vector $\\mathbf{p}^{t}($ size : $1 \\times n)$;\n8) put all $\\mathbf{p}^{t}$ into updated (11), sample $m-m s$ individuals denoted by $\\mathbf{p o p}_{\\text {part }}^{t}($ size : $(m-m s) \\times n)$;\n9) $\\mathbf{p o p}^{t+1}=$ concate $\\left(\\mathbf{p o p}_{\\text {master }}^{t}, \\mathbf{p o p}_{\\text {part }}^{t}, b y=\\right.$ rows $)($ size : $m \\times n)$;\n10: Let $t+1$;\n11: End for;\n12: Output $\\mathbf{X}_{\\text {best }}^{t}$ and fit $_{\\text {best }}$.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:17",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using a Gaussian distribution model, how should practitioners determine the elite set size from which to build the probabilistic model, given a population size of PS and a selection rate of sr?",
      "topics": [
        "selection"
      ],
      "answer": "When using a simple Gaussian Estimation of Distribution Algorithm (GEDA), the elite set is formed by selecting the top [PS * sr] individuals from the population, where PS represents the population size and sr is the selection rate of elite individuals. This means that if PS is 100 and sr is 0.2, then [100 * 0.2] = 20 individuals are selected to form the elite set for that generation. These individuals are then used to estimate the parameters of the Gaussian distribution.",
      "chunk_id": 3871,
      "paper_id": "An Adaptive Evolutionary Multi-Objective Estimation of Distribution Algorithm and Its Application to Multi-UAV Path Planning",
      "paper_title": "An Adaptive Evolutionary Multi-Objective Estimation of Distribution Algorithm and Its Application to Multi-UAV Path Planning",
      "paper_year": "2023",
      "chunk_content": "Terrain concealment is primarily related to the altitude at which the UAV flies during actual flight. In this study, it is assumed that the safe flight altitude of the UAV is denoted as $h_{\\text {safe }}$, the maximum flight altitude is $h_{\\text {max }}$, and the terrain concealment index $f_{\\text {hide }}$ can be expressed as follows:  \n$$\nf_{\\text {hide }}=\\left\\{\\begin{array}{lc}\n\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left(h_{\\text {safe }}+h_{\\max }\\right) l_{i j}, & z_{i j}^{\\prime}<h_{\\text {safe }} \\\\\n\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left(2 h_{\\text {safe }}+h_{\\max }-z_{i j}^{\\prime}\\right) l_{i j}, & z_{i j}^{\\prime} \\geq h_{\\text {safe }}\n\\end{array}\\right.\n$$  \nwhere $z^{\\prime} i j=z i j-z_{D E M}, z_{i j}$ represents the altitude of a given path segment, and $z_{D E M}$ is the height value of the corresponding path segment in the digital map of the planning space. Furthermore, $l_{i j}$ denotes the distance cost of UAV $i$ on path segment $j$.\nWhen multiple UAVs are involved in a mission, they need to be at an appropriate, safe distance from each other to prevent collisions and to avoid exposing each other's positions. This enhances the safety of the UAVs working together on a mission. The spatial synergy performance of multiple UAVs can be expressed as the sum of the minimum distances between multiple UAV path points within $n$ path segments [25]. The spatial synergy index $f_{\\text {space }}$ can be expressed as follows:  \n$$\n\\begin{aligned}\nf_{\\text {space }} & =\\sum_{j=1}^{n} \\sum_{i=1}^{m^{\\prime}} f_{i j} \\\\\nf_{i j} & = \\begin{cases}0, & \\min d_{j}\\left(i, i_{\\text {nei }}\\right)>d_{\\text {safe }} \\\\\n\\left(\\frac{d_{\\text {safe }}}{\\min d_{j}\\left(i, i_{\\text {nei }}\\right)}\\right)^{4}, & \\min d_{j}\\left(i, i_{\\text {nei }}\\right) \\leq d_{\\text {safe }}\\end{cases}\n\\end{aligned}\n$$  \nwhere $\\min d_{j}\\left(i, i_{\\text {nei }}\\right)$ is the Euclidean distance between UAV $i$ and its closest untraversed UAV $i_{\\text {nei }}$ on path segment $j, m$ is the number of UAVs passing through path segment $j$, and $d$ is the minimum safe distance between two UAVs. As per Eq. 10, the lower the value of the spatial synergy index, the higher the spatial synergy between the UAVs.\nIn actual flight, UAVs are often subject to many constraints due to their own airframe performance. Specifically, during flight the UAV is mainly limited by the minimum straight flight distance $l_{\\max }$, the maximum turn angle $\\theta$, the maximum climb height $Z_{\\max }$ and the maximum total path length $L_{\\max }$. Therefore, combining the four optimization objectives proposed in the previous section, and taking the path $r$ as a variable, a multi-objective optimization model can be proposed\nas follows:  \n$$\n\\begin{aligned}\n& \\operatorname{minimize} F(x)=\\left(f_{d}(r), f_{i}(r), f_{\\text {hide }}(r), f_{\\text {space }}(r)\\right)^{T} \\\\\n& \\text { s.t. }\\left\\{\\begin{array}{l}\nl_{i j} \\leq l_{\\max } \\\\\n\\left\\|z_{i j}-z_{i(j+1)}\\right\\| \\leq Z_{\\max } \\\\\n\\arccos \\frac{\\alpha_{i} \\cdot \\alpha_{i-1}^{T}}{\\left\\|\\alpha_{i}\\right\\| \\cdot\\left\\|\\alpha_{i-1}\\right\\|} \\leq \\theta \\\\\n\\sum_{j=1}^{n}\\left|l_{i j}\\right| \\leq L_{\\max }\n\\end{array}\\right.\n\\end{aligned}\n$$  \nAssuming that the UAV path is composed of a series of path nodes,i.e. $r=\\left\\{X_{i} \\mid i=1,2, \\ldots, n+1\\right\\}$, then $\\alpha_{i}$ in the above equation is the vector composed of the path nodes $X_{i}$ and $X_{i+1}$.\nThe Estimation of Distribution Algorithm (EDA) is a technique that utilizes statistical methods to create a probability model from which new offspring are sampled to generate new solutions. It is a method that characterizes the distribution of solutions from a macroscopic perspective of the population. One of the probability models that can be used is the Gaussian distribution model, which has good applicability.  \nAssuming that the population size is $P S$, with individuals $x \\in R^{n}$, and the selection rate of elite individuals is $s r$, i.e., $[P S \\cdot s r]$ promising individuals are selected per generation to form the elite set, the simple Gaussian Estimation of Distribution Algorithm (GEDA) can be summarized in",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:19",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the multi-valued EDAs for maximizing $r$-valued fitness functions $f: \\{0 . . r-1\\}^{n} \\rightarrow \\mathbb{R}$, what is the significance of the 1-norm, denoted by $||p||_{1}$ for $p \\in \\mathbb{R}_{\\geq 0}^{n}$, in the context of these algorithms?",
      "topics": [
        "fitness"
      ],
      "answer": "The text defines $||p||_{1}$ as the sum of the entries of $p$, where $p$ is a vector in $\\mathbb{R}_{\\geq 0}^{n}$. While the text does not explicitly state its significance to the multi-valued EDAs, it establishes the notation for potentially representing probability distributions or weights associated with the $n$ variables in the $r$-valued fitness function's domain, where each variable can take values from $0$ to $r-1$. The 1-norm would then represent the total probability or weight.",
      "chunk_id": 2716,
      "paper_id": "Estimation-of-distribution algorithms for multi-valued decision variables",
      "paper_title": "Estimation-of-distribution algorithms for multi-valued decision variables",
      "paper_year": "2024",
      "chunk_content": "We denote by $\\mathbb{N}$ the set of all natural numbers, including 0 , and by $\\mathbb{R}$ the set of all real numbers. Additionally, for $a, b \\in \\mathbb{N}$, let $[a . . b]=[a, b] \\cap \\mathbb{N}$, and let $[a]=[1 . . a]$. When we say that a random process is a martingale and do not specify a filtration, then we mean that the process is a martingale with respect to its natural filtration. Further, for all $n \\in \\mathbb{N}_{\\geq 1}$ and $p \\in \\mathbb{R}_{\\geq 0}^{n}$, we denote the 1-norm of $p$, that is, the sum of the entries of $p$, by $\\|p\\|_{1}$. For a proposition $P$, we denote the Iverson bracket by $\\mathbb{1}\\{P\\}$, which is 1 if $P$ is true, and it is 0 otherwise.  \nLet $n \\in \\mathbb{N}_{\\geq 1}$ and $r \\in \\mathbb{N}_{\\geq 2}$. We consider the maximization of functions of the form $f:\\{0 . . r-1\\}^{n} \\rightarrow \\mathbb{R}$, which we call $r$-valued fitness functions. Whenever we mention an $r$-valued fitness function, we implicitly assume that its dimension $n$ and the cardinality $r$ of its domain are given. We call each $x \\in[0 . . r-1]^{n}$ an individual, and we call $f(x)$ the fitness of $x$.  \nWe say that a random variable $Y$ stochastically dominates another random variable $X$, not necessarily defined on the same probability space, denoted by $X \\preceq Y$, if and only if for all $\\lambda \\in \\mathbb{R}$, we have $\\operatorname{Pr}[X \\leq \\lambda] \\leq \\operatorname{Pr}[Y \\leq \\lambda]$.\nIn this section, we generalize the three common univariate EDAs for the binary decision variable to multi-valued decision variables. We do so in a manner that is consistent with the existing (empirical) literature on univariate EDAs [13,15]. We call our EDA variants multi-valued EDAs. To this end, we briefly discuss the binary case in Section 4.1 before presenting our framework in Section 4.2. In our presentation, we concentrate on the UMDA [37] and then briefly present the generalizations of the other two common univariate EDAs.  \nWe note that for classic evolutionary algorithms, multi-valued decision variables have been discussed to some extent [38-44]. Due to the very different working principles, we could not see how these results help in designing and analyzing multi-valued EDAs.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:21",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the treewidth, denoted as $\\omega(f)$, relate to the width, $w(f)$, and induced width, $w^{*}(f)$, of an additive fitness function $f(x_{1}, \\cdots, x_{n})$ with interaction graph $G_{f}$, in terms of variable interaction?",
      "topics": [
        "fitness",
        "treewidth",
        "interaction graph",
        "estimation of distribution algorithms"
      ],
      "answer": "The treewidth $\\omega(f)$ of an additive fitness function $f$ is defined directly as the treewidth of its interaction graph $G_{f}$. The width $w(f)$ and induced width $w^{*}(f)$ are defined respectively as the width and induced width of $G_{f}$ under a given ordering $\\pi$ of the variables. Therefore, while treewidth is an inherent property of the fitness function's interaction graph, width and induced width are dependent on the ordering of the variables, influencing the measure of variable interaction.",
      "chunk_id": 13102,
      "paper_id": "Space complexity of estimation of distribution algorithms",
      "paper_title": "Space complexity of estimation of distribution algorithms",
      "paper_year": "2005",
      "chunk_content": "[IMAGE1]  \nFigure 1: Examples of Tree Decompositions.  \nBased on the interaction graph, we can measure the degree of the variable interaction in an additive fitness function using the treewidth.\nDefinition 3.8. Let $f\\left(x_{1}, \\cdots, x_{n}\\right)$ be an additive fitness function with the interaction graph $G_{f}$.  \n1. The treewidth $\\omega(f)$ of $f$ is defined to be the treewidth of $G_{f}$.\n2. Given an ordering $\\pi$ of the variables, the width $w(f)$ and the induced width $w^{*}(f)$ are defined respectively to be the width and induced width of $G_{f}$ under FORMULA_114.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:23",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, specifically concerning the management and updating of the tree structure's nodes and their associated statistics?",
      "topics": [
        "control"
      ],
      "answer": "The EDA's code should implement a tree structure where each node is represented as a `Node` object, containing `stats`, `size`, and `level` attributes. The algorithm starts with a `root` node. The core loop iterates through a list of `leaf` nodes. For each `node`, the code samples solutions `node.size` times using `node.wstate`. Unique solutions are identified, and for each unique `sol`, a new `node_sol` is created with an updated `level` and `size`. Crucially, `node_sol.stats` must be updated based on `level_sol` before `node_sol` is added to the `leaf` list, and the original `node` is removed. This ensures proper management of the tree's growth and the propagation of updated statistics.",
      "chunk_id": 9519,
      "paper_id": "Quantum-Inspired Estimation Of Distribution Algorithm To Solve The Travelling Salesman Problem",
      "paper_title": "Quantum-Inspired Estimation Of Distribution Algorithm To Solve The Travelling Salesman Problem",
      "paper_year": "2021",
      "chunk_content": "0 : stats $\\leftarrow$ Statistics to sample $W$ state circuit\n0 : size $\\leftarrow$ Number of shots from the quantum circuit\n0 : level $\\leftarrow$ Level in the tree structure\n0 : wstate $\\leftarrow W$ state circuit with stats probabilities\n0 : end struct\n1: $\\operatorname{root} \\leftarrow \\operatorname{Node}($ stats $[0]$, size $=N$, level $=0)$\n2: leaf $\\leftarrow[$ root $]$\n3: for node in leaf do\n4: $\\quad$ sols $\\leftarrow$ Sample node.wstate node.size times\n5: for sol in unique(sols) do\n6: $\\quad$ level $_{\\text {sol }} \\leftarrow$ node.level +1\n7: $\\quad$ size $_{\\text {sol }} \\leftarrow$ Count samplings of sol in sols\n8: node $_{\\text {sol }} \\leftarrow$ Node $\\left(\\right.$ stats $\\left[\\right.$ level $\\left._{\\text {sol }}\\right]$, level $_{\\text {sol }}$, size $\\left._{\\text {sol }}\\right)$\n9: node $_{\\text {sol }}$.stats $\\leftarrow$ Update statistics for row level $_{\\text {sol }}$ given node $_{\\text {sol }}$\n10: $\\quad$ leaf.add $\\left(\\right.$ node $\\left._{\\text {sol }}\\right) \\leftarrow$ Add node to leaf nodes list\n11: end for\n12: leaf.remove(node) $\\leftarrow$ Remove node from leaf nodes list\n13: end for $=0$\nin the $|0\\rangle$ state,  \n$$\n\\begin{aligned}\n\\left|W_{n}\\right\\rangle & =\\frac{1}{\\sqrt{n}}(|10 \\ldots 00\\rangle+|01 \\ldots 00\\rangle+\\ldots .+ \\\\\n& +|00 \\ldots 10\\rangle+|00 \\ldots 01\\rangle\\rangle\n\\end{aligned}\n$$  \nThe general W state of Eq. (8) has been modified in order to be able to set different probabilities to the different qubits. Thus, we can apply this approach to sample solutions according to Eq. (4). The circuit building is described in Algorithm 3. The process is divided into two main parts: (i) probability redistribution, in which, the desired probabilities of the pure states that constitute the W state are translated to rotations in the qubit $Y$ axis with $R Y$ gates and controlled$R Y$ gates $(C R Y)$, and (ii) state reshuffling, to ensure that the number of qubits in the $|1\\rangle$ state is only one, with controlled-X gates $(C X)$ and $X$ axis rotation gates $(X)$.  \nAn example of a circuit of size $n=5$ in which all pure states have the same probabilities is shown in Fig. 2.  \nThe influence of noise in the W state circuit samplings is shown in Fig. 3. Panel (a) shows the histogram of the results obtained executing the quantum circuit in a quantum simulator without noise, while panel (b) shows the results obtained executing the circuit in a real quantum computer. Both experiments were run 1000 times with probabilities $\\left[\\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}\\right]$. Note that in Fig. 3(b) some not desired solutions are sampled with a small probability due to the quantum computer noise. Solutions must be filtered and the probability distribution  \n[IMAGE0]  \nFig. 1. Example of the quantum individuals sampling of size $n=3$. An initial matrix of statistics $\\boldsymbol{p}(\\boldsymbol{Q})$ is updated in each node depending on its parents samplings. In the leaf nodes, the final individuals are obtained. The algorithm samples $N$ individuals. Each node distributes its number of samples among its child nodes.",
      "question_type": "implementation focused",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:26",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of the proposed GPU-compatible parallel BOA (gBOA), how is the Bayesian Dirichlet (BD) metric calculation broken down to suit the GPU architecture?",
      "topics": [
        "design"
      ],
      "answer": "The BD metric calculations are divided into smaller problems in two steps. First, the calculation is broken down into \\(N\\) parts, where \\(N\\) is the total number of variables, with each part representing calculations for edges ending in the \\(i^{th}\\) variable. Each of these divisions is assigned to one thread block of CUDA. In the second step, the computation for each block is further broken down into smaller tasks, each assigned to a single thread inside that thread block.",
      "chunk_id": 6592,
      "paper_id": "Theoretical and Empirical Analysis of a GPU Based Parallel Bayesian Optimization Algorithm",
      "paper_title": "Theoretical and Empirical Analysis of a GPU based Parallel Bayesian Optimization Algorithm",
      "paper_year": "2009",
      "chunk_content": "We propose a GPU compatible parallel BOA (BOA on GPU or gBOA). In order to avoid the problems discussed above, we will have to further breakdown the calculation of BD metrics. While designing an algorithm for GPU, we must keep the following facts about the CUDA and GPU architecture into consideration:  \n1) GPU is good at dealing with 1000's of threads at the same time with each thread doing a very small part of the overall job.\n2) Use of shared memory and registers wherever possible.\n3) Coalescing global memory access wherever possible.\n4) Avoiding braches in the Threads of the same warp.\n5) Try to maximize occupancy. Occupancy can be maximized by choosing an appropriate value thread block size, shared memory size and number of registers used.\nIn the proposed approach, we divide the BD metric calculations into smaller problems in two distinct steps. In the first step we break down the BD metrics calculation in $N$ parts. Where, $N$ is the total number of variables and the $i^{\\text {th }}$ part\n[IMAGE4]  \nFig. 5. Host side controller of the proposed implementation.  \n[IMAGE5]  \nFig. 6. Bayesian Dirichlet (BD) Kernel.\nrepresents the calculations for edges ending in the $i^{t h}$ variable. Each division of this step is assigned to one thread block of CUDA. The first step is similar to the parallelization suggested by Jiri et al. [8]. In the second step, we further break the computation for each block into smaller tasks. Each of these tasks is then assigned to a single thread inside that thread block. Therefore, in our implementation the block number represents the variable (node) number that it processes, and within each block there are a number of threads that solve a very small part of the overall computation. Overall flow of the implementation is shown in Fig. 5. It is clear from the figure that FORMULA_29 kernel is launched once for each generation. BD kernel shown in Fig. 6, lies at the heart of gBOA. Therefore, the next section expounds on each part of the BD kernel in detail. Compliance to the SIMD architecture of GPU and the efficiency of memory usage is also discussed in detail.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:27",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when comparing AtRBMIEDA to other interactive evolutionary computation algorithms?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to demonstrate that AtRBMIEDA, which combines IEDA with an attention mechanism (AM) and Restricted Boltzmann Machine (RBM), achieves superior personalized search performance compared to AtRBM, traditional IEDA, RBM-assisted IGA (RBMIGA), and RBMIEDA without the attention mechanism. The evaluation focuses on metrics such as RMSE, HR, and MAP, showing AtRBMIEDA's improved accuracy in predicting user preferences and providing recommendations.",
      "chunk_id": 10215,
      "paper_id": "Enhanced Interactive Estimation of Distribution Algorithms with Attention Mechanism and Restricted Boltzmann Machine",
      "paper_title": "Enhanced Interactive Estimation of Distribution Algorithms with Attention Mechanism and Restricted Boltzmann Machine",
      "paper_year": "2020",
      "chunk_content": "In order to demonstrate the comprehensive performance of the proposed AtRBMIEDA, a user is randomly selected to participate in the interactive personalized search. The rated items of the user are sorted by the timestamp. The first $50 \\%$ of these items is built as a training dataset, of which the first $20 \\%$ is used as the initial historical interactions and the last\n$30 \\%$ is divided into 10 copies as new UGC for each iteration. The remaining $50 \\%$ of those is regarded as the feasible searching space for the personalized search. The AtRBM and AtRBMIEDA algorithms conduct the personalized search for the user, respectively. The experimental results in KindleStore are shown in Fig. 2.  \nAs can be seen from Figure 2, the HR and AP values of AtRBMIEDA have been greatly improved compared with AtRBM. Therefore, by combining IEDA, AtRBMIEDA is obviously superior to AtRBM for the personalized search.  \nFurthermore, AtRBMIEDA is compared with four IECs algorithms, such as traditional IEDA, RBM-assisted IGA (RBMIGA), RBMEDA [11], and RBMIEDA without AM (denoted as RBMIEDA). Each algorithm evolves 10 generations, and gives 10 predictions and recommendations for the current user. All the algorithms are independently run 10 times. The average results are shown in Table 3, and the best results are marked in bold.  \nIn Table 3, the results marked with  represent that the corresponding algorithm is significantly from the best result with confidence level 0.95 under the Mann-Whitney U test. IEDA does not have the RMSE values since no surrogate model is built to predict the ratings of items. The following observations can be obtained from Table 3.\n(1) RBMIGA generates new individuals in the IGA framework and uses the RBM-based surrogate model to estimate the individual fitness to guide the evolutionary optimization. Compared with RBMIGA, RBMEDA replaces IGA by IEDA to produce the suitable items with users preferences to get better searching results.\n(2) AtRBMIEDA achieves the best results in all of the datasets. For example, AtRBMIEDA achieves the best RMSE 1.421 in CDsandVinyl, which is $5.52 \\%$ lower than RBMIEDA. The HR and MAP values get the optimal values 0.00510 and 0.982 respectively, which is $10.15 \\%$ and $7.32 \\%$ higher than RBMIEDA. It indicates that integrating AM enhances the performance of extracting the user preferences of the RBMbased user preference model and improves the prediction and recommendation accuracy of AtRBMIEDA.  \nIn order to further demonstrate the performance of the proposed algorithm, each IECs algorithm iterates 10 times with 10 times of the rating prediction and item recommendations. The personalized searching processes of a user in KindleStore and CDsandVinyl are shown in Fig. 3 and Fig. 4 respectively.",
      "question_type": "evaluation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:29",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs for DAG task scheduling, how does the algorithmic mechanism of the relative position based probability model interact with the hybrid decoding mechanism to influence the exploration and exploitation balance?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The relative position based probability model, designed to describe the probability distribution of solutions, is initialized according to the DAG structure and heuristic solutions. By sampling this model, diverse and promising task processing permutations are produced, contributing to exploration. The hybrid decoding mechanism, which adjusts the produced permutations during the EDA-based search by choosing appropriate decoding methods according to the structure of the permutation, refines these permutations, thus contributing to exploitation. Furthermore, the problem-specific path relinking scheme, used in two search operators, enhances local intensification, which further contributes to exploitation. The interplay between these mechanisms aims to balance exploration of the search space with exploitation of promising solutions for the DAG task scheduling problem.",
      "chunk_id": 9487,
      "paper_id": "A path relinking enhanced estimation of distribution algorithm for direct acyclic graph task scheduling problem",
      "paper_title": "A path relinking enhanced estimation of distribution algorithm for direct acyclic graph task scheduling problem",
      "paper_year": "2021",
      "chunk_content": "In this paper, a path relinking enhanced EDA is designed for DAG-SP. The simulation results based on extensive benchmark datasets with different scales of tasks, processors as well as CCRs show that the tailored hybrid decoding mechanism and path relinking based local intensification are effective to improve the performance of EDA. Moreover, our proposed algorithm is superior to existing algorithms in solving DAG-SP. The main contributions of this work in designing the optimization algorithm are summarized as follows.  \n1. A hybrid decoding mechanism based on existing list heuristics is developed to adjust the produced permutations during the EDA-based search. With such a mechanism, appropriate decoding method can be chosen according to the structure of permutation.\n2. A relative position based probability model is designed to describe the probability distribution of solutions. In addition, the probability model is initialized according to the DAG structure and heuristic solutions. Via sampling such a model, diverse and promising task processing permutations can be produced.\n3. Two search operators based on problem-specific path relinking scheme are designed, and a path relinking enhanced local intensification procedure is presented. With the local intensification procedure, exploitation ability is enhanced.\nEfficient DAG task scheduling algorithm can uplift the performance of IoT, fog or cloud computing applications. Due to the wide application of cloud and fog computing in our daily life, such a solution has significant impact on the optimization of the quality of user experience [46,47]. In addition, appropriate task assignment solution gives rise to the resource balancing within multi-processors, multi-cores and multi virtual machines (VMs) within a single processor. Therefore, DAG task scheduling techniques such as our proposed algorithm can be well applied in the related areas.  \nFor the large and distributed cloud computing environment, it is essential to cut down the extra time generated by scheduling overhead, which results in a shorter execution time of the entire  \nTable 8\nComparative results on FFT DAGs.  \nTable 9\nComparative results on scientific workflow instances.\nprocess. Efficient DAG task scheduling algorithm plays an important part in distributed workflow task balancing [5], offering a good solution to the assignment of the tasks within the workflow to the processors.  \nSimilarly, resource consumption cost optimization within many-core processor is important because of the limited resource and high computation load of embedded systems [6]. Efficient DAG task scheduling algorithm is adopted to handle the task precedence constraints during the task scheduling process. In addition, DAG task scheduling algorithm increases the utilization of VMs and brings forth resource balancing in multi-vCPU VMs [7].  \nIn the future, we will study DAG-SP with different metrics and constraints by considering the uncertainty in computing system and applications. In addition, we will develop effective task scheduling algorithms by fusing the evolutionary computing and the problem-specific search knowledge. It is also interesting to apply the proposed algorithm for the real-world applications.\nChu-ge Wu: Data curation, Analysis, Methodology, Writing draft. Ling Wang: Conceptualization, Analysis, Methodology, Review, Funding acquisition. Jing-jing Wang: Conceptualization, Methodology, Funding acquisition.\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\nThis research is supported by the National Science Fund for Distinguished Young Scholars of China [No. 61525304], the National Natural Science Foundation of China [No. 61873328].",
      "question_type": "relationship",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:32",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to evolve neural networks using Gene Expression Programming (GEP-NN), how should practitioners determine the size of the tail region of a gene, given the head length and maximum arity of neurons?",
      "topics": [
        "crossover",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "To determine the tail length ($T_l$) in GEP-NN, practitioners should use the formula $T_{l}=(M A-1) \tImes H_{l}+1$, where $MA$ is the maximum arity (maximum number of inputs) of the neurons and $H_{l}$ is the head length. For example, if the head length is 2 and the maximum arity is 4, the tail length would be $(4-1) * 2 + 1 = 7$.",
      "chunk_id": 7681,
      "paper_id": "Toward an estimation of distribution algorithm for the evolution of artificial neural networks",
      "paper_title": "Toward an Estimation of Distribution Algorithm for the Evolution of Artificial Neural Networks",
      "paper_year": "2010",
      "chunk_content": "Gene Expression Programming for program trees contained a gene that listed functions and terminals. The gene was separated into two sections known as the head and tail regions (the former appears first in the gene). The tail consists of only terminals whereas the head contains functions and terminals. The tail region's length is defined by the length of the head region and the maximum 'arity' (number of parameters) of the functions. By defining the gene in this way any gene will represent a functionally correct program tree. The tail is long enough so in the case that the head consists only of functions of maximum arity there will be terminals to place as parameters to those functions. The opposing extreme is when the first portion of the head is a terminal. In that situation the output is equivalent to that terminal and the remaining elements of the gene are unused. Usually a gene will be somewhere between these two extremes.  \nIn order to evolve neural networks with a similar gene the functions and terminals are substituted for neurons and inputs and a third region of the gene is defined. Neurons can be imagined to be functions which perform a summation on a given number of inputs. Neurons with 2, 3, and 4 inputs are called D, T, Q respectively. The terminals are replaced by inputs. The third region added to the GEP gene is known as the weight domain and encodes the weights. GEP-NN used 10 weights randomly generated in the range $-2,2$. The elements of the weight domain are pointers to these 10 weights.  \nBefore an ANN can be evaluated it must be generated from its gene encoding. The generative process begins at the leftmost element in the gene and constructs a tree in a breadthfirst manner. The weights are then added in a breadth-first manner as well.  \nAn example gene could be:  \n$$\nT D i_{1} i_{2} i_{3} i_{4} i_{1} i_{2} i_{3} W_{1} W_{2} W_{3} W_{4} W_{5} W_{8} W_{9}\n$$  \nWhere $D, T$, and $Q$ are neurons with 2,3 , or 4 inputs (respectively). $i_{1}$ through $i_{4}$ are inputs to the network. Finally, $W_{1}$ through $W_{10}$ represent the weights.  \nWhich encodes the following ANN:\n[IMAGE0]  \nThis example gene has a head length of 2 . The tail size was calculated as: $T_{l}=(M A-1) \\cdot H_{l}+1=7$. Where $T_{l}$ is the tail length, $M A$ is the maximum arity (or max number of inputs), and $H_{l}$ is the head length. The length of the weight domain is $W_{l}=H_{l} \\cdot M A=8$.  \nMultiple genes can be used to generate a neural network, this is called a multigenic system. To combine multiple genes the networks are generated and those outputs are combined with an OR function. The OR function represented by a binary ANN has any number of inputs with a weight of 1 on each. Therefore, if one or more outputs 1 the output is 1 .  \nIn order to evolve these genes GEP uses a method involving crossover and mutation. This work did not use crossover and mutation, but replaced them with a probabilistic modelbuilding approach that maintains a probability distribution of the most promising solutions and samples this distribution to create new individuals.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:33",
      "generation_style": "practical_application"
    },
    {
      "question": "HEFT is presented as a scheduling heuristic, and multi-objective HEFT (MOHEFT) builds upon it. What algorithmic modifications are introduced in MOHEFT to address multi-objective DAG task scheduling problems, and how are the solutions sorted to form a Pareto set?",
      "topics": [
        "heuristic"
      ],
      "answer": "MOHEFT is designed as a general framework to provide a set of solutions for the decision maker when solving multi-objective Direct Acyclic Graph (DAG) task scheduling problems. New solutions generated by MOHEFT are sorted according to crowding distance. The best $K$ solutions, based on this crowding distance sorting, are then chosen as the Pareto set, representing a trade-off between different objectives. Fuzzy dominance can also be introduced to improve the performance of MOHEFT, which optimizes both makespan and cost index.",
      "chunk_id": 9451,
      "paper_id": "An evolutionary fuzzy scheduler for multi-objective resource allocation in fog computing",
      "paper_title": "An evolutionary fuzzy scheduler for multi-objective resource allocation in fog computing",
      "paper_year": "2021",
      "chunk_content": "To optimize the agreement index of the applications as well as to guarantee the robustness of our scheduling solution, we model the task offloading and scheduling problem as a multiobjective offline optimization problem and find out a fitness trade-off between performance index and the robustness. The remainder of the paper is organized as follows: Section 2 reviews the related work. Section 3 provides the basic concepts on multiobjective optimization problem, fuzzy theory and the problem statement including system and application model, mathematic model and the robustness analysis. Then, the proposed algorithm is detailed described in Section 4. In Section 5, the numerical studies are provided to demonstrate the effectiveness of our proposed algorithm. Finally, the paper draws some conclusions and outlines ideas for future work in Section 6.\nTo optimize the IoT-fog-cloud system performance, resource allocation and computational task offloading are core aspects to consider. The resource allocation and computational task offloading problems turn to be more difficult and complicated since inherent heterogeneity, uncertainty and dynamic within the computing environment as well as the different objectives raised up by users and operators. As the most important performance index, different expressions of indexes are proposed to mathematically describe the time-sensitive request of IoT applications. An online strategy [12] is proposed to maximize the number of tasks meeting deadlines. Tardiness [13] is set as a penalty variable within the fitness value. Delay constraints are adopted in [14] to obtain feasible solutions. Apart from the performance index, the objectives, such as cost and energy consumption, are taken into consideration under different situations. Some state-of-art evolutionary algorithms [15-17] are adopted and perform well in multi-objective problems as it is capable of adjusting the solution accordingly.  \nApart from optimization objectives, different kinds of scheduling models are proposed to emulate practical condition. Task queue model [18-21] is adopted to describe the task generating and caching situation in the gateway, fog and cloud nodes. In spite of the task queue model, independent task model [22,23] is used to model user requests. Quality of Experiment (QoE) aware application placement solution is presented in [22] where tasks are clustered by fuzziness method and labelled with linguistic classification. Inspired by this work, fuzzy logic is employed to realize fuzziness and de-fuzziness onto the application tasks in our work.  \nIn addition, to model the precedence constraints between tasks, Direct Acyclic Graph (DAG) is used to model the application. Heterogeneous earliest finish time (HEFT) [27] produces\n[IMAGE0]  \nFig. 1. Membership function of a triangular fuzzy number [30].\nscheduling schemes in heterogeneous processors environment for shortening application completion time. Tasks are sorted and opportunistically inserted to available processor idle time slot of towards the earliest finish time. HEFT is ranked as the best of twenty scheduling heuristic methods in terms of robustness and performance [28]. A mixed-integer linear programming is presented in [24] to model offloading the dependent tasks with deadline constraints in IoT-fog system. This work ignores IoT devices and takes the cloud computing tier as a processor with unlimited computing capability. To solve the multi-objective DAG task scheduling problem, multi-objective HEFT [29] is designed as a general framework to provide a set of solutions for the decision maker. New solutions are sorted according to crowding distance and best $K$ solutions are chosen as Pareto set. Fuzzy dominance is introduced to improve the performance of MOHEFT in [25], which optimizes both makespan and cost index. Related works on fog resource allocation problem are summarized in Table 1. In this work, we consider a fuzzy DAG task scheduling problem where the agreement index is used to evaluate task latency. Meanwhile, robustness is another objective which is considered to guarantee the stability of the algorithm.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:35",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the convergence behavior of the FLC (Fuzzy Logic Controller) using Distribution Factor 1 (DF1) compare to that of FLC using Distribution Factor 2 (DF2), specifically in terms of IMP (Improvement) variations and the number of generations required to achieve convergence?",
      "topics": [
        "convergence",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "When using DF1 (0.6:0.4) with the FLC, initial IMP variations range from -0.35 to +0.4, reducing to -0.004 to +0.003 after approximately 20 generations, with convergence achieved after around 85 generations. In contrast, using DF2 (0.8:0.2) results in significantly lower IMP variations and achieves convergence much earlier, specifically within FORMULA_199 generations, due to its proximity to the best optimized solution of 356 type 1 clusters and 88 type 2 clusters.",
      "chunk_id": 7933,
      "paper_id": "Fuzzy Logics as an Integral Part of Evolutionary Algorithms",
      "paper_title": "Fuzzy Logics as an Integral Part of Evolutionary Algorithms",
      "paper_year": "2019",
      "chunk_content": "In this approach, IMP is defined based on improvement in two successive generations. Therefore, even if $\\mathrm{OF}_{\\text {best }}$ is having a higher value in initial generations, the variations are seen in two successive generations only to estimate $\\alpha$. The results obtained for the two initial DFs are appended below:  \n1. Using DF1 (0.6:0.4): Figure 6 shows the variation of $\\mathrm{IMP}_{S}$ with generations. It is observed that the initial variations in IMP are quite large $(-0.35$ to +0.4$)$.\n[IMAGE5]  \nFig. 6. Value of $\\mathrm{IMP}_{s B}$ with each generation using FLC ( $\\mathrm{IMP}_{s}$ approach) with DF1 (0.6:0.4). The smaller variations after 18 generations are given in the inset.  \nHowever, the variations reduce significantly after 20 generations ( -0.004 to +0.003 ). This shows that after few generations, the algorithm is nearing convergence. After $\\sim 85$ generations, IMP is 0 most of time and convergence is achieved. Figure 7 shows the variation of $\\alpha$ with generations. The value of $\\alpha$ is generated in two regions mainly below 0.18 and above 0.18 . This is based on negative IMP and positive IMP, respectively. As only two generations are considered, a zig-zag kind of curve is seen. It is also to be noted that after few iterations ( 20) even with a very small positive, a negative value of IMP gives a large variation in $\\alpha$. This is desired, as in the later generations even a small IMP should give a large $\\alpha$ and vice versa. The best LP achieved is the same as achieved with our earlier study ${ }^{11}$ using population size $N=1200$ and $\\alpha=0.5$.\n[IMAGE6]  \nFig. 7. Value of $\\alpha$ with each generation using FLC (IMP, approach) with DF1 (0.6:0.4).  \n2. Using DF2 (0.8:0.2): It was observed from Ref. 11 that the best optimized solution has 356 type 1 clusters and 88 type 2 clusters. This is very near to the initial DF (0.8:0.2) as compared to DF1 (0.6:0.4). Therefore, lesser variations are expected here for IMP and $\\alpha$. Figures 8 and 9 show the variation of IMP and $\\alpha$ with generations. Comparing Fig. 8 with Fig. 6 and Fig. 9 with Fig. 7, it is evident that the convergence is achieved much earlier ( FORMULA_199 generations) in this case, as expected. Further, the variations are also significantly lower. However, the best LP achieved is the same as observed with DF1.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:38",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for graph matching, what data structures are required to represent an individual solution?",
      "topics": [
        "representation",
        "data structures",
        "graph matching"
      ],
      "answer": "An individual solution can be represented using an array $X$ of size $\\left|V_{2}\\right|$, where $\\left|V_{2}\\right|$ is the number of nodes in the data graph $G_{2}$. Each element $X_{i}$ in the array, where $1 \\leq i \\leq \\left|V_{2}\\right|$, stores an integer value $k$ between 1 and $\\left|V_{1}\\right|$, indicating that the $i^{th}$ node of $G_{2}$ is matched with the $k^{th}$ node of the model graph $G_{1}$.",
      "chunk_id": 6072,
      "paper_id": "Estimation of distribution algorithms- A new evolutionary computation approach for graph matching problems",
      "paper_title": "Estimation of distribution algorithms:: A new evolutionary computation approach for graph matching problems",
      "paper_year": "2001",
      "chunk_content": "The choice of an adequate individual representation is a very important step in any problem to be solved with heuristics that will determine the behavior of the search. An individual represents a point in the search space that has to be evaluated, and therefore is a solution. For a graph matching problem, each solution represents a match between the nodes of a data graph $G_{2}$ and those of model graph $G_{1}$.  \nA possible representation that has already been used either in GAs or discrete EDAs [34] consists of individuals with $\\left|V_{2}\\right|$ variables, where each variable can take any value between 1 and $\\left|V_{1}\\right|$. More formally, the individual as well as the solution it represents could be defined as follows: for $1 \\leq k \\leq\\left|V_{1}\\right|$ and $1 \\leq i \\leq\\left|V_{2}\\right|, X_{i}=k$ means that the $i^{t h}$ node of $G_{2}$ is matched with the $k^{t h}$ node of $G_{1}$.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:40",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the contribution of the local surrogate model controlled during the generation of high-quality solutions in the described Estimation of Distribution Algorithm?",
      "topics": [
        "control"
      ],
      "answer": "The contribution of the local surrogate model is controlled by the probability \\(P_{c}\\). This parameter determines the probability that components of sampled solutions are replaced by those of solutions derived from the local surrogate model. Furthermore, \\(\\left\\lfloor P_{b} \\cdot N\\right\\rfloor\\) best solutions are used to construct the local surrogate models.",
      "chunk_id": 4577,
      "paper_id": "An Estimation of Distribution Algorithm With Cheap and Expensive Local Search Methods",
      "paper_title": "An Estimation of Distribution Algorithm With Cheap and Expensive Local Search Methods",
      "paper_year": "2015",
      "chunk_content": "Input: the probability model $P(x)$.\nOutput: a new candidate solution $x$.\n1 for $i \\leftarrow 1$ to $n$ do\nRandomly select a bin $m$, according the probability $P_{i, j}, j=1, \\ldots, M$\nUniformly randomly pick a value $x_{i}$ from $\\left[a_{i, M-1}, a_{i, M}\\right]$ if $m=M$ or from $\\left[a_{i, m-1}, a_{i, m}\\right)$ if $m<M$.\n4 end\n5 return $x=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)^{T}$.  \nFig. 1(d) illustrates our basic idea in the case of four bins. The VWH model focuses more on the promising search areas especially when the population converges to a small area. In such a case, the space defined by $\\prod_{i=1}^{n}\\left[a_{i, 1}, a_{i, M-1}\\right]$ might be very small and thus EDA/LS will spend more resources on exploitation.  \nEach component $x_{i}, i=1, \\ldots, n$ of solution $x$ is sampled independently and the procedure is shown in Algorithm 2.\nTo improve the performance of UMDAs, other techniques can be combined with UMDAs. In [32] and [38], classical LS methods are applied to improve some selected solutions. Surrogate models are usually used to estimate the objective values and thus to reduce the number of Fes [45]. In this paper, we propose to improve a solution quality by using a local surrogate model. Since this method does not need any FE and works in a local area, we call it a cheap LS on a surrogate model.  \nThe basic idea of the cheap LS is to replace some components of sampled solutions by those of solutions derived from a local surrogate model with a probability $P_{c}$. Fig. 2 illustrates this idea. To generate high-quality solutions, $\\left\\lfloor P_{b} \\cdot N\\right\\rfloor$ best solutions are used to construct local surrogate models. $P_{c}$ controls the contribution of the local model. Lines 11-13 in Algorithm 1 shows the details of replacement.  \nAs proposed in [46]-[48], the relation between the objective function and each decision variable $z$ can be approximated by a quadratic model as  \n$$\nf=c_{1} z^{2}+c_{2} z+c_{3}\n$$  \n[IMAGE2]\nsampled solutions solutions from cheap local search\ncandidate solutions\nFig. 2. Illustration of reproduction by combining EDA and local surrogate models in EDA/LS. We assume that the leftmost panel shows the individuals, while the middle panel shows the optimal solutions derived from the local surrogate models. They are combined in a way like crossover to create new offspring.\n[IMAGE3]  \nFig. 3. Illustration of local quadratic approximation to detect local optimal point.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:41",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the mutation operation within the UMDA framework described, and how does it influence the probability vector p(i,t)?",
      "topics": [
        "mutation"
      ],
      "answer": "The primary objective of the mutation operation in UMDA is to introduce diversity into the probability vector p(i, t). This is achieved by altering locus i with a probability pm, where pm is the mutation probability. If a random number r is less than pm, p(i, t) is updated based on its value relative to 0.5, either decreasing it by a factor of (1.0 - m) if p(i, t) > 0.5, leaving it unchanged if p(i, t) = 0.5, or increasing it by m after decreasing it by a factor of (1.0 - m) if p(i, t) < 0.5. This mechanism allows the algorithm to explore different regions of the search space, preventing premature convergence.",
      "chunk_id": 11761,
      "paper_id": "Univariate Marginal Distribution Algorithm in Combination with Extremal Optimization (EO",
      "paper_title": "Univariate Marginal Distribution Algorithm in Combination with Extremal Optimization (EO, GEO)",
      "paper_year": "2011",
      "chunk_content": "The Muhlenbein introduced UMDA [1,2,12] as the simplest version of estimation of distribution algorithms (EDAs). SUMDA starts from the central probability vector that has value of 0.5 for each locus and falls in the central point of the search space. Sampling this probability vector creates random solutions because the probability of creating a 1 or 0 on each locus is equal. Without loss of generality, a binary-encoded solution $x=\\left(x_{1}, \\ldots, x_{l}\\right) \\in\\{0,1\\}^{l}$ is sampled from a probability vector $\\mathrm{p}(\\mathrm{t})$. At iteration t , a population $\\mathrm{S}(\\mathrm{t})$ of n individuals are sampled from the probability vector $\\mathrm{p}(\\mathrm{t})$. The samples are evaluated and an interim population $D(t)$ is formed by selecting $\\mu(\\mu<n)$ best individuals. Then the probability vector is updated by extracting statistics information from $\\mathrm{D}(\\mathrm{t})$ as follows:  \n$$\np^{\\prime}(t)=\\frac{1}{\\mu} \\sum_{k=1}^{k=\\mu} x_{k}(t)\n$$  \nThe mutation operation always changes locus $\\mathrm{i}=\\{1, \\ldots, \\mathrm{l}\\}$, if a random number $\\mathrm{r}=\\operatorname{rand}(0,1)<p_{m} \\quad\\left(p_{m}\\right.$ is the mutation probability), then mutate $\\mathrm{p}(\\mathrm{i}, \\mathrm{t})$ using the following formula:  \n$$\np^{\\prime}(i, t)=\\left\\{\\begin{array}{l}\np(i, t) *\\left(1.0-\\delta_{m}\\right), p(i, t)>0.5 \\\\\np(i, t), p(i, t)=0.5 \\\\\np(i, t) *\\left(1.0-\\delta_{m}\\right)+\\delta_{m}, p(i, t)<0.5\n\\end{array}\\right.\n$$  \nWhere $\\delta_{m}$ is mutation shift. After the mutation operation, a new set of samples is generated by the new probability vector and this cycle is repeated.  \nAs the search progresses, the elements in the probability vector move away from their initial settings of 0.5 towards either 0.0 or 1.0 , representing samples of height fitness. The search stops when some termination condition holds, e.g., the maximum allowable number of iterations $t_{\\max }$ is reached.\nExtremal optimization [4,8,9] was recently proposed by Boettcher and Percus. The search process of EO eliminates components having extremely undesirable (worst) performance in sub-optimal solution, and replaces them with randomly selected new components iteratively. The basic algorithm operates on a single solution S, which usually consists of a number of variables $x_{i}(1 \\leq i \\leq n)$. At each update step, the variable $x_{i}$ with worst fitness is identified to alter. To improve the results and avoid the possible dead ends, Boettcher and Percus subsequently proposed $\\tau$-EO that is regarded as a general modification of EO by introducing a parameter. All variables $x_{i}$, are ranked according to the relevant fitness. Then each independent variable $x_{i}$ to be moved is selected according to the probability distribution (3).  \n$$\np=k^{-\\tau}\n$$  \nSousa and Ramos have proposed a generalization of the EO that was named the Generalized Extremal Optimization (GEO) [10] method. To each species (bit) is assigned a fitness number that is proportional to the gain (or loss) the objective function value has in mutating (flipping) the bit. All bits are then ranked. A bit is then chosen to mutate according to the probability distribution. This process is repeated until a given stopping criteria is reached .",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:43",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the Q-GROA handle infeasible solutions for the Set-Union Knapsack Problem (SUKP), specifically addressing the calculation of \\(W_{-}N_{j}\\)?",
      "topics": [
        "optimization"
      ],
      "answer": "The Q-GROA algorithm, used to address infeasible solutions for the SUKP, employs a repair stage to obtain a preliminary feasible solution. A key component is the calculation of \\(W_{-}N_{j}\\), which is defined as \\(\\sum_{i \\in U_{j}}\\left(w_{i} / c_{i}\\right)\\) for \\(j=1,2, \\ldots, m\\). Here, \\(c_{i}\\) represents the number of occurrences of element \\(i\\) in the subsets \\(U_{1}, U_{2}, \\ldots, U_{m}\\), and \\(w_i\\) represents a weight associated with element \\(i\\). The Quicksort algorithm is then used to sort items in descending order based on \\(p_{j} / W_{-} N_{j}\\), where \\(p_j\\) is presumably a profit value associated with subset \\(U_j\\). The time complexity for calculating parameters and sorting is \\(O(m \\log m) + O(mn)\\), and the repair stage has a time complexity of \\(O(mn)\\).",
      "chunk_id": 8554,
      "paper_id": "Estimation of Distribution Algorithm Based on Levy Flight for Solving the Set-Union Knapsack Problem",
      "paper_title": "Estimation of Distribution Algorithm Based on Levy Flight for Solving the Set-Union Knapsack Problem",
      "paper_year": "2019",
      "chunk_content": "The SUKP is a constrained optimization problem that will definitely generate infeasible solutions when metaheuristic algorithms are used to solve it. Because infeasible solutions reduce the effectiveness of the algorithm, how to deal with infeasible solutions is the key problem that needs to be solved. The most common methods for dealing with infeasible solutions are the repair approach, the penalty function approach, the purist approach, the separation method and the hybrid approach [31], [32]. They have their own advantages and disadvantages for the general constrained optimization problem, but for the $0-1 \\mathrm{KP}$, Michalewicz [33] showed that the repair approach is more suitable than any other approach to address nonfeasible solutions. He et al. [5], [34] proposed a repair and optimization algorithm for solving the infeasible solutions of randomized time varying knapsack problems, the discount $\\{0-1\\}$ knapsack problem (D $[0-1] \\mathrm{KP}$ ) and the SUKP. On the basis of the S-GROA [5], Q-GROA is proposed to handle the infeasible solutions of the SUKP.  \nAccording to the SUKP, suppose that $c_{i}(0<=c_{i}<=m)$ $(i=1,2, \\ldots, n)$ counts the number of occurrences of the element $i(i \\in U)$ in the subsets $U_{1}, U_{2}, \\ldots, U_{m}$. Let $W_{-} N_{j}=\\sum_{i \\in U_{j}}\\left(w_{i} / c_{i}\\right)(j=1,2, \\ldots, m)$. Let $H[1 \\ldots m]$ be the descending subscript order in which the Quicksort algorithm is employed to sort all items in $S$ in descending order according to $p_{j} / W_{-} N_{j}(j=1,2, \\ldots, m)$. For an arbitrary $m$ dimensional $0-1$ vector $\\boldsymbol{Y}=\\left[y_{1}, y_{2}, \\ldots, y_{m}\\right] \\in\\{0,1\\}^{m}$, we simplify the notation as $\\boldsymbol{A}_{\\boldsymbol{Y}}=\\left\\{i \\mid y_{i} \\in \\boldsymbol{Y} \\&\\& y_{i}=1,1 \\leq i \\leq m\\right\\}$. The detailed steps of the Q-GROA are shown in Algorithm 2.  \nIn the Q-GROA, the Quicksort algorithm's time complexity is $O(m \\log m)$, where step 1 calculates the parameters $c_{i}(i=1,2, \\ldots, n), W_{-} N_{j}(j=1,2, \\ldots, m)$ and $H[1 \\ldots m]$, and the time complexity is $O(m \\log m)+O(m n)$. Step 2 assigns 0 to the potential solution $Y$, and the time complexity is $O(m)$. A repair stage (steps 3 to 7 ) is used to obtain a preliminary feasible solution, and the time complexity is $O(m n)$. Without considering the elements that have been",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:46",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm for the Agent Routing Problem in Multi-point Dynamic Task (ARP-MPDT), how should practitioners initialize the $G_{\\text {NHM }}$ matrix, given that it is related to the state growth index of each task?",
      "topics": [
        "selection"
      ],
      "answer": "To initialize the $G_{\\text {NHM }}$ matrix, which represents the initial state growth index for each task, practitioners should set it up as a matrix where each element $G_{\\text {NHM }}(i, j)$ is equal to $\\alpha_{j}$. The matrix $G_{\\text {NHM }}$ will have dimensions corresponding to the number of tasks, denoted as $n$, resulting in the structure: $\\left[G_{\\text {NHM }}(i, j)\\right]_{\\text {min }}=\\left[\\begin{array}{cccc} \\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\ \\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\end{array}\\right]$. Here, $\\alpha_{j}$ represents the state growth index of the $j$-th task.",
      "chunk_id": 11312,
      "paper_id": "A Multi-Model Estimation of Distribution Algorithm for Agent Routing Problem in Multi-Point Dynamic Task",
      "paper_title": "A Multi-model Estimation of Distribution Algorithm for Agent Routing Problem in Multi-point Dynamic Task",
      "paper_year": "2018",
      "chunk_content": "According to the aforementioned assumptions, because the agent is not allowed to go to other task points before completing its current task, the feasible solution of ARP-MPDT can be expressed by the access sequence of task points. In the following, the coding scheme will be explained by an example including 6 task points:  \nThe access sequence of all task points is denoted as follows:  \n$$\n\\mathbf{z}=\\{1,2,4,6,3,5\\}\n$$  \nThe value of each variable in $T$ can be calculated according to the following formulas:  \n$$\n\\begin{aligned}\n& t_{z(1)}^{r}=0 \\\\\n& t_{z(i)}^{l}=t_{z(i)}^{r}+\\Delta t_{z(i)} \\\\\n& t_{z(i+1)}^{r}=t_{z(i)}^{l}+\\frac{D_{z(i), z(i+1)}}{V}\n\\end{aligned}\n$$  \nIn this way, the value of the objective function can be calculated for each solution encoded by an access sequence of all task points.\nEDA describes the distribution information of the superior solutions of the problem by establishing probability models ${ }^{[9]}$, and the probability model is sampled to get a new generation of population. EDA relies on the loop of probabilistic modeling and sampling to discover the best solutions. The basic algorithm procedure is shown as the following ${ }^{[10]}$ :\nStep 1: Initialize a population of solutions(individuals);\nStep 2: Calculate fitness value of every individual, and select some individuals which has better fitness value into the dominant group;\nStep 3: Use the dominant group as samples to update the probability model;\nStep 4: Sample the probability model to generate new solutions;\nStep 5: Judge the termination condition. If the termination condition is satisfied, the algorithm stops and the result is output; otherwise, go to step 2.\nA graph for ARP-MPDT can be built by taking the task points as nodes and using the distance between any two points as the weight of the arc connecting them. It is obvious that the quality of solutions to ARP-MPDT relies on both the states of nodes and the weights of arcs in the graph. In this sense, neither NHM nor EHM can solely adapt to ARP-MPDT in general cases.  \nWhen the execution time takes up most of the total time, the agent's traveling time is not a primary element. It is better to solve the ARP-MPDT with EDA employing NHM, because the execution time mainly depends on the property of task points(nodes). On the other hand, if the traveling time takes up most of the total time, it is better to solve the ARP-MPDT with EDA employing EHM. Both NHM and EHM are adopted in the proposed algorithm. However, it is hard to determine which probability model to use without any prior knowledge. A coefficient is designed to adjust dynamically the selection proportion of NHM to EHM in generating new individuals.  \nBecause of the difference between the two models based on NHM or EHM, the sampling strategies and the updating strategies of probability models are also different. A certain proportion of the individuals in new population will be selected as samples by truncation sorting to update both EHM and NHM.  \nThe flowchart of the proposed algorithm for ARP-MPDT is illustrated in Fig.1and the notations are explained as Table1.  \nTable 1: Notations of the proposed algorithm\n1) Initialization  \nIn this paper, the initial $G_{\\text {NHM }}$ is related to the state growth index of each task. It can be initialized as follows:  \n$$\nG_{\\text {NHM }}=\\left[G_{\\text {NHM }}(i, j)\\right]_{\\text {min }}=\\left[\\begin{array}{cccc}\n\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\\n\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\alpha_{1} & \\alpha_{2} & \\cdots & \\alpha_{n}\n\\end{array}\\right]\n$$  \n[IMAGE0]  \nFig.1: Flowchart of the proposed algorithm",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:48",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Pareto-based Multi-objective Estimation of Distribution Algorithm with Gaussian Copulas (PMOEDAGC), what convergence and diversity metrics are used to evaluate its performance, and how are smaller values of these metrics interpreted in the context of algorithm performance?",
      "topics": [
        "convergence"
      ],
      "answer": "The performance of the PMOEDAGC algorithm is evaluated using the convergence metric denoted as $\\gamma$ and the diversity metric denoted as $\\Delta$. According to the description, smaller values of both the convergence metric $\\gamma$ and the diversity metric $\\Delta$ indicate better performance of the algorithm. These metrics are used to quantitatively assess both the closeness of the solutions to the true Pareto front (convergence) and the spread of the solutions across the objective space (diversity).",
      "chunk_id": 5322,
      "paper_id": "Pareto-Based Multi-objective Estimation of Distribution Algorithm with Gaussian Copulas and Application in RFID Network Planning",
      "paper_title": "Pareto-Based Multi-objective Estimation of Distribution Algorithm with Gaussian Copulas and Application in RFID Network Planning",
      "paper_year": "2012",
      "chunk_content": "In order to test efficiency of the proposed algorithm, the performance of the proposed algorithm is compared with that of some multi-objective optimization algorithms. The following benchmark functions[10] have been used to test.  \n1) ZDT1: $f_{1}(\\mathbf{x})=x_{1}$  \n$$\n\\begin{aligned}\nf_{2}(\\mathbf{x})= & g(\\mathbf{x})(1-\\sqrt{x_{1} / g(\\mathbf{x})}) \\quad x_{1} \\in[0,1] \\\\\n& g(\\mathbf{x})=1+9\\left(\\sum_{i=2}^{D} x_{i}\\right) /(D-1)\n\\end{aligned}\n$$  \n2) ZDT2: $f_{1}(\\mathbf{x})=x_{1}$  \n$$\n\\begin{aligned}\nf_{2}(\\mathbf{x})= & g(\\mathbf{x})\\left(1-\\left(x_{1} / g(\\mathbf{x})\\right)^{2}\\right) \\quad x_{1} \\in[0,1] \\\\\n& g(\\mathbf{x})=1+9\\left(\\sum_{i=2}^{D} x_{i}\\right) /(D-1)\n\\end{aligned}\n$$  \n3) ZDT3: $f_{1}(\\mathbf{x})=x_{1}$  \n$$\n\\begin{aligned}\n& f_{2}(\\mathbf{x})=g(\\mathbf{x})\\left(1-\\sqrt{\\frac{x_{1}}{g(\\mathbf{x})}} \\cdot \\frac{x_{1}}{g(\\mathbf{x})} \\sin \\left(10 \\pi x_{1}\\right)}\\right) \\quad x_{1} \\in[0,1] \\\\\n& g(\\mathbf{x})=1+9\\left(\\sum_{i=2}^{D} x_{i}\\right) /(D-1)\n\\end{aligned}\n$$  \n4) ZDT4: $f_{1}(\\mathbf{x})=x_{1}$  \n$$\n\\begin{gathered}\nf_{2}(\\mathbf{x})=g(\\mathbf{x})\\left(1-\\sqrt{x_{1} / g(\\mathbf{x})}\\right) \\quad x_{1} \\in[0,1], x_{1} \\in[-5,5], \\\\\ng(\\mathbf{x})=1+10(D-1)+\\sum_{i=1}^{D}\\left(x_{i}^{2}-10 \\cos \\left(4 \\pi x_{1}\\right)\\right)\n\\end{gathered}\n$$  \n5) ZDT6: $f_{1}(\\mathbf{x})=1-\\exp \\left(-4 x_{1}\\right) \\sin ^{6}\\left(6 \\pi x_{1}\\right)$  \n$$\n\\begin{gathered}\nf_{2}(\\mathbf{x})=g(\\mathbf{x})\\left(1-\\left(f_{1}(x) / g(\\mathbf{x})\\right)^{2}\\right) \\quad x_{1} \\in[0,1] \\\\\ng(\\mathbf{x})=1+9\\left(\\sum_{i=2}^{D} x_{i} /(D-1)\\right)^{0.25}\n\\end{gathered}\n$$  \nConvergence metric $\\gamma[3]$ and Diversity metric $\\Delta[3]$ were used. The smaller the value of these metrics is, the better the performance of the algorithm is. The initial population was generated from a uniform distribution in the ranges specified below. Population size $N=100$. All experiments were repeated for 20 runs. The maximum number of iterations is set to 2000 in each running. TABLE 1 listed the mean and variances of the convergence and diversity metrics obtained using SPEA2[2], NSGA-II[3], FastPGA[4] and the proposed algorithm (PMOEDAGC) on ZDT1, ZDT2, ZDT3, ZDT4 and ZDT6. It can be known from TABLE 1, in both aspects of convergence and distribution of solutions, PMOEDAGC outperforms SPEA2, NSGA-II and FastPGA on the benchmark functions.  \nThe algorithm is also applied RFID network planning problem. A simplified $30 \\mathrm{~m} \\times 30 \\mathrm{~m}$ square working area with 60 tags is used for the simulation. 20 RFID readers, whose radiated power is adjustable in the range from 0 to 30 dBm , are considered to serve this area. FORMULA_123 is used as the multi-objective function. The population size in the algorithm is set to 200 . The algorithm runs to a maximum number of 4000 iterations. A sample of Pareto optimal solution for network planning is listed in TABLE 2.  \nTABLE I\nMean and Variances of Convergence and Diversity Metrics for Multi-Objective Benchmark Functions\nThe proposed algorithm employs the multivariate Gaussian copulas to construct probability distribution model, and the new individuals are generated according to the model. An archive is used to maintain the non-dominated solutions. The Pareto optimal solutions are selected from the archive. The archive gets updated with the inclusion of the non-dominated solutions from the combined population and current archive.  \nThe algorithm is applied to some benchmarks and RFID Network planning. The results show that the algorithm has better performance than SPEA2[2], NSGA-II[3], FastPGA[4] on the benchmarks and is effective in RFID networks planning.  \nTABLE II\na Sample of Pareto Optimal Solution for Network Planning",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:49",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the performance of TAMMEA compare to Random, Randoop, and CATG in the very difficult category, based on the strong mutation score ($MS_{\\text{strong}}$)?",
      "topics": [
        "analysis"
      ],
      "answer": "In the very difficult category, TAMMEA achieves a higher $MS_{\\text{strong}}$ than Random, Randoop, and CATG for most programs. Random, Randoop, and CATG each have at least two subject programs with $MS_{\\text{strong}} = 0\\%$, indicating they fail to kill any mutants in those cases, while TAMMEA generally maintains a higher score. Random, Randoop and CATG have the worst performance because their $M S_{\\text{strong}}$ of each program was $0\\%.",
      "chunk_id": 2669,
      "paper_id": "Test Data Generation for Mutation Testing Based on Markov Chain Usage Model and Estimation of Distribution Algorithm",
      "paper_title": "Test Data Generation for Mutation Testing Based on Markov Chain Usage Model and Estimation of Distribution Algorithm",
      "paper_year": "2024",
      "chunk_content": "[IMAGE15]  \nFig. 17. A mutant $M$ of J3 after using $A O I S$ mutation operator.\nproposed by Dang et al. [16] (as shown in Section IV-D) and obtained the effectiveness of each method for each category, as shown in Fig. 16.  \nFrom Fig. 16, we could observe that: 1) For the easy category (as shown in Fig. 16(a)), each of the nine methods could achieve $M S_{\\text {strong }}=100 \\%$ on each tested program, which indicated that each method had equal effectiveness in this type. 2) For the middle category (as shown in Fig. 16(b)), TAMMEA (blue bar) could achieve $M S_{\\text {strong }}=100 \\%$ for all subject programs, whereas each of the other eight methods had at least two subject programs with $M S_{\\text {strong }}<100 \\%$ and Random had the worst performance because its $M S_{\\text {strong }}$ of each program was less than $90 \\%$. 3) For the difficult category (as shown in Fig. 16(c)), TAMMEA could achieve $M S_{\\text {strong }}=100 \\%$ for each tested program except for J12, J13, and J14, whereas each of the other eight methods had at least four programs with $M S_{\\text {strong }}<100 \\%$. Furthermore, TAMMEA could obtain $M S_{\\text {strong }}>=40 \\%$ for J12, J13, and J14, while each of the other eight methods obtained $M S_{\\text {strong }}<40 \\%$. 4) For the very difficult category (as shown in Fig. 16(d)), TAMMEA could achieve a higher $M S_{\\text {strong }}$ than each of the other eight methods for each program except for (J1, J2, and J7) and FUZGENMUT was only second to TAMMEA on the whole, whereas each of the other seven methods had at least two subject programs with $M S_{\\text {strong }}=0 \\%$ and three methods (Random, Randoop, and CATG) had the worst performance because its $M S_{\\text {strong }}$ of each program was $0 \\%$. Based on the above analysis of results, we could draw a conclusion: under the same constraints, our method could kill more mutants (these mutants were usually deeply buried in the code or deeply nested in the path) for the difficult type (or very difficult type) than other methods, which made our method have a higher $M S_{\\text {strong }}$.  \nIn addition, we used code from J3 (other tested programs were similar to J3) as an example based on the previous experimental results to specifically illustrate the characteristics of mutants for the very difficult category. We randomly selected a mutant $M$ (as shown in Fig. 17) from all mutants for the very difficult category and $M$ was obtained by using mutation operator $A O I S$ to mutate the statement $i f($ cual $==3)$ in J3.\n[IMAGE16]  \nFig. 18. The comparison results of efficiency for TAMMEA and other eight baseline techniques.  \nFrom Fig. 17, we could observe that $M$ was deeply buried in the code or deeply nested in the path, which meant that our method could touch and kill it while other methods could not touch and kill it. Similar to FORMULA_651, other mutants from the very difficult category also met the same characteristics.  \nIn summary, the test data generated by TAMMEA had higher fault-detection effectiveness than those of the other eight baseline techniques under strong mutation criterion.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:51",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for the stochastic RCPSP, what data structures are required to represent a scheduling policy, and how do policies like resource-based or activity-based policies utilize an activity list?",
      "topics": [
        "scheduling",
        "data structures",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "For the stochastic RCPSP, a scheduling policy $\\pi$ can be interpreted as a function that maps a given scenario $d$ (a vector of activity durations) to start times of activities $s(d, \\pi)$. Policies such as resource-based, activity-based, and pre-processor policies operate with an activity list, where the activity list and policy are used interchangeably. The activity list dictates the order in which activities are considered for scheduling, influencing the overall project makespan $s_{J+1}(d, \\pi)$.",
      "chunk_id": 4698,
      "paper_id": "An estimation of distribution algorithm and new computational results for the stochastic resource-co",
      "paper_title": "An estimation of distribution algorithm and new computational results for the stochastic resource-constrained project scheduling problem",
      "paper_year": "2015",
      "chunk_content": "In the stochastic RCPSP, we can no longer use a vector of start times of activities to represent a solution because we do not know the exact duration of each activity before it has been finished. As a result, a scheduling policy is needed to decide which activity to choose at each decision time. Decision times are $t=0$ (the start time of the project) and the finishing times of activities. For each decision time $t$, only information which has become available up to $t$ can be used to make the decision (non-anticipativity constraint, see e.g. Stork 2001). That means we can only know the durations of activities which have been finished up to time $t$. After all activities are completed, we obtain a scenario $d$ from the random duration vector $D$. Consequently, every policy $\\pi$ may alternatively be interpreted as a function $\\pi$ : $R_{J+2}^{+} \\rightarrow R_{J+2}^{+}$that maps a given scenario $d$ to start times of activities (schedules) $s(d, \\pi)$ (Stork 2000). For a given sample $d$ and scheduling policy $\\pi, s_{J+1}(d, \\pi)$ denotes the makespan of the project. The objective for the SRCPSP is to select a policy $\\pi^{*}$ which minimizes the expected makespan $E\\left[s_{J+1}\\left(D, \\pi^{*}\\right)\\right]$.  \nVarious classes of policies have been proposed for the SRCPSP. Some wellknown classes of policies are earliest-start policies ( $\\Pi^{E S}$ ), preselective policies $\\left(\\Pi^{P S}\\right)$, linear preselective policies $\\left(\\Pi^{L P S}\\right)$, resource-based policies $\\left(\\Pi^{R B}\\right)$, activitybased policies $\\left(\\Pi^{A B}\\right)$, and pre-processor policies $\\left(\\Pi^{P P}\\right)$, (see Stork 2001; Ashtiani et al. 2011).  \nThe policy classes $\\Pi^{E S}, \\Pi^{P S}$ and $\\Pi^{L P S}$ are based on the so-called minimal forbidden sets (see Stork 2000 for details). Since the number of minimal forbidden  \nsets grows exponentially with the number of activities, the computational time becomes unacceptable when dealing with practical project scheduling problems. As a result, policies which do not need the calculation of minimal forbidden sets should be adopted when dealing with real size projects. These are resource-based policies, activity-based policies and pre-processor policies. As will be shown, each of these policies operates in a specific way with an activity list. Hence, with $\\pi$ we denote activity list and policy interchangeably.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:48:53",
      "generation_style": "implementation_focused"
    },
    {
      "question": "When evaluating the runtime performance of EDAs on the DeceivingLeadingBlocks (DLB) problem, how does the proven runtime guarantee of the UMDA algorithm compare to that of classic elitist evolutionary algorithms?",
      "topics": [
        "evaluation metrics",
        "EDAs",
        "runtime analysis"
      ],
      "answer": "On the DeceivingLeadingBlocks (DLB) problem, the univariate marginal distribution algorithm (UMDA) has a proven runtime guarantee of O(n^2 log n). This contrasts with classic elitist evolutionary algorithms, which have runtime guarantees of O(n^3) with optimal parameter choices on the same problem. This difference motivates investigation into non-elitist approaches.",
      "chunk_id": 1775,
      "paper_id": "Choosing the Right Algorithm With Hints From Complexity Theory",
      "paper_title": "Choosing the Right Algorithm With Hints From Complexity Theory (Hot-off-the-Press Track at GECCO 2022)",
      "paper_year": "2022",
      "chunk_content": "GECCO '22 Companion, July 9-13, 2022, Boston, MA, USA\n(c) 2022 Copyright held by the owner/author(s).  \nACM ISBN 978-1-4503-9268-6/22/07.\nhttps://doi.org/10.1145/3520304.3534069  \nby giving an indication which of the existing algorithms could be useful for a particular problem. In simple words, what we propose is trying to find out which classes of black-box algorithms contain fast algorithms for the problem at hand. These algorithms may well be artificial as we use them only to determine the direction in which to search for a good established algorithm for our problem. Only once we are sufficiently optimistic that a certain property of black-box algorithms is helpful for our problem, we regard the established heuristics in this class and see if one of them indeed has a good performance.  \nTo show that this abstract heuristic approach towards selecting a good algorithm can indeed be successful, we regard the DeceivingLeadingBlocks (DLB) problem recently proposed by Lehre and Nguyen [9]. Lehre and Nguyen conducted rigorous runtime analyses of several classic evolutionary algorithms, all leading to runtime guarantees of order $O\\left(n^{3}\\right)$ with optimal parameter choices. For the EDA univariate marginal distribution algorithm (UMDA), a runtime guarantee of $O\\left(n^{2} \\log n\\right)$ was proven in [6]. No other proven upper bounds on runtimes of randomized search heuristics on the DLB problem existed prior to this work. With only these results from only two prior works, it is safe to call the DLB problem relatively novel and thus an interesting object for our investigation.  \nFinding more efficient randomized search heuristics: We note that the classic algorithms regarded in [9] are all elitist evolutionary algorithms or non-elitist algorithms with parameter settings that let them imitate an elitist behavior. To obtain a first indication whether it is worth investigating truly non-elitist algorithms for this problem, we show two results. (i) We prove that the $(1+1)$ elitist unbiased black-box complexity of the DLB problem is $\\Omega\\left(n^{3}\\right)$. (ii) We show that there is a simple, artificial, $(1+1)$-type non-elitist unbiased black-box algorithm solving the DLB problem in quadratic time. These two findings motivate us to analyze the existing $(1+1)$ type non-elitist heuristics. Among them, we find that the Metropolis algorithm [10] with a suitable temperature also optimizes DLB in time FORMULA_14. We note that there are very few runtime analyses on the Metropolis algorithm, so it is clear that a synopsis of the existing runtime analysis literature would not have easily suggested this algorithm.",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:48:55",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when addressing large-scale global optimization (LSGOs)?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The primary objective is to improve performance while reducing the computational cost associated with solving LSGOs by introducing a novel multivariate EDA based on a latent subspace (LS-EDA). The LS-EDA employs a probabilistic PCA model and the EM algorithm to reduce computational complexity, particularly for high-dimensional problems, and aims to characterize the structure of optimization problems.",
      "chunk_id": 8477,
      "paper_id": "A latent space-based estimation of distribution algorithm for large-scale global optimization",
      "paper_title": "A latent space-based estimation of distribution algorithm for large-scale global optimization",
      "paper_year": "2019",
      "chunk_content": "Traditional EDAs' performance deteriorates dramatically when the dimensionality of problems grows. Although sev-  \neral attempts aim to improve the performance of EDA for large-scale optimization, they fail to fundamentally solve the problem of high computational budget. This paper presents a novel multivariate EDA based on a latent subspace (LS-EDA) to improve the performance while reducing the computational cost to solve LSGOs. By employing a probabilistic PCA model, the proposed method shows significantly better performance over the traditional EDAs on some categories of optimization problems, such as large-scale separable problems and nonseparable problems with only a few local optima. The proposed LS-EDA uses of the EM algorithm reduce the computational complexity, especially for the problems with a high-dimensional space. Experimental results show that the runtime of LS-EDA is lower than those of the other EDAs when the problem dimensionality increases. Similar to EDA-MCC, LS-EDA can also characterize the structure of optimization problems and give some possible clues to provide insight into the properties, especially for black-box optimization problems. Compared with DECC-G, an evolutionary algorithm in a cooperative framework, LS-EDA performs well on the complex problems, such as subcomponent overlapping and nonseparable functions.  \nThe advantages of LS-EDA can be summarized as follows: (1) Its computing budget is lower than the other EDAs, thereby making it more suitable to solve real-world problems; (2) due to EM algorithm, it seldom encounters the problems of unacceptable numerical computation burden, such as finding an irreversible matrix in learning a probabilistic model, and space overflow because of error accumulation; (3) its performance is superior to the traditional EDAs in terms of the accuracy; and (4) its performance is also superior to some evolutionary algorithms with a cooperative framework for highly complex problems.  \nBased on our experimental results, we also discover some limitations of LS-EDA. First, its performance is worse than evolutionary algorithms with a cooperative framework on simple problems, such as fully separative problems. Secondly, the convergence curve of LS-EDA shows that it is fast at the initial searching stage, but it seems quickly trapped into stagnation. Some open issues are worthy of further study. First, how to determine the number of latent variables to grasp the implicit information of samples needs to be fully tested and analyzed. Moreover, due to their complementary nature between LS-EDA and DECC-G, we should integrate the LS-EDA into a cooperative coevolution framework.  \nAcknowledgements This study was funded by the NSF of China (Grant Numbers 61170305, 61672024), the NSF of USA (Grant Number CMMI-1162482) and the Key Research Program in Higher Education of Henan (Grant Number 17A520046).\nConflict of interest The authors declare that they have no conflict of interest.  \nEthical approval This article does not contain any studies with human participants performed by any of the authors.  \nInformed consent Informed consent was obtained from all individual participants included in the study.",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:48:56",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of the Compact Firefly Optimizer, how does the algorithmic mechanism of updating the Probabilistic Vector (PV) components, specifically \f$\\mu_i^{i+1}\\f$ and \f$\\sigma_i^{i+1}\\f$, contribute to the algorithm's search process?",
      "topics": [
        "crossover"
      ],
      "answer": "In the Compact Firefly Optimizer, the Probabilistic Vector (PV) is updated iteratively to guide the search. The mean, denoted as \f$\\mu_i^{i+1}\\f$, for each dimension \f$i\\f$ is updated using the formula \f$\\mu_i^{i+1} = \\mu_i^i + I/N = (\\sigma_i^i - \\lambda^i)\\f$, where \f$I\\f$ represents the genes of the loser, \f$N\\f$ is the virtual population size, \f$\\sigma_i^i\\f$ is the current standard deviation, and \f$\\lambda\\f$ is the initial standard deviation. The standard deviation, denoted as \f$\\sigma_i^{i+1}\\f$, is updated using the formula \f$[\\sigma_i^{i+1}]^j = {\\sigma_i^i}^j + {\\varepsilon_i^i}^2 - {\\varepsilon_i^{i+1}}^2 + \\frac{x}{N} \\times ({w_i^i}^2 - {I_i^i})^2\\f$, where \f$w\\f$ represents the genes of the winner. These updates adjust the distribution from which new solutions are generated, effectively shifting the search towards promising regions of the search space based on the competition between solutions.",
      "chunk_id": 12044,
      "paper_id": "CFO  A new compact swarm intelligent algorithm for global optimization and optimal bipedal robots walking",
      "paper_title": "CFO: A New Compact Swarm Intelligent Algorithm for Global Optimization and Optimal Bipedal Robots Walking",
      "paper_year": "2016",
      "chunk_content": "```\nAlgorithm 1: Compact Firefly Optimizer\n1. N : Virtual population size\n2. \\(\\lambda\\) : Initial standard deviation\n3. \\(\\mathrm{m} \\text { : problem dimension}\n4. \\(R{\\text {dump }}=\\mathrm{Initialize}\\) the dumping ratio\n5. \\(R=\\) Initialize the mutation coefficient\n6. \\(\\mathrm{t}=1 \\quad / \\) iteration index /\n7. for \\(j=1: m\\) do / Initialization of PV /\n8. \\(\\quad \\mu{j}{ }^{j}=0 ; \\quad \\sigma{j}{ }^{j}=\\lambda\\);\n9. end\n10. Elite=generate (PV) / Assume Elite /\n11. while Termination condition / Main loop /\n12. \\(\\mathrm{G}{j}=\\) generate \\(\\left(\\mathrm{PV}^{\\mathrm{nt}}\\right)\\)\n13. \\(\\mathrm{G}{j}=\\) generate \\(\\left(\\mathrm{PV}^{\\mathrm{nt}}\\right)\\)\n14. [ winner, loser ] = compete( \\(\\left.\\mathrm{G}{1}, \\mathrm{G}{2}\\right)\\)\n15. Move the winner toward the elite\n16. for \\(i=1: \\mathrm{m} \\quad / \\) Crossover /\n17. if rand \\(<\\mathrm{pCr}\\)\n18. winner(i)=elite(i)\n19. endif\n20. endfor\n21. [ winner, loser ] = compete(winner, elite)\n22. elite \\(=\\) winner \\(; \\) Update elite /\n23. for \\(i=1: \\mathrm{m}\\) do / updating PV /\n24. \\(\\mu{i}{ }^{i+1}=\\mu{i}{ }^{i}+I / N=\\left(\\sigma{i}{ }^{i}-\\lambda^{i}\\right)\\);\n25. / Landw, are the genes of the loser and winner/\n26. \\(\\left[\\sigma{i}{ }^{i+1}\\right]^{j}=\\left\\{\\sigma{i}{ }^{i}\\right\\}^{j}+\\left\\{\\varepsilon{i}{ }^{i}\\right\\}^{2}-\\left\\{\\varepsilon{i}{ }^{i+1}\\right\\}^{2}+\\frac{\\mathbf{x}}{N} \\times\\left(\\left\\{w{i}{ }^{i}\\right\\}^{2}-\\left\\{I,{ }^{i}\\right\\}\\right)^{2} ;\\)\n27. endfor\n28. \\(R=R  R{\\text {dump }}\\)\n29. while \\(\\mathbf{j}<=10 \\quad / \\) refinement the elite /\n30. NewElite \\(=(1-R L) \\) elite + RL randn(-1,1)\n31. [ winner, loser ] = compete(NewElite, elite)\n32. elite \\(=\\) winner \\(; \\) Update elite /\n33. for \\(i=1: \\mathrm{m}\\) do / updating PV /\n34. \\(\\mu{i}{ }^{i+1}=\\mu{i}{ }^{i}+I / N=\\left(\\sigma{i}{ }^{i}-\\lambda^{i}\\right)\\);\n35. / $L$ andw, are the genes of the loser and winner*/",
      "question_type": "advantage",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:00",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm, how should practitioners leverage subpopulations to identify and mitigate ineffective marginal distributions within a probabilistic model, specifically detailing the process of model pruning based on these identified distributions?",
      "topics": [
        "heuristic"
      ],
      "answer": "Practitioners should split the entire population into two subpopulations. One subpopulation is used to build the probabilistic model, while the other is used to collect statistics indicating the ineffectiveness of certain marginal distributions within the model built on the first subpopulation. By applying appropriate heuristics or criteria, the likely ineffective portions of the model can be pruned. For example, in the ECGA implementation, a judging criterion is used to detect likely ineffective marginal distributions of a given marginal product model, effectively approximating the result of knowing effective distributions without directly identifying them.",
      "chunk_id": 7624,
      "paper_id": "Sensibility of Linkage Information and Effectiveness of Estimated Distributions",
      "paper_title": "Sensibility of Linkage Information and Effectiveness of Estimated Distributions",
      "paper_year": "2010",
      "chunk_content": "The idea of sensible linkage can be closely mapped into another notion called effective distributions. By effective distributions, we mean that by sampling these distributions, the solution quality can be reliably advanced. Hence, the crucial criteria for effective distributions are the consistency with building blocks and the provision of good directions for further search. If it is possible to extract effective marginal distributions from the built probabilistic model, we can perform partial sampling using only these marginal distributions and leave the remaining parts of the solutions unchanged. Thus, the diversity is maintained and we are free from the building block disruption and random drift problems. For instance, returning to the earlier 16-bit optimization problem, if it is possible to identify those partial models that are built on the sensible linkage like $\\left[s_{1} s_{2} s_{3} s_{4}\\right]$ in the first generation and $\\left[s_{5} s_{6} s_{7} s_{8}\\right]$ in the second generation, we can sample only the corresponding marginal distributions which are, in this case, effective. That is, in the first generation, for each solution string, we resample only $s_{1} s_{2} s_{3} s_{4}$ according to the marginal distribution and keep $s_{5} s_{6} \\cdots s_{16}$ unchanged. In the second generation, we resample only $s_{1}$ to $s_{8}$ according to the marginal distributions and keep $s_{9} s_{10} \\cdots s_{16}$ with the same values (note that $s_{1} s_{2} s_{3} s_{4}$ converged). In this way, we do not have to resort to increasing the population size to deal with the problems caused by the disparate building block scaling.  \nThe above thoughts leave us one complication: the identification of effective distributions. However, the direct identification of effective distributions may be a difficult if not impossible task. It may be wise to adopt a complementary approach-to identify those marginal distributions that are not likely to be effective. If there is a way to identify the ineffective distributions, we can bypass them and use only the rest of the probabilistic model, and thus approximate the result of knowing effective distributions. Our idea is that we can split the entire population into two subpopulations, use only one of the subpopulations for building the probabilistic model, and utilize the other subpopulation to collect some statistics for possible indications of ineffectiveness of certain marginal distributions in the probabilistic model built on the first subpopulation. That is, with some appropriate heuristics or criteria, we can prune the likely ineffective portions of the model.  \nIn the next section, our implementation in ECGA of the proposed concept will be detailed. More specifically, a judging criterion will be proposed to detect the likely ineffective marginal distributions of a given marginal product model.",
      "question_type": "practical application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:01",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the use of Bayesian Networks (BNs) within Estimation of Distribution Algorithms (EDAs), how does the factorization of the joint distribution represented by a BN contribute to efficient reasoning during inference, and what is the computational implication of directly computing marginalization without this factorization?",
      "topics": [
        "algorithm"
      ],
      "answer": "The factorization of the joint distribution in a Bayesian Network (BN), represented as $P(A, X, D) = \\sum_{T, E, L, B, S} P(A, T, X, E, D, L, B, S)$ allows for efficient reasoning by grouping common factors, as demonstrated by transforming the summation. Without this factorization, directly computing the marginalization involves a number of terms that grows exponentially with the number of variables, leading to increased computational complexity. Lauritzen and Spigelhalter show that grouping common factors makes the calculation more efficient.",
      "chunk_id": 6834,
      "paper_id": "Triangulation of Bayesian networks with recursive estimation of distribution algorithms",
      "paper_title": "Triangulation of Bayesian networks with recursive estimation of distribution algorithms",
      "paper_year": "2009",
      "chunk_content": "Let $\\mathbf{X}=\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ be an $n$-dimensional random variable, where $x_{i}$ is an instantiation of $X_{i}$. A PGM or Probabilistic Graphical Model $\\left(S, \\theta_{\\mathrm{a}}\\right)$ is a graphical structure $S=(\\mathbf{X}, \\mathscr{A})$ and a set of local parameters $\\theta_{\\mathrm{a}}, \\mathbf{X}$, a set of nodes, represents the system variables and $\\mathscr{A}$, a set of arcs, the conditional dependence/independence relationships among the variables of the structure. A Bayesian network (BN) is a PGM where the graphical structure is a directed acyclic graph (DAG), $X_{i}$ are random discrete variables (called nodes) and the set of parameters $\\theta_{\\mathrm{a}}=\\left(\\theta_{\\mathrm{gh}}\\right)$, where $k$ goes from 1 to $r_{i}, j$ from 1 to $q_{i}$ and $i$ from 1 to $n$, represents the local probability distributions over $\\mathbf{X}$, i.e., $\\theta_{\\mathrm{gh}}$ is the conditional probability of $X_{i}$ being in its $k$ th value given that the set of its parents variables is in its $j$ th-value. Finally, $r_{i}$ is the number of different values of $i$ th variable and $q_{i}$ represents the number of possible instantiations for the set of parents of $i$ th variable.  \n[^0]\n[^0]:     Corresponding author. Address: Donostia International Physics Center, Donostia - San Sebastian, Paseo Manuel de Lardizabal 4, 20018 Guipuzcoa, Spain. Tel.: +34 943 018347; fax: +34 943015600.  \nE-mail addresses: txomin.romero@ehu.es (T. Romero), pedro.larranaga@fi.upm.es (P. Larranaga).  \nThe BN paradigm can be used as a model to make inferences in domains with intrinsic uncertainty. The factorisation of the joint distribution that a BN represents allows an efficient reasoning inside the model. Introductions and classic textbooks about BN include [10,18] and [30]. As a model to make inferences, we will try to obtain their best triangulation, but we will also use them in the estimation of distribution algorithms themselves.  \nThe most direct way to make inference in a BN is to compute the marginalization over the not instantiated variables. The number of terms involved in the marginalization grows exponentially with the number of variables. Lauritzen and Spigelhalter show [26] that, instead of calculating each joint probability separately in order to add them in a posterior step, we can group the common factors of all of them in order to make the calculation more efficient. For example, for the Asia network (Fig. 1), we have:  \n$$\n\\begin{aligned}\nP(A, X, D) & =\\sum_{T, E, L, B, S} P(A, T, X, E, D, L, B, S) \\\\\n& =P(A) \\sum_{T} P(T \\mid A)\\left[\\sum_{E} P(X \\mid E)\\left[\\sum_{L} P(E \\mid T, L)\\left[\\sum_{B} P(D \\mid E, B)\\left[\\sum_{S} P(L \\mid S) P(B \\mid S) P(S)\\right]\\right]\\right]\\right]\n\\end{aligned}\n$$  \nWe can rewrite Eq. (1) as  \nFORMULA_30",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:03",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How does the initialization of the population differ between the standard Estimation of Distribution Algorithm (EDA) and the SM-CC scheduling solution described, and what impact might this have on the search process?",
      "topics": [
        "scheduling"
      ],
      "answer": "The standard EDA begins with a population initialized by an evenly distributed probability matrix, while the SM-CC scheduling solution employs a randomly shuffle procedure for initializing the population. Specifically, the SM-CC starts with an initial individual $\\pi(0)$ where the job permutation in each batch is sorted using the longest processing time (LPT) rule. This difference could lead to the SM-CC solution exploring a different region of the search space initially, potentially biasing the search towards solutions favored by the LPT rule.",
      "chunk_id": 800,
      "paper_id": "A modified RBM-based estimation of distribution algorithm for steelmaking-continuous casting scheduling",
      "paper_title": "A Modified RBM-Based Estimation of Distribution Algorithm for Steelmaking-Continuous Casting Scheduling",
      "paper_year": "2014",
      "chunk_content": "[IMAGE3]  \nFig. 3 Representation of SM-CC scheduling solution\nUnlike the standard EDA beginning with a population of initial individuals by an evenly distributed probability matrix, a randomly shuffle procedure is employed for initializing population.\nStep 1 Generate an initial individual $\\pi(0)$ whose job permutation in each batch is sorted with longest processing time (LPT) rule, and let the counter $C k=1$.\nStep 2 If $C k<N$, randomly choose a batch from $\\pi(0)$, and randomly produce a new job permutation in the selected batch. Else, exit this procedure.\nStep 3 If the new individual is same as previous one, then skip this repetitive solution. Else, set $C k=C k+1$, put it into the initial population.\nStep 4 Go to Step 2.\nC. BLS Method for Upstream Stages Scheduling Problem  \nAfter the job permutation of each batch is determined, the solution can be decoded as follows.\nStep 1 Parallel machine scheduling at the last stage.\nStep 1.1 Set $i=g$, calculate the release time $r h_{i}$ of the $l^{\\text {th }}$ batch at the last stage, where  \n$$\nr h_{i}=\\max \\left(d_{i 1} \\sum_{t=1}^{g-1}\\left(p_{i, Q_{t, t}}+t_{i, t+1}\\right)\\right)\n$$  \nStep 1.2 For batch $l=1$ to $h$, do\nAssign the first available machine $m_{g, k}$ to the $l^{\\text {th }}$ batch and calculate start time of each job in the $l^{\\text {th }}$ batch, as follows.  \n$$\ns_{g, k l_{j, i}}=\\max \\left(A T_{g, k}+u_{k}, r h_{i}\\right)+\\sum_{g=0}^{g-1} p_{g, k l_{k, i}}\n$$  \nWhere $A T_{g, k}$ is the available time of machine $m_{g, k}$ when a batch assigned. And its initial value is 0 .\nStep 2 Backward scheduling for upstream stages.\nWhile $i!=1$ set $i=i-1$, do.\nStep 2.1 Calculate the latest completion time of each job at the $i^{\\text {th }}$ stage according to the start time of the job $j$ at the $(i+1)^{\\text {th }}$ stage.  \n$$\nL C T_{i, j}=x_{i+1, j}-t_{i, j+1}\n$$  \nStep 2.2 Sort all jobs at the $i^{\\text {th }}$ stage according to $L C T_{i, j}$ in descending order, then select machine with the latest start time for job $j$.  \n$$\nm_{i, k}=\\arg \\left(\\max _{k \\in\\{1,2, \\ldots, n\\}}\\left(L C T_{i, j}-p_{i, j}, R A T_{i, k}-p_{i, j}\\right)\\right)\n$$  \nWhere $R A T_{i, k}$ is the reverse available time of the machine at the $i^{\\text {th }}$ stage. And its initial value is positive infinity.\nStep 3 Right shift.\nIf $\\min \\left(s_{i, j}\\right)<0$, then right shift all operations for $-\\min \\left(s_{i, j}\\right)$ units.\n[IMAGE_4]  \nRBM (Fig. 4) is a free energy-based neural network with binary nodes that can learn a probability distribution from large-scale input data set. Recently, with the development of efficient training algorithms for RBM (i.e., contrastive divergence, CD ), it has been widely applied in machine learning fields, such as feature extraction, dimensionality reduction, classification, collaborative filtering, and so on. Since those advantages of RBM, H Tang and VA proposed an RBM-based EDA [17] [18]. After the CD training algorithm is executed, the parameters of RBM, weights, biases, and hidden states, are obtained, the visible states can be estimated by trained model. So, we encode probability of each decision variable by RBM model, of which conditional probability is constructed by unobserved latent variables. This procedure is different from energy statistics method proposed at [17]. According to this idea, the probability model of EDA is obtained as follows.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:05",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to implement the offspring generation, specifically concerning the probabilities PEDA, PC, and the polynomial mutation operator?",
      "topics": [
        "mutation"
      ],
      "answer": "The code should implement a probabilistic branching structure for offspring generation. With probability PEDA, offspring are generated using Estimation of Distribution, where the mean of the top M% chromosomes' decision variables is used as the mean of a normal distribution, and the standard deviation is one-tenth of the difference of limits for each decision variable. With probability (1-PEDA)*PC, Simulated Binary Crossover is applied. Finally, with probability (1-PEDA)*(1-PC), a polynomial mutation operator is used. Each branch should produce a single offspring, which is then tested for acceptance into both the regular and archive populations.",
      "chunk_id": 12356,
      "paper_id": "A Hybrid Territory Defined evolutionary algorithm approach for closed loop green supply chain network design",
      "paper_title": "A Hybrid Territory Defined evolutionary algorithm approach for closed loop green supply chain network design",
      "paper_year": "2016",
      "chunk_content": "Three different procedures are used for offspring generation in the algorithm. With a probability of PEDA offspring is generated\n[IMAGE8]  \nFig. 9. Pareto optimal front comparison for case 5.\n[IMAGE9]  \nFig. 10. Pareto optimal front comparison for case 8.\nusing Estimation of Distribution. The procedure used for generation is, top $\\mathrm{M} \\%$ of the chromosomes from population are selected. Since using these values of the decision variable we get solutions of good quality, the mean of these values is used as estimates of the mean of normal distribution. The standard deviation of the normal distribution is assumed to be one tenth of the difference of limits for each decision variable. With probability $(1-P E D A) * P C$ offspring is generated using Simulated Binary Crossover operator as described in the NSGA II. With probability $(1-P E D A) *$ $(1-P C)$ offspring were generated using polynomial mutation operator.\nThe offspring is first tested for acceptance into regular population, and then it is tested for acceptance into archive population.  \n[IMAGE10]  \nFig. 11. Pareto optimal front comparison for case 9.\nThe evaluation procedure is as follows, first the offspring is tested for dominance. All the individuals that are dominated by offspring are marked, if offspring is dominated by at least one chromosome in $P(t)$, it is rejected and a new offspring is generated, otherwise\noffspring is accepted and a marked individual is randomly selected and removed from $P(t)$. If none of the individual is marked then a chromosome is randomly selected and removed.\nFor offspring to be accepted in archive population, it should not lie in the territory of any of the existing chromosomes in the archive population. The procedure is as follows, the offspring is tested for dominance, all the individuals dominated by offspring are marked, if it is dominated by any individual in $A(t)$ then it is rejected. If it is not dominated by any individual then all the marked individuals are removed from $A(t)$ and we calculate the scaled rectilinear distance of offspring from each chromosome. The chromosome with the minimum scaled rectilinear distance is selected and maximum scaled absolute objective difference is calculated between offspring and the selected chromosome for all the objectives. If it is more than the territory size the offspring is accepted in archive population else it is rejected and a new offspring is generated.  \nScaled Rectilinear Distance : $d_{i c}=\\sum_{j=1}^{m}\\left|f_{i j}-f_{i j}\\right|$  \nTable 9\nResult comparison for case 1.\nCase 1 Results  \nTable 10\nResult comparison for case 4.  \nTable 11\nResult comparison for case 5.\n$m=$ number of objective, $i=$ chromosome number varies from 1 to number of chromosomes in archive population, $f=$ normalized value of the objective function, $c=$ offspring chromosome.  \nMaximum Scaled Absolute Objective Difference : $\\delta$\n$=\\max \\left|f_{i j}-f_{i j}\\right|$\n$i^{\\circ}=$ chromosome with minimum scaled rectilinear distance, $f=$ normalized value of the objective function, FORMULA_237 offspring chromosome.",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:07",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model for the flexible job shop scheduling problem (FJSP)?",
      "topics": [
        "scheduling"
      ],
      "answer": "The effectiveness of the EDA model is evaluated using two specific metrics: C_max, which represents the makespan, and TEC, which represents the total electricity cost. TEC is further broken down into TEC_MP (machine processing), TEC_MS (machine setup), TEC_MI (machine idle), and TEC_MT (transportation electricity cost).",
      "chunk_id": 3407,
      "paper_id": "Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem",
      "paper_title": "Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem",
      "paper_year": "2023",
      "chunk_content": "Same as Ref [53], TOUEP is formulated as (4), where $n$ is a positive integer and the unit of time $t$ is the hour.  \n$$\nf(t)= \\begin{cases}5, & t \\in[24 n-3,24 n+7) \\\\ 8, t \\in[24 n+7,24 n+11) \\cup[24 n+17,24 n+21) \\\\ 10, & t \\in[24 n+11,24 n+17)\\end{cases}\n$$  \nIt can be observed from (4) that the TOUEP keeps the same regulation every day. The electricity price in a day time can be illustrated as Fig. 1. The TEC of a solution is the sum electricity cost of all price intervals according to the TOUEP setting.\n[IMAGE0]  \nFig. 1. TOUEP in a day.\nThis section provides the FJSP model. The objectives of the FJSP model are defined as (5-7).  \n$$\n\\begin{gathered}\n\\min \\left\\{C_{\\max }, T E C\\right\\}, \\\\\nC_{\\max }=\\max C_{i, j}, \\forall i, j \\\\\nT E C=T E C_{M P}+T E C_{M S}+T E C_{M I}+T E C_{M T}\n\\end{gathered}\n$$  \ns.t.  \n$$\n\\begin{gathered}\nP S_{i, j} \\geq P C_{i, j-1}, \\forall i, j=2, \\ldots, O F_{i} \\\\\nP C_{i, j} \\geq P S_{i, j}, \\forall i, j \\\\\nM S_{k, r} \\leq M C_{k, r}, \\forall k, r \\\\\nP S_{i, j}=M S_{k, r}, \\forall i, j, k, r, Y_{i, j, k, r}=1 \\\\\nP C_{i, j}=M C_{k, r}, \\forall i, j, k, r, Y_{i, j, k, r}=1 \\\\\nP S_{i, j} \\geq 0, \\forall i, j \\\\\n\\sum_{k=1}^{K} \\sum_{r=1}^{R} Y_{i, j, k, r}=1, \\forall i, j \\\\\n\\sum_{i=1}^{I} \\sum_{j=1}^{O C_{i}} Y_{i, j, k, r} \\leq 1, \\forall k, r \\\\\n\\sum_{i 1=1}^{I} Y_{i 1, j 1, k, r-1} \\geq \\sum_{i 2=1}^{I} Y_{i 2, j 2, k, r}, \\forall j 1, j 2, k, r=2, \\ldots, R \\\\\nP C_{i, j}-P S_{i, j}=p t_{i, j, k}^{*} / \\eta_{k}, \\forall i, j, k, r, s, Y_{i, j, k r}=1 \\wedge S_{i, j, s}=1 \\\\\nM S_{k, r} \\geq M C_{k, r-1}, \\forall k, r=2, \\ldots, R \\\\\nS C_{k, r}-S S_{k, r}=s t_{k, 0, \\Omega}, \\forall i 1, i 2, j 1, j 2, k, r=2, \\ldots, R \\\\\nY_{0, j 1, k, r-1}=1 \\wedge Y_{i 2, j 2, k, r}=1 \\\\\nS S_{k, r}=M C_{k, r-1}, \\forall k, r=2, \\ldots, R \\\\\nI S_{k, r} \\geq 0, \\forall k, r \\\\\nS S_{k, r} \\geq 0, \\forall k, r \\\\\nS C_{k, 1}-S S_{k, 1}=0, \\forall k \\\\\nI S_{k, 1}=0, \\forall k \\\\\nT C_{i, 1}-T S_{i, 1}=0, \\forall i\n\\end{gathered}\n$$  \n$$\n\\begin{gathered}\nS C_{k, r} \\geq S S_{k, r}, \\forall k, r \\\\\nI C_{k, r}=M S_{k, r}, \\forall k, r \\\\\nI C_{k, r} \\geq I S_{k, r}, \\forall k, r \\\\\nT C_{i, j}-T S_{i, j}=t t_{k 1, k 2}, \\forall i, j=2, \\ldots, O P_{i}, k 1, k 2, r 1, r 2 \\\\\nY_{i, j-1, k 1, r 1}=1 \\wedge Y_{i, j, k 2, r 2}=1 \\\\\nT S_{i, j} \\geq P C_{i, j-1}, \\forall i, j=2, \\ldots, O P_{i} \\\\\nP S_{i, j} \\geq T C_{i, j}, \\forall i, j\n\\end{gathered}\n$$  \n$L t p_{i, j, k, p-1, s} \\geq L t p_{i, j, k, p, s}, \\forall i, j, k, s, p=2, \\ldots, P$,  \n$$\n\\begin{gathered}\n\\sum_{i=1}^{I} \\sum_{j=1}^{O P_{i}} \\sum_{s=1}^{S} L t p_{i, j, k, p, s} \\leq L p_{p}, \\forall k, p \\\\\n\\sum_{p=1}^{P} L t p_{i, j, k, p}=\\frac{P C_{i, j}-P S_{i, j}}{s p_{s, k}}, \\forall i, j, k, r, s, Y_{i, j, k, r} \\\\\n=1 \\wedge S_{i, j, s}=1 \\\\\n\\sum_{p=1}^{P} L t s_{i, j, k, p}=S C_{k, r}-S S_{k, r}, \\forall i, j, k, r, Y_{i, j, k, r}=1 \\\\\n\\sum_{p=1}^{P} L t i_{i, j, k, p}=I C_{k, r}-I S_{k, r}, \\forall i, j, k, r, Y_{i, j, k, r}=1 \\\\\n\\sum_{p=1}^{P} L t t_{i, j, k, p}=T C_{i, j}-T S_{i, j}, \\forall i, j, k, r, Y_{i, j, k, r}=1 \\\\\nL t p_{i, j, k, p, s} \\geq 0, \\forall i, j, k, p, s \\\\\nL t s_{i, j, k, p} \\geq 0, \\forall i, j, k, p \\\\\nL t i_{i, j, k, p} \\geq 0, \\forall i, j, k, p \\\\\nL t t_{i, j, k, p} \\geq 0, \\forall i, j, k, p \\\\\n\\sum_{s=1}^{S} S_{i, j, s}=1, \\forall i, j\n\\end{gathered}\n$$  \n$$\nT E C_{M P}=\\sum_{i=1}^{I} \\sum_{j=1}^{O P_{i}} \\sum_{k=1}^{K} \\sum_{p=1}^{P} \\sum_{s=1}^{S}\\left(P t_{k, s} \\cdot L t p_{i, j, k, p} \\cdot E P_{p}\\right)\n$$  \nFORMULA_116  \nConstraint (8) guarantees that all operations of each job should be operated in sequence. Constraints (9) and (10) ensure that the completion time of each operation should be no earlier than\nits starting time. Constraints (11) and (12) are the links between job processing time and machine perspective, respectively. Constraint (13) indicates that the processing time of each operation is reasonable. Constraint (14) specifies that each operation should be operated by only one machine. Constraint (15) states that only one operation is performed at each processing priority of each machine. Constraint (16) ensures that operations are performed in priority order on each machine. Constraint (17) rules the processing time of each operation. Constraint (18) makes sure that no time overlapping is permitted in FJSP scheduling. Constraint (19) rules the setup time of each operation. Constraint (20) describes that the setup starting time is the completion time of the same-machine predecessor operation. Constraint (21) shows that the setup completion time is the idle starting time of each operation. Constraint (22) denotes that the setup time of each operation is reasonable. Constraints (23)-(25) indicate that the first performed operation of each machine does not need machine setup, idle time, and transportation time, respectively. Constraint (26) ensures that the setup completion time is no earlier than its setup starting time. Constraint (27) describes that the idle completion time is the starting time of each operation. Constraint (28) rules that the idle completion time is no earlier than its idle starting time. Constraint (29) rules the transportation time of each operation. Constraint (30) states that transportation begins when the same-job predecessor operation is completed. Constraint (31) guarantees that the job should be performed after transportation stage. Constraint (32) ensures that processing time is distributed in price intervals order. Constraint (33) ensures that the times in different price intervals are not overlapping. Constraints (34-37) calculate varying time stages under various electricity price intervals. All of the constraints on electricity price intervals are similar to those in Ref [5]. Constraints (38-41) ensure that all time is feasible under different electricity price intervals. Constraint (42) denotes that each operation only has one processing speed. Constraints (43-46) calculate the TEC of machine processing, machine setup, machine idle, and transportation, respectively.",
      "question_type": "evaluation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:08",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of the LBH model within the $EDA_{mvn}$ algorithm when solving MINLP problems with discontinuous feasible regions?",
      "topics": [
        "constraints"
      ],
      "answer": "The LBH model in $EDA_{mvn}$, when applied to MINLP problems, exhibits a vulnerability to being trapped in larger discontinuous feasible parts due to its tendency to find good candidate solutions in large areas while struggling with smaller areas. This behavior increases the probability of available values in larger parts and quickly discards smaller parts, leading to a loss of diversity and premature convergence to a local optimum. Even with decreasing penalty factor values to improve search in small discontinuous feasible parts, the precision to feasibility can be affected, potentially preventing the algorithm from finding a truly feasible solution.",
      "chunk_id": 1541,
      "paper_id": "An improved Estimation of Distribution Algorithm for Solving Constrained Mixed-Integer Nonlinear Programming Problems",
      "paper_title": "An improved Estimation of Distribution Algorithm for Solving Constrained Mixed-Integer Nonlinear Programming Problems",
      "paper_year": "2022",
      "chunk_content": "In [2], the authors showed the influence of the larger discontinuous feasible parts in the truncation and rounding techniques in MINLP problems. Unlike previous techniques, $E D A_{m v n}$ uses a direct integer-restriction-handling technique, since the LBH model directly generates integer values. In this section, we disclose the influence of those discontinuous parts on the LBH model. For that, the example in (12) is presented.  \n$$\n\\begin{gathered}\n\\operatorname{minimize} f(x, y)=2(x-1)^{2}+(y-3)^{2} \\\\\n\\text { subject to: } g(x, y)=x^{2}+y^{2}-4 \\leq 0 \\\\\nx \\in[-3,3] \\\\\ny \\in\\{-3,3\\}\n\\end{gathered}\n$$  \nIn the MINLP problem in (12), $x$ is a continuous variable and $y$ is a integer variable, both in the range between -3 and 3. The optimal solution is $f(0,2)=3$, as shown in Fig. 4(a). The shaded area represents the feasible region defined by the constraints, and the red zones are the discontinuous feasible parts that also satisfy the integer restrictions. Note in Fig. 4(b), the global optimal solution is located in a small discontinuous  \nfeasible part (upper red point). Local optimal solutions can be found in the larger discontinuous feasible parts.  \nThe MINLP problem in (12) was solved by $E D A_{m v n}$ and PSO for mixed-variable $\\left(P S O_{m v}\\right)$, to illustrate the vulnerability of the LBH model to being trapped in larger discontinuous feasible parts. $P S O_{m v}$ [10] is a hybrid approach that uses the LBH model as integer restrictions handler. The parameter values used by both algorithms were obtained by the calibration process explained in Section V-C.  \nFig. 5 shows the execution of $E D A_{m v n}$. In the 2 nd generation the population is in the exploration phase. However, in the 5th generation the entire population is located in the largest discontinuous feasible parts, as shown in Fig. 5(b). Therefore, the probability of the LBH model for the available value $y=2$ is zero. This inhibits any possibility of exploring the global optimum feasible region. In the later generations, the population tends to the best local optimum in the large discontinuous feasible parts, as shown in Figs. 5(c), 5(d). In $E D A_{m v n}$, the search in small discontinuous feasible parts improves when the penalty factor values decrease, since in regions close to feasibility parts low $C V(\\mathbf{x}, \\mathbf{y})$ are obtained. However, since the precision to the feasibility is affected by the penalization values, in many cases the algorithm does not get a real feasible solution.\nFORMULA_119 (see Fig. 6) also starts with a randomly generated population. It can be observed in Fig. 6(c) that, even in the 10th generation there are individuals exploring the region close to the global optimum. However, the population tends towards the best local optimal solution of the larger discontinuous feasible parts, as shown in Fig. 6(d).  \nIn summary, the LBH model finds good candidates in large areas with relative ease, but it only finds infeasible points around small areas. This behavior increases the probability of available values in larger parts, and quickly discards small parts that remain unexplored or poorly explored. Once the entire population enters the wrong part, the loss of diversity causes the population to be trapped in a local optimum.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:10",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of deterministic Single Airport Ground Holding Policy (SAGHP), what mathematical principles govern the assignment of ground holding time to flights to minimize total delay cost, and how are airport capacity constraints enforced in the model?",
      "topics": [
        "constraints"
      ],
      "answer": "In the deterministic SAGHP, the objective is to minimize the total delay cost, represented by the equation 'min <binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> <binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>=<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> GX', where 'G' represents the cost of flight 'i' arriving at time slot 'j', and 'X' is a binary variable that equals 1 if flight 'i' lands in period 'j' and 0 otherwise. The constraints ensure that each flight has exactly one arrival slot, expressed as '<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>=<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> X = 1 i  F', where 'F' is the set of all flights. Airport capacity constraints are enforced by the inequality '<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> X  K j  T', where 'K' is the airport capacity in slot 'j', and 'T' represents the set of all time slots. This constraint ensures that the number of flights landing in each time slot does not exceed the airport's capacity for that slot, balancing capacity and demand.",
      "chunk_id": 7894,
      "paper_id": "Research Survey and Application on Ground Holding Policy",
      "paper_title": "Research Survey and Application on Ground Holding Policy",
      "paper_year": "2019",
      "chunk_content": "If there is only one airport overcrowded, the capacity of airport could be estimated beforehand. Under the constraint\nof satisfying airport capacity, ground holding time of each flight is calculated, to minimize the total delay costs. The situation mentioned above is simplified as Single Airport Ground Holding Policy problem (SAGHP), which is shown in Fig. 1.  \nSAGHP makes assumption of the following:  \n1) During time period $[0, \\mathrm{~T}]$, there are totally N flights landing at destination airport Z , which are represented as set $F=\\{1,2, \\ldots, N\\}$;\n2) During time period $[0, \\mathrm{~T}]$, there is only one capacity constrained airport $Z$;\n[IMAGE0]  \nFig. 1. Single airport ground holding policy problem\n3) The time period $[0, T]$ can be equally divided into T slots: $1,2, \\ldots, \\mathrm{~T}$;\n4) Holding cost function is assumed in linear, under the reasonable air holding time (no longer than existing maximal air holding time), and other non-linear factors as safety are ignored;\n5) For each flight, the scheduled departure time and flight time of each air route are known. Cost of air delay and ground delay can be calculated by departure time given.  \nAs a sum, SAGHP is described as: for a given destination airport, under the constraints of airport capacity (AAR: airport arrival rate), assign ground holding time for each flight to minimize the total delay cost.  \nAirport capacity is defined as maximal landing airplanes during a given time period (usually 1 hour). If the forecasting capacity is static, the corresponding problem is called deterministic SAGHP, if impact of weather is considered, capacity of airport is not deterministic but stochastic. Usually the capacity is modeled as following some distribution, such as normal distribution. In that case, ground holding time and air holding time are required to be considered simultaneously. This problem is called stochastic SAGHP. In next subsection, several types of mathematic models are given in detail.\nThe capacity of airport Z is assumed to be known beforehand and defined as deterministic time based function [4]. The mathematic model of deterministic SAGHP is given:  \n$$\n\\begin{aligned}\n& \\min \\sum_{i=1}^{N} \\sum_{j=}^{m+1} G_{i j} X_{i j} \\\\\n& \\text { s.t. } \\sum_{j=m_{i}}^{m+1} X_{i j}=1 \\quad \\forall i \\in F \\\\\n& \\sum_{i=1}^{N} X_{i j} \\leq K_{j} \\quad \\forall j \\in T\n\\end{aligned}\n$$  \n$$\nX_{i j}=\\left\\{\\begin{array}{l}\n1, \\text { if flight } i \\text { landing in period } j \\\\\n0, \\text { else }\n\\end{array}\\right.\n$$  \nwhere $m_{i}$ represents the index of landing time period of flight $i, \\mathrm{G}_{\\mathrm{ij}}$ represents the cost of flight i arrival at time slot $j$, and $\\mathrm{K}_{\\mathrm{j}}$ is the airport capacity in slot $j$. Equation (2) ensures that each flight has one and only one arrival slot. Equation (3) is constraints of airport capacity for each slot, guaranteeing the balance between capacity and demand.",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:13",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm with resampling, how should practitioners enlarge the sampling region, specifically addressing the cases when $\\delta_{j}^{g}$ is greater than or less than $\\zeta$?",
      "topics": [
        "initialization",
        "resampling",
        "Estimation of Distribution Algorithm"
      ],
      "answer": "To enlarge the sampling region in an Estimation of Distribution Algorithm with resampling, first calculate $\\tau_{j}$ and $v_{j}$ as the maximum and minimum values of $z_{l, j}^{g}$ across all $l$ from 1 to $L$, for each dimension $j$ from 1 to $D$. If $\\delta_{j}^{g}$ is greater than $\\zeta$, set $U_{j}^{*}$ to $\\tau_{j}$ and $L_{j}^{*}$ to $v_{j}$. Otherwise, if $\\delta_{j}^{g}$ is not greater than $\\zeta$, set $U_{j}^{*}$ to $\\tau_{j} + \\operatorname{rand}(0,1)(U_{j} - \\tau_{j})$ and $L_{j}^{*}$ to $v_{j} - \\operatorname{rand}(0,1)(v_{j} - L_{j})$, where $\\operatorname{rand}(0,1)$ generates a random number between 0 and 1.",
      "chunk_id": 3094,
      "paper_id": "An Estimation of Distribution Algorithm With Resampling and Local Improvement for an Operation Optimization Problem in Steelmaking Process",
      "paper_title": "An Estimation of Distribution Algorithm With Resampling and Local Improvement for an Operation Optimization Problem in Steelmaking Process",
      "paper_year": "2024",
      "chunk_content": "Input: the initialization parameters of resampling.\n1: Enlarge the sampling region:\nFor $j=1: D$  \n$$\n\\tau_{j}=\\max _{1 \\leq l \\leq L} z_{l, j}^{g}, v_{j}=\\min _{1 \\leq l \\leq L} z_{l, j}^{g}\n$$  \nIf $\\delta_{j}^{g}>\\zeta$  \n$$\nU_{j}^{*}=\\tau_{j}, L_{j}^{*}=v_{j}\n$$  \nElse  \n$$\n\\begin{aligned}\nU_{j}^{*} & =\\tau_{j}+\\operatorname{rand}(0,1)\\left(U_{j}-\\tau_{j}\\right) \\\\\nL_{j}^{*} & =v_{j}-\\operatorname{rand}(0,1)\\left(v_{j}-L_{j}\\right)\n\\end{aligned}\n$$  \nEnd if\nEnd for\n2: Resampling:\nFor $o=1: 2 N P$\nFor $j=1: D$  \n$$\n\\hat{z}_{o, j}=L_{j}^{*}+\\operatorname{rand}(0,1)\\left(U_{j}^{*}-L_{j}^{*}\\right)\n$$  \nEnd for  \n$$\ns_{o}=\\left\\|\\hat{z}_{o}-z_{\\text {best }}\\right\\|_{2}\n$$\n3: Select $N P$ resampled individuals with the smallest $s_{o}$ to form a population. Evaluate the individuals in the population and select superior individuals from this population, and recalculate $\\boldsymbol{u}^{g}$ and $\\boldsymbol{\\delta}^{g}$ based on this set of superior individuals.\nOutput: the resampled population.  \nNote that resampling may be performed only when eva $<r_{-}$eva. For the first generation after eva FORMULA_139 (and only for this one generation), the overall best individual in the external archive is used to replace the current best individual.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:16",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the $r$-UMDA, under what mathematical conditions does the probability of the minimum value of $q_{i, 0}^{(s)}$ over the range $s \\in [0, T]$ being less than or equal to $\\frac{1}{2r}$ satisfy a specific upper bound, and what is that bound?",
      "topics": [
        "algorithm"
      ],
      "answer": "The probability that the minimum value of $q_{i, 0}^{(s)}$ over the range $s \\in [0, T]$ is less than or equal to $\\frac{1}{2r}$ is bounded above by $2 \\exp \\left(-\\frac{\\mu}{12 T r+(4 / 3) r}\\right)$, where $\\mu$ is a parameter, $T$ represents a time horizon, and $r$ is related to the $r$-valued variant of the LeAdingOnes problem on which the $r$-UMDA (Algorithm 2) is analyzed. This bound is obtained using stochastic domination to yield a tail bound for the function $f$.",
      "chunk_id": 2730,
      "paper_id": "Estimation-of-distribution algorithms for multi-valued decision variables",
      "paper_title": "Estimation-of-distribution algorithms for multi-valued decision variables",
      "paper_year": "2024",
      "chunk_content": "$$\n\\operatorname{Pr}\\left[\\min _{s \\in[0, T]} q_{i, 0}^{(s)} \\leq \\frac{1}{2 r}\\right] \\leq 2 \\exp \\left(-\\frac{\\mu}{12 T r+(4 / 3) r}\\right)\n$$  \nUsing the stochastic domination yields the tail bound for $f$.\nWe analyze the runtime of the $r$-UMDA (Algorithm 2) on an $r$-valued variant of LeAdingONes. We start by describing the previous runtime results of EDAs on LeAdingOnes (Section 6.1), then define the FORMULA_395-LeAdingOnes problem formally (Section 6.2), and finally state and prove our main result (Theorem 6, Section 6.3).",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:18",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "According to the details in the chunk, what advantages does the ACABC algorithm have over the standard ABC algorithm in terms of search efficiency and solution quality?",
      "topics": [
        "optimization"
      ],
      "answer": "The ACABC algorithm improves upon the ABC algorithm by incorporating ACEDA into the onlooker stage, creating a more intelligent onlooker mechanism. This mechanism sorts solutions based on fitness, constructs a probability distribution model using ACEDA from the best solutions, and samples from this distribution to generate new individuals. This ensures the new population follows the distribution of the dominant population. Furthermore, ACABC modifies the neighborhood search strategy using the gbest value and an adaptive parameter to enhance exploitation. The result is a faster convergence speed and greater precision compared to the standard ABC algorithm for most test functions.",
      "chunk_id": 4655,
      "paper_id": "Archimedean copula estimation of distribution algorithm based on artificial bee colony algorithm",
      "paper_title": "Archimedean copula estimation of distribution algorithm based on artificial bee colony algorithm",
      "paper_year": "2015",
      "chunk_content": "In this paper, we propose a novel hybrid algorithm called ACABC algorithm. The ABC algorithm is a biologicalinspired optimization algorithm with a random search process. In order to improve the search efficiency, we introduce ACEDA into the onlooker stage and propose a more intelligent onlooker mechanism. In the modified mechanism, onlookers first sort all solutions obtained by employed bees in descending order according to the fitness values, select excellent individuals to construct dominant population, then construct a probability distribution model based on ACEDA, and sample based on the estimated distribution to generate new individuals. The updating strategy ensures that the new population obeys the distribution of the dominant population. In addition, we modify the neighborhood search strategy with the gbest value by guiding the operator and the adaptive parameter to improve the exploitation of the algorithm. Experimental results show that the ACABC algorithm speeds up the convergent speed  \nwith greater precision for most test functions. In conclusion, the novel hybrid ACABC algorithms outperform the ABC algorithms and ACEDA.\n[IMAGE6]  \nHaidong Xu was born in 1990. She received her B.S. degree from Shandong University in June, 2012 in communication engineering and now she is an M.Sc. student in the same University. Her main research area includes artificial intelligence and computing intelligence, artificial neural network, swarm intelligence algorithms and mathematical statistics.\nE-mail: xu-hai-dong1990@163.com\n[IMAGE7]  \nMingyan Jiang was born in 1964. He received his M.S. degree from Shandong University in 1992 and his Ph.D. degree in 2005. He finished his postdoctoral research in Spain (CTTC) in communication signal and system in 2007. Now he is a full professor and a doctoral supervisor in the School of Information Science and Engineering in Shandong University, China. His research interests include soft computing, signal and image processing, computer network, artificial intelligence and data mining. He has published more than 200 professional papers and 6 books.\nE-mail: jiangmingyan@sdu.edu.cn\n[IMAGE8]  \nKun Xu was born in 1988. He received his B.S. degree from Shandong Normal University in June, 2011 in electronic information engineering and now is an M.Sc. student in Shandong University. His main research interests include machine learning, parallel computation, optimization and artificial intelligence.\nE-mail: xukunsdu@163.com",
      "question_type": "advantage",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:19",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA/L model, specifically regarding the local search components?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The EDA/L algorithm, a hybrid Estimation of Distribution Algorithm, uses two local search algorithms. First, for each new solution generated, the incomplete simplex method (Nelder and Mead) is applied for O(n) steps, where 'n' likely refers to the dimensionality of the problem. Then, if the result is deemed satisfactory, unconstrained optimization by diagonal quadratic approximation (UOBDQA) is applied to refine the solution further towards a local minimum.",
      "chunk_id": 13327,
      "paper_id": "Hybrid estimation of distribution algorithm for global optimization",
      "paper_title": "Hybrid Estimation of Distribution Algorithm for Global Optimization",
      "paper_year": "2004",
      "chunk_content": "Several EDAs have been proposed for solving global optimization problems. In these existing algorithms, the probability distribution of the promising solutions are modelled by a Gaussian distribution (Larranaga and Lozano, 2001), a Gaussian mixture (Bosman and Thierens, 2001) or a histogram (Tsutsui et al., 2001). Since many points are needed to build a good probability model, these algorithms are often very time-consuming in practice.  \nA very natural way to improve the performance of EAs is to hybridize local search with EAs. Indeed, the hybrid evolutionary approach, often called the memetic algorithm in the literature, has proved to be a very efficient algorithmic framework for solving hard optimization problems, particularly, hard combinatorial optimization problems (Baluja and Davies, 1997; Merz and Freisleben, 2000; Robles et al., 2001). In a hybrid EA, EA operators (such as crossover and mutation) generate a starting point, a local search method starts from this point and locates the corresponding local minimum. Due to the diversity provided by EA operators, the algorithm is less likely to be trapped in a local minimum, while the local search speeds up the convergence of the algorithm greatly. Very recently, Bosman and Thierens have hybridized their iterated density estimation evolutionary algorithm (IEDA) with the conjugate gradient algorithm for solving the global optimization problem (Bosman and Thierens, 2001). Their algorithm requires calculation of derivatives so it cannot  \nbe used in the case when the derivatives of the objective function $f(x)$ are not available.  \nIn this paper, we introduce a new hybrid EDA for global optimization which has been successful on a number of test problems. We refer to the algorithm as estimation of distribution algorithm with local search (EDA/L). Most existing hybrid EAs utilize one local search technique. In EDA/L approach, however, we use two local search algorithms. One is the incomplete simplex method (Nelder and Mead, 1965) and the other is unconstrained optimization by diagonal quadratic approximation (UOBDQA) (Powell, 2002). For every new solution that is generated in the initialization step or sampled from a probability model in EDA/L, we apply the downhill simplex method to it and only allow the simplex method to run $O(n)$ steps. Then, if the resultant solution of the incomplete simplex method is good enough, we apply UOBDQA to it. The incomplete simplex method helps to locate promising solutions more accurately while the role of UOBDQA is to find good local minima and hopefully the global minimum. The other feature of EDA/L is that it generates its initial population from $D$ by the uniform design technique (Fang and Wang, 1994). The uniform design technique can generate points in $D$ that are more evenly distributed in FORMULA_12 than points generated randomly. We study the effectiveness of main components of our proposed algorithm in this paper. The experimental results show that our algorithm is better than four recent EAs in terms of the solution quality and computational cost.",
      "question_type": "implementation focused",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:21",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the eEDA model compared to other algorithms, based on the provided convergence graphs?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The effectiveness of the eEDA is evaluated by comparing its convergence process with that of other algorithms like Genetic Algorithm (GA) and Tabu Search (TS). The Y-axis of the convergence graph represents the objective function value, which serves as a performance indicator. A lower objective function value at a given generation, and faster convergence to a lower value, indicates better performance. The evaluation considers both the speed of convergence and the final objective function value achieved.",
      "chunk_id": 8309,
      "paper_id": "Evolutionary Estimation of Distribution Algorithm for Agricultural Routing Planning in Field Logistics",
      "paper_title": "Evolutionary Estimation of Distribution Algorithm for Agricultural Routing Planning in Field Logistics",
      "paper_year": "2019",
      "chunk_content": "Fig. 6 depicts the convergence process of GA, TS, and eEDA for problems 20(a) and 90(b). The X-axis is the generation, while the Y-axis is the objective function value. GA's solution to problem 20 is worse than the others, while the one for Problem 90 is better than TS after half of the generations. TS converges the fastest in problem 90; however, it seems to be trapped in a local-optima since the solution is not improved after approximately a quarter of the total iterations. For both problems, eEDA's solution is always better than those of other algorithms. The eEDA's objective function converges fast and ends with the best solution compared to GA and TS. Overall, the eEDA's convergence process is better than those of GA and TS.  \nThe eEDA combines EDA and the permutation neighborhood search in its structure, enabling the algorithm to both explore and exploit the candidate solution. Both CW and TS focus only on exploiting the solutions without exploring it, while GA focuses only on exploring the solution. These reasons enable eEDA to outperform CW, GA, and TS.\n[IMAGE3]  \nFig. 4. The machine' route and solution for problem 12b.  \n[IMAGE4]  \nFig. 5. The eEDA's route for problem 90.\n[IMAGE_5]  \nFig. 6. The convergence graph for (a) Problem 20; and (b) Problem 90.\nThis study is a preliminary study that gathers several data from previous studies describing different rectangular fields in ARP. Then, an extended version of EDA, called Evolutionary EDA, is proposed to solve the ARP problem. This research conducts a comparative study of datasets from published experiments using different algorithms. The algorithms that are used for comparison are Clarke Wright, Genetic Algorithm, and Tabu Search. The experimental results demonstrate that eEDA outperforms the other algorithms.  \nSince there is no standard dataset in ARP, future research could focus on developing benchmark datasets with different sizes and layouts. The generation of ARP data for a practical purpose that considers actual situations can also be another focus of future study. The development of algorithms can also be regarded as another future research path, given that there is still a limited dominant algorithm for finding optimal solutions in ARP.\nThis research is supported by the LPDP - Indonesia Endowment Fund for Education, Ministry of Finance, Republic Indonesia.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:23",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs when evaluating SNP tagging, and how does Tree-EDA address this objective by considering SNP pairs?",
      "topics": [
        "selection"
      ],
      "answer": "The primary objective is to determine if considering pairs of tagging SNPs improves results compared to using only single tagging SNPs. Tree-EDA optimizes an objective function that measures the number of tagging SNPs. The algorithm uses parameters such as a population size of 5000, 100 generations, and truncation selection with a parameter T=15(%), employing a best elitism replacement strategy to avoid re-evaluating the fitness function of the best individuals. The algorithm stops when the maximum number of generations is reached or the population becomes too homogeneous, with no more than 10 different individuals.",
      "chunk_id": 7366,
      "paper_id": "Multi-marker tagging single nucleotide polymorphism selection using estimation of distribution algorithms",
      "paper_title": "Multi-marker tagging single nucleotide polymorphism selection using estimation of distribution algorithms",
      "paper_year": "2010",
      "chunk_content": "To evaluate the introduced algorithms, we used the HapMap reference panel [4]. As done in a previous work [9], samples over the ENCODE regions are used for the experiments. These data, from 270 individuals from four populations (people of European ancestry [CEU], Yoruba of Ibadan, Nigeria [YRI], Han Chinese [CHB], and Japanese [JPT]) are made up of polymorphisms over 10 genomic regions spanning a total 5 Mb of the sequence. These regions have been carefully studied and are believed to have complete ascertainment for SNPs with frequency higher than $\\%$.  \nTable 1 shows the details of 40 SNP problem instances used as benchmark for evaluating the algorithms. In the table, name refers to the HapMap region and population, $n$ is the total number of SNPs, $n^{\\prime}$ is the number of SNPs that can be tagged by another SNP or pair of SNPs (the rest of SNPs are fixed since they can be only selftagged), nPairs is the number of pairs of SNPs above the correlation threshold and similarly, nTriples is the number of triples such that the correlation of the tagged SNP given a pair of tagging SNPs is above the correlation threshold.\nGiven a data set $D$ consisting of $m$ haplotypes, first we compute the $r_{D}^{2}$ for each pair of SNPs $s_{i}$ and $s_{j}$. Those SNPs for which the frequency of the most probable allele is above 0.95 are not  \nTable 1\nDetails of the SNP problem benchmark.  \nconsidered. Then $r_{D, j j, k}^{2}$ is computed for $i \\neq j \\neq k$. Only pairs of SNPs that are in the sequence at a distance lower than $d=40,000$ are considered. The resulting set of all initial pairs and triples is reduced by eliminating those subsets of SNPs with an $r^{2}$ below the minimum threshold $r_{\\min }^{2}=0.8$.\nTree-EDA, as other approaches based on EDAs, has a set of parameters to be selected. In this work we have chosen some default values based on our experience, without looking exhaustively for the best combination. The population size was set to 5000 and the number of generations was set to 100 . Truncation selection with parameter $T=15(\\%)$ was employed. In this selection scheme, the best $T+N$ individuals of the population are selected to construct the probabilistic model. We apply a replacement strategy called best elitism in which the selected population at generation $t$ is incorporated into the population of generation FORMULA_158, keeping the best individuals found so far and avoiding to reevaluate their fitness function. The algorithm will stop when the maximum number of generations is reached or the selected population has become too homogeneous (no more than 10 different individuals).\nThe main goal of the experiments was to determine whether the consideration of pairs of tagging SNPs can improve the results achieved when only single tagging SNPs are used. Tree-EDA is used to optimize the objective function that measures the number of  \nTable 2\nResults achieved by SAT Tagger, Tagger and Tree-EDA for the 40 SNP problem instances.\ntagging SNPs. Since EDAs are stochastic methods, we conduct for each SNP problem a set of experiments and extract statistical information from the analysis of these experiments. The performance of Tree-EDA was evaluated considering the fitness of the best, average, and worst solutions found in all the experiments. The number of experiments conducted for each instance was 10 .",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:25",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of combining an Estimation of Distribution Algorithm (EDA) with an Immune Genetic Algorithm (IGA) optimize the population generation process?",
      "topics": [
        "comparison"
      ],
      "answer": "The Estimation of Distribution Algorithm (EDA) is combined with the Immune Genetic Algorithm (IGA) to optimize the population generation process by calculating the distribution probability of excellent populations and selecting these populations for iteration. This enhances the population quality during the IGA's genetic selection process, leading to continuous optimization, improvement, and ultimately, the attainment of the optimal solution. The EDA optimizes the population update process such as genetic selection of the IGA.",
      "chunk_id": 3502,
      "paper_id": "Research on gas emission quantity prediction model based on EDA-IGA",
      "paper_title": "Research on gas emission quantity prediction model based on EDA-IGA",
      "paper_year": "2023",
      "chunk_content": "Peng Ji ${ }^{\\mathrm{a}}$, Shiliang Shi ${ }^{\\mathrm{a}, \\mathrm{b}}$, Xingyu Shi ${ }^{\\mathrm{c}, *}$${ }^{a}$ College of Resource Environment and Safety Engineering, Hunan University of Science and Technology, Xiangtan 411201, China${ }^{\\mathrm{b}}$ Provincial Key Laboratory of Safe Mining Techniques of Coal Mines Hunan University of Science and Technology, Taoyuan Road, Yuhu District,Xiangtan, Hunan Province, 411201, China${ }^{\\text {c }}$ Changsha University of Science \\& Technology, Wanjiali Road, Tianxin District, Changsha, Hunan Province, 410114, China\nKeywords:\nGas emission quantity\nImmune genetic algorithm\nEstimation of distribution algorithm\nPrediction  \nA B S T R A C T  \nIn order to accurately predict the possible gas emission quantity in coal mines, it is proposed to use the multi-thread calculation of the Immune Genetic Algorithm (IGA) and injection of vaccines to improve the accuracy of prediction and combine the Estimation of Distribution Algorithm (EDA) to the distribution probability of excellent populations. Calculating, and selecting excellent populations for iteration, optimize the population generation process of the Immune Genetic Algorithm, so that the population quality is continuously optimized and improved, and the optimal solution is obtained, thereby establishing a gas emission quantity prediction model based on the Immune Genetic Algorithm and Estimation of Distribution Algorithm. Using the 9136 mining face with gas emission hazards in a coal mine from Shandong Province in China as the prediction object, the absolute gas emission quantity is used to scale the gas emission quantity, and it is found that the model can accurately predict the gas emission quantity, which is consistent with the on-site emission unanimous. In the prediction comparison with IGA, it is found that the accuracy of the prediction results has increased by $9.51 \\%$, and the number of iterations to achieve the required goal has been reduced by $67 \\%$, indicating that the EDA has a better role in optimizing the population update process such as genetic selection of the IGA. Comparing the prediction results of other models, it is found that the prediction accuracy of the EDA-IGA is FORMULA_8, which is the highest prediction accuracy, indicating that this prediction model can be used as a new method for the prediction of coal mine gas emission. Accurately predicting the gas emission quantity can provide guidance for safe mining in coal mines. The gas emission quantity can also be used as a safety indicator to reduce the possibility of coal mine accidents, ensure the personal safety of coal miners and reduce economic losses in coal mines.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:26",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm based on the model of Jarboui et al. [10] for scheduling problems, how should practitioners modify the set $\\Omega_{k}$ to reduce computational complexity from $O(n^{2})$ to $O(n)$ during the construction of new individuals?",
      "topics": [
        "complexity"
      ],
      "answer": "To reduce the complexity from $O(n^{2})$ to $O(n)$, practitioners should modify the set $\\Omega_{k}$ (the set of unscheduled jobs until position $k$) into $\\Omega_{kq}$. The latter set, $\\Omega_{kq}$, should be composed of only $q$ jobs that are not yet scheduled, following their order in a randomly selected parent sequence $s_{0}$ until position $k$. This limits the search space during the construction of new individuals, achieving linear time complexity.",
      "chunk_id": 6730,
      "paper_id": "An Estimation of Distribution Algorithm for Flowshop Scheduling with Limited Buffers",
      "paper_title": "An Estimation of Distribution Algorithm for Flowshop Scheduling with Limited Buffers",
      "paper_year": "2009",
      "chunk_content": "Fig. 1 EDA procedure\nnumber of times job $j$ comes immediately after the job at the position $k-1$ in the new individual from the sequences of the selected parents. This parameter is used to highlight the importance of similar blocks in the sequence. $\\Omega_{k}$ represents the set of jobs not already scheduled until position $k$. According to this model, the task of constructing new offspring has a complexity order of $O\\left(n^{2}\\right)$. Although this model provides a good solution quality, it consumes high CPU times, especially when the size of the problem increases. In this work, we propose an improvement to the model of Jarboui et al. [10] by reducing its complexity. First, a sequence of jobs $s_{0}$ is selected, at random, among the $M$ selected parents. Then, the probabilistic model is built like the one described above while modifying the set $\\Omega_{k}$ into $\\Omega_{k q}$. The latter set is composed of $q$ jobs not already scheduled, following their order in $s_{0}$, until position $k$. So, while comparing the model proposed here and the one proposed by Jarboui al. [10], we find that the phase of construction of new individual requires a linear time $O(n)$ in this proposed model. Moreover, this formulation grants more intensification to the algorithm. The pseudo-code of the EDA is given in Fig. 1.",
      "question_type": "practical application",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:29",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Histogram Estimation of Distribution Algorithm (HEDA) discussed, how does the algorithm's reliance on replacing the old population with the new population in each generation affect its exploration of the search space, and what are the potential consequences for convergence, specifically in terms of avoiding local optima?",
      "topics": [
        "search"
      ],
      "answer": "In the described HEDA, the complete replacement of the old population with the new population in each generation is intended to increase the searching space. The rationale is to avoid premature convergence to local optima. However, the provided text does not include any formal convergence proofs or guarantees for this HEDA variant. Instead, the performance is evaluated empirically on Reversible Lanes Optimization Problems (RLOP) by comparing it against a Genetic Algorithm (GA) using metrics such as the Wilcoxon rank-sum test to assess significant differences in results, without providing mathematical bounds on convergence rate or solution quality.",
      "chunk_id": 8256,
      "paper_id": "A Histogram Estimation of Distribution Algorithm for Reversible Lanes Optimization Problems",
      "paper_title": "A Histogram Estimation of Distribution Algorithm for Reversible Lanes Optimization Problems",
      "paper_year": "2019",
      "chunk_content": "After building histogram model, we could generate offspring by their probability in each iteration. The Eq. (9) shows the probability of $n^{\\mathrm{m}}$ decision variable equals to $j$ in $t^{\\mathrm{m}}$ generation, where max $_{n}$ denotes the maximum value that $n^{\\mathrm{m}}$ variable could take. Because of the previous normalization operations, the height of each bins are also normalized (10). For simplicity, in this edition of HEDA we just use the new population to replace the old one, which could increase the searching space of HEDA and avoid falling into local areas.  \n$$\n\\begin{gathered}\nP_{n}^{i}(j)=\\frac{H_{n}^{i}(j)}{\\sum_{i=0}^{n^{\\max }} H_{n}^{i}(i)} \\\\\n\\sum_{i=0}^{n^{\\max }} H_{n}^{i}(i)=1\n\\end{gathered}\n$$\nIn this section, to show the process and performance of proposed method in RLOP, we arrange several experiments on specific network instances. First, we present a detail explanation about how HEDA works on RLOP. A specific instance is presented in this part. Second, to evaluate the performance of HEDA, several problem instances are simulated both in HEDA and genetic algorithm (GA). Since the GA is also a metaheuristic method and was original designed in discrete space, we believe these two algorithms are comparable in RLOP.\nThe parameters settings are shown in Table I. The crossover probability and the mutation probability follow literature [31].  \nTABLE I\nPARSHUPTIES SETTINGS  \nFor test instances, we generate two different size of networks with the same mesh structure manually. One contains 9 nodes and the other contains 16 nodes. About the characteristic of roadways, the free flow cost $t_{0}^{0}$ is generated randomly between 0 to 0.1 ; the feasible unit lane capacity $K_{a}$ are among set $\\{2.5,5,7.5,10\\} ; n_{a}$ are randomly chosen in set $\\{1,2,3,4\\}$. The O-D pair demands are uniformly distributed between 0 and 1 except that the destination point is the last node. The O-D pair demands that reach the last node are uniformly distributed over (3.0, 4.0). The reason why we set O-D demands like this is that we want to simulate the asymmetric flow as authentic as possible.  \nAdditionally, it is worthwhile to mention that all results are averaged over 30 independent simulations and all experiments are conducted on a PC with Intel(R) Core (TM) (7-7700 3.60GHz CPU, 8Gb memory. Besides, the Wilcoxon rank-sum test is carried out to show that the results have significant difference between HEDA and GA.",
      "question_type": "theoretical foundation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:30",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Based on the provided information, how does the probability calculation \\(p_{i}(x)\\) relate to the counts \\(\\operatorname{count}(D_{j} \\leq \\xi)\\) and \\(\\operatorname{count}(D_{j})\\) in the context of Estimation of Distribution Algorithms (EDAs)?",
      "topics": [
        "optimization"
      ],
      "answer": "The probability \\(p_{i}(x)\\) is calculated as the ratio of \\(\\operatorname{count}(D_{j} \\leq \\xi)\\) to \\(\\operatorname{count}(D_{j})\\), where \\(\\operatorname{count}(D_{j} \\leq \\xi)\\) represents the number of elements in \\(D_{j}\\) that are less than or equal to \\(\\xi\\), and \\(\\operatorname{count}(D_{j})\\) represents the total number of elements in \\(D_{j}\\). This ratio is used within an EDA to estimate the probability of a variable \\(x\\) based on observed data.",
      "chunk_id": 7577,
      "paper_id": "A learning strategy for multi-robot based on probabilistic evolutionary algorithm",
      "paper_title": "A Learning Strategy for Multi-robot Based on Probabilistic Evolutionary Algorithm",
      "paper_year": "2010",
      "chunk_content": "___________,____________,______  \n$$\np_{i}(x)=\\frac{\\operatorname{count}\\left(D_{j} \\leq \\xi\\right)}{\\operatorname{count}\\left(D_{j}\\right)}\n$$  \n, $j \\square\\{1,2, \\ldots, n\\}, t$ _ $t$  $\\square$  $\\xi$ _____, $\\mathrm{P}_{t}(x)<\\mathrm{P}_{t+1}(x)$ , $t+1$ _________ $t$ , $\\xi$ _,___ $\\mathrm{DB}(q, f)$ ___",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:32",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDAMA model, specifically detailing how the Simulated Annealing (SA) local search is integrated and how solutions are selected for this local search?",
      "topics": [
        "search"
      ],
      "answer": "The EDAMA model integrates SA-based local search after Step 7 of the standard EDA. First, each solution is assigned a probability based on its performance using the rank-based fitness assignment technique. Then, the roulette wheel mechanism is used to select solutions based on their assigned probabilities; solutions with higher probabilities are more likely to be selected. Subsequently, the selected solutions undergo SA-based local search with a predefined probability $p_{t s}$. The initial temperature for SA is calculated as $t_{0}=-\\left(c_{t s}-c_{b}\\right) / \\ln p_{t}$, where $c_{t s}$ is the worst objective value, $c_{b}$ is the best objective value, and $p_{t}$ is the acceptance probability of the worst solution compared to the best. An exponential cooling schedule, $t_{k}=\\lambda t_{k-1}$, with $0<\\lambda<1$, is then applied.",
      "chunk_id": 7222,
      "paper_id": "Controlling Chaos by an Improved Estimation of Distribution Algorithm",
      "paper_title": "CONTROLLING CHAOS BY AN IMPROVED ESTIMATION OF DISTRIBUTION ALGORITHM",
      "paper_year": "2010",
      "chunk_content": "Starting from an initial state, simulated annealing (SA) randomly generates a new state in the neighborhood of the original one, which causes a change of $\\Delta E$ in the objective function value. For minimization problems, the new state is accepted with probability $\\min \\{1, \\exp (-\\Delta E / T)\\}$, where $T$ is a control parameter. SA provides a mechanism to probabilistically escape from local optima and the search process can be controlled by the cooling schedule [12].  \nIn EDAMA, SA-based local search is inserted after Step 7 in EDA to enrich the local searching behaviors and to avoid premature convergence. Based on its performances, each solution is assigned a probability to be selected by the rank-based fitness assignment technique [10]. Then, the roulette wheel mechanism [10] is used to decide which solutions will be selected. Subsequently, the selected solutions will perform the SA-based local search with a predefined probability $p_{t s}$. Due to the mechanism of roulette wheel rule, good solution will gain more chance for exploitation. Besides, it is easy to control such an exploitation process by adjusting the value of $p_{t s}$. Moreover, for the parameter settings of SA, proper initial temperature should be high enough so that all states of the system have an equal probability of being visited and at the same time it should not be rather high so that a lot of unnecessary searches in high temperature will be avoided. In EDAMA, an initial temperature is set as $t_{0}=-\\left(c_{t s}-c_{b}\\right) / \\ln p_{t}$, where $c_{t s}$ and $c_{b}$ denote the worst and best objective values in the initial population, respectively; $p_{t}$ denotes the acceptance probability of the worst solution compared with the best one. Exponential cooling schedule, $t_{k}=\\lambda t_{k-1}, 0<\\lambda<1$, is applied, which is believed to be an excellent cooling recipe, since it provides a rather good compromise between a computationally fast schedule and the ability to reach low-energy state.\nAs a typical discrete chaotic system, Henon Map is described as follows.  \n$$\n\\left\\{\\begin{array}{l}\nx_{1}(k+1)=-p x_{1}^{2}(k)+x_{2}(k)+1 \\\\\nx_{2}(k+1)=q x_{1}(k)\n\\end{array}\\right.\n$$  \nwhere $p=1.4$, and $q=0.3$.\nConsider (P1) first, the target $\\mathbf{x}_{1}$ is set to be a fixed point $(0.63135,0.18941)^{T}$.  \nLet $\\mathbf{x}_{0}=(0,0)^{T}$, and $u(k)$ is only added to $x_{1}$ with the bound $\\mu=0.01$. To test the performance of EDAMA, EDAMA is compared with standard EDA and SA. In EDAMA, the population size is 100 , the maximum generation is $200, p_{0}=0.1$, $p_{e}=0.05$, and cooling rate $\\lambda=0.9$. In EDA, the population size is 100 , and the maximum generation is 200 . In SA, $p_{e}=0.05, \\lambda=0.9$, the step of Metropolis sampling process under each temperature is set to 1000 , and the maximum generation is set to 20 . Under different values of $N$, Table 1 lists the mean objective value and the best objective value of 100 independent runs for each of the above three algorithms. From Table 1, it can be seen that EDAMA is superior to EDA and SA in term of searching quality and derivation of the results. It could be concluded that EDAMA is more effective and more robust on initial conditions.  \nTable 1 Statistics performance of EDAMA, EDA and SA under different FORMULA_96",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:34",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How is the probability vector \\(P_{r}^{t}(i, k, j)\\) in the \\(t_{th}\\) generation for the \\(r_{th}\\) population calculated in \\(PMBGNP_{M}\\), and what roles do the connection information and transition information between nodes play in this calculation?",
      "topics": [
        "algorithm"
      ],
      "answer": "In \\(PMBGNP_{M}\\), the probability vector \\(P_{r}^{t}(i, k, j)\\) is calculated as \\(\\frac{\\sum_{n \\in N}\\left(\\delta_{n}^{t}(i, k, j)+\\eta \\sigma_{n}^{t}(i, k, j)\\right)}{\\sum_{j \\in \\bar{A}(i, k)} \\sum_{n \\in N}\\left(\\delta_{n}^{t}(i, k, j*)+\\eta \\sigma_{n}^{t}(i, k, j*)\\right)}\\), where \\(N\\) is the set of suffixes of elite individuals, \\(A(i, k)\\) is the set of suffixes of connected nodes from the \\(k_{th}\\) branch of node \\(i\\), \\(\\delta_{n}^{t}(i, k, j)\\) is 1 if the \\(k_{th}\\) branch of node \\(i\\) in individual \\(n\\) is connected to node \\(j\\) in the \\(t_{th}\\) generation (0 otherwise), \\(\\eta\\) is a coefficient, and \\(\\sigma_{n}^{t}(i, k, j)\\) represents the number of times the transition from the \\(k_{th}\\) branch of node \\(i\\) to node \\(j\\) occurs in individual \\(n\\) in the \\(t_{th}\\) generation. Connection information, represented by \\(\\delta_{n}^{t}(i, k, j)\\), indicates whether a direct connection exists between nodes, while transition information, represented by \\(\\sigma_{n}^{t}(i, k, j)\\), captures the frequency of transitions between nodes during problem-solving, weighting the probability calculation based on how often a specific node transition is utilized in elite individuals.",
      "chunk_id": 7203,
      "paper_id": "Probabilistic model building Genetic Network Programming using multiple probability vectors",
      "paper_title": "Probabilistic Model Building Genetic Network Programming Using Multiple Probability Vectors",
      "paper_year": "2010",
      "chunk_content": "For a population $r(r \\in R)$, the probabilistic model of population $r$ is represented as a probability vector $P_{r}$. The connection probabilities between different nodes are considered to construct the probabilistic model of $\\mathrm{PMBGNP}_{M}$. The probability vectors are used by learning the structure of promising individuals. For the $r_{t h}$ population, $P_{r}^{t}$ denotes the probability vector in the $t_{t h}$ generation, and $P_{r}^{t}(i, k, j)$ represents the connection probability from the $k_{t h}$ branch of node $i$ to node $j$. The probability vector $P_{r}^{t}$ is composed of a set of $P_{r}^{t}(i, k, j)$.  \nFig. 3 shows the procedure to carry out the probabilistic model. $\\mathrm{PMBGNP}_{M}$ selects a set of elite individuals from the\n[IMAGE2]  \nFig. 3. The procedure of $\\mathrm{PMBGNP}_{M}$ to construct the probabilistic model.\n[IMAGE3]  \nFig. 4. An example of node transition.\n$r_{t h}$ population. The probability vector $P_{r}$ consists of all the structure information of the elite individuals. For example, the information of the $k_{t h}$ branch of node $i$ is used to obtain various probabilities to connect to the next node, such as $P(i, k, 1), P(i, k, 2), \\ldots$ etc.  \nThese connection probabilities are calculated by considering the connection information and transition information between different nodes. The reason why we consider these two factors is as follows. In GNP, the directed graph structure is based on the connections of different nodes by branches. Therefore, the connection information is the most important information which deserves to be studied. On the other hand, in GNP, usually not all the nodes are used for transition to solve the problems in one individual. The node transition is made by selecting the necessary nodes. In an example shown in Fig. 4 , the nodes are transited like $P_{1} \\rightarrow J_{2} \\rightarrow J_{3} \\rightarrow J_{6} \\rightarrow P_{3}$ to solve the problems, which means the information on the connections between these transited nodes is useful for solving the problems.  \nTherefore, for the $r_{t h}$ population, the probability vector in the $t_{t h}$ generation is calculated as follows.\n$P_{r}^{t}(i, k, j)=\\frac{\\sum_{n \\in N}\\left(\\delta_{n}^{t}(i, k, j)+\\eta \\sigma_{n}^{t}(i, k, j)\\right)}{\\sum_{j \\in \\in \\bar{A}(i, k)} \\sum_{n \\in N}\\left(\\delta_{n}^{t}(i, k, j*)+\\eta \\sigma_{n}^{t}(i, k, j*)\\right)}$,\nwhere,\n$N$ : set of suffixes of elite individuals.\n$A(i, k)$ : set of suffixes of connected nodes from the $k_{t h}$ branch of node $i$.\n$\\delta_{n}^{t}(i, k, j):$ value defined by  \n$$\n\\delta_{n}^{t}(i, k, j)=\\left\\{\\begin{array}{cl}\n1 & \\text { if the } k_{t h} \\text { branch of node } i \\text { in } \\\\\n& \\text { individual } n \\text { is connected to } \\\\\n& \\text { node } j \\text { in the } t_{t h} \\text { generation, } \\\\\n0 & \\text { otherwise. }\n\\end{array}\\right.\n$$  \n$\\eta$ : coefficient.\n$\\sigma_{n}^{t}(i, k, j)$ : value defined by\n$\\sigma_{n}^{t}(i, k, j)=\\ell \\quad$ if the transition from the $k_{t h}$ branch of node $i$ to node $j$ in individual $n$ occurs $\\ell$ times in the $t_{t h}$ generation.\nBesides, the following exponential smoothing method is considered to update the current probabilistic model considering the previous generation's probability vectors.  \n$$\nP_{r}(i, k, j) \\leftarrow(1-\\alpha) P_{r}(i, k, j)+\\alpha P_{r}^{t}(i, k, j)\n$$  \nHere, the coefficient $\\alpha$ can be considered as a smoothing rate and $\\alpha \\in(0,1)$.  \nAfter modeling the probability distribution, the probabilistic model consists of $|R|$ probability vectors with regard to all the populations, which could be denoted as follows.  \n$$\nP=\\left\\{P_{r} \\mid r \\in R\\right\\}\n$$  \n$$\nP_{r}=\\left\\{P_{r}(i, k, j) \\mid i \\in I, k \\in A(i), j \\in A(i, k)\\right\\}\n$$  \nwhere,\n$R$ : set of suffixes of populations.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:38",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of the algorithmic approach detailed for EDAs in the context of V2G-enabled energy scheduling?",
      "topics": [
        "testing"
      ],
      "answer": "The EDA-based approach is applied to handle large-scale V2G enabled energy scheduling by explicitly extracting global statistical information from promising solutions, making it less susceptible to local minima and the non-linear characteristics inherent in V2G problems.",
      "chunk_id": 4934,
      "paper_id": "Intelligent PHEV charging and discharging strategy in smart grid",
      "paper_title": "Intelligent PHEV Charging and Discharging Strategy in Smart Grid",
      "paper_year": "2012",
      "chunk_content": "Fig 4 shows the deep discharge effect on the battery cycle life in V2G mode. Fig 5 shows the battery\ndegradation cost ( $\\$ / \\mathrm{kWh}$ ) of different types of batteries with respect to DoD. Fig 6 compares the overall cost/profit with 3 types of PHEV/PEV batteries in V2G mode.\n[IMAGE4]  \nFig. 4 Battery Cycle Life in V2G Mode\n[IMAGE5]  \nFig. 5 Battery Degradation Cost in V2G Mode\n[IMAGE6]  \nFig. 6 Variation of Cost/Profit with Different Types of Batteries in V2G Mode (Case 1 and 2)\nThe profit-to-cost ratio is defined as FORMULA_142\nThe comparison listed in Table III is also in favor of LiIon battery in V2G application.  \nTABLE III\nProfit-cost Ratio with Different Types of Batteries  \nAccording to the simulation results, Li-Ion battery technology is the best candidate among three major battery technologies for V2G application. EV battery technology is not fully ready for a frequent switch between charging/discharging modes. The high opportunity cost of  \nbatteries still prevents V2G from becoming a reality in near-term. At the current stage, the V2G economics are in favor of Li-Ion battery technology.  \nThe issues with the commercially available batteries in the vehicle application include, but are not limit to: 1) Battery energy and power densities need to be further improved; 2) Battery life is an issue; 3) Battery safety must be assured, especially during fast charging and in hot weather; 4) Battery cost needs to be significantly reduced; 5) The power electronics technologies that interface the battery with the grid and the motor must be further improved to increase efficiency and reduce weight.  \nTo the authors' best knowledge, most published work related to V2G concept mainly focus on the demonstration of the V2G capability. The mathematical framework and simulation results presented in this paper can be used as a reference for the policy maker and utilities to further access the cost and benefits of the commercial deployment of V2G in the near future.\nIn this paper, the authors described the optimal energy management for a real-world PHEV/PEV parking deck with V2G capability from a mathematical perspective. In this model, the authors also considered the constraints imposed by the battery charging limit, the power line capacity, the desired departure SOC, certain battery requirements. In order to enable the smooth integration of PHEVs/PEVs into the power grid, the authors have applied an EDA-based approach to handle a large-scale V2G enabled energy scheduling.  \nIn this paper, the authors used a PC to perform the calculations for algorithm testing. The simulation results were given to demonstrate the effectiveness of the proposed EDA-based approach in solving V2G problems at a municipal PHEV/PEV parking deck. Since an EDA explicitly extract global statistical information from promising solutions, it is immune to the potential local minimum and the non-linear nature of the problem. The simulation results also demonstrated that the algorithm converged to a better solution than some of the more traditional methods. In the future work, the temperature condition will be also taken into account to further model the battery degradation cost.  \nHowever, it is important to mention that V2G technology is still in the early deployment stage due to certain technical and economical issues. Although V2G is a promising concept, the following two major issues might delay its real-world implementation in the short term: 1) a two-way power/communication enabled system infrastructure; and 2) an unproven business model and economic justification.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:39",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of varying the cooling rate and maximum number of iterations within the Gibbs sampler impact the exploration-exploitation balance in the described evolutionary approach?",
      "topics": [
        "evolutionary"
      ],
      "answer": "The evolutionary approach adjusts the cooling rate, denoted as 'r' and calculated as `r=1+(g^{2} / 10)`, and the maximum number of iterations, denoted as 'I' and calculated as `I=1 / 20 g`, of the Gibbs sampler over generations 'g'. In early generations, a higher cooling rate and fewer iterations favor exploration, allowing the algorithm to sample broadly. As the model fits more closely to the fitness function in later generations, reducing the cooling rate and increasing the maximum number of iterations encourages exploitation, focusing the search on promising regions identified during exploration. This dynamic adjustment aims to prevent premature convergence to suboptimal solutions.",
      "chunk_id": 6950,
      "paper_id": "Structure learning and optimisation in a Markov-network based estimation of distribution algorithm",
      "paper_title": "Structure Learning and Optimisation in a Markov-network based Estimation of Distribution Algorithm",
      "paper_year": "2009",
      "chunk_content": "Based on the poor results for the single-step algorithm it is worth determining whether an evolutionary approach would be able to overcome the issues with poor structure.  \nOne important change was a reduction in the run time for the Gibbs sampler. With this algorithm there is no longer an assumption that a model with a close fit to the fitness function will be found in the first generation. This means that areas of high probability within the model will not necessarily be areas of high fitness, and running the Gibbs sampler slowly to convergence is likely to result in an individual of inferior fitness to the global optimum. The algorithm was initially run with a fixed value for cooling rate and maximum number of iterations. It was found that performance was improved by varying these parameters over the course of the evolution - reducing the cooling rate and increasing the maximum number of iterations with each generation. This allowed the algorithm to be balanced towards exploration in early generations and exploitation in later ones as the model fits more closely to the fitness function. For each generation $g$, the cooling rate $r$ was calculated according to (8) and the maximum number of iterations of the Gibbs sampler $I$ was calculated according to (9). The parameters for these were determined empirically to yield the best results.  \n$$\n\\begin{gathered}\nr=1+\\left(g^{2} / 10\\right) \\\\\nI=1 / 20 g\n\\end{gathered}\n$$  \nWe also adopted a steady-state approach for the algorithm, replacing $5 \\%$ of the population each generation. This allows\n[IMAGE1]  \nFig. 2: Fitness Model Statistics for EvDEUM- $\\chi^{2}$ on 25bit 2D Ising lattice over 30 runs\n[IMAGE2]  \nFig. 3: Fitness Model Statistics for EvDEUM- $\\chi^{2}$ on 100bit 2D Ising lattice over 30 runs\nus to use a large population for the structure learning component and maintain diversity for as long as possible.  \n1. Generate random initial population $\\pi$\n2. Select a subset $\\sigma_{1}$, the top $25 \\%$ of $\\pi$\n3. Run Chi-Square edge detection algorithm to search for statistical dependencies apparent in $\\sigma_{1}$\n4. Refine structure\n5. Select a subset $\\sigma_{2}$, the top 1.1 N of $\\pi$\n6. Use $\\sigma_{2}$ to build MFM\n7. Calculate $C_{r}$\n8. Sample $R$ new individuals from MFM using random walk Gibbs sampler and replace poorest $R$ individuals in FORMULA_111 with these",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:42",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing a branch and bound algorithm to solve the bi-objective Next Release Problem, what specific steps should practitioners take to maximize pruning efficiency and avoid degenerating into an exhaustive search?",
      "topics": [
        "optimization"
      ],
      "answer": "To maximize pruning efficiency in the branch and bound algorithm for the bi-objective NRP, practitioners should prioritize pruning at the beginning of a branch. This involves evaluating whether a modified partial solution fulfills NRP interactions as early as possible in the search tree. Specifically, after setting \\(r_i = 1\\) in a partial solution during the algorithm's execution, the algorithm must immediately check if the modified partial solution fulfills all NRP interactions. If any interaction is not fulfilled, the algorithm should prune that branch, avoiding further exploration of requirement sets derived from that partial solution. The algorithm's worst-case running time is \\(O(k \\cdot b^d)\\), where \\(b\\) is the branching factor, \\(d\\) is the depth, and \\(k\\) is the time to explore a partial solution; effective pruning reduces the explored portion of the search tree, mitigating the exponential complexity.",
      "chunk_id": 3307,
      "paper_id": "An estimation of distribution algorithm based on interactions between requirements to solve the bi-objective Next Release Problem",
      "paper_title": "An estimation of distribution algorithm based on interactions between requirements to solve the bi-objective Next Release Problem",
      "paper_year": "2023",
      "chunk_content": "Branch and bound algorithms (Morrison et al., 2016) are indicated for finding exact solutions to NP-hard optimization problems, like the bi-objective NRP. In this particular problem, they explore the search space by building a search tree, whose nodes will be sets of requirements. Instead of generating each combination of requirements and testing if it satisfies all the interactions to be a solution to the NRP problem (i.e. exhaustive search), we can start from an empty solution and try to add (or not) a requirement following an ancestral ordering (i.e. branch), discarding this partial solution as soon as any of the interactions are not fulfilled (i.e. bound). Algorithm 1 shows this process in detail. Note that pruning is done in the if-sentence, when the modified partial solution does not fulfil any of the NRP interactions.\nData: A bi-objective NRP and $\\sigma$ an ancestral ordering of its requirements\nResult: The set of solutions for the bi-objective NRP\nCreate an empty list of partial solutions;\nfor each $r_{i}$ following the ancestral ordering $\\sigma$ do\nCreate an empty list of modified partial solutions;\nwhile the list of partial solutions is not empty do\nTake a partial solution from the list;\nSet $r_{i}=0$ in the partial solution;\nAdd the modified partial solution to the list of modified partial solutions;\nSet $r_{i}=1$ in the partial solution;\nif the modified partial solution fulfils NRP interactions then\nAdd the modified partial solution to the list of modified partial solutions;\nend\nend\nThe list of modified partial solutions becomes the list of partial solution list;\nend\nReturn the solutions in the partial solution list;\nThe algorithm performance depends on pruning. It will be more efficient if pruning is done at the beginning of a branch. Whilst, if no pruning is done, the algorithm will degenerate into an exhaustive search. Thus, the worst-case running time for the branch and bound algorithm (Morrison et al., 2016) is $O\\left(k \\cdot b^{d}\\right)$, where $b$ is the search tree branching factor, $d$ is the depth of this tree and $k$ is a bound on the time needed to explore a partial solution. Fig. 4 illustrates how the brunch and bound algorithm explores the search space for the 5 requirements bi-objective NRP problem using $\\sigma_{1}=\\left\\{r_{01}+r_{05} \\prec r_{03} \\prec r_{04} \\prec r_{02}\\right\\}$ as ancestral ordering. Requirement sets depicted in red indicate that interactions are not fulfilled and, if possible, pruning is applied, avoiding the exploration of 8 requirement sets which means avoiding exploring $25.81 \\%$ of the search tree.  \n[IMAGE2]  \nFig. 3. Transformation of exclusion interactions.\n[IMAGE_3]  \nFig. 4. Branch and bound search tree. The requirement sets are represented between braces, 1 indicates that the requirement is included, 0 that it is not included and - that it is pending to be included or not.",
      "question_type": "application",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:44",
      "generation_style": "practical_application"
    },
    {
      "question": "Within the Variable Neighborhood Search (VNS) component described, how does the repetition time \\(R\\) for the neighborhood structures (LS, LI, LM, GM, and GE) change based on the current iteration number \\(Gen\\), and what is the rationale behind this adjustment?",
      "topics": [
        "fitness"
      ],
      "answer": "The repetition time \\(R\\) for the neighborhood structures LS, LI, LM, GM, and GE, denoted as \\(R_{\\mathrm{LS}}, R_{\\mathrm{LI}}, R_{\\mathrm{LM}}, R_{\\mathrm{GM}}\\), and \\(R_{\\mathrm{GE}}\\) respectively, varies depending on the current iteration number \\(Gen\\). When \\(1 \\leq \\operatorname{Gen} \\leq 100\\), global and local strategies are equally important. For \\(101 \\leq \\operatorname{Gen} \\leq 200\\), the repetition times of global strategies decrease, while the repetition times of local strategies increase. Finally, when \\(Gen\\) satisfies FORMULA_514 (the exact condition is not specified but implies a later stage), the repetition of local strategies is enhanced. The rationale is that in the initial stages, job distribution across factories significantly impacts the solution, so both global and local searches are crucial. As the algorithm progresses, adjusting scheduling within factories becomes more effective, leading to increased emphasis on local strategies.",
      "chunk_id": 8868,
      "paper_id": "A hybrid estimation of distribution algorithm for distributed flexible job shop scheduling with crane transportations",
      "paper_title": "A hybrid estimation of distribution algorithm for distributed flexible job shop scheduling with crane transportations",
      "paper_year": "2021",
      "chunk_content": "The local move (LM) neighborhood structure is employed to generate a neighbor solution by changing the assigned machine of an operation that has the maximum machine makespan. Fig. 9 illustrates the LM procedure, and the detailed steps of LM are as follows.  \nStep 1. Identify the machine that has the maximum machine makespan.\nStep 2. Select an operation at random that is assigned to the machine.\nStep 3. Change the assigned machine for the operation to another available machine that belongs to the same factory.\nThe global move (GM) neighborhood structure is utilized to generate a neighbor solution by moving all operations of one job from one factory to another factory. Fig. 10 illustrates the LM procedure, and the detailed steps of LM are as follows.  \nStep 1. In the factory vector, select a job and change its factory assignment.  \nStep 2. In the scheduling vector, select all operations of the job, and change their assigned factory to another factory.  \nStep 3. In the machine assignment vector, change the assigned machines of the moved operations. The assigned machines are in the new factory, and the machines are assigned randomly from a set of available machines.\nThe global exchange (GE) neighborhood structure is employed to generate a neighbor solution by exchanging the operations of two jobs from different factories. Fig. 11 illustrates the GE procedure, and the detailed steps of GE are as follows.  \nStep 1. Randomly select two jobs from different factories.  \n[IMAGE7]  \nFig. 8. Local insert neighborhood structure.\n[IMAGE8]  \nFig. 9. Local move neighborhood structure.  \nStep 2. In the factory vector, exchange the factory assignment of the two jobs.  \nStep 3. In the scheduling vector, select all operations of the two jobs and exchange their assigned factories with each other.  \nStep 4. In the machine assignment vector, change the assigned machines of the moved operations. The assigned machines are in the new factory, and the machines are assigned randomly from a set of available machines.\nIn every iteration of the VNS component, only one neighborhood structure is used to generate new individuals. The repetition time $R$ for LS, LI, LM, GM, and GE is $R_{\\mathrm{LS}}, R_{\\mathrm{LI}}, R_{\\mathrm{LM}}, R_{\\mathrm{GM}}$, and $R_{\\mathrm{GE}}$, respectively. In each repetition, the original solution and generated solution are compared, and the better solution is retained. The repetition time $R$ for neighborhood structures differs based on the current iteration number Gen (for the first iteration, Gen is set to 1). In the initial stage of itera-\ntion process, the job distribution of factories has great influence on the solution outcome; therefore, we set global strategies and local strategies are equally important when $1 \\leq \\operatorname{Gen} \\leq 100$. Later, the job distribution of most individuals are reasonable, so adjusting scheduling in factories can improve the quality more effectively. As a consequence, when 101 $\\leq \\operatorname{Gen} \\leq 200$, we decrease the repetition times of global strategies and increase that of local strategies. For the later stage, the temporary best individual has a satisfying fitness, making global strategies hard to obtain better new best individuals; so, we enhance the repetition of local strategies for exploiting better individuals when Gen FORMULA_514.  \nTo improve the proposed algorithm, the five neighborhood structures are organized into eight groups. The detailed process of the VNS component is illustrated in Algorithm 2.",
      "question_type": "theory",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:46",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What advantage does the proposed Local Linear Wavelet Neural Network (LLWNN) offer over the standard Wavelet Neural Network (WNN) in high-dimensional spaces with sparse data, according to the provided details?",
      "topics": [
        "performance"
      ],
      "answer": "The Local Linear Wavelet Neural Network (LLWNN) introduces a linear model \\(v_{i} = \\omega_{i 0} + \\omega_{i 1} x_{1} + \\ldots + \\omega_{i n} x_{n}\\) in place of the direct weight \\(\\omega_{i}\\) used in the standard Wavelet Neural Network (WNN). This substitution aims to provide a more parsimonious interpolation when modeling samples are sparse in high-dimensional spaces, potentially reducing the number of hidden units needed compared to the WNN which requires many units due to the crudeness of local approximations.",
      "chunk_id": 12934,
      "paper_id": "Stock index modeling using EDA based Local Linear Wavelet Neural Network",
      "paper_title": "Stock index modeling using EDA based Local Linear Wavelet Neural Network",
      "paper_year": "2005",
      "chunk_content": "In terms of wavelet transformation theory, wavelets in the following form  \n$$\n\\begin{gathered}\n\\Psi=\\left\\{\\Psi_{i}=\\left|\\mathbf{a}_{i}\\right|^{\\frac{1}{2}} \\phi\\left(\\frac{\\mathrm{x}-\\mathrm{b}_{\\mathrm{i}}}{\\mathrm{a}_{\\mathrm{i}}}\\right): \\mathrm{a}_{\\mathrm{i}}, \\mathrm{~b}_{\\mathrm{i}} \\in \\mathrm{R}^{\\mathrm{n}}, \\mathrm{i} \\in \\mathrm{Z}\\right\\} \\\\\n\\mathrm{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) \\\\\n\\mathrm{a}_{\\mathrm{i}}=\\left(a_{i 1}, a_{i 2}, \\ldots, a_{i n}\\right) \\\\\n\\mathrm{b}_{\\mathrm{i}}=\\left(b_{i 1}, b_{i 2}, \\ldots, b_{i n}\\right)\n\\end{gathered}\n$$  \nare a family of functions generated from one single function $\\psi(x)$ by the operation of dilation and translation. $\\psi(x)$,  \nwhich is localized in both the time space and the frequency space, is called a mother wavelet and the parameters $a_{i}$ and $\\mathrm{b}_{i}$ are named the scale and translation parameters, respectively. The x represents inputs to the WNN model.  \nIn the standard form of wavelet neural network, the output of a WNN is given by  \n$$\nf(x)=\\sum_{i=1}^{M} \\omega_{i} \\Psi(x)=\\sum_{i=1}^{M} \\omega_{i}\\left|a_{i}\\right|^{-\\frac{i}{2}} \\psi\\left(\\frac{x-b_{i}}{a_{i}}\\right)\n$$  \nwhere $\\psi_{i}$ is the wavelet activation function of $i$ th unit of the $\\omega_{i}$ is the weight connecting the $i$ th unit of the hidden layer to the output layer unit. Note that for the $n$-dimensional input space, the multivariate wavelet basis function can be calculated by the tensor product of $n$ single wavelet basis functions as follows  \n$$\n\\psi(x)=\\prod_{i=1}^{n} \\psi\\left(x_{i}\\right)\n$$  \nObviously, the localization of the $i$ th units of the hidden layer is determined by the scale parameter $a_{i}$ and the translation parameter $b_{i}$. According to the previous researches, the two parameters can either be predetermined based upon the wavelet transformation theory or be determined by a training algorithm. Note that the above wavelet neural network is a kind of basis function neural network in the sense of that the wavelets consists of the basis functions.  \nNote that an intrinsic feature of the basis function networks is the localized activation of the hidden layer units, so that the connection weights associated with the units can be viewed as locally accurate piecewise constant models whose validity for a given input is indicated by the activation functions. Compared to the multilayer perceptron neural network, this local capacity provides some advantages such as the learning efficiency and the structure transparency. However, the problem of basis function networks is also led by it. Due to the crudeness of the local approximation, a large number of basis function units have to be employed to approximate a given system. A shortcoming of the wavelet neural network is that for higher dimensional problems many hidden layer units are needed.  \nIn order to take advantage of the local capacity of the wavelet basis functions while not having too many hidden units, here we propose an alternative type of wavelet neural network. The architecture of the proposed LLWNN [8] is shown in Fig.1. Its output in the output layer is given by  \n$$\ny=\\sum_{i=1}^{M}\\left(\\omega_{i 0}+\\omega_{i 1} x_{1}+\\ldots+\\omega_{i n} x_{n} \\Psi_{i}(x)\\right.\n$$  \n$$\n=\\sum_{i=1}^{M}\\left(\\omega_{i 0}+\\omega_{i 1} x_{1}+\\ldots+\\omega_{i n} x_{n}\\right)\\left|a_{i}\\right|^{-\\frac{i}{2}} \\psi\\left(\\frac{x-b_{i}}{a_{i}}\\right)\n$$  \nwhere $x=\\left[x_{1}, x_{2}, \\ldots, x_{n}\\right]$. Instead of the straightforward weight $\\omega_{i}$ (piecewise constant model), a linear model  \n$$\nv_{i}=\\omega_{i 0}+\\omega_{i 1} x_{1}+\\ldots+\\omega_{i n} x_{n}\n$$  \nis introduced. The activities of the linear models $v_{i}(i=1,2, \\ldots M)$ are determined by the associated locally active wavelet functions $\\psi_{i}(x)(i=1,2, \\ldots M)$, thus $v_{i}$ is only locally significant. The motivations for introducing the local linear models into a WNN are as follows: (1) Local linear models have been studied in some neurofuzzy systems and shown good performances [18], [19]; and (2) Local linear models should provide a more parsimonious interpolation in high-dimension spaces when modeling samples are sparse.  \nThe scale and translation parameters and local linear model parameters are randomly initialized at the beginning and are optimized by a EDA discussed in the following section.\n[IMAGE_0]  \nFig. 1. A local linear wavelet neural network",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:48",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the SPEDA algorithm to leverage the benefits of combining Gaussian and CKDE nodes, particularly for high-dimensional problems (D=50) where pure CKDE approaches like mKEDA may falter?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "SPEDA",
        "CKDE",
        "Gaussian models",
        "high-dimensional optimization"
      ],
      "answer": "To effectively implement SPEDA, the architecture should facilitate a hybrid approach where both Gaussian and CKDE nodes are utilized. Specifically, the code should allow for a modular combination of these nodes within the probabilistic model. For D=50, emphasis should be placed on optimizing the interaction between Gaussian and CKDE components, as the text suggests that this combination scales better than using CKDEs alone, as seen in the mKEDA algorithm. This could involve adaptive mechanisms to dynamically adjust the weights or influence of each node type during the optimization process, based on performance metrics such as the function evaluations (FEV) and convergence rate observed during runtime. The code should also facilitate the efficient computation and updating of the CKDEs to maintain a low standard deviation in the results, as this is a noted advantage of using CKDEs within SPEDA.",
      "chunk_id": 2460,
      "paper_id": "Semiparametric Estimation of Distribution Algorithms for Continuous Optimization",
      "paper_title": "Semiparametric Estimation of Distribution Algorithms for Continuous Optimization",
      "paper_year": "2024",
      "chunk_content": "Table III shows the mean and standard deviation of the FEV of each algorithm after 25 independent runs for each of the benchmarks with $D=50$, where the best results for each function are highlighted in blue.  \nAs in the 30-D case, SPEDA improves the results found by EMNA, EGNA, and mKEDA, although mKEDA provides competitive results compared to our approach. Although it is not as remarkable as in the case of $D=30$, SPEDA provides the lowest variance among the results found in almost all benchmarks, since the use of the CKDEs reduces it. This\n[IMAGE9]  \nFig. 8. Mean best cost found FEV by SPEDA for the cec143 for different archive lengths ( $l$ ) during runtime after executing each experiment 25 independent times.\nis the case in $\\mathrm{m}_{\\mathrm{n}} \\mathrm{KEDA}$, which also shows a low standard deviation, compared to the other EDAs. The results show that SPEDA is able to converge to the best solutions in 30 out of the 49 functions. The main competitor for the SPEDA approach in this comparison is L-SHADE, reaching the best solution in 22 out of the 49 functions. Moreover, L-SHADE outperforms the results found by SPEDA in 17 functions and SPEDA outperforms L-SHADE in 18 functions.  \nSPEDA achieves the best results for all the unimodal functions except for the cec142, in which CMA-ES, SHADE, and L-SHADE win it. Regarding the separable functions (cec148 and cec1410), SPEDA converges to the best solution in all runs for both cases. Regarding the hybrid functions, L-SHADE approach is the best in this characteristic, followed by our proposal. SPEDA is the only approach able to find the best results in composition functions, as in the 30 dimensions case. Note that, in the case of $D=30, \\mathrm{~m}_{\\mathrm{n}} \\mathrm{KEDA}$ achieved good results for these functions, while no such results are shown in the case of $D=50$. This may suggest that the combination of Gaussian and CKDE nodes scales better from the optimization point of view, compared to the exclusive use of CKDEs. Finally,  \nTABLE III\nMean and Standard Deviation of FEV APTR 25 Executions on All Benchmark Functions With 50 Variables ( $D=50$ ) Obtained From the EMNA, EGNA, SPEDA, mKEDA, CMA-ES, JADE, SHADE, and L-SHADE Algorithms. The Best  \nregarding the optimization of functions where the number of local optima is large, SPEDA is the best performing algorithm ( 6 out of 10 ), as in the 30 dimensions case, followed by CMA-ES ( 5 out of 10 ).\nThe results shown in Table III have been statistically analyzed. Fig. 9 shows the credibility intervals ( $5 \\%$ and $95 \\%$ quantiles) and expected probability of winning (green dots) for results shown in Table III.\n[IMAGE10]  \nFig. 9. Credible intervals ( $5 \\%$ and $95 \\%$ quantiles) and expected probability of winning (green dots) for $f=0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:51",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the performance of the EDA model for the Electric Vehicle Charging Scheduling Problem (EVCSP)?",
      "topics": [
        "optimization"
      ],
      "answer": "The performance of the Hybrid Markov network and Mallows model-based EDA (HMM-EDA) is evaluated in terms of the gap from the best solution with respect to the objective, when compared against methods like constraint programming (CP), simulated annealing (SA), discrete particle swarm optimization (PSO), and artificial bee colony (ABC). The benchmark used is based on a sample station with three lines and 180 charging points, considering arrival and due times.",
      "chunk_id": 1341,
      "paper_id": "An EDA-based method for solving electric vehicle charging scheduling problem under limited power and maximum imbalance constraints",
      "paper_title": "An EDA-based method for solving electric vehicle charging scheduling problem under limited power and maximum imbalance constraints",
      "paper_year": "2022",
      "chunk_content": "[IMAGE_1]  \nFig. 1. A general structure of an EV charging station with multiple charging points in three charging lines (Garcia-Alvarez et al., 2018).\nand EDAs are competent in handling the possible relations among decision variables (Kacprzyk \\& Pedrycz, 2015).  \nThe strength of EDAs is in their search mechanism that can learn and adapt itself according to the problem. They are rooted in evolutionary computing and machine learning. From the evolutionary perspective, they have adopted using a population of promising solutions that evolve iteratively by performing selection and variation steps. They also adopted the idea of data-driven modeling from machine learning in which a probabilistic model is learned based on a population of previously visited reasonable solutions, and the resulting model is used to infer where other reasonable solutions might be (Kacprzyk \\& Pedrycz, 2015).  \nOur EDA-based proposed approach comprises two EDAs: a Markov network-based EDA (MN-EDA) and a Mallows model-based EDA (MMEDA) algorithms. We called our proposed method \"HMM-EDA\" after the Hybrid Markov network and Mallows model-based EDA. The reason for this hybridization is that we model the EVCSP with two types of decision variables; (1) assignment of each EV to a charging line and (2) sequence of all EVs charging. Markov network is a suitable model for dealing with the interaction among variables (Shakya et al., 2012). Due to the shared power supply in our considered EVCSP, EVs interact with each other once they seize a power line. So, MN-EDA is proposed to handle charging line assignment while considering these interactions. In addition, by considering EV sequence as a permutation problem, we offered MM-EDA since the Mallows model is a suitable approach for permutation modeling (Zangari et al., 2017). It is worth mentioning that permutation problems are defined as ordering specific symbols where two symbols cannot have the same position, and two positions cannot belong to the same symbol (Ceberio et al., 2012).  \nThe proposed method is evaluated using the benchmark introduced in (Garcia-Alvarez et al., 2018). This benchmark is obtained from a sample station with three lines where each line has 60 charging points ( 180 charging points in total). It includes arrival times and due times corresponding to the expected behavior of real users in different situations. Even though the charging line assignment is pre-determined in this benchmark, we have also considered this assignment as a decision variable due to specific features of our generalized problem.  \nTo compare the performance of the HMM-EDA with other solving methods, we proposed a constraint programming (CP) model since it provides an optimal solution for our problem. Moreover, we solved our problem with state-of-art meta-heuristic methods, including simulated\nannealing (SA), discrete particle swarm optimization (PSO), and artificial bee colony (ABC). Results are compared in terms of the gap from the best solution with respect to the objective, showing the superiority of the proposed HMM-EDA.  \nThe contributions of this study are as follows:  \n1. According to the literature, it is assumed that the assignment of each EV to the charging lines is known. However, in this study, new decision variables are added to the problem formulation for handling EV assignment, which is very important for real-world applications. It is worth mentioning that solving the more generalized form of this EVCSP has not been addressed in the literature yet.",
      "question_type": "evaluation metrics",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:52",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "Based on the text, what is the main conclusion regarding the performance comparison between the OBCEDA algorithm and other algorithms, specifically GA and TS, across varying numbers of orders ($n$) and article capacities ($K$)?",
      "topics": [
        "comparison"
      ],
      "answer": "The performance comparison reveals that there is generally no statistically significant difference in variance between the OBCEDA algorithm and the GA or TS algorithms, indicating similar stability, with performance being the same in 100% of trials at a significance level of $\\alpha=0.01$. However, OBCEDA's average performance was superior to GA in 37 out of 50 trials when $n=60$ and $K=75$, while there was no significant difference in averages in most other scenarios of $n$ and $K$.",
      "chunk_id": 4740,
      "paper_id": "A continuous estimation of distribution algorithm for the online order-batching problem",
      "paper_title": "A continuous estimation of distribution algorithm for the online order-batching problem",
      "paper_year": "2015",
      "chunk_content": "Table 3 Comparison of results for each average with $n=30, K=75$  \nTable 4 Comparison of results for each variance with $n=30, K=75$  \nThere is no statistically significant difference between samples  \nTable 5 Comparison of results for each average with $n=60, K=45$\nTable 6 Comparison of results for each variance with $n=60, K=45$  \nThere is no statistically significant difference between samples  \nAccording to Table 6, there is no statistically significant difference between variances of both algorithms. The performance was the same in 50 of the 50 trials with $\\alpha=0.01$ of significance level. We consider that the stability of both algorithms is practically the same ( $100 \\%$ of the time).  \nTable 7 details the average obtained for each trial when the total number of orders is 60 and the $K$ capacity is 75 articles. We analyze the performance between averages of GA and OBCEDA algorithms.  \nOn Table 7, there is a significant difference between the averages of both algorithms. The performance of OBCEDA was superior in 37 of the 50 trials.  \nTable 8 shows the variance obtained for each trial. We analyze whether there is a statistically significant difference between variances of both algorithms.  \nBased on Table 8, there is no statistically significant difference between variances of both algorithms. The performance was the same in 50 of the 50 trials with $\\alpha=0.01$ of significance level. We consider that the stability of both algorithms is practically the same ( $100 \\%$ of the time).  \nThe same GA is used for comparison with the primary approach, i.e., batch probability matrix in the same stochastic nature of the order-picking warehouse.  \nTable 9 details the average obtained for each trial when the total number of orders is 30 and the $K$ capacity is 45 articles. We analyze the performance between averages of both algorithms.  \nAs we can see in Table 9, there is no a significant difference between the averages of both algorithms.  \nTable 10 shows the average obtained for each trial when the total number of orders is 30 and the $K$ capacity is 75 articles. We analyze the performance between averages of both algorithms.  \nOn Table 10, there is no a significant difference between the averages of both algorithms.  \nTable 11 details the average obtained for each trial when the total number of orders is 60 and the $K$ capacity is 45 articles. We analyze the performance between averages of both algorithms.  \nAccording to Table 11, there is no a significant difference between the averages of both algorithms.  \nTable 12 shows the average obtained for each trial when the total number of orders is 60 and the $K$ capacity is 75 articles. We analyze the performance between averages of both algorithms.  \nBased on Table 12, there is no a significant difference between the averages of both algorithms.  \nTable 13 details the average obtained for each trial when the total number of orders is 30 and the $K$ capacity is 45 articles. We analyze the performance between averages of TS and OBCEDA algorithms.  \nAs we can see in Table 13, there is no a significant difference between the averages of both algorithms. The performance of OBCEDA was almost equal to the TS performance.  \nTable 7 Comparison of results for each average with $n=60, K=75$\nTable 8 Comparison of results for each variance with $n=60, K=75$  \n*There is no statistically significant difference between samples  \nTable 9 Comparison of results for each average  \nTable 10 Comparison of results for each average",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:49:54",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms for learning Bayesian networks, what mathematical principles govern the penalized maximum likelihood score, specifically contrasting the general formula with the K2 metric's calculation of the marginal likelihood?",
      "topics": [
        "complexity"
      ],
      "answer": "The penalized maximum likelihood score, used in some EDAs for Bayesian network structure learning, aims to maximize the likelihood of the data given the structure while penalizing model complexity. This score is calculated as $\\sum_{i=1}^{n} \\sum_{j=1}^{q_{i}} \\sum_{k=1}^{r_{i}} N_{i j k} \\log \\frac{N_{i j k}}{N_{i j}}-f(N) \\sum_{i=1}^{n} q_{i}\\left(r_{i}-1\\right)$, where $N_{i j k}$ represents the number of cases where variable $X_{i}$ has value $x_{i}^{k}$ and its parents $\\mathbf{P a}_{i}$ have their $j$th value, $N_{i j}$ is the sum of $N_{i j k}$ over all $k$, $q_{i}$ is the number of possible instances of the parents of $X_i$, $r_i$ is the number of possible values of $X_i$, and $f(N)$ is a penalization function, often the Jeffreys-Schwarz criterion (BIC) with $f(N)=\\frac{1}{2} \\log N$. In contrast, the K2 metric computes the log marginal likelihood $p(D \\mid S)$ directly as $\\prod_{i=1}^{n} \\prod_{j=1}^{q_{i}} \\frac{\\left(r_{i}-1\\right) !\\left(N_{i j}+r_{i}-1\\right) !}{\\prod_{k=1}^{r_{i}} N_{i j k} !}$, assuming independent cases and a uniform prior distribution over the parameters given the structure. The penalized maximum likelihood score explicitly includes a complexity penalty term $f(N)$, while the K2 metric implicitly incorporates a complexity penalty through the structure of the formula and its Bayesian derivation.",
      "chunk_id": 13230,
      "paper_id": "Learning Bayesian networks in the space of structures by estimation of distribution algorithms",
      "paper_title": "Learning Bayesian networks in the space of structures by estimation of distribution algorithms",
      "paper_year": "2003",
      "chunk_content": "$\\mathbf{X}=\\left(X_{1}, \\ldots, X_{n}\\right)$ denotes an $n$-dimensional random variable and $\\mathbf{x}=$ $\\left(x_{1}, \\ldots, x_{n}\\right)$ represents one of its possible instances. If the variable $X_{i}$ has $r_{i}$ possible values $x_{i}^{1}, \\ldots, x_{i}^{r_{i}}$, the local distribution, $p\\left(x_{i} \\mid \\mathbf{p a}_{i}^{j, S}, \\boldsymbol{\\theta}_{i}\\right)$ is an unrestricted discrete distribution $p\\left(x_{i}^{k} \\mid \\mathbf{p a}_{i}^{j, S}, \\boldsymbol{\\theta}_{i}\\right)=\\theta_{i_{j}^{k} \\mid \\mathbf{p a}_{i}^{j}} \\equiv \\theta_{i j k}$, where $\\mathbf{p a}_{i}^{j, S}, \\ldots, \\mathbf{p a}_{i}^{q_{j}}, S$ denotes the values of $\\mathbf{P a}_{i}^{S}$, the set of parents of the variable $X_{i}$ in the structure $S$. The term $q_{i}$ denotes the number of possible different instances of the parent variables of $X_{i}$. Thus, $q_{i}=\\prod_{X_{g} \\in \\mathbf{P a}_{i}} r_{g}$. The local parameters are given by $\\boldsymbol{\\theta}_{i}=$ $\\left(\\left(\\theta_{i j k}\\right)_{k=1}^{r_{i}}\\right)_{j=1}^{q_{i}}$. In other words, the parameter $\\theta_{i j k}$ represents the conditional probability of variable $X_{i}$ being in its $k$ th value, knowing that the set of its parent variables is in its $j$ th value. We represent by $D=\\left\\{\\mathbf{x}_{1}, \\ldots, \\mathbf{x}_{N}\\right\\}$ a database with $N$ cases. The information contained in $D$ is used to learn the Bayesian network structure $S$.  \nUsing the maximum likelihood estimate for $\\theta_{i j k}\\left(\\hat{\\theta}_{i j k}=N_{i j k} / N_{i j}\\right.$ where $N_{i j k}$ denotes the number of cases in $D$ in which the variable $X_{i}$ has the value $x_{i}^{k}$ and $\\mathbf{P a}_{i}$ has its $j$ th value and $N_{i j}=\\sum_{k=1}^{r_{i}} N_{i j k}$ ), and incorporating some form of penalty model complexity into the maximized likelihood, we obtain a general formula for the penalized maximum likelihood score as  \n$$\n\\sum_{i=1}^{n} \\sum_{j=1}^{q_{i}} \\sum_{k=1}^{r_{i}} N_{i j k} \\log \\frac{N_{i j k}}{N_{i j}}-f(N) \\sum_{i=1}^{n} q_{i}\\left(r_{i}-1\\right)\n$$  \nwhere $f(N)$ is a nonnegative penalization function. A usual choice for it is the Jeffreys-Schwarz criterion, sometimes called the BIC, ${ }^{11}$ where $f(N)=\\frac{1}{2} \\log N$.  \nIn the Bayesian approach to the Bayesian network model induction from data, we express our uncertainty on the model (structure and parameters) by defining a variable in which its states correspond to the possible network structure hypothesis $S^{h}$ and assessing the probability $p\\left(S^{h}\\right)$. In the approach known as Bayesian model selection we select the model in which its logarithm of the relative posterior probability, i.e., $\\log p(S, D)$, is maximum. Taking into account that $\\log p(S \\mid D) \\propto$ $\\log p(S, D)=\\log p(S)+\\log p(D \\mid S)$ and under the assumption that the prior distribution over the structure is uniform, an equivalent criterion is the log marginal likelihood $(\\log p(D \\mid S))$ of the data given the structure. It is possible to compute the marginal likelihood efficiently and in a closed form under some general assumptions. ${ }^{12,13}$ For instance, it is shown ${ }^{12}$ that if the cases occur independently (there are no missing values) and the density of the parameters given the structure is uniform, then  \n$$\np(D \\mid S)=\\prod_{i=1}^{n} \\prod_{j=1}^{q_{i}} \\frac{\\left(r_{i}-1\\right)!\\left(N_{i j}+r_{i}-1\\right)!}{\\prod_{k=1}^{r_{i}} N_{i j k}!}\n$$  \nThis score is known as the K2 metric.\nThe literature includes several scores that, inspired in the information theory, ${ }^{14}$ are able to calculate the entropy of a probability distribution represented by a Bayesian network. It is shown that the entropy of the distribution represented by a Bayesian network structure $S$ is ${ }^{15}$  \n$$\nH_{S}=\\sum_{i=1}^{n} \\sum_{j=1}^{\\phi_{i}} p\\left(\\mathbf{P a}_{i}=j\\right) H_{S_{i} \\mid \\mathbf{P a}_{i=j}}\n$$  \nwhere $H_{X_{i} \\mid \\mathbf{P a}_{i=j}}=\\sum_{k=1}^{r_{i}} p\\left(X_{i}=x_{i}^{k} \\mid \\mathbf{P a}_{i}=j\\right) \\ln p\\left(X_{i}=x_{i}^{k} \\mid \\mathbf{P a}_{i}=j\\right)$.",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:49:58",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the EDA named EA/G to be integrated with Genetic Algorithms (GAs) to form the EA/G-GA algorithm?",
      "topics": [
        "genetic"
      ],
      "answer": "The implementation of EA/G-GA involves using the EA/G algorithm, an Estimation of Distribution Algorithm, and integrating it with Genetic Algorithms (GAs). The objective is to leverage the probabilistic model-building of EA/G with the genetic operators of GAs to improve performance, particularly in NP-hard problems like single machine scheduling. The integration aims to mitigate premature convergence, a drawback associated with EDAs.",
      "chunk_id": 11879,
      "paper_id": "EA:G-GA for Single Machine Scheduling Problems with Earliness:Tardiness Costs",
      "paper_title": "EA/G-GA for Single Machine Scheduling Problems with Earliness/Tardiness Costs",
      "paper_year": "2011",
      "chunk_content": "ISSN 1099-4300\nwww.mdpi.com/journal/entropy\nShih-Hsin Chen ${ }^{1}$, Min-Chih Chen ${ }^{2}$, Pei-Chann Chang ${ }^{3, *}$ and Yuh-Min Chen ${ }^{2}$${ }^{1}$ Department of Electronic Commerce Management, Nanhua University, Dalin Chiayi 62248, Taiwan; E-Mail: worldstar.chen@gmail.com${ }^{2}$ Institute of Manufacturing Engineering, National Cheng Kung University, Tainan 70101, Taiwan;E-Mail: solo535353@gmail.com (M.-C.C); ymchen@mail.ncku.edu.tw (Y.-M.C)${ }^{3}$ Department of Information Management, Yuan-Ze University, 135 Yuan-Tung Road, Chungli, Taoyuan 32023, Taiwan Author to whom correspondence should be addressed; E-Mail: iepchang@saturn.yzu.edu.tw;Tel.: +886-3-4638800, Ext: 2305; Fax: +886-3-4638884.Received: 10 May 2011; in revised form: 30 May 2011 / Accepted: 10 June 2011 /Published: 14 June 2011\nAn Estimation of Distribution Algorithm (EDA), which depends on explicitly sampling mechanisms based on probabilistic models with information extracted from the parental solutions to generate new solutions, has constituted one of the major research areas in the field of evolutionary computation. The fact that no genetic operators are used in EDAs is a major characteristic differentiating EDAs from other genetic algorithms (GAs). This advantage, however, could lead to premature convergence of EDAs as the probabilistic models are no longer generating diversified solutions. In our previous research [1], we have presented the evidences that EDAs suffer from the drawback of premature convergency, thus several important guidelines are provided for the design of effective EDAs. In this paper, we validated one guideline for incorporating other meta-heuristics into the EDAs. An algorithm named \"EA/G-GA\" is proposed by selecting a well-known EDA, EA/G, to work with GAs. The proposed algorithm was tested on the NP-Hard single machine scheduling problems with the total weighted earliness/tardiness cost in a just-in-time environment. The experimental results indicated that the EA/G-GA outperforms the compared algorithms statistically significantly across different stopping criteria and demonstrated the robustness of the proposed algorithm. Consequently, this paper is of interest and importance in the field of EDAs.  \nKeywords: Estimation of Distribution Algorithms; probability estimation; statistical learning problem; EA/G; diversity; single machine scheduling problems",
      "question_type": "process",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:49:59",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the Estimation of Distribution Algorithms (EDAs) discussed for the permutation flowshop scheduling problem (PFSP), what advantages do EDAs offer compared to exact algorithms when optimizing for the total flow time (TFT) criterion, given the problem's NP-complete nature for more than two machines?",
      "topics": [
        "optimization"
      ],
      "answer": "While exact algorithms can accurately determine the optimal solution for the permutation flowshop scheduling problem (PFSP) with respect to the total flow time (TFT), their computational cost becomes prohibitive for instances beyond a small size (approximately 10-15 jobs). The NP-complete nature of the problem for more than two machines, as established by Garey et al., implies that the computational time required for exact algorithms grows exponentially with the number of jobs. Estimation of Distribution Algorithms (EDAs), as metaheuristic optimization techniques, offer a potential advantage by providing solutions within a reasonable time span for larger PFSP instances, even though they do not guarantee optimality. In contrast to exact methods like branch and bound, EDAs are designed to handle the complexity of larger problem instances, offering a trade-off between solution quality and computational efficiency.",
      "chunk_id": 1266,
      "paper_id": "A Distance-Based Ranking Model Estimation of Distribution Algorithm for the Flowshop Scheduling Problem",
      "paper_title": "A Distance-Based Ranking Model Estimation of Distribution Algorithm for the Flowshop Scheduling Problem",
      "paper_year": "2014",
      "chunk_content": "SINCE Johnson published his work on the two-machine flowshop in 1954 [1], numerous papers have dealt with the flowshop scheduling problem. Early research on this topic was highly theoretical and focused mainly on exact methods. In 1976, Garey et al. [2] proved that this problem is NPcomplete for more than two machine instances, and thus, stated the difficulty of achieving optimal solutions. In later decades, the problem was extensively addressed in the literature [3], [4]. A simplified version of this problem is the permutation flowshop scheduling problem (PFSP) [4], where the goal is to find the optimal sequence of $n$ jobs that must be processed in $m$ machines. Even though the PFSP was formulated in the 1950s,  \n[^0]it is still a meaningful research topic due to its strong engineering background. Initially, the most common optimization criterion in the PFSP was the total completion time of the jobs, also called makespan. However, the minimization of the total flow time (TFT) has captured the attention of the scientific community since it is more relevant than the makespan for the current dynamic production environments. The TFT measures the sum of the times that each job remains in the flowshop. Thus, minimizing the TFT can lead to the stable utilization of resources, rapid turn-around of jobs, and minimization of work-in-progress inventory costs [5].\nThe literature contains evidence of a wide variety of strategies that approach the PFSP with respect to the TFT criterion (PFSP-TFT). Exact algorithms accurately work out the optimal solution. However, they are computationally costly and, with the exception of small size examples (instances up to 10-15 jobs), exact algorithms cannot be used in a reasonable time span. Examples of such methods are branch and bound approaches [6], [7]. Besides the exact methods, heuristic procedures such as constructive heuristics [5], [8]-[13] and composite heuristics [10], [14]-[16] have also been proposed. Unfortunately, such heuristics have shown a poor performance when solving PFSP instances of 50 jobs or more.\nAdvances in metaheuristic optimization supplied the research community with new techniques to tackle combinatorial optimization problems. As proof of these advances, we found a wide variety of strategies in the literature for solving the PFSP, such as local search [17]-[19], simulated annealing [20], tabu search [21]-[23], genetic algorithms (GAs) [24]-[28], particle swarm optimization [29]-[32], ant colony optimization [33]-[36], or estimation of distribution algorithms (EDAs) [37]. Currently, the literature points to the hybrid approaches, such as those published by Costa et al. [variable neighborhood search 4 - (VNS $\\left.{ }_{4}\\right)$ ] [19] and Xu et al. [asynchronous genetic algorithm (AGA)] [26], as the cutting-edge algorithms for optimizing the PFSP-TFT. In the first case, the authors propose the combination of a VNS with a constructive algorithm called $\\operatorname{LR}(n / m)$ [10]. In the second case, a GA is hybridized with VNS. Additionally, to guide the initial population, FORMULA_4 is also used.\nIn this paper, we go deeper into the development of EDAs, proposing a new EDA for permutation-based optimization problems and testing its performance on the PFSP-TFT.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:02",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "Within the EDA framework described, how does the selection step, which uses fast non-dominated sorting and crowding distance, balance convergence towards Pareto-optimal solutions with maintaining population diversity, considering the crowding distance calculation: d[u_{k,G=1+1}^{i}] = |J_{1}[u_{k,G=1+1}^{i+1}]-J_{1}[u_{k,G=1+1}^{i-1}]| + |J_{2}[u_{k,G=1+1}^{i+1}]-J_{2}[u_{k,G=1+1}^{i-1}]|?",
      "topics": [
        "search"
      ],
      "answer": "The selection step in the EDA uses a two-stage process to select M individuals for the next generation, balancing convergence and diversity. First, fast non-dominated sorting categorizes solutions (Q  P_{G=}) into fronts J^{1}, J^{2}, ..., J^{l} based on non-domination. Solutions from better fronts (lower index) are preferred, promoting convergence towards Pareto-optimal solutions (minimizing J1 and J2). If adding an entire front J^{n} would exceed the population size M, crowding distance is used to maintain diversity within that front. The crowding distance, d[u_{k,G=1+1}^{i}], estimates the space surrounding a solution u_{k,G=1+1}^{i} by averaging the absolute differences in objective function values (J1 and J2) of its two nearest neighbors in the same front. Solutions with smaller crowding distances are penalized. By removing solutions with the smallest crowding distance from Pop(t+1)  J^{n} until the population size is M, the selection process favors solutions in less crowded regions of the objective space, promoting diversity. If multiple solutions have the same smallest crowding distance, one is randomly chosen for removal, ensuring the algorithm doesn't get stuck due to ties.",
      "chunk_id": 4344,
      "paper_id": "Double-Objective Optimal Control for Non-Gaussian Systems  An Example Study on Analytical vs Numerical Solutions",
      "paper_title": "Double-Objective Optimal Control for Non-Gaussian Systems: An Example Study on Analytical vs Numerical Solutions",
      "paper_year": "2015",
      "chunk_content": "Estimation of distribution algorithms (EDAs) are stochastic optimization methods that search for the space of potential solutions. Different from GA(Genetic Algorithm), there is no crossover or mutation in EDAs. Instead, they build and sample explicit probability distribution model of promising solutions. In the following, details of how to use EDA optimization techniques to solve the multi-objective optimal control problem (4) will be presented.  \nDenote $u_{k}=u_{k-1}+\\Delta u_{k}$, the EDA method is used to find the optimal $\\Delta u_{k}$ by minimizing $J_{1}$ and $J_{2}$ simultaneously. The algorithm consists of four main stages: initialization, modelling, reproduction, and selection, which are briefly presented as follows.  \nGenerate initial population randomly in the decision space $\\left(-\\left(U_{\\max }+u_{k-1}\\right) \\leq \\Delta u_{k} \\leq U_{\\max }-u_{k-1}\\right)$ according to the uniform distribution:\n$P_{G=0}=\\left\\{\\Delta u_{k, G=0}^{1}, \\cdots, \\Delta u_{k, G=0}^{M}\\right\\}$\nwhere $M$ is the total number of populations. Generate $N$ random noises based on PDF (2): $\\omega_{k}=\\left\\{\\omega_{k, G=0}^{1}, \\cdots, \\omega_{k, G=0}^{N}\\right\\}$. For every $\\Delta u_{k, G=0}^{1}(i=1,2, \\cdots, M)$ in $P_{G=0}$, we can obtain $N$ output $y_{k}=\\left\\{y_{k, G=0}^{1}, \\cdots, y_{k, G=0}^{N}\\right\\}$ according to (1). Then, use the following equations to obtain the mean value and entropy of output:\n$E\\left(y_{k}\\right)=\\frac{1}{N} \\sum_{i=1}^{N} y_{k, G=0}^{i}$\nEntropy $\\left\\{y_{k}\\right\\}=-\\log \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\kappa\\left(y_{k, G=0}^{i}-y_{k, G=0}^{j}, 2 \\sigma^{2}\\right)$\nwhere $\\kappa\\left(s, \\sigma^{2}\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{s^{2}}{2 \\sigma^{2}}\\right)$ is the Gaussian kernel function, $\\sigma^{2}$ represents typical symmetric variance. Eventually, the objectives can be obtained according to equation (3) and (4):  \n$$\n\\begin{aligned}\nJ\\left(u_{k, G=0}\\right)= & {\\left[\\left(J_{1}\\left(u_{k, G=0}^{1}\\right), J_{2}\\left(u_{k, G=0}^{1}\\right)\\right) \\cdots\\right.} \\\\\n& \\left.\\left(J_{1}\\left(u_{k, G=0}^{M}\\right), J_{2}\\left(u_{k, G=0}^{M}\\right)\\right)\\right]^{T}\n\\end{aligned}\n$$  \nBy using the non-domination sorting selection method, the Pareto optimal solutions can be obtained. Choose the PDF of these solutions as the probability model of the EDA. Generate a new set $Q=\\left\\{\\Delta u_{k, G=\\sigma}^{1}, \\Delta u_{k, G=\\sigma}^{2}, \\cdots, \\Delta u_{k, G=\\sigma}^{M}\\right\\}$ with $M$ random members according to the established model. Select $M$ optimal individuals from $Q \\cup P_{G=\\sigma}$ to create $P_{G=1+1}$ based on the following principle:  \n1) Use the fast non-dominated sorting approach to establish the partial ordering relation of population $Q \\bigcup \\operatorname{Pop}(t): J^{1} \\succ J^{2} \\succ \\cdots \\succ J^{1}$. Denote $\\operatorname{Pop}(t+1)=\\varnothing$, and $\\operatorname{Pop}(t+1)=\\operatorname{Pop}(t+1) \\bigcup J^{n}, \\quad n=1,2, \\cdots, l \\quad$ until $|(P o p(t+1))|>M$\n2) If $|(P o p(t+1))|>M$, for all members in $\\operatorname{Pop}(t+1) \\cap J^{n}$, compute their crowding distances using the following equation:  \n$$\n\\begin{aligned}\nd\\left[\\Delta u_{k, G=1+1}^{i}\\right] & =\\left|J_{1}\\left[\\Delta u_{k, G=1+1}^{i+1}\\right]-J_{1}\\left[\\Delta u_{k, G=1+1}^{i-1}\\right]\\right| \\\\\n& +\\left|J_{2}\\left[\\Delta u_{k, G=1+1}^{i+1}\\right]-J_{2}\\left[\\Delta u_{k, G=1+1}^{i-1}\\right]\\right|\n\\end{aligned}\n$$  \nRemove the element in $\\operatorname{Pop}(t+1) \\cap J^{n}$ with the smallest crowding distance from $\\operatorname{Pop}(t+1)$. In the case when there are more than one member with the smallest crowding distance, randomly choose one and remove it.  \nThe EDA for problem (5) at $k$ instant can be summarized as follows:  \nStep 1 Initialization: Set $t:=0$. Generate an initial population $P_{G=0}=\\left\\{\\Delta u_{k, G=0}^{1}, \\cdots, \\Delta u_{k, G=0}^{M}\\right\\}$ and compute the $J-$ value of each individual solution in $P_{G=0}$.  \nStep 2 Modelling: Build the probability model of the Pareto optimal solutions in generation $P_{G=\\sigma}$.  \nStep 3 Reproduction: Generate a new solution set $P_{G=\\sigma}$ from the model established in Step 2. Evaluate the $J$-value of each solution in $Q$.  \nStep 4 Selection: Select $M$ individuals from $Q \\cup P_{G=\\sigma}$ to create $P_{G=1+1}$.  \nStep 5 Set FORMULA_113 and go to Step 1.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:05",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned for solving the Hybrid Flow-shop Scheduling Problem (HFSP), what binary variables are used to represent job assignments and sequencing?",
      "topics": [
        "search"
      ],
      "answer": "The implementation uses two binary variables: $X_{j i k}$, which equals 1 if job $j$ is assigned to machine $i$ at stage $k$, and 0 otherwise; and $Y_{j i k}$, which equals 1 if job $i$ precedes job $j$ at stage $k$, and 0 otherwise. These variables are crucial for representing the scheduling decisions within the EDA.",
      "chunk_id": 218,
      "paper_id": "An Estimation of Distribution Algorithm for Solving Hybrid Flow-shop Scheduling Problem with Stochastic Processing Time",
      "paper_title": "An Estimation of Distribution Algorithm for Solving Hybrid Flow-shop Scheduling Problem with Stochastic Processing Time",
      "paper_year": "2013",
      "chunk_content": "[^0]:    ${ }^{1}$ This work is supported by the National Key Basic Research and Development Program of China (2013CB329503), the National Science Foundation of China (61174189 and 61025018), the Doctoral Program Foundation of Institutions of Higher Education of China (20100002110014), and the National Science and Technology Major Project of China (No.2011ZX02504-008).  \nmechanism is provided to update the probability model with the superior individuals. By sampling the probability model, new individuals can be generated among the search region with promising solutions. Numerical tests based on some well known benchmark instances are carried out. The comparisons with the existing GA demonstrate the effectiveness and robustness of the proposed algorithm.  \nThe remainder of the paper is organized as follows. The SHFSP is described in Section 2. In Section 3 the basic EDA is introduced, and the framework of the EDA for solving the SHFSP is proposed in Section 4. Simulation results and comparisons are provided in Section 5. Finally, we end the paper with some conclusions in Section 6.\n$n$ : the number of jobs to be processed;\n$s$ : the number of processing stages;\n$m_{i}$ : the number of the machines at stage $k$;\n$X_{j i k}$ : a binary variable which is equal to 1 if job $j$ is assigned to machine $i$ at stage $k$ and is equal to 0 otherwise;\n$Y_{j i k}$ : a binary variable which is equal to 1 if job $i$ precedes job $j$ at stage $k$ and is equal to 0 otherwise;\n$R_{i}$ : the releasing time of job $i$;\n$S_{i k}$ : the starting time of job $i$ at stage $k$;\n$P_{i k}$ : the processing time of job $i$ at stage $k$;\n$C_{i k}$ : the completing time of job $i$;\n$L$ : a very large constant;\n$N$ : the number of stochastic scenarios;\n$\\zeta(I)$ : the $i^{\\text {th }}$ set of the sampled parameters from the initial scenario $I$;\n$P_{i}$ : the processing time of the initial scenario;\n$\\alpha \\in[0,1]$ : the uncertainty degree of the processing times.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:07",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How do the parameters $SI$, $\\alpha$, $\\beta$, and $\\gamma$ adapt during the iteration process of the Estimation of Distribution Algorithm, and what role does $Gen_{max}$ play in this adaptation?",
      "topics": [
        "optimization"
      ],
      "answer": "The parameters $SI$, $\\alpha$, $\\beta$, and $\\gamma$ change uniformly with the iteration process from 20 to $popSize \\times \\eta$, $a_{max}$ to 0.01, $\\beta_{max}$ to 0.01, and $\\gamma_{max}$ to 0.01, respectively. Here, $popSize$ represents the number of individuals in the population, and $\\eta$ is the proportion of superior individuals selected. $Gen_{max}$ defines the iteration range of this self-adaptive process, controlling the degree of self-adaptation for these parameters during optimization.",
      "chunk_id": 8866,
      "paper_id": "A hybrid estimation of distribution algorithm for distributed flexible job shop scheduling with crane transportations",
      "paper_title": "A hybrid estimation of distribution algorithm for distributed flexible job shop scheduling with crane transportations",
      "paper_year": "2021",
      "chunk_content": "$S i=\\left\\{\\begin{array}{l}20+\\operatorname{int}\\left[\\frac{G e n}{G e n_{\\max }}\\right.(\\text { popSize } \\cdot \\eta-20)] \\text {, } \\quad \\text { if } G e n \\leq G e n_{\\max } \\\\ \\text { popSize } \\cdot \\eta, \\quad \\text { else }\\end{array}\\right.$\n$\\alpha=\\left\\{\\begin{array}{ll}a_{\\max }-\\frac{G e n}{G e n_{\\max }}\\left(a_{\\max }-0.01\\right), & \\text { if } G e n \\leq G e n_{\\max } \\\\ 0.01, & \\text { else }\\end{array}\\right.$\n$\\beta=\\left\\{\\begin{array}{ll}\\beta_{\\max }-\\frac{G e n}{G e n_{\\max }}\\left(\\beta_{\\max }-0.01\\right), & \\text { if } G e n \\leq G e n_{\\max } \\\\ 0.01, & \\text { else }\\end{array}\\right.$\n$\\gamma=\\left\\{\\begin{array}{ll}\\gamma_{\\max }-\\frac{G e n}{G e n_{\\max }}\\left(\\gamma_{\\max }-0.01\\right), & \\text { if } G e n \\leq G e n_{\\max } \\\\ 0.01, & \\text { else }\\end{array}\\right.$  \nIn (64), int $[x]$ is the maximum integer number less than or equal to $x . a_{\\max }, \\beta_{\\max }, \\gamma_{\\max }$, and $G e n_{\\max }$ are constant, and $a_{\\max }, \\beta_{\\max }$, and $\\gamma_{\\max }$ are the maximum values of $\\alpha, \\beta$, and $\\gamma$ during the self-adaptive iteration process. It can be concluded from (64-67) that with the iteration process of the proposed algorithm, the value intervals of $S I, \\alpha, \\beta$, and $\\gamma$ uniformly change from 20 to popSize $\\times \\eta, a_{\\max }$ to $0.01, \\beta_{\\max }$ to 0.01 , and $\\gamma_{\\max }$ to 0.01 , respectively, where popSize denotes the number of individuals in the population (in this study, popSize $=100$ ), $\\eta$ is the proportion of superior individuals selected from the population, and $a_{\\max }, \\beta_{\\max }$ and $\\gamma_{\\max }$ are larger than 0.01 . From Eqs. (64-67), Gen $_{\\max }$ is the iteration range of self-adaptive process for parameters, it controls the degree of self-adaptive parameters mode in optimization.\nThe factory vector, scheduling vector, and machine assignment vector of the solution are generated by probability matrices $A, B$, and $C$, respectively.  \nFor the generation of the factory vector, the assigned factory of every job is generated based on the probability distribution of the factory vector. Each position $i$ in factory vector is generated based on the probability distribution of $\\left\\{A_{i 1}, A_{i 2}, \\ldots, A_{i F}\\right\\}$, where $F$ is the number of factories.  \nFor the generation of the scheduling vector, each position $m$ in scheduling vector is generated based on the probability distribution of $\\left\\{B_{m 1}, B_{m 2}, \\ldots, B_{m f}\\right\\}$, where $I$ is the number of jobs. Note that if all operations for a job are distributed in the scheduling vector, the distribution probability of the job should be set to 0 . This signifies that the probability sum of each following position is not 1 . To generate a feasible solution, when the distribution probability is changed at position $c$ during the generation process, a repair process is required, which is expressed as (68):\n$B_{m i} \\leftarrow B_{m i} / \\sum_{i=1}^{I} B_{m i}, m \\geq c$\nFor the generation of the machine assignment vector, each machine assignment of operation $O_{i, j}$ is generated based on the probability distribution of $\\left\\{C_{O j 1}, C_{O j 2}, \\ldots, C_{O j k a n u l l a h i e}\\right\\}$ that all machines in the available machine set can perform $O_{i, j}$.  \n[IMAGE_6]  \nFig. 7. Local swap neighborhood structure.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:08",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "In essence, what is the overall purpose of using Bayesian Networks (BNs) within Estimation of Distribution Algorithms (EDAs) to represent the joint probability distribution (JPD) of variables?",
      "topics": [
        "representation"
      ],
      "answer": "The primary purpose of employing Bayesian Networks (BNs) in EDAs is to provide a tractable representation of the joint probability distribution (JPD) across multiple random variables, denoted as \\(p(X_{1}, \\ldots, X_{n})\\). Directly modeling the JPD becomes computationally infeasible for medium to large \\(n\\) due to the exponential growth in the number of parameters required (e.g., \\(2^{n}-1\\) for binary variables). BNs address this intractability by leveraging conditional independencies between variables to reduce the number of parameters. Specifically, the BN, consisting of a DAG \\(\\mathscr{G}\\) and parameters \\(\\theta\\), encodes conditional independencies such that each node \\(X_{i}\\) is conditionally independent (c.i.) of its non-descendants \\(\\mathbf{N D}(X_{i})\\) given its parents \\(\\mathbf{P a}(X_{i})\\). This factorization, according to the local Markov independencies, allows for a more compact and manageable representation of the JPD, enabling efficient probabilistic inference and optimization within the EDA framework.",
      "chunk_id": 9570,
      "paper_id": "Bayesian networks for interpretable machine learning and optimization",
      "paper_title": "Bayesian networks for interpretable machine learning and optimization",
      "paper_year": "2021",
      "chunk_content": "BNs are widely used models of uncertain knowledge. They are useful because they can provide a compact representation of a JPD across many random variables, $p\\left(X_{1}, \\ldots, X_{n}\\right)$. The JPD over the variables of a domain is of great interest since, when known, it lets us answer any probabilistic question about the domain and thus solve tasks of interest such as, for example, predicting the value of a particular variable given the values of other variables.  \nIn general, however, a JPD is intractable with a medium or large $n$ (number of variables) because specifying it requires an enormous number of parameters (e.g., $2^{n}-1$ parameters if all variables are binary). This is intractable computationally, as we cannot store nor process that many parameters; cognitively, as an expert cannot  \nunderstand such a model; and statistically, as we cannot obtain sufficient data to estimate it reliably. A JPD can be made tractable by leveraging the notion of conditional independence between variables in order to reduce the number of parameters. Random variables $X$ and $Y$ are conditionally independent (c.i.) given another random variable $Z$ if\n$p(x \\mid y, z)=p(x \\mid z) \\quad \\forall x, y, z$ values of $X, Y, Z$.\nThat is, $X$ and $Y$ are c.i. given $Z$ if, for any $Z=z$, knowing $Y=y$ does not affect the probability of $x$ (note that $X, Y, Z$ may also be disjoint random vectors). Thus, after decomposing $p(x, y, z)$ according to the chain rule, $p(x, y, z)=p(z) p(y \\mid z) p(x \\mid y, z)$, we can equivalently write it as $p(z) p(y \\mid z) p(x \\mid z)$, thus reducing the number of parameters in the last factor.  \nA BN consists of a DAG $\\mathscr{G}$ and a set of parameters $\\theta$ (see Fig. 1). The vertices (i.e., nodes) of $\\mathscr{G}$ correspond to the variables $\\mathbf{X}=\\left(\\mathbf{X}_{1}, \\ldots, \\mathbf{X}_{n}\\right)$ while its directed edges (i.e., arcs) encode the conditional independencies among the variables $\\mathbf{X}$. The parents of a node $X_{i}, \\mathbf{P a}\\left(X_{i}\\right)$, are all the nodes with arcs pointing to $X_{i}$, while the children of $X_{i}$ are all nodes towards which $X_{i}$ has outgoing arcs. The descendants of $X_{i}$ are all the nodes reachable from $X_{i}$ by following the arcs, while its complement in $\\mathbf{X} \\backslash\\left\\{\\mathbf{X}_{i}\\right\\}$ is $\\mathbf{N D}\\left(X_{i}\\right)$, the set of non-descendants of $X_{i}$. The basic set of conditional independences encoded by a BN is\n$X_{i}$ is c.i. of $\\mathbf{N D}\\left(X_{i}\\right)$ given $\\mathbf{P a}\\left(X_{i}\\right), i=1, \\ldots, n$,\nthat is, each node is c.i. of its non-descendants given its parents. This set of independencies is referred to as the local Markov independencies.  \nIf the local Markov independencies of $\\mathscr{G}$ hold in a JPD $p(\\mathbf{X})$ then we can factorize $p(\\mathbf{X})$ according to $\\mathscr{G}$ and vice versa. Namely, the fact that $\\mathscr{G}$ is acyclic ensures there is at least one topological ordering of the variables $X_{1}, \\ldots, X_{n}$ such that $\\left\\{X_{1}, \\ldots, X_{i-1}\\right\\}$ only contains non-descendants of $X_{i}$. Thus, after applying the chain rule,\n$p\\left(X_{1}, \\ldots, X_{n}\\right)=p\\left(X_{1}\\right) p\\left(X_{2} \\mid X_{1}\\right) p\\left(X_{3} \\mid X_{1}, X_{2}\\right) \\cdots p\\left(X_{n} \\mid X_{1}, \\ldots, X_{n-1}\\right)$,\nwe can remove all non-descendants other than parents from the conditioning sides,\nFORMULA_50,",
      "question_type": "synthesis summary",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:11",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of the Compact Genetic Algorithm (cGA) use the probability vector (PV) to represent and evolve potential solutions, and what is the role of the population size 'n' in updating this PV?",
      "topics": [
        "genetic",
        "Estimation of Distribution Algorithms",
        "Compact Genetic Algorithm",
        "probability vector"
      ],
      "answer": "The Compact Genetic Algorithm (cGA) represents a possible solution using a probability vector (PV), where the length of the PV corresponds to the number of variables in the problem. The value of each element in the PV measures the probability of a variable taking a particular value. Initially, all elements of the PV are set to 0.5, representing a uniform distribution. In each generation, two individuals are generated from the current PV, and after they compete, the winner updates the PV. The updating rule increases or decreases the probability vector by a factor of 1/n, where 'n' is the population size. Specifically, if the winner has a value of 1 at a certain position and the loser has a value of 0 at that same position, then the corresponding element in the PV, denoted as p[i], is updated as p[i] + 1/n. Conversely, if the winner has a value of 0 and the loser has a value of 1, then p[i] is updated as p[i] - 1/n. The algorithm stops when all elements in the PV have a value of either 0 or 1, indicating convergence to a solution.",
      "chunk_id": 5274,
      "paper_id": "Improved compact genetic algorithm for EM complex system design",
      "paper_title": "Improved Compact Genetic Algorithm for EM Complex System Design",
      "paper_year": "2012",
      "chunk_content": "Compact Genetic Algorithm - cGA, first presented in [1], uses probability vector (PV) to represent a possible solution. In cGA, instead of using real population as in traditional Genetic Algorithm, it manages PV to get the distribution of good solutions. The length of PV corresponds to the number of variables of problem, and the value of PV measures the probability of one variable to get particular value e.g. the proportion of \" 1 \" in case of binary problem. A full treatment of the method can be found in [1-2], but for the sake of clarity and uniformity of notation it is briefly summarized in the following section.  \nThe pseudo code of cGA is described in Fig.1. Initially, the PV is assigned a value of 0.5 i.e. assuming uniform distribution for every position. In each generation, two individuals are generated from current PV. They are left to compete, and the winner will be responsible for updating the PV. The updating rule will increase or decrease probability vector by a factor $1 / n$ (n-population size) according to the value of the winner. The  \ncGA will stop when PV has value of 0 or 1 at all positions i.e. finding optimal solution.  \n1) Initialize probability vector for $\\mathrm{i}:=1$ to 1 do $\\mathrm{p}[\\mathrm{i}]:=0.5$;\n2) Generate two individual from the vector\n$\\mathrm{a}:=$ generate(p);\n$\\mathrm{b}:=$ generate(p);\n3) Let them compete\nwinner, loser: = evaluate(a,b);\n4) Update the probability vector towards the better one for $\\mathrm{i}:=1$ to 1 do\nif winner[i] \\# loser[i] then\nif winner $[\\mathrm{i}]=1$ then $\\mathrm{p}[\\mathrm{i}]:=\\mathrm{p}[\\mathrm{i}]+1 / \\mathrm{n}$;\nelse $\\mathrm{p}[\\mathrm{i}]:=\\mathrm{p}[\\mathrm{i}]-1 / \\mathrm{n}$;\n5) Check if the vector has converged for $\\mathrm{i}:=1$ to 1 do\nif $\\mathrm{p}[\\mathrm{i}]=0$ and $\\mathrm{p}[\\mathrm{i}]<1$ then\nreturn to step 2;\n6) FORMULA_15 presents the final solution\ncGA parameter:\nn : population size\n1 : chromosome length  \nFig. 1: pseudo code of cGA",
      "question_type": "algorithmic mechanism",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:14",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm to maximize overall throughput in cellular networks with D2D communication under power and interference constraints, how should practitioners address the computational complexity given that the problem is NP-Hard?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithm",
        "resource management",
        "D2D communication"
      ],
      "answer": "Practitioners should recognize that finding a sub-optimal solution in polynomial time using a greedy approach is nearly impossible due to the exponential increase in computational complexity with more users. Therefore, they should apply an evolutionary technique, such as an Estimation of Distribution Algorithm (EDA), which is suitable for addressing complex problems of combinatorial nature like joint resource management in D2D. The EDA can achieve near-optimal solution convergence with a minimal number of iterations.",
      "chunk_id": 7978,
      "paper_id": "Estimation of Distribution Algorithm for Joint Resource Management in D2D Communication",
      "paper_title": "Estimation of Distribution Algorithm for Joint Resource Management in D2D Communication",
      "paper_year": "2019",
      "chunk_content": "Mushtaq Ahmad ${ }^{2} \\cdot$ Muhammad Naeem ${ }^{1,2} \\cdot$ Muhammad Iqbal ${ }^{2}$Published online: 7 May 2019(c) Springer Science+Business Media, LLC, part of Springer Nature 2019\nDevice to device (D2D) communication technique is one of the established means to enhance data rate in next generation wireless systems. Use of same resource of cellular users by D2D pairs creates interference problem among users. Simultaneous resource management and mode selection in emerging cellular networks having D2D capabilities can surely improve overall system throughput. This work addresses the problem of overall throughput maximization of emerging cellular networks while ensuring the power and interference constraints. The joint resource management problem is NP-Hard and is classified as mixed integer non-linear constraint optimization problem. Due to the fact that, the computational complexity of the system increases exponentially with the increase in users, it is almost impossible to find sub-optimal solution in polynomial time using greedy approach. Therefore, this paper applies evolutionary technique, like estimation of distribution algorithm which has the potential to address the complex problems having combinatorial nature such as joint resource management strategy in D2D. Near optimal solution convergence is achieved by the algorithm with minimal number of iterations. Simulation results show the effectiveness of the proposed approach as compared to other algorithms.  \nKeywords Device-to-device communication $\\cdot$ Admission control $\\cdot$ Mode selection $\\cdot$ EDA",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:16",
      "generation_style": "practical_application"
    },
    {
      "question": "Based on the experimental setup described, what is the calculation step size used within the Estimation of Distribution Algorithm (EDA) based optimization process executed in Mobile Edge Computing Units (MEC-Us)? How does this parameter relate to the spatial granularity of the energy consumption optimization?",
      "topics": [
        "control"
      ],
      "answer": "The calculation step size in the Estimation of Distribution Algorithm (EDA) based optimization process within the Mobile Edge Computing Units (MEC-Us) is 10 meters. This parameter defines the spatial granularity at which the EDA evaluates and adjusts the energy consumption plan. Specifically, the EDA performs calculations and potentially modifies the active adjustment of energy consumption every 10 meters along the driving route.",
      "chunk_id": 10293,
      "paper_id": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
      "paper_title": "A novel strategy for power sources management in connected plug-in hybrid electric vehicles based on mobile edge computation framework",
      "paper_year": "2020",
      "chunk_content": "In this study, we perform a comprehensive evaluation for the proposed cooperative strategy based on the novel asynchronous control framework. The performance in active energy consumption plan by the raised strategy is emphatically analyzed. The general behaviors of the adaptive energy management are also discussed based on the MPC algorithm. All the simulation was executed on a workstation with an Intel Xeon E3-1270 @ 3.4 GHz with 32-Gigabyte memory. Two driving routes are chosen with the total length of 4.5 km . Each MECU is responsible for the workload within 1.5 km . The selected driving routes stem from the urban center, of which the complex driving conditions are well suited for the validation of the MEC based cooperative control strategy. The real velocity profiles of the two driving routes are sketched in Fig. 5 (a), along with the predicted velocity. The predicted velocity profiles show high accuracy in contrast with the real driving data. The difference between the predicted velocity profiles and real driving data is caused by the data deficiency in some route segments. With respect to the simulation results, the EDA-W refers to the application of EDA on the whole route. The EDA-Seg indicates application of EDA in each route segment without any energy consumption adjustment. The AEDA-Seg represents applying EDA in each route segment with the corresponding active adjustment. The calculation step in the EDA based  \nTable 3\nEnergy consumption in whole trips by different EDA methods.\nTable 4\nEnergy consumption in whole trips by different strategies.\noptimization process in MEC-Us is 10 m . The details of the experimental setup information are listed in Table 2.",
      "question_type": "definition",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:18",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is the computational complexity of Algorithm 1, and what are its memory and disk-space requirements?",
      "topics": [
        "complexity"
      ],
      "answer": "Algorithm 1 has a computational complexity of o(n^2 * 2^(n-2)). Its memory requirement is 2^(n+2) bytes, and its disk-space requirement is FORMULA_112 bytes, where 'n' refers to the number of variables.",
      "chunk_id": 5860,
      "paper_id": "The Impact of Exact Probabilistic Learning Algorithms in EDAs Based on Bayesian Networks",
      "paper_title": "The Impact of Exact Probabilistic Learning Algorithms in EDAs Based on Bayesian Networks",
      "paper_year": "2008",
      "chunk_content": "sets $\\{C \\backslash\\{c\\} \\mid c \\in C\\}$. It must be computed for all $2^{n-1}$ variable sets (parent candidate sets) related with $X_{i}$.  \nStep 3 of the algorithm is based on the following observation: The best network $G^{*}$ for a variable set $W$ must have a sink $s$. As $G^{*}$ is a network with the highest score, sink $s$ must have incoming arcs from its best possible set of parents. In this way, the rest of the nodes and the arcs must form the best possible network for variables $W \\backslash\\{s\\}$. Therefore, the best sink for $\\mathbf{W}, \\operatorname{sink}^{*}(\\mathbf{W})$, is the node that maximizes the sum between the local score for $s$ and the score for the network $S$ without node $s$.  \nWhen we have the best sinks for all $2^{n}$ variable sets, it is possible to yield the best ordering ord in reverse order. Then, for each position from $|\\mathbf{X}|$ to 1 , in ord $_{i}^{*}$ we have to store the best sink for the set $\\bigcup_{j=i+1}^{|\\mathbf{X}|}\\left\\{\\operatorname{ord}_{j}^{*}(\\mathbf{X})\\right\\}$.  \nHaving a best ordering and a table with the best parents for any candidate set, it is possible to obtain a best network consistent with the given ordering. For the $i^{\\text {th }}$ variable in the optimal ordering, the best parents from its predecessors are picked.  \nMore details about the algorithm can be found in [42]. We use an implementation of Algorithm 1 given by the authors ${ }^{1}$. The computational complexity of the algorithm is $o\\left(n^{2} 2^{n-2}\\right)$. The memory requirement of the method is $2^{n+2}$ bytes and the disk-space requirement is FORMULA_112 bytes.",
      "question_type": "comparison",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:19",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the EDA model described, specifically regarding the annealing scheme for the prior scale matrices \\(\\lambda_{ul}\\) and \\(\\lambda_{ur}\\)?",
      "topics": [
        "Estimation of Distribution Algorithms",
        "annealing scheme",
        "prior scale matrices",
        "algorithm implementation"
      ],
      "answer": "The annealing scheme for \\(\\lambda_{ul}\\) and \\(\\lambda_{ur}\\) involves iteratively relaxing these prior scale matrices to achieve coarse-to-fine registration. The algorithmic steps are as follows: First, initialize \\(\\lambda_{ul}\\) and \\(\\lambda_{ur}\\) with initial values. Second, iterate through a series of decreasing temperature stages, such as \\(\\{20, 10, 5, 2, 1\\}\\). In each stage, lower the temperature and recalculate \\(\\lambda_{ul}\\) and \\(\\lambda_{ur}\\), balancing them. This process aims to avoid the algorithm being trapped in local minima, which can lead to inaccurate alignment. Larger matrices are initially used, which are then slowly reduced to achieve fine matching.",
      "chunk_id": 2328,
      "paper_id": "An Estimation of Distribution Algorithm Based on Variational Bayesian for Point-Set Registration",
      "paper_title": "An Estimation of Distribution Algorithm Based on Variational Bayesian for Point-Set Registration",
      "paper_year": "2022",
      "chunk_content": "The complex term is  \n$$\ng\\left(\\sigma_{l}\\right)=-\\frac{\\boldsymbol{\\tau}_{\\boldsymbol{b}}\\left(-\\boldsymbol{t}_{n}+\\eta\\right)^{w}}{\\left(\\sigma_{l}\\right)^{w}}\n$$  \nThe first-order Taylor expansion for (10) is $h\\left(\\sigma_{l}, \\sigma_{l}^{*}\\right)=$ $g\\left(\\sigma_{l}^{*}\\right)+g^{\\prime}\\left(\\sigma_{l}^{*}\\right)\\left(\\sigma_{l}-\\sigma_{l}^{*}\\right)$. Then, let $\\varphi=g^{\\prime}\\left(\\sigma_{l}^{*}\\right)$, and the  \nfollowing item about $\\sigma_{j}^{*}$ is defined as $j(\\varphi)$. Therefore, we convert (10) into the following simple linear relationship $h\\left(\\sigma_{i}, \\varphi\\right)=\\varphi \\sigma_{i}+j(\\varphi)$. Afterward, we obtain the best $\\varphi$ as follows according to the local variation:  \n$$\n\\begin{aligned}\n\\varphi= & \\frac{\\tau_{b}\\left(-t_{n}+\\eta\\right)^{w}}{\\sigma_{i}^{w+1}} \\cdot\\left(\\frac{w+1}{w}\\right)^{-(w+1)} \\\\\n& \\cdot\\left[w^{1 /(w+1)}+w^{-[w /(w+1)]}\\right]^{w+1}\n\\end{aligned}\n$$  \nBy transforming complex terms into simple linear relationships, we can understand that the prior of $\\lambda_{0}$ follows an exponential distribution and that the same is true for $\\sigma_{u l}, \\sigma_{v l}, \\sigma_{u r}$, and $\\sigma_{v r}$. For $u$ and $v$, using the local variation for processing will only introduce complexity. Therefore, we treat it as a parameter.  \nWe then determine a priori of each variable, and the results are as follows:  \n$$\n\\begin{aligned}\np(\\boldsymbol{\\mu}, \\boldsymbol{\\Lambda})= & p(\\boldsymbol{\\mu} \\mid \\boldsymbol{\\Lambda}) p(\\boldsymbol{\\Lambda})=p\\left(\\boldsymbol{\\mu}, \\boldsymbol{\\Lambda} \\mid \\mu_{0}, \\boldsymbol{\\tau}_{0}, \\epsilon_{0}, \\boldsymbol{\\varrho}_{0}\\right) \\\\\n= & \\prod_{j=1}^{J} \\mathcal{N}\\left(\\boldsymbol{\\mu} \\mid \\mu_{0},\\left(\\boldsymbol{\\tau}_{0} \\boldsymbol{\\Lambda}\\right)^{-1}\\right) \\mathcal{V}\\left(\\boldsymbol{\\Lambda} \\mid \\boldsymbol{\\varrho}_{0}, \\epsilon_{0}\\right) \\\\\n\\mathcal{Z}_{n} & \\left.\\sim \\operatorname{Mult}\\left(z_{n} \\mid \\boldsymbol{\\pi}\\right)=\\prod_{k=1}^{K+K_{0}} \\pi_{k}^{z_{n k}}\\right) \\\\\n\\boldsymbol{\\pi} & \\left.\\sim \\operatorname{Dir}\\left(\\boldsymbol{\\pi} ; \\kappa_{0}\\right)=c\\left(\\kappa_{0}\\right) \\prod_{k=1}^{K+K_{0}} \\pi_{k}^{\\kappa_{0}-1}\\right. \\\\\n\\mathcal{G} & \\left.\\sim\\left(\\mathcal{G}_{k} ; \\xi_{0}, \\zeta_{0}, \\varsigma_{0}\\right)=\\frac{\\zeta_{0}}{2 \\zeta_{0} \\Gamma\\left(\\frac{1}{\\zeta_{0}}\\right)} \\exp \\left(-\\left|\\frac{\\mathcal{X}_{k}-\\xi_{0}}{\\zeta_{0}}\\right| \\varsigma_{0}\\right)\\right. \\\\\n\\boldsymbol{\\sigma} & \\left.\\sim E\\left(\\lambda_{0}\\right)=\\lambda_{0} \\cdot \\exp \\left\\{-\\lambda_{0} \\boldsymbol{\\sigma}\\right\\}\\right) \\\\\n\\boldsymbol{\\alpha} & \\left.\\sim \\operatorname{Gam}\\left(\\boldsymbol{\\alpha} \\mid a_{0}, b_{0}\\right), \\boldsymbol{\\beta} \\sim \\operatorname{Gam}\\left(\\boldsymbol{\\beta} \\mid c_{0}, d_{0}\\right)\\right. \\\\\nv & \\left.\\sim \\operatorname{Mult}(\\boldsymbol{v} \\mid \\boldsymbol{\\gamma}), \\boldsymbol{\\gamma} \\sim \\operatorname{Dir}\\left(\\boldsymbol{\\gamma} ; j_{0}\\right)\\right.\n\\end{aligned}\n$$  \nWe then select the optimal control methods for each variable, including conjugate priors, local variation, and parametrization. The directed graph in Fig. 3 is built according to our designed probability model.\n2) Prior Annealing: The initialization of the prior parameters has a great influence on the posterior approximation of VB inference. The prior scale matrices $\\lambda_{u l}$ and $\\lambda_{u r}$ are either too large or too small, which will influence the effect of the registration. Larger matrices will also reduce the chances for the algorithm to be trapped in the local minimum, thereby leading to inaccurate alignment and greater uncertainty. In contrast, although smaller $\\lambda_{u l}$ and $\\lambda_{u r}$ can achieve fine matching, the local minimum can be easily captured.  \nTherefore, we use an annealing scheme to slowly relax $\\lambda_{u l}$ and $\\lambda_{u r}$ and recalculate the balance between them. We observe a series of stages (i.e., $\\{20,10,5,2,1\\}$ ) to lower the temperature and achieve coarse-to-fine registration.\nWe obtain $K$ Gaussian mixture components in the target point set, and each target point corresponds to a certain component based on posterior probability. In addition, the proposed\n[IMAGE2]  \nFig. 3. Directed acyclic graph of the probability model for PSR. The white circle nodes are the latent random variables, the gray-shaded circles represent the observed variables, the noncircled nodes are constants, and the direction of the arrow represents the dependency.\nmixture model with $K_{0}$ components estimates the outliers to prevent them from affecting the matching accuracy [12], [46]. For each target point $t_{n}$, a corresponding indicator variable $\\mathcal{Z}=\\left\\{\\boldsymbol{z}_{n}\\right\\}_{n=1}^{K+K_{0}}$ can be found in the model. Among them, $\\boldsymbol{z}_{n}$ represents a 1-of- $\\left(K+K_{0}\\right)$ binary vector. We compare the value obtained by the inference calculation of $\\mathcal{Z}$ with the expected threshold $t_{z}$. When $\\mathcal{Z}>t_{z}$, it is a mixed variable of outlier; otherwise, it is inlier. This is accept-reject sampling of inlier.",
      "question_type": "process",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:21",
      "generation_style": "implementation_focused"
    },
    {
      "question": "What specific metrics are used to evaluate the effectiveness of the EDA model, given a set of instances $\\theta$, a set of tasks $UT$, a probability of local search $pls$, and a total number of fitness evaluations $FEm$?",
      "topics": [
        "initialization"
      ],
      "answer": "The effectiveness of the EDA model is evaluated based on the best solution $s_{r}$ found during the optimization process. The algorithm iteratively updates $s_{r}$ after evaluating each child solution, aiming to maximize fitness within the constraint of $FEm$ evaluations. The CEvaluate function is used to assess the fitness $F(c_{i})$ of each chromosome $c_{i}$ in the population, considering the instances $\\theta$ and tasks $UT$. The algorithm also compares the fitness of the child with the fitness of pop[ra] to determine if the child should replace pop[ra].",
      "chunk_id": 1722,
      "paper_id": "Evolving Robust Solutions to Uncertain Capacitated Arc Routing Problem with Time Window",
      "paper_title": "Evolving Robust Solutions to Uncertain Capacitated Arc Routing Problem with Time Window",
      "paper_year": "2022",
      "chunk_content": "Data: a set of instances $\\theta$, a set of tasks $U T$, probability of local search $p l s$, total times of fitness evaluation $F E m$\nResult: the best solution $s_{r}$\n1 $p o p \\leftarrow$ initialization()\n2 for each $c_{i} \\in$ pop do\n$F\\left(c_{i}\\right) \\leftarrow \\mathrm{CEvaluate}\\left(c_{i}, \\theta, U T\\right)$\nupdate $s_{r}$\nindex[i] $\\leftarrow \\mathrm{i}$\nend\n7 sort index in ascending order according to the fitness value.\n8 while the evaluate times is smaller than FEm do\nfor $i=0$ to popsize $/ 2-1$ do\nfor $j=0$ to $U T-1$ do\npoptemp $[i][j] \\leftarrow \\operatorname{pop}[$ index $[i][j]$\nend\nend\nehm $\\leftarrow$ an edge histogram matrix based on poptemp\nsample a random integer $r a$ from the uniform distribution between 0 to popsize-1\nchild $\\leftarrow \\mathrm{EHBSA}($ pop[ra], chm, 2, size of UT)\nsample a random number $r b$ from the uniform distribution between 0 to 1\nif $r b<p l s$ then\nchild $\\leftarrow$ StochasticLS(child,ehm, $\\theta$ )\nend\nupdate $s_{r}$ after evaluating child\nif child is better than pop[ra] and is different from any other chromosomes in the population then replace pop[ra] with child\nend\nsort index in ascending order according to the fitness value.\nend\n27 return $s_{r}$\nData: a set of instances $\\theta$, a set of tasks $U T$, probability of local search $p l s$, total times of fitness evaluation $F E m$\nResult: the best solution $s_{r}$\n1 $p o p \\leftarrow$ initialization with best insertion\n2 for each $c_{i} \\in$ pop do\n$\\mathrm{F}\\left(c_{i}\\right) \\leftarrow \\mathrm{CEvaluate}\\left(c_{i}, \\theta, U T\\right)$\nupdate $s_{r}$\nend\nwhile the evaluate times is smaller than FEm do randomly pick $c_{i} \\in$ pop and $c_{j} \\in$ pop\ngenerating $c_{x}$ by using the crossover operator to $c_{i}$ and $c_{j}$.\nsample a random number $r b$ from the uniform distribution between 0 to 1\nif $r b<p l s$ then\n$c_{x} \\leftarrow$ ExtendedLS $\\left(c_{x}, \\theta\\right)$\nend\nupdate $s_{r}$ after evaluating $c_{x}$\nif $c_{x}$ is better than pop[ra] and is different from any other chromosomes in the population then replace $p o p[r a]$ with $c_{x}$\nend\nend\n18 return FORMULA_144",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:23",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the methodology described in the context of EDAs for the Minimal Switching Graph (MSG) problem?",
      "topics": [
        "search"
      ],
      "answer": "The primary objective is to efficiently find optimal or near-optimal solutions to the NP-complete Minimal Switching Graph problem by using a hybrid Estimation of Distribution Algorithm. This involves combining the efficient exploration capabilities of the Univariate Marginal Distribution Algorithm (UMDA) for sampling start search points with the effective exploitation of a hill-climbing algorithm to find local optima.",
      "chunk_id": 6179,
      "paper_id": "A hybrid estimation of distribution algorithm for the Minimal Switching Graph problem",
      "paper_title": "A hybrid estimation of distribution algorithm for the Minimal Switching Graph problem",
      "paper_year": "2006",
      "chunk_content": "Maolin TangFaculty of Information TechnologyQueensland University of Technology2 George Street, Brisbane, Australiam.tang@qut.edu.au  \nRaymond Y. K. LauDepartment of Information SystemsCity University of Hong KongTat Chee Avenue, Kowloon, Hong Kongraylau@cityu.edu.hk\nMinimal Switching Graph (MSG) is a graphical model for the constrained via minimization problem - a combinatorial optimization problem in integrated circuit design automation. From a computational point of view, the problem is NP-complete. In this paper we present a new approach to the MSG problem using hybrid Estimation of Distribution Algorithms (EDAs). This approach uses a Univariate Marginal Distribution Algorithm (UMDA) to sample start search points and employs a hill-climbing algorithm to find a local optimum in the basins where the start search points are located. By making use of the efficient exploration of the UMDA and the effective exploitation of the hill-climbing algorithm, this hybrid EDA can find an optimal or nearoptimal solution efficiently and effectively. The hybrid EDA has been implemented and compared with the UMDA and the hill-climbing algorithm. Experimental results show that the hybrid EDA significantly outperforms both the UMDA and the hill-climbing algorithm.",
      "question_type": "synthesis summary",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:25",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs for scheduling, how does the algorithmic mechanism of inserting a family \\(\\Gamma_{b}\\) in front of another family \\(\\Gamma_{a}\\) within a cellular impact the calculation of the makespan \\(C_{\\max }(\\boldsymbol{x})\\), and what is the resulting reduction in computational complexity?",
      "topics": [
        "scheduling"
      ],
      "answer": "The insertion operator, where family \\(\\Gamma_{b}\\) from cellular \\(f'\\) is inserted in front of family \\(\\Gamma_{a}\\) in cellular \\(f\\), aims to improve the solution \\(\\boldsymbol{x}^{C}\\). The text explains that after this insertion, the computational complexity (CC) of calculating the makespan \\(C_{\\max }(\\boldsymbol{x})\\) is reduced from \\(O(n \\times m)\\) to \\(O(m)\\), where \\(n\\) is the number of families and \\(m\\) is the number of machines. This reduction is based on equations (24)-(27), which are derived from equations (15)-(17). The processing time of \\(\\Gamma_{1}\\) before \\(\\Gamma_{3}\\) in cellular 1 is not affected, while only \\(M L_{2,4,3}\\) is changed to \\(M L_{2,4,3}\\) in the calculation of processing time after \\(\\Gamma_{2}\\) in cellular 2. Here, \\(M L_{b-1, b, m}\\) represents a component of the makespan calculation related to the machine \\(m\\) and families \\(b-1\\) and \\(b\\), and \\(D_{b, i, i+1}\\) represents the processing time between job \\(i\\) and job \\(i+1\\) within family \\(b\\).",
      "chunk_id": 3052,
      "paper_id": "An enhanced estimation of distribution algorithm with problem-specific knowledge for distributed no-wait flowshop group scheduling problems",
      "paper_title": "An enhanced estimation of distribution algorithm with problem-specific knowledge for distributed no-wait flowshop group scheduling problems",
      "paper_year": "2024",
      "chunk_content": "[IMAGE3]  \nFig. 2. Gantt chart of an example.  \nTable 4\nProcessing time of jobs on machines.  \nTable 5\nSequence-dependence setup time of families on machines.\n[IMAGE4]  \n$$\nC_{\\max }^{\\prime}(\\boldsymbol{x})=\\sum_{b=1}^{n_{1}} M L_{b-1, b, m}+\\sum_{b=a+1}^{b_{2}} M L_{b-1, b, m}+M L_{a-1, a, m}+M L_{a, a+1, m}+\n$$  \n$$\n\\sum_{b=1}^{a} \\sum_{i=1}^{n_{b}-1} D_{b, i, i+1}+\\sum_{b=a+1}^{b_{2}} \\sum_{i=1}^{n_{b}-1} D_{b, i, i+1}+\\sum_{i=1}^{n_{b}-1} D_{b, i, i+1}\n$$  \n$C_{\\max }^{\\prime}(\\boldsymbol{x})=\\sum_{b=1}^{n_{1}} M L_{b-1, b, m}+\\sum_{b=b+2}^{b_{2}} M L_{b-1, b, m}+M L_{b-1, b, m}+M L_{a, b+1, m}+$  \n$$\n\\sum_{b=1}^{b} \\sum_{i=1}^{n_{b}-1} D_{b, i, i+1}+\\sum_{b=a+1}^{b_{2}} \\sum_{i=1}^{n_{b}-1} D_{b, i, i+1}+\\sum_{i=1}^{n_{b}-1} D_{b, i, i+1}\n$$  \nFor ease of understanding, an intuitive example is provided in Fig. 4. As illustrated in Fig. 4(a), families $\\Gamma_{3}$ and $\\Gamma_{2}$ are assigned to cellular $f_{2}$ and $f_{1}$, respectively. From Fig. 4(b), after swapping the positions of $\\Gamma_{3}$ and $\\Gamma_{2}$, it can be concluded that the processing time of $\\Gamma_{1}$ before $\\Gamma_{3}$ in cellular 1 is not affected, while only $M L_{2,4,3}$ is changed to $M L_{2,4,3}$ in the calculation of processing time after $\\Gamma_{2}$ in cellular 2 .  \nProperty 2. For a feasible solution $\\boldsymbol{x}$, randomly select family $\\Gamma_{n}$ in\n[IMAGE5]  \nFig. 3. Gantt chart of a feasible scheduling solution $\\boldsymbol{x}_{0}$.  \n[IMAGE6]\n(a) Gantt chart of $\\boldsymbol{\\pi}$.\n[IMAGE7]\n(b) Gantt chart after swapping $\\Gamma_{2}$ and $\\Gamma_{3}$.\n[IMAGE8]  \nFig. 4. Illustration of Property 1 and Property 2.  \n[IMAGE9]\n(c) Gantt chart after inserting $\\Gamma_{3}$ in front of $\\Gamma_{1}$.  \nFig. 5. Illustration of Property 3 and Property 4.\ncellular $f$ and family $\\Gamma_{b}$ in cellular $f(f \\neq f$ and each cellular has $M$ machines) from $\\boldsymbol{x}^{C}$. Next, insert $\\Gamma_{b}$ in front of $\\Gamma_{a}$ in $\\boldsymbol{x}^{C}$. After performing this insert operator, a new solution $\\boldsymbol{x}$ is obtained. The CC of calculating $C_{\\max }(\\boldsymbol{x})$ can be reduced from $O(n \\times m)$ to $O(m)$.  \nProof. Assuming that $S_{f}$ and $S_{f}$ families are assigned to cellulars $f$ and $f$, respectively. According to Eqs. (15)-(17), $C_{\\max }^{\\prime}(\\boldsymbol{x})$ and $C_{\\max }^{\\prime}(\\boldsymbol{x})$ can\nreduced from $O(n \\times m)$ to $O(m)$ based on Eqs. (24)-(27).  \nFORMULA_221",
      "question_type": "conceptual deep",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:28",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm within the Bayesian Artificial Immune System (BAIS) framework for generating ensembles of neural networks, what specific implementation steps are required to replace the traditional mutation operator with a probabilistic model, and how does this model, specifically a Bayesian network, capture interactions among variables in the problem?",
      "topics": [
        "optimization"
      ],
      "answer": "Within the BAIS framework, the traditional mutation operator is replaced with a probabilistic model representing the probability distribution of promising solutions. A Bayesian network is adopted as the probabilistic model to capture interactions among the variables. The algorithm evolves a population of single-hidden-layer multilayer perceptron (MLP) networks, using alternative activation functions for each neuron to promote diversity in performance while maintaining high accuracy of classification. The degree of diversity between the classifiers is then estimated.",
      "chunk_id": 11658,
      "paper_id": "Learning Ensembles of Neural Networks by Means of a Bayesian Artificial Immune System",
      "paper_title": "Learning Ensembles of Neural Networks by Means of a Bayesian Artificial Immune System",
      "paper_year": "2011",
      "chunk_content": "ENSEMBLE is a learning paradigm where alternative proposals, called components, combine their individual outputs to produce a unique solution to a given problem [1], [2]. Ensembles of neural networks have been widely explored in the last decade for both classification and regression problems. The main motivation is the possibility of improving the generalization capability and, consequently, the overall performance of the system. Several theoretical and empirical results have indicated that the success of the ensemble paradigm is supported by two prior conditions: their individual components must be accurate enough and must present distinct error profiles [3].  \nBasically, the design of ensembles can be viewed as a threestage process: generation of a pool of candidates, selection of some of them from this pool, and combination of the individual outputs to produce a single output. Given that there is no systematic procedure to properly implement these stages in a broad range of applications, several meta-heuristics have been proposed for helping the design of ensembles.  \nIn this context, and aiming at promoting distinct behavior for the components of the ensembles, some proposals have  \n[^0]been reported in the literature using artificial immune systems (AISs) to generate ensembles of neural networks [4][10], motivated by their remarkable characteristics [11], [12]: 1) they are inherently able to maintain population diversity; 2) the size of the population at each generation is automatically adjusted according to the demands of the problem; and 3) local optimal solutions are simultaneously preserved once located.  \nHowever, the available AISs suffer from a drawback that produces a negative impact on complex optimization problems, such as generation of neural network ensembles, they are not able to deal effectively with building blocks. Given that each candidate solution may be taken as a vector of attributes, building blocks are high-quality partial components of the whole solution [13], [14]. These partial solutions are composed of specific elements of the vector of attributes. If the mutation operator does not take into account the relationship among the attributes of the problem, building blocks are not supposed to survive, being disrupted by mutation. With the preservation of building blocks, you may concentrate the search on reduced portions of the search space, and then the chances of finding the global optimum and local optima increases over time.  \nRecently, we have proposed a general framework to implement high-performance AISs, denoted Bayesian AIS [15], which replaces the traditional mutation operator with a probabilistic model representing the probability distribution of the promising solutions found so far. Then the obtained probabilistic model is used to generate new individuals. A Bayesian network is adopted as the probabilistic model because of its capability to properly capture the most expressive interactions among the variables of the problem. Besides the capability to deal with building blocks, BAIS still preserves the aforementioned advantages of AISs. Founded on the BAIS framework, some algorithms were developed and applied to different optimization problems [16]-[19]. In response to the particularities of each application domain, these algorithms differ in the codification scheme (responsible for the characterization of the search space), in the objective function (e.g., mono-objective or multiobjective), in the suppression mechanism, and also in every operator that depends on the kind of codification adopted. As a consequence, the BAIS of this paper is not the same as the BAIS of previous papers. It employs the same framework (core structure), but is composed of dedicated modules to design ensembles of neural networks.  \nFirstly, BAIS evolves a population of single-hidden-layer multilayer perceptron (MLP) networks, with alternative activation functions for each neuron, aiming at promoting diversity in performance under high accuracy of classification. The degree of diversity between the classifiers is estimated on the",
      "question_type": "theory",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:29",
      "generation_style": "practical_application"
    },
    {
      "question": "How does the CPU time complexity of the LS-EDA algorithm compare to other Gaussian-based EDAs like UMDA ${ }_{c}^{G}$ and RP-EDA, and what factor is suggested to explain the difference in performance?",
      "topics": [
        "performance"
      ],
      "answer": "LS-EDA costs the least CPU time for most benchmark functions, except for F6-F8, and its average CPU time is similar to that of SaNSDE in F7. UMDA ${ }_{c}^{G}$ and RP-EDA have CPU times several orders of magnitude higher than LS-EDA. The power of the EM algorithm employed in LS-EDA is suggested as a potential explanation for this difference in performance.",
      "chunk_id": 8470,
      "paper_id": "A latent space-based estimation of distribution algorithm for large-scale global optimization",
      "paper_title": "A latent space-based estimation of distribution algorithm for large-scale global optimization",
      "paper_year": "2019",
      "chunk_content": "please refer to Larranaga and Lozano (2002), Hansen and Ostermeier (2001) and Kabn et al. (2015). In LS-EDA, we set $N=200, \\omega=0.7$. The experimental results are summarized in Table 6 for 500-D and Table 7 for 1000-D. For all compared algorithms except for EDA-MCC, the average evolutionary curve from 25 independent runs is plotted in Figs. 4 and 5 for 500-D and 1000-D, respectively. The average CPU time of 25 runs for 500-D problems is shown in Fig. 3. First, we compare convergence speeds for all algorithms. The same phenomena are shown in Figs. 4 and 5. The convergence speed of LS-EDA is the fastest one among all the compared algorithms except CMA-ES. For F1, the progress rate of LS-EDA is far more quickly than the compared algorithms, and it seems that the others are trapped into stagnation. For F4, F6 and F8, each of LS-EDA's convergence curves for these functions can be approximated by a hyperbolic curve, while the others seem to fall into trouble with more FEs. For F9 and F10, its evolutionary curves show the fast approaching the best solution at the very beginning, while the curves of the other algorithms show much slower convergence than those of LS-EDA.  \nNext, we compare the CPU time for all algorithms. Figure 3 clearly shows that CMA-ES is the most time-consuming algorithm, followed by UMDA ${ }_{c}^{G}$ and RP-EDA. Their CPU time is several orders of magnitude higher than its peers'. We can find that LS-EDA costs the least CPU time for most of the benchmark functions except for F6-F8, and its average CPU time is similar to that of SaNSDE in F7. Overall, sep-CMA-ES and SaNSDE cost CPU time more than LS-EDA. As a conclusion, in this round, LS-EDA, sep-CMA-ES and SaNSDE are winners, while UMDA ${ }_{c}^{G}$, CMA-ES and RPEDA are the losers. An interesting question is: Despite that UMDA ${ }_{c}^{G}$, RP-EDA and LS-EDA are Gaussian-based EDA, why are UMDA ${ }_{c}^{G}$ and RP-EDA the loser? The answer may be the power of the EM algorithm employed in LS-EDA. We also verify that the advantage of LS-EDA is more significant than that of the others when $D$ increases. Due to space limitation, we do not give the experimental results.  \nFinally, the solution precision of all compared algorithms for 500-D and 1000-D problems is analyzed. The results for 500-D problems are given in Table 6. It can be seen that UMDA FORMULA_246, EDA-MCC, CMA-ES, sep-CMA-ES and LS-EDA perform perfectly on the first group of separable functions F1 and F2. They approach the global optima regardless of the average or best case, and SaNSDE and RP-EDA are slightly poorer than them. On the second group of nonseparable functions F3-F10, LS-EDA, EDA-MCC, CMA-ES and sep-CMA-ES show the most stable performance. They break even on F5 and F6, and both reach the global optimum. On the other functions, they have their merits as well. Although CMA-ES slightly outperforms LS-EDA on three functions F3, F4, and F9, it consumes much more time and memory. On the other functions, their precision is within",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:31",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What is the key algorithmic difference between the $r$-UMDA and the $r$-PBIL in how they update frequencies during the learning process?",
      "topics": [
        "genetic"
      ],
      "answer": "The $r$-UMDA updates frequencies by directly setting them to the relative frequency of values at a given position among the \\$\\mu\\$ best individuals. In contrast, the $r$-PBIL computes a convex combination of the relative frequency with the current frequency, using a scaling factor \\$\\rho\\$ to determine the weight given to each. This means $r$-PBIL incrementally adjusts the frequencies rather than directly replacing them like $r$-UMDA.",
      "chunk_id": 2722,
      "paper_id": "Estimation-of-distribution algorithms for multi-valued decision variables",
      "paper_title": "Estimation-of-distribution algorithms for multi-valued decision variables",
      "paper_year": "2024",
      "chunk_content": "```  \nFurther, each frequency is at least $a$, since this value is added at the end of eq. (1) and since $p_{i, j}^{*} \\geq a$ by definition of $p_{i}^{*}$. Last, since each frequency is at least $a$ after restricting, the largest a frequency can be is $1-(r-1) a=b$.  \nIn order to disallow the extreme frequencies 0 and 1 but to stay close to the binary case, we propose to choose the upper border as $1-1 / n$. Following our ideas above, this implies that the lower border is $1 /((r-1) n)$. This is consistent with the binary case but generalizes to the $r$-valued domain.  \nWe say that an EDA is without margins if and only if the lower border is 0 and the upper border is 1 . That is, the restriction of the frequencies does not take place.\n$r$-UMDA. We generalize the UMDA (Algorithm 1) to the $r$-UMDA (Algorithm 2), utilizing our framework. This leads to the same generalization mentioned by Santana et al. [13]. Like the UMDA, the $r$-UMDA has three parameters, namely the population size $\\lambda \\in \\mathbb{N}_{\\geq 1}$, the selection size $\\mu \\in[\\lambda]$, and the $r$-valued fitness function $f$. It also updates its frequencies analogously to the UMDA by choosing $\\mu$ best individuals from the population of size $\\lambda$ and then setting each frequency at position $i \\in[n]$ for value $j \\in[0 . . r-1]$ to the relative frequency of value $j$ at position $i$ among the $\\mu$ best individuals (line 7). We note that this results in a valid frequency vector for each row $i \\in[n]$, since  \n$$\n\\sum_{j \\in[0, r-1]} \\frac{1}{\\mu} \\sum_{k \\in[\\mu]} \\mathbb{1}\\left\\{x_{i}^{(i, k)}=j\\right\\}=\\frac{1}{\\mu} \\sum_{k \\in[\\mu]} \\sum_{j \\in[0, r-1]} \\mathbb{1}\\left\\{x_{i}^{(i, k)}=j\\right\\}=\\frac{1}{\\mu} \\sum_{k \\in[\\mu]} 1=1\n$$  \n$r$-PBIL. Another popular univariate EDA is population-based incremental learning (PBIL [46]). It operates very similarly to the UMDA, with the only difference being in how it performs an update. In contrast to the UMDA, the PBIL does not set a frequency to the relative frequency of respective values at a position but, instead, computes the convex combination of the relative frequency with the current frequency value in its frequency vector. To this end, it utilizes a parameter $\\rho \\in[0,1]$, the scaling factor.  \nWe generalize the PBIL to the $r$-PBIL (Algorithm 3). Each frequency vector of the $r$-PBIL sums to 1 (before the restriction) because it is a convex combination of the $r$-UMDA's update (which sums to 1 ) and the current frequency vector (which also sums to 1 ).\n$r$-cGA. Another popular univariate EDA is the compact genetic algorithm (cGA [47]). The cGA only has a single parameter $K \\in \\mathbb{R}_{>0}$ ), the hypothetical population size, and it creates only two samples each iteration. It ranks these two samples by fitness and then adjusts each frequency by $\\frac{1}{K}$ such that the frequency of the value of the better sample is increased and that of the worse sample decreased.",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:33",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "What are the precise algorithmic steps for executing the CEDA model, specifically how does it extend a co-evolutionary framework incorporating a divide-and-conquer strategy?",
      "topics": [
        "optimization",
        "Estimation of Distribution Algorithms",
        "co-evolutionary framework",
        "divide-and-conquer strategy"
      ],
      "answer": "The Cooperative Estimation of Distribution Algorithm (CEDA) extends a co-evolutionary framework by incorporating a divide-and-conquer strategy. While the precise algorithmic steps are not explicitly detailed in this content, the CEDA uses this strategy to address challenges in complex and large problems, where local constraints and objectives from each managerial entity and their contributions toward global objectives cannot be effectively represented in a single model. The CEDA's co-evolutionary framework coupled with divide-and-conquer enables it to outperform hybrid Genetic Algorithms (GAs) for Semiconductor Final Test Scheduling (SFTS) problems.",
      "chunk_id": 906,
      "paper_id": "The cooperative estimation of distribution algorithm  a novel approach for semiconductor final test scheduling problems",
      "paper_title": "The cooperative estimation of distribution algorithm: a novel approach for semiconductor final test scheduling problems",
      "paper_year": "2014",
      "chunk_content": "Xin-Chang Hao _ Jei-Zheng Wu $\\cdot$ Chen-Fu Chien $\\cdot$ Mitsuo Gen  \nReceived: 28 July 2012 / Accepted: 16 February 2013\n(C) Springer Science+Business Media New York 2013\nA large number of studies have been conducted in the area of semiconductor final test scheduling (SFTS) problems. As a specific example of the simultaneous multiple resources scheduling problem, intelligent manufacturing planning and scheduling based on meta-heuristic methods, such as the genetic algorithm (GA), simulated annealing, and particle swarm optimization, have become common tools for finding satisfactory solutions within reasonable computational times in real settings. However, only a few studies have analyzed the effects of interdependent relations during group decision-making activities. Moreover, for complex and large problems, local constraints and objectives from each managerial entity and their contributions toward global objectives cannot be effectively represented in a single model. This paper proposes a novel cooperative estimation of dis-  \n[^0]tribution algorithm (CEDA) to overcome these challenges. The CEDA extends a co-evolutionary framework incorporating a divide-and-conquer strategy. Numerous experiments have been conducted, and the results confirmed that CEDA outperforms hybrid GAs for several SFTS problems.  \nKeywords Cooperative estimation of distribution algorithm $\\cdot$ Manufacturing management $\\cdot$ Flexible manufacturing systems FORMULA_4 Semiconductor final test scheduling problems",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:36",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the accuracy of a projection matrix P, obtained through an Estimation of Distribution Algorithm (EDA) for camera self-calibration, be assessed based on the projection of 3-D points onto a 2-D image plane?",
      "topics": [
        "optimization"
      ],
      "answer": "The accuracy of the projection matrix P can be evaluated by calculating the reprojection errors. These errors arise from assumptions such as zero skew (s=0) and equal scale (f=f_u=f_v) that are relaxed through EDA optimization. The matrix P projects a 3-D point (X, Y, Z, 1) onto a 2-D image plane at (u, v, 1) using the formula [u, v, 1]^T = P * [X, Y, Z, 1]^T, where P is derived from intrinsic (K) and extrinsic (R, T) camera parameters.",
      "chunk_id": 10868,
      "paper_id": "Self-Calibration of Traffic Surveillance Cameras Based on Moving Vehicle Appearance and 3-D Vehicle Modeling",
      "paper_title": "SELF-CALIBRATION OF TRAFFIC SURVEILLANCE CAMERAS BASED ON MOVING VEHICLE APPEARANCE AND 3-D VEHICLE MODELING",
      "paper_year": "2018",
      "chunk_content": "To address the problem of estimating the most consistent pair of orthogonal $V_{X}$ and $V_{Z}$ based on the locations of $P, V_{Y}$ and $L_{\\infty}[1][3]$, according to Fig. 4(b), first we choose a random point on $L_{\\infty}$ as $V_{X}$. Next, two auxiliary lines, $L_{1}$ and $L_{2}$, can be obtained. At last, $V_{Z}$ can be defined as the intersection of $L_{2}$ and $L_{\\infty}$.\nVanishing points derived from 3-D parallel lines have been proved to be very helpful for estimating camera parameters [1][3]. Our ultimate target of pinhole self-calibration is to get a projection matrix $P$ so that a 3-D point (X, Y, Z, 1) can be accurately projected onto a 2-D image plane at ( $\\mathrm{u}, \\mathrm{v}, 1$ ):  \n$$\n[u, v, 1]^{T}-P \\cdot[X, Y, Z, 1]^{T}=K \\cdot[R[T] \\cdot[X, Y, Z, 1]^{T}\n$$  \nThe matrix $P$ associated with camera parameters can be decomposed into three matrices, denoted as the intrinsic parameter matrix $K$ with five intrinsic parameters (focal length in $x$ direction $f_{\\mathrm{u}}$, focal length in $y$ direction $f_{\\mathrm{v}}$, coordinates of principal point $p_{\\mathrm{u}}$ and $p_{\\mathrm{v}}$, and skew value $s$ ), the rotation matrix $R$ determined by three extrinsic parameters ( $r o l l$ angle around Z -axis $\\gamma$, pitch angle around X -axis $\\beta$ and yaw angle around Y -axis $\\alpha$ ), and the translation matrix $T$ involving another three extrinsic parameters ( $t_{X}$ moving along X -axis, $t_{Y}$ moving along Y -axis, and $t_{Z}$ moving along Z -axis), respectively.  \nFollowing previous works [8-10], we first assume the camera with zero skew $s=0$ and equal scale, i.e., $f=f_{\\mathrm{u}}=f_{\\mathrm{v}}$. In addition, we assume the camera's principal point $P\\left(p_{\\mathrm{u}}, p_{\\mathrm{v}}\\right)$ to be at the image center. Also, the rough range of camera height is considered to be known. Accurate height value will be derived by EDA in Section 2.4. Except the skew,  \n[IMAGE3]  \nFig. 4. (a) Vertical vanishing points $V_{Y}$ derivation based on $V_{X}, V_{Z}$ and $P$. Dotted lines $L_{1}, L_{2}$ and $L_{3}$ are auxiliary lines. (b) $V_{X}$ and $V_{Z}$ Localization from $V_{Y}, P$, and $L_{\\infty}$. Dotted lines $L_{1}$ and $L_{2}$ are auxiliary lines.\nall the other assumptions will result in reprojection errors. That is why the EDA optimization is further utilized to relax these assumptions later.  \nTo derive translation matrix $T$, the origin $(0,0,0)$ in 3-D world is set to the intersection of perpendicular lines through camera and the ground plane. Therefore, both $t_{X}$ and $t_{Z}$ equal to zero. What's more, $t_{Y}$ is set to the negative of camera height. Accordingly, all camera parameters can be calculated from the orthogonal pair of the vanishing point coordinates $V_{X}\\left(u_{Y_{A}}, v_{Y_{Z}}\\right)$ and $V_{Z}\\left(u_{Y_{Z}}, v_{Y_{Z}}\\right)$, which are derived from extracting foreground vehicle edge lines and the estimated location of FORMULA_89.",
      "question_type": "definition",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:37",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the key takeaway about the application of polynomial interpolation schemes within the context of optimizing fuel-optimal transfers in close-range space rendezvous using the presented EDA approach?",
      "topics": [
        "optimization"
      ],
      "answer": "The key takeaway is that, within the explored parameter space, the SP polynomial interpolation method, specifically with approximately 18 nodes, is associated with the highest quality solutions for fuel-optimal transfers. Furthermore, the BS mapping method appears to be the most promising technique for finding high-quality solutions, regardless of the initial conditions for this specific close-range space rendezvous mission.",
      "chunk_id": 3598,
      "paper_id": "Trajectory optimization of space vehicle in rendezvous proximity operation with evolutionary feasibility conserving techniques",
      "paper_title": "Trajectory optimization of space vehicle in rendezvous proximity operation with evolutionary feasibility conserving techniques",
      "paper_year": "2023",
      "chunk_content": "Table 1 contains the parameters for close-range space rendezvous mission considered in the experiments. Note that the specified initial mass, reference area, and the drag coefficient stands for both target and chaser within the simulation. Since the main aim of the experiments is to analyze the robustness of the presented approach and evaluating the practicality of the schemes for interpolation, several initial conditions  \nTable 1\nClose-range space rendezvous mission parameters\nTable 2\nInitial values for state vector.  \nbased on the practicality in real-world operations of the close-range space rendezvous problem are assumed according to Table 2.  \nBased on the proposed approach, each experiment can be conducted with a different choice for variety of parameters and techniques. For each initial condition, these parameters are number of polynomial points for thrust components, type of the mapping technique, and the interpolation method. The number of interpolation nodes is considered as 5 to 24 , which is 20 cases for this parameter. Results will indicate that no solutions with higher quality can be found with number of nodes more than 18 in the experiments. Also, with respect to three options for interpolating the thrust profile (SP, CR and NK) and four options for the mapping process (LD, LS, BD and BS), total number of 240 cases of setup regarding each initial condition is considered. Running the optimization algorithm 10 times for each case results in a vast database of solutions, including 2400 solutions to be analyzed. In each run, the obtained solutions are kept with its corresponding parameter selection. The top ten best obtained solutions are presented in Table 3. Results are separated for each initial condition.  \nAccording to the results, the high quality solutions correspond to 18 number of nodes for interpolating the components of thrust vector. The optimizer found solutions with almost similar quality by considering other number of nodes close to the top solution. Solving the problem with number of nodes higher than the top solution did not end in a better solution. Therefore, it is implied that the optimizer achieved the best available solution up to this point. Analysis of the employed mapping mechanisms in high quality solutions in Table 3 shows that BS mapping method is the most promising technique in finding the majority of the high quality solutions, regardless of the initial condition for this close-range space rendezvous mission. The question that whether the BS method is also the best mapping mechanism for another space rendezvous mission will be answered in the next subsection. According to the best obtained solutions, the time-variation of relative position and velocity with respect to each initial conditions is shown in Fig. 6. In this figure, the variations of relative states are presented and the value of terminal states are shown as the header of each plot. It shows that the best achieved solutions satisfy terminal conditions.  \nFig. 7 shows the variation of spacecraft mass and the magnitude of thrust acted on the chaser spacecraft. As can be inferred, the spacecraft with initial condition $C_{4}$ requires the highest quantity of propellant for reaching the target space vehicle with respect to maximum level of 122.3 N for thrust. On the other hand, assuming the initial condition of $C_{3}$, results the minimum required thrust level of 45.46 N . Moreover, analyzing the interpolation approaches gives important insights regarding the practicality of the employed polynomial schemes. All top solutions are associated with SP polynomial interpolation method. Best solutions  \nTable 3\nHigh quality solutions (top ten) for fuel-optimal transfers in close-range space rendezvous.\n[IMAGE6]  \nFig. 6. Time histories of state vector for different initial conditions.  \n[IMAGE7]  \nFig. 7. Time histories of thrust magnitude $(\\hat{Y})$ and spacecraft overall mass $\\omega_{j}$.",
      "question_type": "synthesis summary",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:39",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "Within the framework of Estimation of Distribution Algorithms, what mathematical principles govern the performance index $P_{p, m}(A_i) = \\sum_{j=1 ; j \\neq i}^{K} \\delta(A_i, A_j, \\Phi_{p, m})$, and how does this index relate to the observed performance differences between GNG and MB-GNG across varying objective space dimensions?",
      "topics": [
        "analysis"
      ],
      "answer": "The performance index $P_{p, m}(A_i)$ quantifies the performance of algorithm $A_i$ when solving problem $\\Phi_{p, m}$ by summing the $\\delta(A_i, A_j, \\Phi_{p, m})$ values for all other algorithms $A_j$. The function $\\delta$ is not defined in the text. The mean performance index $\\bar{P}_{p}(A_{i}) = \\frac{1}{|\\mathcal{M}|} \\sum_{m \\in \\mathcal{M}} P_{p, m}(A_{i})$ averages the performance index across different objective space dimensions $m$ within the set $\\mathcal{M} = \\{3, 5, 7, 9\\}$. Observed results indicate that MB-GNG generally outperforms other algorithms in dimensions larger than three, except for the nine-objective case where GNG exhibits superior performance. This suggests that the model-building component of MB-GNG is more effective in higher dimensions, but may encounter limitations or overfitting issues when the number of objectives becomes excessively large, leading to GNG's better performance at nine objectives.",
      "chunk_id": 11485,
      "paper_id": "MB-GNG  Addressing drawbacks in multi-objective optimization estimation of distribution algorithms",
      "paper_title": "MB-GNG: Addressing drawbacks in multi-objective optimization estimation of distribution algorithms",
      "paper_year": "2011",
      "chunk_content": "Relying on $\\delta(\\cdot)$, the performance index $P_{p, m}\\left(A_{i}\\right)$ of a given algorithm $A_{i}$ when solving $\\Phi_{p, m}$ is then computed as\n$P_{p, m}\\left(A_{i}\\right)=\\sum_{j=1 ; j \\neq i}^{K} \\delta\\left(A_{i}, A_{j}, \\Phi_{p, m}\\right)$.  \n[IMAGE1]  \nFig. 1. Mean values of the performance index across the different problems and objective space dimensions. Algorithms involved are the leader algorithm (Ldr), the $k$-means (k-ms), EM, Bayesian networks (Bays), CMA-ES (CMA), GNG and the model-building GNG (MBG). NSGA-II (NSII) and SPEA2 (SPE2) are also included for comparison reasons.\n[IMAGE2]  \nFig. 2. Progression of the mean floating-point CPU operations used by the modelbuilding algorithms as the objective space dimension increases. For each algorithm four points are plotted corresponding to $M=\\{3,5,7,9\\}$. See Fig. 1 for a description of the acronyms.  \nThis index intends to summarize the performance of each algorithm with regard to its peers.\nFig. 1 exhibits the results computing the performance indexes. Fig. 1(a) represents the mean performance indexes yielded by each algorithm when solving each problem in all of its configured objective dimensions,\n$\\bar{P}_{p}\\left(A_{i}\\right)=\\frac{1}{|\\mathcal{M}|} \\sum_{m \\in \\mathcal{M}} P_{p, m}\\left(A_{i}\\right) ; \\quad \\mathcal{M}=\\{3,5,7,9\\}$.\nIt is worth noticing that GNG and, particularly, MB-GNG have better overall results than the other algorithms. It is somewhat unexpected that the randomized leader and the $k$-means algorithms do not have a very good overall performance for some problems, like WFG5 and WFG7 for the randomized leader and WFG8 and WFG9 for $k$-means. A possible hypothesis is that these results may be biased by the three-objective problems, where there are sizable differences compared with the results of the other dimensions.  \nThis situation is clarified in Fig. 1(b), which presents the mean values of the index computed for each dimension,\nFORMULA_135.\nIn this representation, it becomes noticeable that MB-GNG outperforms the other approaches in dimensions larger than three, with the exception of the nine objectives case, in which the original GNG outperforms MB-GNG.  \nAnother key issue when dealing with high-dimensional problems is the computational cost of the algorithms. One simple way of inspecting this point is to compute the number of CPU operations dedicated to model building in each case. Fig. 2 summarizes these results. NSGA-II and SPEA2 are not included in the analysis,\nsince they do not perform any model building. The main conclusion in this case is that MB-GNG requires more or less the same amount of resources to yield better results than the other approaches.\nThe authors wish to thank the referee and the associate editor assigned to this paper for their comments and suggestions. They helped to substantially improve the paper. They also wish to thank Prof. Elisenda Molina for her assistance in the preparation of the manuscript. LM, JG, AB and JMM were supported by projects CICYT TIN2008-06742-C02-02/TSI, CICYT TEC2008-06732-C02-02/TEC, SINPROB, CAM CONTEXTS 52009/TIC-1485 and DPS2008-07029-C02-02. CACC was supported by CONACyT project 103570.",
      "question_type": "process",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:42",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "In which practical scenarios does the EDA model named BOA outperform other approaches in the context of probe selection?",
      "topics": [
        "optimization"
      ],
      "answer": "The EDA named BOA outperforms other approaches when seeking the smallest probe set for datasets in the non-unique probe selection problem. It also provides an indication of dependencies between variables or probes, which can be valuable for biologists.",
      "chunk_id": 6980,
      "paper_id": "Bayesian Optimization Algorithm for the Non-unique Oligonucleotide Probe Selection Problem",
      "paper_title": "Bayesian Optimization Algorithm for the Non-unique Oligonucleotide Probe Selection Problem",
      "paper_year": "2009",
      "chunk_content": "In this paper, we presented a new approach for solving the non-unique probe selection problem. Our approach which is based on one of the EDAs named BOA obtains results that compare favorably with the state-of-the-art. Comparing to all the approaches deployed on the non-unique probe selection, our approach proved its efficiency. It obtained the smallest probe set for most datasets. Besides its high ability for optimization, our approach has another advantage over others which is its ability to indicate dependencies between the variables or probes for each dataset. This information can be of interest for biologists.  \nWe also investigated the effect of increasing the dependencies between variables searched by BOA for some of the datasets. According to the presented results, it is possible that the results found for some of these datasets are the global optimal values. This requires more experiments and investigation. The non-unique probe selection has been discussed in this paper according the assumption of existence of single target in the sample. Therefore, one of the future works can be to focus on extending the problem with the assumption of multiple targets in the sample. Also, the discovered dependencies by our approach can be interpreted more precisely by biologists in order to detect more interesting information. As an extension to the presented work, we plan to incorporate several metrics into solution quality measure, and use a multi-objective optimization technique. One of the objectives can be the measure of ability of obtained solutions to recognize all targets present in the sample. This is referred to as decoding ability [10. Using multi-objective optimization, parallelization techniques in the implementation can also be used in order to improve the running time of experiments considerably.",
      "question_type": "advantage",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:43",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the evolutionary algorithm with guided mutation (EA/G) discussed, what specific mathematical conditions or theoretical guarantees are established concerning its convergence properties when applied to the minimum weight dominating set problem?",
      "topics": [
        "mutation"
      ],
      "answer": "The provided information describes a hybrid approach called EA/G-IR, combining the evolutionary algorithm with guided mutation (EA/G) and an improvement operator, and does not specify any mathematical conditions or theoretical guarantees concerning its convergence properties. The content focuses on its performance compared to state-of-the-art approaches on benchmark instances, but lacks any mathematical proofs or formal analysis of convergence.",
      "chunk_id": 4624,
      "paper_id": "A hybrid evolutionary algorithm with guided mutation for minimum weight dominating set",
      "paper_title": "A hybrid evolutionary algorithm with guided mutation for minimum weight dominating set",
      "paper_year": "2015",
      "chunk_content": "In this paper, we have presented a hybrid approach called EA/G-IR combining the evolutionary algorithm with guided\nmutation (EA/G) and an improvement operator for the minimum weight dominating set problem. We have compared the performance of our EA/G-IR approach with the state-of-the-art approaches available in the literature on standard benchmark instances comprising general graphs and unit disk graphs. Computational results clearly show the superiority of EA/G-IR over the state-of-the-art approaches as it is able to find better quality solutions in general in much shorter time.  \nAs a future work, we intend to extend our approach to the connected minimum weight dominating set problem and the capacitated minimum weight dominating set problem. Similar approaches can also be developed for the set covering problem, the minimum weight vertex cover problem and the target coverage problems in wireless sensor networks etc.  \nAcknowledgments Authors are grateful to two anonymous reviewers for their valuable comments and suggestions which has helped in improving the quality of this paper.",
      "question_type": "theoretical foundation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:45",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "How do the update rules for the probability vector differ between Population Based Incremental Learning (PBIL) and Compact Genetic Algorithm (CGA), given that both treat solution variables as independent and utilize a probability vector?",
      "topics": [
        "optimization"
      ],
      "answer": "While both PBIL and CGA utilize a probability vector to represent the joint probability distribution as a product of univariate distributions, the specific mechanisms for updating this probability vector differ. The provided text highlights that PBIL and CGA both use a probability vector, but explicitly states that their update rules are different, without detailing the exact nature of those differences.",
      "chunk_id": 1161,
      "paper_id": "A block based estimation of distribution algorithm using bivariate model for scheduling problems",
      "paper_title": "A block based estimation of distribution algorithm using bivariate model for scheduling problems",
      "paper_year": "2014",
      "chunk_content": "In EDAs, the problem specific interactions among the variables of individuals are taken into consideration. The two main steps of EDAs are to estimate the probability distribution of selected solutions and to generate new chromosomes by sampling this probability distribution. In Evolutionary Computations the interactions are kept implicitly in mind whereas in EDAs the interrelations are expressed explicitly through the joint probability distribution associated with the individual variable selected at each generation. The probability distribution is calculated from a database of selected individuals from the previous generation. An offspring is obtained from the sampling of this probability distribution. Neither crossovers nor mutations have been applied in EDAs. However, to derive the estimation of the joint probability distribution associated with the database containing the selected individuals is a challenge task. The flowchart of EDA is shown in Fig. 1.  \nPaul and Iba (2002) proposed three probability distribution models. In this paper, independent uni-variate marginal distribution is estimated from marginal frequencies as shown in the following:\n$p l\\left(X_{i}\\right)=\\frac{\\sum_{j=1}^{N} \\delta_{i}\\left(X_{i}=x_{i} \\mid D_{i-1}^{S e}\\right)}{N}$\n$\\delta_{i}\\left(x_{i}=x_{i} \\mid D_{i-1}^{S e}\\right)=1$ if in jth individual $x_{i}$ has its ith value; otherwise it is zero.  \nDifferent EDAs use different models for the estimation of probability distribution. Population based incremental learn-  \n[IMAGE0]  \nFig. 1 EDA flowchart\ning (PBIL) proposed by Baluja (1994) and compact genetic algorithm (CGA) proposed by Harik et al. (1999) treat each variable of solutions as independent from one another. As a result, n-dimensional joint probability distribution factorizes as a product of FORMULA_14 univariate and independent probability distributions. PBIL and CGA both use a probability vector while the update rules of probability vector of PBIL and CGA are different.  \nIn order to estimate the relationship between variables, a bivariate dependencies model is built. Zhang (2004) proposed univariate marginal distribution algorithm (UMDA) and another factorized distribution algorithm (FDA) for discrete optimization problems. He introduced the heuristic functions and the limit models of these two algorithms and analyzed the stability of these limit models. Higher order statistics is used to improve the chance of finding the global optimal solution. For applications of UMDA with Laplace corrections in binary and permutation domains is proposed by Paul and Iba (2002).  \nEdge histogram sampling algorithm (EHBSA) is a local search mechanism proposed by Tsutsui (2002). He proposed probabilistic model-building genetic algorithms (PMBGAs) in permutation representation domain using edge histogram based sampling algorithms (EHBSAs). He also proposed two types of sampling mechanisms, EHBSA/WO without template and EHBSA/WT with template which execute based on different situations. Tsutsui et al. (2006) modify his previous research using the EHBSA and proposes another histogram based model which called the node histogram sampling algo-\nrithm (NHBSA). In this paper we employee EHBSA be one of local search mechanism.",
      "question_type": "comparative analysis",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:47",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "To implement the specific EDA mentioned, what data structures are required to represent the population and the histogram model, given that the algorithm uses a real-number encoding for decision variables?",
      "topics": [
        "encoding",
        "data structures",
        "histogram model"
      ],
      "answer": "To represent the population, a data structure capable of storing $M$ individuals is needed, where $M$ is the population size. Each individual should store the decision variables directly in decimal form, as the algorithm uses a real-number encoding. The histogram model $H_{0}^{t}$ requires a data structure that can store the distribution for each variable $n$ across its possible values (bins) from 0 to $max_{n}$, where $max_{n}$ is the maximum value of the $n^{th}$ variable. This can be implemented using arrays or lists to store the probabilities for each bin $j$, where $j$ is in the range $[0, max_{n}]$.",
      "chunk_id": 8254,
      "paper_id": "A Histogram Estimation of Distribution Algorithm for Reversible Lanes Optimization Problems",
      "paper_title": "A Histogram Estimation of Distribution Algorithm for Reversible Lanes Optimization Problems",
      "paper_year": "2019",
      "chunk_content": "Input: population size $M$, sample size $m$, variable size $N$, the maximum value of $n^{t h}$ variable $m a x_{n}$\nStep 1: Initialize population $P$ with $M$ individuals;\nSet initial model $H_{0}^{0}$ with uniform distribution;\nSet generation counter $t \\simeq 1$;\nStep 2: While stopping criterion is not met do Calculate fitness value of $M$ individuals; Sort $M$ individuals in ascending order by their fitness value;\nUpdate the global best solution gbest;\nSelect first $m$ individuals and build histogram model $H_{0}^{t}$ for $n^{t h}$ variable;\n$H_{0}^{t}(j) \\leftarrow n H_{0}^{-1}(j)+(1-\\alpha) H_{0}^{t}(j)$, for each variable $n$ and each bin $j, j \\in\\left[0, m a x_{n}\\right]$.\n$P^{t} \\leftarrow$ new population sampled with model $H_{0}$;\nReplace population $P$ with $P^{t}$;\n$t \\approx t+1$;\nEnd While\nOutput: the gbest and its fitness value\nFor RLOP, the decision variables are the number of lanes of each reversible roadways, which are denoted as FORMULA_111. So, it is natural for us to use a real-number encoding chromosome representation. In a chromosome, the decision variables are directly stored in decimal form. The length of a chromosome is the same as the number of reversible roadways. It should be noted that, for different variables, the feasible solution space is also different.",
      "question_type": "implementation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:49",
      "generation_style": "implementation_focused"
    },
    {
      "question": "How can the quality of the EDA's approximation of the Pareto Set (PS) manifold be measured using the Principal Curve (PC) and Laplacian Eigenmaps (LE) algorithms?",
      "topics": [
        "representation"
      ],
      "answer": "The Principal Curve (PC) algorithm projects solutions from the n-dimensional decision space onto a discrete curve, approximating the PS manifold. Subsequently, the Laplacian Eigenmaps (LE) algorithm reduces the dimensionality of these projected solutions to one dimension, revealing neighborhood relationships. The accuracy of the PS manifold approximation can be inferred by assessing how well these neighborhood relationships in the one-dimensional space correspond to the geometric characteristics of the PS manifold in the original n-dimensional decision space. A better correspondence suggests a higher quality approximation.",
      "chunk_id": 1045,
      "paper_id": "A general framework for evolutionary multiobjective optimization via manifold learning",
      "paper_title": "A general framework for evolutionary multiobjective optimization via manifold learning",
      "paper_year": "2014",
      "chunk_content": "approximate a segment of the PS in the decision space. However, the major drawback of RM-MEDA just lies in its modeling technique, i.e., local PCA, which uses several linear models to approximate the nonlinear manifold. In this case, the number of local models, i.e., $K$, should have significant impacts on the algorithm performances [27]. But unfortunately, $K$ is usually problem dependent.  \nManifold learning, also known as nonlinear dimensionality reduction, tries to find a representation of the data, originally in a high-dimensional ambient space, in a relatively low-dimensional space, while preserving the structural information, especially the neighborhood structure. In the context of machine learning, manifold learning techniques have been widely accepted as a data preprocessing or feature extraction step, after which pattern recognition algorithms (e.g., clustering and classification) are applied. Many algorithms have been proposed to tackle this problem, such as Laplacian eigenmaps (LE) [1], principal curve (PC) [21,9], semi-definite embedding [28] and self-organizing map [29]. Since the dimensionality of the decision space is usually much larger than the number of objectives, the regularity property of a continuous MOP implies that the PS is a low-dimensional manifold embedded in the ambient decision space. Therefore, it is natural and reasonable to exploit advanced manifold learning techniques in the context of multiobjective optimization. There are some works along this direction, such as semi-definite embedding has been used for reducing the redundant objectives in many-objective optimization [23] and self-organizing map has been employed as a useful tool for visualizing the high dimensional PF [4] and generating offspring [3]. Nevertheless, the advantages of manifold learning in EMO have not been fully exploited. In this paper, we present a general framework that applies advanced manifold learning techniques to EMO in a systematic and rational manner. As a preliminary study along this direction, this paper only discusses the bi-objective continuous MOPs. At each generation, we first use the PC algorithm to project solutions, in the $n$-dimensional decision space, to a discrete curve that passes through their middle and provides an approximation of the PS manifold. Afterwards, we use the LE algorithm to reduce the dimensionality of these projected solutions to one, and find out the neighborhood relationship in a one-dimensional space. Correspondingly, such neighborhood relationship can be readily applicable to solutions in the original $n$-dimensional decision space, and it also reflects the geometric characteristic of the PS manifold. Finally, based on the neighborhood relationship, for each solution in the population, we will locate its neighboring solution and interpolate a new point as an offspring.  \nIn the remainder of this paper, we first provide the problem formulation of MOP in Section 2. Then, we make some comments on RM-MEDA in Section 3. Afterwards, we present the technical details of our framework in Section 4. Some experiments are conducted in Section 5 to validate the effectiveness of our proposed algorithm, and finally Section 6 concludes this paper and provides some future directions.",
      "question_type": "evaluation metrics",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:51",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "Based on the text, what is the main conclusion regarding the comparative performance of EMSM-EDA against EMNA$_{8}$, AMaLGaM, JADE, and SaDE across unimodal, multimodal, and complicated composition functions within the CEC2013 test suite?",
      "topics": [
        "performance"
      ],
      "answer": "The EMSM-EDA generally exhibits superior performance on unimodal functions (CEC2013$_{1}$-CEC2013$_{5}$) compared to EMNA$_{8}$, AMaLGaM, JADE, and SaDE, often finding optimal solutions. For basic multimodal functions (CEC2013$_{6}$-CEC2013$_{20}$), EMSM-EDA initially performs comparably to JADE with 30 dimensions, but is surpassed by JADE with 50 dimensions. On complicated composition functions (CEC2013$_{21}$-CEC2013$_{28}$), EMSM-EDA demonstrates strong performance with 30 dimensions, but is outperformed by AMaLGaM with 50 dimensions, while remaining superior to EMNA$_{8}$, JADE, and SaDE.",
      "chunk_id": 1529,
      "paper_id": "An efficient mixture sampling model for gaussian estimation of distribution algorithm",
      "paper_title": "An efficient mixture sampling model for gaussian estimation of distribution algorithm",
      "paper_year": "2022",
      "chunk_content": "This part compares EMSM-EDA with EMNA ${ }_{8}$ [8], AMaLGaM [6], JADE [46], and SaDE [47] on IEEE CEC2013 test suite. The parameter settings of EMNA $_{8}$, JADE, and SaDE are based on the above references. The test results of AMaLGaM are directly obtained from reference [6]. To analyze the comparison results more clearly, this paper utilizes the method in [48], where \"  \n[IMAGE9]  \nFig. 9. Evolution of FEVs derived from EMSM-EDA and EDA ${ }^{5}$ on 4 functions of CEC2014 benchmark functions with 100D.\n+\", \"-\", and \" $\\approx$ \" denote that the performance of the comparison algorithm is better than, worse than, or similar to EMSMEDA, respectively. In addition, the best results are bolded. Tables 7 and 8 summarize the test results obtained by the five algorithms on test suite with 30D and 50D. The comments can be obtained.  \n1. CEC2013 ${ }_{1}$-CEC2013 ${ }_{5}$ are unimodal functions, on which EMSM-EDA shows the best performance among the five algorithms with 30D and 50D. For the case of 30D, EMSM-EDA can find the optimal solutions for all 5 test functions, while AMaLGAM fails on CEC2013 ${ }_{3}$. Moreover, JADE and SaDE only obtain the optimal solutions of CEC2013 ${ }_{1}$ and CEC2013 ${ }_{5}$. In particular, $\\mathrm{EMNA}_{8}$ cannot find the optimal solutions for all 5 test functions. When the test functions are 50D, EMSM-EDA finds the optimal solutions for 4 test functions and still has the best performance.\n2. For basic multimodal functions $\\mathrm{CEC} 2013_{6}$ - $\\mathrm{CEC} 2013_{20}$ with 30D, EMSM-EDA and JADE have better performance which can obtain 8 best solutions for all 15 test functions. AMaLGAM obtains 2 best solutions. Moreover, there is only 1 best solution for $\\mathrm{EMNA}_{8}$ and SaDE. In the case of 50D, EMSM-EDA is surpassed by JADE on 9 functions, which indicates the performance of JADE is superior to EMSM-EDA. EMSM-EDA performs much better than $\\mathrm{EMNA}_{8}$, AMaLGAM, and SaDE.\n3. For complicated composition functions $\\mathrm{CEC} 2013_{21^{-}} \\mathrm{CEC} 2013_{28}$ with 30D, EMSM-EDA finds 4 best solutions for all 8 test functions and has the best performance. As a comparison, AMaLGAM and JADE can obtain 3 best solutions. Moreover, SaDE only finds 1 best solution. As a classical GEDA, $\\mathrm{EMNA}_{8}$ cannot obtain best solutions. For test functions with 50D, although EMSM-EDA defeats $\\mathrm{EMNA}_{8}$, JADE, and SaDE, it is surpassed by AMaLGAM on 4 test functions, which indicates AMaLGAM performs better than EMSM-EDA.",
      "question_type": "evaluation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:53",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of EDAs, how does the algorithmic mechanism of learning dependencies between variables contribute to the effectiveness of EDAs compared to Genetic Algorithms (GAs) for configuration design problems?",
      "topics": [
        "evolutionary"
      ],
      "answer": "EDAs are chosen to solve configuration design problems because, unlike GAs, many EDAs exploit the structure of the problem, such as dependencies between variables, to generate new solutions at each iteration of the optimization process. This is particularly relevant because mechanical assemblies often feature dependencies between their constituting components. Furthermore, EDAs have been shown to require fewer function evaluations to find optimal solutions compared to GAs, which is crucial when fitness evaluation, involving physics-based simulation, is computationally expensive.",
      "chunk_id": 8662,
      "paper_id": "Configuration Design of Mechanical Assemblies using an Estimation of Distribution Algorithm and Constraint Programming",
      "paper_title": "Configuration Design of Mechanical Assemblies using an Estimation of Distribution Algorithm and Constraint Programming",
      "paper_year": "2019",
      "chunk_content": "A notable trend in engineering is the increasing application of artificial intelligence and computational techniques to automate and improve design and manufacturing workflows. In particular, improving the early-stage design process can lead to significant cost-savings associated with the development and manufacturing of optimally functioning products [1].  \nOne challenging early-stage design problem in mechanical engineering is configuration design [2], defined as follows. Given a fixed set of predefined components and joints, find the optimal combination of components interfaced via joints that exhibits the desired mechanical behavior. An example of such a problem would be to compose a suspension system out of beams, springs, and dampers via fixed or spherical joint types, that would have minimal acceleration at a particular point on the chassis, as illustrated in Fig. 1.  \nThe configuration design problem can be characterized as a discrete, constrained, and black-box optimization problem, which is difficult to solve. First, we can treat the configuration design problem as operating in the space of graphs, where a particular graph represents a mechanical assembly with vertices as joints and edges as components. Each node and edge can be considered as a categorical design variable whose\n[IMAGE_0]  \nFig. 1. Configuration design problem for a mechanical assembly.\nvalues specify the types of components and joints being used in the assembly. Also, several constraints must be satisfied for a given configuration to be considered feasible as a physically realizable and practical mechanical assembly. Moreover, the precise analytical form of the fitness function for a given solution depends on its configuration. Hence, evaluation of each solution requires invoking a physics-based simulation solver with the configuration as input.  \nConsidering the above characterization, the current work applies an evolutionary computation (EC) technique to solve configuration design problems. In particular, this paper investigates using an Estimation of Distribution Algorithm (EDA). EDAs are a class of evolutionary algorithms [3]-[13] that use probability distributions estimated from a pool of candidate solutions to sample new solutions at each iteration of optimization. Reasons for choosing the EDA approach are as follows.  \nFirst, fitness evaluation is expensive for mechanical assemblies, especially for those exhibiting dynamic behaviors. For example, evaluating the fitness of a suspension system requires physics-based simulation of its behavior over a specified time period. Even with the most advanced solvers, it can take in the order of minutes to evaluate a single solution. Hence, it is critical to minimize fitness evaluations as much as possible.  \nSecond, most mechanical assemblies feature dependencies between their constituting components. Such dependencies should be leveraged in solving the problem, either by learning them during the optimization process or being specified by  \nthe designer. If the dependency knowledge is learned, it can be communicated to the designer for better interpretation of the solutions found and exploring alternatives. The knowledge can also be reused for solving similar design problems later.  \nAn EDA is deemed suitable in addressing the above challenges. First, for various EDAs, it has been shown that a fewer number of function evaluations are required to find optimal solutions compared to genetic algorithms (GA) [4], [5], [7], [11], [12], [14]. Second, many EDAs exploit the structure of the problem, e.g., dependencies between variables, to generate new solutions at each iteration of the optimization process [4], [6]-[13]. If the designer has prior knowledge about the problem, this can be introduced in the form of a probability distribution model. Also, most EDAs can learn the problem knowledge as part of optimization, which can be communicated to the designers for their benefit.",
      "question_type": "relationship",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:50:55",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "What specific implementation steps are required for the EDA named Natural Gradient based Estimation of Distribution Algorithm (NAGEDA) to repair the covariance matrix?",
      "topics": [
        "Estimation of Distribution Algorithms"
      ],
      "answer": "In NAGEDA, after computing the maximum likelihood estimate of the covariance matrix \\$\\boldsymbol{\\Sigma}\\\\, a repair technique is applied. This involves replacing any eigenvalues of \\$\\boldsymbol{\\Sigma}\\\\ that are below a threshold of 10^{-100} by setting them to the minimum value of 10^{-100}. Following this, the matrix \\$\\boldsymbol{\\Sigma}\\\\ is reconstructed using the modified eigenvalues.",
      "chunk_id": 4751,
      "paper_id": "An Estimation of Distribution Algorithm based on the Natural Gradient and the Boltzmann Distribution",
      "paper_title": "An Estimation of Distribution Algorithm based on the Natural Gradient and the Boltzmann Distribution",
      "paper_year": "2015",
      "chunk_content": "Initial parameters: $\\vec{\\mu}=[0,0]^{\\top}$ and $\\boldsymbol{\\Sigma}=\\mathbf{I}$.\nFigure 2 shows the results of this experiment. Once again Figures 2-(b) and 2-(c) show similar behaviour; both are focusing the Gaussian distribution on a smaller area around the global optimum. On the other hand, the parameter $\\beta=1 / 10$ encourages the increment of the spread of the Boltzmann density. As a consequence, in Figure 2-(a) the multivariate Gaussian distribution covers a bigger area according to the step size. This behaviour might be very useful to avoid being trapped in local optimum locations.  \nThe previous experiments suggest that our proposal is capable of managing the exploration and exploitation phases. Note that, it is a desirable attribute to build effective evolutionary algorithms and maintain the diversity of the population [8] [16]. The next section is dedicated to building an Estimation of Distribution Algorithm (EDA) based on the natural gradient developed through the previous sections.\nThe Estimation of Distribution Algorithms (EDAs) fit a multivariate density function on regions near optimum locations; so that any new sample might be near the global optimum. However, it is well-known that the EDA approach might reduces the spread of population too early [13]. The EDA presented below deals with similar issues by effectively using the gathered information through the optimisation process. In addition, some of the ideas presented here can be applied in the general EDA context.  \nThis section introduces our proposal named Natural Gradient based Estimation of Distribution Algorithm (NAGEDA), see Figure 3. The algorithm exploits the developed updating rules for the parameters $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}=\\mathbf{C C}^{\\top}$. The central idea consists in the computation of a search distribution capable of predicting the location of optimum regions. Here, the Natural Gradient estimator developed in sections 3 and 4 plays an important role.  \nThe NAGEDA starts with a random population, which is utilised to compute the fitness values $\\mathcal{F}\\left(\\vec{x}_{i}\\right)$ and the energy values $\\mathcal{G}\\left(\\vec{x}_{i}\\right)$. Note that Eq. (20) is a valid formula to find the maximum values of the fitness function $\\mathcal{F}(\\vec{x})$. But, the minimization problems should be attained via $\\mathcal{F}(\\vec{x})=$  \n$-\\mathcal{F}(\\vec{x})$. Then, the whole set of individuals $\\mathcal{P}^{(t)}$ is used to compute the maximum likelihood estimates $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}$. Additionally, a repair technique is applied to the estimate $\\boldsymbol{\\Sigma}$, line 7. This technique replaces the eigenvalues below $10^{-100}$ by setting the minimum value to $10^{-100}$; as a consequence the matrix $\\boldsymbol{\\Sigma}$ is built again. Next, the initial matrix $\\mathbf{C}$ is computed via a singular value decomposition of $\\boldsymbol{\\Sigma}$. It allows for the estimate of the vectors $\\vec{z}_{i}$; note that $\\vec{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. Hence, the proposed natural gradient is computed to update the parameters $\\vec{\\mu}$ and $\\boldsymbol{\\Sigma}$, line 10 . Next, new individuals are simulated from the updated multivariate Gaussian density. Since the set $\\mathcal{P}_{S}^{(t)}$ could have better individuals than the actual population, the next population $\\mathcal{P}^{(t+1)}$ is chosen by $\\mathcal{P}^{(t)} \\cup \\mathcal{P}_{S}^{(t)}$. This step adds the necessary selective pressure to maintain the improvement of the population. This algorithm only needs to update the variables $\\beta$ and $\\eta$, but an auto-adaptive rule is added for this purpose, lines 16-24.",
      "question_type": "implementation",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:50:56",
      "generation_style": "practical_application"
    },
    {
      "question": "Regarding the AAVS-EDA and EMNA${_g}$ algorithms, what differences in search direction identification are observed during the evolution process, specifically concerning the cosine of the angle $\\theta$ and its implications for functions $f_2$, $f_6$, and $f_{18}$?",
      "topics": [
        "performance"
      ],
      "answer": "During the evolution process, AAVS-EDA generally achieves larger cosine values of the angle $\\theta$ than EMNA${_g}$, indicating that AAVS enables AAVS-EDA to identify better search directions. For function $f_2$, AAVS-EDA finds the steepest descent direction after only a few generations. For $f_{18}$, AAVS-EDA detects better search directions than EMNA${_g}$ in the early and middle search stages. However, in the late search stage for $f_{18}$, both algorithms are trapped in local optimal regions, where the main search direction becomes less meaningful.",
      "chunk_id": 11065,
      "paper_id": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_title": "Anisotropic adaptive variance scaling for Gaussian estimation of distribution algorithm",
      "paper_year": "2018",
      "chunk_content": "[IMAGE9]  \nFig. 7. Evolution of FEV derived from AAVS-EDA, EMNA ${ }_{g}$, AMaLGaM and IPOP-CMAES on (a) $f_{2}$, (b) $f_{6}$ and (c) $f_{18}$.  \nFig. 6 shows the variation of $\\cos (\\theta)$ during the evolution process. It is clear that, for all the three functions, AAVS-EDA achieves larger cosine values than EMNA ${ }_{g}$ in most cases, which means that AAVS indeed enables AAVS-EDA to identify better search direction. Especially for $f_{2}$, AAVS-EDA finds the steepest descent direction after only a few generations. As for $f_{18}$, AAVS-EDA also detects better search direction than EMNA ${ }_{g}$ in the early and middle search stages. However, in the late search stage, both algorithms are trapped into local optimal regions, where the main search direction becomes less meaningful.  \nFig. 7 shows the evolution curve of FEV, from which it can be observed that AAVS-EDA significantly outperforms EMNA ${ }_{g}$ on all the three functions. Besides EMNA ${ }_{g}$ and AAVS-EDA, Fig. 7 also presents the variation of FEVs obtained by AMaLGaM[19] and IPOP-CMAES[26]. As mentioned in section 1, AMaLGaM is an efficient EDA variant which synthetically adopts the strategies of AMS, AVS and SDR. IPOP-CMAES is an improved CMA-ES variant, which is competitive to many state-of-the-art EAs [27]. To ensure the fairness of the comparison, the AMaLGaM version which adopts the multivariate Gaussian model and a fixed population size was employed in our experiment. Its population size was set the same as that of AAVS-EDA, and all the other parameters were set the same as in [19]. As for IPOP-CMAES, we employed the source code and the default parameter settings provided by the authors of [43, 44]. It can be seen from Fig. 7(a) that AAVS-EDA, AMaLGaM and IPOP-CMAES all perform pretty well on $f_{2}$, where IPOPCMAES finds the global optimum with much fewer FEs. As for $f_{6}$, it can be seen from Fig. 7(b) that AMaLGaM gets stuck earlier; IPOP-CMAES improves AMalGaM and obtains the best solution within the allowed maximum number of FEs, but it still falls into a local optimum finally; Different from these two algorithms, AAVS-EDA keeps an improvement tendency during the whole evolution process. Fig. 7(c) presents the results on hybrid function $f_{18}$, from which it can be observed that all the four algorithms are trapped into local optimal solutions. In spite of this, AAVS-EDA demonstrates satisfying performance since it gets stuck at the latest and finds the best solution among these algorithms tested. It is notable that AAVSEDA still finds better solutions for $f_{18}$ after consuming about half of FEs. The reason is that it has strong exploration ability and identifies a relatively good search direction at that time, which can be clearly illustrated by Fig. 6(c).\n4.3 Comparison with other state-of-the-art EAs",
      "question_type": "comparison",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:50:59",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What are the key algorithmic differences between the Cauchy EDA and Rosenbrock's algorithm in how they update their models of the local neighborhood?",
      "topics": [
        "search",
        "Estimation of Distribution Algorithms"
      ],
      "answer": "The Cauchy EDA, as a population-based algorithm, updates its model of the local neighborhood based on a relatively large set of selected individuals each generation. Rosenbrock's algorithm, which maintains only the best-so-far solution, updates its model (orthonormal basis) only in strictly defined situations, with the time periods using the same model lasting a varying number of iterations. Additionally, the Cauchy EDA uses the Cauchy distribution to sample new candidate solutions, while Rosenbrock's algorithm uses a strictly defined pattern, iterating over all axes of the orthonormal basis and generating one solution in the respective direction in a particular iteration.",
      "chunk_id": 7481,
      "paper_id": "Comparison of cauchy EDA and rosenbrocks algorithms on the BBOB noiseless testbed",
      "paper_title": "Comparison of Cauchy EDA and G3PCX Algorithms on the BBOB Noiseless Testbed",
      "paper_year": "2010",
      "chunk_content": "Benchmarking, Black-box optimization, Estimation-of-distribution algorithm, Cauchy distribution, Rosenbrock's algorithm\nDuring the black-box optimization benchmarking (BBOB) workshop in 2009 many diverse algorithm were benchmarked on a well-prepared set of functions using common conditions. The BBOB 2010 methodology [2] provides additional means to compare two algorithms in more detail. In this paper, two algorithms which took part in the BBOB 2009 workshop are further compared. Data for both algorithms were taken from the 2009 benchmarking, but the comparison is made using the new post-processing scripts and templates for BBOB 2010.  \nThe two algorithms chosen for the comparison are:  \n[^0]- Rosenbrock's algorithm introduced in [8]. It could be described as an adaptive pattern search. Its performance on the BBOB 2009 noiseless test suite was reported in [6].\n- The estimation-of-distribution algorithm (EDA) with Cauchy sampling distribution (Cauchy EDA) [5]. It represents the class of evolutionary optimization algorithms.\nDespite their different origins, both algorithms maintain the model of local neighborhood. It is interesting to see if there exists any systematic difference resulting from the different adaptation mechanisms and other differences between the algorithms, or if the similar principle of maintaining the model of the local neighborhood also unifies the performance of both algorithms.\nIn the next section, both algorithms are shortly described and their differences are emphasized. Sec. 3 contains all the results used to compare the algorithms and their discussions. After the presentation of the time demands of both algorithms in Sec. 4, Sec. 5 concludes the paper.\nThe exact descriptions of the algorithms along with the parameter settings can be found in [6] and [5], respectively. The main differences between the algorithms are:  \n- The Cauchy EDA is a population based algorithm, while Rosenbrock's algorithm maintains the best-sofar solution only.\n- The Cauchy EDA updates the model of the local neighborhood on the basis of (a relatively large set of) selected individuals each generation. Rosenbrock's algorithm updates the model (orthonormal basis) only in strictly defined situations; the time periods which use the same model may last varying number of iterations.\n- The Cauchy EDA uses the Cauchy distribution to sample new candidate solutions. Rosenbrock's algorithm uses strictly defined pattern to sample new candidates; it iterates over all axes of the orthonormal basis and generates one solution in the respective direction in a particular iteration.\n- To fight the premature convergence, it uses a constant multiplier to enlarge the variance of the distribution (as suggested in [4]). Rosenbrock's algorithm needs no such modification.\nFor both algorithms, the crafting effort FORMULA_0.  \n[^0]:    Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.\nGECCO'10, July 7-11, 2010, Portland, Oregon, USA.\nCopyright 2010 ACM 978-1-4503-0073-5/10/07 ...S10.00.",
      "question_type": "comparative analysis",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:51:00",
      "generation_style": "comparative_analysis"
    },
    {
      "question": "How should a developer structure the code for the EDA, based on the description, to effectively implement the neighborhood generation strategies using insert, swap, and inverse operators?",
      "topics": [
        "optimization"
      ],
      "answer": "To implement the EDA with insert, swap, and inverse operators for neighborhood generation, the code should include functions for each operator: `insert(solution)`, `swap(solution)`, and `inverse(solution)`. A main loop should randomly choose one of these four strategies (including an implicit 'no change' option) to generate a neighboring solution. The code must then evaluate the generated neighbor to select the best one to update the leading solution. Finally, the remaining solutions should be added to two shared neighbor sets.",
      "chunk_id": 10519,
      "paper_id": "An Improved Discrete Migrating Birds Optimization for Lot-Streaming Flow Shop Scheduling Problem with Blocking",
      "paper_title": "An Improved Discrete Migrating Birds Optimization for Lot-Streaming Flow Shop Scheduling Problem with Blocking",
      "paper_year": "2018",
      "chunk_content": "Insertion, swap and inverse operators are commonly used to produce a promising neighboring solution, which can enhance the solution's exploitation ability by slightly disturbing the neighboring solution. For more details about the above operators, please refer to [8].  \nIn this section, three strategies based on insert, swap, and inverse operators are proposed: (1) perform insert once; (2) apply swap one time; (3) conduct inverse once. Generally speaking, more strategies generate different solutions with a larger probability than a single strategy, and avoid the population trapping in local optima.  \nWe randomly chose one of the above four strategies to generate solutions, in which the best neighbor solution is selected to update the leading solution, and the remaining solutions are put into two shared neighbor sets, respectively.",
      "question_type": "implementation focused",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:51:02",
      "generation_style": "implementation_focused"
    },
    {
      "question": "In the context of networked control systems, how does the buffer size at the controller impact the evaluation of the Estimation of Distribution Algorithm's (EDA) performance, specifically considering the trade-off between utilizing the most recent plant state and mitigating the effects of network-induced delays and packet losses?",
      "topics": [
        "design"
      ],
      "answer": "The buffer size, exemplified by a size of 1, dictates that the sensor packet with the latest timestamp updates the buffer content. Evaluating the EDA's performance requires assessing how effectively it utilizes this most recent, potentially delayed or intermittently available, plant state, \\(\\operatorname{buffer}(A)\\), to compute the control signal \\(\\boldsymbol{u}\\) using the state feedback controller \\(\\boldsymbol{u}=\\boldsymbol{K} \\operatorname{buffer}(A)\\). The evaluation must quantify the impact of sensor-to-controller delay \\(\\tau_{s c}\\) and packet losses modeled by switches \\(S_1\\) and \\(S_2\\) on the accuracy and stability of the control signal, considering that the controller is event-driven based on buffer updates.",
      "chunk_id": 5669,
      "paper_id": "Optimization and stabilization of networked control systems  An Estimation of Distribution Algorithm approach",
      "paper_title": "Optimization and Stabilization of Networked Control Systems: an Estimation of Distribution Algorithm approach\\",
      "paper_year": "2008",
      "chunk_content": "The NCS considered in this paper is depicted in Fig.1, where the plant is modeled by a linear discrete-time system:  \n$$\n\\boldsymbol{x}(k+1)=\\boldsymbol{F} \\boldsymbol{x}(k)+\\boldsymbol{G} \\boldsymbol{u}(k)\n$$  \nwhere $\\boldsymbol{x}(k) \\in \\mathbb{R}^{n}$ and $\\boldsymbol{u}(k) \\in \\mathbb{R}^{m}$ are the plant state and the control input, respectively. $\\boldsymbol{F}$ and $\\boldsymbol{G}$ are known matrices with appropriate dimensions.  \nThe sensor is time-driven. At each sampling period, the sampled plant state and the time it is sampled (i.e., timestamp) are encapsulated into a packet and sent to the controller via the network. The timestamp will ensure the controller determine the order of the sensor packets, and  \n[^0]:    Electrical and Computer Engineering Department, North Carolina State University, Raleigh, NC-27606, USA. Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, Beijing, P. R. China, 100084.  \n[IMAGE0]  \nFig. 1. The structure of the concerned networked control systems\ncorrespondingly select the right one to compute the control signal. In practice, the data packets in NCSs usually suffer time delays and packet losses during network transmissions. As shown in Fig.1, for the considered NCSs, we use $\\tau_{s c}$ and $\\tau_{c a}$ to denote the sensor-to-controller delay and the controller-to-actuator delay, and use two switches $S_{1}$ and $S_{2}$ to model the packet losses in the backward network and the forward network. For example, when $S_{1}$ is open, the sensor packet is lost during the network transmission from the sensor to the controller; whereas when $S_{1}$ is closed, the packet is successfully transmitted to the controller with a sensor-to-controller delay $\\tau_{s c}$. Similar arrangements are for the forward network.  \nThe controller has a buffer denoted as buffer A. The buffer size used in this paper is 1 , which implies that the sensor packet with the latest timestamp is used to update the buffer content. In more details, when a sensor packet arrives at the controller, it will be compared with the timestamp of the plant state in buffer A. The recent plant state (i.e., the one with the recent timestamp) and its timestamp will be put into buffer A. The networked controller is a memoryless state feedback controller with the following form:  \n$$\n\\boldsymbol{u}=\\boldsymbol{K} \\operatorname{buffer}(A)\n$$  \nwhere $\\boldsymbol{K}$ is the feedback gain to be designed, $\\operatorname{buffer}(A)$ is the updated plant state in buffer A. The controller is eventdriven, i.e., whenever there is new data in buffer A, the controller starts calculating the control signal. Immediately after the calculation, the new control signal and the timestamp of the used plant state are encapsulated in a packet and sent to the actuator via the network. The timestamp will ensure the actuator select the right control signal to control the plant.",
      "question_type": "evaluation metrics",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:51:05",
      "generation_style": "evaluation_metrics"
    },
    {
      "question": "What is the primary objective of the back mixing methodology described in the context of EDAs, and how does it address challenges related to fitness landscapes?",
      "topics": [
        "fitness"
      ],
      "answer": "The primary objective of back mixing is to refine the solution search process in Estimation of Distribution Algorithms by mixing chromosomes with flipped patterns, accepting changes based on fitness improvement. It aims to deal with plateaus and basins in real-world problem landscapes by allowing side walks (changes taken for equal fitness) only when strict fitness improvement is not initially achieved, thus balancing exploration and exploitation while mitigating strong drift effects.",
      "chunk_id": 4506,
      "paper_id": "Optimization by Pairwise Linkage Detection",
      "paper_title": "Optimization by Pairwise Linkage Detection, Incremental Linkage Set, and Restricted / Back Mixing: DSMGA-II",
      "paper_year": "2015",
      "chunk_content": "Algorithm 3: Back Mixing\nP: population, \\(f\\) : evaluation function, \\(T\\) : trial solution\n\\(E\\) : set of candidate solutions\nInput: \\(D\\) : donor, \\(L\\) : mask\nimproved \\(\\leftarrow\\) false\nfor \\(j=1\\) to \\(\\lceil\\mathcal{P}\\rceil\\) do\n\\(T \\leftarrow P{j}\n\\(T{L} \\leftarrow D{L}\nif \\(f(T)>f\\left(P{j}\\right)\\) then\n\\(P{j} \\leftarrow T\\)\nimproved \\(\\leftarrow\\) true\nelse\nif \\(f(T)=f\\left(P{j}\\right)\\) then\n\\(E \\leftarrow E \\cup\\{T\\}\\)\n-improved then\naccept all solutions in E\nreturn \\(\\mathcal{P}\\)\n```  \nof the back mixing. Every chromosome in the population is then mixed with the flipped pattern, and the change is adopted only if the fitness is improved. Note that the acceptance criterion is different from the restricted mixing. Real-world problems may contain various landscapes such as plateaus and basins, where solutions are of equal qualities and difficult to explore. Many operators have been developed to deal with such difficulties, such as the forced improvements (FI) [3]. However, diversity issue should be handled carefully. The back mixing tempts to substitute every solution with the same allele fragment, and it causes a strong drift effect if side walks (changes taken for equal fitness) are allowed. In contrast, if the acceptance criterion is set to strict fitness improvement, more evaluations are needed in order to jump out of the plateaus. Either case decreases the performance. Therefore, the acceptance criterion for the back mixing is set to strict fitness improvement as default, and side walks are allowed only if no solution is improved with the default setting during the back mixing. The pseudo-code for the back mixing is given in Algorithm 3.  \nNote that the implementation is slightly different from the above to alleviate the computational burden. In short, the idea behind this operator is graph refining to reduce unnecessary evaluations. The empirical results suggest that the back mixing is able to deal with both plateaus and diversity issues, which is detailed in Section 4.3.",
      "question_type": "application",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:51:07",
      "generation_style": "synthesis_summary"
    },
    {
      "question": "In the context of Multi-Objective Evolutionary Algorithms (MOEAs), how does the algorithmic mechanism of dominance-based selection, as implemented in algorithms like Fast Non-dominated Sorting Genetic Algorithm (NSGA-II), Pareto envelope-based selection algorithm II (PESAII), and the improved strength Pareto EA (SPEA2), contribute to approximating the Pareto optimal set for multi-objective optimization problems (MOPs)?",
      "topics": [
        "genetic"
      ],
      "answer": "Dominance-based MOEAs, such as NSGA-II, PESAII, and SPEA2, approximate the Pareto optimal set by distinguishing and selecting promising candidate solutions. NSGA-II constructs an initial population and selects solutions with a higher front order until the original population size is reached using non-dominated sorting and crowding distance comparison. PESAII and SPEA2 maintain non-dominant solutions and remove dominant solutions from the population. This process aims to find the best set of solutions in the decision space, where the objective functions \\(f_{1}(\\mathbf{x}), \\ldots, f_{k}(\\mathbf{x})\\) are minimized, subject to constraints \\(f_{j}(\\mathbf{x}) \\leq f_{j}(\\mathbf{x}^{*})\\) for all \\(j\\) from 1 to \\(m\\), and \\(f_{j}(\\mathbf{x})=f_{j}(\\mathbf{x}^{*})\\) for at least one objective function. Here, \\(\\mathbf{x}\\) represents the optimization parameters \\((x_{1}, x_{2}, \\ldots, x_{n})\\) in the solution space \\(S\\) within \\(R^{n}\\).",
      "chunk_id": 1925,
      "paper_id": "Multi-Objective Deep Network-Based Estimation of Distribution Algorithm for Music Composition",
      "paper_title": "Multi-Objective Deep Network-Based Estimation of Distribution Algorithm for Music Composition",
      "paper_year": "2022",
      "chunk_content": "Multi-objective optimization problems (MOPs) represent optimization problems with the objectives of conflicting relationships [17]. Typical MOPs are mathematically defined as follows [18]:  \n$$\n\\begin{gathered}\n\\min \\mathbf{F}(\\mathbf{x})=\\left[f_{1}(\\mathbf{x}), f_{2}(\\mathbf{x}), \\ldots, f_{k}(\\mathbf{x})\\right]^{T} \\\\\n\\mathbf{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)^{T} \\\\\n\\text { subject to } f_{j}(\\mathbf{x}) \\leq f_{j}\\left(\\mathbf{x}^{*}\\right), \\quad \\forall j=\\{1, \\ldots, m\\} \\\\\nf_{j}(\\mathbf{x})=f_{j}\\left(\\mathbf{x}^{*}\\right) \\\\\n\\text { for at least one objective function }\n\\end{gathered}\n$$  \nMulti-objective optimization finds the best set of solutions in the decision space, and this set of solutions is called the pareto optimal solution. Pareto-optimal front approximates these pareto-optimal surfaces in the target space. where $\\left(f_{1}(\\mathbf{x}), \\ldots, f_{k}(\\mathbf{x})\\right)$ are $k$ objectives functions, $x \\in S,\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$ are the $n$ optimization parameters,\nand $S \\in R^{n}$ is the solution or parameter space. FORMULA_13 is said to be a pareto optimal solution of MOP [19], [20].\nALGORITHMS (MOEAS)\nEvolutionary algorithms (EAs) find a solution by evolving a group of candidate solutions during repeated operations of fitness evaluation, selection, crossover and mutation. The EA approach can discover and return diverse non-dominated solutions over wider regions in search space simultaneously. Many real-world multi-optimization problems are challenged by a variety of characteristics and difficulties; non-linearity, the number of constraints and variables, complex relations among variables, several conflicting objectives, and so on [21], [22].\nTo efficiently address MOPs, various Multi-Objective Evolutionary Algorithms (MOEAs) based on EA have been proposed. Among them, the dominance-based-MOEA type solved the problem of MOP by approximating the pareto optimal set by distinguishing and selecting promising candidate solutions [23]. Typical, Fast Non-dominated Sorting Genetic Algorithm (NSGA-II) [14] constructs an initial population through evaluation, and the solutions with the higher front order are selected in rank order until the original population size is reached. It performs non-dominate sorting and crowding distance comparison to select individuals and create new offspring through crossover and mutation. Pareto envelope-based selection algorithm II (PESAII) [24] and the improved strength Pareto EA (SPEA2) [25] also maintain non-dominant solutions and take a way to remove dominant solutions from the population.",
      "question_type": "theory",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:51:10",
      "generation_style": "conceptual_deep"
    },
    {
      "question": "For implementing an Estimation of Distribution Algorithm using the UMDA probability model, how should practitioners update the probability vector \\(P(g)\\) at each generation, and what considerations should be given to the parameter \\(\\lambda\\)?",
      "topics": [
        "genetic"
      ],
      "answer": "To update the probability vector \\(P(g)=\\left(p\\left(x_{1}\\right), \\ldots . . p\\left(x_{k}\\right) \\ldots, p\\left(x_{N}\\right)\\right)\\) in the UMDA probability model, practitioners should first select a subset \\(s(g-1)\\) of \\(m\\) individuals with the best fitness from the previous population \\(pop(g-1)\\). The size of this subset, \\(m\\), is determined by \\(m = \\lambda * M\\), where \\(M\\) is the population size and \\(\\lambda < 1\\).  The probability \\(p(x_i)\\) that the \\(i\\)-th gene is 1 is then updated based on FORMULA_12, which represents the value of the \\(i\\)-th gene of the \\(j\\)-th individual.  The parameter \\(\\lambda\\) controls the selection pressure; a smaller \\(\\lambda\\) means fewer individuals are used to build the probability model, potentially leading to faster convergence but also a higher risk of premature convergence due to overfitting the distribution of the solution space.",
      "chunk_id": 1189,
      "paper_id": "Estimation of Distribution Algorithm using Variety of Information",
      "paper_title": "Estimation of Distribution Algorithm using Variety of Information",
      "paper_year": "2014",
      "chunk_content": "Estimation of distribution algorithm, probability model, former information of probability model, inferior individuals\nEstimation of distribution algorithm (EDA), the combination of statistical learning and evolutionary algorithms, is proposed to solve the building block damage problem of genetic algorithm, and has been claimed as a paradigm shift in the field of evolutionary computation[1].EDA get estimate of the probability distribution of superior solutions set, then new solutions are generated by sampling the distribution encoded by this model.\nThe operation is repeated to realize the evolution of population. Sampling probability model avoids damage to the promising solutions[2], which is contrary to the operation of crossover and mutation in genetic algorithm, it is also the main characteristic different from genetic algorithm. So estimation of distribution algorithm has also been called probability model building genetic  \n[^0]\n\nalgorithms[1]. EDA controls the evolutionary direction of population from macro, solves high dimensional problem and difficult optimization problem effectively and reduces the time complexity[3]. It has been widely studied in recent years[4-9].\n\nEDA generates new inviduals through sampling from probability model, so probability model is the key factor, efficient probability model can produce high quality solutions and diversity solutions, how to build the probability model is the key to EDA. In most EDAs, only superior solutions of current population are used to build probability models and then sampling from the probability model to produce new individuals, the information of former probability model is discarded, thus it may lead to overfitting of the distribution of solution space when learning the probability model in the process of evolution, and also result in no longer generate diversity solutions after several generations and result in premature convergence. Therefore the information of former probability model is used to improve the estimation of distribution in this paper.\n\nThe Ref [10] proposed to use inferior solutions when generate new individuals.In this paper, the method will be modified and combined with utlilzation of former probability model to generate a new EDA.\n\nThe rest of this paper is organized as follows: Section 2 describes basic estimation of distribution algorithm. Section 3 describes the two operators , one is the use of information of fomer probability model,the other is the use of information of inferior solutions. Experimental results are presented in section 4. Finally, we conclude this paper in section 5.\n\n2. ESTIMATION OF DISTRIBUTION ALGORITHM\n\n2.1 Probability Model\n\nProbability vector $P(g)=\\left(p\\left(x_{1}\\right), \\ldots . . p\\left(x_{k}\\right) \\ldots, p\\left(x_{N}\\right)\\right)$ is probability model to describe the distribution of solution space, $p\\left(x_{k}\\right)$ is the probability of $x_{k}=1$. Offspring solutions are generated by sampling from probability model, i.e. randomly generate a number $\\mathrm{r}, \\mathrm{r} \\in[0,1]$,if $\\mathrm{r}<p\\left(x_{k}\\right)$, $x_{i}=1$; otherwise $x_{i}=0$.\n\nIn this paper, the UMDA [11] probability model is adopted, and the probability model is built by subset $\\mathrm{s}(\\mathrm{g}-1)$ which is composed of m individuals with best fitness in $\\operatorname{pop}(\\mathrm{g}-1)$, $\\mathrm{m}=\\lambda^{*} \\mathrm{M}$, where: $\\lambda<1, \\mathrm{M}$ is population size . $p\\left(x_{i}\\right)$ updated by Eq.(1), where FORMULA_12 is the value of the ith gene of the jth",
      "question_type": "implementation",
      "complexity": "advanced",
      "generated_at": "2025-06-27 00:51:12",
      "generation_style": "practical_application"
    },
    {
      "question": "How do univariate Estimation of Distribution Algorithms, such as UMDA and PBIL, model the joint probability distribution of selected individuals, and what assumption do they make about the variables?",
      "topics": [
        "genetic"
      ],
      "answer": "Univariate EDAs factorize the joint probability of the selected individuals as a product of univariate marginal probabilities. This approach is based on the assumption of independence among variables. UMDA estimates each univariate marginal distribution from the marginal frequencies of the selected individuals. PBIL, in contrast, uses the probability distribution of the previous generation, in addition to that of recently sampled individuals, to calculate a new probability distribution.",
      "chunk_id": 307,
      "paper_id": "Structure Learning of Bayesian Networks by Estimation of Distribution Algorithms with Transpose Mutation",
      "paper_title": "Structure Learning of Bayesian Networks by Estimation of Distribution Algorithms with Transpose Mutation",
      "paper_year": "2013",
      "chunk_content": "The basic workflow of EDAs is similar to that of conventional GAs. After randomly reproducing chromosomes for the first generation, it repeats a set of genetic operations, i.e., selection, estimation, and reproduction, until a stopping criterion is fulfilled. A new population of individual solutions is generated by sampling a probabilistic model, which is estimated on the basis of representative individuals selected from the previous population. The dependencies among variables in each individual are expressed by the joint probability distribution of the individuals selected at each generation.  \nBecause the solutions of EDAs are evolved through a probabilistic model, the main issue is the construction of an effective probabilistic model. Many studies have proposed a variety of probabilistic models; they can be categorized into three approaches according to the manner of capturing the dependencies among variables: univariate, bivariate, and multivariate approaches.  \nThe univariate model is based on the assumption of independence among variables; it factorizes the joint probability of the selected individuals as a product of univariate marginal probabilities. UMDA uses the simplest approach to estimating the joint probability distribution [13]; each univariate marginal distribution is estimated from the marginal frequencies of the selected individuals. In contrast, PBIL uses the probability distribution of the previous generation, in addition to that of recently sampled individuals, to calculate a new probability distribution [14]. The cGA is a tournament-based incremental algorithm; it updates the probability distribution using the winner of two competing individuals [15].  \nBivariate EDAs consider the dependencies among pairs of variables by using efficient data structures. MIMIC searches for the best permutation among variables by using a chain structure to capture the pairwise dependencies among the variables [16]. BMDA factorizes the joint probability distribution for second-order statistics by using an acyclic dependency graph [17]. DTEDA uses a tree structure to represent dependency relationships [18].  \nMultivariate EDAs factorize the joint probability distribution by using statistics of order greater than two. The probabilistic model complexity and the computational cost of determining the model are greater than those in the cases of univariate and bivariate EDAs. Thus, such approaches require a more complex learning process. EcGA divides the variables into a number of groups, and then factorizes the joint probability distribution as a product of marginal distributions of variable size [19]. EBNA uses the Bayesian information criterion (BIC) score to learn the joint probability model of the selected individuals [20]. BOA uses the Bayesian Dirichlet equivalent (BDe) measure to compute the quality of each candidate dependency [21].  \nBayesian networks are graphical structures for representing the probabilistic relationships among  \nvariables [22]. The structure learning of Bayesian networks is an NP-Hard optimization problem because the number of structures grows exponentially with the number of variables [23]. It has been shown that the heuristic approach of EDAs is effective and efficient because of the extremely high cardinality of the search spaces. With regard to the application of EDAs for learning Bayesian networks, Blanco et al. used the UMDA and PBIL to infer the structure of Bayesian networks [7]. MIMIC was used to obtain the optimal ordering of variables for Bayesian networks [24]. The Bayesian networks learned using UMDA, PBIL, and MIMIC were more accurate than those learned using GAs, as compared to the original networks.",
      "question_type": "theoretical foundation",
      "complexity": "basic",
      "generated_at": "2025-06-27 00:51:14",
      "generation_style": "theoretical_foundation"
    },
    {
      "question": "What computational trade-offs are described between the LSSVM and the HKLSSVM approaches for modeling the end-point quality of molten steel?",
      "topics": [
        "performance"
      ],
      "answer": "The Least Squares Support Vector Machine (LSSVM) has a faster computation speed compared to standard Support Vector Machines (SVM) because LSSVMs solve analytical formulas using linear equations, whereas SVMs use quadratic optimization. The Hybrid Kernel LSSVM (HKLSSVM) aims to improve the generalization ability of the LSSVM by combining a Gaussian kernel function, defined as K1(xi, xj) = exp(-||xi - xj||^2 / (2 * sigma^2)), with a polynomial kernel function, defined as K2(xi, xj) = (xi^T * xj + 1)^d_Ploy, into a hybrid kernel function: K(x, xi) = (1 - kappa) * K1(x, xi) + kappa * K2(x, xi). This introduces the trade-off of increased complexity in kernel computation for potentially better generalization performance.",
      "chunk_id": 3088,
      "paper_id": "An Estimation of Distribution Algorithm With Resampling and Local Improvement for an Operation Optimization Problem in Steelmaking Process",
      "paper_title": "An Estimation of Distribution Algorithm With Resampling and Local Improvement for an Operation Optimization Problem in Steelmaking Process",
      "paper_year": "2024",
      "chunk_content": "The input end-point control parameters include the rate of blowing oxygen, the amounts of auxiliary raw materials, and the rate of blowing inert gas at the bottom. The main output performance indicators are the temperature, the carbon content, and the contents of other elements. However, because of the complex physical and chemical reactions that occur in the furnace at high temperature, it is difficult to build exact mechanism models expressing the relationship between the inputs and outputs. Furnace state data can be sampled using multisource sensors, with the temperature being observed using a flame analyzer, some composition contents in the molten steel being detected using throwing probe and sublance sampling, and gas quantity being detected using a gas analyzer. In practice, operators usually control the levels of input parameters to attain the desired outputs, based on experience and knowledge collected from historical data.  \nIn this article, a data-driven model is built to accurately control the end-point quality of the molten steel in BOF steelmaking. The modeling method is based mainly on LSSVMs, proposed by Suykens and Vandewalle [44]. LSSVMs have faster computation speed compared with SVMs. Because the analytical formulas can be solved using linear equations in LSSVMs, rather than by means of quadratic optimization in SVMs. To improve the generalization ability of LSSVMs, this article proposes an LSSVM method with a hybrid kernel function (HKLSSVM). The principle is introduced below.  \nGiven a sample set of $N$ data points $\\left\\{\\boldsymbol{x}_{i}, y_{i}\\right\\}, i=1,2, \\ldots, N$, where $\\boldsymbol{x}_{i} \\in \\mathfrak{R}^{d}$ is the $i$ th input data, $d$ is the number of features, and $y_{i} \\in \\Re$ is the corresponding $i$ th output data, the inputoutput relationship is expressed by the following equation:  \n$$\nf\\left(\\boldsymbol{x}_{i}\\right)=\\boldsymbol{w}^{T} \\cdot \\varphi\\left(\\boldsymbol{x}_{i}\\right)+b, \\quad i=1,2, \\ldots, N\n$$  \nwhere $\\varphi\\left(\\boldsymbol{x}_{i}\\right)$ is a feature map, with which $\\boldsymbol{x}_{i}$ can be mapped into a high-dimensional feature space. $\\boldsymbol{w}^{T}$ and $b$ are the regression coefficients and the bias, respectively.  \nAccording to the principle of structural risk minimization, the LSSVM problem can be written as  \n$$\n\\begin{gathered}\n\\min _{\\boldsymbol{w}, b, \\boldsymbol{e}} J(\\boldsymbol{w}, \\boldsymbol{e})=\\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+\\frac{\\gamma}{2} \\sum_{i=1}^{N} e_{i}^{2} \\\\\n\\text { s.t. } y_{i}=\\boldsymbol{w}^{T} \\cdot \\varphi\\left(\\boldsymbol{x}_{i}\\right)+b+e_{i} \\\\\n\\gamma \\geq 0\n\\end{gathered}\n$$  \nwhere $\\gamma$ is a penalty coefficient, which is set to a value in the range of $[100,1000]$, and $e_{i}$ is a slack variable. Using the Lagrangian multiplier $\\alpha_{i}$, the above LSSVM problem can be expressed as  \n$$\n\\operatorname{Lag}\\left(\\boldsymbol{w}, b, \\boldsymbol{e}, \\alpha_{i}\\right)=J(\\boldsymbol{w}, \\boldsymbol{e})-\\sum_{i=1}^{N} \\alpha_{i}\\left[\\boldsymbol{w}^{T} \\varphi\\left(\\boldsymbol{x}_{i}\\right)+b+e_{i}-y_{i}\\right]\n$$  \nBy the Karush-Kuhn-Tucker condition, the following linear equations can be obtained:  \n$$\n\\left[\\begin{array}{cc}\n0 & \\mathbf{1}^{T} \\\\\n\\mathbf{1} & \\Omega+\\gamma^{-1}\n\\end{array}\\right]\\left[\\begin{array}{l}\nb \\\\\n\\boldsymbol{\\alpha}\n\\end{array}\\right]=\\left[\\begin{array}{l}\n0 \\\\\n\\boldsymbol{y}\n\\end{array}\\right]\n$$  \nwhere $\\mathbf{1}=(1, \\ldots, 1)^{T}, \\boldsymbol{\\alpha}=\\left(\\alpha_{1}, \\ldots, \\alpha_{N}\\right)^{T}, \\boldsymbol{y}=$ $\\left(y_{1}, \\ldots, y_{N}\\right)^{T}$, and $\\Omega=\\left\\{\\Omega_{i j} \\mid i, j=1, \\ldots, N\\right\\}=\\varphi\\left(\\boldsymbol{x}_{i}\\right)^{T} \\varphi\\left(\\boldsymbol{x}_{j}\\right)$ is a symmetric matrix of the kernel function. $K\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)$ is a Mercer kernel function that is defined as follows:  \n$$\nK\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)=\\varphi\\left(\\boldsymbol{x}_{i}\\right)^{T} \\cdot \\varphi\\left(\\boldsymbol{x}_{j}\\right), i, j=1,2, \\ldots, N\n$$  \nThe LSSVM model can then be presented as  \n$$\nf(\\boldsymbol{x})=\\sum_{i=1}^{N} \\alpha_{i} K\\left(\\boldsymbol{x}, \\boldsymbol{x}_{i}\\right)+b\n$$  \nTo describe global and local performances by means of different kernel functions, a Gaussian kernel is combined with a polynomial kernel in this article to form a hybrid kernel function.  \nThe Gaussian kernel function is defined as  \n$$\nK_{1}\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)=\\exp \\left(-\\frac{\\left\\|\\boldsymbol{x}_{i}-\\boldsymbol{x}_{j}\\right\\|^{2}}{2 \\sigma^{2}}\\right), i, j=1,2, \\ldots, N\n$$  \nwhere $\\sigma$ is the width parameter of the kernel function, and the range of the parameter is set to $[1,100]$.  \nThe polynomial kernel function is defined as  \n$$\nK_{2}\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)=\\left(\\boldsymbol{x}_{i}^{T} \\boldsymbol{x}_{j}+1\\right)^{d_{\\text {Ploy }}}, i, j=1,2, \\ldots, N\n$$  \nwhere $d_{\\text {Ploy }}$ is the order of the polynomial kernel function and is an integer in the range of $[1,10]$. The hybrid kernel function can be expressed as  \n$$\nK\\left(\\boldsymbol{x}, \\boldsymbol{x}_{i}\\right)=(1-\\kappa) K_{1}\\left(\\boldsymbol{x}, \\boldsymbol{x}_{i}\\right)+\\kappa K_{2}\\left(\\boldsymbol{x}, \\boldsymbol{x}_{i}\\right), i=1,2, \\ldots, N\n$$",
      "question_type": "comparative analysis",
      "complexity": "medium",
      "generated_at": "2025-06-27 00:51:16",
      "generation_style": "comparative_analysis"
    }
  ]
}