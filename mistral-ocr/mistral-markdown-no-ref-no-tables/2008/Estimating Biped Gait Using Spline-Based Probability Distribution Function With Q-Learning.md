# Estimating Biped Gait Using Spline-Based Probability Distribution Function With Q-Learning 

Lingyun Hu, Changjiu Zhou, and Zengqi Sun, Senior Member, IEEE


#### Abstract

This paper studies the probability distribution functions of the parameters to be learned and optimized in biped gait generation. By formulating the gait pattern generation into a multiobjective optimization problem with consideration of geometric and state constraints, dynamically stable and low energy cost biped gaits are generated and optimized by the proposed method, namely Spline-based Estimation of Distribution Algorithm (EDA) with Q-learning updating rule (EDA_S_Q). Instead of assuming variables as independent ones, the relationship between them is exploited by formulating the corresponding probability models with the Catmull-Rom cubic spline function. Such kind of function is proved to be a suboptimal and adaptive realization of the cubic spline function and is capable of providing highprecision description. Moreover, the probability models are updated autonomously by Q-learning method, which is model-free and adaptive. Thus, EDA_S_Q can deal with complex probability distribution functions without a prior knowledge about the distribution. The biped gait generated by EDA_S_Q has been verified using the simulation model of a humanoid soccer robot RoboErectus. It also shows that EDA_S_Q can generate the desired biped gaits autonomously in short learning epochs. An interpretation of the transition probability distribution achieved by EDA_S_Q provides us easy understanding for biped locomotion and better control in humanoid robots.


Index Terms-Biped robot, Estimation of Distribution Algorithm (EDA), gait pattern generation, probability model, Q-learning, spline function.

## I. INTRODUCTION

$\mathbf{P}$ESEMBLING human walking is essential for biped robot control. It requires the cooperation between all actuated joints in searching for the ideal set of gait characteristics like stability [1], energy efficiency [2], and simplicity. Though several techniques have been proposed to compute the expected biped gaits [3], the problem of generating dynamically stable walking trajectories remains a difficult challenge especially when considering some constraints, e.g., energy cost.

To develop a more efficient biped gait generation and optimization method for the humanoid robot "Robo-Erectus" (RE),

Manuscript received January 31, 2006; revised August 23, 2007. This work was supported in part by the Singapore Tote Fund, by the Singapore Polytechnic R\&D Fund, and by the National Key Project for Basic Research of China under Grant 2002CB312205. This research was conducted when L. Hu was a Research Associate in Advanced Robotics and Intelligent Control Center (ARICC) at Singapore Polytechnic.
L. Hu and C. Zhou are with the School of Electrical and Electronic Engineering, Singapore Polytechnic, Singapore 139651 (e-mail:ZhooCH@sp.edu.sg).
Z. Sun is with the Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China (e-mail: seq-dcs@tsinghua. edu.cn).

Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.

Digital Object Identifier 10.1109/TIE.2007.908526
one of the foremost leading soccer-playing humanoid robots in the RoboCup Humanoid League developed by Advanced Robotics and Intelligent Control Center at Singapore Polytechnic (www.robo-erectus.org) [4], we proposed the Estimation of Distribution Algorithms (EDAs) [5] based gait optimization approaches in our previous works [6]-[8]. They can generate walking patterns by minimizing the specified objective function under several constraints with the assumption that parameters are independent in EDA, which uses probability distributions derived from the optimization function to generate search points instead of crossover and mutation as done by Genetic Algorithms (GAs). However, those parameters are interrelated and the relationship between them gives an allaround understanding of the joint effect on biped gait stability and energy transformation. To explore and exploit it, the Splinebased EDA with Q-learning-based updating rule (EDA_S_Q) is developed in this paper to study the probability distribution of the parameters to be optimized. Moreover, instead of using the Gaussian distribution as the probability model in traditional EDAs, Catmull-Rom cubic spline [9], [10] is used to achieve suboptimal and self-adaptive probability distribution functions, which are updated automatically by the Q-learning-based [11] method without a predesigned updating rule. As part of the project, the learned trajectories have been tested successfully on the biped robot RE.

The rest of this paper is organized as follows. Section II presents a brief survey of related work with an emphasis on why we choose EDA to solve the biped gait optimization problem. Then, the biped gait optimization framework including the objective function and various constraints is described in Section III. Next, the modified EDA using spline probability distribution function and Q-learning-based updating method, namely EDA_S_Q, for solving the optimization problem is proposed in Section IV. Experimental results achieved by EDA_S_Q are given in Section V, and Section VI is the discussion on the probability model and updating rule in terms of probability learning and optimization for biped gait generation. Finally, some concluding remarks and future work are given in Section VII.

## II. RELATED WORK

For the lumped-mass model of biped mechanisms, a commonly used method to generate a dynamically stable trajectory is prescribing a time evolution of the Zero Moment Point (ZMP) [12] trajectory such that it lies within the supporting polygon constructed by the biped feet [1], [13]. Besides conceptual simplicity, the advantages of this kind of method include that

the closed form solution can be easily derived for on-line implementation. By introducing some computational intelligent algorithms, like neural networks [14], fuzzy systems [15], and GAs [16], the point mass model has been applied widely in biped gait generation and optimization.

However, the number of degrees of freedom (DOFs) in modern humanoid robots is large. It increases the difficulty of finding and representing an optimal biped trajectory for the point mass model. Moreover, parameters to be optimized become sensitive to each other. For such cases, a probability model seems to be one of the preferable solutions because it can describe the distribution with few variables. While reviewing the existing literature, there exist many papers on biped gait synthesis [13], [17]. However, there are very few papers that report the use of a probability model to accelerate the search in high dimensional coupling space for biped gait generation and optimization. In our first attempt to use probability modeling and evolutionary computation, we developed an EDA-based framework for biped gait generation and optimization [6]. Three key poses are selected in one gait cycle to produce the complete gait trajectory by third-order spline functions. Joint coordinates at the transition phases are the parameters to be optimized. Based on the framework, EDAs with different probability distribution functions and updating rules have been tested and compared for different requirements [7], [8], [18], [19].
Among them, the EDA with Catmull-Rom cubic splinebased probability function shows quicker convergence speed compared to traditional EDAs. Such a kind of probability distribution function can approximate an arbitrary continuous function with arbitrarily high quality [20], and it can provide precise description for complex multimodal probability distribution functions. Such cases as shown in the simulation results are most likely to appear in the 2-D probability distribution functions used to describe the relationship between parameters. Traditional probability functions like the Gaussian function are not suitable to describe this relationship. Therefore, the Catmull-Rom cubic spline function is applied in EDA_S_Q as the probability distribution function, which has been proved in this paper to be a suboptimal and adaptive realization of the cubic spline function with the kernels $\left|x^{3}\right|$ (see Appendix I). We also provide guidelines on how to improve the approximation precision in Appendix II.
For the specially-designed probability model, the selection of a suitable updating method needs experience and may convert to new optimization problems. To build and update the probability model from learning instead of exclusively being determined in advance, the idea of reinforcement learning (RL) [4] is incorporated with EDA in this paper. RL can learn the unknown desired distribution by providing an agent with suitable evaluation of its performance. By formulating the relationship between parameters with conditional probability distribution functions, probability models can be updated autonomously by the RL agents, which provide us a new viewpoint to explore the inherent dynamics in biped locomotion.
In conclusion, EDA_S_Q is able to find out the preferable solutions in high dimensional coupling space quickly and approximate the probability model autonomously with the help
of the spline-based probability function and Q-learning-based updating rule. As indicated by the comparison experiment with traditional EDAs in Section VI, the faster convergence of EDA_S_Q brought by the spline-based probability function may be helpful for online application. Also, the conditional probability functions updated by Q-learning-based rule can give some tips in biped locomotion and robot control.

## III. Problem DEfinition

The definition of the biped gait generation and optimization problem consists of three elements. 1) Parameters to be optimized. As mentioned in Section II, biped trajectories are parameterized by a third-order spline function of the joint angles at transition poses, which are the correct parameters to be optimized. 2) Desired features of the expected gaits. The commonly used criteria include dynamical stability [12], energy efficiency [2], and so on. In this paper, ZMP displacement and required joint torques are applied to form the objective function pro rata. 3) Description of physical feasibility for biped walking. Geometric constraints for joint motion range and actuator torques are first considered to satisfy the practical requirement. Additionally, state constraints to guarantee the stability and state feasibility like maximum joint rotational velocities are also considered in final problem definition. They are expressed by a set of inequality and equality constraints.

Consequently, among the set of all trajectories satisfying the above constraints, the one with the least sum of ZMP displacement and actuator torques is desired to be found using the proposed method.

For the biped gaits optimization and learning problem, we consider the following objective function constructed using the energy cost and stability criteria

$$
\begin{aligned}
\text { Minimize } \Upsilon(\cdot) & =\beta_{f} f(\cdot)+\beta_{g} g(\cdot) \\
& =\sum_{i=1}^{N_{c}}\left(\beta_{f} \mathbf{N}\left(f_{i}(\cdot)\right)+\beta_{g} \mathbf{N}\left(g_{i}(\cdot)\right)\right)
\end{aligned}
$$

Subject to GC1 $A_{p} \leq p(\phi) \leq B_{p}$

$$
\begin{aligned}
& \text { GC2 } A_{q} \leq q \leq B_{q} \\
& \text { FC1 } \sum_{i=1}^{N_{t}}\left(m_{i} \ddot{p}_{i}\right)=f_{\mathrm{R}}+f_{\mathrm{L}}+\sum_{i=1}^{N_{t}}\left(m_{i} g\right) \\
& \text { FC2 } f_{\mathrm{d}}=\min \left(\mathrm{FI}\left(f_{\mathrm{R}}, f_{\mathrm{L}}\right)\right) \\
& \text { VC } A_{\dot{q}} \leq \dot{q} \leq B_{\dot{q}} \\
& \text { ZC } A_{\text {emp }} \leq p_{\text {emp }} \leq B_{\text {emp }}
\end{aligned}
$$

where $\Upsilon(\cdot)$ represents the optimization goal to achieve the dynamically stable and energy-efficient biped gaits. $f_{i}=\|p_{\text {emp }}^{i}-$ $p_{\text {emp }}^{d} \|_{2}$ calculates the Euclidean distance between the actual ZMP $p_{\text {emp }}^{i}$ and the desired ZMP $p_{\text {emp }}^{d}$ at the $i$ th sample index. $\|\cdot\|_{2}$ is the second-order norm. $g_{i}=\sum_{j=1}^{N_{q}} \tau_{i j}$ summarizes the

torque of all actuated joints at the $i$ th sample index. $\mathbf{N}$ is the normalization operator to make the two targets comparable. $N_{y}$ is the number of sampling points in one gait cycle. $\beta_{f}$ and $\beta_{g}$ are weights satisfying $\beta_{f}+\beta_{g}=1$ to notify the desired character of generated gaits.

The ZMP is defined as the point on the ground at which the net moment of the inertial forces and the gravity forces have no component along the horizontal axes [12]. For kinematic chain structure, the ZMP coordinate in $x$ - and $y$-direction can be calculated by the following:

$$
\begin{aligned}
& x_{\mathrm{zmp}}=\frac{\sum_{i=1}^{N_{\mathrm{q}}}\left(m_{i}\left(\ddot{z}_{i}+g\right) x_{i}-m_{i} \ddot{x}_{i} z_{i}-\left(I_{i} \ddot{\theta}_{i}\right)_{y}\right)}{\sum_{i=1}^{N_{\mathrm{q}}}\left(m_{i}\left(\ddot{z}_{i}+g\right)\right)} \\
& y_{\mathrm{zmp}}=\frac{\sum_{i=1}^{N_{\mathrm{q}}}\left(m_{i}\left(\ddot{z}_{i}+g\right) y_{i}-m_{i} \ddot{y}_{i} z_{i}+\left(I_{i} \ddot{\theta}_{i}\right)_{x}\right)}{\sum_{i=1}^{N_{\mathrm{q}}}\left(m_{i}\left(\ddot{z}_{i}+g\right)\right)}
\end{aligned}
$$

where $m_{i}$ is the mass of link $i$ and $g$ is the gravity acceleration. The coordinate of link $i$ is described by $\left(x_{i}, y_{i}, z_{i}\right)$. Correspondingly, accelerations of link $i$ in $x$-, $y$ - and $z$-direction are represented by $\ddot{x}_{i}, \ddot{y}_{i}$, and $\ddot{z}_{i}$, respectively. $\left(I_{i}\right)_{x}$ and $\left(I_{i}\right)_{y}$ are the inertial components. $\left(\ddot{\theta}_{i}\right)_{x}$ and $\left(\ddot{\theta}_{i}\right)_{y}$ are the absolute angular acceleration component around $x$ - and $y$-axis at the center of gravity of link $i$.

GC1 and GC2 are geometric constraints to guarantee the feasibility of generated gaits. $p=\left[p_{t, i}\right]^{\mathrm{T}}, A_{p}=\left[A_{p_{t, i}}\right]^{\mathrm{T}}, B_{p}=$ $\left[B_{p_{t, i}}\right]^{\mathrm{T}}, p_{t, i}=\left[x_{t, i}, y_{t, i}, z_{t, i}\right]$ denotes center position of link $i$ at time $t, i=1,2, \ldots, N_{\mathrm{l}} . A_{p_{t, i}}$ and $B_{p_{t, i}}$ are lower and upper boundaries of $p_{t, i} . q=\left[q_{t, i}\right]^{\mathrm{T}}$ stands for the $i$ th joint angle at time $t, i=1,2, \ldots, N_{\mathrm{q}}, A_{\mathrm{q}}=\left[A_{\mathrm{q}, i}\right]^{\mathrm{T}}, B_{\mathrm{q}}=\left[B_{\mathrm{q}, i}\right]^{\mathrm{T}}, A_{\mathrm{q}, i}$, and $B_{\mathrm{q}, i}$ are lower and upper boundaries of $q_{t, i} . N_{\mathrm{l}}$ and $N_{\mathrm{q}}$ are the number of links and actuated torques in biped robot.

Besides geometric constraints, state constraints including force, velocity, and ZMP constraints are also considered in this paper.

FC1 and FC2 are force constraints. $f_{\mathrm{R}}$ and $f_{\mathrm{L}}$ are the ground reaction force at the right and left foot, respectively. $\hat{p}_{i}$ is the acceleration of link $i$. Since only the sum $f_{\mathrm{R}}+f_{\mathrm{L}}$ is known during the double support phase, the force constraint FC2 is assumed as the internal force $f_{\mathrm{d}}$, which must be minimized in the closed loop structure. FI is the function to calculate the internal force.

VC is velocity constraint. $A_{\dot{q}}=\left[A_{\dot{q}_{t, i}}\right]^{\mathrm{T}}$ and $B_{\dot{q}}=\left[B_{\dot{q}_{t, i}}\right]^{\mathrm{T}}$ are lower and upper boundaries of $\dot{q}_{t, i}$.

ZC stands for ZMP constraint. According to the dynamic stability criterion defined by ZMP [12], the position of ZMPs should be within the stable region, which changes from the area of the standing feet to the convex polygon formulated by the two feet when gaits change from single support to double support phase. Where $p_{\mathrm{zmp}}=\left[p_{\mathrm{zmp}, i}\right]^{\mathrm{T}}$, $p_{\mathrm{zmp}, i}=\left(x_{\mathrm{zmp}, i}, y_{\mathrm{zmp}, i}, 0\right)$ is position of the $i$ th ZMP. $A_{\mathrm{zmp}}=$ $\left[A_{\mathrm{zmp}, i}\right]^{\mathrm{T}}$ and $B_{\mathrm{zmp}}=\left[B_{\mathrm{zmp}, i}\right]^{\mathrm{T}}$ are lower and upper boundaries of the stable region, respectively.

For details of the dynamical and gait pattern models used to calculate the parameters in gait generation, please refer to [7], [8], and [21].
![img-0.jpeg](img-0.jpeg)

Fig. 1. Structure of spline function for $\operatorname{Pro}_{i, j}$.

## IV. EDA_S_Q FOR BIPED GAIT OPTIMIZATION

For the simplified nonlinear parameter optimization problem with inequality constraints, if all DOFs would be optimized, trajectories with a smaller objective function value could be obtained. Different from previous heuristic methods, the proposed algorithm adopts a new evolutionary algorithm called EDAs to search for the joint angle permutation. For unknown probability distribution functions, EDAs build the probability model by using the selected set of solutions and making use of this estimation to generate new solutions. As the input coordinates $q_{i}\left(i=1,2, \ldots, N_{\mathrm{l}}\right)$ of the $N_{\mathrm{l}}$ links in joint space are considered to be interrelated, the interrelationship between parameters needs to be formulated autonomously and accurately. This is realized by setting a spline-based probability function and Q-learning-based updating rule in EDA_S_Q.

## A. Spline Function Based Probability Model

Different from traditional probability models, the proposed algorithm employs piecewise polynomial spline interpolation schemes, which are a continuous first derivative and have local adaptation, to describe the probability model. The structure of probability distribution function $\operatorname{Pro}_{i, j}$ is illustrated in Fig. 1.

Supposing $q_{i, j}$ is the angular position of joint $j$ at the $i$ th key pose in one gait cycle, $i=1,2, \ldots, N_{\mathrm{kp}}, j=1,2, \ldots, N_{\mathrm{q}}$, then the output of this probability distribution function $\operatorname{Pro}_{i, j}$ can be calculated by

$$
\begin{aligned}
v_{i, j} & =\left\lfloor\frac{q_{i, j}}{\Delta w}+\frac{N_{w}}{2}\right\rfloor \\
u_{i, j} & =\frac{q_{i, j}}{\Delta w}+\frac{N_{w}}{2}-v_{i, j} \\
\operatorname{Pro}_{i, j} & =F_{i, j, y_{o}}(\cdot)=\sum_{m=0}^{3} w_{i, j, x_{o_{i, j}+m}} C_{m}\left(u_{i, j}\right)
\end{aligned}
$$

Equations (4) and (5) implement the computation for local parameters. $\rfloor$ is the floor operator and it is designed to guarantee that $u_{i, j}$ is always nonnegative. $\Delta w=w_{x_{o+1}}-w_{x_{o}}$. It is proved that function smoothness can be tuned by $\Delta w$, which is insensitive to generalization error in a suitable range [22]. Hence, it is not necessary to learn the optimal $\Delta w$ using

a complex procedure. The proposed method sets it by manual tuning. $N_{w}$ is the number of points and

$$
\left(\begin{array}{c}
C_{0}(u) \\
C_{1}(u) \\
C_{2}(u) \\
C_{3}(u)
\end{array}\right)^{\mathrm{T}}=\frac{1}{2}\left(\begin{array}{c}
u^{3} \\
u^{2} \\
u \\
1
\end{array}\right)^{\mathrm{T}} \times\left(\begin{array}{cccc}
-1 & 3 & -3 & 1 \\
2 & -5 & 4 & -1 \\
-1 & 0 & 1 & 0 \\
0 & 2 & 0 & 0
\end{array}\right)
$$

As shown in Appendix II, an accurate prediction of the Catmull-Rom spline approximation error can be described by function $w_{\text {int }} \Delta x^{L}\left|\tilde{F}^{L}(v)\right|_{L_{2}}$ with the sampling step $\Delta w$ and approximation order $L$.

Remark 1: The higher the approximation order $L$, the better the approximation quality. However, the high order will inevitably add to the computational load. The third order is a practical choice.

Remark 2: For basis functions of identical approximation order, the smaller the approximation constant $w_{\text {int }}$, the better the approximation quality.

Since the Catmull-Rom spline is a suboptimal of the cubic spline function as demonstrated by Appendix I, it can also be understood as a subclass of Moms functions, which stands apart as the best achievable compromise between approximation quality and speed [20]. By setting such kinds of probability distribution functions, the proposed method can characterize more complex distribution functions because every continuous function on a closed interval can be approximated uniformly to any prescribed accuracy by a spline function [23].

## B. Q-Learning

Besides the probability distribution function, the updating rule is also important to the learning quality of EDAs. For distribution functions in traditional EDAs, updating rules should be specially designed with consideration of probability function type, learning rate and so on. To update it autonomously, the idea of RL is employed in this paper.

In RL, the optimal action selection method or policy is obtained by maximizing the numerical reward signal. Q-learning is a commonly used off-policy temporal difference control algorithm that approximates the optimal action-value function independent of the policy being followed. The $Q$-value, which is updated after every state transition, is calculated by

$$
Q(s, a)=Q(s, a)+\alpha\left(r+\gamma \max Q\left(s^{\prime}, a^{\prime}\right)-Q(s, a)\right)
$$

where $s^{\prime}$ is the following state of $s$ after action $a$ and $a^{\prime}$ is the corresponding action set for state $s . r$ is the scalar feedback provided by the critic. Let $Q^{*}$ be the global optima, it is proved that if each action is executed in each state an infinite number of times on an infinite run and $\alpha$ is decayed appropriately, the $Q$-value will converge with probability one to $Q^{*}$ [24].

The idea of updating the probability function with Q-learning is efficiently used here to enhance the intelligence of the proposed method. A multivariate distribution model $\operatorname{Pro}_{i+1 \mid i, j}$ is given to represent the conditional probability of the $j$ th variable in the $i+1$ th moment with the given value in the $i$ th moment. An example of the conditional probability function $\operatorname{Pro}_{2 \mid 1, j}$ for the relationship between the first and the second key
![img-1.jpeg](img-1.jpeg)

Fig. 2. Spline-based probability distribution function $\operatorname{Pro}_{2 \mid 1, j}$.
poses is exhibited in Fig. 2. Points in conditional probability distributions are 2-D interpolated by sample points, which are updated by Q-learning method as

$$
\begin{aligned}
\operatorname{Pro}_{i+1 \mid i, j}= & \operatorname{Pro}_{i+1 \mid i, j} \\
& +\alpha\left(r\left(q_{i, j}\right)+\gamma \max \operatorname{Pro}_{i+1, j}-\operatorname{Pro}_{i+1 \mid i, j}\right)
\end{aligned}
$$

where $i=1,2, \ldots, N_{\mathrm{kp}}-1, j=1,2, \ldots, N_{\mathrm{q}}$. Reward $r$ is specially designed with the same structure as that in the objective function. It is calculated by the selected $N_{\mathrm{b}}$ best samples as

$$
r\left(q_{i, j}\right)=\beta_{f} r_{\text {local }}\left(q_{i, j}\right)+\beta_{\mathrm{g}} r_{\text {global }}\left(q_{i, j}\right)
$$

where local reward $r_{\text {local }}\left(q_{i, j}\right)=\mathbf{N}\left(\tau_{i, j}^{-1}\right)$ focuses on energy cost at each actuated joint and it affects mainly on the corresponding joint; while the global reward $r_{\text {global }}\left(q_{i, j}\right)=\mathbf{N}\left(f_{j}^{-1}\right)$ is the ZMP displacement at current sample moment. All joints have an effect on this factor. These two parts give an all-around estimation on reward and can provide proper feedback to Q-learning.

Remark 3: It can be seen that conditional probability is updated with consideration of the reward defined by current state parameters and the probability at the next pose. The rewards determine the immediate, intrinsic desirability of states. The probability at the next state indicates the long-term desirability of states after taking into account the states that are likely to follow, and the rewards available in those states. Such a kind of updating rule can be applied for various kinds of probability functions without foreknown knowledge.

## C. Proposed Method EDA_S_Q

As mentioned in Section II, a total of $N_{\mathrm{kp}}=3$ key poses are determined in one complete gait cycle. The probability distribution functions of the joint angles at the first key pose are modeled by spline-based probability distribution functions. They are updated by

$$
\operatorname{Pro}_{1, j}=(1-\alpha) \operatorname{Pro}_{1, j}+\alpha r\left(q_{1, j}\right)
$$

The relationship between the joint angles at sequential poses is also formulated by the same kind of probability distribution

function and updated with the Q-learning method as shown in (8). The information at current state and future state estimation is all taken into account in terms of $Q$-value. Thus, it is possible for a conditional probability distribution function to adjust the distribution autonomously in learning.

Hence, for input $q_{1, j}$, the probability distribution for $q_{2, j}$ and $q_{3, j}$ can be achieved by

$$
\begin{aligned}
& \operatorname{Pro}_{2, j}=\operatorname{Pro}_{2 \mid 1, j} \operatorname{Pro}_{1, j} \\
& \operatorname{Pro}_{3, j}=\operatorname{Pro}_{3 \mid 2, j} \operatorname{Pro}_{2, j}
\end{aligned}
$$

In conclusion, EDA_S_Q describes evolution as

$$
q(t+1)=B^{N_{\mathrm{e}}} \Upsilon R^{N_{\mathrm{b}}} \mathrm{Sq}(t)
$$

where $\mathrm{Sq}(t)$ defines the spline-based probability distribution function of the offspring. From this distribution, a population of $N_{\mathrm{e}}$ offspring is sampled via random selection $R^{N_{\mathrm{b}}}$ and evaluated by the fitness operator $\Upsilon$. Proportional to the fitness, a population of $N_{\mathrm{b}}$ parents is selected by the selection method $B^{N_{\mathrm{e}}}$.

The final structure of the proposed method EDA_S_Q can be outlined as follows:

1) Initialization Set $k=1$. Randomly initialize $\operatorname{Pro}_{i+1 \mid i, j}(k)$ and $\operatorname{Pro}_{i, j}(k), \quad i=1,2, \ldots, N_{\mathrm{kp}}-1$, $j=1,2, \ldots, N_{\mathrm{q}}, l=1,2, \ldots, N_{\mathrm{kp}}$.
2) Sampling Generate $N_{\mathrm{e}}$ samples $q^{s_{m}}$ from $\operatorname{Pro}_{i, j}(k)$ to form the current population $O(k)$ by (6), $m=1,2, \ldots$, $N_{\mathrm{e}}, i=1,2, \ldots, N_{\mathrm{kp}}$.
3) Selection Select the $N_{\mathrm{b}}$ best points $q^{b_{\mathrm{s}}}$ from $q^{s_{\mathrm{m}}}$ according to $\Upsilon$ calculated by (1), $N_{\mathrm{b}}=\alpha_{\mathrm{s}} N_{\mathrm{s}}\left(0<\alpha_{\mathrm{s}}<1\right)$, $n=1,2, \ldots, N_{\mathrm{b}}$.
4) Updating Calculate the reward $r\left(q_{i, j}\right)$ according to (9). Update $\operatorname{Pro}_{1, j}(k+1)$ and $\operatorname{Pro}_{i+1 \mid i, j}(k+1)$ by (8) and (10), respectively. New probabilities of $\operatorname{Pro}_{2, j}(k+1)$ and $\operatorname{Pro}_{3, j}(k+1)$ are obtained by (11) and (12).
5) If stop condition is not met, go back to step 2) and let $k=k+1$.

## V. EXPERIMENTAL RESULTS

To show the effectiveness of EDA_S_Q for biped gait generation and optimization, it is applied to the simulation model of the humanoid robot called RE. The height and weight of RE are 600 mm and 4.6 kg , respectively. A total of 23 DOFs are designed in RE with six per leg, four per arm, one for head, and two for waist. They are driven by a servomotor with maximum torque of $30 \mathrm{~kg} \cdot \mathrm{~cm}$. A laptop computer with a Windows XP operation system is set on RE for online control. The simplified model takes the basic structure parameters as the number of links $N_{\mathrm{l}}=9$, number of key poses $N_{\mathrm{kp}}=3$. A total of $N_{\mathrm{s}}=20$ poses are sampled in one gait cycle, and the first, the sixteenth and the eighteenth of them are key poses. The width of hip $l_{h}=15 \mathrm{~cm}$, other links take the value of foot length $l_{1}=$ 10 cm , fore foot length $l_{a}=5 \mathrm{~cm}$, heel length $l_{b}=5 \mathrm{~cm}$, ankle length $l_{2}=4 \mathrm{~cm}$, crus and thigh length $l_{3}=l_{4}=8 \mathrm{~cm}$, trunk length $l_{5}=20 \mathrm{~cm}$, step length $D_{\mathrm{s}}=30 \mathrm{~cm}$, and the max height of swing foot $D_{h}=3 \mathrm{~cm}$. Masses of links $m_{1}=m_{2}=0.1 \mathrm{~kg}$,
![img-2.jpeg](img-2.jpeg)

Fig. 3. ZMPs of the learned biped gait.
![img-3.jpeg](img-3.jpeg)

Fig. 4. Torques of the biped gait after learning.
$m_{3}=m_{4}=0.2 \mathrm{~kg}, m_{5}=1 \mathrm{~kg}$. Desired ZMP is set as the middle line in the stable region.

Parameters used in EDA_S_Q are $N_{\mathrm{e}}=8, N_{\mathrm{b}}=4, \beta_{f}=$ $\beta_{g}=0.5, \alpha=0.01, \gamma=0.1$. The number of sample points for the spline function is chosen as $N_{w}=20$ empirically [22]. EDA_S_Q stops learning when $\Upsilon(k)<2$ for four continuous optimization epochs or the learning index $k>200$.

Fig. 6 shows the objective function value obtained by EDA_S_Q. It reduces from about 4.5 to less than 3 in 100 epochs and finally converges to 2.9 in the desired 200 iterations. ZMP trajectory and torques of the learned gait are shown in Figs. 3 and 4, respectively. The torque before learning is exhibited in Fig. 5 for comparison. It can be seen that ZMP trajectory stays in a stable region without too much margin because it will cost too much energy. Since the objective function considers both stability and energy cost, only those gaits that are not only stable but also efficient will be finally selected. On average, both criteria are significantly lower in comparison to that before learning.

![img-4.jpeg](img-4.jpeg)

Fig. 5. Torques of the biped gait before learning.

## VI. DiscuSSION

For biped gait generation and optimization, if only the stability criterion is considered, traditional gait planning methods [13] can deal with them. However, for the multiobjective problem described in (1), heuristic methods are necessary for intelligent searching. Moreover, as indicated in Section II, traditional GAs depend on a lot of parameters, which is unfit for the multiDOFs structure learning. To emphasize the precise description brought by the special kind of probability distribution function, biped gait optimization is performed on traditional EDA with Gaussian function $G(\mu, \sigma)$-based probability distribution function for comparison. Means $\mu$ and covariance $\sigma$ are updated by (14) and (15), respectively [6].

$$
\begin{aligned}
\mu_{i, j}(k+1)= & (1-\alpha) \mu_{i, j}(k) \\
& +\alpha\left(\mu_{i, j, b}(k)+\mu_{i, j, 2 b}(k)-\mu_{i, j, w}(k)\right) \\
\sigma_{i, j}(k+1)= & (1-\alpha) \sigma_{i, j}(k)+\alpha \\
& \times \sqrt{\frac{1}{N_{\mathrm{b}}} \sum_{i=1}^{N_{\mathrm{b}}}\left(\mu_{i, j, l}(k)-\tilde{\mu}_{i, j, l}(k)\right)^{2}}
\end{aligned}
$$

where $\mu_{i, j, b}(k), \mu_{i, j, 2 b}(k)$ and $\mu_{i, j, w}(k)$ are values of the best, second best and worst individual (with respect to the objective function $\Upsilon$ ) for $q_{i, j}$ at iteration $k, \mu_{i, j, l}$ are the $N_{\mathrm{b}}$ best individuals and $\tilde{\mu}_{i, j, l}$ is their mean, $l=1,2, \ldots, N_{\mathrm{b}}, \alpha$ is the learning rate. Other parameters in EDA are the same as that in EDA_S_Q.

Objective function values obtained by EDA with different learning rates are shown in Fig. 6. It can be seen that an EDA with smaller learning rate ( 0.1 ) has longer convergent ability but with slower learning speed, while large learning rate ( 0.5 ) has worse convergent precision. However, even the preferable choice of learning rate ( 0.3 ) cannot get the same precision after 200 learning iterations. Moreover, the function value of traditional EDAs decreases along learning but from higher initial values (about 5.0 in average) with comparison
![img-5.jpeg](img-5.jpeg)

Fig. 6. Objective function variation obtained by EDA.

TABLE I
EDA AND EDA_S_Q

to that (about 4.6) of EDA_S_Q. The spline-based probability model improves the description precision for EDA_S_Q and thus can start the optimization from a lower initial value. Table I compares the experimental results of EDA_S_Q and that of traditional EDA with $\alpha=0.3$, which is the best in traditional ones. The quantitative comparison demonstrates that EDA_S_Q is better than the traditional EDA in terms of convergence speed.

Details of the efficiency for the spline-based probability model have been proved in [7]. In this paper, we will focus more on the function of Q-learning-based updating rule. In the special application for biped gait optimization and learning, the probability model of each joint is modified not only by selected solutions but also affected by the probability model of the same joint at the next key pose. Instead of assuming joint angles as independent variables, EDA_S_Q employs the inner function between them to formulate the correct probability function. The interrelationship of joint angles at successive moments is also taken into consideration to update each probability model. Therefore, as shown in Table I, the permutation of joint angles at key poses with a smaller objective function value $(\Upsilon=3.5)$ can be achieved more quickly by EDA_S_Q (about ten iterations) than traditional EDA (at least 30 iterations).

Giving an example of the conditional probability distribution function $\operatorname{Pro}_{2 \mid 1,2}$ of joint 2 between the first and the second key poses, variation of $\operatorname{Pro}_{2 \mid 1,2}$ is shown in Fig. 7. The four figures record the distribution at the initial time [Fig. 7(a)], the 30th iteration [Fig. 7(b)], the 60th iteration [Fig. 7(c)], and the 100th iteration [Fig. 7(d)] in sequence.

![img-6.jpeg](img-6.jpeg)

Fig. 7. $\operatorname{Pro}_{2[1,2}(k)$ during learning. (a) $k=1$. (b) $k=30$. (c) $k=60$. (d) $k=100$.

The peaks in Fig. 7 stand for the promising searching space. For example, for given joint angles of joint 2 at the first key pose $q_{1,2}(t)=0.3$, the preferable solution for the same joint at the second key pose would be $q_{2,2}(t)=-0.2$ with the probability about 0.8 . Here, $q_{2,2}(t)$ is not obtained directly from the corresponding probability distribution but from the conditional probability, which reflects the interrelationship between $q_{1,2}(t)$ and $q_{2,2}(t)$.

Thus, it can be concluded that: 1) the motor for joint 2 at the second key pose should work mainly during $[-0.5,0]$ because $\operatorname{Pro}_{2[1,2}$ has a large probability value in this range whatever $q_{1,2}$ is. 2) $[0,0.5]$ is the desired region of motion for joint 2 at the first key pose because $\operatorname{Pro}_{2[1,2}$ is flat when $q_{1,2}$ alters in $[0,0.5]$. This means that under such conditions, $q_{2,2}$ can vary in a correspondingly large region with legible poses. Similar conclusions can also be achieved through similar discussion on other conditional probability distribution functions.

The two merits, learning capability and precise description ability, that are inherited from Q-learning and spline-based EDA provide EDA_S_Q the remarkable ability to approximate a complex probability model without using prior knowledge in short learning epochs. It is also a useful tool to explore the relationship between interrelated parameters to be optimized,
which may help us understand the biped locomotion and to control biped robots.

## VII. CONCLUSION

There are two factors that affect the learning quality of EDA: the probability model and the updating rule. In this paper, we look at both factors to develop a new EDA with splinebased probability function and Q-learning-based updating rule (EDA_S_Q), which is able to more efficiently generate and optimize dynamically stable and low energy cost biped gaits. To deal with the relationship between the parameters of conjoint poses, their probability distribution functions are formulated without prior knowledge. Q-learning operates as a very efficient updating rule to improve the distribution function with simple rewards. By means of the proposed EDA_S_Q, desired biped gaits are generated and optimized with acceptable convergence time. Some suggestions on working scope for motors at joints can also be achieved through analyzing the conditional probability functions.

The experimental results show that the proposed EDA_S_Q is significantly better than traditional EDA in terms of convergence speed to achieve dynamically stable and energy-efficient biped gaits. The generated gaits can also be used to drive our

humanoid soccer robot, RE, which is one of the foremost leading soccer-playing humanoid robots in the RoboCup Humanoid League. To the best of our knowledge, the proposed EDA_S_Q is the first such kind of work in the framework of EDA and biped gait generation and optimization.

Based on the results of this paper, the body dynamics of the mechanical robot will be studied with transition probability models in future work. Our research challenge lies in the interpretation of transition probability models for biped locomotion so that we can progress toward a better understanding of human locomotion and extend the results to better control of humanoid robots.

## APPENDIX I

Catmull-Rom cubic spline function $f_{c}$ is a suboptimal realization of the cubic spline function $f_{\mathrm{s}}$ obtained by regularization theory.

For $v_{j} \leq x \leq v_{j+1}, 1 \leq j<N$,

$$
\begin{aligned}
f_{c}(x)= & \sum_{i=1}^{N} \alpha_{i}\left|x-v_{i}\right|^{3} \\
= & \alpha_{1}\left|x-v_{1}\right|^{3}+\cdots+\alpha_{j-1}\left|x-v_{j-1}\right|^{3} \\
& +\alpha_{j}\left|x-v_{j}\right|^{3}-\alpha_{j+1}\left|x-v_{j+1}\right|^{3} \\
& -\alpha_{j+2}\left|x-v_{j+1}\right|^{3}-\cdots-\alpha_{N}\left|x-v_{N}\right|^{3}
\end{aligned}
$$

where $\alpha_{i}$ are coefficients and $v_{i}$ are interpolation samples. $i=1, \ldots, N, N$ is the number of samples. Collecting the terms of equal degree, $f_{\mathrm{s}}$ can be expressed as

$$
f_{\mathrm{s}}(x)=A x^{3}+B x^{2}+C x+D
$$

To reproduce the interval $\left[v_{j}, v_{j+1}\right]$ with Catmull-Rom cubic spline, four control points $W_{1}, W_{2}, W_{3}, W_{4}$ are set on the curve equally as $\Delta x=v_{j+1}-v_{j}, w_{x_{2}}=v_{j}, w_{x_{3}}=v_{j+1}$. Thus

$$
\begin{aligned}
f_{c}(x)= & \frac{1}{2}\left(-w_{y_{1}}+3 w_{y_{2}}-3 w_{y_{3}}+w_{y_{4}}\right)\left(\frac{x-v_{j}}{\Delta x}\right)^{3} \\
& +\frac{1}{2}\left(2 w_{y_{1}}-5 w_{y_{2}}+4 w_{y_{3}}-w_{y_{4}}\right)\left(\frac{x-v_{j}}{\Delta x}\right)^{2} \\
& +\frac{1}{2}\left(-w_{y_{1}}+w_{y_{3}}\right)\left(\frac{x-v_{j}}{\Delta x}\right)+w_{y_{2}} \\
= & \bar{A} x^{3}+\bar{B} x^{2}+\bar{C} x+\bar{D} \\
= & f_{\mathrm{s}}(x)
\end{aligned}
$$

These calculations show that Catmull-Rom spline with properly chosen control points is equivalent to the optimal cubic spline everywhere between $v_{j}$ and $v_{j+1}$.

## APPENDIX II

This appendix considers the general problem of reconstruction of a function $D(x)$ on the continuous variable $x$ from a discrete set of measurements collected on a uniform grid with
step size $\Delta x$. The main interest is to quantify the difference between $D(x)$ and its approximated version $F_{\Delta x}(x)$.

Corollary: $\lim _{\Delta x \rightarrow 0}\left|F_{\Delta x}(x)-D(x)\right|=\lim _{\Delta x \rightarrow 0}|\varepsilon|=0$ with the constraints that $F_{\Delta x}(k \Delta x)=D(k \Delta x)$. Where $F_{\Delta x}=\sum_{k \in \chi^{d}} w_{k} C((x / \Delta x)-k), x \in R^{d}, w_{k}$ are samples at integer coordinates. $C(x)$ is the interpolation function. $\chi_{i}=\left[\left[\left(x_{i}(t) / \Delta x\right)+(N / 2)\right], \ldots,\left[\left(x_{i}(t) / \Delta x\right)+(N / 2)\right]+3\right]$. $N$ is the number of total samples. To satisfy the requirement of exact interpolation, $C(x)$ must vanish for all integer arguments except at the origin, where it must take a unit value.

Proof: For the mean square

$$
\begin{aligned}
\varepsilon^{2}(\Delta x) & =\left|F_{\Delta x}(x)-D(x)\right|_{L_{2}}^{2} \\
& =\int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty}\left(F_{\Delta x}(x)-D(x)\right)^{2} d x_{1}, \ldots, d x_{d}
\end{aligned}
$$

the following formula predicts the approximation error in the Fourier domain [25]:

$$
\eta^{2}(\Delta x)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty}|\bar{F}(\delta)|^{2} E_{\mathrm{int}}(\delta \Delta x) d \delta_{1}, \ldots, d \delta_{d}
$$

where $\bar{F}(\delta)=\int F(x) e^{2 \pi i \delta x} d x$ is the Fourier transform of the arbitrary function $F(x), E_{\text {int }}$ is an interpolation error kernel that depends on the basis function only. It is given by

$$
E_{\mathrm{int}}(\delta)=\frac{\left|\sum_{k \in \chi^{d}} \hat{C}(\delta+2 \pi k)\right|^{2}+\sum_{k \in \chi^{d}}|\hat{C}(\delta+2 \pi k)|^{2}}{\left|\sum_{k \in \chi^{d}} \hat{C}(\delta+2 \pi k)\right|^{2}}
$$

$\varepsilon=\eta$ holds for band limited functions [25]. A decrease in the sampling width $\Delta x$ will result in a decrease of the argument of $E_{\text {int }}$. Thus, the error kernel must vanish at the origin such that

$$
\eta^{2}(\Delta x)=\lim _{\Delta x \rightarrow 0}\left(w_{\mathrm{int}}\right)^{2} \Delta x^{2} \frac{1}{2 \pi} \int_{-\infty}^{\infty}\left|\delta^{L} \hat{F}(\delta)\right|^{2} d \delta
$$

The vanishing rate of error kernel is controlled by approximation order $L$ and a constant

$$
w_{\mathrm{int}}=\lim _{\delta \rightarrow 0} \frac{\sqrt{E_{\mathrm{int}}(\delta)}}{\delta^{L}}
$$

Finally, we have

$$
\begin{aligned}
\lim _{\Delta x \rightarrow 0} \eta(\Delta x) & =\lim _{\Delta x \rightarrow 0}\left|F_{\Delta x}(x)-F(x)\right| \\
& =w_{\mathrm{int}} \Delta x^{L}\left|\bar{F}^{L}(\delta)\right|_{L_{2}}
\end{aligned}
$$

Therefore, for any smooth function $w(x)$ with approximation order $L$ and a constant $w_{\text {int }}$, the approximation error $\varepsilon$ predicted by $\eta$ decreases like $\Delta x^{L}$, where $\Delta x$ is sufficiently small.

Remark 4: Approximation order $L$ gives a global estimation of approximation speed when the sampling width $\Delta x$ gets finer.

Remark 5: The constant $w_{\text {int }}$ ranks the quality of basis functions that having the same approximation order $L$. A smaller $w_{\text {int }}$ corresponds to a better $w(x)$.
