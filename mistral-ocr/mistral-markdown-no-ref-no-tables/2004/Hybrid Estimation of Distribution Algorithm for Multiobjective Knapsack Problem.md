# Hybrid Estimation of Distribution Algorithm for Multiobjective Knapsack Problem 

Hui Li, Qingfu Zhang, Edward Tsang, and John A. Ford<br>Department of Computer Science, University of Essex<br>Wivenhoe Park, Colchester CO4 3SQ, United Kingdom<br>\{hlil,qzhang,edward,fordj\}@essex.ac.uk


#### Abstract

We propose a hybrid estimation of distribution algorithm (MOHEDA) for solving the multiobjective $0 / 1$ knapsack problem (MOKP). Local search based on weighted sum method is proposed, and random repair method (RRM) is used to handle the constraints. Moreover, for the purpose of diversity preservation, a new and fast clustering method, called stochastic clustering method (SCM), is also introduced for mixture-based modelling. The experimental results indicate that MOHEDA outperforms several other state-of-the-art algorithms.


## 1 Introduction

Over the past twenty years, numerous multiobjective evolutionary algorithms (MOEAs) have been proposed for multiobjective optimization problems (MOPs) [2]. Compared with classical methods, MOEAs are more suitable for solving MOPs for the following reasons: (i) multiple solutions can be found in a single run of a MOEA; (ii) a good spread of the nondominated solutions can be reached; and (iii) a MOEA is less susceptible to the shape or continuity of the Pareto-optimal front. Due to the conflicting relationships between objectives, it is unlikely to find such a solution that optimizes all objectives simultaneously. In practice, it is a hard task to find all nondominated solutions when, as is often the case, the number of Pareto-optimal solutions is huge or even infinite. Therefore, when applying an evolutionary algorithm to MOPs, two major issues should be addressed:

- The resultant nondominated front should be as close to the Pareto-optimal front as possible (convergence);
- The nondominated solutions should be distributed as uniformly (in most cases) and widely along the Pareto-optimal front as possible (diversity).

The performance of MOEAs can be improved by local search. IMMOGLS 5] should be regarded as the first algorithm to hybridize MOEAs with local search. In this algorithm, all weights are generated randomly. Jaszkiewicz (1998) proposed multiobjective genetic local search (MOGLS) 1]. Weighted Tchebycheff scalarizing functions are used to evaluate the fitness value for each individual solution. Local search and selection are implemented on the basis of the current

scalarizing function. In MOGLS, all weights of the scalarizing function are also created in a random way. Without using the linear combination of objectives, Knowles and Corne (2000)[7] proposed a memetic Pareto archived evolutionary strategy (M-PAES), which combines the recombination operators with an evolutionary strategy (PAES). In M-PAES, the acceptance of a new solution generated by genetic search or local search depends not only on the Pareto-dominance relationship but also on the grid-type partition of the objective space.

Estimation of distribution algorithm (EDA) is a new paradigm in evolutionary computation. Recently, few multiobjective EDAs have been proposed and studied. Mixture-Based Iterated Density Estimation Evolutionary Algorithms (MIDEA) was proposed by Thierens and Bosman (2001) 3]. Multiobjective Bayesian Optimization Algorithms (mBOA) was introduced by Khan, Goldberg, and Pelikan (2002) 9]. Population-Based Ant Colony Optimization for MOP was developed by Guntsch1 and Middendorf (2003) 8]. This class of algorithms generalizes genetic algorithms by replacing the crossover and mutation operators with learning and sampling the probability distribution of the best individuals in the previous population.

However, the main goal of MOEAs is to improve the performance both in algorithmic convergence and in diversity preservation. To this end, we propose a hybrid estimation of distribution algorithm for solving the MOKP.

This paper is organized as follows. In section 2, MOPs and MOKP are briefly introduced. Local search is discussed in section 3. Section 4 contains stochastic clustering method. In the following section, MOHEDA is proposed. The experimental results are presented in section 6. In the final section, conclusions are given.

# 2 Multiobjective Optimization 

A general MOP consists of a set of $d$ decision variables, a set of $n$ objectives, and a set of $m$ constraints. Both objectives and constraints are functions of the decision variables. The optimization goal is to

$$
\begin{array}{cc}
\operatorname{maximize} & f_{i}(\mathbf{x}) \quad i=1, \ldots, n \\
\text { s.t. } & c_{j}(\mathbf{x}) \leq 0 \quad j=1, \ldots, m
\end{array}
$$

where $\quad \mathbf{x}=\left(x_{1}, \ldots, x_{d}\right)$ is the decision vector in the decision space and $\mathbf{f}(\mathbf{x})=$ $\left(f_{1}(\mathbf{x}), \ldots, f_{n}(\mathbf{x})\right)$ is the objective vector in the objective space.

For any two decision vectors $\mathbf{x}^{(\mathbf{1})}$ and $\mathbf{x}^{(\mathbf{2})}, \mathbf{x}^{(\mathbf{1})}$ is said to dominate $\mathbf{x}^{(\mathbf{2})}$, denoted by $\mathbf{x}^{(\mathbf{1})} \succ \mathbf{x}^{(\mathbf{2})}$, if $f_{k}\left(\mathbf{x}^{(\mathbf{1})}\right) \geq f_{k}\left(\mathbf{x}^{(\mathbf{2})}\right), \forall k \in\{1, \ldots, n\}$ and there exists at least a $k^{\prime} \in\{1, \cdots, n\}$ such that $f_{k^{\prime}}\left(\mathbf{x}^{(\mathbf{1})}\right)>f_{k^{\prime}}\left(\mathbf{x}^{(\mathbf{2})}\right)$. A decisoin vector $x^{*}$ is said to be Pareto-optimal if there is no any decision vector in the decision space which dominates $x^{*}$.

MOKP is a well-known NP-hard multiobjective combinatorial optimization problem, which has been studied by many researchers for testing the performance of MOEAs. It is a generalization of the 0-1 single objective knapsack problem.

Let $p_{i j}$ be the profit of item $j$ associated with knapsack $\mathrm{i}, \omega_{i j}$ be the weight of item $j$ associated with knapsack i , and $c_{i}$ be the capacity of knapsack i , the goal is to find a binary vector $\mathbf{x}=\left(x_{1}, \ldots, x_{d}\right) \in\{0,1\}^{d}$ such that

$$
\sum_{j=1}^{d} \omega_{i j} \cdot x_{j} \leq c_{i}, i=1,2, \ldots, m
$$

and for which $\mathbf{f}(\mathbf{x})=\left(f_{1}(\mathbf{x}), \ldots, f_{n}(\mathbf{x})\right)$ is maximized, where

$$
f_{i}(\mathbf{x})=\sum_{j=1}^{d} p_{i j} \cdot x_{j}, i=1, \cdots, n
$$

# 3 Local Search 

Local search is a simple iterative method for finding good approximate solutions. It should be pointed out that the acceptance function of a neighbour solution in MOPs are slightly different from that in single objective problems. For example, in M-PAES, a reference set is required to evaluate the Pareto-based fitness values of solutions. In this paper, the acceptance function $h(\mathbf{x})$ is defined as the linear combination of all objectives by:

$$
h(\mathbf{x})=\sum_{i=1}^{n} w_{i} \cdot f_{i}(\mathbf{x})
$$

where $w_{i}>0, i=1, \ldots, n$, is the weight for the $i^{t h}$ objective and $\sum_{i=1}^{n} w_{i}=1$.
In IMMOGLS and MOGLS, the weights for the acceptance function are generated randomly. Here, the weights are determined by the start solution $\mathbf{x}$ in the following way. Two extra vectors in the objective space: $\left(f_{\max }^{(1)}, \ldots, f_{\max }^{(n)}\right)$ and $\left(f_{\min }^{(1)}, \ldots, f_{\min }^{(n)}\right)$, are required. In the context of evolutionary algorithm, $f_{\text {max }}^{(k)}$ and $f_{\text {min }}^{(k)}$ are the maximization and the minimization of the $k^{t h}$ objective in the population. Then, the raw weight $w_{i}^{\prime}$ is given by:

$$
w_{i}^{\prime}=f_{i}(\mathbf{x})-f_{\min }^{(i)}, i=1, \ldots, n
$$

Take the order of magnitude into consideration, the unbiased coefficient $e_{i}, i=1, \ldots, n$, is introduced as:

$$
e_{i}=\frac{1}{f_{\max }^{(i)}-f_{\min }^{(i)}}
$$

Therefore, the weights for the acceptance function are:

$$
w_{i}=\frac{w_{i}^{\prime} \cdot e_{i}}{\sum_{j=1}^{n} w_{j}^{\prime} \cdot e_{j}}, i=1, \ldots, n
$$

The local search procedure for MOKP is described as follows:

# Algorithm 1: Local Search 

- (1) Select the starting solution $\mathbf{x}$, and generate a set of heuristic weights $w_{i}, i \in\{1, \ldots, n\}$ according to (7);
- (2) For each item $j \in I=\left\{n_{1}, \ldots, n_{|I|}\right\}$ with $x_{j}=0$;

- Set $x_{j}:=1$;
- Repair the modified $\mathbf{x}$;
- Record the set $\mathcal{I}_{j}$ of all removed items;
- Compute $t_{j}:=\sum_{i=1}^{n} w_{i} \cdot p_{i j}-\sum_{k \in \mathcal{I}_{j}} \sum_{i=1}^{n} w_{i} \cdot p_{i k}$;
- Reset $\mathbf{x}$.
- (3) Sort the series $t_{j}, j \in\left\{n_{1}, \ldots, n_{|I|}\right\}$ and calculate $j_{m}:=\arg \max _{j \in I} t_{j}$;
- (4) Update $\mathbf{x}$ with $x_{j_{m}}:=1$ and set $x_{k}:=0$ for all $k \in \mathcal{I}_{j_{m}}$;
- (5) If the maximal number of local search steps is reached, stop; Otherwise, goto step 2 .

Note that a portion of solutions generated by recombination operators or the move in local search might be infeasible. In this case, some repair strategies should be employed to handle the constraints. Greedy repair method (GRM) is a frequently-used approach. In this paper, we propose random repair method (RRM) for handling constraints and constructing the random neighbourhood. The items will be randomly removed from the knapsacks until the constraints are satisfied. In comparison with GRM, RRM is easy to implement and its computational time is less than that of GRM. We also note that the initial population with higher quality can be created by GRM.

## 4 Stochastic Clustering Method

As pointed out in [3], the diversity of the Pareto-optimal front can be maintained by the mixture of factorized probability distributions. The population is divided into a couple of clusters using the Euclidean leader algorithm. Each cluster is processed separately and a local probability model is built on its related cluster. In the context of population-based algorithms, each cluster consists of a number of good selected solutions which are currently optimal with respect to a certain weighted sum function. Then, different possible weighted sum functions can be simultaneously optimized in a single generation. In this paper, we propose a new and fast clustering method, called stochastic clustering method (SCM). The process of SCM is mathematically described in the remainder of this section.

Assume that $\prod_{i=1}^{n}\left[L B_{i}, U B_{i}\right]$ is the domain of a population $P$ in the objective space, where $L B_{i}=\min _{\mathbf{x} \in P} f_{i}(\mathbf{x})$ and $U B_{i}=\max _{\mathbf{x} \in P} f_{i}(\mathbf{x})$. Suppose that we have a set of subdomains $D_{j}=\prod_{i=1}^{n}\left[L B_{i}^{(j)}, U B_{i}^{(j)}\right], j=1, \ldots, J$, where $J$ is the number of subdomains. A quantitative metric for the objective with the maximal range in the subdomain $D_{j}, j=1, \ldots, J$, is defined as:

$$
r_{j}=\max _{i \in\{1, \ldots, n\}} \frac{U B_{i}^{(j)}-L B_{i}^{(j)}}{U B_{i}-L B_{i}}
$$

The index of the objective with the maximal range in the subdomain $D_{j}$ is given by:

$$
I_{j}=\arg \max _{i \in\{1, \ldots, n\}} \frac{U B_{i}^{(j)}-L B_{i}^{(j)}}{U B_{i}-L B_{i}}
$$

Then, the $K^{t h}\left(K=\arg \max _{j \in\{1, \ldots, J\}} r_{j}\right)$ subdomain with the maximal metric for the range is decomposed in the following way:

$$
\begin{aligned}
L B_{i}^{(a)} & =L B_{i}^{(b)}=L B_{i}^{(K)} \text { if } i \neq I_{K} \\
U B_{i}^{(a)} & =U B_{i}^{(b)}=U B_{i}^{(K)} \text { if } i \neq I_{K} \\
L B_{I_{K}}^{(a)} & =L B_{I_{K}}^{(K)} \\
U B_{I_{K}}^{(a)} & =L B_{I_{K}}^{(K)}+\left(\frac{1}{3}+\alpha\right) \Delta \\
L B_{I_{K}}^{(b)} & =L B_{I_{K}}^{(K)}+\left(\frac{1}{3}+\alpha\right) \Delta \\
U B_{I_{K}}^{(b)} & =U B_{I_{K}}^{(K)}
\end{aligned}
$$

where $\Delta=U B_{I_{K}}^{(K)}-L B_{I_{K}}^{(K)}$ and $\alpha$ is a random number in $[0,1]$. In this way, the subdomain $D_{K}$ can be divided into two nonoverlapped subdomains $D_{a}=$ $\prod_{i=1}^{n}\left[L B_{i}^{(a)}, U B_{i}^{(a)}\right]$ and $D_{b}=\prod_{i=1}^{n}\left[L B_{i}^{(b)}, U B_{i}^{(b)}\right]$. In SCM, there is no need to calculate the distances between individuals which are crucial for other clustering algorithms. Moreover, subdomains dynamically vary with generations.

For instance, we have two two-dimensional subdomains $D_{1}=[0,10] \times[0,20]$ and $D_{2}=[0,20] \times[0,30]$. Here, we assume that $e_{1}$ equals to $e_{2}$. Then, the metric values of $D_{1}$ and $D_{2}$ are $20 \cdot e_{1}$ and $30 \cdot e_{2}$ respectively. Therefore, we decompose $D_{2}$ into $[0,20] \times[10+\alpha 10,30]$ and $[0,20] \times[0,10+\alpha 10]$.

# 5 Hybrid Estimation of Distribution Algorithm 

Estimation of Distribution Algorithms (EDAs) were first introduced by Mühlenbein and Paaß (1996) [6]. The detailed introduction of EDAs can be found in Larrañaga's book [10]. In EDAs, there are neither crossover nor mutation operators. Instead, a new population is sampled from a probability distribution, which is modelled from the selected best solutions. The dependencies among the variables involved can be explicitly and effectively captured and exploited. According to the types of dependencies among variables involved, EDAs can be classified into three categories: without dependencies (UMDA 1998, PBIL 1994, and cGA 1998), bivariate dependencies (MIMIC 1997, COMIT 1997, and BMDA 1999), and multivariate dependencies (EcGA 1999, FDA 1999, EBNA 2000, and BOA 2000).

Recently, hybrid estimation of distribution algorithms have been developed for solving global optimization [11]. To improve the performance of a MOEA both in convergence and in diversity, we propose a mixture-based hybrid estimation of

distribution algorithm (MOHEDA). Univariate Marginal Distribution Algorithm (UMDA) is employed. In UMDA, the joint probability distribution of the selected individuals at each generation, $p(\mathbf{x}, t)$, is factorized as a product of independent univariate marginal distributions $p\left(x_{i}, t\right), i=1, \ldots, d$. This joint distribution can be written as:

$$
p(\mathbf{x}, t)=p\left(\mathbf{x} \mid \operatorname{Pop}^{S e}(t-1)\right)=\prod_{i=1}^{d} p\left(x_{i}, t\right)
$$

where $\operatorname{Pop}^{S e}(t-1)$ is the set of selected individuals from the previous population.
In MOHEDA, an elite population is maintained to store all nondominated solutions found so far. At the beginning of search, this population is empty. It is updated by the local optima obtained in the local search. The mating pool $P_{m}^{(t)}$ consists of the solutions selected from the elite population or current population. Using SCM, the domain of $P_{m}^{(t)}$ is divided into $n_{d}$ subdomains $D_{j}, j=1, \ldots, n_{d}$. The mixture-based probability models can be reformulated by:

$$
p^{(k)}(\mathbf{x}, t)=p\left(\mathbf{x} \mid \operatorname{Pop}^{S e}(k, t)\right)=\prod_{i=1}^{d} p^{(k)}\left(x_{i}, t\right)
$$

where $\operatorname{Pop}^{S e}(k, t)$ is the set of mating parents which belong to the $k^{t h}$ subdomain $D_{k}$. In the following, we summarize the framework of MOHEDA.

# Algorithm 2: MOHEDA 

- (1) Initialization: Generate an initial population $P^{(0)}$ with $n_{p}$ individuals randomly and create an elite population $P_{e}^{(0)}:=\emptyset$; Perform local search on $P^{(0)}$ and update $P_{e}^{(0)}$; Set $\mathrm{t}:=0$.
- (2) Selection: Select $n_{p}$ individuals from $P^{(t)} \cup P_{e}^{(t)}$ and place them in the mating pool $P_{m}^{(t)}$;
- (3) Stochastic Clustering: Decompose the domain of $P_{m}^{(t)}$ into $n_{d}$ disjoint subdomains;
- (4) Mixture-Based Modelling: Estimate the distribution $p^{(k)}(\mathbf{x}, t)$ on each subdomain $D_{k}, k=1, \ldots, n_{d}$
- (5) Sampling: Sample the new population $P^{(t+1)}$ with $n_{p}$ individuals according to the distributions $p^{(k)}(\mathbf{x}, t), k=1, \ldots, n_{d}$;
- (6) Local Search: Select $\frac{n_{p}}{2}$ individuals from $P^{(t+1)}$, perform local search for each selected individual and update $P_{e}^{(t+1)}$ with the local optima;
- (7) Termination: If the termination criteria are satisfied, then stop. Otherwise, set $\mathrm{t}:=\mathrm{t}+1$ and go to step 2 .

In MOHEDA, both repair methods are taken into account. In the initialization, we use GRM to generate high quality solutions. Besides, new solutions produced by sampling and local search are repaired by RRM. Note that the size of the elite population will probably be increased since more and more new possible nondominated solutions may be found during the evolution. To maintain the limited size $n_{e}$ of the elite population, we remove some individuals randomly until the number of elite individuals is less than $n_{e}$.

# 6 Experiments 

In this section, the performance metrics of MOEAs are introduced. Some experiments are devised to test the performance of MOHEDA both in convergence and in diversity. The numerical results are briefly discussed.

### 6.1 Performance Metrics

How to assess the performance of MOEAs is very difficult. Many performance metrics have been proposed and studied for convergence and diversity. In this section, three metrics are briefly discussed.

The coverage metric proposed by Zitzler is used to assess the performance of various MOEAs. The function $\mathcal{C}(A, B)$ maps the ordered algorithm pair $(A, B)$ into a real number in $[0,1]$. The value $\mathcal{C}(A, B)$ means the percentage of the solutions in $A$ covered by the solutions in $B$.

In order to evaluate the convergence of MOGLS and MOHEDA, the average values (front error) of the minimal, mean and maximal distances between nondominated front and the Pareto-optimal front in 20 runs are calculated. The lower value of the distances, the closer to the Pareto-optimal front the resultant nondominated front is.

Consider not only the standard deviation of distances between nondominated solutions but also the maximal spread, we propose a new metric to evaluate the spread of the set $A$ of nondominated solutions. This metric can be formulated as:

$$
D=\frac{\sum_{k=1}^{n}\left(f_{\max }^{(k)}-f_{\min }^{(k)}\right)}{\sqrt{\frac{1}{|A|} \sum_{i=1}^{|A|}\left(d_{i}-\bar{d}\right)^{2}}}
$$

where $d_{i}$ is the Euclidean distance between the $i^{\text {th }}$ solution and its closest neighbour and $\bar{d}$ is the mean distance. The greater value of the diversity metric, the better the diversity of nondominated solutions is.

### 6.2 Experimental Settings

The proposed MOHEDA has been compared with MOGLS. Nine test instances including 2,3 and 4 objectives, associated with 250,500 and 750 items respectively, are considered. The profits, weights and capacities in our experiments are identical to the data reported in [1][3], which can be downloaded from the link http://www.tik.ee.ethz.ch/ zitzler/testdata.html/.

In Jaszkiewicz's paper [1], MOGLS has been demonstrated to be the best algorithm for MOKP. MOGLS outperforms several other MOEAs, such as NSGA, SPEA and M-PAES. Thus, we only compared our algorithm with MOGLS. MOHEDA was implemented in $\mathrm{C}++$. All experiments were performed on identical PCs (AMD Athlon 2400MHZ) running Linux.

Three parameters: the size of the population $n_{p}$, the number of subdomains $n_{d}$ and the limited size of the elite population $n_{e}$, are given in Table 1. To be

![img-0.jpeg](img-0.jpeg)

Fig. 1. Nondominated solutions of the instances with 2 knapsacks: 500 items (left), 750 items (right).
consistent with the parameter settings of other algorithms, the size of population and the maximal number of objective function evaluations are determined in the same way as SPEA [4] and MOGLS [1]. The search was terminated after completing $n_{p} \times 500$ objective function evaluations. We performed MOHEDA 20 runs on each of 9 instances.

Table 1. Parameter Settings

# 6.3 Experimental Results 

The mean coverage metrics of MOHEDA and MOGLS for nine test instances among 20 runs are given in Table 2. In the case of 2 knapsacks, there are nearly $98 \%$ of the solutions of MOGLS covered by the solutions of MOHEDA. It can be observed from Fig. 1 that the nondominated solutions of MOHEDA are welldistributed along the true Pareto-optimal front. For the instances with 3 knapsacks, MOHEDA still performs better than MOGLS, and about $65 \%$ of nondominated solutions of MOGLS are dominated by the solutions of MOHEDA. MOHEDA is slightly superior to MOGLS for the instances with 4 knapsacks. Nevertheless, the coverage metric $\mathcal{C}$ (MOGLS,MOHEDA) decreases as the number of knapsacks increases. This might be caused by the immaturity of the population. If we increase the number of evolutionary generations, a better coverage metric could be obtained.

Table 2. Coverage Metrics for 9 Test Instances

![img-1.jpeg](img-1.jpeg)

Fig. 2. Nondominated solutions of the instance with 3 knapsacks and 750 items: MOHEDA(left), MOGLS(right).

Table 3. Convergence and Diversity Metrics
# 7 Conclusions 

MOHEDA has been compared with MOGLS on MOKP. The experimental results show that MOHEDA outperforms MOGLS both in convergence and in diversity. The following techniques are effectively used in MOHEDA: (1) random repair method is used; (2) random neighbourhood structure is constructed in local search; (3) stochastic clustering method is employed; (4) a mixture-based UMDA is introduced. The distinct feature of MOHEDA is that multiple possible weighted sum functions can be optimized in a single generation. Moreover, the further work may focus on the performance analysis of MOHEDA.
