# Novel Prediction Strategies for Dynamic Multiobjective Optimization 

Qingyang Zhang, Shengxiang Yang ${ }^{\oplus}$, Senior Member, IEEE, Shouyong Jiang, Ronggui Wang, and Xiaoli Li ${ }^{\ominus}$


#### Abstract

This paper proposes a new prediction-based dynamic multiobjective optimization (PBDMO) method, which combines a new prediction-based reaction mechanism and a popular regularity model-based multiobjective estimation of distribution algorithm (RM-MEDA) for solving dynamic multiobjective optimization problems. Whenever a change is detected, PBDMO reacts effectively to it by generating three subpopulations based on different strategies. The first subpopulation is created by moving nondominated individuals using a simple linear prediction model with different step sizes. The second subpopulation consists of some individuals generated by a novel sampling strategy to improve population convergence as well as distribution. The third subpopulation comprises some individuals generated using a shrinking strategy based on the probability distribution of variables. These subpopulations are tailored to form a population for the new environment. The experimental results carried out on a variety of bi- and three-objective benchmark functions demonstrate that the proposed technique has competitive performance compared with some state-of-the-art algorithms.


Index Terms-Dynamic multiobjective optimization, nondominated sorting, prediction-based reaction, probability distribution.

## I. INTRODUCTION

MANY real-world optimization problems, such as scheduling [36], planning [37], constrained optimization [39], electromagnetic micromirrors [44], dynamic subset sum [46], weapon selection [47], and

Manuscript received December 24, 2018; revised April 26, 2019; accepted June 1, 2019. Date of publication June 13, 2019; date of current version March 31, 2020. This work was supported in part by the National Natural Science Foundation of China under Grant 61673331, Grant 61873006, Grant 61473034, and Grant 61673053, in part by the Shenzhen Peacock Plan under Grant KQTD2016112514355531, in part by the Beijing Science and Technology Major Project under Grant Z18110003118012, and in part by the National Key Research and Development Project under Grant 2018YFC1602704 and Grant 2018YFB1702704. (Corresponding author: Shengxiang Yang.)
Q. Zhang is with the School of Computer Science and Technology, Jiangsu Normal University, Xuzhou, China (e-mail: hgd_qy@126.com).
S. Yang is with the School of Computer Science and Informatics, De Montfort University, Leicester LE1 9BH, U.K., and also with the Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China (e-mail: syang@dmu.ac.uk).
S. Jiang is with the School of Computer Science, University of Lincoln, Lincoln LN6 7TS, U.K. (e-mail: matb4neu@gmail.com).
R. Wang is with the School of Computer and Information, Hefei University of Technology, Hefei 230009, China (e-mail: wangrgui@hfut.edu.cn).
X. Li is with the Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China (e-mail: lixiaolibjut@bjut.edu.cn).

This paper has supplementary downloadable material available at http://ieeexplore.ieee.org, provided by the author.

Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.

Digital Object Identifier 10.1109/TEVC.2019.2922834
machine learning [40], [41], require to be solved in dynamic or uncertain environments [42]. This kind of problems are called dynamic multiobjective optimization problems (DMOPs), which are characterized by some changes that may occur in the Pareto-optimal set (POS) or Pareto-optimal front (POF), objective functions, constraints, or other parameters. Sometimes, the changes between two consecutive moments are not significant and have some similarities. It is not necessary to restart the relevant programs. Therefore, the study on DMOPs is meaningful in solving practical applications efficiently. Recently, DMOPs is one of the hot topics that has attracted increasing attention in the field of evolutionary computation.

Although there may exist different classes of dynamic optimization problems according to [14] and [43], this paper considers the following mathematical form of DMOPs:

$$
\min _{x \in \Omega} F(x, t)=\left(f_{1}(x, t), f_{2}(x, t), \ldots, f_{m}(x, t)\right)^{T}
$$

where $\Omega=\prod_{i=1}^{D}\left[L_{i}, U_{i}\right] \subset R^{D}$ is the feasible area of the decision space, and $F$ consists of $m$ time-varying objective functions. $x=\left(x_{1}, x_{2}, \ldots, x_{D}\right)$ defines the decision vector involving $D$ variables, and $t$ is the time instant of the problem. $L_{i}$ and $U_{i}$ represent the lower and upper bounds of the $i$ th variable $x_{i}$, respectively.

Different from single optimization problems (SOPs), multiobjective optimization problems (MOPs) usually involves at least two conflicting optimization objectives that need to be optimized simultaneously. Due to multiobjectivity, the goal of solving MOPs is not to find a single optimal solution but to find a set of tradeoff solutions. When an MOP involves time-dependent components, it can be regarded as a DMOP. Compared with stationary MOPs, DMOPs are more difficult due to the nature of dynamics, which may cause the change of POS in the decision space or POF in the objective space over time. DMOPs are frequently reported in real-world applications like engineering [38] and water distribution systems [45], and there is a great need of effective approaches to solve them. Due to great importance and economic relevance, there are an increasing number of research interests in dynamic optimization [10], [15], [34].

To solve DMOPs, most of the existing dynamic multiobjective evolutionary algorithms (DMOEAs) directly adopt the techniques from static multiobjective evolutionary algorithms (MOEAs), assuming that a DMOP can be divided into a sequence of MOPs over time. That is, solving a DMOP can be regarded as adopting MOEAs to solve a sequence of correlated MOPs and obtain corresponding

POSs or POFs [48]. However, an efficient DMOEA should not only have a good MOEA, but also have a good reaction mechanism, which is able to keep a good balance between convergence and diversity over time [10]. Since the changes are unknown in advance, a DMOEA may not have enough time for searching optimal solutions before a change occurs. So, it is necessary for a DMOEA to have the fast convergence performance. Meanwhile, whenever a change occurs, previously obtained solutions may not remain optimal for the new environment [50]. So, how to address diversity loss is also important. In addition, change detection techniques are needed since they can prevent the algorithm from being misled in the optimization process.

Based on above considerations, this paper proposes a new prediction-based DMOEA, called PBDMO, which combines several strategies to generate a high-quality population for new environments. First, a new prediction strategy is proposed to relocate nondominated solutions of the previous environment diversely around the estimated location of the new POF after a change occurs. Second, a classification strategy is proposed to classify decision variables into principal and nonprincipal groups in order to effectively generate well-diversified solutions. Third, the probability distribution of decision variables is used to generate another group of good solutions. Solutions generated from these three strategies undergo nondominated sorting and then form a population for the new environment. The experimental results indicate that PBDMO has promising tracking ability for time-varying POFs or POSs. Overall, the main contributions of this paper include the following.

1) New strategies to relocate nondominated solutions for previous environments well to the new POF.
2) Classification-based sampling to enhance population diversity.
3) Probability-based space shrinkage to generate highquality solutions.
4) Systematic studies that demonstrate the effectiveness the proposed strategies.
As a result, the proposed PBDMO has two main advantages over the considered state-of-the-art algorithms as demonstrated by extensive empirical studies. First, PBDMO is able to generate a well-diversified and well-positioned population so as to track the moving POF closely and with good solution distribution. Second, PBDMO is more robust than the other algorithms as its performance does not fluctuate widely across a variety of problems with diverse dynamic characteristics.
The rest of this paper is outlined as follows. Section II gives the basic framework and related work about DMOEAs. Section III describes the proposed PBDMO algorithm in detail. In Section IV, the performance of the proposed algorithm is validated and analyzed based on a comprehensive set of benchmark functions. Section V presents further analysis on the proposed algorithm. Section VI concludes this paper.

## II. Related Work

In recent years, much effort has been devoted to designing efficient DMOEAs. A widely used framework of DMOEAs in the literature is shown in Algorithm 1. As shown in

## Algorithm 1 Basic Framework of DMOEA

1: Initialize time instance $t=0$;
2: Generate an initial population $\operatorname{Pop}_{t}$;
3: while The termination criterion is not satisfied do
4: Detect change;
5: if Change detected then
6: Optimize the population using DMOEA;
7: else
8: $\quad$ Optimize the population using MOEA;
9: end if
10: end while
this framework, the whole procedure of solving DMOPs contains two main components: 1) change detection and 2) multiobjective algorithms, including DMOEAs and MOEAs.

## A. Change Detection

Change detection is an important part in dynamic optimization since it identifies whether the change has appeared or not and determines whether a response should be made [9]. Changes are detected by either re-evaluating solutions [11], [12], [33] or checking population statistical information [20]. Each method has its advantages and disadvantages for different DMOPs. Most existing studies focus on the former, which is easy to implement but likely sensitive to noise. In contrast, the latter is robust to noise, but it needs some additional parameters.

## B. Dynamic Multiobjective Optimization Algorithms

Due to the frequency or severity of change, there may be limited computational resources available for evolution before another change arrives, and changes may occur in various forms. This provides different levels of challenges. So, high-quality algorithms are needed to cope with the change if detected. A good dynamic multiobjective algorithm should consider two important elements: 1) diversity and 2) convergence. The former helps the algorithm avoid local optima whereas the latter determines whether the algorithm tracks changes rapidly. How to design an algorithm that can balance the diversity and convergence for tracking the uncertain POF or POS closely is always a formidable task. Most existing algorithms can be categorized into the following four different classes: 1) diversity-based algorithms; 2) memory-based algorithms; 3) multipopulation-based algorithms; and 4) prediction-based algorithms.

Diversity-based algorithms aim to increase/maintain population diversity in the event of environmental changes. Many diversity maintenance methods have been proposed in recent years. Hyper-mutation and random immigration are effective approaches to maintain population and there have been applied to the nondominated sorting genetic algorithm II (NSGA-II) [7], resulting in two dynamic variants, i.e., DNSGA-II-A and DNSGA-II-B for DMOPs. However, these approaches seem ineffective in complex dynamic environments, particularly when changes are not predictable [28].

Memory-based algorithms transfer knowledge of previous environments to new environments. Generally, some promising solutions are stored in memory and reused after a change

is detected. In [10], a co-evolutionary multiobjective algorithm hybridizes competitive and cooperative mechanisms to solve the DMOPs, and the out-of-date archived solutions are replaced by an external population. Azzouz et al. [2] proposed an adaptive hybrid population management strategy using memory, local search, and random strategies. The main idea is that according to the change severity, the number of memory and random solutions can be tuned when facing changing environments. Jiang and Yang [14] used a steady-state manner to respond to changes. The main feature of this method is that when a change occurs, a portion of recorded outdated solutions with good distribution are reused based on the information collected from previous environments. The memory-based algorithms may perform effectively in problems with periodical changing environments.

Multipopulation-based algorithms use several subpopulations to explore different regions in the feasible space for diversity maintenance [3]. This type of algorithm performs effectively in problems with multipeak problems. Goh and Tan [10] introduced multipopulation strategies to tackle changes in multiobjective dynamic environments and observed good performance.

Prediction-based algorithms refer to the reuse of information collected from previous environments and POS/POF prediction for future environments. Compared with other algorithms mentioned before, prediction-based algorithms can accommodate the changes in advance, which may be the reason for popularity in DMOEAs. For example, in [22], Kalman filter is combined with evolutionary algorithms to solve DMOPs. Population prediction strategy (PPS) proposed by Zhou et al. [34] is used to predict the whole population. The univariate auto-regression (AR) model was used to predict the next locations of the centroid and manifold of the whole population based on the information of previous environments. In [19], [24], and [35], other prediction techniques were proposed by combining some special points obtained from previous environments, such as knee points, center points, and boundary points, with certain search methods so as to predict the new POS/POF accurately.

## C. Multiobjective Optimization Algorithms

MOEAs are an important part or the core of solving MOPs. Technically, any existing MOEAs can be directly applied to evolve the population for the period that the environment stays unchanged. Existing DMOEAs show promising performance in solving different problems, but most of them are designed by considering different machine learning models [22], [34]. The internal properties of decision variables are usually neglected, which will affect the accuracy and quality of discovered solutions. Motivated by this, this paper proposes three strategies that take the distribution and classification of variables into account to generate high-quality populations for new environments. The proposed PBDMO algorithm is described in detail below.

## III. PROPOSED PBDMO ALGORITHM

The basic framework of the PBDMO algorithm is presented in Algorithm 2. As shown, the proposed algorithm consists of

[^0]```
Algorithm 2 Overall Framework of PBDMO
    Initialize parameter settings for the algorithm;
    Initialize and evaluate population \(\left(\right.\) Pop \(_{0}\) ) and set Iter: \(=0\);
    while the termination criterion is not met do
        if change detected then
        Generate the first sub-population \(\left(\right.\) SubPop \(\left._{1}\right)\) resulting from
        predicting a new non-dominated set;
        Generate the second sub-population \(\left(\right.\) SubPop \(\left._{2}\right)\) by the
        proposed sampling strategy;
        Generate the third sub-population \(\left(\right.\) SubPop \(\left._{3}\right)\) according to
        Algorithm 5;
        Merge these sub-populations MixPop: \(=\operatorname{SubPop}_{1} \cup$
        SubPop \(\left._{2} \cup \operatorname{SubPop}_{3}\right\);
        Obtain a population from MixPop by non-dominated
        sorting;
        else
            Optimize the population using RM-MEDA;
        end if
        Iter \(=\) Iter +1
    end while
```

three key strategies to obtain a new population in response to changes. The main idea of this algorithm is to use history information, variable relationship, and variable probability distribution to generate a population that approximates the new POS/POF as much as possible. Like other predicted algorithms, our hypothesis is that there is sort of similarity between two consecutive changes. These strategies are described as follows.

## A. Predicting the Nondominated Set

From the statistical point of view, the geometric center is an important characteristic and can be used to represent the changing trend of population to some extent. Here, we compute the moving direction of the center point of the last two consecutive populations and use it to predict the position of the nondominated members of current population in the new environment.

Suppose that $\mathrm{Pc}_{t}$ is the centroid of population $\left(\mathrm{Pop}_{t}\right)$ and $\mathrm{Pos}_{t}$ is the nondominated set of $\mathrm{Pop}_{t}$ at the time $t . \mathrm{Pc}_{t}$ can be calculated as follows:

$$
\mathrm{Pc}_{t}=\frac{\sum_{x_{i} \in \mathrm{Pop}_{t}} x_{i}}{\left|\mathrm{Pop}_{t}\right|}
$$

where $\left|\mathrm{Pop}_{t}\right|$ is the population size, $x_{t}=\left(x_{t}^{1}, x_{t}^{2}, \ldots, x_{t}^{D}\right)$ denotes the decision vector of a solution at time $t$. The moving direction $\left(\operatorname{Dir}_{t}\right)$ of the center point at time $t$ is calculated by

$$
\operatorname{Dir}_{t}=\mathrm{Pc}_{t}-\mathrm{Pc}_{t-1}
$$

Then, the new position of members in $\mathrm{Pos}_{t}$ at time $t+1$ can be obtained by $\mathrm{Dir}_{t}$ and $\mathrm{Pos}_{t}$ according to the following formula:

$$
\mathrm{Pos}_{t+1}=\mathrm{Pos}_{t}+\mathrm{Dir}_{t} \times r s
$$

where $r s$ refers to the moving step-size along the moving direction $\mathrm{Dir}_{t}$. Here, three different values of $r s$ (i.e., $0.5,1.0$, and 1.5) can be used, which represents a small, medium, and large movement of $\mathrm{Pos}_{t}$, respectively. Fig. 1 illustrates the prediction process.

As shown in Fig. 1, $\mathrm{Pc}_{t}$ and $\mathrm{Pc}_{t-1}$ (black points) are utilized to obtain $\mathrm{Dir}_{t} . \mathrm{Pos}_{t}$ moves to three different regions described


[^0]:    Authorized licensed use limited to: Univ Politecnica de Madrid. Downloaded on March 08,2025 at 18:57:53 UTC from IEEE Xplore. Restrictions apply.

## Algorithm 3 Predicting the Nondominated Set

1: Retrieve the populations $\operatorname{Pop}_{t}$ and $\operatorname{Pop}_{t-1}$ at time $t$ and $t-1$, respectively;
2: Calculate the population centers according to Eq. (2);
3: Predict the moving direction according to Eq. (3);
4: Generate three sub-populations $\operatorname{Pos}_{t+1}^{1}, \operatorname{Pos}_{t+1}^{2}$ and $\operatorname{Pos}_{t+1}^{3}$ using Eq. (4) with different $r s$ values;
5: Save the sub-populations to SubPop ${ }_{1}$.
![img-0.jpeg](img-0.jpeg)

Fig. 1. Illustration of predicting nondominated solutions.
by $\operatorname{Pos}_{t+1}^{1}, \operatorname{Pos}_{t+1}^{2}$, and $\operatorname{Pos}_{t+1}^{3}$ using the suggested $r s$ values. A combination of these three solution predictions is more likely to approximate the true POS of the population ( $\operatorname{Pos}_{t+1}^{\text {true }}$ ) at time $t+1$. Algorithm 3 provides the implementation of this prediction strategy.

However, two questions arise here-how many step-sizes and how big the step-sizes should be used. The three step-sizes and their values $(0.5,1.0$, and 1.5$)$ are used due to two reasons. First, the three step-sizes classify possible changes into three levels, which is a common practice in fuzzy systems [23]. Here, $r s=1$ suggests the use of the same step-size as for the previous environment, meaning that the change is similar to the previous change (medium changes). $r s=0.5$ and $r s=1.5$ mean small and large changes, respectively, and they are chosen not only for simplicity but also by sensitivity analysis as will be detailed later. It is also possible to use much smaller or bigger values for $r s$ to represent small or large changes, but this would betray our assumption that there exists similarities between two consecutive changes. Second, three levels of changes are considered for the sake of computational efficiency, although we recognize that the prediction can be improved with more detailed classification. The three step sizes allow to predict a possible range of the new POS and increase the probability of finding new solutions. Sensitivity analysis of these $r s$ values can be found later in Section V.

## B. Novel Sampling Strategy

Introducing some sampling points from the search space into the new population can potentially increase the population diversity [10], [14]. However, the contribution of sampling points to convergence is often uncertain. Here, we
![img-1.jpeg](img-1.jpeg)

Fig. 2. Illustration of the sampling strategy in the 2-D space.
develop a novel sampling strategy that potentially enhances the convergence in addition to diversity.

To aid effective sampling, the decision vector is divided into two subvectors: 1) the principal and 2) nonprincipal variables. Nonprincipal variables can be assumed to depend on principal ones. The assumption holds to some degree as, from the mathematical point of view, objective functions present the dependency between them even if there is no dependency between variables.

The determination of principal variables is not difficult. To ease the task, we just need to identify the most principal variable and regard the others as nonprincipal variables. The identification uses a very simple approach, that is, the most principal variable is the one having the largest standard deviation (the first encountered is chosen if there is a tie) in the nondominated set. Let $x_{d}$ be the identified most principal variable, $N_{1}$ evenly spaced points are sampled for $x_{d}$. For any nonprincipal variable $x_{k}(k \in\{1, \ldots, D\} \backslash\{d\})$, $N_{2}$ sampling points are obtained by

$$
h x_{k}^{i}=L_{k}+i \times \frac{U_{k}-L_{k}}{N_{2}},\left(i=1, \ldots, N_{2}\right)
$$

where $L_{k}$ and $U_{k}$ are the lower and upper bounds of $x_{k}$, respectively. This results in a total of $N_{1} \times N_{2}$ sampling points $\tilde{x}=\left(x_{d}^{i}, h x_{k}^{i}\right)$, for $i=1, \ldots, N_{1}$ and $j=1, \ldots, N_{2}$.

After that, all the sampled points are evaluated and nondominated solutions are identified by nondominated sorting. These nondominated solutions form the second subpopulation in response to the environmental change. Fig. 2 illustrates the proposed sampling strategy in the 2-D space, where four points are uniformly sampled from the principal variable $x_{1}$, nine points from the nonprincipal variable $x_{2}$, and nondominated points are marked in red. Algorithm 4 shows the steps of creating a subpopulation by the proposed sampling strategy.

The setting of $N_{1}$ and $N_{2}$ is problem-specific. For example, it is expected to use a large number of sampling points for problems with a large number of variables and a small number of sampling points for problems with a few variables. Setting large values for them should help generate high-quality subpopulation but would lead to high-computational costs. Therefore, for simplicity, $N_{2}$ is recommended to couple with the number of variables, e.g., $N_{2}=D$, and $N_{1}$ is set to a

## Algorithm 4 Sampling Strategy

1: Sample uniformly points for the first variable according to Eq. (5);
2: For each sampled value of the first variable, generate a set of uniformly distributed points of the other variables according to Eq. (5);
3: Evaluate these solutions and select the non-dominated solutions using non-dominated sorting;
4: Save the non-dominated solutions to SubPop 2 .
![img-2.jpeg](img-2.jpeg)

Fig. 3. Example of variable distribution and predicted variable bounds.
value such that the total number of sampling points generated from this strategy is less than half of the population, i.e., $N_{1} N_{2}=N_{1} D \leq N / 2$.

## C. Shrinking Strategy

The chance of generating high-quality solutions improves if we can estimate to some extent where the optimal solutions probably reside. Here, we propose a shrinking strategy to refine the likely optimal range of variables, which is essentially a reduction of the decision space, based on the probability distribution of variables. The strategy is mainly applied to nonprincipal variables mentioned in Section III-B as the optimal range of principal variables is highly uncertain and an inaccurate shrinkage may generate more negative impact on principal variables than on nonprincipal variables. The range shrinking strategy works for a given nonprincipal variable $x_{i}$ as follows. First, the maximum probable value of $x_{i}$ at time $t$, denoted $D v_{t}$, is calculated using the probability estimation strategy [17] on the corresponding nondominated set. Second, the maximum probable value of $x_{i}$ for a new environment $D v_{t+1}$ at time $t+1$ can be predicted by using the last two consecutive $D v_{t-1}$ and $D v_{t}$ as follows:

$$
D v_{t+1}=D v_{t}+\left(D v_{t}-D v_{t-1}\right)
$$

Then, the upper bound of $x_{i}$ at time $t+1$ is estimated as

$$
D v_{t+1}^{u}=D v_{t+1}+\left(D v_{t+1}-D v_{t}\right)
$$

For simplicity, the lower bound of $x_{i}$, denoted $D v_{t+1}^{l}$, at time $t+1$ is made identical to $D v_{t}$. Fig. 3 illustrates the construction of a shrank range for nonprincipal variable $x_{2}$. At the end, the estimated range of $x_{i}$ for the new environment is $\left[D v_{t+1}^{l}, D v_{t+1}^{u}\right]$. Combining the estimated range for all nonprincipal variables and the original range of the

## Algorithm 5 Shrinking Strategy

1: Find the populations $\left(\right.$ Pop $_{t}$ and $\left.P o p_{t-1}\right)$ at time $t$ and $t-1$, respectively;
2: Compute the maximum probable value for each non-principal variable $x_{i}$ at time $t-1$ and $t$ using the probability density estimation strategy [17];
3: Estimate the new maximum probable value for each $x_{i}$ at time $t+1$ by Eq. (6);
4: Calculate the bounds of $x_{i}$ by Eq. (7);
5: Create a sub-population SubPop ${ }_{3}$ by sampling from the shrank decision space.
principal variable, we have a shrank decision space $\Omega=$ $\left[L_{1}, U_{1}\right] \cup \prod_{i=2}^{D}\left[D v_{t+1}^{l}, D v_{t+1}^{u}\right] \subset R^{D}$, from which another subpopulation (SubPop ${ }_{3}$ ) of solutions will be uniformly sampled. The implementation of this strategy is shown in Algorithm 5.

## IV. EXPERIMENTAL STUDY

## A. Test Instances

The performance of the proposed approach is examined on a recently proposed DF test suite [15], which has nine bi-objective and five tri-objective benchmark functions with diverse properties, such as variable linkage, disconnectivity, irregular POF shapes, and time-dependent geometries. The DF test suite consists of functions taken from other test suites, e.g., FDA [8], dMOP [10], ZJZ [33], and JY [13]. The time instance $t$ used in the test suite is given as $t=\left(1 / n_{t}\right)\left\lfloor\left(\tau / \tau_{t}\right)\right\rfloor$, where $n_{t}$, $\tau$, and $\tau_{t}$ are the severity of change, the number of iterations, and the frequency of change, respectively. The dimension $(D)$ of benchmark functions is set to 10 . The definition of these test instances can be found in [15].

## B. Performance Indicators

Performance indicators play an important role in assessing the performance of algorithms. In this paper, we adopts the following three performance indicators.

1) Mean Inverted Generational Distance: The mean inverted generational distance (MIGD), a widely adopted measure [30], [32], [34], is mainly employed to measure the convergence and diversity of solutions obtained by an algorithm. Suppose that $\mathrm{POF}_{t}^{*}$ is a set of uniformly distributed solutions in the true POF and $\mathrm{POF}_{t}^{o b}$ is a POF approximation, at time $t$, IGD can be calculated as

$$
\operatorname{IGD}\left(\mathrm{POF}_{t}^{*}, \mathrm{POF}_{t}^{o b}\right)=\frac{\sum_{g \in \mathrm{POF}_{t}^{*}} d\left(g, \mathrm{POF}_{t}^{o b}\right)}{\left|\mathrm{POF}_{t}^{*}\right|}
$$

where $d\left(g, \mathrm{POF}_{t}^{o b}\right)$ refers to the minimum Euclidian distance between $g$ and the points in $\mathrm{POF}_{t}^{o b}$, and $\left|\mathrm{POF}_{t}^{*}\right|$ is the number of solutions in $\mathrm{POF}_{t}^{*}$. Then, the MIGD can be computed as

$$
\mathrm{MIGD}=\frac{\sum_{t \in T} \mathrm{IGD}\left(\mathrm{POF}_{t}^{*}, \mathrm{POF}_{t}^{o b}\right)}{|T|}
$$

where $T$ is a set of discrete time points and $|T|$ is the total number of changes in a run.

2) Mean Schott's Spacing Metric: The Schott's spacing (SP) metric [10], [21], [25] aims to evaluate the distribution of $\mathrm{POF}_{t}^{o b}$. The following gives the expression formula:

$$
\mathrm{SP}\left(\mathrm{POF}_{t}^{o b}\right)=\sqrt{\frac{1}{\left|\mathrm{POF}_{t}^{o b}\right|-1}\left(\sum_{i=1}^{\left|\mathrm{POF}_{t}^{o b}\right|}\left(D_{i}-\bar{D}\right)\right)}
$$

where $D_{i}$ is the Euclidean distance between the $i$ th point in $\mathrm{POF}_{t}^{o b}$ and its nearest point in $\mathrm{POF}_{t}^{o b} . \bar{D}$ represents the average value of $D_{i}$. The mean Schott's spacing metric (MSP) can be defined as follows:

$$
\mathrm{MSP}=\frac{\sum_{t \in T} \mathrm{SP}\left(\mathrm{POF}_{t}^{o b}\right)}{|T|}
$$

3) Hypervolume Metric: Hypervolume (HV) [34] is a widely used indicator in multiobjective optimization. The calculation of HV requires a reference point, which is usually defined as a vector dominated by any points in the true POF. A larger HV value indicates a better approximation. HV is defined as follows:

$$
\mathrm{HV}_{t}=\mathrm{HV}\left(\mathrm{POF}_{t}^{o b}\right)
$$

where $\mathrm{HV}\left(\mathrm{POF}_{t}^{o b}\right)$ refers to the HV [27] of set $\mathrm{POF}_{t}^{o b}$. The reference point for the computation of HV is $\left(z_{j}+0.5, j=\right.$ $1, \ldots, m)$, where $z_{j}$ is the maximum value of the $j$ th objective of true POF. The mean HV (MHV) can be calculated as follows:

$$
\mathrm{MHV}=\frac{\sum_{t \in T} \mathrm{HV}_{t}}{|T|}
$$

## C. Compared Algorithms

In order to validate the performance of our proposed method, several existing approaches are selected as the comparison algorithms. A brief description of these algorithms and their parameter settings is given as follows.

1) Population Prediction Strategy (PPS): The main idea of PPS is dividing the optimal solutions into two parts: 1) population center and 2) manifold. An AR model is adopted to predict the next population center based on a time series of history population centers. Similarly, history manifolds are also used to predict the new manifold. Then, a new population will be generated based on the predicted population center and manifold [34].
2) Dynamic Version of NSGA-II (DNSGA-II): DNSGA-II is a dynamic version of NSGA-II by making some changes to the original NSGA-II. Two versions are available: 1) NSGA-II-A and 2) NSGA-II-B. The former is formed by replacing a small portion of the population with random solutions, and it is suitable for solving dynamic problems with severe changes. The latter is similar to the former except that the replacement uses mutated solutions of existing individuals, and works well in solving problems with small changes. Both of them are used in this paper [7].
3) First-Order Difference Model-Based MOEA/D: Firstorder difference model-based MOEA/D (MOEA/D-FD) [5] utilizes history information to predict the location of the new POS after a change is detected. The new population is composed of two kinds of solutions: 1) the old solutions and 2) the predicted ones. The movement of population centroid defines a predicted direction. To make the new population diversified, evenly distributed individuals selected from the previous population are used in the prediction.

## D. Parameter Settings

The parameters of the MOEAs considered in the experiment were referenced from their original papers. Some key parameters in these algorithms were set as follows.

1) Population Size: The population size $(N)$ in all the algorithms was set to 100 . Around 1000 points were uniformly sampled from the true POF for computing the performance metrics in both bi- and three-objective cases.
2) Other Parameters: All the parameters in the compared algorithms used the same settings as in their original studies.
a) Parameters in PBDMO: The second sampling strategy obtains $N_{1} N_{2}$ sampling points from $L_{1}+\{0.2,0.4,0.6,0.8\} *\left(U_{1}-L_{1}\right)$, and the size of SubPop ${ }_{3}$ was set to $0.3 N$.
3) Stopping Criterion and the Number of Executions: Each algorithm terminates after a prespecified number of generations and should cover all possible changes. To minimize the effect of static optimization, we gave 50 generations for each algorithm before the first change occurs. The total number of generations was set to $3 n_{t} \tau_{t}+50$, which ensures there are $3 n_{t}$ changes during the evolution. Additionally, each algorithm was executed 20 independent times on each test instance.
4) Change Detection: For all the algorithms, a maximum number of $10 \%$ population members are re-evaluated for change detection.

## E. Experimental Results

To study the impact of the change frequency on algorithms' ability in dynamic environments, the severity of change $\left(n_{t}\right)$ was fixed to 10 , and the frequency of change $\left(\tau_{t}\right)$ was set to 5 , 10 , and 20 , respectively. The statistical results are presented in Tables I-III, where the best values obtained by one of the five algorithms are highlighted in bold face.

Table I lists the MIGD values of all the algorithms. It can be seen that PBDMO obtains the best results on the majority of 14 test instances. For three functions, DF2, DF11, and DF12, the difference between PBDMO and the best method is very small. The considerably small IGD values of PBDMO suggest the POF approximations are close to the true POF, showing its excellent tracking ability. This demonstrates that the proposed prediction technique can generate good populations for varying environments. Even if there exist different levels of change severity, PBDMO can still achieve better performance than other algorithms in these test instances.

The MHV values for the algorithms are presented in Table II. One can see that the MHV results are highly consistent with the MIGD ones. PBDMO has significantly better

TABLE I
Mean and Standard Deviation Values of MIGD Obtained by Five Algorithms


MHV values than other algorithms in most of the problems, but it seems slightly inefficient on DF2, DF10, and DF11. DNSGA-II-B has a marginal advantage over the others on DF8 and DF13 with slow changes. Nevertheless, the MHV metric further indicates the ability of PBDMO to solve dynamic problems.

As indicated in Table III, PBDMO has the best solution distribution on three bi-objective problems, i.e., DF1, DF5, and DF7, but seems to have worse MSP values than the others in a majority of the test cases, although the difference is not significant. MOEA/D-FD is clearly the winner as it obtains the best MSP values in most cases. We wonder why MOEA/D-FD can obtain a good solution distribution where the others can not, and we postulate that this is mainly attributed to different distribution mechanisms used in these algorithms. MOEA/D-FD is a decomposition-based algorithm that converts a multiobjective problem into a number of single-objective subproblems. The weights used in aggregation functions are generated evenly, and it has been widely reported that the Tchebycheff approach is able to provide a good distribution of solutions. In contrast, the other MOEAs do not have this mechanism, and their environmental selection for solution

TABLE II
MeAn and Standard Deviation Values of MHV Obtained by Five Algorithms


distribution maintenance may not be able to generate solutions as well-organized as in MOEA/D. Keeping a well-organized set of solutions is particularly more difficult for these nondecomposition MOEAs in three-objective problems. Moreover, a good solution distribution does not necessarily guarantee a good approximation to the POF. While MOEA/D-FD wins on solution distribution, it loses to PBDMO on the other two measures, i.e., MIGD and MHV, which are more reliable to distinguish between algorithms in terms of the overall performance.

It can also be observed from the three measures that the frequency of change has a significant effect on algorithms' performance, and the effect decreases when environmental changes become slow. For three-objective problems, different changes cause these algorithms poor POF approximations, as indicated by their large MIGD and MHV values in Tables I and II, respectively. Overall, PBDMO seems less sensitive to the frequency of change, as can be seen from its gradual improvement on the three measures when $\tau_{i}$ increases from 5 to 20 . On the other hand, drastic changes with respect

TABLE III
MEAN AND STANDARD DEVIATION VALUES OF MSP Obtained by Five Algorithms


to the measures for DNSGA-II-A, DNSGA-II-B, PPS, and MOEA/D-FD are observed in most of the test instances with the variation of frequencies.

Apart from tabular presentation, we provide the evolution curves of the average IGD values for most of the test instances in Fig. 4. It can be clearly seen that, compared with other algorithms, PBDMO responds to changes more stably and recovers faster for most of the test problems, thereby obtaining higher convergence performance. The only exception is DF10, where PBDMO performs slightly worse for the first half of time points, but it is the best for the second half. On

DF8, the overall performance of PBDMO is better than the others, although no noticeable difference can be seen for some changes.

Another observation is that the IGD values for the algorithms fluctuate widely on most problems, such as DF1, DF7, DF13, and DF14. Despite that, PBDMO performs steadier compared with other algorithms. For a graphical view of these algorithms' tracking ability, we also plot their POF approximations for DF3, DF5, DF7, and DF8 in Fig. 5. It evidently shows that PBDMO is vary capable of tacking environmental changes, but may have convergence issues for boundary

![img-3.jpeg](img-3.jpeg)

Fig. 4. Mean IGD curves for different problems with $n_{t}=10$ and $r_{t}=10$.
TABLE IV
Performance Comparison of Different PBDMO Variants on HV


individuals. The less converged boundary solutions in PBDMO may affect the performance indicators.

Computational time for all the algorithms is reported in the supplementary material due to page limit. It is found that PBDMO requires longer computational time than all the other algorithms except PPS. This is acceptable given the fact PBDMO generally obtains better results as mentioned above.

## V. More Experimental Analysis

## A. Component Analysis

The proposed method has three key components. However, the role that each component plays in handling dynamics remains unclear. Here, we modify PBDMO to study each component separately. Specifically, a one-step-size prediction strategy replaces the three-step-size strategy in PBDMO for predicting the nondominated set. That is, a single step-size value $(r s=1)$ is used, and this variant is called PBDMOV1.

In other words, PBDMOV1 uses a very common prediction strategy similar to most existing prediction-based algorithms. A comparison between PBDMO and PBDMOV1 should illustrate the unique advantage of the three step-size strategy. The sampling strategy is switched off to study its importance to PBDMO, and this variant is named PBDMOV2. Similarly, we also deactivate the shrinking strategy to study the role it plays in PBDMO, resulting in another variant called PBDMOV3.

These three variants are all compared with the original PBDMO, and their MHV values are presented in Table IV. The corresponding MIGD and MSP values can be found in the supplementary material. The following details the influence of each component.

1) Predicting Nondominated Set: It is not difficult to see that PBDMO performs better than PBDMOV1 on bi-objective cases, but it is outperformed by PBDMOV1 on three-objective problems according the MIGD, MHV, and MSP values. The reason may be due to the fact that the three-step-size strategy

![img-4.jpeg](img-4.jpeg)

Fig. 5. POF approximations of five algorithms for different problems with $n_{t}=10$ and $\tau_{t}=10$.
in PBDMO would generate more boundary individuals than the one-step-size strategy in PBDMOV1. Boundary individuals are more likely to be nondominated solutions than intermediate individuals. Too much nondominated boundary solutions is not good for population diversity. Despite that, the three-step-size strategy brings more benefits than the one-step-size strategy for the majority of the problems.
2) Sampling Strategy: All three measures show that PBDMO performs significantly better than PBDMOV2 on almost all test cases, although PBDMOV2 has slightly better solution distribution on DF2, DF8, DF10, and DF12 than PBDMO as suggested by the MSP measure. Thus, the proposed sampling strategy clearly enhances the initial population for each new environment, and can efficiently improve the performance of the algorithm (see Figs. 2 and 3 in the supplementary material).
3) Shrinking Strategy: It can be observed from the results of the three indicators that PBDMO is better than PBDMOV3 in almost all the problems. This demonstrates the use of space shrinkage indeed helps improve the prediction of population for changing environments. This is not surprising because shrinking the decision space based on the probability distribution of variables improves the chance of creating promising solutions, which in return improves the quality of the initial population for each new environment.

The comparison between the three variants and the original PBDMO shows that each component is indispensable for the high performance of PBDMO. Removing any of them causes somewhat performance degradation in general. Thus, it is a good way to combine them in one algorithm, as done by PBDMO.

TABLE V
PBDMO With Different StEP-Size Values


## B. Influence of $r s$ Values

The three-step-size strategy for predicting nondominated set uses three different step-sizes, and they are set to ( $0.5,1$, and 1.5) in PBDMO. Here, we wonder whether other $r s$ values will enable PBDMO significantly better performance than ( $0.5,1$, and 1.5), particularly when changing the value for the small or large step-size. Thus, we carried out experiments on two groups of $r s$ settings. The first group (S) uses different values for the small step-size whereas the second group (L) has several values for the large step-size. The influence of the medium step-size is not investigated as we assume it is for moderate cases where two consecutive environmental changes are similar. A step-size of 1 is a very common setting for moderate cases in many prediction-based algorithms. Table V details these two groups of settings.

The experimental results are shown in Table VI for groups S and L. It is seen from the S group comparison that the optimal value for the small step-size is problem dependent: small values favor some problems while slightly large values favor others. A comparison between PBDMO and each S column of Table VI demonstrates that the setting ( $0.5,1$, and 1.5) helps PBDMO to win slightly more competitions. A similar observation can be made for the L group from Table VI. Thus, this experiment supports the decision made on choosing a step-size vector of ( $0.5,1$, and 1.5 ).

## C. Influence of Subpop ${ }_{3}$ Size

The size of Subpop ${ }_{3}$ is another important parameter that can affect the performance of PBDMO. So, it is varied with an increment of 0.1 from 0.1 to 0.5 times of the population size, to study its potential influences. Other parameters are kept the same as in the previous section. The results are given in Table VII. It is clear that no single optimal Subpop ${ }_{3}$ size exists for all the problems but instead the optimal Subpop ${ }_{3}$ sizes are quite divergent. While some problems (e.g., DF1) are not very sensitive to the size of Subpop ${ }_{3}$, other problems (e.g., DF2 and DF3) show widely fluctuated performance over the tested sizes and obtained the best performance when the size of Subpop ${ }_{3}$ is around $0.3 N$. It is also clear that although PBDMO with $0.3 N$ is not the best on some cases, it is very close to the best ones. Therefore, $0.3 N$ is the most preferred subpopulation size for Subpop ${ }_{3}$ in PBDMO.

## D. Influence of the Severity of Change $n_{t}$

To study whether different change severity levels bring significant influence to the performance of the algorithm, experiments were carried out with $\tau_{I}$ fixed to 10 , and $n_{I}$ set to 5,10 , and 20 . The simulation results can be found in the
supplementary material. We observe that all algorithms are sensitive to $n_{t}$. Although various $n_{t}$ bring different difficulties to the problem, the PBDMO can still obtain promising results with respective other compared algorithms. In total, PBDMO has more robust performance in solving problems with different changing levels.

## E. Comparison With State-of-the-Arts

A transfer learning-based DMOEA (TrDMOEA) has been recently developed and shown promising performance on DMOPs [49]. Here, we compare PBDMO with this state-of-the-art to demonstrate the effectiveness of the proposed strategies. Table VIII shows the MIGD values of the two algorithms for some selected problems, and more results can be found in the supplementary material. It is clear that PBDMO is more effective than TrDMOEA for DF problems, showing complex learning models do not necessarily guarantee high performance. Note that, PBDMO is also computationally cheaper than TrDMOEA.

## VI. DISCUSSION

We would like to have more discussion here about the advantages and limitations of the three components of the proposed PBDMO method. First, the three-step-size strategy for predicting nondominated solutions increases the population diversity, which allows the population to explore widely for the new environment and helps to improve the search performance of dynamic multiobjective algorithms. However, the improvement comes at the expense of complexity increase because it generates more solutions than an one-step-size strategy does. Besides, it is likely to generate too many near-boundary individuals, as shown in the experimental results, which may not be beneficial to global search if most of these near-boundary individuals are nondominated. Therefore, this strategy could be improved by controlling the number of near-boundary members effectively.

Second, the sampling technique generates solutions by classifying decision variables into two groups, which can be very helpful for generating well-distributed solutions in the population. The subpopulation from this strategy additionally has convergence advantages as the solutions have been filtered by nondominated sorting. This provides us a new way of efficient sampling in dynamic environments. However, the strategy heavily depends on the classification. This paper assumes there is a single most principal variable, and this assumption may not hold for generalization. The sampling strategy needs improvements on the classification and robustness when the principal variable is misidentified or there are many principal variables.

Third, the shrinking strategy aids efficient sampling, thereby improving the quality of the initial population for each new environment. However, it sometimes fails to work effectively, particularly when facing cases where two consecutive POSs has low similarities. This results in poor estimate of the range of nonprincipal variables. The failure has been observed for DF11 and DF12, for which the POS is very unpredictable. Therefore, further improvement should be made on this strategy to shrink the decision space more effectively.

TABLE VI
Performance Comparison of PBDMO Variants on MIGD FOR $\left(n_{I}, \tau_{I}\right)=(10,10)$


TABLE VII
Performance Comparison of PBDMO With Different Sizes of Subpop $\gamma$ on MIGD

TABLE VIII
Performance Comparison Between PBDMO and TrDMOEA For Selected Problems on MIGD

## VII. CONCLUSION

In this paper, a new dynamism handling algorithm, called PBDMO, is proposed for solving multiobjective problems with time-varying characteristics. This approach consists of three main components, that is, a three step-size strategy for predicting the nondominated set, a sampling strategy, and a shrinking strategy. These components are important for creating a good initial population, enhancing either diversity or convergence, when a change occurs in the environment.

A recent test suite of 14 benchmark functions with different characteristics is employed to assess the performance of our algorithm. The experimental comparisons indicate that the proposed method performs much better than the other algorithms considered in this paper on most of the test problems. This demonstrates PBDMO has a good tracking ability and responds fast to environmental changes. Besides, the role that each component of the proposed algorithm plays in handling dynamics is also investigated properly, showing that the combination of these components indeed is better than using each only.

Although PBDMO has shown a good tracking ability and search performance on the tested functions, there are still several relevant issues to be addressed in the future. For example, developing prediction strategies that can better deal with near boundary solutions is an important future work. It is also important to develop more efficient strategies that can adaptively classify principle and nonprincipal decision variables according to the characteristics of the problem being handled. How to improve the shrinking strategy in PBDMO is also an interesting future work.
