# A hybrid estimation of distribution algorithm for simulation-based scheduling in a stochastic permutation flowshop 

K. Wang ${ }^{\text {a, }}$, S.H. Choi ${ }^{\text {b }}$, H. Lu ${ }^{\text {c }}$<br>${ }^{a}$ Department of Management Science and Engineering, Economics and Management School, Wuhan University, Wuhan, China<br>${ }^{\text {b }}$ Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Pokfulam Road, Hong Kong<br>${ }^{c}$ Department of Logistics Management, School of Logistics Engineering, Wuhan University of Technology, Wuhan, China

## A R T I C L E I N F O

Article history:
Received 13 January 2015
Received in revised form 8 September 2015
Accepted 9 September 2015
Available online 16 September 2015

Keywords:
Permutation flowshop scheduling
Stochastic processing times
Estimation of distribution algorithm
Genetic algorithm
Meta-model

## A B S T R A C T

The permutation flowshop scheduling problem (PFSP) is NP-complete and tends to be more complicated when considering stochastic uncertainties in the real-world manufacturing environments. In this paper, a two-stage simulation-based hybrid estimation of distribution algorithm (TSSB-HEDA) is presented to schedule the permutation flowshop under stochastic processing times. To deal with processing time uncertainty, TSSB-HEDA evaluates candidate solutions using a novel two-stage simulation model (TSSM). This model first adopts the regression-based meta-modelling technique to determine a number of promising candidate solutions with less computation cost, and then uses a more accurate but timeconsuming simulator to evaluate the performance of these selected ones. In addition, to avoid getting trapped into premature convergence, TSSB-HEDA employs both the probabilistic model of EDA and genetic operators of genetic algorithm (GA) to generate the offspring individuals. Enlightened by the weight training process of neural networks, a self-adaptive learning mechanism (SALM) is employed to dynamically adjust the ratio of offspring individuals generated by the probabilistic model. Computational experiments on Taillard's benchmarks show that TSSB-HEDA is competitive in terms of both solution quality and computational performance.
(c) 2015 Elsevier Ltd. All rights reserved.

## 1. Introduction

The permutation flowshop scheduling problem (PFSP) is a wellknown and well-studied combinatorial optimisation problem (Gupta \& Stafford, 2000; Vallada \& Ruiz, 2009). In the classical PFSP, jobs arrive at the shop floor simultaneously and then follow the same processing order on each of the machines. The PFSP has been proven strongly NP-complete for more than two machines (Garey, Johnson, \& Sethi, 1976). Due to its great significance in both academic and real-world applications, the PFSP has attracted considerable attention after the pioneering work of Johnson (1954).

Although a tremendous amount of effort has been devoted to addressing the PFSP, most of the research works consider a static environment, in which no unexpected events would occur to disturb job processing. Real-world manufacturing environments, however, tend to suffer a variety of uncertainties, including change of processing time, machine breakdown, rush orders, and job cancellations, etc. (Gholami, Zandieh, \& Alem-Tabriz, 2009; Ouelhadj \&

[^0]Petrovic, 2009). Therefore, permutation flowshop scheduling under uncertainties has recently received an increasing attention.

Three types of approaches, namely exact algorithms, heuristics, and meta-heuristics, are commonly adopted to solve the PFSPs in the literature (Ruiz \& Maroto, 2005; Xu, Yin, Cheng, Wu, \& Gu, 2014). Exact algorithms aim to achieve the optimal solution, and hence are computationally expensive for large-sized PFSPs. Examples of such methods are branch and bound approaches (Chung, Flynn, \& Kirca, 2002). In addition to exact algorithms, heuristics and meta-heuristics have also been introduced to find approximate solutions within reasonable computational cost. Since most existing heuristic methods, such as constructive heuristics and improvement heuristics, tend to perform poorly on large-sized PFSPs (Ceberio, Irurozki, Mendiburu, \& Lozano, 2014), a wide range of meta-heuristics have been applied to address the PFSPs (Zobolas, Tarantilis, \& Ioannou, 2009).

To deal with uncertainties in a flowshop, the simulation-based meta-heuristics (SBM) have been successfully developed to construct and evaluate candidate solutions. In these approaches, a discrete-event simulator is usually incorporated into a metaheuristic (Wang, Choi, Qin, \& Huang, 2013), such as genetic algorithm (GA) (Dugardin, Yalaoui, \& Amodeo, 2010), immune


[^0]:    * Corresponding author. Tel.: +86 2768753063.

    E-mail addresses: kai.wang@whu.edu.cn (K. Wang), shchoi@hku.hk (S.H. Choi), lehaili@whut.edu.cn (H. Lu).

algorithm (Zandieh \& Gholami, 2009), ant colony optimisation (ACO) algorithm (Ahmadizar, Ghazanfari, \& Ghomi, 2010), and hybrid meta-heuristics (Safari \& Sadjadi, 2011). As an iterative procedure, the meta-heuristic guides its subordinate heuristics to iteratively produce high-quality candidate solutions until a termination criterion is met. In the SBM, the performance of candidate solutions is estimated over iterations using the discrete-event simulator. Accordingly, the computation time of such an evaluation process inevitably greatly increases with the growth of the number of candidate solutions or simulation replications. The main disadvantage of SBM technique therefore lies in the large computation time required for performance evaluation under uncertainties (Dugardin et al., 2010).

To overcome such drawback, some effective approaches have recently been proposed for scheduling under uncertainties. Instead of estimating the performance of all candidate solutions, these approaches only evaluate a number of promising candidate solutions by a time-consuming simulator. Zhang, Song, and Wu (2012) developed a hybrid particle swarm optimisation (PSO) algorithm for stochastic job shop scheduling problems. They first adopted the lower bound of the objective value to give a quick performance evaluation on candidate solutions, and then only the ones in the satisfactory regions were further estimated using a discrete-event simulator. Moreover, to determine the promising candidate solutions for further optimisation under uncertainties, both Horng, Lin, and Yang (2012) and Juan, Barrios, Vallada, Riera, and Jorba (2014) applied the stochastic simulation model with less simulation replications for performance evaluation.

Despite an increasing amount of research interest in developing new SBMs, few research works have been reported on improving their computational performance for scheduling problems under uncertainties.

This paper therefore presents an effective SBM to address the PFSPs under stochastic processing times. Enlightened by the works of Zhang et al. (2012), Horng et al. (2012), and Juan et al. (2014), we incorporate an efficient two-stage simulation-based model into a hybrid estimation of distribution algorithm (EDA) to generate good-quality schedules with less computational effort.

The EDA was first introduced by MÃ¼hlenbein and Paass (1996) as an alternative to conventional evolutionary algorithms (EA). Different from conventional EAs, EDA adopts a probabilistic model to generate the offspring. This model is established by learning from an elite set of individuals in the previous population. As an effective method to inherit good genes over generations, EDA has recently been successfully used to a wide range of combinatorial optimisation problems (Hauschild \& Pelikan, 2011), such as the PFSP and its variants. Jarboui, Eddaly, and Siarry (2009) presented an efficient EDA to solve the PFSP with total flow time minimisation. For the same scheduling problem, Zhang and Li (2011) improved the EDA efficiency by incorporating the longest common subsequence into the probabilistic model. Wang, Wang, Liu, and Xu (2013) developed an effective EDA to minimise the makespan of the distributed permutation flowshop. More recently, Ceberio et al. (2014) introduced a probabilistic distance-based ranking exponential model, named the Mallows model, to construct EDA solutions. To further investigate the performance of EDA for the PFSP, hybridisation of EDA with other meta-heuristics has also been studied. Liu, Gao, and Pan (2011) hybridised EDA with PSO to allow social information sharing among candidate solutions. Moreover, Tzeng, Chen, and Chen (2012) incorporated the idea of ant colony system (ACS) into EDA to schedule a permutation flowshop.

The proposed two-stage simulation-based hybrid EDA (TSSB-HEDA) differentiates itself from the conventional EDA by
two mechanisms, namely a two-stage simulation model (TSSM) and a self-adaptive learning mechanism (SALM). To reduce the computation cost of TSSB-HEDA, TSSM first employs a regressionbased meta-model to provide a rough estimation of candidate solutions, and only a number of promising ones are identified and further evaluated using a discrete-event simulator. Moreover, to prevent EDA from early search stagnation, TSSB-HEDA employs both the probabilistic model of EDA and genetic operators of GA to produce offspring individuals. Motivated by the idea of neural network training, SALM dynamically adjusts the ratio of offspring generated by the probabilistic model to avoid being trapped into premature convergence. An extensive search of literature on PFSP suggests that not much research effort has been devoted to applying EDA to schedule the permutation flowshop under uncertainties.

The rest of the paper is organised as follows. Section 2 presents the mathematical formulation of PFSP. Section 3 describes the proposed TSSB-HEDA in details. To validate the performance of TSSB-HEDA under stochastic processing times, simulations are conducted and the computation results are analysed in Section 4. Finally, in Section 5, we conclude the paper and discuss some topics for future research.

## 2. Problem description

The PFSP is a well-known combinatorial optimisation problem. In the classical PFSP, a finite set $j=\{1,2, \ldots, n\}$ of n jobs are firstly released simultaneously to the shop floor, and then are processed on a finite set $M=\left\{m_{1}, m_{2}, \ldots, m_{m}\right\}$ of m machines with no preemption allowed. Each job $j, j \in J$, consists of m operations that have to be processed on the machines in the order of $m_{1}, m_{2}, \ldots$, $m_{m}$. All the jobs have deterministic processing times and follow the same processing order on each machine.

In the real-world manufacturing environments, however, a variety of unexpected events, such as tool wear, equipment failure, operator unavailability, and quality issues, may lead to uncertain processing times (Lawrence \& Sewell, 1997). This paper describes the processing time uncertainty using the level of processing time variation (LPTV), which is described as follows:
$L P T V=\sigma / E(P)$
where $E(P)$ and $\sigma$ indicate the expected value and the standard deviation of processing time, respectively. According to formula (1), a larger LPTV may result in a large deviation between the expected and the actual processing times. For example, suppose $E[P]$ of a job equals 15 time units, LPTV values of 0.2 and 0.4 lead the standard deviation of actual processing time from $E[P]$ to be 3 and 6 times units respectively.

The objective of PFSP in this study is to determine a feasible permutation $\pi$ to minimise the makespan, i.e. the maximum completion time of all operations. With consideration of processing time uncertainty, we formulate the PFSP as follows:
$\min \left\{E\left[C\left(\pi_{n}, m\right)\right]\right\}$
Subject to the following constraints:
$C\left(\pi_{1}, 1\right)=S P\left(\pi_{1}, 1\right)$
$C\left(\pi_{j}, 1\right)=C\left(\pi_{j-1}, 1\right)+S P\left(\pi_{j}, 1\right), \quad j=2, \ldots, n$
$C\left(\pi_{1}, i\right)=C\left(\pi_{1}, i-1\right)+S P\left(\pi_{1}, i\right), \quad i=2, \ldots, m$
$C\left(\pi_{j}, i\right)=\max \left\{C\left(\pi_{j-1}, i\right), C\left(\pi_{j}, i-1\right)\right\}+S P\left(\pi_{j}, i\right)$,
$i=2, \ldots, m ; j=2, \ldots, n$

where
$i$ : machine index, $1 \leqslant i \leqslant m$
$j$ : job index, $1 \leqslant j \leqslant n$
$\pi_{j}: j$ th job in permutation $\pi=\left\{\pi_{1}, \ldots, \pi_{n}\right\}, 1 \leqslant j \leqslant n$
$C\left(\pi_{j}, i\right)$ : completion time of Job $\pi_{j}$ on machine $i$
$S P\left(\pi_{j}, i\right)$ : stochastic processing time of Job $\pi_{j}$ on machine $i$.

## 3. Details of the proposed two-stage simulation-based hybrid EDA (TSSB-HEDA)

### 3.1. The framework of TSSB-HEDA

As a relatively new paradigm of EAs, EDA reproduces the offspring from a probabilistic model, rather than crossover and mutation operators used in traditional GAs. The probabilistic model describes statistical information of elite individuals from previous generations, and therefore is capable of predicting the most promising search area. As an iterative procedure, EDA includes the following steps (Pan \& Ruiz, 2012): (1) Randomly generate an initial population; (2) Choose some good individuals to construct the elite set; (3) Establish the probabilistic model from the elite set; (4) Generate new individuals from the estimated probabilistic model; and (5) Steps 2-4 are repeated until a stopping criterion is satisfied.

Since new populations are generated entirely from the probabilistic model, EDA may not generate diversified individuals. It tends to trap into premature convergence after some generations (Chen, Chen, Chang, Zhang, \& Chen, 2010). Incorporation of metaheuristics, particularly GA, might be an effective approach to avoiding premature convergence. Although the genetic operators of GA, such as crossover and mutation, can provide the population diversity by perturbing the good solution structure, few studies on the integration of GA with EDA have been reported. Some existing hybrid frameworks mainly include ACGA (Chang, Hsieh, Chen, Lin, \& Huang, 2009) and eACGA (Chen, Chen, Chang, \& Chen, 2012). In these hybrid approaches, the probabilistic model of EDA and genetic operators of GA are alternated to produce the offspring
![img-0.jpeg](img-0.jpeg)

Fig. 1. The framework of TSSB-HEDA.
over a predefined number of generations. No adaptive strategy is adopted to guide the process of population generation.

Fig. 1 illustrates the framework of the proposed TSSB-HEDA, which is differentiated from the conventional EDA by the twostage simulation model (TSSM) and hybridisation of EDA and GA. To provide an efficient method for performance evaluation, TSSBHEDA incorporates TSSM into EDA to estimate the performance of offspring individuals under stochastic processing times. Furthermore, to preserve the population diversity, both the probabilistic model of EDA and genetic operators of GA are applied to create new individuals in this study. Enlightened by the weight training process of neural networks, the EDA participation ratio $R_{\text {EDA }}$, indicating the ratio of individuals generated by the probabilistic model, is dynamically adjusted by a self-adaptive learning mechanism (SALM). The rest of Section 3 first provides a detailed explanation of TSSM and the hybrid EDA with genetic operators, and subsequently follows the complete procedure of TSSB-HEDA.

### 3.2. The Two-stage simulation model (TSSM) under stochastic processing times

TSSB-HEDA applies the TSSM to reduce the computation cost of performance evaluation considering processing time uncertainty. In the first stage, a regressing-based meta-model is applied to estimate the performance of candidate solutions, so that a number of promising ones can be quickly determined. From these selected solutions, a discrete-event simulator is then used in the second stage to obtain a more accurate evaluation.

### 3.2.1. Stage I: using the regression-based meta-model for performance evaluation

In the real-world manufacturing systems, processing time uncertainty may advance or postpone job processing, and in turn lead to deviations between the planned and the actual schedules. The effect of schedule deviations, if not be properly compensated by the slack or idle time on the machines, could eventually degrade schedule performance (Saad, 2003; Wang \& Choi, 2014). Accordingly, less slack or idle time on the machines may result in significant degradation of schedule performance. Moreover, the configuration of permutation flowshop systems, including the number of jobs to be processed, the number of machines, and LPTVs of machines may influence the performance degradation of the planned schedule. To estimate the schedule performance in a realistic permutation flowshop, there is therefore a need to develop an effective method to predict the performance degradation of planned schedules.

Simulation modelling and analysis on manufacturing systems are often complicated, time-consuming, and challenging. Due to the robust and fast decision support in the decision-making process, meta-modelling techniques, including regression and neural network models, have been widely applied to predict the simulation results in real-world manufacturing environments. Instead of an actual simulation model, a meta-model approximates a functional relationship between simulation input parameters and system responses (Vinod \& Sridharan, 2011; Yu \& Popplewell, 1994). Since regression analysis is one of the commonly used methods for finding such functional relationship, it has been applied to establish the meta-model to evaluate the schedule performance in this study.

To obtain a number of promising candidate solutions, the multiple linear regression meta-model is firstly applied to estimate the degradation of schedule performance (DSP) with processing time uncertainty. The makespan of the actual schedule, i.e. $M_{A S}$, is then computed as follows:
$M_{A S}=M_{P S} \times D S P$

where $M_{P S}$ represents the makespan of the planned schedule. Based on $M_{A S}$, the promising candidate solutions can be easily identified.

The DSP of a planned schedule may be affected by machine size, job size, LPTV, and the slack ratio (SR). The SR, describing the slack per processing time of a planned schedule, is measured by
$S R=\sum_{i=1}^{m} \sum_{j=1}^{n} S_{i j} / P_{i j}$
where $m$ denotes the number of machines, $n$ represents the number of jobs to be processed, $S_{i j}$ and $P_{i j}$ indicate the free slack and the processing time of job $j$ on machine $i$ respectively.

In the literature of scheduling under uncertainties, free slack is commonly applied to estimate the robustness of a given schedule (Xiong, Xing, \& Chen, 2013). It is therefore used in this study to define the SR. Different from idle time, free slack in a permutation flowshop is measured by the amount of time that an operation could be right-shifted without delaying its start on the next machine. The difference between free slack and idle time of a given schedule is depicted in Fig. 2.

To predict the DSP of a planned schedule, we adopt job size, machine size, LPTV, and SR as the independent variables, and the multiple linear regression meta-model is accordingly established as follows:
$D S P=\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\beta_{3} x_{3}+\beta_{4} x_{4}+\beta_{5} x_{1} x_{2}+\beta_{6} x_{1} x_{3}$

$$
+\beta_{7} x_{1} x_{4}+\beta_{8} x_{2} x_{3}+\beta_{9} x_{2} x_{4}+\beta_{10} x_{3} x_{4}+e
$$

where $x_{1}, x_{2}, x_{3}$, and $x_{4}$ represent job size, machine size, LPTV, and SR; $\beta_{0}$ is the constant; $\beta_{1}, \beta_{2}, \beta_{3}$, and $\beta_{4}$ denote the coefficients corresponding to job size, machine size, LPTV, and SR; $\beta_{5}, \beta_{6}, \ldots, \beta_{10}$ are the coefficients corresponding to the interaction effects between job size, machine size, LPTV, and SR; $e$ is the error.

The meta-model is often constructed in a three-step process (Hurrion \& Birgil, 1999; Vinod \& Sridharan, 2009). First, a factorial experimental design is conducted to obtain a set of simulation results. The meta-model is then established using either regression or neural network techniques. Finally, a validation test on the developed meta-model is conducted by comparing predicted results with simulation results. In this study, the simulation results under stochastic processing times (to be presented in Section 4.2) are used to build the meta-model shown in formula (9). After obtaining the multiple linear regression meta-model, the performance of candidate solutions can be roughly estimated according to formula (7), and accordingly the best $\alpha \times 100 \%(\alpha \in[0,1])$ ones can be chosen to establish a set of promising solutions $\Pi_{p}$ for further performance evaluation.

### 3.2.2. Stage II: using the discrete-event simulator for performance evaluation

In this stage, only the promising solutions $\Pi_{p}$ are further estimated using a discrete-event simulator. To model the manufacturing process in a permutation flowshop, processing time uncertainty is considered in this simulator, which is described below.
![img-2.jpeg](img-2.jpeg)
(a) Idle time in a schedule

Algorithm I: The discrete-event simulator
Step 1: Set the number of simulation replications $N_{\text {sim }}$ and counter $n=1$.
Step 2: Initialise the level of processing time variation $\left(\right.$ LPTV $\left._{k}\right)$ for each machine $M_{k}$.
Step 3: Allocate the jobs to machines according to the job sequence of a candidate solution.
Step 4: Following the processing route in a permutation flowshop (i.e. from the first machine to the last machine), the actual completion times of jobs on each machine $M_{k}$ are obtained as follows:
Step 4.1: Identify the first unprocessed job $j$ on machine $M_{k}$ and record its start time.
Step 4.2: Apply a truncated normal distribution (to be detailed in Section 4.1) to generate actual processing time of job j on machine $M_{k}$.
Step 4.3: Obtain the completion time of job $j$ on machine $M_{k}$ by summing its start time with its actual processing time.
Step 4.4: If all the jobs assigned to machine $M_{k}$ have been completed, record their completion times; otherwise, return to step 4.1.
Step 5: Record the simulated makespan under stochastic processing times as $M_{\text {sim }}^{n}$, i.e. the completion time of the last job on the last machine.
Step 6: If $n>N_{\text {sim }}$, return the average simulated makespan over $N_{\text {sim }}$ simulation replications as $M_{\text {avg }}=\sum_{n=1}^{N_{\text {avg }}} M_{\text {sim }}^{n} / N_{\text {sim }}$; otherwise, set $n=n+1$ and return to step 3.

Based on the above simulator, $M_{\text {avg }}$ is used to evaluate the candidate solutions of $\Pi_{p}$. To model the manufacturing process in a permutation flowshop, this simulator employs a large $N_{\text {sim }}=100$ for performance evaluation under stochastic processing times, inevitably resulting in a costly and time-consuming evaluation process.

### 3.3. The hybrid EDA with genetic operators

TSSB-HEDA employs both TSSM and genetic operators to address the PFSPs with processing time uncertainty. The details of TSSB-HEDA are described as follows.

### 3.3.1. Solution encoding and initial population

TSSB-HEDA applies the permutation-based encoding scheme to represent individual solutions. Such a method has been widely adopted for permutation flowshop scheduling during the past decades (Gao, Pan, \& Li, 2011; Li \& Pan, 2014; Wang, Pan, Suganthan, Wang, \& Wang, 2010). For example, as a solution to a PFSP with 4 jobs, job sequence $\{1,4,2,3\}$ shows that job 1 is first scheduled, then successively followed by job 4 , job 2 , and job 3 . To better
![img-2.jpeg](img-2.jpeg)
(b) Free slack in a schedule

cover the promising regions of the entire search space, TSSB-HEDA generates the initial population randomly.

### 3.3.2. Selection

The probabilistic model of EDA is established based on an elite set of individuals, which are selected from previous population using a selection operator. To reduce the computation time of performance evaluation under stochastic processing times, TSSM adopts a regression-based meta-model to determine some promising individuals, which are further estimated using a simulator, i.e. Algorithm I. Since different methods are used to estimate the individual fitness in TSSB-HEDA, it is not suitable to select good individuals from the population only depending on their fitness values. Therefore, a modified linear rank selection is employed to choose part of individuals with good performance under stochastic processing times.

The modified linear rank selection involves two steps: (1) the individuals are ranked in ascending order of the estimated fitness under stochastic processing times, which is the reciprocal of the objective function. Based on the regression-based meta-model, the worst $(1-\alpha) \times 100 \%(\alpha \in[0,1])$ individuals are first identified and sorted. Then, using Algorithm I, the rest $\alpha \times 100 \%(\alpha \in[0,1])$ individuals are evaluated and sorted; (2) the individuals are selected with the probability:
$P\left(x_{k}^{i}\right)=r_{k}^{i} / \sum_{x_{k}^{i} \in P_{k}} r_{k}^{i}$
where $P_{k}$ denotes the $k$ th population of TSSB-HEDA, $x_{k}^{i}$ and $r_{k}^{i}$ represent the $i$ th individual and its rank in population $P_{k}$ respectively. To produce the elite set for the probabilistic model construction, such selection process continues until $\beta \times 100 \%(\beta \in[0,1])$ individuals of current population have been chosen.

### 3.3.3. Probabilistic model

Instead of using genetic operators, the probabilistic model is applied in the conventional EDA to guide the exploration of the search space. It therefore affects the EDA performance substantially. To address the PFSP with total flow time minimisation, Jarboui et al. (2009) developed an effective probabilistic model with consideration of both job order in the sequence and similar job blocks of selected elite parents. In their proposed model, the probability for selecting job $j$ at position $k$, i.e. $\pi_{j k}$, is computed as follows:
$\pi_{j k}=\frac{\eta_{j k} \times \mu_{j(k-1)}}{\sum_{k \in D_{k}}\left(\eta_{j k} \times \mu_{j(k-1)}\right)}$
where $\eta_{j k}$ represents the number of times that job $j$ appears before or at position $k$ in the selected individuals augmented by a given constant $\delta_{1} ; \mu_{j(k-1)}$ denotes the number of times that job $j$ appears immediately after the job at position $k-1$ in the selected individuals augmented by a given constant $\delta_{2} ; D_{k}$ indicates the set of jobs that are not scheduled until position $k$.

Such a probabilistic modelling method has its own disadvantage when applied to solve the PFSP. According to the definition of $\mu_{j(k-1)}$, it equals zero when $k=1$, since no job can be positioned before job $j$ if it is selected as the first job to be processed. This may lead the probability of positioning any job at position 1 to be zero. Therefore, instead of being determined by the genetic information of the elite set, the first job in the sequence is randomly chosen. To overcome such drawback, we apply a new probabilistic model to determine $\pi_{j k}$ as
$\pi_{j k}= \begin{cases}\frac{\eta_{j k}}{\sum_{k \in D_{k}} \eta_{j k}}, & k=1 \\ \frac{\eta_{j k} \times \mu_{j(k-1)}}{\sum_{k \in D_{k}}\left(\eta_{j k} \times \mu_{j(k-1)}\right)}, & k=2,3, \ldots, n\end{cases}$
Based on formula (12), the job assigned to a specific position $k$ in the sequence can be determined by the probability of $\pi_{j k}$. For each generation, $R_{E D A} \times 100 \%\left(R_{E D A} \in[0,1]\right)$ offspring are generated by the probabilistic model.

### 3.3.4. Crossover and mutation

To prevent EDA from being trapped into premature convergence, genetic operators, namely crossover and mutation, are adopted to generate part of population. As the primary genetic operator, crossover guides the exploration of new promising regions in the search space. It usually produces the offspring by interchanging parts of their parents (genes) (Huang, Wang, Zhang, \& Pang, 2015). TSSB-HEDA applies the order crossover to generate the offspring, which is explained as follow: two parents are first divided into three parts by selecting two random cut points. Then the middle parts of two children are then directly inherited from their parents, and the remaining genes of child 1 are filled following the job order appeared in parent 2. Similarly, the remaining genes of child 2 are determined based on parent 1. An example of order crossover is illustrated in Fig. 3.

To preserve the population diversity, mutation changes one or more genes in a chromosome from its initial state (Choi \& Wang, 2012). TSSB-HEDA adopts the pairwise interchange mutation to swap two randomly selected jobs of the individual, as illustrated in Fig. 4.

For each generation of TSSB-HEDA, the order crossover is performed to generate $\left(1-R_{E D A}\right) \times 100 \%\left(R_{E D A} \in[0,1]\right)$ of new individuals, and each of them is mutated with rate $p_{m}$.

### 3.3.5. Self-adaptive learning mechanism

To improve the population diversity of EDA, both the probabilistic model of EDA and genetic operators of GA are adopted to produce the offspring. The proposed TSSB-HEDA applies a selfadaptive learning mechanism (SALM) to determine the EDA participation ratio, which indicates how many individuals of a population are produced by the probabilistic model. SALM is based on the weight training process of neural network, which has been adopted by Agarwal, Colak, and Eryarsoy (2006) to address the traditional flowshop scheduling problems. In their research work, a set of weights were used to construct solutions by perturbing the data of original scheduling problem. To iteratively improve the solutions, they employed a learning approach to dynamically change the weights by reinforcement and backtracking. The set of weights were reinforced if an iteration resulted in improvement, and were backtracked to the best set of weights so far if there was no improvement over a certain number of iterations.

Inspired by the work of Agarwal et al. (2006), SALM uses both reinforcement and backtracking to adjust the EDA participation ratio $R_{E D A}$. The idea of reinforcement originates from the weight training process of neural network. If the best individual found so far improves, we record $R_{E D A}$ at current population as the best one and then reinforce its change from previous generation using a reinforcement factor (RF). Thus, if $R_{E D A}$ increases from its previous value, more offspring are sampled from the probabilistic model at the next generation. Otherwise, fewer offspring are produced using the probabilistic model. If no improvement happens at an iteration, a perturbation strategy is used to update $R_{E D A}$, which allow either slightly increase or decrease the number of offspring generated by the probabilistic model. In addition to reinforcement, SALM allows backtracking to a previous $R_{E D A}$ according to the predefined tolerate iterations with no improvement (TINI). If the best individual does not improve for consecutive TINI generations, EDA may produce offspring with similar structure and tend to get trapped into premature convergence. Therefore, backtracking is performed

![img-3.jpeg](img-3.jpeg)

Fig. 3. An example of order crossover.
![img-4.jpeg](img-4.jpeg)

Fig. 4. An example of pairwise interchange mutation.
by changing the current $R_{E D A}$ to the best one so far. The procedure of SALM is detailed below.

## Algorithm II: SALM

Step 1: Find the best individual in the current generation $i$. If it provides the best makespan so far, record the makespan as the best makespan $M_{b}$ and the current $R_{\text {EDA }}^{i}$ as the best EDA participation ratio $B R_{\text {EDA }}$.
Step 2: If the TINI counter $k \leqslant T I N I$ and improvement of $M_{b}$ occurs at current generation $i$, set $k=1$ and use one of the following strategies to reinforce the EDA participation ratio at generation $i+1$, i.e. $R_{\text {EDA }}^{i+1}$. In these two strategies, $R F$ indicates the reinforcement factor.
(a) $R_{\text {EDA }}^{i+1}=\min \left\{R_{\text {EDA }}^{i}+R F \times\left(R_{\text {EDA }}^{i}-R_{\text {EDA }}^{i-1}\right), 1\right\}$,
if $R_{\text {EDA }}^{i}-R_{\text {EDA }}^{i-1} \geqslant 0$
(b) $R_{\text {EDA }}^{i+1}=\max \left\{R_{\text {EDA }}^{i}+R F \times\left(R_{\text {EDA }}^{i}-R_{\text {EDA }}^{i-1}\right), 0\right\}$,
if $R_{\text {EDA }}^{i}-R_{\text {EDA }}^{i-1}<0$
Step 3: If $k \leqslant T I N I$ and no improvement of $M_{b}$ occurs at current generation $i$, set $k=k+1$ and select one of the following strategies to update the EDA participation ratio at generation $i+1$, i.e. $R_{\text {EDA }}^{i+1}$. In these two strategies, $r$ represents a uniformly random number from $[0,1]$ and $\gamma$ is the learning rate.
(a) $R_{\text {EDA }}^{i+1}=\min \left\{R_{\text {EDA }}^{i}+r \times \gamma, 1\right\}$, if $r \geqslant 0.5$
(b) $R_{\text {EDA }}^{i+1}=\max \left\{R_{\text {EDA }}^{i}-r \times \gamma, 0\right\}$, if $r<0.5$

Step 4: If $k>$ TINI and no improvement of $M_{b}$ occurs during the past TINI generations, set $k=1$ and $R_{\text {EDA }}^{i+1}=B R_{\text {EDA }}$.

After the offspring are produced by the probabilistic model and genetic operators, SALM is applied to adjust the EDA participation ratio. We initialise the TINI counter $k=1$ and the EDA participation ratio $R_{\text {EDA }}=50 \%$ when SALM is implemented for the first time.

### 3.3.6. Stopping criterion

A variety of stopping criteria have been considered in the literature of EDA, such as the number of generations (Wang, Wang, et al., 2013), the number of consecutive generations with no improvement (Zhang \& Li, 2011), the number of examined solutions (Chen \& Chen, 2013), and bound of computation time
(Jarboui et al., 2009). Similar to that of Wang, Wang, et al. (2013), the maximum number of generations is adopted as the stopping criterion of TSSB-HEDA.

### 3.4. Complete procedure of TSSB-HEDA

According to the detailed description above, the complete procedure of TSSB-HEDA is described as follows:

## Notation

$N_{\text {sim }} \quad$ the number of simulation replications
$P_{s} \quad$ the size of population
$\alpha \quad$ the ratio of population related to identifying promising individuals for further performance evaluation
$\beta \quad$ the ratio of population related to establishing the probabilistic model of EDA
TINI tolerate iterations with no improvement of SALM
$R F \quad$ reinforcement factor of SALM
$\gamma \quad$ the learning rate of SALM
$k \quad$ the TINI counter of SALM
$R_{\text {EDA }} \quad$ the EDA participation ratio
$S_{c} \quad$ the best individual of current population
$S_{b} \quad$ the best individual found so far
CurGen the current generation index
MaxGen the maximum number of generations

## Algorithm III: TSSB-HEDA

Step 1: Set the algorithm parameters $N_{\text {sim }}, P_{s}, P_{m}, \alpha, \beta, \gamma, T I N I$, $R F$, MaxGen. Let CurGen $=1, k=1$, and $R_{\text {EDA }}=50 \%$;
Step 2: Randomly initialise a population of $P_{s}$ individuals;
Step 3: Estimate the initial population under stochastic processing times using the TSSM and choose the best one as $S_{b}$;
Step 4: Identify $\beta \times P_{s}$ individuals to establish the elite set $\Pi_{e}$;
Step 5: Construct the probabilistic model of EDA using $\Pi_{e}$ according to formula (12);
Step 6: Apply the constructed probabilistic model to sample and generate $R_{\text {EDA }} \times P_{s}$ offspring;
Step 7: Apply the order crossover and the pairwise interchange mutation to generate $\left(1-R_{\text {EDA }}\right) \times P_{s}$ offspring;
Step 8: Employ the TSSM to determine the best individual of the current population under stochastic processing times, i.e. $S_{c}$, and then update $S_{b}=S_{c}$ if the expected makespan of $S_{c}$ is less than that of $S_{b}$;
Step 9: Perform SALM to adjust $R_{\text {EDA }}$;
Step 10: If CurGen $\geqslant$ MaxGen, return $S_{b}$; otherwise, let CurGen $=$ CurGen +1 and return to step 4.

## 4. Computational experiments

The proposed TSSB-HEDA is coded in the Netbeans ${ }^{\text {TM }}$ development environment 7.4 and performed on a PC with Intel ${ }^{\circledR}$ Core $^{\text {TM }}$ i5 2.7 GHz processor and 6 GB memory. To validate the effectiveness of TSSB-HEDA, we designed and conducted three experiments, which are detailed in the following sections.

### 4.1. Design of experiments

The first experiment constructs the regression-based metamodel to predict the DSP of planned schedules under stochastic processing times. Instead of conducting a full factorial experiment, the second experiment applies the Taguchi experimental design to identify the near optimum values of key parameters in TSSB-HEDA. After these two experiments, TSSB-HEDA is well prepared to address the PFSP under stochastic processing times, and its performance with makespan criterion is subsequently analysed in the third experiment.

To model the processing time uncertainty in a permutation flowshop, the actual job processing time $P$ is generated from a normal distribution with its expected value of $E(P)$ and the standard deviation of $\sigma$. To guarantee job processing time to be nonnegative in these three experiments, we adopt a left-truncated normal distribution at zero, i.e. $P \sim N\left(E(P), \sigma^{2}\right)$ where $P \in(0,+\infty)$. For the second and the third experiments, TSSB-HEDA and the compared algorithms are terminated when $10 \times \mathrm{n}$ generations are reached, where n is the number of jobs.

### 4.2. Development of regression-based meta-model for DSP estimation

To obtain the regression-based meta-model for DSP estimation, it is necessary to first generate the simulation results that describe the effect of simulation inputs, including job size, machine size, LPTV, and SR, on the performance degradation of planned schedules under stochastic processing times. The levels of these four simulation inputs used in the experiment are presented in Table 1.

For each possible combination of simulation inputs, an experimental PFSP with processing time uncertainty is generated. To solve this problem, a job sequence is first randomly generated and converted into a feasible schedule with a specific SR. The makespans of such schedules under stochastic processing times and deterministic processing times, i.e. $M_{A S}$ and $M_{P S}$, are subsequently obtained. Lastly, the degradation of schedule performance of a planned schedule, i.e. DSP, is computed as

$$
D S P=M_{A S} / M_{P S}-1
$$

Such process continues until each combination of the simulation inputs in Table 1 has been examined. Therefore, a total of 625 $(5 \times 5 \times 5 \times 5=625)$ simulation experiments are conducted to generate the simulation results.

Based on the simulation results, multiple linear regression analysis has been applied to establish the meta-model using formula (9). Accordingly, the proposed regression-based meta-model is obtained as follows:

Table 1
Simulation inputs and their levels.

$$
\begin{aligned}
& D S P=-0.04497+0.00019 x_{1}+0.00593 x_{2}+2.10028 x_{3} \\
& -0.16319 x_{4}-0.00002 x_{1} x_{2}-0.00266 x_{1} x_{3} \\
& -0.00033 x_{1} x_{4}+0.02441 x_{2} x_{3}-0.00358 x_{2} x_{4} \\
& -1.71680 x_{3} x_{4}
\end{aligned}
$$

To evaluate the effectiveness of the developed meta-model, Table 2 gives the results of analysis of variance with $5 \%$ significance level for the meta-model. According to Table 2, the following observations are made: (1) The regression-based meta-model is statistically significant because of the small $p$-value (less than 0.05); (2) The correlation of coefficient $R^{2}$ (larger than 0.95 ) implies that the meta-model can explain over $95 \%$ of the variance in the estimated performance degradation. These observations indicate that the regression-based meta-model is statistically adequate to fit the simulation results under stochastic processing times.

To further test the validity of the developed meta-model, we consider two typical PFSPs, i.e. $50 \times 10$ and $100 \times 20$, in which the expected processing times are generated from the uniform distribution with range $[1,20]$. For these two PFSPs, different values of LPTV and SR are adopted as the inputs of the simulation model. LPTV is chosen to be $0.15,0.25,0.35$, and 0.45 . SR can be 0.26 , 0.34 , and 0.42 . Table 3 presents the DSPs obtained using the discrete-event simulator and the predicted DSPs using the metamodel for the chosen LPTVs and SRs. It is clear that the percentage deviation between the meta-model results and the simulation results is less than $5 \%$, indicating that the developed meta-model provides a good prediction of DSP under stochastic processing times.

### 4.3. Parameter tuning of TSSB-HEDA

The performance of TSSB-HEDA depends on the values of some important parameters, such as $P_{s}$ (the size of population), $\alpha$ (the ratio of population related to identifying promising individuals for further performance evaluation), $\beta$ (the ratio of population related to establishing the probabilistic model of EDA), $p_{\text {ss }}$ (mutation rate), $\gamma$ (the learning rate of SALM), TINI (tolerate iterations with no improvement of SALM), and RF (reinforcement factor of SALM). To determine the near optimum values of these parameters, Taguchi experiments (Taguchi, 1986) are conducted on a moderate-size PFSP with 50 jobs and 10 machines. In this PFSP, LPTVs of machines and expected job processing times are uniformly generated in the ranges $[0.1,0.5]$ and $[1,20]$, respectively. Compared with a full factorial experiment, the Taguchi method is capable of reducing the number of experiments substantially (Naderi, Ghomi, \& Aminnayeri, 2010).

Seven key parameters of TSSB-HEDA and their different factor levels considered in Taguchi experiments are presented in Table 4. Accordingly, an orthogonal array $L_{18}\left(6^{1} \times 3^{6}\right)$ shown in Table 5 is established by MINITAB 16 for parameter tuning. Rather than performing $6^{1} \times 3^{6}=4374$ experiments in a full factorial design, we only conduct a total of 18 Taguchi experiments to identify the near optimum values of these seven parameters. For each of the Taguchi experiment, TSSB-HEDA with a specific level combination of factors is first run separately 20 times for the same experimental PFSP

Table 2
Results of analysis of variance for the meta-model.
Table 3
Validation results of the meta-model.

under stochastic processing times. The average of simulated makespans, i.e. the value of response variable (RV) in a Taguchi experiment, is then determined. Based on RV values, the average response at each factor level is obtained and presented in Fig. 5.

To further analyse the significance of individual factor in TSSBHEDA, Table 6 ranks the factors according to their Delta statistics, which is the difference between the highest and lowest average of RV. The rank of a factor shows its relative importance to the performance of TSSB-HEDA.

From the ranks in Table 6, it is clear that $\alpha$ has the most significant effect on the performance of TSSB-HEDA. Although a large $\alpha$ may result in a more accurate performance estimation of candidate solutions under stochastic processing time, the large computation cost of modelling processing time uncertainty has to be considered. As shown in Fig. 5, the performance of TSSB-HEDA improves slightly once $\alpha$ is larger than 0.3 . The parameter $\alpha$ of 0.3 is therefore adopted in this study to prevent large computation time. The value of $P_{s}$ is likewise set to 300 when considering the amount of computation cost. For the parameters associated with SALM, the moderate values of TINI and RF can help avoid large fluctuation of the EDA partition ratio, and hence may provide a better balance between population diversity and convergence performance. Furthermore, the values of $\beta, p_{\mathrm{m}}$, and $\gamma$ can be easily determined by Fig. 5. From the above analysis, all the key parameters of TSSBHEDA are accordingly set as: $\alpha=0.30, P_{s}=300, \beta=0.15$, $p_{\mathrm{m}}=0.10, \gamma=0.05, T I N I=30$, and $R F=1.10$.

### 4.4. Performance evaluation of TSSB-HEDA

Different from traditional EDA for permutation flowshop scheduling in a static environment, the proposed TSSB-HEDA is characterised by using TSSM and genetic operators to construct solutions considering processing time uncertainty. Therefore, to

Table 4
Factors and their levels of TSSB-HEDA.
Table 5
Orthogonal array $L_{18}\left(6^{1} \times 3^{6}\right)$ of TSSB-HEDA.
evaluate the effectiveness of TSSB-HEDA, it is compared with three scheduling algorithms, namely simulation-based hybrid EDA (SBHEDA), TSSB-EDA with no genetic operators (TSSB-EDA), and TSSB-GA. The brief explanation of these compared scheduling algorithms is shown below:

- SB-HEDA: This algorithm is the same as TSSB-HEDA, except for applying a time-consuming simulator to estimate all candidate solutions rather than some selected promising ones. Compared with TSSB-HEDA, SB-HEDA provides a more accurate performance estimation of candidate solutions, so that it tends to outperform TSSB-HEDA in terms of solution quality. However, with respect to computational efficiency, SB-HEDA is more costly and time-consuming since it takes $O\left(P_{s}\right)$ time for performance evaluation, while TSSB-HEDA takes about $O\left(\alpha P_{s}\right)(\alpha \in[0,1])$ time for such task.
- TSSB-EDA: Rather than hybridising the probabilistic model of EDA with genetic operators of GA for population generation in TSSB-HEDA, this algorithm only applies the probabilistic model to produce the offspring.
- TSSB-GA: Similar to TSSB-HEDA, the initial population is randomly generated and two genetic operators, namely order crossover and swap mutation, are adopted to produce the offspring. The crossover and mutation rates are empirically fixed at 0.8 and 0.1 , respectively.

![img-5.jpeg](img-5.jpeg)

Fig. 5. Factor level trend of TSSB-HEDA.

Table 6
Average response value and rank of each factor.
To have a fair comparison, the key parameters of SB-HEDA, TSSB-EDA, and TSSB-GA, such as $P_{r}$, MaxGen, and $N_{\min }$, have the same values as those used in TSSB-HEDA. Moreover, all these four algorithms are stopped after $10 \times \mathrm{n}$ generations. This experiment is conducted on the well-known Taillard's benchmark problems with $m=5,10$, and 20 and $n=20,50,100$, and 200 (Taillard, 1993). Ten instances are considered for each PFSP, in which the LPTVs of machines are generated from the uniform distribution with range $[0.1,0.5]$. To compare schedule performance of TSSB-HEDA, SB-HEDA, TSSB-EDA, and TSSB-GA, we perform the four algorithms 10 times for each instance and measure the solution quality of each instance group by the minimum relative percentage deviation (denoted as $\Delta_{\min }$ ), the average relative percentage deviation (denoted as $\Delta_{\text {avg }}$ ), and the maximum relative percentage deviation (denoted as $\Delta_{\min }$ ). These three performance measures are computed as follows:
$\Delta_{\min }=\sum_{t=1}^{10}\left(\frac{\left(R S_{\text {sig }}^{r}-S_{\text {best }}^{r}\right) \times 100}{S_{\text {best }}^{r}}\right) / 10$
$\Delta_{\text {avg }}=\sum_{t=1}^{10}\left(\frac{\left(A S_{\text {sig }}^{r}-S_{\text {best }}^{r}\right) \times 100}{S_{\text {best }}^{r}}\right) / 10$
$\Delta_{\text {max }}=\sum_{t=1}^{10}\left(\frac{\left(W S_{\text {sig }}^{r}-S_{\text {best }}^{r}\right) \times 100}{S_{\text {best }}^{r}}\right) / 10$
where $R S_{\text {sig }}^{r}, A S_{\text {sig }}^{r}$, and $W S_{\text {sig }}^{r}$ respectively denote makespans of the best, average, and worst solutions obtained using a specific algorithm for instance $r ; S_{\text {best }}^{r}$ represents the minimum makespan among the solutions generated using all compared algorithms for instance $r$.

Table 7 shows the experiment results of SB-HEDA and TSSBHEDA under stochastic processing times. According to the experiment results, the following are observed: (1) SB-HEDA performs better than TSSB-HEDA in terms of $\Delta_{\min }, \Delta_{\text {avg }}$, and $\Delta_{\text {max }}$. The good performance of SB-HEDA lies in evaluating all the offspring individuals by the time-consuming simulator; (2) since the difference in the performance of SB-HEDA and TSSB-HEDA is not significant, TSSM is found to be effective to estimate the schedule performance considering processing time uncertainty.

Different from the conventional EDA, TSSB-HEDA hybridises EDA with GA to address the PFSP under stochastic processing times. Therefore, to further validate the effectiveness of TSSB-HEDA, it is compared with TSSB-EDA and TSSB-GA. The experiment results in Table 8 indicate that TSSB-HEDA performs

Table 7
Comparison results of SB-HEDA and TSSB-HEDA under normal processing times.
Table 8
Computation results of TSSB-HEDA, TSSB-EDA, and TSSB-GA under normal processing times.
Table 9
Average CPU times of SB-HEDA, TSSB-HEDA, TSSB-EDA, and TSSB-GA under normal processing times.

significantly better than either TSSB-EDA or TSSB-GA. Furthermore, $\Delta_{\max }$ of TSSB-HEDA is less than $\Delta_{\max }$ of TSSB-EDA and TSSB-GA for all the test problems, which shows the superiority of the proposed TSSB-HEDA.

To further investigate the performance of the proposed TSSB-HEDA, the computation time of TSSB-HEDA, SB-HEDA, TSSB-EDA, and TSSB-GA are compared. Table 9 summarises the average CPU times in seconds of these four algorithms. From this table, the following conclusions can be made:
(1) SB-HEDA is computationally more expensive than TSSBHEDA, although it provides slightly better results, as shown in Table 7. TSSB-HEDA is computationally more efficient than SB-HEDA because it only applies the time-consuming simulator to evaluate a small portion of a population, i.e. $\alpha P_{i}(\alpha \in[0,1])$, rather than the whole population.
(2) As a hybridisation of EDA and GA, the average CPU time of SB-HEDA is between those of TSSB-EDA and TSSB-GA.

## 5. Conclusion

In this paper, an effective two-stage simulation-based hybrid EDA (TSSB-HEDA) is presented to address the permutation flowshop scheduling problems with processing time uncertainty. To reduce the computation cost of evaluating the offspring, TSSBHEDA employs a novel two-stage simulation model (TSSM) for performance estimation. In the first stage of TSSM, a regression-based meta-model is adopted to provide a quick performance evaluation on offspring individuals, and only a number of promising ones are subsequently estimated in the second stage using a relatively
time-consuming simulator. Furthermore, to enhance the population diversity of EDA, TSSB-HEDA applies both the probabilistic model of EDA and genetic operators of GA to produce the offspring. Inspired by the idea of neural network leaning, a self-adaptive learning mechanism (SALM) is established to determine the ratio of offspring generated by the probabilistic model.

To validate the performance of TSSB-HEDA, it has been compared with three scheduling algorithms, namely simulation-based hybrid EDA (SB-HEDA), TSSB-HEDA with no genetic operators (TSSB-EDA), and TSSB-GA. The experiment results on the well-known Taillard's benchmark problems show that TSSB-HEDA can maintain a good balance between schedule performance and computation time. Such a quality-time balance is resulted from the efficiency of TSSM in estimating the schedule performance with processing time uncertainty, and SALM in dynamically adjusting the ratio of individuals generated by EDA to avoid early search stagnation. Since realworld manufacturing suffers a variety of uncertainties, future research may extend the proposed TSSB-HEDA to deal with other unexpected events in a permutation flowshop, such as rush order and machine breakdown. Furthermore, another research direction can focus on exploring possible hybridisation of EDA with other effective meta-heuristics to enhance the population diversity.

## Acknowledgments

We would like to thank the anonymous referees for their constructive and pertinent comments. This research is partially supported by Key Program from National Natural Science Foundation of China (No. 71231007), National Science Foundation of China (No. 71301124), Humanities and Social Sciences Foundation of the Ministry of Education of China (No. 13YJCG30165), Fundamental Research Funds for the Central Universities.
