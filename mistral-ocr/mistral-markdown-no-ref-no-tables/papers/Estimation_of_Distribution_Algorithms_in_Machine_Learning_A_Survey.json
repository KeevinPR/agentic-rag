{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2024/Estimation of Distribution Algorithms in Machine Learning A Survey.md",
    "filename": "Estimation of Distribution Algorithms in Machine Learning A Survey.md",
    "title": "Estimation of Distribution Algorithms in Machine Learning A Survey",
    "year": "2024"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] Y. Saeys, I. Inza, and P. Larrañaga, \"A review of feature selection techniques in bioinformatics,\" Bioinformatics, vol. 23, no. 19, pp. 2507-2517, 2007.\n[2] H. Sharp, \"Cardinality of finite topologies,\" J. Combinatorial Theory, vol. 5, pp. 82-86, Jul. 1968.\n[3] R. W. Robinson, \"Counting unlabeled acyclic digraphs,\" in Combinatorial Mathematics (Lecture Notes in Mathematics), vol. 622. Heidelberg, Germany: Springer, 1997, pp. 28-42.\n[4] R. E. Tarjan and M. Yannakakis, \"Simple linear-time algorithms to test chordality of graphs, test acyclicity of hypergraphs, and selectively reduce acyclic hypergraphs,\" SIAM J. Comput., vol. 13, no. 3, pp. 566-578, 1984.\n\n[5] T. Minka, \"Algorithms for maximum-likelihood logistic regression,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. 758, 2001.\n[6] D. E. Rumelhart, G. R. Hinton, and R. J. Williams, \"Learning representations by back-propagation errors,\" Nature, vol. 323, pp. 533-536, Oct. 1986.\n[7] J. H. Holland, Adaptation in Natural and Artificial Systems. Ann Arbor, MI, USA: Univ. Michigan Press, 1975.\n[8] D. E. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Learning. Boston, MA, USA: Wesley, 1989.\n[9] M. Dorigo and T. Stützle, Ant Colony Optimization. Cambridge, MA, USA: MIT Press, 2004.\n[10] R. C. Eberhart and J. Kennedy, Swarm Intelligence. Burlington, MA, USA: Morgan Kaufmann, 2001.\n[11] P. Larrañaga and J. A. Lozano, Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., 2002.\n[12] R. Storn and K. Price, \"Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces,\" J. Global Optim., vol. 11, no. 4, pp. 341-359, 1997.\n[13] L. J. Fogel, \"Autonomous automata,\" Ind. Res., vol. 4, no. 2, pp. 14-19, 1962.\n[14] J. R. Koza, Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge, MA, USA: MIT Press, 1992.\n[15] I. Rechenberg, Evolutionstrategie: Optimierung Technischer Systeme Nach Prinzipien der Biologischen Evolution. Stuttgart, Germany: Fromman-Holzboog, 1973.\n[16] M. S. Krejca and C. Witt, \"Theory of estimation-of-distribution algorithms,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer, 2020, pp. 405-442.\n[17] B. Xue, M. Zhang, W. N. Browne, and X. Yao, \"A survey on evolutionary computation approaches to feature selection,\" IEEE Trans. Evol. Comput., vol. 20, no. 4, pp. 606-626, Aug. 2016.\n[18] B. Badhon, M. M. Xabit, S. Xu, and M. Kabir, \"A survey on association rule mining based on evolutionary computation,\" Int. J. Comput. Appl., vol. 41, no. 1, pp. 1-11, 2019.\n[19] A. Telikani, A. H. Gandomi, and A. Shahbahrami, \"A survey of evolutionary computation for association rule mining,\" Inf. Sci., vol. 524, pp. 318-352, Jul. 2020.\n[20] R. C. Barros, M. P. Basgalupp, A. C. P. L. F. de Carvalho, and A. A. Freitas, \"A survey of evolutionary algorithms for decision-tree induction,\" IEEE Trans. Syst., Man Cybern. C, Appl. Rev., vol. 42, no. 3, pp. 291-312, May 2012.\n[21] A. Darwish, A. E. Hassanien, and S. Das, \"A survey of swarm and evolutionary computing approaches for deep learning,\" Artif. Intell. Rev., vol. 53, no. 3, pp. 1767-1812, 2020.\n[22] Z.-H. Zhan, J.-Y. Li, and J. Zhang, \"Evolutionary deep learning: A survey,\" Neurocomputing, vol. 483, pp. 42-58, Apr. 2022.\n[23] N. Li, L. Ma, G. Yu, B. Xue, M. Zhang, and Y. Jin, \"Survey on evolutionary deep learning: Principles, algorithms, applications and open issues,\" 2022, arsiv2208.10658v1.\n[24] M. J. A. Hasan and S. Ramakrishnan, \"A survey: Hybrid evolutionary algorithms for cluster analysis,\" Artif. Intell. Rev., vol. 36, no. 3, pp. 179-204, 2011.\n[25] E. R. Hruschka, R. J. G. B. Campello, A. A. Freitas, and A. C. P. L. F. de Carvalho, \"A survey of evolutionary algorithms for clustering,\" IEEE Trans. Syst., Man Cybern. C, Appl. Rev., vol. 39, no. 2, pp. 133-155, Mar. 2009.\n[26] A. Mukhopadhyay, U. Maulik, and S. Bandyopadhyay, \"A survey of multiobjective evolutionary clustering,\" ACM Comput. Surveys, vol. 47, no. 4, pp. 1-46, 2015.\n[27] P. Larrañaga, H. Karshenas, C. Bielza, and R. Santana, \"A review on evolutionary algorithms in Bayesian network learning and inference tasks,\" Inf. Sci., vol. 233, pp. 109-125, Jun. 2013.\n[28] H. Al-Sahaf et al., \"A survey on evolutionary machine learning,\" J. Royal New Zealand, vol. 49, no. 2, pp. 205-228, 2019.\n[29] A. Mukhopadhyay, U. Maulik, S. Bandyopadhyay, and C. A. Coello-Coello, \"Survey of multiobjective evolutionary algorithms for data mining: Part I,\" IEEE Trans. Evol. Comput., vol. 18, no. 1, pp. 4-19, Feb. 2014.\n[30] A. Mukhopadhyay, U. Maulik, S. Bandyopadhyay, and C. A. Coello-Coello, \"Survey of multiobjective evolutionary algorithms for data mining: Part II,\" IEEE Trans. Evol. Comput., vol. 18, no. 1, pp. 20-35, Feb. 2014.\n[31] K.A. De Jong, Evolutionary Computation. A Unified Approach. Cambridge, MA, USA: MIT Press, 2006.\n[32] C. Darwin, The Origin of Species by Means of Natural Selection or the Preservation of Favoured Races in the Struggle for Life. London, U.K.: John Murray, 1859.\n[33] M. Pelikan, D. E. Goldberg, and F. Lobo, \"A survey of optimization by building and using probabilistic models,\" Comput. Optim. Appl., vol. 21, no. 1, pp. 5-20, 2002.\n[34] J. A. Lozano, P. Larrañaga, I. Inza, and E. Bengoetxea, Towards a New Evolutionary Computation. Advances in Estimation of Distribution Algorithms. Heidelberg, Germany: Springer, 2005.\n[35] M. Hauschild and M. Pelikan, \"An introduction and survey of estimation of distribution algorithms,\" Swarm Evol. Comput., vol. 1, no. 3, pp. 111-128, 2011.\n[36] R. Santana, J. A. Lozano, and P. Larrañaga, \"Research topics in discrete estimation of distribution algorithms based on factorizations,\" Memet. Comput., vol. 1, pp. 35-54, Mar. 2009.\n[37] P. Larrañaga, H. Karshenas, C. Bielza, and R. Santana, \"A review on probabilistic graphical models in evolutionary computation,\" $J$. Heurist., vol. 18, no. 5, pp. 795-819, 2012.\n[38] J. Ceberio, A. Mendiburu, and J. A. Lozano, \"A roadmap for solving optimization problems with estimation of distribution algorithms,\" Nat. Comput., 2022, doi: 10.1007/s11047-022-09913-2.\n[39] X. Qian, J. Yu, A. Zhao, Q. Liu, and R. Zhang, \"Decentralised estimation of distribution algorithm for parallel pumps based on log-linear model,\" Int. J. Smart Grid Green Commun., vol. 2, no. 1, pp. 70-85, 2020.\n[40] W. Dong, Y. Wang, and M. Zhou, \"A latent space-based estimation of distribution algorithm for large-scale global optimization,\" Soft Comput., vol. 23, pp. 4593-4615, Jul. 2019.\n[41] R. Santana, \"Estimation of distribution algorithms with Kikuchi approximations,\" Evol. Comput., vol. 13, no. 1, pp. 67-97, 2005.\n[42] S. Shakya and J. McCall, \"Optimization by estimation of distribution with DEUM framework based on Markov random fields,\" Int. J. Autom. Comput., vol. 4, no. 3, pp. 262-272, 2007.\n[43] S. Shakya and R. Santana, Markov Networks in Evolutionary Computation. Heidelberg, Germany: Springer, 2012.\n[44] E. Pira, \"Using Markov chain based estimation of distribution algorithm for model-based safety analysis of graph transformation,\" J. Comput. Sci. Technol., vol. 36, pp. 839-855, Jul. 2021.\n[45] M. Soto, Y. González-Fernández, and A. Ochoa, \"Modelling with copulas and vines in estimation of distribution algorithms,\" Investigación Operacional, vol. 36, no. 1, pp. 1-23, 2015.\n[46] T. K. Paul and H. Iba, \"Reinforcement learning estimation of distribution algorithm,\" in Genetic and Evolutionary Computation (Lecture Notes in Computer Science 2724). Heidelberg, Germany: Springer, 2003, pp. 1259-1270.\n[47] L. Martí, J. García, A. Berlanga, and J. M. Molina, \"Multi-objective optimization with an adaptive resonance theory-based estimation of distribution algorithm,\" Ann. Math. Artif. Intell., vol. 68, no. 4, pp. 247-273, 2013.\n[48] L. Martí, J. García, A. Berlanga, and J. M. Molina, \"MONEDA: Scalable multi-objective optimization with a neural network-based estimation of distribution algorithm,\" J. Global Optim., vol. 66, pp. 729-768, Mar. 2016.\n[49] L. Bao, X. Sun, D. Gong, and Y. Zhang, \"Multisource heterogeneous user-generated contents-driven interactive estimation of distribution algorithms for personalized search,\" IEEE Trans. Evol. Comput., vol. 26, no. 5, pp. 844-858, Oct. 2022.\n[50] M. Probst, F. Rothlauf, and J. Grahl, \"Scalability of using restricted Boltzmann machines for combinatorial optimization,\" Eue. J. Oper. Res., vol. 256, no. 2, pp. 368-383, 2017.\n[51] V. A. Shim, K. C. Tan, C. Y. Cheong, and J. Y. Chia, \"Enhancing the scalability of multi-objective optimization via restricted Boltzmann machine-based estimation of distribution algorithm,\" Inf. Sci., vol. 248, pp. 191-213, Nov. 2013.\n[52] M. Probst and F. Rothlauf, \"Harmless overfitting: Using denoising autoencoders in estimation of distribution algorithms,\" J. Mach. Learn. Res., vol. 21, no. 78, pp. 1-31, 2020.\n[53] S. Bhattacharjee, \"Variational autoencoder based estimation of distribution algorithms and applications to individual based ecosystem modelling using EcoSim,\" Ph.D. dissertation, Dept. Comput. Sci., Univ. Windsor, Windsor, ON, Canada, 2019.\n[54] J.-H. Jeong, E. Lee, J.-H. Lee, and C.W. Ahn, \"Multi-objective deep network-based estimation of distribution algorithm for music composition,\" IEEE Access, vol. 10, pp. 71973-71985, 2022.\n[55] M. Probst, \"Generative adversarial networks in estimation of distribution algorithms for combinatorial optimization,\" 2016, arXiv:1509.09235v2.\n\n[56] D. Cucci, L. Malagó, and M. Matteucci, \"Variable transformations in estimation of distribution algorithms,\" in Parallel Problem Solving from Nature (Lecture Notes in Computer Science 7491). Heidelberg, Germany: Springer, 2012, pp. 428-437.\n[57] C. González, J. A. Lozano, and P. Larrañaga, \"Analyzing the PBIL algorithm by means of discrete dynamical systems,\" Complex Syst., vol. 12, no. 4, pp. 465-479, 2001.\n[58] T. Chen, K. Tang, G. Chen, and X. Yao, \"Analysis of computational time of simple estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 14, no. 1, pp. 1-22, Feb. 2010.\n[59] B. Doerr and M. S. Krejca, \"A simplified run time analysis of the univariate marginal distribution algorithm on LeadingOnes,\" Theor. Comput. Sci. vol. 851, pp. 121-128, Jan. 2021.\n[60] C. González, J. A. Lozano, and P. Larrañaga, \"Mathematical modelling of UMDAc algorithm with tournament selection. Behaviour on linear and quadratic functions,\" Int. J. Approx. Reason., vol. 31, no. 4, pp. 313-340, 2002.\n[61] Q. Zhang and H. Mühlenbein, \"On the convergence of a class of estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 8, no. 2, pp. 127-136, Apr. 2004.\n[62] B. Doerr and W. Zheng, \"Sharp bounds for genetic drift in estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 2, no. 6, pp. 1140-1149, Dec. 2020.\n[63] J. Pearl, Probabilistic Reasoning in Intelligent Systems. Burlington, MA, USA: Morgan Kaufmann, 1988.\n[64] D. Koller and N. Friedman, Probabilistic Graphical Models: Principles and Techniques. Cambridge, MA, USA: MIT Press, 2009.\n[65] M. Maathuis, M. Drton, S. Lauritzen, and M. Wainwright, Handbook of Graphical Models. Boca Raton, FL, USA: CRC Press, 2019.\n[66] C. Bielza and P. Larrañaga, Data-Driven Computational Neuroscience. Machine Learning and Statistical Models. Cambridge, U.K.: Cambridge Univ. Press, 2020.\n[67] R. Shachter and C. Kenley, \"Gaussian influence diagrams,\" Manag. Sci., vol. 35, no. 5, pp. 527-550, 1989.\n[68] D. Geiger and D. Heckerman, \"Learning Gaussian networks,\" in Proc. 10th Int. Conf. Uncertainty Artif. Intell., 1994, pp. 235-243.\n[69] R. Neapolitan, Learning Bayesian Networks. Upper Saddle River, NJ, USA: Prentice Hall, 2003.\n[70] R. Daly, Q. Shen, and S. Aitken, \"Learning Bayesian networks: Approaches and issues,\" Knowl. Eng. Rev., vol. 26, no. 2, pp. 99-157, 2011.\n[71] M. Scanagatta, A. Salmerón, and F. Stella, \"A survey on Bayesian network structure learning from data,\" Progr. Artif. Intell., vol. 8, pp. 425-439, May 2019.\n[72] O. Spirtes and C. Glymour, \"An algorithm FOS fast recovey of sparse causal graphs,\" Social Sci. Comput. Rev., vol. 90, no. 1, pp. 62-72, 1991.\n[73] H. Akaike, \"A new look at the statistical model identification,\" IEEE Trans. Autom. Control, vol. 19, no. 6, pp. 716-723, Dec. 1974.\n[74] G. Schwarz, \"Estimating the dimension of a model,\" Ann. Stat., vol. 6, no. 2, pp. 461-464, 1978.\n[75] G. F. Cooper and E. Herskovits, \"A Bayesian method for the induction of probabilistic networks from data,\" Mach. Learn., vol. 9, pp. 309-347, Oct. 1992.\n[76] D. Heckerman, D. Geiger, and D. M. Chickering, \"Learning Bayesian networks: The combination of knowledge and statistical data,\" Mach. Learn., vol. 20, pp. 197-243, Sep. 1995.\n[77] M. Henrion, \"Propagating uncertainty in Bayesian networks by probabilistic logic sampling,\" in Uncertainty in Artificial Intelligence, vol. 2. Amsterdam, The Netherlands: North-Holland, 1988, pp. 149-163.\n[78] R. M. Fung and K. C. Chang, \"Weighing and integrating evidence for stochastic simulation in Bayesian networks,\" in Uncertainty in Artificial Intelligence, vol. 5. Amsterdam, The Netherlands: North-Holland, 1990, pp. 209-220.\n[79] J. Pearl, \"Evidential reasoning using stochastic simulation of causal models,\" Artif. Intell., vol. 32, no. 2, pp. 245-257, 1987.\n[80] Q. Dang, W. Gao, and M. Gong, \"An efficient mixture sampling model for Gaussian estimation of distribution algorithm,\" Inf. Sci., vol. 608, pp. 1157-1182, Aug. 2022.\n[81] T. Miquêlez, E. Bengoetxea, and P. Larrañaga, \"Evolutionary computation based on Bayesian classifiers,\" Int. J. Appl. Math. Comput. Sci., vol. 14, pp. 101-115, Jan. 2004.\n[82] H. Karshenas, R. Santana, C. Bielza, and P. Larrañaga, \"Multiobjective estimation of distribution algorithm based on joint modeling of objectives and variables,\" IEEE Trans. Evol. Comput., vol. 18, no. 4, pp. 519-542, Aug. 2014.\n[83] P. Larrañaga, R. Etxeberria, J. A. Lozano, and J. M. Peña, \"Optimization in continuous domains by learning and simulation of Gaussian networks,\" in Proc. Genet. Evol. Comput. Conf. Workshop Program, 2000, pp. 201-204.\n[84] P. A. N. Bosman and J. Grahl, \"Matching inductive search bias and problem structure in continuous estimation-of-distribution algorithms,\" Eur. J. Oper. Res., vol. 185, no. 3, pp. 1246-1264, 2008.\n[85] H. Mühlenbein and G. Paaß, \"From recombination of genes to the estimation of distributions. I. Binary parameters,\" in Parallel Problem Solving From Nature (Lecture Notes in Computer Science 1411). Heidelberg, Germany: Springer, 1996, pp. 178-187.\n[86] S. Baluja, \"Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-94-163, 1994.\n[87] M. Sebag and A. Ducoulombier, \"Extending population-based incremental learning to continuous spaces,\" in Parallel Problem Solving from Nature (Lecture Notes in Computer Science 1498). Heidelberg, Germany: Springer, 1998, pp. 418-427.\n[88] G. Harik, F. G. Lobo, and D. E. Goldberg, \"The compact genetic algorithm,\" in Proc. IEEE Conf. Evol. Comput., 1998, pp. 523-528.\n[89] B. Doerr and M. Dufay, \"General univariate estimation-of-distribution algorithms,\" in Proc. 17th Int. Conf. Parallel Problem Solving Nat., 2022, pp. 470-484.\n[90] J. S. De Bonet, C. L. Isbell, and P. Viola, \"MIMIC: Finding optima by estimating probability densities,\" in Proc. Adv. Neural Inf. Process. Syst., vol. 9, 1997, pp. 424-430.\n[91] S. Baluja and S. Davies, \"Combining multiple optimization runs with optimal dependency trees,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-97-157, 1997.\n[92] M. Pelikan and H. Mühlenbein, \"The bivariate marginal distribution algorithm,\" Advances in Soft Computing-Engineering Design and Manufacturing. London, U.K.: Springer, 1999, pp. 521-535.\n[93] R. Etxeberria and P. Larrañaga, \"Global optimization using Bayesian networks,\" in Proc. 2nd Int. Symp. Artif. Intell., 1999, pp. 332-339.\n[94] P. Larrañaga, R. Etxeberria, J. A. Lozano, and J. M. Peña, \"Combinatorial optimization by learning and simulation of Bayesian networks,\" in Proc. 16th Conf. Uncertainty Artif. Intell., 2000, pp. 343-352.\n[95] W. Dong, T. Chen, P. Tino, and X. Yao, \"Scaling up estimation of distribution algorithms for continuous optimization,\" IEEE Trans. Evol. Comput., vol. 17, no. 6, pp. 797-822, Dec. 2013.\n[96] M. Pelikan, D. E. Goldberg, and E. Cantú-Paz, \"BOA: The Bayesian optimization algorithm,\" in Proc. Genet. Evol. Comput. Conf., vol. 1, 1999, pp. 525-532.\n[97] H. Mühlenbein and T. Mahning, \"FDA-A scalable evolutionary algorithm for the optimization of additively decomposed functions,\" Evol. Comput., vol. 7, no. 4, pp. 353-376, Dec. 1999.\n[98] W. Dong and X. Yao, \"Unified eigen analysis on multivariate Gaussian based estimation of distribution algorithms,\" Inf. Sci., vol. 178, no. 15, pp. 3000-3023, 2008.\n[99] Y. Liang, Z. Ren, X. Yao, Z. Feng, A. Chen, and W. Guo, \"Enhancing Gaussian estimation of distribution algorithm by exploiting evolution direction with archive,\" IEEE Trans. Cybern., vol. 50, no. 1, pp. 140-152, Jan. 2020.\n[100] H. Xu, J. Yang, P. Jia, and Y. Ding, \"Effective structure learning for estimation of distribution algorithms via L1-regularized Bayesian networks,\" Int. J. Adv. Robot. Syst., vol. 10, no. 1, p. 17, 2013.\n[101] H. Karshenas, R. Santana, C. Bielza, and P. Larrañaga, \"Regularized continuous estimation of distribution algorithms,\" Appl. Soft Comput., vol. 13, no. 5, pp. 2412-2432, 2013.\n[102] P. A. N. Bosman and D. Thierens, \"IDEAs based on the normal kernels probability density function,\" Dept. Comput. Sci., Utrecht Univ., Utrecht, The Netherlands, Rep. UU-CS-2000-11, 2000.\n[103] P. A. N. Bosman and D. Thierens, \"Multi-objective optimization with diversity preserving mixture-based iterated density estimation evolutionary algorithms,\" Int. J. Approx. Reason., vol. 31, no. 3, pp. 259-289, 2002.\n[104] J. M. Peña, J. A. Lozano, and P. Larrañaga, \"Globally multimodal problem optimization via an estimation of distribution algorithm based on unsupervised learning of Bayesian networks,\" Evol. Comput., vol. 13, no. 1, pp. 43-66, 2005.\n[105] G. Harik, \"Linkage learning via probabilistic modelling in the ECGA,\" Univ. Illinois Urbana-Champaign, Champaign, IL, USA, Rep. 99010, 1999.\n\n[106] C. A. Coello-Coello, G. B. Lamont, and D. A. Van Veldhuizen, Evolutionary Algorithms for Solving Multi-Objective Problems. New York, NY, USA: Springer, 2007.\n[107] R. Santana, C. Bielza, J. A. Lozano, and P. Larrañaga, \"Mining probabilistic models learned by EDAs in the optimization of multi-objective problems,\" in Proc. 11th Annu. Conf. Genet. Evol. Comput., 2009, pp. 445-452.\n[108] M. Costa and E. Minsci, \"MOPED: A multi-objective Parzen-based estimation of distribution algorithm for continuous problems,\" in Evolutionary Multi-Criterion Optimization (Lecture Notes in Computer Science 2632). Heidelberg, Germany: Springer, 2003, pp. 282-294.\n[109] E. Bergsetsea, P. Larrañaga, C. Bielza, and J. A. Fernández del Pozo, \"Optimal row and column ordering to improve table interpretation using estimation of distribution algorithms,\" J. Heurist., vol. 17, no. 5, pp. 567-588, 2011.\n[110] J. Bertin, Graphics and Graphic Information Processing. Berlin, Germany: Walter de Gruyter, 1981.\n[111] H. Walker and W. Durost, Statistic Tables: Their Structure and Use, Bureau of Publications, Columbia Univ., New York, NY, USA, 1936.\n[112] J. L. Flores, I. Inza, and P. Larrañaga, \"Wrapper discretization by means of estimation of distribution algorithms,\" Intell. Data Anal. J., vol. 11, no. 5, pp. 525-546, 2007.\n[113] R. Agrawal and R. Srikant, \"Fast algorithms for mining association rules in large databases,\" in Proc. 20th Int. Conf. Very Large Data Bases, 1994, pp. 487-499.\n[114] X. Zhang, B. Xue, G. Sui, and J. Cui, \"Association rule mining based on estimation of distribution algorithm for blood indices,\" in Proc. Int. Conf. Comput. Netw., Electron. Autom., 2017, pp. 59-65.\n[115] X. Li, S. Mabu, H. Zhou, K. Shimada, and K. Hirasawa, \"Genetic network programming with estimation of distribution algorithms for class association rule mining in traffic prediction,\" in Proc. IEEE Congr. Evol. Comput., 2010, pp. 1-8.\n[116] E. Fix and J. L. Hodges, \"Discriminatory analysis-non parametric discrimination: Consistency properties,\" USAF School Aviation Med., Wright-Patterson AFB, OH, USA, Rep. 4, 1951.\n[117] I. Inza, P. Larrañaga, and B. Sierra, \"Feature weighting for nearest neighbour by EDAs,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad. Publ., 2002, pp. 295-311.\n[118] J. R. Quinlan, \"Induction of decision trees,\" Mach. Learn., vol. 1, no. 1, pp. 81-106, 1986.\n[119] H. E. L. Cagnini, R. C. Barros, and M. P. Basgalupp, \"Estimation of distribution algorithms for decision-tree induction,\" in Proc. Congr. Evol. Comput., 2017, pp. 2022-2029.\n[120] J. Holland, \"A mathematical framework for studying learning in classifier systems,\" Physica D, vol. 2, no. 1, pp. 307-317, 1986.\n[121] K. De Jong and W. Spears, \"Learning concept classification rules using genetic algorithms,\" in Proc. 12th Int. Joint Conf. Artif. Intell., 1991, pp. 651-656.\n[122] B. Sierra, E. A. Jiménez, I. Inza, and P. Larrañaga, \"Rule induction by estimation of distribution algorithms,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., 2002, pp. 313-322.\n[123] J. Yang, H. Xu, and P. Jia, \"Effective search for Pittsburgh learning classifier systems via estimation of distribution algorithms,\" Inf. Sci., vol. 198, pp. 100-117, Sep. 2012.\n[124] J. Yang, H. Xu, and P. Jia, \"Effective search for genetic-based machine learning systems via estimation of distribution algorithms and embedded feature reduction techniques,\" Neurocomputing, vol. 113, pp. 105-121, Aug. 2013.\n[125] L. DelaOssa, J. A. Gámez, and J. M. Puerta, \"Learning weighted linguistic fuzzy rules by using specifically-tailored hybrid estimation of distribution algorithms,\" Int. J. Approx. Reason., vol. 50, no. 3, pp. 541-560, 2009.\n[126] B.E. Boser, I. M. Guyon, and V. N. Vapnik, \"A training algorithm for optimal margin classifiers,\" in Proc. 5th Annu. Workshop Comput. Learn. Theory, 1992, pp. 144-152.\n[127] L.C. Padierna, M. Carpio, A. Rojas, H. Puga, R. Baltazar, and H. Fraire, \"Hyper-parameter tuning for support vector machines by estimation of distribution algorithms,\" in Nature-Inspired Design of Hybrid Intelligent Systems, vol. 667. Cham, Switzerland: Springer, 2017, pp. 787-800.\n[128] W. McCulloch and W. Pitts, \"A logical calculus of the ideas immanent in nervous activity,\" Bull. Math. Biophys., vol. 5, pp. 115-133, Dec. 1943.\n[129] S. Baluja, \"An empirical comparison of seven iterative and evolutionary function optimization heuristics,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-95-193, 1995.\n[130] M.R. Gallagher, \"Multi-layer perceptron error surfaces: Visualization, structure and modelling,\" Ph.D. dissertation, Comput. Sci. Electr. Eng., Univ. Queensland, Herston, QLD, Australia, 2000.\n[131] C. Cotta, E. Alba, R. Sagarna, and P. Larrañaga, \"Adjusting weights in artificial neural networks using evolutionary algorithms,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., 2002, pp. 361-377.\n[132] Y. Chen and A. Abraham, \"Estimation of distribution algorithms for optimization of neural networks for intrusion detection,\" Proc. 8th Int. Conf. Artif. Intell. Soft Comput., 2006, pp. 9-18.\n[133] Q. Li, Y. Du, Z. Liu, Z. Zhou, G. Lu, and Q. Chen, \"Drought prediction in the Yunnan-Guizhou plateau of China by coupling the estimation of distribution algorithm and the extreme learning machine,\" Nat. Hazards, vol. 113, pp. 1635-1661, May 2022.\n[134] E. Galić and M. Höhfeld, \"Improving the generalization performance of multi-layer-perceptrons with population-based incremental learning,\" in Parallel Problem Solving From Nature (Lecture Notes in Computer Science 1141). Heidelberg, Germany: Springer, 1996, pp. 740-750.\n[135] G. Holker and M. V. dos Santos, \"Toward an estimation of distribution algorithm for the evolution of artificial neural networks,\" in Proc. 3rd Conf. Comput. Sci. Softw. Eng., 2010, pp. 17-22.\n[136] E. Cantú-Paz, \"Pruning neural networks with distribution estimation algorithms,\" in Proc. Genet. Evol. Comput. Conf., 2003, pp. 790-800.\n[137] J. Peralta-Donate, X. Li, G. G. Sánchez, and A. S. de Miguel, \"Time series forecasting by evolving artificial neural networks with genetic algorithms, differential evolution and estimation of distribution algorithm,\" Neural Comput. Appl., vol. 22, pp. 11-20, Jan. 2013.\n[138] Y. Bengio, \"Learning deep architectures for AI,\" Found. Trends Mach. Learn., vol. 2, no. 1, pp. 1-127, 2009.\n[139] J.-Y. Li, Z.-H. Zhan, J. Xu, S. Kwong, and J. Zhang, \"Surrogateassisted hybrid-model estimation of distribution algorithm for mixed-variable hyperparameters optimization in convolutional neural networks,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 34, no. 5, pp. 2338-2352, May 2023.\n[140] O. G. Tolodano-López, J. Madera, H. González, and A. Simón-Cuevas, \"A hybrid method based on estimation of distribution algorithms to train convolutional neural networks for text categorization,\" Pattern Recognit. Lett., vol. 160, pp. 105-111, Aug. 2022.\n[141] Q. Xu, A. Liu, X. Yuan, Y. Song, C. Zhang, and Y. Li, \"Random mask-based estimation of the distribution algorithm for stacked autoencoder one-step pre-training,\" Comput. Ind. Eng., vol. 158, Aug. 2021, Art. no. 107400.\n[142] J. Berkson, \"Application of the logistic function to bio-assay,\" J. Amer. Stat. Assoc., vol. 39, no. 227, pp. 357-365, 1944.\n[143] V. Robles, C. Bielza, P. Larrañaga, S. González, and L. Ohno-Machado, \"Optimizing logistic regression coefficients for discrimination and calibration using estimation of distribution algorithms,\" TOP, vol. 16, no. 2, pp. 345-366, 2008.\n[144] C. Bielza, V. Robles, and P. Larrañaga, \"Regularized logistic regression without a penalty term: An application to cancer classification with microarray data,\" Expert Syst. Appl., vol. 38, no. 5, pp. 5110-5118, 2011.\n[145] M. L. Minsky, \"Step toward artificial intelligence,\" Proc. IRE, vol. JRPROC-49, no. 1, pp. 8-30, Jan. 1961.\n[146] N. Friedman, D. Geiger, and M. Goldszmidt, \"Bayesian network classifiers,\" Mach. Learn., vol. 50, nos. 1-2, pp. 95-125, 1997.\n[147] C. Bielza, and P. Larrañaga, \"Discrete Bayesian network classifiers,\" ACM Comput. Surveys, vol. 47, no. 1, 2014, Art. no. 5.\n[148] V. Robles, P. Larrañaga, J. M. Peña, E. Menasalvas, and M. S. Pérez, \"Interval estimation Naïve Bayes,\" in Advances in Intelligent Data Analysis (Lecture Notes in Computer Science 2810). Heidelberg, Germany: Springer, 2003, pp. 143-154.\n[149] M. Pazzani, \"Constructive induction of Cartesian product attributes,\" in Proc. Inf., Stat. Induct. Sci. Conf., 1996, pp. 66-77.\n[150] V. Robles et al., \"Bayesian networks multi-classifiers for protein secondary structure prediction,\" Artif. Intell. Med., vol. 31, no. 2, pp. 117-136, 2004.\n[151] D. H. Wolpert, \"Stacked generalization,\" Neural Netw., vol. 5, no. 2, pp. 241-259, 1992.\n[152] I. Mendialdua, A. Arruti, E. Jauregi, E. Lazkano, and B. Sierra, \"Classifier subset selection to construct multi-classifiers by means of estimation of distribution algorithms,\" Neurocomputing, vol. 157, pp. 46-60, Jul. 2015.\n\n153] Y. Freund and R. E. Schapire, \"A decision-theoretic generalization of on-line learning and an application to boosting,\" J. Comput. Syst. Sci., vol. 55, no. 1, pp. 119-139, 1997.\n[154] H. E. L. Cagnini, M. P. Basgalupp, and R. C. Barros, \"Increasing boosting effectiveness with estimation of distribution algorithms,\" in Proc. IEEE Congr. Evol. Comput., 2018, pp. 1-8.\n[155] H. Bunke, \"18 Parameter estimation in nonlinear regression models,\" in Handbook of Statistics, vol. 1. Amsterdam, The Netherlands: Elsevier, 1980, pp. 593-615.\n[156] L. M. Torres-Treviño, \"Symbolic regression using $\\alpha-\\beta$ operators and estimation of distribution algorithms: Preliminary results,\" in Proc. 13th Genet. Evol. Comput. Conf., 2011, pp. 647-654.\n[157] M. A. Sotelo-Figueroa, A. Hernández-Aguirre, A. Espinal, J. A. Soria-Alcaraz, and J. Ortiz-López, \"Symbolic regression by means of grammatical evolution with estimation distribution algorithms as search engine,\" in Fuzzy Logic Augmentation of Neural and Optimization Algorithms: Theoretical Aspects and Real Applications. Studies in Computational Intelligence, vol. 749. Cham, Switzerland: Springer, 2018, pp. 169-180.\n[158] D. Wittenberg and F. Rothlauf, \"Denoising autoencoder genetic programming for real-world symbolic regression,\" in Proc. Genet. Evol. Comput. Conf., 2022, pp. 612-614.\n[159] C. Jin and S.-W. Jin, \"Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms,\" Appl. Soft Comput., vol. 15, pp. 113-120, Feb. 2014.\n[160] P. M. Lewis, \"The characteristic selection problem in recognition systems,\" IRE Trans. Inf. Theory, vol. TIT-8, no. 2, pp. 171-178, Feb. 1962.\n[161] I. Inza, P. Larrañaga, R. Etxeberria, and B. Sierra, \"Feature subset selection by Bayesian network-based optimization,\" Artif. Intell., vol. 123, pp. 157-184, Oct. 2000.\n[162] I. Inza, P. Larrañaga, and B. Sierra, \"Feature subset selection by Bayesian networks: A comparison with genetic and sequential algorithms,\" Int. J. Approx. Reason., vol. 27, pp. 143-164, Aug. 2001.\n[163] E. Canti-Paz, \"Feature subset selection by estimation of distribution algorithms,\" in Proc. 4th Annu. Conf. Genet. Evol. Comput., 2002, pp. 303-310.\n[164] G. Neuman and D. Cairns, \"Applying a hybrid targeted estimation of distribution algorithm to feature selection problems,\" in Proc. 5th Int. Joint Conf. Comput. Intell., 2013, pp. 136-143.\n[165] C. Bielza, V. Robles, and P. Larrañaga, \"Estimation of distribution algorithms as logistic regression regularizers of microarray classifiers,\" Methods Inf. Med., vol. 48, no. 3, pp. 236-241, 2009.\n[166] S. Maza and M. Tonaltria, \"Feature selection for intrusion detection using new multi-objective estimation of distribution algorithms,\" Appl. Intell., vol. 49, pp. 4237-4257, May 2019.\n[167] H. Chen, S. Yuan, and K. Jiang, \"Fitness approximation in estimation of distribution algorithms for feature selection,\" in Advances in Artificial Intelligence (Lecture Notes in Computer Science 3809), Heidelberg, Germany: Springer, 2005, pp. 904-909.\n[168] T. Sorensen, \"A method for establishing groups of equal amplitude in plant sociology based on similarity of species contents and its application to analyses of the vegetation on Danish commons,\" Biologiske Skrifter, vol. 5, pp. 1-34, 1948.\n[169] J. Fan, \"OPE-HCA: An optimal probabilistic estimation approach for hierarchical clustering algorithm,\" Neural Comput. Appl., vol. 31, pp. 2095-2105, Jul. 2019.\n[170] E. W. Forgy, \"Cluster analysis of multivariate data: Efficiency versus interpretability of classification,\" Biometrics, vol. 21, no. 3, pp. 768-769, 1965.\n[171] J. Roure, P. Larrañaga, and R. Sangüesa, \"An empirical comparison between $k$-means, GAs and EDAs in partitional clustering,\" in Estimation of Distribution Algorithms A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., pp. 343-360, 2002.\n[172] L. Kaufman, and P. J. Rousseeuw, \"Clustering by means of medoids,\" in Statistical Data Analysis Based on the Lq Norm and Related Methods. Amsterdam, The Netherlands: North-Holland, 1997, pp. 405-416.\n[173] H. E. L. Cagnini, R. C. Barros, C. V. Quevedo, and M. P. Basgalupp, \"Medoid-based data clustering with estimation of distribution algorithms,\" in Proc. 31st Annu. ACM Symp. Appl. Comput., 2016, pp. 112-115.\n[174] B. J. Frey and D. Dueck, \"Clustering by passing messages between data points,\" Science, vol. 315, no. 5814, pp. 972-976, 2007.\n[175] R. Santana, C. Bielza, and P. Larrañaga, \"Affinity propagation enhanced by estimation of distribution algorithms,\" in Proc. Genet. Evol. Conf., 2011, pp. 331-338.\n[176] H. E. L. Cagnini, and R. C. Barros, \"PASCAL: An EDA for parameterless shape-independent clustering,\" in Proc. IEEE Congr. Evol. Comput., 2016, pp. 3434-3440.\n[177] A. S. G. Meiguins, R. C. Limão, B. S. Meiguins, F. S. Samuel Jr., and A. A. Freitas, \"AutoClustering: An estimation of distribution algorithm for the automatic generation of clustering algorithms,\" in Proc. IEEE World Congr. Comput. Intell., 2012, pp. 1-7.\n[178] A. P. Demopter, N. M. Land, and D. B. Rubin, \"Maximum likelihood from incomplete data via the EM algorithm,\" J. Royal Stat. Soc. B, vol. 39, no. 1, pp. 1-38, 1977.\n[179] S. Lauritzen, \"The EM algorithm for graphical association models with missing data,\" Comput. Stat. Data Anal., vol. 19, pp. 191-201, Feb. 1995.\n[180] J. M. Peña, J. A. Lozano, and P. Larrañaga, \"Unsupervised learning of Bayesian networks via estimation of distribution algorithms: An application to gene expression data clustering,\" Int. J. Uncertainty, Fuzziness Knowl. Based Syst., vol. 12, pp. 63-82, Jan. 2004.\n[181] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction, Cambridge, MA, USA: MIT Press, 1998.\n[182] H. Handa and T. Nishimura, \"Solving reinforcement learning problems by using estimation of distribution algorithms,\" in Proc. 2nd Int. Conf. Soft Comput. 9th Intell. Syst. Int. Symp. Adv. Intell. Syst., 2008, pp. 676-681.\n[183] J. Lafferty, A. McCallum, and F. C. N. Pereira, \"Conditional random fields: Probabilistic models for segmenting and labeling sequence data,\" in Proc. 19th Int. Conf. Mach. Learn., 2001, pp. 282-289.\n[184] V. Mnih et al., \"Human-level control through deep reinforcement learning,\" Nature, vol. 518, pp. 529-533, Feb. 2015.\n[185] Y. Du, J.-Q. Li, X.-L. Chen, P.-Y. Duan, and Q.-K. Pan, \"Knowledgebased reinforcement learning and estimation of distribution algorithm for flexible job shop scheduling problem,\" IEEE Trans. Emerg. Topics Comput. Intell., vol. 7, no. 4, pp. 1036-1050, Aug. 2023.\n[186] S. L. Lauritzen and D. J. Spiegelhalter, \"Local computations with probabilities on graphical structures and their application to expert systems,\" J. Royal Stat. Soc. B, Methodol., vol. 50, no. 2, pp. 157-224, 1988.\n[187] G. F. Cooper, \"The computational complexity of probabilistic inference using Bayesian belief networks,\" Artif. Intell., vol. 42, nos. 2-3, pp. 393-405, 1990.\n[188] P. Larrañaga, C. M. H. Kuijpers, M. Poza, and R. H. Murga, \"Decomposing Bayesian networks: Triangulation of the moral graph with genetic algorithms,\" Stat. Comput., vol. 7, no. 1, pp. 19-34, 1997.\n[189] T. Romero and P. Larrañaga, \"Triangulation of Bayesian networks with recursive estimation of distribution algorithms,\" Int. J. Approx. Reason., vol. 50, no. 3, pp. 472-484, 2009.\n[190] L. M. de Campos, J. A. Gámez, P. Larrañaga, S. Moral, and T. Romero, \"Partial abductive inference in Bayesian networks: An empirical comparison between GAs and EDAs,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., pp. 323-341, 2002.\n[191] R. Blanco, I. Inza, and P. Larrañaga, \"Learning Bayesian networks in the space of structures by estimation of distribution algorithms,\" Int. J. Intell. Syst., vol. 18, no. 2, pp. 205-220, 2003.\n[192] G. Thibault, S. Bonnevay, and A. Aussem, \"Learning Bayesian network structures by estimation of distribution algorithms: An experimental analysis,\" in Proc. IEEE Int. Conf. Digital Inf. Manag., 2007, pp. 127-132.\n[193] D. W. Kim, S. Ko, and B. Y. Kang, \"Structure learning of Bayesian networks by estimation of distribution algorithms with transpose mutation,\" J. Appl. Res. Technol., vol. 11, no. 4, pp. 586-596, 2013.\n[194] S. Fukuda, Y. Yamanaka, and T. Yoshihiro, \"A probability-based evolutionary algorithm with mutations to learn Bayesian network,\" Int. J. Artif. Intell. Interact. Multimedia, vol. 3, no. 1, pp. 7-13, 2014.\n[195] T. Romero, P. Larrañaga, and B. Sierra, \"Learning Bayesian networks in the space of orderings with estimation of distribution algorithms,\" Int. J. Pattern Recognit. Artif. Intell., vol. 18, no. 4, pp. 607-625, 2004.\n[196] L. Rabiner and B. Juang, \"An introduction to hidden Markov models,\" IEEE ASSP Mag., vol. 3, no. 1, pp. 4-16, Jan. 1986.\n[197] B. Maxwell and S. Anderson, \"Training hidden Markov models using population-based learning,\" in Proc. 1st Annu. Genet. Evol. Comput. Conf., vol. 1, 1999, pp. 944-950.\n[198] I. Inza, M. Merino, P. Larrañaga, J. Quiroga, B. Sierra, and M. Giralà, \"Feature subset selection by genetic algorithms and estimation of distribution algorithms: A case study in the survival of cirrhotic patients treated with TIPS,\" Artif. Intell. Med., vol. 23, no. 2, pp. 187-205, 2001.\n\n[199] R. Armañanzas et al., \"Peakbin selection in mass spectrometry data using a consensus approach with estimation of distribution algorithms,\" IEEE/ACM Trans. Comput. Biol. Bioinf., vol. 8, no. 3, pp. 760-774, May/Jun. 2011.\n[200] Y. Saeys, S. Degroeve, D. Aeyels, Y. van de Peer, and P. Rouzé, \"Fast feature selection using a simple estimation of distribution algorithm: A case study on splice site prediction,\" Bioinformatics, vol. 19, no. 2, pp. II179-II188, 2003.\n[201] M. Ayodele, \"Application of estimation of distribution algorithm for feature selection,\" in Proc. 19th Genet. Evol. Comput. Conf., 2019, pp. 43-44.\n[202] C. Cano, F. García, F. J. López, and A. Blanco, \"Intelligent system for the analysis of microarray data using principal components and estimation of distribution algorithms,\" Expert Syst. Appl., vol. 36, no. 3, pp. 4654-4663, 2009.\n[203] H. Handa, \"EDA-RL: Estimation of distribution algorithms for reinforcement learning problems,\" in Proc. 11th Annu. Conf. Genet. Evol. Comput., 2009, pp. 405-412.\n[204] N. K. Kitson, A. C. Constantinou, Z. Guo, Y. Liu, and K. Chobtham, \"A survey of Bayesian network structure learning,\" Artif. Intell. Rev., vol. 56, pp. 8721-8814, Jan. 2023.\n[205] D. Atienza, C. Bielza, and P. Larrañaga, \"Semiparametric Bayesian networks,\" Inf. Sci., vol. 584, pp. 564-582, Jan. 2022.\n[206] D. Atienza, P. Larrañaga, and C. Bielza, \"Hybrid semiparametric Bayesian networks,\" TEST, vol. 31, pp. 299-327, Jun. 2022.\n[207] V. P. Soloviev, C. Bielza, and P. Larrañaga, \"Semiparametric estimation of distribution algorithms for continuous optimization,\" IEEE Trans. Evol. Comput., early access, Jun. 29, 2023, doi: 10.1109/TEVC.2023.3290670.\n[208] J. Ceberio, B. Doerr, C. Witt, and V. P. Soloviev, \"Estimation-of-distribution algorithms: Theory and applications,\" Dagstuhl Rep., vol. 12, no. 5, pp. 17-36, 2022.\n[209] G. Ochoa, K. M. Malan, and C. Blum, \"Search trajectory networks: A tool for analysing and visualising the behaviour of metaheuristics,\" Appl. Soft Comput., vol. 109, Sep. 2021, Art. no. 107492.\n[210] H. Borchani, G. Varando, C. Bielza, and P. Larrañaga, \"A survey on multi-output regression,\" in Wiley Interdisciplinary Reviews-Data Mining and Knowledge Discovery, vol. 5. Hoboken, NJ, USA: Wiley, 2015, pp. 216-233.\n[211] J. A. Lozano and P. Larrañaga, \"Applying genetic algorithms to search for the best hierarchical clustering of a dataset,\" Pattern Recognit. Lett., vol. 20, no. 9, pp. 911-918, 1999.\n[212] J. A. Castellanos-Garzón, C. A. García, and L. A. Miguel-Quintales, \"An evolutionary hierarchical clustering method with a visual validation tool,\" in Proc. Int. Work Conf. Artif. Neural Netw., 2009, pp. 367-374.\n![img-9.jpeg](img-9.jpeg)\n\nPedro Larrañaga (Senior Member, IEEE) received the M.Sc. degree in mathematics (statistics) from the University of Valladolid, Valladolid, Spain, in 1981, and the Ph.D. degree in computer science from the University of the Basque Country, Bilbo, Spain, in 1995 (Excellence Award).\n\nHe is a Professor of Computer Science and Artificial Intelligence with the Universidad Politécnica de Madrid, Madrid, Spain. He has published over 200 papers in high-impact factor journals, and he has supervised over 30 Ph.D. theses. His research interests include the areas of probabilistic graphical models, metaheuristics for optimization, classification models, and real applications, such as biomedicine, bioinformatics, neuroscience, industry 4.0, and sports.\n\nProf. Larrañaga received the 2013 Spanish National Prize in Computer Science, the Spanish Association for Artificial Intelligence Prize in 2018, and the 2020 Machine Learning Award from Amity University, India. He has been a Fellow of the European Association for Artificial Intelligence since 2012, the Academia Europaea since 2018, and the Asia-Pacific Artificial Intelligence Association since 2021, a member of the Jakiunde, the Academy of Sciences, Arts, and Letters of the Basque Country since 2022, and an ELLIS Fellow since 2023.\n![img-10.jpeg](img-10.jpeg)\n\nConcha Bielza (Senior Member, IEEE) received the M.Sc. degree in mathematics from the Universidad Complutense de Madrid, Madrid, Spain, in 1989, and the Ph.D. degree in computer science from the Universidad Politécnica de Madrid, Madrid, in 1996 (Extraordinary Doctorate Award).\n\nShe is a Professor of Statistics and Operations Research with the Artificial Intelligence Department, Universidad Politécnica de Madrid. She has published more than 150 papers in impact factor journals and has supervised 21 Ph.D. theses. Her research interests are primarily in the areas of probabilistic graphical models, decision analysis, metaheuristics for optimization, machine learning, anomaly detection, and real applications, such as biomedicine, bioinformatics, neuroscience, and industry.\n\nProf. Bielza was awarded the 2014 UPM Research Prize and the 2020 Machine Learning Award from Amity University, India. She has been an ELLIS Fellow since 2023.",
    "references": [
      {
        "ref_id": "1",
        "text": "Y. Saeys, I. Inza, and P. Larrañaga, \"A review of feature selection techniques in bioinformatics,\" Bioinformatics, vol. 23, no. 19, pp. 2507-2517, 2007."
      },
      {
        "ref_id": "2",
        "text": "H. Sharp, \"Cardinality of finite topologies,\" J. Combinatorial Theory, vol. 5, pp. 82-86, Jul. 1968."
      },
      {
        "ref_id": "3",
        "text": "R. W. Robinson, \"Counting unlabeled acyclic digraphs,\" in Combinatorial Mathematics (Lecture Notes in Mathematics), vol. 622. Heidelberg, Germany: Springer, 1997, pp. 28-42."
      },
      {
        "ref_id": "4",
        "text": "R. E. Tarjan and M. Yannakakis, \"Simple linear-time algorithms to test chordality of graphs, test acyclicity of hypergraphs, and selectively reduce acyclic hypergraphs,\" SIAM J. Comput., vol. 13, no. 3, pp. 566-578, 1984."
      },
      {
        "ref_id": "5",
        "text": "T. Minka, \"Algorithms for maximum-likelihood logistic regression,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. 758, 2001."
      },
      {
        "ref_id": "6",
        "text": "D. E. Rumelhart, G. R. Hinton, and R. J. Williams, \"Learning representations by back-propagation errors,\" Nature, vol. 323, pp. 533-536, Oct. 1986."
      },
      {
        "ref_id": "7",
        "text": "J. H. Holland, Adaptation in Natural and Artificial Systems. Ann Arbor, MI, USA: Univ. Michigan Press, 1975."
      },
      {
        "ref_id": "8",
        "text": "D. E. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Learning. Boston, MA, USA: Wesley, 1989."
      },
      {
        "ref_id": "9",
        "text": "M. Dorigo and T. Stützle, Ant Colony Optimization. Cambridge, MA, USA: MIT Press, 2004."
      },
      {
        "ref_id": "10",
        "text": "R. C. Eberhart and J. Kennedy, Swarm Intelligence. Burlington, MA, USA: Morgan Kaufmann, 2001."
      },
      {
        "ref_id": "11",
        "text": "P. Larrañaga and J. A. Lozano, Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., 2002."
      },
      {
        "ref_id": "12",
        "text": "R. Storn and K. Price, \"Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces,\" J. Global Optim., vol. 11, no. 4, pp. 341-359, 1997."
      },
      {
        "ref_id": "13",
        "text": "L. J. Fogel, \"Autonomous automata,\" Ind. Res., vol. 4, no. 2, pp. 14-19, 1962."
      },
      {
        "ref_id": "14",
        "text": "J. R. Koza, Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge, MA, USA: MIT Press, 1992."
      },
      {
        "ref_id": "15",
        "text": "I. Rechenberg, Evolutionstrategie: Optimierung Technischer Systeme Nach Prinzipien der Biologischen Evolution. Stuttgart, Germany: Fromman-Holzboog, 1973."
      },
      {
        "ref_id": "16",
        "text": "M. S. Krejca and C. Witt, \"Theory of estimation-of-distribution algorithms,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer, 2020, pp. 405-442."
      },
      {
        "ref_id": "17",
        "text": "B. Xue, M. Zhang, W. N. Browne, and X. Yao, \"A survey on evolutionary computation approaches to feature selection,\" IEEE Trans. Evol. Comput., vol. 20, no. 4, pp. 606-626, Aug. 2016."
      },
      {
        "ref_id": "18",
        "text": "B. Badhon, M. M. Xabit, S. Xu, and M. Kabir, \"A survey on association rule mining based on evolutionary computation,\" Int. J. Comput. Appl., vol. 41, no. 1, pp. 1-11, 2019."
      },
      {
        "ref_id": "19",
        "text": "A. Telikani, A. H. Gandomi, and A. Shahbahrami, \"A survey of evolutionary computation for association rule mining,\" Inf. Sci., vol. 524, pp. 318-352, Jul. 2020."
      },
      {
        "ref_id": "20",
        "text": "R. C. Barros, M. P. Basgalupp, A. C. P. L. F. de Carvalho, and A. A. Freitas, \"A survey of evolutionary algorithms for decision-tree induction,\" IEEE Trans. Syst., Man Cybern. C, Appl. Rev., vol. 42, no. 3, pp. 291-312, May 2012."
      },
      {
        "ref_id": "21",
        "text": "A. Darwish, A. E. Hassanien, and S. Das, \"A survey of swarm and evolutionary computing approaches for deep learning,\" Artif. Intell. Rev., vol. 53, no. 3, pp. 1767-1812, 2020."
      },
      {
        "ref_id": "22",
        "text": "Z.-H. Zhan, J.-Y. Li, and J. Zhang, \"Evolutionary deep learning: A survey,\" Neurocomputing, vol. 483, pp. 42-58, Apr. 2022."
      },
      {
        "ref_id": "23",
        "text": "N. Li, L. Ma, G. Yu, B. Xue, M. Zhang, and Y. Jin, \"Survey on evolutionary deep learning: Principles, algorithms, applications and open issues,\" 2022, arsiv2208.10658v1."
      },
      {
        "ref_id": "24",
        "text": "M. J. A. Hasan and S. Ramakrishnan, \"A survey: Hybrid evolutionary algorithms for cluster analysis,\" Artif. Intell. Rev., vol. 36, no. 3, pp. 179-204, 2011."
      },
      {
        "ref_id": "25",
        "text": "E. R. Hruschka, R. J. G. B. Campello, A. A. Freitas, and A. C. P. L. F. de Carvalho, \"A survey of evolutionary algorithms for clustering,\" IEEE Trans. Syst., Man Cybern. C, Appl. Rev., vol. 39, no. 2, pp. 133-155, Mar. 2009."
      },
      {
        "ref_id": "26",
        "text": "A. Mukhopadhyay, U. Maulik, and S. Bandyopadhyay, \"A survey of multiobjective evolutionary clustering,\" ACM Comput. Surveys, vol. 47, no. 4, pp. 1-46, 2015."
      },
      {
        "ref_id": "27",
        "text": "P. Larrañaga, H. Karshenas, C. Bielza, and R. Santana, \"A review on evolutionary algorithms in Bayesian network learning and inference tasks,\" Inf. Sci., vol. 233, pp. 109-125, Jun. 2013."
      },
      {
        "ref_id": "28",
        "text": "H. Al-Sahaf et al., \"A survey on evolutionary machine learning,\" J. Royal New Zealand, vol. 49, no. 2, pp. 205-228, 2019."
      },
      {
        "ref_id": "29",
        "text": "A. Mukhopadhyay, U. Maulik, S. Bandyopadhyay, and C. A. Coello-Coello, \"Survey of multiobjective evolutionary algorithms for data mining: Part I,\" IEEE Trans. Evol. Comput., vol. 18, no. 1, pp. 4-19, Feb. 2014."
      },
      {
        "ref_id": "30",
        "text": "A. Mukhopadhyay, U. Maulik, S. Bandyopadhyay, and C. A. Coello-Coello, \"Survey of multiobjective evolutionary algorithms for data mining: Part II,\" IEEE Trans. Evol. Comput., vol. 18, no. 1, pp. 20-35, Feb. 2014."
      },
      {
        "ref_id": "31",
        "text": "K.A. De Jong, Evolutionary Computation. A Unified Approach. Cambridge, MA, USA: MIT Press, 2006."
      },
      {
        "ref_id": "32",
        "text": "C. Darwin, The Origin of Species by Means of Natural Selection or the Preservation of Favoured Races in the Struggle for Life. London, U.K.: John Murray, 1859."
      },
      {
        "ref_id": "33",
        "text": "M. Pelikan, D. E. Goldberg, and F. Lobo, \"A survey of optimization by building and using probabilistic models,\" Comput. Optim. Appl., vol. 21, no. 1, pp. 5-20, 2002."
      },
      {
        "ref_id": "34",
        "text": "J. A. Lozano, P. Larrañaga, I. Inza, and E. Bengoetxea, Towards a New Evolutionary Computation. Advances in Estimation of Distribution Algorithms. Heidelberg, Germany: Springer, 2005."
      },
      {
        "ref_id": "35",
        "text": "M. Hauschild and M. Pelikan, \"An introduction and survey of estimation of distribution algorithms,\" Swarm Evol. Comput., vol. 1, no. 3, pp. 111-128, 2011."
      },
      {
        "ref_id": "36",
        "text": "R. Santana, J. A. Lozano, and P. Larrañaga, \"Research topics in discrete estimation of distribution algorithms based on factorizations,\" Memet. Comput., vol. 1, pp. 35-54, Mar. 2009."
      },
      {
        "ref_id": "37",
        "text": "P. Larrañaga, H. Karshenas, C. Bielza, and R. Santana, \"A review on probabilistic graphical models in evolutionary computation,\" $J$. Heurist., vol. 18, no. 5, pp. 795-819, 2012."
      },
      {
        "ref_id": "38",
        "text": "J. Ceberio, A. Mendiburu, and J. A. Lozano, \"A roadmap for solving optimization problems with estimation of distribution algorithms,\" Nat. Comput., 2022, doi: 10.1007/s11047-022-09913-2."
      },
      {
        "ref_id": "39",
        "text": "X. Qian, J. Yu, A. Zhao, Q. Liu, and R. Zhang, \"Decentralised estimation of distribution algorithm for parallel pumps based on log-linear model,\" Int. J. Smart Grid Green Commun., vol. 2, no. 1, pp. 70-85, 2020."
      },
      {
        "ref_id": "40",
        "text": "W. Dong, Y. Wang, and M. Zhou, \"A latent space-based estimation of distribution algorithm for large-scale global optimization,\" Soft Comput., vol. 23, pp. 4593-4615, Jul. 2019."
      },
      {
        "ref_id": "41",
        "text": "R. Santana, \"Estimation of distribution algorithms with Kikuchi approximations,\" Evol. Comput., vol. 13, no. 1, pp. 67-97, 2005."
      },
      {
        "ref_id": "42",
        "text": "S. Shakya and J. McCall, \"Optimization by estimation of distribution with DEUM framework based on Markov random fields,\" Int. J. Autom. Comput., vol. 4, no. 3, pp. 262-272, 2007."
      },
      {
        "ref_id": "43",
        "text": "S. Shakya and R. Santana, Markov Networks in Evolutionary Computation. Heidelberg, Germany: Springer, 2012."
      },
      {
        "ref_id": "44",
        "text": "E. Pira, \"Using Markov chain based estimation of distribution algorithm for model-based safety analysis of graph transformation,\" J. Comput. Sci. Technol., vol. 36, pp. 839-855, Jul. 2021."
      },
      {
        "ref_id": "45",
        "text": "M. Soto, Y. González-Fernández, and A. Ochoa, \"Modelling with copulas and vines in estimation of distribution algorithms,\" Investigación Operacional, vol. 36, no. 1, pp. 1-23, 2015."
      },
      {
        "ref_id": "46",
        "text": "T. K. Paul and H. Iba, \"Reinforcement learning estimation of distribution algorithm,\" in Genetic and Evolutionary Computation (Lecture Notes in Computer Science 2724). Heidelberg, Germany: Springer, 2003, pp. 1259-1270."
      },
      {
        "ref_id": "47",
        "text": "L. Martí, J. García, A. Berlanga, and J. M. Molina, \"Multi-objective optimization with an adaptive resonance theory-based estimation of distribution algorithm,\" Ann. Math. Artif. Intell., vol. 68, no. 4, pp. 247-273, 2013."
      },
      {
        "ref_id": "48",
        "text": "L. Martí, J. García, A. Berlanga, and J. M. Molina, \"MONEDA: Scalable multi-objective optimization with a neural network-based estimation of distribution algorithm,\" J. Global Optim., vol. 66, pp. 729-768, Mar. 2016."
      },
      {
        "ref_id": "49",
        "text": "L. Bao, X. Sun, D. Gong, and Y. Zhang, \"Multisource heterogeneous user-generated contents-driven interactive estimation of distribution algorithms for personalized search,\" IEEE Trans. Evol. Comput., vol. 26, no. 5, pp. 844-858, Oct. 2022."
      },
      {
        "ref_id": "50",
        "text": "M. Probst, F. Rothlauf, and J. Grahl, \"Scalability of using restricted Boltzmann machines for combinatorial optimization,\" Eue. J. Oper. Res., vol. 256, no. 2, pp. 368-383, 2017."
      },
      {
        "ref_id": "51",
        "text": "V. A. Shim, K. C. Tan, C. Y. Cheong, and J. Y. Chia, \"Enhancing the scalability of multi-objective optimization via restricted Boltzmann machine-based estimation of distribution algorithm,\" Inf. Sci., vol. 248, pp. 191-213, Nov. 2013."
      },
      {
        "ref_id": "52",
        "text": "M. Probst and F. Rothlauf, \"Harmless overfitting: Using denoising autoencoders in estimation of distribution algorithms,\" J. Mach. Learn. Res., vol. 21, no. 78, pp. 1-31, 2020."
      },
      {
        "ref_id": "53",
        "text": "S. Bhattacharjee, \"Variational autoencoder based estimation of distribution algorithms and applications to individual based ecosystem modelling using EcoSim,\" Ph.D. dissertation, Dept. Comput. Sci., Univ. Windsor, Windsor, ON, Canada, 2019."
      },
      {
        "ref_id": "54",
        "text": "J.-H. Jeong, E. Lee, J.-H. Lee, and C.W. Ahn, \"Multi-objective deep network-based estimation of distribution algorithm for music composition,\" IEEE Access, vol. 10, pp. 71973-71985, 2022."
      },
      {
        "ref_id": "55",
        "text": "M. Probst, \"Generative adversarial networks in estimation of distribution algorithms for combinatorial optimization,\" 2016, arXiv:1509.09235v2."
      },
      {
        "ref_id": "56",
        "text": "D. Cucci, L. Malagó, and M. Matteucci, \"Variable transformations in estimation of distribution algorithms,\" in Parallel Problem Solving from Nature (Lecture Notes in Computer Science 7491). Heidelberg, Germany: Springer, 2012, pp. 428-437."
      },
      {
        "ref_id": "57",
        "text": "C. González, J. A. Lozano, and P. Larrañaga, \"Analyzing the PBIL algorithm by means of discrete dynamical systems,\" Complex Syst., vol. 12, no. 4, pp. 465-479, 2001."
      },
      {
        "ref_id": "58",
        "text": "T. Chen, K. Tang, G. Chen, and X. Yao, \"Analysis of computational time of simple estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 14, no. 1, pp. 1-22, Feb. 2010."
      },
      {
        "ref_id": "59",
        "text": "B. Doerr and M. S. Krejca, \"A simplified run time analysis of the univariate marginal distribution algorithm on LeadingOnes,\" Theor. Comput. Sci. vol. 851, pp. 121-128, Jan. 2021."
      },
      {
        "ref_id": "60",
        "text": "C. González, J. A. Lozano, and P. Larrañaga, \"Mathematical modelling of UMDAc algorithm with tournament selection. Behaviour on linear and quadratic functions,\" Int. J. Approx. Reason., vol. 31, no. 4, pp. 313-340, 2002."
      },
      {
        "ref_id": "61",
        "text": "Q. Zhang and H. Mühlenbein, \"On the convergence of a class of estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 8, no. 2, pp. 127-136, Apr. 2004."
      },
      {
        "ref_id": "62",
        "text": "B. Doerr and W. Zheng, \"Sharp bounds for genetic drift in estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 2, no. 6, pp. 1140-1149, Dec. 2020."
      },
      {
        "ref_id": "63",
        "text": "J. Pearl, Probabilistic Reasoning in Intelligent Systems. Burlington, MA, USA: Morgan Kaufmann, 1988."
      },
      {
        "ref_id": "64",
        "text": "D. Koller and N. Friedman, Probabilistic Graphical Models: Principles and Techniques. Cambridge, MA, USA: MIT Press, 2009."
      },
      {
        "ref_id": "65",
        "text": "M. Maathuis, M. Drton, S. Lauritzen, and M. Wainwright, Handbook of Graphical Models. Boca Raton, FL, USA: CRC Press, 2019."
      },
      {
        "ref_id": "66",
        "text": "C. Bielza and P. Larrañaga, Data-Driven Computational Neuroscience. Machine Learning and Statistical Models. Cambridge, U.K.: Cambridge Univ. Press, 2020."
      },
      {
        "ref_id": "67",
        "text": "R. Shachter and C. Kenley, \"Gaussian influence diagrams,\" Manag. Sci., vol. 35, no. 5, pp. 527-550, 1989."
      },
      {
        "ref_id": "68",
        "text": "D. Geiger and D. Heckerman, \"Learning Gaussian networks,\" in Proc. 10th Int. Conf. Uncertainty Artif. Intell., 1994, pp. 235-243."
      },
      {
        "ref_id": "69",
        "text": "R. Neapolitan, Learning Bayesian Networks. Upper Saddle River, NJ, USA: Prentice Hall, 2003."
      },
      {
        "ref_id": "70",
        "text": "R. Daly, Q. Shen, and S. Aitken, \"Learning Bayesian networks: Approaches and issues,\" Knowl. Eng. Rev., vol. 26, no. 2, pp. 99-157, 2011."
      },
      {
        "ref_id": "71",
        "text": "M. Scanagatta, A. Salmerón, and F. Stella, \"A survey on Bayesian network structure learning from data,\" Progr. Artif. Intell., vol. 8, pp. 425-439, May 2019."
      },
      {
        "ref_id": "72",
        "text": "O. Spirtes and C. Glymour, \"An algorithm FOS fast recovey of sparse causal graphs,\" Social Sci. Comput. Rev., vol. 90, no. 1, pp. 62-72, 1991."
      },
      {
        "ref_id": "73",
        "text": "H. Akaike, \"A new look at the statistical model identification,\" IEEE Trans. Autom. Control, vol. 19, no. 6, pp. 716-723, Dec. 1974."
      },
      {
        "ref_id": "74",
        "text": "G. Schwarz, \"Estimating the dimension of a model,\" Ann. Stat., vol. 6, no. 2, pp. 461-464, 1978."
      },
      {
        "ref_id": "75",
        "text": "G. F. Cooper and E. Herskovits, \"A Bayesian method for the induction of probabilistic networks from data,\" Mach. Learn., vol. 9, pp. 309-347, Oct. 1992."
      },
      {
        "ref_id": "76",
        "text": "D. Heckerman, D. Geiger, and D. M. Chickering, \"Learning Bayesian networks: The combination of knowledge and statistical data,\" Mach. Learn., vol. 20, pp. 197-243, Sep. 1995."
      },
      {
        "ref_id": "77",
        "text": "M. Henrion, \"Propagating uncertainty in Bayesian networks by probabilistic logic sampling,\" in Uncertainty in Artificial Intelligence, vol. 2. Amsterdam, The Netherlands: North-Holland, 1988, pp. 149-163."
      },
      {
        "ref_id": "78",
        "text": "R. M. Fung and K. C. Chang, \"Weighing and integrating evidence for stochastic simulation in Bayesian networks,\" in Uncertainty in Artificial Intelligence, vol. 5. Amsterdam, The Netherlands: North-Holland, 1990, pp. 209-220."
      },
      {
        "ref_id": "79",
        "text": "J. Pearl, \"Evidential reasoning using stochastic simulation of causal models,\" Artif. Intell., vol. 32, no. 2, pp. 245-257, 1987."
      },
      {
        "ref_id": "80",
        "text": "Q. Dang, W. Gao, and M. Gong, \"An efficient mixture sampling model for Gaussian estimation of distribution algorithm,\" Inf. Sci., vol. 608, pp. 1157-1182, Aug. 2022."
      },
      {
        "ref_id": "81",
        "text": "T. Miquêlez, E. Bengoetxea, and P. Larrañaga, \"Evolutionary computation based on Bayesian classifiers,\" Int. J. Appl. Math. Comput. Sci., vol. 14, pp. 101-115, Jan. 2004."
      },
      {
        "ref_id": "82",
        "text": "H. Karshenas, R. Santana, C. Bielza, and P. Larrañaga, \"Multiobjective estimation of distribution algorithm based on joint modeling of objectives and variables,\" IEEE Trans. Evol. Comput., vol. 18, no. 4, pp. 519-542, Aug. 2014."
      },
      {
        "ref_id": "83",
        "text": "P. Larrañaga, R. Etxeberria, J. A. Lozano, and J. M. Peña, \"Optimization in continuous domains by learning and simulation of Gaussian networks,\" in Proc. Genet. Evol. Comput. Conf. Workshop Program, 2000, pp. 201-204."
      },
      {
        "ref_id": "84",
        "text": "P. A. N. Bosman and J. Grahl, \"Matching inductive search bias and problem structure in continuous estimation-of-distribution algorithms,\" Eur. J. Oper. Res., vol. 185, no. 3, pp. 1246-1264, 2008."
      },
      {
        "ref_id": "85",
        "text": "H. Mühlenbein and G. Paaß, \"From recombination of genes to the estimation of distributions. I. Binary parameters,\" in Parallel Problem Solving From Nature (Lecture Notes in Computer Science 1411). Heidelberg, Germany: Springer, 1996, pp. 178-187."
      },
      {
        "ref_id": "86",
        "text": "S. Baluja, \"Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-94-163, 1994."
      },
      {
        "ref_id": "87",
        "text": "M. Sebag and A. Ducoulombier, \"Extending population-based incremental learning to continuous spaces,\" in Parallel Problem Solving from Nature (Lecture Notes in Computer Science 1498). Heidelberg, Germany: Springer, 1998, pp. 418-427."
      },
      {
        "ref_id": "88",
        "text": "G. Harik, F. G. Lobo, and D. E. Goldberg, \"The compact genetic algorithm,\" in Proc. IEEE Conf. Evol. Comput., 1998, pp. 523-528."
      },
      {
        "ref_id": "89",
        "text": "B. Doerr and M. Dufay, \"General univariate estimation-of-distribution algorithms,\" in Proc. 17th Int. Conf. Parallel Problem Solving Nat., 2022, pp. 470-484."
      },
      {
        "ref_id": "90",
        "text": "J. S. De Bonet, C. L. Isbell, and P. Viola, \"MIMIC: Finding optima by estimating probability densities,\" in Proc. Adv. Neural Inf. Process. Syst., vol. 9, 1997, pp. 424-430."
      },
      {
        "ref_id": "91",
        "text": "S. Baluja and S. Davies, \"Combining multiple optimization runs with optimal dependency trees,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-97-157, 1997."
      },
      {
        "ref_id": "92",
        "text": "M. Pelikan and H. Mühlenbein, \"The bivariate marginal distribution algorithm,\" Advances in Soft Computing-Engineering Design and Manufacturing. London, U.K.: Springer, 1999, pp. 521-535."
      },
      {
        "ref_id": "93",
        "text": "R. Etxeberria and P. Larrañaga, \"Global optimization using Bayesian networks,\" in Proc. 2nd Int. Symp. Artif. Intell., 1999, pp. 332-339."
      },
      {
        "ref_id": "94",
        "text": "P. Larrañaga, R. Etxeberria, J. A. Lozano, and J. M. Peña, \"Combinatorial optimization by learning and simulation of Bayesian networks,\" in Proc. 16th Conf. Uncertainty Artif. Intell., 2000, pp. 343-352."
      },
      {
        "ref_id": "95",
        "text": "W. Dong, T. Chen, P. Tino, and X. Yao, \"Scaling up estimation of distribution algorithms for continuous optimization,\" IEEE Trans. Evol. Comput., vol. 17, no. 6, pp. 797-822, Dec. 2013."
      },
      {
        "ref_id": "96",
        "text": "M. Pelikan, D. E. Goldberg, and E. Cantú-Paz, \"BOA: The Bayesian optimization algorithm,\" in Proc. Genet. Evol. Comput. Conf., vol. 1, 1999, pp. 525-532."
      },
      {
        "ref_id": "97",
        "text": "H. Mühlenbein and T. Mahning, \"FDA-A scalable evolutionary algorithm for the optimization of additively decomposed functions,\" Evol. Comput., vol. 7, no. 4, pp. 353-376, Dec. 1999."
      },
      {
        "ref_id": "98",
        "text": "W. Dong and X. Yao, \"Unified eigen analysis on multivariate Gaussian based estimation of distribution algorithms,\" Inf. Sci., vol. 178, no. 15, pp. 3000-3023, 2008."
      },
      {
        "ref_id": "99",
        "text": "Y. Liang, Z. Ren, X. Yao, Z. Feng, A. Chen, and W. Guo, \"Enhancing Gaussian estimation of distribution algorithm by exploiting evolution direction with archive,\" IEEE Trans. Cybern., vol. 50, no. 1, pp. 140-152, Jan. 2020."
      },
      {
        "ref_id": "100",
        "text": "H. Xu, J. Yang, P. Jia, and Y. Ding, \"Effective structure learning for estimation of distribution algorithms via L1-regularized Bayesian networks,\" Int. J. Adv. Robot. Syst., vol. 10, no. 1, p. 17, 2013."
      },
      {
        "ref_id": "101",
        "text": "H. Karshenas, R. Santana, C. Bielza, and P. Larrañaga, \"Regularized continuous estimation of distribution algorithms,\" Appl. Soft Comput., vol. 13, no. 5, pp. 2412-2432, 2013."
      },
      {
        "ref_id": "102",
        "text": "P. A. N. Bosman and D. Thierens, \"IDEAs based on the normal kernels probability density function,\" Dept. Comput. Sci., Utrecht Univ., Utrecht, The Netherlands, Rep. UU-CS-2000-11, 2000."
      },
      {
        "ref_id": "103",
        "text": "P. A. N. Bosman and D. Thierens, \"Multi-objective optimization with diversity preserving mixture-based iterated density estimation evolutionary algorithms,\" Int. J. Approx. Reason., vol. 31, no. 3, pp. 259-289, 2002."
      },
      {
        "ref_id": "104",
        "text": "J. M. Peña, J. A. Lozano, and P. Larrañaga, \"Globally multimodal problem optimization via an estimation of distribution algorithm based on unsupervised learning of Bayesian networks,\" Evol. Comput., vol. 13, no. 1, pp. 43-66, 2005."
      },
      {
        "ref_id": "105",
        "text": "G. Harik, \"Linkage learning via probabilistic modelling in the ECGA,\" Univ. Illinois Urbana-Champaign, Champaign, IL, USA, Rep. 99010, 1999."
      },
      {
        "ref_id": "106",
        "text": "C. A. Coello-Coello, G. B. Lamont, and D. A. Van Veldhuizen, Evolutionary Algorithms for Solving Multi-Objective Problems. New York, NY, USA: Springer, 2007."
      },
      {
        "ref_id": "107",
        "text": "R. Santana, C. Bielza, J. A. Lozano, and P. Larrañaga, \"Mining probabilistic models learned by EDAs in the optimization of multi-objective problems,\" in Proc. 11th Annu. Conf. Genet. Evol. Comput., 2009, pp. 445-452."
      },
      {
        "ref_id": "108",
        "text": "M. Costa and E. Minsci, \"MOPED: A multi-objective Parzen-based estimation of distribution algorithm for continuous problems,\" in Evolutionary Multi-Criterion Optimization (Lecture Notes in Computer Science 2632). Heidelberg, Germany: Springer, 2003, pp. 282-294."
      },
      {
        "ref_id": "109",
        "text": "E. Bergsetsea, P. Larrañaga, C. Bielza, and J. A. Fernández del Pozo, \"Optimal row and column ordering to improve table interpretation using estimation of distribution algorithms,\" J. Heurist., vol. 17, no. 5, pp. 567-588, 2011."
      },
      {
        "ref_id": "110",
        "text": "J. Bertin, Graphics and Graphic Information Processing. Berlin, Germany: Walter de Gruyter, 1981."
      },
      {
        "ref_id": "111",
        "text": "H. Walker and W. Durost, Statistic Tables: Their Structure and Use, Bureau of Publications, Columbia Univ., New York, NY, USA, 1936."
      },
      {
        "ref_id": "112",
        "text": "J. L. Flores, I. Inza, and P. Larrañaga, \"Wrapper discretization by means of estimation of distribution algorithms,\" Intell. Data Anal. J., vol. 11, no. 5, pp. 525-546, 2007."
      },
      {
        "ref_id": "113",
        "text": "R. Agrawal and R. Srikant, \"Fast algorithms for mining association rules in large databases,\" in Proc. 20th Int. Conf. Very Large Data Bases, 1994, pp. 487-499."
      },
      {
        "ref_id": "114",
        "text": "X. Zhang, B. Xue, G. Sui, and J. Cui, \"Association rule mining based on estimation of distribution algorithm for blood indices,\" in Proc. Int. Conf. Comput. Netw., Electron. Autom., 2017, pp. 59-65."
      },
      {
        "ref_id": "115",
        "text": "X. Li, S. Mabu, H. Zhou, K. Shimada, and K. Hirasawa, \"Genetic network programming with estimation of distribution algorithms for class association rule mining in traffic prediction,\" in Proc. IEEE Congr. Evol. Comput., 2010, pp. 1-8."
      },
      {
        "ref_id": "116",
        "text": "E. Fix and J. L. Hodges, \"Discriminatory analysis-non parametric discrimination: Consistency properties,\" USAF School Aviation Med., Wright-Patterson AFB, OH, USA, Rep. 4, 1951."
      },
      {
        "ref_id": "117",
        "text": "I. Inza, P. Larrañaga, and B. Sierra, \"Feature weighting for nearest neighbour by EDAs,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad. Publ., 2002, pp. 295-311."
      },
      {
        "ref_id": "118",
        "text": "J. R. Quinlan, \"Induction of decision trees,\" Mach. Learn., vol. 1, no. 1, pp. 81-106, 1986."
      },
      {
        "ref_id": "119",
        "text": "H. E. L. Cagnini, R. C. Barros, and M. P. Basgalupp, \"Estimation of distribution algorithms for decision-tree induction,\" in Proc. Congr. Evol. Comput., 2017, pp. 2022-2029."
      },
      {
        "ref_id": "120",
        "text": "J. Holland, \"A mathematical framework for studying learning in classifier systems,\" Physica D, vol. 2, no. 1, pp. 307-317, 1986."
      },
      {
        "ref_id": "121",
        "text": "K. De Jong and W. Spears, \"Learning concept classification rules using genetic algorithms,\" in Proc. 12th Int. Joint Conf. Artif. Intell., 1991, pp. 651-656."
      },
      {
        "ref_id": "122",
        "text": "B. Sierra, E. A. Jiménez, I. Inza, and P. Larrañaga, \"Rule induction by estimation of distribution algorithms,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., 2002, pp. 313-322."
      },
      {
        "ref_id": "123",
        "text": "J. Yang, H. Xu, and P. Jia, \"Effective search for Pittsburgh learning classifier systems via estimation of distribution algorithms,\" Inf. Sci., vol. 198, pp. 100-117, Sep. 2012."
      },
      {
        "ref_id": "124",
        "text": "J. Yang, H. Xu, and P. Jia, \"Effective search for genetic-based machine learning systems via estimation of distribution algorithms and embedded feature reduction techniques,\" Neurocomputing, vol. 113, pp. 105-121, Aug. 2013."
      },
      {
        "ref_id": "125",
        "text": "L. DelaOssa, J. A. Gámez, and J. M. Puerta, \"Learning weighted linguistic fuzzy rules by using specifically-tailored hybrid estimation of distribution algorithms,\" Int. J. Approx. Reason., vol. 50, no. 3, pp. 541-560, 2009."
      },
      {
        "ref_id": "126",
        "text": "B.E. Boser, I. M. Guyon, and V. N. Vapnik, \"A training algorithm for optimal margin classifiers,\" in Proc. 5th Annu. Workshop Comput. Learn. Theory, 1992, pp. 144-152."
      },
      {
        "ref_id": "127",
        "text": "L.C. Padierna, M. Carpio, A. Rojas, H. Puga, R. Baltazar, and H. Fraire, \"Hyper-parameter tuning for support vector machines by estimation of distribution algorithms,\" in Nature-Inspired Design of Hybrid Intelligent Systems, vol. 667. Cham, Switzerland: Springer, 2017, pp. 787-800."
      },
      {
        "ref_id": "128",
        "text": "W. McCulloch and W. Pitts, \"A logical calculus of the ideas immanent in nervous activity,\" Bull. Math. Biophys., vol. 5, pp. 115-133, Dec. 1943."
      },
      {
        "ref_id": "129",
        "text": "S. Baluja, \"An empirical comparison of seven iterative and evolutionary function optimization heuristics,\" Carnegie Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-95-193, 1995."
      },
      {
        "ref_id": "130",
        "text": "M.R. Gallagher, \"Multi-layer perceptron error surfaces: Visualization, structure and modelling,\" Ph.D. dissertation, Comput. Sci. Electr. Eng., Univ. Queensland, Herston, QLD, Australia, 2000."
      },
      {
        "ref_id": "131",
        "text": "C. Cotta, E. Alba, R. Sagarna, and P. Larrañaga, \"Adjusting weights in artificial neural networks using evolutionary algorithms,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., 2002, pp. 361-377."
      },
      {
        "ref_id": "132",
        "text": "Y. Chen and A. Abraham, \"Estimation of distribution algorithms for optimization of neural networks for intrusion detection,\" Proc. 8th Int. Conf. Artif. Intell. Soft Comput., 2006, pp. 9-18."
      },
      {
        "ref_id": "133",
        "text": "Q. Li, Y. Du, Z. Liu, Z. Zhou, G. Lu, and Q. Chen, \"Drought prediction in the Yunnan-Guizhou plateau of China by coupling the estimation of distribution algorithm and the extreme learning machine,\" Nat. Hazards, vol. 113, pp. 1635-1661, May 2022."
      },
      {
        "ref_id": "134",
        "text": "E. Galić and M. Höhfeld, \"Improving the generalization performance of multi-layer-perceptrons with population-based incremental learning,\" in Parallel Problem Solving From Nature (Lecture Notes in Computer Science 1141). Heidelberg, Germany: Springer, 1996, pp. 740-750."
      },
      {
        "ref_id": "135",
        "text": "G. Holker and M. V. dos Santos, \"Toward an estimation of distribution algorithm for the evolution of artificial neural networks,\" in Proc. 3rd Conf. Comput. Sci. Softw. Eng., 2010, pp. 17-22."
      },
      {
        "ref_id": "136",
        "text": "E. Cantú-Paz, \"Pruning neural networks with distribution estimation algorithms,\" in Proc. Genet. Evol. Comput. Conf., 2003, pp. 790-800."
      },
      {
        "ref_id": "137",
        "text": "J. Peralta-Donate, X. Li, G. G. Sánchez, and A. S. de Miguel, \"Time series forecasting by evolving artificial neural networks with genetic algorithms, differential evolution and estimation of distribution algorithm,\" Neural Comput. Appl., vol. 22, pp. 11-20, Jan. 2013."
      },
      {
        "ref_id": "138",
        "text": "Y. Bengio, \"Learning deep architectures for AI,\" Found. Trends Mach. Learn., vol. 2, no. 1, pp. 1-127, 2009."
      },
      {
        "ref_id": "139",
        "text": "J.-Y. Li, Z.-H. Zhan, J. Xu, S. Kwong, and J. Zhang, \"Surrogateassisted hybrid-model estimation of distribution algorithm for mixed-variable hyperparameters optimization in convolutional neural networks,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 34, no. 5, pp. 2338-2352, May 2023."
      },
      {
        "ref_id": "140",
        "text": "O. G. Tolodano-López, J. Madera, H. González, and A. Simón-Cuevas, \"A hybrid method based on estimation of distribution algorithms to train convolutional neural networks for text categorization,\" Pattern Recognit. Lett., vol. 160, pp. 105-111, Aug. 2022."
      },
      {
        "ref_id": "141",
        "text": "Q. Xu, A. Liu, X. Yuan, Y. Song, C. Zhang, and Y. Li, \"Random mask-based estimation of the distribution algorithm for stacked autoencoder one-step pre-training,\" Comput. Ind. Eng., vol. 158, Aug. 2021, Art. no. 107400."
      },
      {
        "ref_id": "142",
        "text": "J. Berkson, \"Application of the logistic function to bio-assay,\" J. Amer. Stat. Assoc., vol. 39, no. 227, pp. 357-365, 1944."
      },
      {
        "ref_id": "143",
        "text": "V. Robles, C. Bielza, P. Larrañaga, S. González, and L. Ohno-Machado, \"Optimizing logistic regression coefficients for discrimination and calibration using estimation of distribution algorithms,\" TOP, vol. 16, no. 2, pp. 345-366, 2008."
      },
      {
        "ref_id": "144",
        "text": "C. Bielza, V. Robles, and P. Larrañaga, \"Regularized logistic regression without a penalty term: An application to cancer classification with microarray data,\" Expert Syst. Appl., vol. 38, no. 5, pp. 5110-5118, 2011."
      },
      {
        "ref_id": "145",
        "text": "M. L. Minsky, \"Step toward artificial intelligence,\" Proc. IRE, vol. JRPROC-49, no. 1, pp. 8-30, Jan. 1961."
      },
      {
        "ref_id": "146",
        "text": "N. Friedman, D. Geiger, and M. Goldszmidt, \"Bayesian network classifiers,\" Mach. Learn., vol. 50, nos. 1-2, pp. 95-125, 1997."
      },
      {
        "ref_id": "147",
        "text": "C. Bielza, and P. Larrañaga, \"Discrete Bayesian network classifiers,\" ACM Comput. Surveys, vol. 47, no. 1, 2014, Art. no. 5."
      },
      {
        "ref_id": "148",
        "text": "V. Robles, P. Larrañaga, J. M. Peña, E. Menasalvas, and M. S. Pérez, \"Interval estimation Naïve Bayes,\" in Advances in Intelligent Data Analysis (Lecture Notes in Computer Science 2810). Heidelberg, Germany: Springer, 2003, pp. 143-154."
      },
      {
        "ref_id": "149",
        "text": "M. Pazzani, \"Constructive induction of Cartesian product attributes,\" in Proc. Inf., Stat. Induct. Sci. Conf., 1996, pp. 66-77."
      },
      {
        "ref_id": "150",
        "text": "V. Robles et al., \"Bayesian networks multi-classifiers for protein secondary structure prediction,\" Artif. Intell. Med., vol. 31, no. 2, pp. 117-136, 2004."
      },
      {
        "ref_id": "151",
        "text": "D. H. Wolpert, \"Stacked generalization,\" Neural Netw., vol. 5, no. 2, pp. 241-259, 1992."
      },
      {
        "ref_id": "152",
        "text": "I. Mendialdua, A. Arruti, E. Jauregi, E. Lazkano, and B. Sierra, \"Classifier subset selection to construct multi-classifiers by means of estimation of distribution algorithms,\" Neurocomputing, vol. 157, pp. 46-60, Jul. 2015."
      },
      {
        "ref_id": "154",
        "text": "H. E. L. Cagnini, M. P. Basgalupp, and R. C. Barros, \"Increasing boosting effectiveness with estimation of distribution algorithms,\" in Proc. IEEE Congr. Evol. Comput., 2018, pp. 1-8."
      },
      {
        "ref_id": "155",
        "text": "H. Bunke, \"18 Parameter estimation in nonlinear regression models,\" in Handbook of Statistics, vol. 1. Amsterdam, The Netherlands: Elsevier, 1980, pp. 593-615."
      },
      {
        "ref_id": "156",
        "text": "L. M. Torres-Treviño, \"Symbolic regression using $\\alpha-\\beta$ operators and estimation of distribution algorithms: Preliminary results,\" in Proc. 13th Genet. Evol. Comput. Conf., 2011, pp. 647-654."
      },
      {
        "ref_id": "157",
        "text": "M. A. Sotelo-Figueroa, A. Hernández-Aguirre, A. Espinal, J. A. Soria-Alcaraz, and J. Ortiz-López, \"Symbolic regression by means of grammatical evolution with estimation distribution algorithms as search engine,\" in Fuzzy Logic Augmentation of Neural and Optimization Algorithms: Theoretical Aspects and Real Applications. Studies in Computational Intelligence, vol. 749. Cham, Switzerland: Springer, 2018, pp. 169-180."
      },
      {
        "ref_id": "158",
        "text": "D. Wittenberg and F. Rothlauf, \"Denoising autoencoder genetic programming for real-world symbolic regression,\" in Proc. Genet. Evol. Comput. Conf., 2022, pp. 612-614."
      },
      {
        "ref_id": "159",
        "text": "C. Jin and S.-W. Jin, \"Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms,\" Appl. Soft Comput., vol. 15, pp. 113-120, Feb. 2014."
      },
      {
        "ref_id": "160",
        "text": "P. M. Lewis, \"The characteristic selection problem in recognition systems,\" IRE Trans. Inf. Theory, vol. TIT-8, no. 2, pp. 171-178, Feb. 1962."
      },
      {
        "ref_id": "161",
        "text": "I. Inza, P. Larrañaga, R. Etxeberria, and B. Sierra, \"Feature subset selection by Bayesian network-based optimization,\" Artif. Intell., vol. 123, pp. 157-184, Oct. 2000."
      },
      {
        "ref_id": "162",
        "text": "I. Inza, P. Larrañaga, and B. Sierra, \"Feature subset selection by Bayesian networks: A comparison with genetic and sequential algorithms,\" Int. J. Approx. Reason., vol. 27, pp. 143-164, Aug. 2001."
      },
      {
        "ref_id": "163",
        "text": "E. Canti-Paz, \"Feature subset selection by estimation of distribution algorithms,\" in Proc. 4th Annu. Conf. Genet. Evol. Comput., 2002, pp. 303-310."
      },
      {
        "ref_id": "164",
        "text": "G. Neuman and D. Cairns, \"Applying a hybrid targeted estimation of distribution algorithm to feature selection problems,\" in Proc. 5th Int. Joint Conf. Comput. Intell., 2013, pp. 136-143."
      },
      {
        "ref_id": "165",
        "text": "C. Bielza, V. Robles, and P. Larrañaga, \"Estimation of distribution algorithms as logistic regression regularizers of microarray classifiers,\" Methods Inf. Med., vol. 48, no. 3, pp. 236-241, 2009."
      },
      {
        "ref_id": "166",
        "text": "S. Maza and M. Tonaltria, \"Feature selection for intrusion detection using new multi-objective estimation of distribution algorithms,\" Appl. Intell., vol. 49, pp. 4237-4257, May 2019."
      },
      {
        "ref_id": "167",
        "text": "H. Chen, S. Yuan, and K. Jiang, \"Fitness approximation in estimation of distribution algorithms for feature selection,\" in Advances in Artificial Intelligence (Lecture Notes in Computer Science 3809), Heidelberg, Germany: Springer, 2005, pp. 904-909."
      },
      {
        "ref_id": "168",
        "text": "T. Sorensen, \"A method for establishing groups of equal amplitude in plant sociology based on similarity of species contents and its application to analyses of the vegetation on Danish commons,\" Biologiske Skrifter, vol. 5, pp. 1-34, 1948."
      },
      {
        "ref_id": "169",
        "text": "J. Fan, \"OPE-HCA: An optimal probabilistic estimation approach for hierarchical clustering algorithm,\" Neural Comput. Appl., vol. 31, pp. 2095-2105, Jul. 2019."
      },
      {
        "ref_id": "170",
        "text": "E. W. Forgy, \"Cluster analysis of multivariate data: Efficiency versus interpretability of classification,\" Biometrics, vol. 21, no. 3, pp. 768-769, 1965."
      },
      {
        "ref_id": "171",
        "text": "J. Roure, P. Larrañaga, and R. Sangüesa, \"An empirical comparison between $k$-means, GAs and EDAs in partitional clustering,\" in Estimation of Distribution Algorithms A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., pp. 343-360, 2002."
      },
      {
        "ref_id": "172",
        "text": "L. Kaufman, and P. J. Rousseeuw, \"Clustering by means of medoids,\" in Statistical Data Analysis Based on the Lq Norm and Related Methods. Amsterdam, The Netherlands: North-Holland, 1997, pp. 405-416."
      },
      {
        "ref_id": "173",
        "text": "H. E. L. Cagnini, R. C. Barros, C. V. Quevedo, and M. P. Basgalupp, \"Medoid-based data clustering with estimation of distribution algorithms,\" in Proc. 31st Annu. ACM Symp. Appl. Comput., 2016, pp. 112-115."
      },
      {
        "ref_id": "174",
        "text": "B. J. Frey and D. Dueck, \"Clustering by passing messages between data points,\" Science, vol. 315, no. 5814, pp. 972-976, 2007."
      },
      {
        "ref_id": "175",
        "text": "R. Santana, C. Bielza, and P. Larrañaga, \"Affinity propagation enhanced by estimation of distribution algorithms,\" in Proc. Genet. Evol. Conf., 2011, pp. 331-338."
      },
      {
        "ref_id": "176",
        "text": "H. E. L. Cagnini, and R. C. Barros, \"PASCAL: An EDA for parameterless shape-independent clustering,\" in Proc. IEEE Congr. Evol. Comput., 2016, pp. 3434-3440."
      },
      {
        "ref_id": "177",
        "text": "A. S. G. Meiguins, R. C. Limão, B. S. Meiguins, F. S. Samuel Jr., and A. A. Freitas, \"AutoClustering: An estimation of distribution algorithm for the automatic generation of clustering algorithms,\" in Proc. IEEE World Congr. Comput. Intell., 2012, pp. 1-7."
      },
      {
        "ref_id": "178",
        "text": "A. P. Demopter, N. M. Land, and D. B. Rubin, \"Maximum likelihood from incomplete data via the EM algorithm,\" J. Royal Stat. Soc. B, vol. 39, no. 1, pp. 1-38, 1977."
      },
      {
        "ref_id": "179",
        "text": "S. Lauritzen, \"The EM algorithm for graphical association models with missing data,\" Comput. Stat. Data Anal., vol. 19, pp. 191-201, Feb. 1995."
      },
      {
        "ref_id": "180",
        "text": "J. M. Peña, J. A. Lozano, and P. Larrañaga, \"Unsupervised learning of Bayesian networks via estimation of distribution algorithms: An application to gene expression data clustering,\" Int. J. Uncertainty, Fuzziness Knowl. Based Syst., vol. 12, pp. 63-82, Jan. 2004."
      },
      {
        "ref_id": "181",
        "text": "R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction, Cambridge, MA, USA: MIT Press, 1998."
      },
      {
        "ref_id": "182",
        "text": "H. Handa and T. Nishimura, \"Solving reinforcement learning problems by using estimation of distribution algorithms,\" in Proc. 2nd Int. Conf. Soft Comput. 9th Intell. Syst. Int. Symp. Adv. Intell. Syst., 2008, pp. 676-681."
      },
      {
        "ref_id": "183",
        "text": "J. Lafferty, A. McCallum, and F. C. N. Pereira, \"Conditional random fields: Probabilistic models for segmenting and labeling sequence data,\" in Proc. 19th Int. Conf. Mach. Learn., 2001, pp. 282-289."
      },
      {
        "ref_id": "184",
        "text": "V. Mnih et al., \"Human-level control through deep reinforcement learning,\" Nature, vol. 518, pp. 529-533, Feb. 2015."
      },
      {
        "ref_id": "185",
        "text": "Y. Du, J.-Q. Li, X.-L. Chen, P.-Y. Duan, and Q.-K. Pan, \"Knowledgebased reinforcement learning and estimation of distribution algorithm for flexible job shop scheduling problem,\" IEEE Trans. Emerg. Topics Comput. Intell., vol. 7, no. 4, pp. 1036-1050, Aug. 2023."
      },
      {
        "ref_id": "186",
        "text": "S. L. Lauritzen and D. J. Spiegelhalter, \"Local computations with probabilities on graphical structures and their application to expert systems,\" J. Royal Stat. Soc. B, Methodol., vol. 50, no. 2, pp. 157-224, 1988."
      },
      {
        "ref_id": "187",
        "text": "G. F. Cooper, \"The computational complexity of probabilistic inference using Bayesian belief networks,\" Artif. Intell., vol. 42, nos. 2-3, pp. 393-405, 1990."
      },
      {
        "ref_id": "188",
        "text": "P. Larrañaga, C. M. H. Kuijpers, M. Poza, and R. H. Murga, \"Decomposing Bayesian networks: Triangulation of the moral graph with genetic algorithms,\" Stat. Comput., vol. 7, no. 1, pp. 19-34, 1997."
      },
      {
        "ref_id": "189",
        "text": "T. Romero and P. Larrañaga, \"Triangulation of Bayesian networks with recursive estimation of distribution algorithms,\" Int. J. Approx. Reason., vol. 50, no. 3, pp. 472-484, 2009."
      },
      {
        "ref_id": "190",
        "text": "L. M. de Campos, J. A. Gámez, P. Larrañaga, S. Moral, and T. Romero, \"Partial abductive inference in Bayesian networks: An empirical comparison between GAs and EDAs,\" in Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation. Amsterdam, The Netherlands: Kluwer Acad., pp. 323-341, 2002."
      },
      {
        "ref_id": "191",
        "text": "R. Blanco, I. Inza, and P. Larrañaga, \"Learning Bayesian networks in the space of structures by estimation of distribution algorithms,\" Int. J. Intell. Syst., vol. 18, no. 2, pp. 205-220, 2003."
      },
      {
        "ref_id": "192",
        "text": "G. Thibault, S. Bonnevay, and A. Aussem, \"Learning Bayesian network structures by estimation of distribution algorithms: An experimental analysis,\" in Proc. IEEE Int. Conf. Digital Inf. Manag., 2007, pp. 127-132."
      },
      {
        "ref_id": "193",
        "text": "D. W. Kim, S. Ko, and B. Y. Kang, \"Structure learning of Bayesian networks by estimation of distribution algorithms with transpose mutation,\" J. Appl. Res. Technol., vol. 11, no. 4, pp. 586-596, 2013."
      },
      {
        "ref_id": "194",
        "text": "S. Fukuda, Y. Yamanaka, and T. Yoshihiro, \"A probability-based evolutionary algorithm with mutations to learn Bayesian network,\" Int. J. Artif. Intell. Interact. Multimedia, vol. 3, no. 1, pp. 7-13, 2014."
      },
      {
        "ref_id": "195",
        "text": "T. Romero, P. Larrañaga, and B. Sierra, \"Learning Bayesian networks in the space of orderings with estimation of distribution algorithms,\" Int. J. Pattern Recognit. Artif. Intell., vol. 18, no. 4, pp. 607-625, 2004."
      },
      {
        "ref_id": "196",
        "text": "L. Rabiner and B. Juang, \"An introduction to hidden Markov models,\" IEEE ASSP Mag., vol. 3, no. 1, pp. 4-16, Jan. 1986."
      },
      {
        "ref_id": "197",
        "text": "B. Maxwell and S. Anderson, \"Training hidden Markov models using population-based learning,\" in Proc. 1st Annu. Genet. Evol. Comput. Conf., vol. 1, 1999, pp. 944-950."
      },
      {
        "ref_id": "198",
        "text": "I. Inza, M. Merino, P. Larrañaga, J. Quiroga, B. Sierra, and M. Giralà, \"Feature subset selection by genetic algorithms and estimation of distribution algorithms: A case study in the survival of cirrhotic patients treated with TIPS,\" Artif. Intell. Med., vol. 23, no. 2, pp. 187-205, 2001."
      },
      {
        "ref_id": "199",
        "text": "R. Armañanzas et al., \"Peakbin selection in mass spectrometry data using a consensus approach with estimation of distribution algorithms,\" IEEE/ACM Trans. Comput. Biol. Bioinf., vol. 8, no. 3, pp. 760-774, May/Jun. 2011."
      },
      {
        "ref_id": "200",
        "text": "Y. Saeys, S. Degroeve, D. Aeyels, Y. van de Peer, and P. Rouzé, \"Fast feature selection using a simple estimation of distribution algorithm: A case study on splice site prediction,\" Bioinformatics, vol. 19, no. 2, pp. II179-II188, 2003."
      },
      {
        "ref_id": "201",
        "text": "M. Ayodele, \"Application of estimation of distribution algorithm for feature selection,\" in Proc. 19th Genet. Evol. Comput. Conf., 2019, pp. 43-44."
      },
      {
        "ref_id": "202",
        "text": "C. Cano, F. García, F. J. López, and A. Blanco, \"Intelligent system for the analysis of microarray data using principal components and estimation of distribution algorithms,\" Expert Syst. Appl., vol. 36, no. 3, pp. 4654-4663, 2009."
      },
      {
        "ref_id": "203",
        "text": "H. Handa, \"EDA-RL: Estimation of distribution algorithms for reinforcement learning problems,\" in Proc. 11th Annu. Conf. Genet. Evol. Comput., 2009, pp. 405-412."
      },
      {
        "ref_id": "204",
        "text": "N. K. Kitson, A. C. Constantinou, Z. Guo, Y. Liu, and K. Chobtham, \"A survey of Bayesian network structure learning,\" Artif. Intell. Rev., vol. 56, pp. 8721-8814, Jan. 2023."
      },
      {
        "ref_id": "205",
        "text": "D. Atienza, C. Bielza, and P. Larrañaga, \"Semiparametric Bayesian networks,\" Inf. Sci., vol. 584, pp. 564-582, Jan. 2022."
      },
      {
        "ref_id": "206",
        "text": "D. Atienza, P. Larrañaga, and C. Bielza, \"Hybrid semiparametric Bayesian networks,\" TEST, vol. 31, pp. 299-327, Jun. 2022."
      },
      {
        "ref_id": "207",
        "text": "V. P. Soloviev, C. Bielza, and P. Larrañaga, \"Semiparametric estimation of distribution algorithms for continuous optimization,\" IEEE Trans. Evol. Comput., early access, Jun. 29, 2023, doi: 10.1109/TEVC.2023.3290670."
      },
      {
        "ref_id": "208",
        "text": "J. Ceberio, B. Doerr, C. Witt, and V. P. Soloviev, \"Estimation-of-distribution algorithms: Theory and applications,\" Dagstuhl Rep., vol. 12, no. 5, pp. 17-36, 2022."
      },
      {
        "ref_id": "209",
        "text": "G. Ochoa, K. M. Malan, and C. Blum, \"Search trajectory networks: A tool for analysing and visualising the behaviour of metaheuristics,\" Appl. Soft Comput., vol. 109, Sep. 2021, Art. no. 107492."
      },
      {
        "ref_id": "210",
        "text": "H. Borchani, G. Varando, C. Bielza, and P. Larrañaga, \"A survey on multi-output regression,\" in Wiley Interdisciplinary Reviews-Data Mining and Knowledge Discovery, vol. 5. Hoboken, NJ, USA: Wiley, 2015, pp. 216-233."
      },
      {
        "ref_id": "211",
        "text": "J. A. Lozano and P. Larrañaga, \"Applying genetic algorithms to search for the best hierarchical clustering of a dataset,\" Pattern Recognit. Lett., vol. 20, no. 9, pp. 911-918, 1999."
      },
      {
        "ref_id": "212",
        "text": "J. A. Castellanos-Garzón, C. A. García, and L. A. Miguel-Quintales, \"An evolutionary hierarchical clustering method with a visual validation tool,\" in Proc. Int. Work Conf. Artif. Neural Netw., 2009, pp. 367-374."
      }
    ],
    "reference_count": 211,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "I",
      "table_title": "Supervised Learning Methods Approached With EDAs",
      "headers": [
        "$k$-nearest neighbors",
        "Weight of each variable [117]",
        "EBNA, EGNA"
      ],
      "rows": [
        [
          "Classification trees",
          119,
          "Ardennes"
        ],
        [
          "Rule induction",
          "Pittsburgh approach [122] <br> Pittsburgh approach [123], [124] <br> Fuzzy rule-based systems [125]",
          "UMDA, COMIT, EBNA <br> BOA <br> UMDA, MIMIC, UMDA ${ }_{c}^{G}$"
        ],
        [
          "Support vector machines",
          127,
          "UMDA ${ }_{c}^{G}$, BUMDA"
        ],
        [
          "Artificial neural networks",
          129130131132133134135136137139140141,
          "PBIL <br> PBIL <br> UMDA ${ }_{c}^{G}$, MIMIC ${ }_{c}^{G}$ <br> UMDA ${ }_{c}^{G}$ <br> PBIL <br> PBIL <br> UMDA ${ }_{c}^{G}$ <br> cGA, EcGA, BOA <br> UMDA <br> UMDA+UMDA ${ }_{c}^{G}$ <br> EMNA, UMDA ${ }_{c}^{G}$ <br> UMDA $_{c}^{G}$"
        ],
        [
          "Logistic regression",
          143144,
          "UMDA ${ }_{c}^{G}$ <br> UMDA $_{c}^{G}$"
        ],
        [
          "Bayesian classifiers",
          148150,
          "UMDA ${ }_{c}^{G}$ <br> UMDA $_{c}^{G}$"
        ],
        [
          "Metaclassifiers",
          152154,
          "EBNA <br> UMDA $_{c}^{G}$"
        ],
        [
          "Regression",
          156157158159,
          "UMDA ${ }_{c}^{G}$ <br> UMDA $_{c}^{G}$ <br> Denoising autoencoder genetic programming <br> UMDA $_{c}^{G}$"
        ],
        [
          "Feature subset selection",
          161162163164165166167,
          "EBNA <br> EBNA <br> cGA, EcGA, BOA <br> TEDA <br> UMDA ${ }_{c}^{G}$ <br> UMDA $_{c}^{G}$ <br> FEDA"
        ]
      ],
      "row_count": 9,
      "column_count": 3
    },
    {
      "table_number": "II",
      "table_title": "Clustering Methods APPROACHED With EDAs",
      "headers": [
        "Hierarchical",
        "Merging clusters [169]",
        "UMDA"
      ],
      "rows": [
        [
          "Partitional",
          -171,
          "MIMIC, COMIT, EBNA"
        ],
        [
          "",
          -173,
          "UMDA"
        ],
        [
          "",
          175,
          "UMDA, EBNA"
        ],
        [
          "",
          -176,
          "UMDA"
        ],
        [
          "",
          -177,
          "PBIL"
        ],
        [
          "Probabilistic",
          -180,
          "UMDA"
        ]
      ],
      "row_count": 6,
      "column_count": 3
    },
    {
      "table_number": "III",
      "table_title": "Optimization Problems Solved With EDAs in Bayesian",
      "headers": [
        "Inference",
        "Triangulation [189]",
        "REDA"
      ],
      "rows": [
        [
          "",
          190,
          "UMDA, MIMIC, EBNA"
        ],
        [
          "Learning",
          191,
          "UMDA, PBIL"
        ],
        [
          "",
          192,
          "UMDA, PBIL"
        ],
        [
          "",
          193,
          "UMDA, PBIL, MIMIC, BOA"
        ],
        [
          "",
          194,
          "PBIL"
        ],
        [
          "",
          195,
          "UMDA, MIMIC, UMDA ${ }_{n}^{G}$, MIMIC $_{n}^{G}$"
        ],
        [
          "",
          197,
          "PBIL"
        ]
      ],
      "row_count": 7,
      "column_count": 3
    }
  ]
}