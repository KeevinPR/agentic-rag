{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2022/A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification.md",
    "filename": "A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification.md",
    "title": "A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification",
    "year": "2022"
  },
  "references": {
    "header": "## References",
    "content": "Abadi, Martin, Agarwal, Ashish, Barham, Paul, et al., 2016. Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems arXiv preprint arXiv: 160304467,\nBhark, Eric, Dehghani, Kaveh, 2014. Assisted history matching benchmarking: design of experiments-based techniques. In: Proc., SPE Annual Technical Conference and Exhibition,\nChang, Haibin, Liao, Qinzhuo, Zhang, Dongxiao, 2017. Surrogate model based iterative ensemble smoother for subsurface flow data assimilation. Adv. Water Resour. 100, $96-108$,\nChen, Chaohui, Gao, Guohua, Li, Ruijian, et al., 2018. Global-search distributed-gaussNewton optimization method and its integration with the randomized-maximumlikelihood method for uncertainty quantification of reservoir performance. SPE J. 23 (5), 1496-1517.\n\nChristlein, V., Sprenger, L., Seuret, M., et al., 2019. Deep generalized max pooling. In: Proc., 2019 International Conference on Document Analysis and Recognition (ICDAR), 20-25 Sept. 2019, pp. 1090-1096,\nDzchamovattana, Silpakorn, Jin, Jianli, Zuloaga-Molero, Pavel, et al., 2018. Application of proxy-based MCMC and EDFM to history match a Vaca Muerta shale oil well. Fuel 220, 490-502,\nElshokh, Ahmed H., Honst, Ibrahim, Wheeler, Mary F., 2014. Efficient Bayesian inference of subsurface flow models using nested sampling and sparse polynomial chaos surrogates. Comput. Methods Appl. Mech. Eng. 269, 515-537,\nEmerick, Alexandre A., Reynolds, Albert C., 2013. Ensemble smoother with multiple data assimilation. Comput. Geosci. 55, 3-15,\nGoodfellow, Ian J., Pouget-Abadie, Jean, Mirza, Mehdi, et al., 2014. Generative adversarial nets. In: Paper Presented at the Proceedings of the 27th International Conference on Neural Information Processing Systems, uma 2 (Montreal, Canada),\nGraves, A., Jailly, N., Mohamed, A., 2013. Hybrid speech recognition with deep bidirectional LSTM. In: Proc., 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, 8-12 Dec. 2013, pp. 273-278,\nGraves, Alex, Schmidhuber, Jürgen, 2005. Framewise phoneme classification with bidirectional LSTM and other neural network architectures. Neural Network. 18 (5), $602-610$.\nHe, K., Zhang, X., Ren, S., et al., 2016. Deep residual learning for image recognition. In: Proc., 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 27-30 June 2016, pp. 770-778,\nHimmelfelau, D.M., 1972. Applied Nonlinear Programming. McGraw-Hill, New York,\nHochreiter, Sepp, Schmidhuber, Jürgen, 1997. Long short-term memory. Neural Comput. 9 (8), 1735-1780,\nKinghorn, Philip, Zhang, Li, Shao, Ling, 2018. A region-based image caption generator with refined descriptions. Neurocomputing 272, 416-424,\nKingma, Diederik, P., Ba, Jianny, 2014. Adam: A Method for Stochastic Optimization arXiv preprint arXiv:14126980,\nLi, Boxiao, Bhark, Eric W., Gross, Stephen, et al., 2019. Best practices of assisted history matching using design of experiments. SPE J. 24 (4), 1435-1451,\nLi, Heng, Sarma, Pallav, Zhang, Dongxiao, 2011. A comparative study of the probabilistic-collocation and experimental-design methods for petroleum-reservoir uncertainty quantification. SPE J. 16 (2), 429-439,\nLi, Weixuan, Lin, Guang, 2015. An adaptive importance sampling algorithm for Bayesian inversion with multimodal distributions. J. Comput. Phys. 294, 173-190,\nLiao, Q., Zhang, D., 2015. Data assimilation for strongly nonlinear problems by transformed ensemble Kalman filter. SPE J. 20 (1), 202-221,\nLiao, Qinzhuo, Zeng, Lingzao, Chang, Haibin, et al., 2019. Efficient history matching using the markov-chain Monte Carlo method by means of the transformed adaptive stochastic collocation method. SPE J. 24 (4), 1468-1489,\nLiu, N., Oliver, D.S., 2005. Ensemble Kalman filter for automatic history matching of geologic facies. J. Petrol. Sci. Eng. 47 (3-4), 147-161,\nMa, Xiaopeng, Zhang, Kai, Yao, Chuanjin, et al., 2020. Multiscale-network structure inversion of fractured media based on a hierarchical-parameterization and datadriven evolutionary-optimization method. SPE J. 25 (5), 2729-2748,\nMa, Xiaopeng, Zhang, Kai, Zhang, Liming, et al., 2021. Data-driven niching differential evolution with adaptive parameters control for history matching and uncertainty quantification. SPE J. 26 (2), 993-1010,\nOliver, Dean S., Chen, Yan, 2011. Recent progress on reservoir history matching: a review. Comput. Geosci. 15 (1), 185-221,\nOliver, Dean S., Reynolds, A.C., et al., 2008. Inverse Theory for Petroleum Reservoir Characterization and History Matching. Cambridge University Press, Cambridge,\nPouerman, D.W., 1978. Interpretation of well-block pressures in numerical reservoir simulation(includes associated paper 6988). Soc. Petrol. Eng. J. 18 (3),\nPeters, E., Chen, Yunxia, Leeuwenburgh, O., et al., 2013. Extended Brugge benchmark case for history matching and water flooding optimization. Comput. Geosci. 50, $16-24$.\n\nRaskutti, G., Wainwright, M.J., Yu, B., 2011. Early stopping for non-parametric regression: an optimal data-dependent stopping rule. In: Proc., 2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton), 28-30 Sept. 2011, pp. 1318-1325.\nRemy, Nicolas, 2005. S-GeMS: the Stanford geostatistical modeling software: a tool for new algorithms development. In: Leuangtbong, Oy, Deutsch, Clayton V. (Eds.), Geostatistics Banff 2004. Springer Netherlands, Dordrecht, pp. 865-871.\nSaad, George, Ghanem, Roger, 2009. Characterization of reservoir simulation models using a polynomial chaos-based ensemble Kalman filter. Water Resour. Res. 45 (4), Sagheer, Alaa, Koth, Mostafa, 2019. Time series forecasting of petroleum production using deep LSTM recurrent networks. Neurocomputing 323, 203-213.\nStuart, A.M., 2010. Inverse problems: a Bayesian perspective. Acta Numer. 19, 451-559.\nTao, Ying Hua, Chan, Chee Song, 2019. Phrase-based image caption generator with hierarchical LSTM network. Neurocomputing 333, 86-100.\nTang, Meng, Liu, Yimin, Darlofsky, Louis J., 2020. A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems. J. Comput. Phys. 413.\n\nXue, L., Gu, S., Mi, L., Zhao, L., Liu, Y., Liao, Q., 2022. An automated data-driven pressure transient analysis of water-drive gas reservoir through the coupled machine learning and ensemble Kalman filter method. J. Petrol. Sci. Eng. 208, 109492,\n\nYang, Q., Chen, W., Li, Y., et al., 2017. Multimodal estimation of distribution algorithms. IEEE Trans. Cybern. 47 (3), 636-650.\nZeng, Lingzao, Zhang, Dongxiao, 2010. A stochastic collocation based Kalman filter for data assimilation. Comput. Geosci. 14 (4), 721-744.\nZhang, Jiangjiang, Jun, Mao, Guang, Lin, et al., 2018. Inverse modeling of hydrologic systems with adaptive multifidelity Markov chain Monte Carlo simulations. Water Resour. Res. 54 (7), 4867-4886. https://doi.org/10.1029/2018WR022658.\nZhang, Kai, Wang, Xiaoya, Ma, Xiaopeng, et al., 2022. The prediction of reservoir production based proxy model considering spatial data and vector data. J. Petrol. Sci. Eng. 208, 109694.\nZhao, Zijing, Kumar, Ajay, 2019. A deep learning based unified framework to detect, segment and recognize irises using spatially corresponding features. Pattern Recogn. 93, 546-557.\nZhong, Zhi, Sun, Alexander Y., Ren, Bo, et al., 2021. A deep-learning-based approach for reservoir production forecast under uncertainty. SPE J. 1-27,\nZhong, Zhi, Sun, Alexander Y., Wang, Yanyong, et al., 2020. Predicting field production rates for waterflooding using a machine learning-based proxy model. J. Petrol. Sci. Eng. 194, 107574,\nZhu, Yinhao, Zaharan, Nicholas, 2018. Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification. J. Comput. Phys. 366, 415-447.",
    "references": [
      {
        "ref_id": "1",
        "text": "Abadi, Martin, Agarwal, Ashish, Barham, Paul, et al., 2016. Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems arXiv preprint arXiv: 160304467,"
      },
      {
        "ref_id": "2",
        "text": "Bhark, Eric, Dehghani, Kaveh, 2014. Assisted history matching benchmarking: design of experiments-based techniques. In: Proc., SPE Annual Technical Conference and Exhibition,"
      },
      {
        "ref_id": "3",
        "text": "Chang, Haibin, Liao, Qinzhuo, Zhang, Dongxiao, 2017. Surrogate model based iterative ensemble smoother for subsurface flow data assimilation. Adv. Water Resour. 100, $96-108$,"
      },
      {
        "ref_id": "4",
        "text": "Chen, Chaohui, Gao, Guohua, Li, Ruijian, et al., 2018. Global-search distributed-gaussNewton optimization method and its integration with the randomized-maximumlikelihood method for uncertainty quantification of reservoir performance. SPE J. 23 (5), 1496-1517."
      },
      {
        "ref_id": "5",
        "text": "Christlein, V., Sprenger, L., Seuret, M., et al., 2019. Deep generalized max pooling. In: Proc., 2019 International Conference on Document Analysis and Recognition (ICDAR), 20-25 Sept. 2019, pp. 1090-1096,"
      },
      {
        "ref_id": "6",
        "text": "Dzchamovattana, Silpakorn, Jin, Jianli, Zuloaga-Molero, Pavel, et al., 2018. Application of proxy-based MCMC and EDFM to history match a Vaca Muerta shale oil well. Fuel 220, 490-502,"
      },
      {
        "ref_id": "7",
        "text": "Elshokh, Ahmed H., Honst, Ibrahim, Wheeler, Mary F., 2014. Efficient Bayesian inference of subsurface flow models using nested sampling and sparse polynomial chaos surrogates. Comput. Methods Appl. Mech. Eng. 269, 515-537,"
      },
      {
        "ref_id": "8",
        "text": "Emerick, Alexandre A., Reynolds, Albert C., 2013. Ensemble smoother with multiple data assimilation. Comput. Geosci. 55, 3-15,"
      },
      {
        "ref_id": "9",
        "text": "Goodfellow, Ian J., Pouget-Abadie, Jean, Mirza, Mehdi, et al., 2014. Generative adversarial nets. In: Paper Presented at the Proceedings of the 27th International Conference on Neural Information Processing Systems, uma 2 (Montreal, Canada),"
      },
      {
        "ref_id": "10",
        "text": "Graves, A., Jailly, N., Mohamed, A., 2013. Hybrid speech recognition with deep bidirectional LSTM. In: Proc., 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, 8-12 Dec. 2013, pp. 273-278,"
      },
      {
        "ref_id": "11",
        "text": "Graves, Alex, Schmidhuber, Jürgen, 2005. Framewise phoneme classification with bidirectional LSTM and other neural network architectures. Neural Network. 18 (5), $602-610$."
      },
      {
        "ref_id": "12",
        "text": "He, K., Zhang, X., Ren, S., et al., 2016. Deep residual learning for image recognition. In: Proc., 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 27-30 June 2016, pp. 770-778,"
      },
      {
        "ref_id": "13",
        "text": "Himmelfelau, D.M., 1972. Applied Nonlinear Programming. McGraw-Hill, New York,"
      },
      {
        "ref_id": "14",
        "text": "Hochreiter, Sepp, Schmidhuber, Jürgen, 1997. Long short-term memory. Neural Comput. 9 (8), 1735-1780,"
      },
      {
        "ref_id": "15",
        "text": "Kinghorn, Philip, Zhang, Li, Shao, Ling, 2018. A region-based image caption generator with refined descriptions. Neurocomputing 272, 416-424,"
      },
      {
        "ref_id": "16",
        "text": "Kingma, Diederik, P., Ba, Jianny, 2014. Adam: A Method for Stochastic Optimization arXiv preprint arXiv:14126980,"
      },
      {
        "ref_id": "17",
        "text": "Li, Boxiao, Bhark, Eric W., Gross, Stephen, et al., 2019. Best practices of assisted history matching using design of experiments. SPE J. 24 (4), 1435-1451,"
      },
      {
        "ref_id": "18",
        "text": "Li, Heng, Sarma, Pallav, Zhang, Dongxiao, 2011. A comparative study of the probabilistic-collocation and experimental-design methods for petroleum-reservoir uncertainty quantification. SPE J. 16 (2), 429-439,"
      },
      {
        "ref_id": "19",
        "text": "Li, Weixuan, Lin, Guang, 2015. An adaptive importance sampling algorithm for Bayesian inversion with multimodal distributions. J. Comput. Phys. 294, 173-190,"
      },
      {
        "ref_id": "20",
        "text": "Liao, Q., Zhang, D., 2015. Data assimilation for strongly nonlinear problems by transformed ensemble Kalman filter. SPE J. 20 (1), 202-221,"
      },
      {
        "ref_id": "21",
        "text": "Liao, Qinzhuo, Zeng, Lingzao, Chang, Haibin, et al., 2019. Efficient history matching using the markov-chain Monte Carlo method by means of the transformed adaptive stochastic collocation method. SPE J. 24 (4), 1468-1489,"
      },
      {
        "ref_id": "22",
        "text": "Liu, N., Oliver, D.S., 2005. Ensemble Kalman filter for automatic history matching of geologic facies. J. Petrol. Sci. Eng. 47 (3-4), 147-161,"
      },
      {
        "ref_id": "23",
        "text": "Ma, Xiaopeng, Zhang, Kai, Yao, Chuanjin, et al., 2020. Multiscale-network structure inversion of fractured media based on a hierarchical-parameterization and datadriven evolutionary-optimization method. SPE J. 25 (5), 2729-2748,"
      },
      {
        "ref_id": "24",
        "text": "Ma, Xiaopeng, Zhang, Kai, Zhang, Liming, et al., 2021. Data-driven niching differential evolution with adaptive parameters control for history matching and uncertainty quantification. SPE J. 26 (2), 993-1010,"
      },
      {
        "ref_id": "25",
        "text": "Oliver, Dean S., Chen, Yan, 2011. Recent progress on reservoir history matching: a review. Comput. Geosci. 15 (1), 185-221,"
      },
      {
        "ref_id": "26",
        "text": "Oliver, Dean S., Reynolds, A.C., et al., 2008. Inverse Theory for Petroleum Reservoir Characterization and History Matching. Cambridge University Press, Cambridge,"
      },
      {
        "ref_id": "27",
        "text": "Pouerman, D.W., 1978. Interpretation of well-block pressures in numerical reservoir simulation(includes associated paper 6988). Soc. Petrol. Eng. J. 18 (3),"
      },
      {
        "ref_id": "28",
        "text": "Peters, E., Chen, Yunxia, Leeuwenburgh, O., et al., 2013. Extended Brugge benchmark case for history matching and water flooding optimization. Comput. Geosci. 50, $16-24$."
      },
      {
        "ref_id": "29",
        "text": "Raskutti, G., Wainwright, M.J., Yu, B., 2011. Early stopping for non-parametric regression: an optimal data-dependent stopping rule. In: Proc., 2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton), 28-30 Sept. 2011, pp. 1318-1325."
      },
      {
        "ref_id": "30",
        "text": "Remy, Nicolas, 2005. S-GeMS: the Stanford geostatistical modeling software: a tool for new algorithms development. In: Leuangtbong, Oy, Deutsch, Clayton V. (Eds.), Geostatistics Banff 2004. Springer Netherlands, Dordrecht, pp. 865-871."
      },
      {
        "ref_id": "31",
        "text": "Saad, George, Ghanem, Roger, 2009. Characterization of reservoir simulation models using a polynomial chaos-based ensemble Kalman filter. Water Resour. Res. 45 (4), Sagheer, Alaa, Koth, Mostafa, 2019. Time series forecasting of petroleum production using deep LSTM recurrent networks. Neurocomputing 323, 203-213."
      },
      {
        "ref_id": "32",
        "text": "Stuart, A.M., 2010. Inverse problems: a Bayesian perspective. Acta Numer. 19, 451-559."
      },
      {
        "ref_id": "33",
        "text": "Tao, Ying Hua, Chan, Chee Song, 2019. Phrase-based image caption generator with hierarchical LSTM network. Neurocomputing 333, 86-100."
      },
      {
        "ref_id": "34",
        "text": "Tang, Meng, Liu, Yimin, Darlofsky, Louis J., 2020. A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems. J. Comput. Phys. 413."
      },
      {
        "ref_id": "35",
        "text": "Xue, L., Gu, S., Mi, L., Zhao, L., Liu, Y., Liao, Q., 2022. An automated data-driven pressure transient analysis of water-drive gas reservoir through the coupled machine learning and ensemble Kalman filter method. J. Petrol. Sci. Eng. 208, 109492,"
      },
      {
        "ref_id": "36",
        "text": "Yang, Q., Chen, W., Li, Y., et al., 2017. Multimodal estimation of distribution algorithms. IEEE Trans. Cybern. 47 (3), 636-650."
      },
      {
        "ref_id": "37",
        "text": "Zeng, Lingzao, Zhang, Dongxiao, 2010. A stochastic collocation based Kalman filter for data assimilation. Comput. Geosci. 14 (4), 721-744."
      },
      {
        "ref_id": "38",
        "text": "Zhang, Jiangjiang, Jun, Mao, Guang, Lin, et al., 2018. Inverse modeling of hydrologic systems with adaptive multifidelity Markov chain Monte Carlo simulations. Water Resour. Res. 54 (7), 4867-4886. https://doi.org/10.1029/2018WR022658."
      },
      {
        "ref_id": "39",
        "text": "Zhang, Kai, Wang, Xiaoya, Ma, Xiaopeng, et al., 2022. The prediction of reservoir production based proxy model considering spatial data and vector data. J. Petrol. Sci. Eng. 208, 109694."
      },
      {
        "ref_id": "40",
        "text": "Zhao, Zijing, Kumar, Ajay, 2019. A deep learning based unified framework to detect, segment and recognize irises using spatially corresponding features. Pattern Recogn. 93, 546-557."
      },
      {
        "ref_id": "41",
        "text": "Zhong, Zhi, Sun, Alexander Y., Ren, Bo, et al., 2021. A deep-learning-based approach for reservoir production forecast under uncertainty. SPE J. 1-27,"
      },
      {
        "ref_id": "42",
        "text": "Zhong, Zhi, Sun, Alexander Y., Wang, Yanyong, et al., 2020. Predicting field production rates for waterflooding using a machine learning-based proxy model. J. Petrol. Sci. Eng. 194, 107574,"
      },
      {
        "ref_id": "43",
        "text": "Zhu, Yinhao, Zaharan, Nicholas, 2018. Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification. J. Comput. Phys. 366, 415-447."
      }
    ],
    "reference_count": 43,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Results of cross check of hyperparameters. $N_{C}$ the dimension of extracted spatial feature, $N_{\\text {min }}$ : the number of neurons in BiLSTM layer, $R^{2}$ : the coefficient of determination on training set, $\\operatorname{Val}_{1} R^{2}$ : the coefficient of determination on validation set. The best value is indicated in bold.",
      "headers": [
        "No.",
        "$N_{c}$",
        "$N_{\\text {min }}$",
        "$R^{2}$",
        "$\\operatorname{Val}_{1} R^{2}$"
      ],
      "rows": [
        [
          1,
          100,
          100,
          0.9645,
          "$\\mathbf{0 . 8 9 0 3}$"
        ],
        [
          2,
          100,
          200,
          0.9631,
          0.8742
        ],
        [
          3,
          500,
          100,
          0.9717,
          0.88
        ],
        [
          4,
          500,
          200,
          0.9744,
          0.8704
        ],
        [
          5,
          1000,
          100,
          0.9714,
          0.866
        ],
        [
          6,
          1000,
          200,
          "$\\mathbf{0 . 9 8 6 9}$",
          0.8445
        ]
      ],
      "row_count": 6,
      "column_count": 5
    },
    {
      "table_number": "2",
      "table_title": "Results of cross check of hyperparameters. $N_{e}$ the dimension of extracted spatial feature, $N_{\\text {total }}$ : the number of neurons in BILSTM layer, $R^{2}$ : the coefficient of determination on training set, $\\operatorname{Val}_{1} R^{2}$ : the coefficient of determination on validation set. The best value is indicated in bold.",
      "headers": [
        "No.",
        "$N_{e}$",
        "$N_{\\text {total }}$",
        "$R^{2}$",
        "$\\operatorname{Val}_{1} R^{2}$"
      ],
      "rows": [
        [
          1,
          100,
          100,
          0.9867,
          "$\\mathbf{0 . 9 8 0 7}$"
        ],
        [
          2,
          100,
          200,
          0.9849,
          0.9804
        ],
        [
          3,
          500,
          100,
          0.9822,
          0.9782
        ],
        [
          4,
          500,
          200,
          "$\\mathbf{0 . 9 8 7 9}$",
          0.9804
        ],
        [
          5,
          1000,
          100,
          0.9494,
          0.9476
        ],
        [
          6,
          1000,
          200,
          0.9861,
          0.98
        ]
      ],
      "row_count": 6,
      "column_count": 5
    }
  ]
}