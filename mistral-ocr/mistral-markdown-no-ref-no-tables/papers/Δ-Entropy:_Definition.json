{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2011/Δ-Entropy: Definition.md",
    "filename": "Δ-Entropy: Definition.md",
    "title": "Δ-Entropy: Definition",
    "year": "2011"
  },
  "references": {
    "header": "## References",
    "content": "[1] J.C. Aguero, G.C. Goodwin, J.I. Yuz, System identification using quantized data, in: Proceedings of the 46th IEEE Conference on Decision and Control, New Orleans, LA, USA, December 2007, pp. 4263-4268.\n[2] B. Chen, J. Hu, L. Pu, Z. Sun, Stochastic gradient algorithm under (h.-p)-entropy criterion, Circuits Systems Signal Processing 26 (2007) 941-960.\n[3] T. Chen, K. Tang, G. Chen, X. Yao, On the analysis of average time complexity of estimation of distribution algorithms, in: Proceedings of 2007 IEEE Congress on Evolutionary Computation (CEC2007), 2007, pp. 453-460.\n[4] T.M. Cover, J.A. Thomas, Element of Information Theory, Wiley \\& Son, Inc., Chichester, 1991.\n[5] L. Devroye, G. Lugosi, Combinatorial Methods in Density Estimation, Springer-Verlag, 2000.\n[6] D. Erdogmus, E.H. Kenneth, J.C. Principe, Online entropy manipulation: stochastic information gradient, IEEE Signal Processing Letters 10 (2003) 242245.\n[7] D. Erdogmus, J.C. Principe, Generalized information potential criterion for adaptive system training, IEEE Transactions on Neural Networks 13 (2002) $1035-1044$.\n[8] D. Erdogmus, J.C. Principe, Convergence properties and data efficiency of the minimum error entropy criterion in Adaline training, IEEE Transactions on Signal Processing 51 (2003) 1966-1978.\n[9] D.Z. Feng, X.D. Zhang, D.X. Chang, W.X. Zheng, A fast recursive total least squares algorithm for adaptive FIR filtering, IEEE Transactions on Signal Processing 52 (2004) 2729-2737.\n[10] E. Gassiat, E. Gautherat, Identification of noisy linear systems with discrete random input, IEEE Transactions on Information Theory 44 (1998) 19411952.\n[11] C. Gonzalez, A. Ramirez, J.A. Lozano, P. Larranaga, Average time complexity of estimation of distribution algorithms, in: The 18th International WorkConference on Artificial Neural Networks (IWANN2005), Lecture Notes in Computer Science, vol. 3512, 2005, pp. 42-49.\n[12] L. Hu, C. Zhou, Z. Sun, Estimating biped gait using spline-based probability distribution function with Q-learning, IEEE Transactions on Industrial Electronics 55 (2008) 1444-1452.\n[13] M. Janzura, T. Koski, A. Otahal, Minimum entropy of error principle in estimation, Information Sciences 79 (1994) 123-144.\n[14] M. Janzura, T. Koski, A. Otahal, Minimum entropy of error estimation for discrete random variables, IEEE Transactions on Information Theory 42 (4) (1996) 1193-1201.\n[15] J.N. Kapur, H.K. Kesavan, Entropy Optimization Principles with Applications, Academic Press Inc., 1992.\n[16] P. Larranaga, J.A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer Academic Publishers, Boston, 2002.\n[17] T.H. Li, Blind identification and deconvolution of linear systems driven by binary random sequences, IEEE Transactions on Information Theory 38 (1992) 26-38.\n[18] T.H. Li, Finite-alphabet information and multivariate blind deconvolution and identification of linear systems, IEEE Transactions on Information Theory 49 (2003) 330-337.\n[19] T. Ling, T. David, Adaptive estimated maximum-entropy distribution model, Information Science 177 (2007) 3110-3128.\n[20] N. Minamide, An extension of the entropy theorem for parameter estimation, Information and Control 53 (1982) 81-90.\n[21] A. Okao, M. Ikeda, R. Takahashi, System identification for nano control: a finite wordlength problem, in: Proceedings of Conference on Control Applications, Istanbul, Turkey, June 2003, pp. 49-53.\n[22] U. Ozettem, D. Erdogmus, Second-order volterra system identification with noisy input-output measurements, IEEE Signal Processing Letters 16 (2009) 18-21.\n[23] U. Ozettem, I. Uysal, D. Erdogmus, Continuously differentiable sample-spacing entropy estimation, IEEE Transactions on Neural Networks 19 (2008) 1978-1984.\n[24] L. Pardo, Statistical Inference Based on Divergence Measures, Chapman \\& Hall/CRC, 2006.\n[25] J.C. Patra, R.N. Pal, R. Baliarsingh, G. Panda, Nonlinear channel equalization for QAM signal constellation using artificial neural networks, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 29 (2) (1999) 262-271.\n[26] C.L. Phillips, H.T. Nagle, Digital Control System Analysis and Design, fourth ed., Prentice Hall Press, 2007.\n[27] J.C. Principe, D. Xu, Q. Zhao, et al, Learning from examples with information theoretic criteria, Journal of VLSI Signal Processing Systems 26 (2000) 6177.\n[28] Y.N. Rao, D. Erdogmus, J.C. Principe, Error whitening criterion for adaptive filtering: theory and algorithms, IEEE Transactions on Signal Processing 53 (2005) 1057-1069.\n[29] R. Rastegar, M.R. Meybodi, A study on global convergence time complexity of estimation of distribution algorithms, in: Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC2005), Lecture Notes in Artificial Intelligence, vol. 3641, 2005, pp. 441-450.\n[30] R. Santana, P. Larranaga, J.A. Lozano, Side chain placement using estimation of distribution algorithms, Artificial Intelligence in Medicine 39 (2007) 4963.\n[31] L.M. Silva, C.S. Felgueiras, L.A. Alexandre, J. Marques, Error entropy in classification problems: a univariate data analysis, Neural Computation 18 (2006) 2036-2061.\n[32] T. Soerstrom, Errors-in-variables methods in system identification, Automatica 43 (2007) 939-958.\n[33] H. Suzuki, T. Sugie, System identification based on quantized I/O data corrupted with noise and its performance improvement, in: Proceedings of the 45th IEEE Conference on Decision and Control, San Diego, CA, USA, December 2006, pp. 3684-3689.\n[34] O. Vasicek, A test for normality based on sample entropy, Journal of the Royal Statistical Society Series A 38 (1976) 54-59.\n[35] L.Y. Wang, G.G. Yin, Y. Zhao, J.F. Zhang, Identification input design for consistent parameter estimation of linear systems with binary-valued output observations, IEEE Transactions on Automatic Control 53 (2008) 867-880.\n[36] L.Y. Wang, J.F. Zhang, G.G. Yin, System identification using binary sensors, IEEE Transactions on Automatic Control 48 (11) (2003) 1892-1907.\n[37] H.L. Weidemann, E.B. Stear, Entropy analysis of estimating systems, IEEE Transactions on Information Theory 16 (1970) 264-270.\n[38] T.C. Yang, Networked control system: a brief survey, Control Theory and Applications, IEE Proceedings 153 (4) (2006) 403-412.\n[39] Q. Zhang, H. Muhlenbein, On the convergence of a class of estimation of distribution algorithms, IEEE Transactions on Evolutionary Computation 8 (2) (2004) 127-136.\n[40] Y. Zhao, L.Y. Wang, G.G. Yin, J.F. Zhang, Identification of Wiener systems with binary-valued output observations, Automatica 43 (2007) 1752-1765.\n[41] A.C. Harvey, C. Fernandez, Time series for count data or qualitative observations, Journal of Business and Economic Statistics 7 (1989) 407-417.\n[42] M. Al-Osh, A. Alzaid, First order integer-valued autoregressive (NAR 1) process, Journal of Time Series Analysis 8 (3) (1987) 261-275.\n[43] K. Brannas, A. Hall, Estimation in integer-valued moving average models, Applied Stochastic Models in Business and Industry 17 (3) (2001) 277-291.\n[44] C.H. Weiß, Thinning operations for modeling time series of counts-a survey, ASIA Advances in Statistical Analysis 92 (3) (2008) 319-341.\n[45] M. Sato-Ilic, Fuzzy regression models on entropy based blocking structures, International Journal of Innovative Computing, Information and Control 5 (6) (2009) 1475-1484.\n[46] W. Zeng, F. Yu, X. Yu, H. Chen, S. Wu, Entropy of intuitionistic fuzzy set based on similarity measure, International Journal of Innovative Computing, Information and Control 5 (12A) (2009) 4737-4744.\n[47] X. Gao, C. You, Maximum entropy membership functions for discrete fuzzy variables, Information Sciences 179 (14) (2009) 2353-2361.\n[48] Q.S. Zhang, S.Y. Jiang, A note on information entropy measures for vague sets and its applications, Information Sciences 178 (21) (2008) 4184-4191.\n[49] J. Balatoni, A. Renyi, On the notion of entropy (Hungarian), vol. 1, Publ. Math. Inst. Hungarian Acad. Sci., 1956, pp. 9-40 (English Translation: Selected Papers of Alfred Renyi, vol. 1, Akademiat Kiado, Budapest, 1976, pp. 558-584).",
    "references": [
      {
        "ref_id": "1",
        "text": "J.C. Aguero, G.C. Goodwin, J.I. Yuz, System identification using quantized data, in: Proceedings of the 46th IEEE Conference on Decision and Control, New Orleans, LA, USA, December 2007, pp. 4263-4268."
      },
      {
        "ref_id": "2",
        "text": "B. Chen, J. Hu, L. Pu, Z. Sun, Stochastic gradient algorithm under (h.-p)-entropy criterion, Circuits Systems Signal Processing 26 (2007) 941-960."
      },
      {
        "ref_id": "3",
        "text": "T. Chen, K. Tang, G. Chen, X. Yao, On the analysis of average time complexity of estimation of distribution algorithms, in: Proceedings of 2007 IEEE Congress on Evolutionary Computation (CEC2007), 2007, pp. 453-460."
      },
      {
        "ref_id": "4",
        "text": "T.M. Cover, J.A. Thomas, Element of Information Theory, Wiley \\& Son, Inc., Chichester, 1991."
      },
      {
        "ref_id": "5",
        "text": "L. Devroye, G. Lugosi, Combinatorial Methods in Density Estimation, Springer-Verlag, 2000."
      },
      {
        "ref_id": "6",
        "text": "D. Erdogmus, E.H. Kenneth, J.C. Principe, Online entropy manipulation: stochastic information gradient, IEEE Signal Processing Letters 10 (2003) 242245."
      },
      {
        "ref_id": "7",
        "text": "D. Erdogmus, J.C. Principe, Generalized information potential criterion for adaptive system training, IEEE Transactions on Neural Networks 13 (2002) $1035-1044$."
      },
      {
        "ref_id": "8",
        "text": "D. Erdogmus, J.C. Principe, Convergence properties and data efficiency of the minimum error entropy criterion in Adaline training, IEEE Transactions on Signal Processing 51 (2003) 1966-1978."
      },
      {
        "ref_id": "9",
        "text": "D.Z. Feng, X.D. Zhang, D.X. Chang, W.X. Zheng, A fast recursive total least squares algorithm for adaptive FIR filtering, IEEE Transactions on Signal Processing 52 (2004) 2729-2737."
      },
      {
        "ref_id": "10",
        "text": "E. Gassiat, E. Gautherat, Identification of noisy linear systems with discrete random input, IEEE Transactions on Information Theory 44 (1998) 19411952."
      },
      {
        "ref_id": "11",
        "text": "C. Gonzalez, A. Ramirez, J.A. Lozano, P. Larranaga, Average time complexity of estimation of distribution algorithms, in: The 18th International WorkConference on Artificial Neural Networks (IWANN2005), Lecture Notes in Computer Science, vol. 3512, 2005, pp. 42-49."
      },
      {
        "ref_id": "12",
        "text": "L. Hu, C. Zhou, Z. Sun, Estimating biped gait using spline-based probability distribution function with Q-learning, IEEE Transactions on Industrial Electronics 55 (2008) 1444-1452."
      },
      {
        "ref_id": "13",
        "text": "M. Janzura, T. Koski, A. Otahal, Minimum entropy of error principle in estimation, Information Sciences 79 (1994) 123-144."
      },
      {
        "ref_id": "14",
        "text": "M. Janzura, T. Koski, A. Otahal, Minimum entropy of error estimation for discrete random variables, IEEE Transactions on Information Theory 42 (4) (1996) 1193-1201."
      },
      {
        "ref_id": "15",
        "text": "J.N. Kapur, H.K. Kesavan, Entropy Optimization Principles with Applications, Academic Press Inc., 1992."
      },
      {
        "ref_id": "16",
        "text": "P. Larranaga, J.A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer Academic Publishers, Boston, 2002."
      },
      {
        "ref_id": "17",
        "text": "T.H. Li, Blind identification and deconvolution of linear systems driven by binary random sequences, IEEE Transactions on Information Theory 38 (1992) 26-38."
      },
      {
        "ref_id": "18",
        "text": "T.H. Li, Finite-alphabet information and multivariate blind deconvolution and identification of linear systems, IEEE Transactions on Information Theory 49 (2003) 330-337."
      },
      {
        "ref_id": "19",
        "text": "T. Ling, T. David, Adaptive estimated maximum-entropy distribution model, Information Science 177 (2007) 3110-3128."
      },
      {
        "ref_id": "20",
        "text": "N. Minamide, An extension of the entropy theorem for parameter estimation, Information and Control 53 (1982) 81-90."
      },
      {
        "ref_id": "21",
        "text": "A. Okao, M. Ikeda, R. Takahashi, System identification for nano control: a finite wordlength problem, in: Proceedings of Conference on Control Applications, Istanbul, Turkey, June 2003, pp. 49-53."
      },
      {
        "ref_id": "22",
        "text": "U. Ozettem, D. Erdogmus, Second-order volterra system identification with noisy input-output measurements, IEEE Signal Processing Letters 16 (2009) 18-21."
      },
      {
        "ref_id": "23",
        "text": "U. Ozettem, I. Uysal, D. Erdogmus, Continuously differentiable sample-spacing entropy estimation, IEEE Transactions on Neural Networks 19 (2008) 1978-1984."
      },
      {
        "ref_id": "24",
        "text": "L. Pardo, Statistical Inference Based on Divergence Measures, Chapman \\& Hall/CRC, 2006."
      },
      {
        "ref_id": "25",
        "text": "J.C. Patra, R.N. Pal, R. Baliarsingh, G. Panda, Nonlinear channel equalization for QAM signal constellation using artificial neural networks, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 29 (2) (1999) 262-271."
      },
      {
        "ref_id": "26",
        "text": "C.L. Phillips, H.T. Nagle, Digital Control System Analysis and Design, fourth ed., Prentice Hall Press, 2007."
      },
      {
        "ref_id": "27",
        "text": "J.C. Principe, D. Xu, Q. Zhao, et al, Learning from examples with information theoretic criteria, Journal of VLSI Signal Processing Systems 26 (2000) 6177."
      },
      {
        "ref_id": "28",
        "text": "Y.N. Rao, D. Erdogmus, J.C. Principe, Error whitening criterion for adaptive filtering: theory and algorithms, IEEE Transactions on Signal Processing 53 (2005) 1057-1069."
      },
      {
        "ref_id": "29",
        "text": "R. Rastegar, M.R. Meybodi, A study on global convergence time complexity of estimation of distribution algorithms, in: Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC2005), Lecture Notes in Artificial Intelligence, vol. 3641, 2005, pp. 441-450."
      },
      {
        "ref_id": "30",
        "text": "R. Santana, P. Larranaga, J.A. Lozano, Side chain placement using estimation of distribution algorithms, Artificial Intelligence in Medicine 39 (2007) 4963."
      },
      {
        "ref_id": "31",
        "text": "L.M. Silva, C.S. Felgueiras, L.A. Alexandre, J. Marques, Error entropy in classification problems: a univariate data analysis, Neural Computation 18 (2006) 2036-2061."
      },
      {
        "ref_id": "32",
        "text": "T. Soerstrom, Errors-in-variables methods in system identification, Automatica 43 (2007) 939-958."
      },
      {
        "ref_id": "33",
        "text": "H. Suzuki, T. Sugie, System identification based on quantized I/O data corrupted with noise and its performance improvement, in: Proceedings of the 45th IEEE Conference on Decision and Control, San Diego, CA, USA, December 2006, pp. 3684-3689."
      },
      {
        "ref_id": "34",
        "text": "O. Vasicek, A test for normality based on sample entropy, Journal of the Royal Statistical Society Series A 38 (1976) 54-59."
      },
      {
        "ref_id": "35",
        "text": "L.Y. Wang, G.G. Yin, Y. Zhao, J.F. Zhang, Identification input design for consistent parameter estimation of linear systems with binary-valued output observations, IEEE Transactions on Automatic Control 53 (2008) 867-880."
      },
      {
        "ref_id": "36",
        "text": "L.Y. Wang, J.F. Zhang, G.G. Yin, System identification using binary sensors, IEEE Transactions on Automatic Control 48 (11) (2003) 1892-1907."
      },
      {
        "ref_id": "37",
        "text": "H.L. Weidemann, E.B. Stear, Entropy analysis of estimating systems, IEEE Transactions on Information Theory 16 (1970) 264-270."
      },
      {
        "ref_id": "38",
        "text": "T.C. Yang, Networked control system: a brief survey, Control Theory and Applications, IEE Proceedings 153 (4) (2006) 403-412."
      },
      {
        "ref_id": "39",
        "text": "Q. Zhang, H. Muhlenbein, On the convergence of a class of estimation of distribution algorithms, IEEE Transactions on Evolutionary Computation 8 (2) (2004) 127-136."
      },
      {
        "ref_id": "40",
        "text": "Y. Zhao, L.Y. Wang, G.G. Yin, J.F. Zhang, Identification of Wiener systems with binary-valued output observations, Automatica 43 (2007) 1752-1765."
      },
      {
        "ref_id": "41",
        "text": "A.C. Harvey, C. Fernandez, Time series for count data or qualitative observations, Journal of Business and Economic Statistics 7 (1989) 407-417."
      },
      {
        "ref_id": "42",
        "text": "M. Al-Osh, A. Alzaid, First order integer-valued autoregressive (NAR 1) process, Journal of Time Series Analysis 8 (3) (1987) 261-275."
      },
      {
        "ref_id": "43",
        "text": "K. Brannas, A. Hall, Estimation in integer-valued moving average models, Applied Stochastic Models in Business and Industry 17 (3) (2001) 277-291."
      },
      {
        "ref_id": "44",
        "text": "C.H. Weiß, Thinning operations for modeling time series of counts-a survey, ASIA Advances in Statistical Analysis 92 (3) (2008) 319-341."
      },
      {
        "ref_id": "45",
        "text": "M. Sato-Ilic, Fuzzy regression models on entropy based blocking structures, International Journal of Innovative Computing, Information and Control 5 (6) (2009) 1475-1484."
      },
      {
        "ref_id": "46",
        "text": "W. Zeng, F. Yu, X. Yu, H. Chen, S. Wu, Entropy of intuitionistic fuzzy set based on similarity measure, International Journal of Innovative Computing, Information and Control 5 (12A) (2009) 4737-4744."
      },
      {
        "ref_id": "47",
        "text": "X. Gao, C. You, Maximum entropy membership functions for discrete fuzzy variables, Information Sciences 179 (14) (2009) 2353-2361."
      },
      {
        "ref_id": "48",
        "text": "Q.S. Zhang, S.Y. Jiang, A note on information entropy measures for vague sets and its applications, Information Sciences 178 (21) (2008) 4184-4191."
      },
      {
        "ref_id": "49",
        "text": "J. Balatoni, A. Renyi, On the notion of entropy (Hungarian), vol. 1, Publ. Math. Inst. Hungarian Acad. Sci., 1956, pp. 9-40 (English Translation: Selected Papers of Alfred Renyi, vol. 1, Akademiat Kiado, Budapest, 1976, pp. 558-584)."
      }
    ],
    "reference_count": 49,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "2",
      "table_title": "Mean $\\pm$ deviation results of $w_{1}$ and $w_{2}$ at the 10th EDA generation for different $\\sigma_{n_{1}}\\left(\\sigma_{n_{2}}=0.1\\right)$.",
      "headers": [
        "$\\sigma_{n_{1}}$",
        "$\\Delta$-entropy",
        "",
        "MSE",
        ""
      ],
      "rows": [
        [
          "",
          "$w_{1}$",
          "$w_{2}$",
          "$w_{1}$",
          "$w_{2}$"
        ],
        [
          0.1,
          "$1.0000 \\pm 0.0008$",
          "$0.4999 \\pm 0.0007$",
          "$0.9896 \\pm 0.0071$",
          "$0.4952 \\pm 0.0067$"
        ],
        [
          0.2,
          "$0.9997 \\pm 0.0015$",
          "$0.4995 \\pm 0.0015$",
          "$0.9609 \\pm 0.0098$",
          "$0.4800 \\pm 0.0097$"
        ],
        [
          0.3,
          "$0.9994 \\pm 0.0016$",
          "$0.4993 \\pm 0.0017$",
          "$0.9192 \\pm 0.0118$",
          "$0.4617 \\pm 0.0140$"
        ],
        [
          0.4,
          "$0.9991 \\pm 0.0019$",
          "$0.4991 \\pm 0.0019$",
          "$0.8629 \\pm 0.0129$",
          "$0.4316 \\pm 0.0163$"
        ],
        [
          0.5,
          "$0.9980 \\pm 0.0039$",
          "$0.4972 \\pm 0.0077$",
          "$0.8015 \\pm 0.0146$",
          "$0.4016 \\pm 0.0200$"
        ]
      ],
      "row_count": 6,
      "column_count": 5
    },
    {
      "table_number": "3",
      "table_title": "Mean $\\pm$ deviation results of $w_{1}$ and $w_{2}$ at the 10th EDA generation for different $\\sigma_{n_{1}}\\left(\\sigma_{n_{1}}=0.1\\right)$.",
      "headers": [
        "$\\sigma_{n_{1}}$",
        "$\\Delta$-entropy",
        "",
        "MSE",
        ""
      ],
      "rows": [
        [
          "",
          "$w_{1}$",
          "$w_{2}$",
          "$w_{1}$",
          "$w_{2}$"
        ],
        [
          0.1,
          "$1.0000 \\pm 0.0008$",
          "$0.4999 \\pm 0.0007$",
          0.9896,
          "$0.4952 \\pm 0.0067$"
        ],
        [
          0.2,
          "$0.9999 \\pm 0.0009$",
          "$0.4999 \\pm 0.0008$",
          "$0.9887 \\pm 0.0096$",
          "$0.4949 \\pm 0.0089$"
        ],
        [
          0.3,
          "$0.9999 \\pm 0.0012$",
          "$0.4998 \\pm 0.0011$",
          "$0.9908 \\pm 0.0139$",
          "$0.4943 \\pm 0.0142$"
        ],
        [
          0.4,
          "$0.9999 \\pm 0.0020$",
          "$0.4998 \\pm 0.0017$",
          "$0.9880 \\pm 0.0192$",
          "$0.4948 \\pm 0.0208$"
        ],
        [
          0.5,
          "$1.0001 \\pm 0.0039$",
          "$0.4998 \\pm 0.0024$",
          "$0.9926 \\pm 0.0231$",
          "$0.4946 \\pm 0.0235$"
        ]
      ],
      "row_count": 6,
      "column_count": 5
    }
  ]
}