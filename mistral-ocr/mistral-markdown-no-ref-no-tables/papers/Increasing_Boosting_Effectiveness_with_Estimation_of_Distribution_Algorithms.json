{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2018/Increasing Boosting Effectiveness with Estimation of Distribution Algorithms.md",
    "filename": "Increasing Boosting Effectiveness with Estimation of Distribution Algorithms.md",
    "title": "Increasing Boosting Effectiveness with Estimation of Distribution Algorithms",
    "year": "2018"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] R. Saleh, H. Farsi, and S. H. Zahiri, \"Ensemble classification of polsar data using multi-objective heuristic combination rule,\" in Swarm Intelligence and Evolutionary Computation (CSIEC), 2016 1st Conference on. IEEE, 2016, pp. 88-92.\n[2] M. Milliken, Y. Bi, L. Galway, and G. Hawe, \"Multi-objective optimization of base classifiers in stackingc by nsga-ii for intrusion detection,\" in Computational Intelligence (SSCI), 2016 IEEE Symposium Series on. IEEE, 2016, pp. 1-8.\n[3] M. Krithiksa and R. Mallipeddi, \"Differential evolution with an ensemble of low-quality surrogates for expensive optimization problems,\" in Evolutionary Computation (CEC), 2016 IEEE Congress on. IEEE, 2016, pp. 78-85.\n[4] Y. Freund and R. E. Schapire, \"A desicion-theoretic generalization of on-line learning and an application to boosting,\" in European conference on computational learning theory. Springer, 1995, pp. 23-37.\n[5] K. Jackowski, B. Krawczyk, and M. Woźniak, \"Improved adaptive splitting and selection: the hybrid training method of a classifier based on a feature space partitioning,\" International journal of neural systems, vol. 24, no. 03, p. 1430007, 2014.\n[6] G. Folino, F. S. Pisani, and P. Sabatino, \"An incremental ensemble evolved by using genetic programming to efficiently detect drifts in cyber security datasets,\" in Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion. ACM, 2016, pp. $1103-1110$.\n[7] W. Zhang, Z. Qu, K. Zhang, W. Mao, Y. Ma, and X. Fan, \"A combined model based on ceemdan and modified flower pollination algorithm for wind speed forecasting,\" Energy Conversion and Management, vol. 136, pp. 439-451, 2017.\n[8] W. L. Woon and O. Kramer, \"Enhanced svr ensembles for wind power prediction,\" in Neural Networks (IJCNN), 2016 International Joint Conference on. IEEE, 2016, pp. 2743-2748.\n[9] A. Peimankar, S. J. Weddell, T. Jalal, and A. C. Lapthorn, \"Evolutionary multi-objective fault diagnosis of power transformers,\" Swarm and Evolutionary Computation, 2017.\n[10] ——, \"Ensemble classifier selection using multi-objective PSO for fault diagnosis of power transformers,\" in Evolutionary Computation (CEC), 2016 IEEE Congress on. IEEE, 2016, pp. 3622-3629.\n[11] S. E. Lacy, M. A. Lones, and S. L. Smith, \"Forming classifier ensembles with multimodal evolutionary algorithms,\" in Evolutionary Computation (CEC), 2015 IEEE Congress on. IEEE, 2015, pp. 723-729.\n[12] Y. Freund, R. E. Schapire et al., \"Experiments with a new boosting algorithm,\" in Icml, vol. 96. Bari, Italy, 1996, pp. 148-156.\n[13] D. W. Opitz, \"Feature selection for ensembles,\" AAAI/IAAI, vol. 379, p. 384, 1999.\n[14] L. Breiman, \"Random forests,\" Machine learning, vol. 45, no. 1, pp. 5-32, 2001.\n[15] R. C. Barros, M. P. Basgalupp, A. de Carvalho, and A. A. Freitas, \"A survey of evolutionary algorithms for decision-tree induction,\" IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, vol. 42, no. 3, pp. 291-312, 2012.\n[16] R. C. Barros, \"On the automatic design of decision-tree induction algorithms,\" Ph.D. dissertation, Universidade de São Paulo, 2013.\n[17] R. C. Barros, A. C. de Carvalho, and A. A. Freitas, Automatic Design of Decision-Tree Induction Algorithms, ser. SpringerBriefs in Computer Science. Springer, 2015, vol. 1.\n[18] H. E. Cagnini, R. C. Barros, and M. P. Basgalupp, \"Estimation of distribution algorithms for decision-tree induction,\" in Evolutionary Computation (CEC), 2017 IEEE Congress on. IEEE, 2017, pp. 20222029.\n[19] R. E. Schapire, \"A brief introduction to boosting,\" in Ijcal, vol. 99, 1999, pp. 1401-1406.\n[20] L. Breiman, \"Bagging predictors,\" Machine learning, vol. 24, no. 2, pp. $123-140,1996$.\n[21] D. H. Wolpert, \"Stacked generalization,\" Neural networks, vol. 5, no. 2, pp. 241-259, 1992.\n[22] P. Larrañaga and J. A. Lozano, Estimation of distribution algorithms: A new tool for evolutionary computation. Springer Science \\& Business Media, 2001, vol. 2.\n[23] J. H. Holland, Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence. MIT press, 1992.\n[24] M. Hauschild and M. Pelikan, \"An introduction and survey of estimation of distribution algorithms,\" Swarm and Evolutionary Computation, vol. 1, no. 3, pp. 111-128, 2011.\n[25] J. Bacardit, M. Stout, J. D. Hirst, K. Sastry, X. Llorà, and N. Krasnogor, \"Automated alphabet reduction method with evolutionary algorithms for protein structure prediction,\" in Proceedings of the 9th annual conference on Genetic and evolutionary computation. ACM, 2007, pp. 346-353.\n[26] H. E. Cagnini, R. C. Barros, C. V. Quevedo, and M. P. Basgalupp, \"Medoid-based data clustering with estimation of distribution algorithms,\" in Proceedings of the 31st Annual ACM Symposium on Applied Computing. ACM, 2016, pp. 112-115.\n[27] H. E. Cagnini and R. C. Barros, \"Pascal: An eda for parameterless shape-independent clustering,\" in Evolutionary Computation (CEC), 2016 IEEE Congress on. IEEE, 2016, pp. 3433-3440.\n[28] R. Santana, C. Bielza, and P. Larrañaga, \"Affinity propagation enhanced by estimation of distribution algorithms,\" in Annual conference on Genetic and evolutionary computation, 2011, pp. 331-338.\n[29] M. Pelikan and A. Hartmann, \"Searching for ground states of ising spin glasses with hierarchical boa and cluster exact approximation,\" Scalable Optimization via Probabilistic Modeling, pp. 333-349, 2006.\n[30] B. Krawczyk, M. Galar, Ł. Jelei, and F. Herrera, \"Evolutionary undersampling boosting for imbalanced classification of breast cancer malignancy,\" Applied Soft Computing, vol. 38, pp. 714-726, 2016.\n[31] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pfettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, \"Scikit-learn: Machine learning in Python,\" Journal of Machine Learning Research, vol. 12, pp. 2825-2830, 2011.\n[32] T. Hastie, S. Rosset, J. Zhu, and H. Zou, \"Multi-class adaboost,\" Statistics and its Interface, vol. 2, no. 3, pp. 349-360, 2009.\n[33] M. Lichman, \"UCI machine learning repository,\" 2013. [Online]. Available: http://archive.ics.uci.edu/ml\n[34] F. Wilcoxon, \"Individual comparisons by ranking methods,\" Biometrics bulletin, vol. 1, no. 6, pp. 80-83, 1945.\n[35] Y. Chen and Y. Zhao, \"A novel ensemble of classifiers for microarray data classification,\" Applied Soft Computing, vol. 8, no. 4, pp. 16641669, 2008.\n[36] P. A. D. Castro and F. J. Von Zuben, \"Learning ensembles of neural networks by means of a bayesian artificial immune system,\" IEEE Transactions on Neural Networks, vol. 22, no. 2, pp. 304-316, 2011.\n[37] T. Escovedo, A. V. A. da Cruz, M. Vellasco, and A. S. Koshiyama, \"Neve: A neuro-evolutionary ensemble for adaptive learning,\" in IFIP International Conference on Artificial Intelligence Applications and Innovations. Springer, 2013, pp. 636-645.\n[38] T. Escovedo, A. A. da Cruz, A. Koshiyama, R. Melo, and M. Vellasco, \"Neve++: A neuro-evolutionary unlimited ensemble for adaptive learning,\" in Neural Networks (IJCNN), 2014 International Joint Conference on. IEEE, 2014, pp. 3331-3338.",
    "references": [
      {
        "ref_id": "1",
        "text": "R. Saleh, H. Farsi, and S. H. Zahiri, \"Ensemble classification of polsar data using multi-objective heuristic combination rule,\" in Swarm Intelligence and Evolutionary Computation (CSIEC), 2016 1st Conference on. IEEE, 2016, pp. 88-92."
      },
      {
        "ref_id": "2",
        "text": "M. Milliken, Y. Bi, L. Galway, and G. Hawe, \"Multi-objective optimization of base classifiers in stackingc by nsga-ii for intrusion detection,\" in Computational Intelligence (SSCI), 2016 IEEE Symposium Series on. IEEE, 2016, pp. 1-8."
      },
      {
        "ref_id": "3",
        "text": "M. Krithiksa and R. Mallipeddi, \"Differential evolution with an ensemble of low-quality surrogates for expensive optimization problems,\" in Evolutionary Computation (CEC), 2016 IEEE Congress on. IEEE, 2016, pp. 78-85."
      },
      {
        "ref_id": "4",
        "text": "Y. Freund and R. E. Schapire, \"A desicion-theoretic generalization of on-line learning and an application to boosting,\" in European conference on computational learning theory. Springer, 1995, pp. 23-37."
      },
      {
        "ref_id": "5",
        "text": "K. Jackowski, B. Krawczyk, and M. Woźniak, \"Improved adaptive splitting and selection: the hybrid training method of a classifier based on a feature space partitioning,\" International journal of neural systems, vol. 24, no. 03, p. 1430007, 2014."
      },
      {
        "ref_id": "6",
        "text": "G. Folino, F. S. Pisani, and P. Sabatino, \"An incremental ensemble evolved by using genetic programming to efficiently detect drifts in cyber security datasets,\" in Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion. ACM, 2016, pp. $1103-1110$."
      },
      {
        "ref_id": "7",
        "text": "W. Zhang, Z. Qu, K. Zhang, W. Mao, Y. Ma, and X. Fan, \"A combined model based on ceemdan and modified flower pollination algorithm for wind speed forecasting,\" Energy Conversion and Management, vol. 136, pp. 439-451, 2017."
      },
      {
        "ref_id": "8",
        "text": "W. L. Woon and O. Kramer, \"Enhanced svr ensembles for wind power prediction,\" in Neural Networks (IJCNN), 2016 International Joint Conference on. IEEE, 2016, pp. 2743-2748."
      },
      {
        "ref_id": "9",
        "text": "A. Peimankar, S. J. Weddell, T. Jalal, and A. C. Lapthorn, \"Evolutionary multi-objective fault diagnosis of power transformers,\" Swarm and Evolutionary Computation, 2017."
      },
      {
        "ref_id": "10",
        "text": "——, \"Ensemble classifier selection using multi-objective PSO for fault diagnosis of power transformers,\" in Evolutionary Computation (CEC), 2016 IEEE Congress on. IEEE, 2016, pp. 3622-3629."
      },
      {
        "ref_id": "11",
        "text": "S. E. Lacy, M. A. Lones, and S. L. Smith, \"Forming classifier ensembles with multimodal evolutionary algorithms,\" in Evolutionary Computation (CEC), 2015 IEEE Congress on. IEEE, 2015, pp. 723-729."
      },
      {
        "ref_id": "12",
        "text": "Y. Freund, R. E. Schapire et al., \"Experiments with a new boosting algorithm,\" in Icml, vol. 96. Bari, Italy, 1996, pp. 148-156."
      },
      {
        "ref_id": "13",
        "text": "D. W. Opitz, \"Feature selection for ensembles,\" AAAI/IAAI, vol. 379, p. 384, 1999."
      },
      {
        "ref_id": "14",
        "text": "L. Breiman, \"Random forests,\" Machine learning, vol. 45, no. 1, pp. 5-32, 2001."
      },
      {
        "ref_id": "15",
        "text": "R. C. Barros, M. P. Basgalupp, A. de Carvalho, and A. A. Freitas, \"A survey of evolutionary algorithms for decision-tree induction,\" IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, vol. 42, no. 3, pp. 291-312, 2012."
      },
      {
        "ref_id": "16",
        "text": "R. C. Barros, \"On the automatic design of decision-tree induction algorithms,\" Ph.D. dissertation, Universidade de São Paulo, 2013."
      },
      {
        "ref_id": "17",
        "text": "R. C. Barros, A. C. de Carvalho, and A. A. Freitas, Automatic Design of Decision-Tree Induction Algorithms, ser. SpringerBriefs in Computer Science. Springer, 2015, vol. 1."
      },
      {
        "ref_id": "18",
        "text": "H. E. Cagnini, R. C. Barros, and M. P. Basgalupp, \"Estimation of distribution algorithms for decision-tree induction,\" in Evolutionary Computation (CEC), 2017 IEEE Congress on. IEEE, 2017, pp. 20222029."
      },
      {
        "ref_id": "19",
        "text": "R. E. Schapire, \"A brief introduction to boosting,\" in Ijcal, vol. 99, 1999, pp. 1401-1406."
      },
      {
        "ref_id": "20",
        "text": "L. Breiman, \"Bagging predictors,\" Machine learning, vol. 24, no. 2, pp. $123-140,1996$."
      },
      {
        "ref_id": "21",
        "text": "D. H. Wolpert, \"Stacked generalization,\" Neural networks, vol. 5, no. 2, pp. 241-259, 1992."
      },
      {
        "ref_id": "22",
        "text": "P. Larrañaga and J. A. Lozano, Estimation of distribution algorithms: A new tool for evolutionary computation. Springer Science \\& Business Media, 2001, vol. 2."
      },
      {
        "ref_id": "23",
        "text": "J. H. Holland, Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence. MIT press, 1992."
      },
      {
        "ref_id": "24",
        "text": "M. Hauschild and M. Pelikan, \"An introduction and survey of estimation of distribution algorithms,\" Swarm and Evolutionary Computation, vol. 1, no. 3, pp. 111-128, 2011."
      },
      {
        "ref_id": "25",
        "text": "J. Bacardit, M. Stout, J. D. Hirst, K. Sastry, X. Llorà, and N. Krasnogor, \"Automated alphabet reduction method with evolutionary algorithms for protein structure prediction,\" in Proceedings of the 9th annual conference on Genetic and evolutionary computation. ACM, 2007, pp. 346-353."
      },
      {
        "ref_id": "26",
        "text": "H. E. Cagnini, R. C. Barros, C. V. Quevedo, and M. P. Basgalupp, \"Medoid-based data clustering with estimation of distribution algorithms,\" in Proceedings of the 31st Annual ACM Symposium on Applied Computing. ACM, 2016, pp. 112-115."
      },
      {
        "ref_id": "27",
        "text": "H. E. Cagnini and R. C. Barros, \"Pascal: An eda for parameterless shape-independent clustering,\" in Evolutionary Computation (CEC), 2016 IEEE Congress on. IEEE, 2016, pp. 3433-3440."
      },
      {
        "ref_id": "28",
        "text": "R. Santana, C. Bielza, and P. Larrañaga, \"Affinity propagation enhanced by estimation of distribution algorithms,\" in Annual conference on Genetic and evolutionary computation, 2011, pp. 331-338."
      },
      {
        "ref_id": "29",
        "text": "M. Pelikan and A. Hartmann, \"Searching for ground states of ising spin glasses with hierarchical boa and cluster exact approximation,\" Scalable Optimization via Probabilistic Modeling, pp. 333-349, 2006."
      },
      {
        "ref_id": "30",
        "text": "B. Krawczyk, M. Galar, Ł. Jelei, and F. Herrera, \"Evolutionary undersampling boosting for imbalanced classification of breast cancer malignancy,\" Applied Soft Computing, vol. 38, pp. 714-726, 2016."
      },
      {
        "ref_id": "31",
        "text": "F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pfettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, \"Scikit-learn: Machine learning in Python,\" Journal of Machine Learning Research, vol. 12, pp. 2825-2830, 2011."
      },
      {
        "ref_id": "32",
        "text": "T. Hastie, S. Rosset, J. Zhu, and H. Zou, \"Multi-class adaboost,\" Statistics and its Interface, vol. 2, no. 3, pp. 349-360, 2009."
      },
      {
        "ref_id": "33",
        "text": "M. Lichman, \"UCI machine learning repository,\" 2013. [Online]. Available: http://archive.ics.uci.edu/ml"
      },
      {
        "ref_id": "34",
        "text": "F. Wilcoxon, \"Individual comparisons by ranking methods,\" Biometrics bulletin, vol. 1, no. 6, pp. 80-83, 1945."
      },
      {
        "ref_id": "35",
        "text": "Y. Chen and Y. Zhao, \"A novel ensemble of classifiers for microarray data classification,\" Applied Soft Computing, vol. 8, no. 4, pp. 16641669, 2008."
      },
      {
        "ref_id": "36",
        "text": "P. A. D. Castro and F. J. Von Zuben, \"Learning ensembles of neural networks by means of a bayesian artificial immune system,\" IEEE Transactions on Neural Networks, vol. 22, no. 2, pp. 304-316, 2011."
      },
      {
        "ref_id": "37",
        "text": "T. Escovedo, A. V. A. da Cruz, M. Vellasco, and A. S. Koshiyama, \"Neve: A neuro-evolutionary ensemble for adaptive learning,\" in IFIP International Conference on Artificial Intelligence Applications and Innovations. Springer, 2013, pp. 636-645."
      },
      {
        "ref_id": "38",
        "text": "T. Escovedo, A. A. da Cruz, A. Koshiyama, R. Melo, and M. Vellasco, \"Neve++: A neuro-evolutionary unlimited ensemble for adaptive learning,\" in Neural Networks (IJCNN), 2014 International Joint Conference on. IEEE, 2014, pp. 3331-3338."
      }
    ],
    "reference_count": 38,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "I",
      "table_title": "ACCURACY IN THE TEST SET FOR EACH ONE OF THE ALGORITHMS, IN THE EXPERIMENTED DATASETS. BOLD VALUES DENOTE THE BEST ALGORITHM FOR THAT DATASET, WHEREAS A BOLD AND UNDERLINED RESULT INDICATES A TIE IN FIRST PLACE.",
      "headers": [
        "Dataset",
        "AdaBoost",
        "AdaBoost-ones",
        "AdaBoost-normal",
        "EEL (ours)"
      ],
      "rows": [
        [
          "diabetes",
          "$0.755 \\pm 0.000$",
          "$0.727 \\pm 0.000$",
          "$0.716 \\pm 0.013$",
          "$\\mathbf{0 . 7 5 6} \\pm \\mathbf{0 . 0 0 4}$"
        ],
        [
          "ecoli",
          "$0.705 \\pm 0.000$",
          "$0.720 \\pm 0.000$",
          "$0.661 \\pm 0.089$",
          "$\\mathbf{0 . 8 1 8} \\pm \\mathbf{0 . 0 0 3}$"
        ],
        [
          "glass",
          "$0.579 \\pm 0.000$",
          "$0.561 \\pm 0.000$",
          "$0.487 \\pm 0.034$",
          "$\\mathbf{0 . 5 0 8} \\pm \\mathbf{0 . 0 0 4}$"
        ],
        [
          "hayes roth",
          "$0.594 \\pm 0.000$",
          "$\\mathbf{0 . 0 0 0} \\pm \\mathbf{0 . 0 0 0}$",
          "$0.598 \\pm 0.003$",
          "$0.598 \\pm 0.003$"
        ],
        [
          "ionosphere",
          "$0.917 \\pm 0.000$",
          "$\\mathbf{0 . 9 2 6} \\pm \\mathbf{0 . 0 0 0}$",
          "$0.920 \\pm 0.004$",
          "$0.917 \\pm 0.006$"
        ],
        [
          "iris",
          "$0.933 \\pm 0.000$",
          "$\\mathbf{0 . 9 4 0} \\pm \\mathbf{0 . 0 0 0}$",
          "$0.933 \\pm 0.004$",
          "$0.933 \\pm 0.000$"
        ],
        [
          "KDD synth control",
          "$0.745 \\pm 0.000$",
          "$0.733 \\pm 0.000$",
          "$0.717 \\pm 0.016$",
          "$\\mathbf{0 . 7 8 4} \\pm \\mathbf{0 . 0 0 3}$"
        ],
        [
          "liver disorders",
          "$0.725 \\pm 0.000$",
          "$0.635 \\pm 0.000$",
          "$0.654 \\pm 0.019$",
          "$\\mathbf{0 . 7 3 0} \\pm \\mathbf{0 . 0 0 6}$"
        ],
        [
          "segment",
          "$0.818 \\pm 0.000$",
          "$0.777 \\pm 0.000$",
          "$0.691 \\pm 0.065$",
          "$\\mathbf{0 . 8 6 6} \\pm \\mathbf{0 . 0 0 0}$"
        ],
        [
          "semeion",
          "$0.964 \\pm 0.000$",
          "$\\mathbf{0 . 9 6 7} \\pm \\mathbf{0 . 0 0 0}$",
          "$0.954 \\pm 0.007$",
          "$0.966 \\pm 0.001$"
        ],
        [
          "sonar",
          "$\\mathbf{0 . 8 1 5} \\pm \\mathbf{0 . 0 0 2}$",
          "$0.797 \\pm 0.007$",
          "$0.797 \\pm 0.014$",
          "$0.809 \\pm 0.017$"
        ],
        [
          "vehicle",
          "$0.621 \\pm 0.000$",
          "$0.603 \\pm 0.000$",
          "$0.589 \\pm 0.012$",
          "$\\mathbf{0 . 6 6 4} \\pm \\mathbf{0 . 0 0 9}$"
        ],
        [
          "wine",
          "$0.944 \\pm 0.000$",
          "$\\mathbf{0 . 9 6 1} \\pm \\mathbf{0 . 0 0 0}$",
          "$0.950 \\pm 0.004$",
          "$0.953 \\pm 0.006$"
        ],
        [
          "winequality red",
          "$0.548 \\pm 0.000$",
          "$0.477 \\pm 0.000$",
          "$0.441 \\pm 0.018$",
          "$\\mathbf{0 . 5 6 0} \\pm \\mathbf{0 . 0 0 3}$"
        ],
        [
          "winequality white",
          "$0.473 \\pm 0.000$",
          "$0.415 \\pm 0.000$",
          "$0.408 \\pm 0.032$",
          "$\\mathbf{0 . 4 9 4} \\pm \\mathbf{0 . 0 0 1}$"
        ],
        [
          "Wins",
          1,
          5,
          0,
          9
        ]
      ],
      "row_count": 16,
      "column_count": 5
    },
    {
      "table_number": "II",
      "table_title": "HYPER-PARAMETERS USED BY EEL.",
      "headers": [
        "Parameter",
        "Description",
        "Value"
      ],
      "rows": [
        [
          "$B$",
          "Number of decision trees",
          50
        ],
        [
          "$G$",
          "Number of generations",
          50
        ],
        [
          "$S$",
          "Number of individuals",
          100
        ],
        [
          "$\\delta$",
          "Fitness threshold",
          0.01
        ],
        [
          "$\\Delta$",
          "Generation threshold",
          5
        ],
        [
          "$\\bar{x}$",
          "Mean of Gaussian",
          "AdaBoost weights"
        ],
        [
          "$\\sigma$",
          "Standard deviation of Gaussian",
          0.25
        ],
        [
          "$\\tau$",
          "Standard deviation decrease",
          0.005
        ]
      ],
      "row_count": 8,
      "column_count": 3
    },
    {
      "table_number": "III",
      "table_title": "UCI DATASETS USED IN OUR EXPERIMENTS.",
      "headers": [
        "Dataset",
        "Instances",
        "Attributes",
        "Min <br> class",
        "Max <br> class",
        "classes"
      ],
      "rows": [
        [
          "diabetes",
          768,
          8,
          268,
          500,
          2
        ],
        [
          "ecoli",
          336,
          7,
          2,
          143,
          8
        ],
        [
          "glass",
          214,
          9,
          9,
          76,
          6
        ],
        [
          "hayes roth",
          160,
          4,
          31,
          65,
          3
        ],
        [
          "ionosphere",
          351,
          33,
          126,
          225,
          2
        ],
        [
          "iris",
          150,
          4,
          50,
          50,
          3
        ],
        [
          "KDD synth control",
          600,
          60,
          100,
          100,
          6
        ],
        [
          "liver disorders",
          345,
          6,
          145,
          200,
          2
        ],
        [
          "segment",
          2310,
          18,
          330,
          330,
          7
        ],
        [
          "semeion",
          1593,
          265,
          158,
          1435,
          2
        ],
        [
          "sonar",
          208,
          60,
          97,
          111,
          2
        ],
        [
          "vehicle",
          846,
          18,
          199,
          218,
          4
        ],
        [
          "wine",
          178,
          13,
          48,
          71,
          3
        ],
        [
          "winequality red",
          1599,
          11,
          10,
          681,
          6
        ],
        [
          "winequality white",
          4898,
          11,
          5,
          2198,
          7
        ]
      ],
      "row_count": 15,
      "column_count": 6
    },
    {
      "table_number": "IV",
      "table_title": "RESULTS OF THE WILCOXON PAIRWISE TEST REGARDING PREDICTIVE ACCURACY. UNDERLINED VALUES INDICATE A REFUSAL OF THE NULL HYPOTHESIS. CHECKS $\\sqrt{ }$ INDICATE A SUPERIORITY OF THE ROW ALGORITHM OVER THE COLUMN ONE.",
      "headers": [
        "",
        "AdaBoost",
        "AdaBoost-Ones",
        "AdaBoost-Normal",
        "EEL"
      ],
      "rows": [
        [
          "AdaBoost",
          "",
          "$\\checkmark$",
          "$\\checkmark$",
          ""
        ],
        [
          "AdaBoost-ones",
          "",
          "",
          "$\\checkmark$",
          ""
        ],
        [
          "AdaBoost-normal",
          "",
          "",
          "$\\checkmark$",
          ""
        ],
        [
          "EEL",
          "$\\checkmark$",
          "$\\checkmark$",
          "$\\checkmark$",
          ""
        ]
      ],
      "row_count": 4,
      "column_count": 5
    }
  ]
}