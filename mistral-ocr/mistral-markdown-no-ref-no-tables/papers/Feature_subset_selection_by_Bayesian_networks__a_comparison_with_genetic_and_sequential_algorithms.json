{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2001/Feature subset selection by Bayesian networks  a comparison with genetic and sequential algorithms.md",
    "filename": "Feature subset selection by Bayesian networks  a comparison with genetic and sequential algorithms.md",
    "title": "Feature subset selection by Bayesian networks  a comparison with genetic and sequential algorithms",
    "year": "2001"
  },
  "references": {
    "header": "## References",
    "content": "[1] S. Acid, L.M. de Campos, Approximations of causal networks by polytrees: an empirical study, in: B. Bouchon-Meunier, R.R. Yager, L.A. Zadeh (Eds.), Advances in Intelligent Computing, vol. 945, Lecture Notes in Computer Science, Springer, Berlin, 1995, pp. 149-158.\n[2] D.W. Aha, R.L. Bankert, Feature selection for case-based classification of cloud types: An empirical comparison, in: Proceedings of the AAAI'94 Workshop on Case-Based Reasoning, 1994, pp. 106-112.\n[3] Alpaydin, E., Combined $5 \\times 2 \\mathrm{cv} F$ test for comparing supervised classification learning algorithms, Neural Comput. 11, 1885-1982.\n[4] T. Bäck, Evolutionary Algorithms is Theory and Practice, Oxford University Press, Oxford, 1996.\n[5] S. Baluja, Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning, Technical Report CMU-CS-94-163, Carnegie Mellon University, Pittsburgh, PA, 1994.\n[6] S. Baluja, S. Davies, Using optimal dependency-trees for combinatorial optimization: Learning the structure of the search space, in: Proceedings of the Fourteenth International Conference on Machine Learning, 1997, pp. 30-38.\n[7] P.P. Bonissone, Y.-T. Chen, K. Goebel, P.S. Khedkar, Hybrid soft computing systems: Industrial and commercial applications, Proc. IEEE 87 (9) (1999) 1641-1667.\n[8] W. Buntine, Theory refinement in Bayesian networks, in: Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, 1991, pp. 52-60.\n[9] E. Castillo, J.M. Gutiérrez, A.S. Hadi, Expert Systems and Probabilistic Network Models, Springer, Berlin, Germany, 1997.\n[10] B. Cestnik, Estimating probabilities: a crucial task in machine learning, in: Proceedings of the European Conference on Artificial Intelligence, 1990, 147-149.\n[11] M. Chickering, D. Geiger, D. Heckerman, Learning Bayesian networks is NP-hard, Technical Report MSR-TR-94-17, Microsoft Research, Redmond, WA, 1994.\n[12] D.M. Chickering, D. Geiger, D. Heckerman, Learning Bayesian networks: Search methods and experimental results, Preliminary Papers of the 5th International Workshop on Artificial Intelligence and Statistics, 1995, pp. 112-128.\n[13] A.P. Dawid, Conditional independence in statistical theory, J. R. Stat. Soc. B 41 (1979) 1-31.\n[14] J.S. De Bonet, C.L. Isbell, P. Viola, MIMIC: Finding optima by estimating probability densities, in: Advances in Neural Information Processing Systems, vol. 9, MIT Press, Cambridge, MA, 1997.\n[15] J. Doak, An evaluation of feature selection methods and their application to computer security, Technical Report CSE-92-18, University of California, Davis, CA, 1992.\n[16] R. Etxeberria, P. Larrañaga, Global optimization with Bayesian networks, in: Proceedings of the Second Symposium on Artificial Intelligence, La Habana, Cuba, 1999, pp. 332-339.\n[17] N. Friedman, Z. Yakhini, On the sample complexity of learning Bayesian networks, in: Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence, Portland, OR, 1996, pp. 274-282.\n[18] D.E. Goldberg, Genetic algorithms in search, optimization, and machine learning, AddisonWesley, Reading, MA, 1989.\n[19] J.J. Grefenstatte, Optimization of control parameters for genetic algorithms, IEEE Trans. Syst., Man Cybern. 1 (1986) 122-128.\n[20] G.R. Harik, F.G. Lobo, D.E. Goldberg, The compact genetic algorithm, IlliGAL Report 97006, Illinois Genetic Algorithms Laboratory, University of Illinois, Urbana-Champaign, 1997.\n[21] G. Harik, Linkage learning via probabilistic modelling in the ECGA, IlliGAL Report 99010, Illinois Genetic Algorithms Laboratory, University of Illinois, Urbana-Champaign, 1999.\n[22] Henrion, M., Propagating uncertainty in Bayesian networks by probabilistic logic sampling, in: Uncertainty in Artificial Intelligence 2, Elsevier, Amsterdam, 1988, pp. 149-163,.\n[23] I. Inza, Feature weighting for nearest neighbor algorithm by Bayesian networks based combinatorial optimization, in: Proceedings of the Student Session of Advanced Course on Artificial Intelligence, 1999, pp. 33-35.\n[24] I. Inza, P. Larrañaga, B. Sierra, R. Etxeberria, J.A. Lozano, J.M. Peña, Representing the behaviour of supervised classification learning algorithms by Bayesian networks, Pattern Recogn. Lett. 20 (11-13) (1999) 1201-1210.\n[25] I. Inza, P. Larrañaga, R. Etxeberria, B. Sierra, Feature subset selection by Bayesian networks based optimization, Artif. Intell. 123 (1-2) (2000) 157-184.\n[26] I. Inza, M. Merino, P. Larrañaga, J. Quiroga, B. Sierra, M. Girala, Feature subset selection by genetic algorithms and estimation of distribution algorithms. A case study in the survival of cirrhotic patients treated with TIPS, Artif. Intell. Med., in press.\n[27] A.K. Jain, R. Chandrasekaran, Dimensionality and sample size considerations in pattern recognition practice, in: Handbook of statistics - II, North-Holland, Amsterdam, The Netherlands, 1982, pp. 835-855.\n[28] A. Jain, D. Zongker, Feature selection: Evaluation, application, and small sample performance, IEEE Trans. Pattern Anal. 19 (2) (1997) 153-158.\n[29] J. Kittler, Feature Set Search Algorithms, in: Pattern Recognition and Signal Processing, Sithoff and Noordhoff, Alphen aan den Rijn, The Netherlands, 1978, pp. 41-60.\n[30] R. Kohavi, G. John, Wrappers for feature subset selection, Artif. Intell. 97 (1-2) (1997) 273324 .\n[31] R. Kohavi, D. Sommerfield, J. Dougherty, Data mining using MLC++, a Machine Learning Library in C++, International Journal of Artificial Intelligence Tools 6 (1997) 537-566.\n[32] M. Kudo, J. Sklansky, Comparison of algorithms that select features for pattern classifiers, Pattern Recogn. 33 (2000) 25-41.\n[33] P. Langley, S. Sage, Induction of selective Bayesian classifiers, in: Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, 1994, pp. 399-406.\n[34] P. Larrañaga, C.M.H. Kuijpers, R.H. Murga, Y. Yurramendi, Learning Bayesian network structures by searching for the best ordering with genetic algorithms, IEEE Trans. Syst. Man Cybern. A 26 (4) (1996) 487-493.\n[35] P. Larrañaga, M. Poza, Y. Yurramendi, R.H. Murga, C.M.H. Kuijpers, Structure Learning of Bayesian networks by genetic algorithms: A performance analysis of control parameters, IEEE Trans. Pattern Anal. 18 (9) (1996) 912-926.\n[36] P. Larrañaga, R. Etxeberria, J.A. Lozano, J.M. Peña, Combinatorial optimization by learning and simulation of Bayesian networks, in Proceedings of the Conference in Uncertainty in Artificial Intelligence, 2000, pp. 343-352.\n[37] P. Larrañaga, J.A. Lozano, Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation, Kluwer Academic Publishers, Norwell, MA, 2001.\n[38] S.L. Lauritzen, Graphical Models, Oxford University Press, Oxford, England, 1996.\n[39] H. Liu, H. Motoda, Feature Selection for Knowledge Discovery and Data Mining, Kluwer Academic Publishers, Norwell, MA, 1998.\n[40] A.J. Miller, Subset Selection in Regression, Chapman \\& Hall, Washington, DC, 1990.\n[41] D. Mladenić, Feature subset selection in text-learning, in: Proceedings of the Tenth European Conference on Machine Learning, 1988, pp. 95-100.\n[42] H. Müehlenbein, The equation for response to selection and its use for prediction, Evol. Comput. 5 (3) (1997) 303-346.\n[43] H. Müehlenbein, G. Paaß, From recombination of genes to the estimation of distributions, in: Binary Parameters, Lecture Notes in Computer Science 1411: Parallel Problem Solving from Nature - PPSN IV, 1996, pp. 178-187.\n[44] H. Müehlenbein, T. Mahnig, FDA - A scalable evolutionary algorithm for the optimization of additively decomposed functions, Evol. Comput. 7 (4) (1999) 353-376.\n[45] P. Murphy, UCI Repository of Machine Learning Databases, Department of Information and Computer Science, University of California, Irvine, CA, 1995.\n[46] P. Narendra, K. Fukunaga, A branch and bound algorithm for feature subset selection, IEEE Trans. Comput. C-26 (9) (1977) 917-922.\n[47] A. Ochoa, M. Soto, R. Santana, J. Madera, N. Jorge, The factorized distribution algorithm and the junction tree: A learning perspective, in: Proceedings of the Second Symposium on Artificial Intelligence, 1999, pp. 368-377.\n[48] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Morgan Kaufmann, Morgan Kaufmann, Palo Alto, CA, 1988.\n[49] M. Pelikan, D.E. Goldberg, E. Cantú-Paz, BOA: The Bayesian Optimization Algorithm, IlliGAL Report 99003, Illinois Genetic Algorithms Laboratory, University of Illinois, Urbana-Champaign, 1999.\n[50] M. Pelikan, H. Müehlenbein, The bivariate marginal distribution algorithm, in: Advances in Soft Computing-Engineering Design and Manufacturing, Springer, London, 1999, pp. 521-535.\n[51] G.M. Provan, M. Singh, Learning Bayesian networks using feature selection, Preliminary Papers of the Fifth International Workshop on Artificial Intelligence and Statistics, 1995, pp. $450-456$.\n[52] P. Pudil, J. Novovicova, J. Kittler, Floating search methods in feature selection, Pattern Recogn. Lett. 15 (1) (1994) 1119-1125.\n[53] R. Sangüesa, U. Cortés, A. Gisolfi, A parallel algorithm for building possibilistic causal networks, Int. J. Approx. Reason. 18 (3-4) (1998) 251-270.\n[54] W. Siedelecky, J. Sklansky, On automatic feature selection, Int. J. Pattern Recogn. 2 (1998) 197-220.\n[55] G. Schwarz, Estimating the dimension of a model, Ann. Stat. 7 (1978) 461-464.\n[56] M. Soto, A. Ochoa, S. Acid, L.M. de Campos, Introducing polytree approximation of distribution algorithm, in: Proceedings of the Second Symposium on Artificial Intelligence, 1999, pp. 360-367.\n[57] G. Syswerda, Uniform crossover in genetic algorithms, in: Proceedings of the International Conference on Genetic Algorithms, vol. 3, 1989, pp. 2-9.\n[58] H. Vafaie, K. De Jong, Robust feature selection algorithms, in: Proceedings of the Fifth International Conference on Tools with Artificial Intelligence, 1993, 356-363.\n[59] M.L. Wong, W. Lam, K.S. Leung, Using Evolutionary programming and minimum description length principle for data mining of Bayesian networks, IEEE Trans. Pattern Anal. 21 (2) (1999) 174-178.\n[60] Y. Xiang, T. Chu, Parallel learning of belief networks in large and difficult domains, Data Min. Knowl. Disc. 3 (3) (1999) 315-338.",
    "references": [
      {
        "ref_id": "1",
        "text": "S. Acid, L.M. de Campos, Approximations of causal networks by polytrees: an empirical study, in: B. Bouchon-Meunier, R.R. Yager, L.A. Zadeh (Eds.), Advances in Intelligent Computing, vol. 945, Lecture Notes in Computer Science, Springer, Berlin, 1995, pp. 149-158."
      },
      {
        "ref_id": "2",
        "text": "D.W. Aha, R.L. Bankert, Feature selection for case-based classification of cloud types: An empirical comparison, in: Proceedings of the AAAI'94 Workshop on Case-Based Reasoning, 1994, pp. 106-112."
      },
      {
        "ref_id": "3",
        "text": "Alpaydin, E., Combined $5 \\times 2 \\mathrm{cv} F$ test for comparing supervised classification learning algorithms, Neural Comput. 11, 1885-1982."
      },
      {
        "ref_id": "4",
        "text": "T. Bäck, Evolutionary Algorithms is Theory and Practice, Oxford University Press, Oxford, 1996."
      },
      {
        "ref_id": "5",
        "text": "S. Baluja, Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning, Technical Report CMU-CS-94-163, Carnegie Mellon University, Pittsburgh, PA, 1994."
      },
      {
        "ref_id": "6",
        "text": "S. Baluja, S. Davies, Using optimal dependency-trees for combinatorial optimization: Learning the structure of the search space, in: Proceedings of the Fourteenth International Conference on Machine Learning, 1997, pp. 30-38."
      },
      {
        "ref_id": "7",
        "text": "P.P. Bonissone, Y.-T. Chen, K. Goebel, P.S. Khedkar, Hybrid soft computing systems: Industrial and commercial applications, Proc. IEEE 87 (9) (1999) 1641-1667."
      },
      {
        "ref_id": "8",
        "text": "W. Buntine, Theory refinement in Bayesian networks, in: Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, 1991, pp. 52-60."
      },
      {
        "ref_id": "9",
        "text": "E. Castillo, J.M. Gutiérrez, A.S. Hadi, Expert Systems and Probabilistic Network Models, Springer, Berlin, Germany, 1997."
      },
      {
        "ref_id": "10",
        "text": "B. Cestnik, Estimating probabilities: a crucial task in machine learning, in: Proceedings of the European Conference on Artificial Intelligence, 1990, 147-149."
      },
      {
        "ref_id": "11",
        "text": "M. Chickering, D. Geiger, D. Heckerman, Learning Bayesian networks is NP-hard, Technical Report MSR-TR-94-17, Microsoft Research, Redmond, WA, 1994."
      },
      {
        "ref_id": "12",
        "text": "D.M. Chickering, D. Geiger, D. Heckerman, Learning Bayesian networks: Search methods and experimental results, Preliminary Papers of the 5th International Workshop on Artificial Intelligence and Statistics, 1995, pp. 112-128."
      },
      {
        "ref_id": "13",
        "text": "A.P. Dawid, Conditional independence in statistical theory, J. R. Stat. Soc. B 41 (1979) 1-31."
      },
      {
        "ref_id": "14",
        "text": "J.S. De Bonet, C.L. Isbell, P. Viola, MIMIC: Finding optima by estimating probability densities, in: Advances in Neural Information Processing Systems, vol. 9, MIT Press, Cambridge, MA, 1997."
      },
      {
        "ref_id": "15",
        "text": "J. Doak, An evaluation of feature selection methods and their application to computer security, Technical Report CSE-92-18, University of California, Davis, CA, 1992."
      },
      {
        "ref_id": "16",
        "text": "R. Etxeberria, P. Larrañaga, Global optimization with Bayesian networks, in: Proceedings of the Second Symposium on Artificial Intelligence, La Habana, Cuba, 1999, pp. 332-339."
      },
      {
        "ref_id": "17",
        "text": "N. Friedman, Z. Yakhini, On the sample complexity of learning Bayesian networks, in: Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence, Portland, OR, 1996, pp. 274-282."
      },
      {
        "ref_id": "18",
        "text": "D.E. Goldberg, Genetic algorithms in search, optimization, and machine learning, AddisonWesley, Reading, MA, 1989."
      },
      {
        "ref_id": "19",
        "text": "J.J. Grefenstatte, Optimization of control parameters for genetic algorithms, IEEE Trans. Syst., Man Cybern. 1 (1986) 122-128."
      },
      {
        "ref_id": "20",
        "text": "G.R. Harik, F.G. Lobo, D.E. Goldberg, The compact genetic algorithm, IlliGAL Report 97006, Illinois Genetic Algorithms Laboratory, University of Illinois, Urbana-Champaign, 1997."
      },
      {
        "ref_id": "21",
        "text": "G. Harik, Linkage learning via probabilistic modelling in the ECGA, IlliGAL Report 99010, Illinois Genetic Algorithms Laboratory, University of Illinois, Urbana-Champaign, 1999."
      },
      {
        "ref_id": "22",
        "text": "Henrion, M., Propagating uncertainty in Bayesian networks by probabilistic logic sampling, in: Uncertainty in Artificial Intelligence 2, Elsevier, Amsterdam, 1988, pp. 149-163,."
      },
      {
        "ref_id": "23",
        "text": "I. Inza, Feature weighting for nearest neighbor algorithm by Bayesian networks based combinatorial optimization, in: Proceedings of the Student Session of Advanced Course on Artificial Intelligence, 1999, pp. 33-35."
      },
      {
        "ref_id": "24",
        "text": "I. Inza, P. Larrañaga, B. Sierra, R. Etxeberria, J.A. Lozano, J.M. Peña, Representing the behaviour of supervised classification learning algorithms by Bayesian networks, Pattern Recogn. Lett. 20 (11-13) (1999) 1201-1210."
      },
      {
        "ref_id": "25",
        "text": "I. Inza, P. Larrañaga, R. Etxeberria, B. Sierra, Feature subset selection by Bayesian networks based optimization, Artif. Intell. 123 (1-2) (2000) 157-184."
      },
      {
        "ref_id": "26",
        "text": "I. Inza, M. Merino, P. Larrañaga, J. Quiroga, B. Sierra, M. Girala, Feature subset selection by genetic algorithms and estimation of distribution algorithms. A case study in the survival of cirrhotic patients treated with TIPS, Artif. Intell. Med., in press."
      },
      {
        "ref_id": "27",
        "text": "A.K. Jain, R. Chandrasekaran, Dimensionality and sample size considerations in pattern recognition practice, in: Handbook of statistics - II, North-Holland, Amsterdam, The Netherlands, 1982, pp. 835-855."
      },
      {
        "ref_id": "28",
        "text": "A. Jain, D. Zongker, Feature selection: Evaluation, application, and small sample performance, IEEE Trans. Pattern Anal. 19 (2) (1997) 153-158."
      },
      {
        "ref_id": "29",
        "text": "J. Kittler, Feature Set Search Algorithms, in: Pattern Recognition and Signal Processing, Sithoff and Noordhoff, Alphen aan den Rijn, The Netherlands, 1978, pp. 41-60."
      },
      {
        "ref_id": "30",
        "text": "R. Kohavi, G. John, Wrappers for feature subset selection, Artif. Intell. 97 (1-2) (1997) 273324 ."
      },
      {
        "ref_id": "31",
        "text": "R. Kohavi, D. Sommerfield, J. Dougherty, Data mining using MLC++, a Machine Learning Library in C++, International Journal of Artificial Intelligence Tools 6 (1997) 537-566."
      },
      {
        "ref_id": "32",
        "text": "M. Kudo, J. Sklansky, Comparison of algorithms that select features for pattern classifiers, Pattern Recogn. 33 (2000) 25-41."
      },
      {
        "ref_id": "33",
        "text": "P. Langley, S. Sage, Induction of selective Bayesian classifiers, in: Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, 1994, pp. 399-406."
      },
      {
        "ref_id": "34",
        "text": "P. Larrañaga, C.M.H. Kuijpers, R.H. Murga, Y. Yurramendi, Learning Bayesian network structures by searching for the best ordering with genetic algorithms, IEEE Trans. Syst. Man Cybern. A 26 (4) (1996) 487-493."
      },
      {
        "ref_id": "35",
        "text": "P. Larrañaga, M. Poza, Y. Yurramendi, R.H. Murga, C.M.H. Kuijpers, Structure Learning of Bayesian networks by genetic algorithms: A performance analysis of control parameters, IEEE Trans. Pattern Anal. 18 (9) (1996) 912-926."
      },
      {
        "ref_id": "36",
        "text": "P. Larrañaga, R. Etxeberria, J.A. Lozano, J.M. Peña, Combinatorial optimization by learning and simulation of Bayesian networks, in Proceedings of the Conference in Uncertainty in Artificial Intelligence, 2000, pp. 343-352."
      },
      {
        "ref_id": "37",
        "text": "P. Larrañaga, J.A. Lozano, Estimation of Distribution Algorithms. A New Tool for Evolutionary Computation, Kluwer Academic Publishers, Norwell, MA, 2001."
      },
      {
        "ref_id": "38",
        "text": "S.L. Lauritzen, Graphical Models, Oxford University Press, Oxford, England, 1996."
      },
      {
        "ref_id": "39",
        "text": "H. Liu, H. Motoda, Feature Selection for Knowledge Discovery and Data Mining, Kluwer Academic Publishers, Norwell, MA, 1998."
      },
      {
        "ref_id": "40",
        "text": "A.J. Miller, Subset Selection in Regression, Chapman \\& Hall, Washington, DC, 1990."
      },
      {
        "ref_id": "41",
        "text": "D. Mladenić, Feature subset selection in text-learning, in: Proceedings of the Tenth European Conference on Machine Learning, 1988, pp. 95-100."
      },
      {
        "ref_id": "42",
        "text": "H. Müehlenbein, The equation for response to selection and its use for prediction, Evol. Comput. 5 (3) (1997) 303-346."
      },
      {
        "ref_id": "43",
        "text": "H. Müehlenbein, G. Paaß, From recombination of genes to the estimation of distributions, in: Binary Parameters, Lecture Notes in Computer Science 1411: Parallel Problem Solving from Nature - PPSN IV, 1996, pp. 178-187."
      },
      {
        "ref_id": "44",
        "text": "H. Müehlenbein, T. Mahnig, FDA - A scalable evolutionary algorithm for the optimization of additively decomposed functions, Evol. Comput. 7 (4) (1999) 353-376."
      },
      {
        "ref_id": "45",
        "text": "P. Murphy, UCI Repository of Machine Learning Databases, Department of Information and Computer Science, University of California, Irvine, CA, 1995."
      },
      {
        "ref_id": "46",
        "text": "P. Narendra, K. Fukunaga, A branch and bound algorithm for feature subset selection, IEEE Trans. Comput. C-26 (9) (1977) 917-922."
      },
      {
        "ref_id": "47",
        "text": "A. Ochoa, M. Soto, R. Santana, J. Madera, N. Jorge, The factorized distribution algorithm and the junction tree: A learning perspective, in: Proceedings of the Second Symposium on Artificial Intelligence, 1999, pp. 368-377."
      },
      {
        "ref_id": "48",
        "text": "J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Morgan Kaufmann, Morgan Kaufmann, Palo Alto, CA, 1988."
      },
      {
        "ref_id": "49",
        "text": "M. Pelikan, D.E. Goldberg, E. Cantú-Paz, BOA: The Bayesian Optimization Algorithm, IlliGAL Report 99003, Illinois Genetic Algorithms Laboratory, University of Illinois, Urbana-Champaign, 1999."
      },
      {
        "ref_id": "50",
        "text": "M. Pelikan, H. Müehlenbein, The bivariate marginal distribution algorithm, in: Advances in Soft Computing-Engineering Design and Manufacturing, Springer, London, 1999, pp. 521-535."
      },
      {
        "ref_id": "51",
        "text": "G.M. Provan, M. Singh, Learning Bayesian networks using feature selection, Preliminary Papers of the Fifth International Workshop on Artificial Intelligence and Statistics, 1995, pp. $450-456$."
      },
      {
        "ref_id": "52",
        "text": "P. Pudil, J. Novovicova, J. Kittler, Floating search methods in feature selection, Pattern Recogn. Lett. 15 (1) (1994) 1119-1125."
      },
      {
        "ref_id": "53",
        "text": "R. Sangüesa, U. Cortés, A. Gisolfi, A parallel algorithm for building possibilistic causal networks, Int. J. Approx. Reason. 18 (3-4) (1998) 251-270."
      },
      {
        "ref_id": "54",
        "text": "W. Siedelecky, J. Sklansky, On automatic feature selection, Int. J. Pattern Recogn. 2 (1998) 197-220."
      },
      {
        "ref_id": "55",
        "text": "G. Schwarz, Estimating the dimension of a model, Ann. Stat. 7 (1978) 461-464."
      },
      {
        "ref_id": "56",
        "text": "M. Soto, A. Ochoa, S. Acid, L.M. de Campos, Introducing polytree approximation of distribution algorithm, in: Proceedings of the Second Symposium on Artificial Intelligence, 1999, pp. 360-367."
      },
      {
        "ref_id": "57",
        "text": "G. Syswerda, Uniform crossover in genetic algorithms, in: Proceedings of the International Conference on Genetic Algorithms, vol. 3, 1989, pp. 2-9."
      },
      {
        "ref_id": "58",
        "text": "H. Vafaie, K. De Jong, Robust feature selection algorithms, in: Proceedings of the Fifth International Conference on Tools with Artificial Intelligence, 1993, 356-363."
      },
      {
        "ref_id": "59",
        "text": "M.L. Wong, W. Lam, K.S. Leung, Using Evolutionary programming and minimum description length principle for data mining of Bayesian networks, IEEE Trans. Pattern Anal. 21 (2) (1999) 174-178."
      },
      {
        "ref_id": "60",
        "text": "Y. Xiang, T. Chu, Parallel learning of belief networks in large and difficult domains, Data Min. Knowl. Disc. 3 (3) (1999) 315-338."
      }
    ],
    "reference_count": 60,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Details of experimental domains",
      "headers": [
        "Domain",
        "Number of <br> instances",
        "Number of <br> classes",
        "Number of features and <br> their types"
      ],
      "rows": [
        [
          "Ionosphere",
          351,
          2,
          "$34(34-\\mathrm{C})$"
        ],
        [
          "Horse-colic",
          368,
          2,
          "$22(15-\\mathrm{D}, 7-\\mathrm{C})$"
        ],
        [
          "Soybean-large",
          683,
          19,
          "$35(35-\\mathrm{C})$"
        ],
        [
          "Anneal",
          898,
          6,
          "$38(6-\\mathrm{D}, 32-\\mathrm{C})$"
        ],
        [
          "Image",
          2310,
          7,
          "$19(19-\\mathrm{C})$"
        ]
      ],
      "row_count": 5,
      "column_count": 4
    },
    {
      "table_number": "2",
      "table_title": "Accuracy percentages of the NB classifier on real datasets without feature selection and using exposed five FSS methods",
      "headers": [
        "Domain",
        "Without FSS",
        "SFS",
        "SBE",
        "GA-o",
        "GA-u",
        "FSS-EBNA"
      ],
      "rows": [
        [
          "Ionosphere",
          "$84.84 \\pm 3.12^{\\dagger}$",
          "$90.25 \\pm 1.58^{*}$",
          "$91.39 \\pm 2.68$",
          "$91.17 \\pm 3.19$",
          "$90.97 \\pm 2.56^{*}$",
          "$92.40 \\pm 2.04$"
        ],
        [
          "Horse-colic",
          "$78.97 \\pm 2.98^{\\dagger}$",
          "$83.31 \\pm 1.98$",
          "$82.12 \\pm 2.41^{*}$",
          "$83.43 \\pm 2.82$",
          "$83.51 \\pm 1.47$",
          "$83.93 \\pm 1.58$"
        ],
        [
          "Soybean-large",
          "$81.96 \\pm 3.46^{\\dagger}$",
          "$86.38 \\pm 3.30^{*}$",
          "$87.78 \\pm 3.90^{*}$",
          "$85.64 \\pm 4.06^{\\dagger}$",
          "$86.09 \\pm 4.37^{\\dagger}$",
          "$88.64 \\pm 1.70$"
        ],
        [
          "Anneal",
          "$93.01 \\pm 3.13^{*}$",
          "$86.72 \\pm 2.09^{\\dagger}$",
          "$92.49 \\pm 2.94^{*}$",
          "$92.95 \\pm 2.67^{*}$",
          "$93.13 \\pm 2.56$",
          "$94.10 \\pm 3.00$"
        ],
        [
          "Image",
          "$79.95 \\pm 1.52^{\\dagger}$",
          "$88.65 \\pm 1.21$",
          "$88.82 \\pm 1.74$",
          "$88.67 \\pm 2.48$",
          "$89.12 \\pm 1.56$",
          "$88.98 \\pm 0.98$"
        ],
        [
          "Average",
          83.74,
          87.06,
          88.52,
          88.37,
          88.56,
          89.53
        ]
      ],
      "row_count": 6,
      "column_count": 7
    },
    {
      "table_number": "3",
      "table_title": "Cardinalities of finally selected features subsets for the NB classifier on real datasets without feature selection and using exposed five FSS methods",
      "headers": [
        "Domain",
        "Without <br> FSS",
        "SFS",
        "SBE",
        "GA-o",
        "GA-u",
        "FSS-EBNA"
      ],
      "rows": [
        [
          "Ionosphere",
          34,
          "$6.00 \\pm 1.41$",
          "$21.30 \\pm 3.80$",
          "$15.00 \\pm 2.36$",
          "$12.66 \\pm 1.03$",
          "$13.40 \\pm 2.11$"
        ],
        [
          "Horse-colic",
          22,
          "$6.00 \\pm 2.74$",
          "$11.20 \\pm 2.65$",
          "$5.00 \\pm 2.82$",
          "$4.60 \\pm 1.75$",
          "$6.10 \\pm 1.85$"
        ],
        [
          "Soybean-large",
          35,
          "$12.70 \\pm 2.71$",
          "$23.50 \\pm 2.75$",
          "$19.00 \\pm 2.09$",
          "$19.16 \\pm 2.31$",
          "$18.90 \\pm 2.76$"
        ],
        [
          "Anneal",
          38,
          "$5.50 \\pm 2.32$",
          "$33.60 \\pm 2.91$",
          "$21.66 \\pm 2.66$",
          "$19.50 \\pm 2.25$",
          "$20.50 \\pm 3.13$"
        ],
        [
          "Image",
          19,
          "$5.60 \\pm 1.57$",
          "$9.40 \\pm 1.95$",
          "$8.00 \\pm 1.41$",
          "$8.00 \\pm 1.09$",
          "$8.00 \\pm 0.66$"
        ]
      ],
      "row_count": 5,
      "column_count": 7
    },
    {
      "table_number": "4",
      "table_title": "Mean stop-generation for GAs and FSS-EBNA",
      "headers": [
        "Domain",
        "GA-o",
        "GA-u",
        "FSS-EBNA"
      ],
      "rows": [
        [
          "Ionosphere",
          "$3.50 \\pm 0.84^{\\dagger}$",
          "$3.10 \\pm 0.56^{\\dagger}$",
          "$1.80 \\pm 0.42$"
        ],
        [
          "Horse-colic",
          "$3.20 \\pm 1.13^{+}$",
          "$3.40 \\pm 0.51^{\\dagger}$",
          "$2.40 \\pm 0.69$"
        ],
        [
          "Soybean-large",
          "$3.30 \\pm 0.82^{+}$",
          "$3.60 \\pm 0.51^{\\dagger}$",
          "$2.50 \\pm 0.70$"
        ],
        [
          "Anneal",
          "$3.80 \\pm 0.42^{\\dagger}$",
          "$3.20 \\pm 0.44^{\\dagger}$",
          "$1.80 \\pm 0.42$"
        ],
        [
          "Image",
          "$3.60 \\pm 0.84$",
          "$3.70 \\pm 0.48$",
          "$3.50 \\pm 0.42$"
        ]
      ],
      "row_count": 5,
      "column_count": 4
    }
  ]
}