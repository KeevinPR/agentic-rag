{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2007/Bayesian inference in estimation of distribution algorithms.md",
    "filename": "Bayesian inference in estimation of distribution algorithms.md",
    "title": "Bayesian inference in estimation of distribution algorithms",
    "year": "2007"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] S. Kern, S. D. Müller, N. Hansen, D. Büche, J. Ocenasek, and P. Koumoutsakos, \"Learning probability distributions in continuous evolutionary algorithms - a comparative review,\" Natural Computing, vol. 3, no. 1, pp. 77-112, 2004.\n[2] P. Larrahaga and J. A. Lozano, Eds., Estimation of Distribution Algorithms : A New Tool for Evolutionary Computation. Kluwer, 2002.\n[3] M. Pelikan, D. E. Goldberg, and F. Lobo, \"A survey of optimization by building and using probabilistic models,\" Computational Optimization and Applications, vol. 21, no. 1, pp. 5-20, 2002.\n[4] R. Y. Rubinstein and D. P. Kroese, The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation and Machine Learning, ser. Information Science and Statistics. Springer, 2004.\n[5] M. Gallagher and M. Frean, \"Population-based continuous optimization, probabilistic modelling and mean shift,\" Evolutionary Computation, vol. 13, no. 1, pp. 29-42, 2005.\n[6] S. Baluja, \"Population-Based Incremental Learning: A method for integrating genetic search based function optimization and competitive learning,\" School of Computer Science, Carnegie Mellon University, Tech. Rep. CMU-CS-94-163, 1994.\n[7] M. Pelikan, D. E. Goldberg, and E. Canti-Paz, \"BOA: The Bayesian optimization algorithm,\" in Proc. Genetic and Evolutionary Computation Conference (GECCO'99), W. Banzhaf and et al., Eds. San Francisco, CA: Morgan Kaufmann, 1999, pp. 525-532.\n[8] B.-T. Zhang, \"A unified Bayesian framework for evolutionary learning and optimization,\" in Advances in Evolutionary Computing: Theory and Applications, ser. Natural Computing Series, A. Ghosh and S. Tsutsui, Eds. Springer, 2003, pp. 393-412.\n[9] H. Mühlenbein, \"The equation for response to selection and its use for prediction,\" Evolutionary Computation, vol. 5, pp. 303-346, 1998.\n[10] P. Larrahaga, R. Etxeberria, J. A. Lozano, and J. M. Peña, \"Optimization by learning and simulation of Bayesian and Gaussian networks,\" University of the Basque Country, Spain, Tech. Rep. KZZA-IK-4-99, 1999.\n[11] A. Gelman, J. B. Curlin, H. S. Stern, and D. B. Rubin, Bayesian Data Analysis, 2nd ed. Chapman and Hall/CRC, 2004.\n[12] R. Fletcher, Practical methods of optimization, 2nd ed. Chichester, New York: Wiley, 1987.\n[13] G. E. P. Box and N. R. Draper, Empirical model-building and response surfaces. Wiley, 1987.\n[14] H. J. Kushner, \"A new method of locating the maximum of an arbitrary multipeak curve in the presence of noise,\" Journal of Basic Engineering, vol. 86, pp. 97-106, 1964.\n[15] B. E. Stuckman, \"A global search method for optimizing nonlinear systems,\" IEEE Transactions on Systems, Man, and Cybernetics, vol. 18, no. 6, pp. 965-977, 1988.\n\n[16] J. Mockus, \"Application of Bayesian approach to numerical methods of global and stochastic optimization,\" Journal of Global Optimization, vol. 4, pp. 347-365, 1994.\n[17] A. Žilinskas, \"A review of statistical models for global optimization,\" Journal of Global Optimization, vol. 2, pp. 145-153, 1992.\n[18] D. R. Jones, \"A taxonomy of global optimization methods based on response surfaces,\" Journal of Global Optimization, vol. 21, pp. 345383, 2001.\n[19] M. J. Sasena, P. Papalambros, and P. Goovaerts, \"Exploration of metamodelling sampling criteria for contrained global optimization,\" Engineering Optimization, vol. 34, no. 3, pp. 263-278, 2002.\n[20] A. W. Moore and J. Schneider, \"Memory-based stochastic optimization,\" in Advances in Neural Information Processing Systems, vol. 8, 1996, pp. 1066-1072.\n[21] J. Boyan and A. Moore, \"Learning evaluation functions to improve optimization by local search,\" Journal of Machine Learning Research, vol. 1, pp. 77-112, 2000.",
    "references": [
      {
        "ref_id": "1",
        "text": "S. Kern, S. D. Müller, N. Hansen, D. Büche, J. Ocenasek, and P. Koumoutsakos, \"Learning probability distributions in continuous evolutionary algorithms - a comparative review,\" Natural Computing, vol. 3, no. 1, pp. 77-112, 2004."
      },
      {
        "ref_id": "2",
        "text": "P. Larrahaga and J. A. Lozano, Eds., Estimation of Distribution Algorithms : A New Tool for Evolutionary Computation. Kluwer, 2002."
      },
      {
        "ref_id": "3",
        "text": "M. Pelikan, D. E. Goldberg, and F. Lobo, \"A survey of optimization by building and using probabilistic models,\" Computational Optimization and Applications, vol. 21, no. 1, pp. 5-20, 2002."
      },
      {
        "ref_id": "4",
        "text": "R. Y. Rubinstein and D. P. Kroese, The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation and Machine Learning, ser. Information Science and Statistics. Springer, 2004."
      },
      {
        "ref_id": "5",
        "text": "M. Gallagher and M. Frean, \"Population-based continuous optimization, probabilistic modelling and mean shift,\" Evolutionary Computation, vol. 13, no. 1, pp. 29-42, 2005."
      },
      {
        "ref_id": "6",
        "text": "S. Baluja, \"Population-Based Incremental Learning: A method for integrating genetic search based function optimization and competitive learning,\" School of Computer Science, Carnegie Mellon University, Tech. Rep. CMU-CS-94-163, 1994."
      },
      {
        "ref_id": "7",
        "text": "M. Pelikan, D. E. Goldberg, and E. Canti-Paz, \"BOA: The Bayesian optimization algorithm,\" in Proc. Genetic and Evolutionary Computation Conference (GECCO'99), W. Banzhaf and et al., Eds. San Francisco, CA: Morgan Kaufmann, 1999, pp. 525-532."
      },
      {
        "ref_id": "8",
        "text": "B.-T. Zhang, \"A unified Bayesian framework for evolutionary learning and optimization,\" in Advances in Evolutionary Computing: Theory and Applications, ser. Natural Computing Series, A. Ghosh and S. Tsutsui, Eds. Springer, 2003, pp. 393-412."
      },
      {
        "ref_id": "9",
        "text": "H. Mühlenbein, \"The equation for response to selection and its use for prediction,\" Evolutionary Computation, vol. 5, pp. 303-346, 1998."
      },
      {
        "ref_id": "10",
        "text": "P. Larrahaga, R. Etxeberria, J. A. Lozano, and J. M. Peña, \"Optimization by learning and simulation of Bayesian and Gaussian networks,\" University of the Basque Country, Spain, Tech. Rep. KZZA-IK-4-99, 1999."
      },
      {
        "ref_id": "11",
        "text": "A. Gelman, J. B. Curlin, H. S. Stern, and D. B. Rubin, Bayesian Data Analysis, 2nd ed. Chapman and Hall/CRC, 2004."
      },
      {
        "ref_id": "12",
        "text": "R. Fletcher, Practical methods of optimization, 2nd ed. Chichester, New York: Wiley, 1987."
      },
      {
        "ref_id": "13",
        "text": "G. E. P. Box and N. R. Draper, Empirical model-building and response surfaces. Wiley, 1987."
      },
      {
        "ref_id": "14",
        "text": "H. J. Kushner, \"A new method of locating the maximum of an arbitrary multipeak curve in the presence of noise,\" Journal of Basic Engineering, vol. 86, pp. 97-106, 1964."
      },
      {
        "ref_id": "15",
        "text": "B. E. Stuckman, \"A global search method for optimizing nonlinear systems,\" IEEE Transactions on Systems, Man, and Cybernetics, vol. 18, no. 6, pp. 965-977, 1988."
      },
      {
        "ref_id": "16",
        "text": "J. Mockus, \"Application of Bayesian approach to numerical methods of global and stochastic optimization,\" Journal of Global Optimization, vol. 4, pp. 347-365, 1994."
      },
      {
        "ref_id": "17",
        "text": "A. Žilinskas, \"A review of statistical models for global optimization,\" Journal of Global Optimization, vol. 2, pp. 145-153, 1992."
      },
      {
        "ref_id": "18",
        "text": "D. R. Jones, \"A taxonomy of global optimization methods based on response surfaces,\" Journal of Global Optimization, vol. 21, pp. 345383, 2001."
      },
      {
        "ref_id": "19",
        "text": "M. J. Sasena, P. Papalambros, and P. Goovaerts, \"Exploration of metamodelling sampling criteria for contrained global optimization,\" Engineering Optimization, vol. 34, no. 3, pp. 263-278, 2002."
      },
      {
        "ref_id": "20",
        "text": "A. W. Moore and J. Schneider, \"Memory-based stochastic optimization,\" in Advances in Neural Information Processing Systems, vol. 8, 1996, pp. 1066-1072."
      },
      {
        "ref_id": "21",
        "text": "J. Boyan and A. Moore, \"Learning evaluation functions to improve optimization by local search,\" Journal of Machine Learning Research, vol. 1, pp. 77-112, 2000."
      }
    ],
    "reference_count": 21,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "IV",
      "table_title": "TEST FUNCTIONS USED IN THE EXPERIMENTS",
      "headers": [
        "Name",
        "Function"
      ],
      "rows": [
        [
          "Sphere",
          "$\\begin{aligned} & f_{S_{p b}}(\\mathbf{x})=\\sum_{i=1}^{n} x_{i}^{2} \\\\ & -5.12 \\leq x_{i} \\leq 5.12, f_{S_{p b}}\\left(\\mathbf{x}^{*}\\right)=0 \\end{aligned}$"
        ],
        [
          "Rastrigin",
          "$\\begin{aligned} & f_{R_{R s i}}(\\mathbf{x})=\\sum_{i=1}^{n}\\left(x_{i}^{2}-1\\right)\\left(x_{i}^{2}-10 \\cos \\left(2 \\pi x_{i}\\right)+10\\right) \\\\ & -5 \\leq x_{i} \\leq 5, f_{R_{R s i}}\\left(\\mathbf{x}^{*}\\right)=0 \\end{aligned}$"
        ],
        [
          "Rosenbrock",
          "$\\begin{aligned} & f_{R_{R s i}}(\\mathbf{x})=\\sum_{i=1}^{n-1}\\left(x_{i}^{2}-x_{i+1}\\right)^{2}+\\left(x_{i}-1\\right)^{2} \\\\ & -2 \\leq x_{i} \\leq 2, f_{R_{r s i}}\\left(\\mathbf{x}^{*}\\right)=0 \\end{aligned}$"
        ],
        [
          "Griewangk",
          "$\\begin{aligned} & f_{G r i}(\\mathbf{x})=\\sum_{i=1}^{n} \\frac{x_{i}^{2}}{4000}-\\prod_{i=1}^{n} \\cos \\left(\\frac{x_{i}}{a^{2}}\\right)+1 \\\\ & -600 \\leq x_{i} \\leq 600, f_{G r i}\\left(\\mathbf{x}^{*}\\right)=0 \\end{aligned}$"
        ],
        [
          "Ackle",
          "$\\begin{aligned} & f_{A c k}(\\mathbf{x})=-20 \\exp \\left(-0.2 \\sqrt{\\frac{1}{30} \\sum_{i=1}^{n} x_{i}^{2}}\\right) \\\\ &-\\exp \\left(\\frac{1}{30} \\sum_{i=1}^{n} \\cos 2 \\pi x_{i}\\right)+20+e \\\\ & -15 \\leq x_{i} \\leq 30, f_{A c k}\\left(\\mathbf{x}^{*}\\right)=0 \\end{aligned}$"
        ]
      ],
      "row_count": 5,
      "column_count": 2
    },
    {
      "table_number": "V",
      "table_title": "PERFORMANCE RESULTS ON 10D VERSIONS OF THE TEST FUNCTIONS.",
      "headers": [
        "Function",
        "UMDA Mean (Std)",
        "BayEDA Mean (Std)"
      ],
      "rows": [
        [
          "Sphere",
          "$9.63 \\mathrm{E}-09(2.36 \\mathrm{E}-09)$",
          "$1.18 \\mathrm{E}-08(2.63 \\mathrm{E}-09)$"
        ],
        [
          "Rastrigin",
          "$7.12 \\mathrm{E}-06(8.15 \\mathrm{E}-06)$",
          "$1.56 \\mathrm{E}-05(2.16 \\mathrm{E}-05)$"
        ],
        [
          "Rosenbrock",
          "$8.21 \\mathrm{E}+01(2.04 \\mathrm{E}-02)$",
          "$8.21 \\mathrm{E}+01(2.41 \\mathrm{E}-02)$"
        ],
        [
          "Gnewangk",
          "$7.54 \\mathrm{E}-14(2.45 \\mathrm{E}-14)$",
          "$1.08 \\mathrm{E}-13(2.86 \\mathrm{E}-14)$"
        ],
        [
          "Ackleys",
          "$1.96 \\mathrm{E}-08(2.75 \\mathrm{E}-09)$",
          "$2.11 \\mathrm{E}-08(3.42 \\mathrm{E}-09)$"
        ]
      ],
      "row_count": 5,
      "column_count": 3
    }
  ]
}