{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2020/An evolutionary algorithm for automated machine learning focusing on classifier ensembles- An improved algorithm and extended results.md",
    "filename": "An evolutionary algorithm for automated machine learning focusing on classifier ensembles- An improved algorithm and extended results.md",
    "title": "An evolutionary algorithm for automated machine learning focusing on classifier ensembles- An improved algorithm and extended results",
    "year": "2020"
  },
  "references": {
    "header": "## References",
    "content": "[1] Zhi-Hua Zhou, Ensemble Methods: Foundations and Algorithms, 1st edition, Chapman \\& Hall/CRC, 2012.\n[2] L.I. Kuncheva, Classifier ensembles for changing environments, in: F. Roli, J. Kittler, T. Windeatt (Eds.), Multiple Classifier Systems, in: Lecture Notes in Computer Science, vol. 3077, Springer, 2004, pp. 1-15.\n[3] L.I. Kuncheva, Combining Pattern Classifiers: Methods and Algorithms, Wiley-Interscience, 2004.\n[4] C. Thornton, F. Hutter, H.H. Hoos, K. Leyton-Brown, Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms, in: Proc. 19th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, ACM Press, 2013, pp. 847-855.\n[5] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, I. Witten, The WEKA data mining software: an update, ACM SIGKDD Explor. Newsl. 11 (1) (2009) $10-18$.\n[6] M. Feuerer, A. Klein, K. Eggensperger, J. Springenberg, M. Blum, F. Hutter, Efficient and robust automated machine learning, Adv. Neural Inf. Process. Syst. 28 (2015) 2962-2970.\n[7] P. Larrañaga, J.A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer, Boston, MA, 2002.\n[8] S. Baluja, R. Caruana, Removing the genetics from the standard genetic algorithm, in: Proc. 12th Int. Conf. on Machine Learning, California, July, 1995, 1995, pp. 38-46.\n[9] M. Fernández-Delgado, E. Cernadas, S. Barro, D. Amorim, Do we need hundreds of classifiers to solve real world classification problems?, J. Mach. Learn. Res. 15 (1) (2014) 3133-3181.\n[10] P. Brazdil, C. Giraud-Carrier, C. Soares, R. Vilalta, Metalearning: Applications to Data Mining, Springer, 2009.\n[11] L. Kotthoff, C. Thornton, H.H. Hoos, F. Hutter, K. Leyton-Brown, Auto-WEKA 2.0: automatic model selection and hyperparameter optimization in WEKA, J. Mach. Learn. Res. 18 (1) (2017) 826-830.\n[12] A.A. Freitas, Data Mining and Knowledge Discovery with Evolutionary Algorithms, Springer, 2002.\n[13] A.E. Eiben, J.E. Smith, Introduction to Evolutionary Computing, 2nd edition, Springer, 2015.\n[14] I. Inza, P. Larrañaga, B. Sierra, Feature subset selection by estimation of distribution algorithms, in: Estimation of Distribution Algorithms, Springer, 2002, pp. 269-293.\n[15] K. Shelke, S. Jayaraman, S. Ghosh, J. Valadi, Hybrid feature selection and peptide binding affinity prediction using an EDA based algorithm, in: Proc. IEEE Congress on Evolutionary Computation (CEC), 2013, pp. 2384-2389.\n[16] M. Zangari, R. Santana, A. Mendibury, A.T.R. Pozo, Not all PBILs are the same: unveiling the different learning mechanisms of PBIL variants, Appl. Soft Comput. 53 (April 2017) 88-96.\n[17] X. Yang, H. Dong, H. Zhang, Naive Bayes based on estimation of distribution algorithms for classification, in: International Conference on Information Science and Engineering, 2009, pp. 908-911.\n[18] Y. Saeys, S. Degroeve, D. Aeyels, P. Rouzé, Y. Van de Peer, Feature selection for splice site prediction: a new method using EDA-based feature ranking, BMC Bioinform. 5 (64) (2004), 11 pages.\n[19] P. Kordík, Jan Černý, T. Frýda, Discovering predictive ensembles for transfer learning and meta-learning, Mach. Learn. 107 (1) (2018) 177-207.\n[20] S.B. Kotsiantis, Supervised machine learning: a review of classification techniques, in: Emerging Artificial Intelligence Applications in Computer Engineering, IOS Press, 2007, pp. 3-24.\n[21] M. Wistuba, N. Schilling, L. Schmidt-Thieme, Automatic frankensteining: creating complex ensembles autonomously, in: Proc. SIAM Int. Conf. on Data Mining, SIAM, 2017, pp. 741-749.\n[22] J. Léveuque, C. Gagné, R. Sabourin, Bayesian hyper-parameter optimization for ensemble learning, in: Proc. 32nd Conference on Uncertainty in Artificial Intelligence (UAI), Jersey City, New Jersey, USA, 2016, 2016, pp. 437-446.\n[23] A. Lacoste, H. Larochelle, F. Laviolette, M. Marchand, Sequential model-based ensemble optimization, Computing Research Repository (CoRR) (2014).\n[24] R. Olson, R. Urbanowicz, P. Andrews, N. Lavender, L. Kidd, J.H. Moore, Automating biomedical data science through tree-based pipeline optimization, in: European Conference on the Applications of Evolutionary Computation, Springer, 2016, pp. 123-137.\n[25] A.G.C. de Sá, G.L. Pappa, A.A. Freitas, Automated selection and configuration of multi-label classification algorithms with grammar-based genetic programming, in: Proc. of the 15th International Conf. on Parallel Problem Solving from Nature (PPSN-2018), to be Held in Coimbra, Portugal, Sep. 2018, 2018, https://doi.org/10.1007/978-3-319-99259-4_25, in press.\n[26] A.G.C. de Sá, W.J.G.S. Pinto, L.O.V.B. Oliveira, G.L. Pappa, RECIPE: a grammar-based framework for automatically evolving classification pipelines, in: Proc. of the 20th European Conference on Genetic Programming (EuroGP'17), in: LNCS, vol. 10196, Springer, 2017, pp. 246-261.\n[27] Janez Demsar, Statistical comparisons of classifiers over multiple data sets, J. Mach. Learn. Res. 7 (2006) 1-30.\n[28] J.C. Xavier-Júnior, A.A. Freitas, A. Feitosa-Neto, T.B. Ludermir, A novel evolutionary algorithm for automated machine learning focusing on classifier ensembles, in: 7th Brazilian Conference on Intelligent Systems (BRAOS 2018), 2018, pp. 462-467.\n[29] L. Rokach, Ensemble-based classifiers, Artif. Intell. Rev. 33 (1-2) (2010) 1-39.\n[30] S.B. Kotsiantis, Bagging and boosting variants for handling classification problems: a survey, Knowl. Eng. Rev. 29 (1) (2014) 78-100.\n[31] O. Sagi, L. Rokach, Ensemble learning: a survey, Wiley Interdiscip. Rev. Data Min. Knowl. Discov. 8 (4) (2018) e1249.",
    "references": [
      {
        "ref_id": "1",
        "text": "Zhi-Hua Zhou, Ensemble Methods: Foundations and Algorithms, 1st edition, Chapman \\& Hall/CRC, 2012."
      },
      {
        "ref_id": "2",
        "text": "L.I. Kuncheva, Classifier ensembles for changing environments, in: F. Roli, J. Kittler, T. Windeatt (Eds.), Multiple Classifier Systems, in: Lecture Notes in Computer Science, vol. 3077, Springer, 2004, pp. 1-15."
      },
      {
        "ref_id": "3",
        "text": "L.I. Kuncheva, Combining Pattern Classifiers: Methods and Algorithms, Wiley-Interscience, 2004."
      },
      {
        "ref_id": "4",
        "text": "C. Thornton, F. Hutter, H.H. Hoos, K. Leyton-Brown, Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms, in: Proc. 19th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, ACM Press, 2013, pp. 847-855."
      },
      {
        "ref_id": "5",
        "text": "M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, I. Witten, The WEKA data mining software: an update, ACM SIGKDD Explor. Newsl. 11 (1) (2009) $10-18$."
      },
      {
        "ref_id": "6",
        "text": "M. Feuerer, A. Klein, K. Eggensperger, J. Springenberg, M. Blum, F. Hutter, Efficient and robust automated machine learning, Adv. Neural Inf. Process. Syst. 28 (2015) 2962-2970."
      },
      {
        "ref_id": "7",
        "text": "P. Larrañaga, J.A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer, Boston, MA, 2002."
      },
      {
        "ref_id": "8",
        "text": "S. Baluja, R. Caruana, Removing the genetics from the standard genetic algorithm, in: Proc. 12th Int. Conf. on Machine Learning, California, July, 1995, 1995, pp. 38-46."
      },
      {
        "ref_id": "9",
        "text": "M. Fernández-Delgado, E. Cernadas, S. Barro, D. Amorim, Do we need hundreds of classifiers to solve real world classification problems?, J. Mach. Learn. Res. 15 (1) (2014) 3133-3181."
      },
      {
        "ref_id": "10",
        "text": "P. Brazdil, C. Giraud-Carrier, C. Soares, R. Vilalta, Metalearning: Applications to Data Mining, Springer, 2009."
      },
      {
        "ref_id": "11",
        "text": "L. Kotthoff, C. Thornton, H.H. Hoos, F. Hutter, K. Leyton-Brown, Auto-WEKA 2.0: automatic model selection and hyperparameter optimization in WEKA, J. Mach. Learn. Res. 18 (1) (2017) 826-830."
      },
      {
        "ref_id": "12",
        "text": "A.A. Freitas, Data Mining and Knowledge Discovery with Evolutionary Algorithms, Springer, 2002."
      },
      {
        "ref_id": "13",
        "text": "A.E. Eiben, J.E. Smith, Introduction to Evolutionary Computing, 2nd edition, Springer, 2015."
      },
      {
        "ref_id": "14",
        "text": "I. Inza, P. Larrañaga, B. Sierra, Feature subset selection by estimation of distribution algorithms, in: Estimation of Distribution Algorithms, Springer, 2002, pp. 269-293."
      },
      {
        "ref_id": "15",
        "text": "K. Shelke, S. Jayaraman, S. Ghosh, J. Valadi, Hybrid feature selection and peptide binding affinity prediction using an EDA based algorithm, in: Proc. IEEE Congress on Evolutionary Computation (CEC), 2013, pp. 2384-2389."
      },
      {
        "ref_id": "16",
        "text": "M. Zangari, R. Santana, A. Mendibury, A.T.R. Pozo, Not all PBILs are the same: unveiling the different learning mechanisms of PBIL variants, Appl. Soft Comput. 53 (April 2017) 88-96."
      },
      {
        "ref_id": "17",
        "text": "X. Yang, H. Dong, H. Zhang, Naive Bayes based on estimation of distribution algorithms for classification, in: International Conference on Information Science and Engineering, 2009, pp. 908-911."
      },
      {
        "ref_id": "18",
        "text": "Y. Saeys, S. Degroeve, D. Aeyels, P. Rouzé, Y. Van de Peer, Feature selection for splice site prediction: a new method using EDA-based feature ranking, BMC Bioinform. 5 (64) (2004), 11 pages."
      },
      {
        "ref_id": "19",
        "text": "P. Kordík, Jan Černý, T. Frýda, Discovering predictive ensembles for transfer learning and meta-learning, Mach. Learn. 107 (1) (2018) 177-207."
      },
      {
        "ref_id": "20",
        "text": "S.B. Kotsiantis, Supervised machine learning: a review of classification techniques, in: Emerging Artificial Intelligence Applications in Computer Engineering, IOS Press, 2007, pp. 3-24."
      },
      {
        "ref_id": "21",
        "text": "M. Wistuba, N. Schilling, L. Schmidt-Thieme, Automatic frankensteining: creating complex ensembles autonomously, in: Proc. SIAM Int. Conf. on Data Mining, SIAM, 2017, pp. 741-749."
      },
      {
        "ref_id": "22",
        "text": "J. Léveuque, C. Gagné, R. Sabourin, Bayesian hyper-parameter optimization for ensemble learning, in: Proc. 32nd Conference on Uncertainty in Artificial Intelligence (UAI), Jersey City, New Jersey, USA, 2016, 2016, pp. 437-446."
      },
      {
        "ref_id": "23",
        "text": "A. Lacoste, H. Larochelle, F. Laviolette, M. Marchand, Sequential model-based ensemble optimization, Computing Research Repository (CoRR) (2014)."
      },
      {
        "ref_id": "24",
        "text": "R. Olson, R. Urbanowicz, P. Andrews, N. Lavender, L. Kidd, J.H. Moore, Automating biomedical data science through tree-based pipeline optimization, in: European Conference on the Applications of Evolutionary Computation, Springer, 2016, pp. 123-137."
      },
      {
        "ref_id": "25",
        "text": "A.G.C. de Sá, G.L. Pappa, A.A. Freitas, Automated selection and configuration of multi-label classification algorithms with grammar-based genetic programming, in: Proc. of the 15th International Conf. on Parallel Problem Solving from Nature (PPSN-2018), to be Held in Coimbra, Portugal, Sep. 2018, 2018, https://doi.org/10.1007/978-3-319-99259-4_25, in press."
      },
      {
        "ref_id": "26",
        "text": "A.G.C. de Sá, W.J.G.S. Pinto, L.O.V.B. Oliveira, G.L. Pappa, RECIPE: a grammar-based framework for automatically evolving classification pipelines, in: Proc. of the 20th European Conference on Genetic Programming (EuroGP'17), in: LNCS, vol. 10196, Springer, 2017, pp. 246-261."
      },
      {
        "ref_id": "27",
        "text": "Janez Demsar, Statistical comparisons of classifiers over multiple data sets, J. Mach. Learn. Res. 7 (2006) 1-30."
      },
      {
        "ref_id": "28",
        "text": "J.C. Xavier-Júnior, A.A. Freitas, A. Feitosa-Neto, T.B. Ludermir, A novel evolutionary algorithm for automated machine learning focusing on classifier ensembles, in: 7th Brazilian Conference on Intelligent Systems (BRAOS 2018), 2018, pp. 462-467."
      },
      {
        "ref_id": "29",
        "text": "L. Rokach, Ensemble-based classifiers, Artif. Intell. Rev. 33 (1-2) (2010) 1-39."
      },
      {
        "ref_id": "30",
        "text": "S.B. Kotsiantis, Bagging and boosting variants for handling classification problems: a survey, Knowl. Eng. Rev. 29 (1) (2014) 78-100."
      },
      {
        "ref_id": "31",
        "text": "O. Sagi, L. Rokach, Ensemble learning: a survey, Wiley Interdiscip. Rev. Data Min. Knowl. Discov. 8 (4) (2018) e1249."
      }
    ],
    "reference_count": 31,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Probability Vectors (PVs) for ensemble methods' hyper-parameter optimization at level 2 of Fig. 1. The columns of the table refer to the type of the ensemble at level 1, the number of PVs for the ensemble, the name of the PV, the number of components in the PV, and the values of the hyper-parameters, respectively.",
      "headers": [
        "Ens. type <br> L1",
        "\\# PVs <br> Ens.",
        "PV <br> name",
        "\\# Comp. <br> in PV",
        "Hyper-parameter <br> values"
      ],
      "rows": [
        [
          "RC",
          2,
          "L2-RC-I <br> L2-RC-S",
          "$\\begin{aligned} & 63 \\\\ & 255 \\end{aligned}$",
          2641255
        ],
        [
          "AD",
          4,
          "L2-AD-Q <br> L2-AD-P <br> L2-AD-I <br> L2-AD-S",
          "$\\begin{aligned} & 2 \\\\ & 51 \\\\ & 127 \\\\ & 255 \\end{aligned}$",
          5010021281255
        ],
        [
          "BA",
          4,
          "L2-BA-P <br> L2-BA-I <br> L2-BA-S <br> L2-BA-O",
          "$\\begin{aligned} & 91 \\\\ & 127 \\\\ & 255 \\\\ & 2 \\\\ & \\hline \\end{aligned}$",
          1010021281255
        ],
        [
          "RF",
          3,
          "L2-RF-I <br> L2-RF-K <br> L2-RF-W",
          "$\\begin{aligned} & 255 \\\\ & 32 \\\\ & 20 \\end{aligned}$",
          2256132120
        ],
        [
          "ST",
          4,
          "L2-ST-X <br> L2-ST-S <br> L2-ST-B <br> L2-ST-NBC",
          "$\\begin{aligned} & 10 \\\\ & 255 \\\\ & 9 \\\\ & 10 \\end{aligned}$",
          110125519110
        ],
        [
          "VT",
          4,
          "L2-VT-S <br> L2-VT-R <br> L2-VT-B <br> L2-VT-NBC",
          "$\\begin{aligned} & 255 \\\\ & 6 \\\\ & 9 \\\\ & 10 \\end{aligned}$",
          125519110
        ]
      ],
      "row_count": 6,
      "column_count": 5
    },
    {
      "table_number": "2",
      "table_title": "Probability Vectors (PVs) for base classifier selection at level 3 of Fig. 1. The columns of the table refer to the type of the ensemble at level 1, the number of PVs for the ensemble, the name of the PV, the number of components in the PV, and the candidate base classifiers (one PV component for each of them), respectively.",
      "headers": [
        "Ensem. type <br> at Level 1",
        "PV <br> name",
        "\\# Comp. <br> in the PV",
        "Candidate base <br> classifiers"
      ],
      "rows": [
        [
          "Rand. Comm.",
          "L3-RC-BC-sel",
          9,
          48
        ],
        [
          "AdaBoost",
          "L3-AD-BC-sel",
          9,
          48
        ],
        [
          "Bagging",
          "L3-BA-BC-sel",
          9,
          48
        ],
        [
          "Stacking",
          "L3-ST-BC-sel",
          9,
          48
        ],
        [
          "Vote",
          "L3-VT-BC-sel",
          9,
          48
        ],
        [
          "No ensemble",
          "L3-NE-BC-sel",
          9,
          48
        ]
      ],
      "row_count": 6,
      "column_count": 4
    },
    {
      "table_number": "3",
      "table_title": "Probability Vectors (PVs) for the base classifiers' hyper-parameter optimization at level 4 of Fig. 1. The columns of the table refer to the type of the base classifier at level 3, the number of PVs for that base classifier, the name of the PV, the number of components in the PV, and the values of the hyper-parameters, respectively.",
      "headers": [
        "BC L2",
        "\\# PVs <br> BCs.",
        "PV <br> name",
        "\\# Comp. <br> in PV",
        "Hyper-parameter values"
      ],
      "rows": [
        [
          "DT",
          4,
          "LV4-DT-E",
          4,
          "acc, rmse, mae, auc"
        ],
        [
          "",
          "",
          "LV4-DT-I",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-DT-S",
          2,
          "BestFirst, GreedyStepWise"
        ],
        [
          "",
          "",
          "LV4-DT-X",
          1,
          14
        ],
        [
          "IBK",
          5,
          "LV4-IBK-E",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-IBK-K",
          64,
          164
        ],
        [
          "",
          "",
          "LV4-IBK-X",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-IBK-F",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-IBK-I",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-O",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-U",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-B",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-J",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-A",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-S",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-J48-M",
          64,
          164
        ],
        [
          "",
          "",
          "LV4-J48-C",
          95,
          550
        ],
        [
          "KST",
          3,
          "LV4-KST-B",
          100,
          1100
        ],
        [
          "",
          "",
          "LV4-KST-E",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-KST-X",
          4,
          "a, d, m n"
        ],
        [
          "MLP",
          8,
          "LV4-MLP-L",
          10,
          110
        ],
        [
          "",
          "",
          "LV4-MLP-M",
          10,
          110
        ],
        [
          "",
          "",
          "LV4-MLP-B",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-MLP-H",
          4,
          "a, i, o, t"
        ],
        [
          "",
          "",
          "LV4-MLP-C",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-MLP-R",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-MLP-D",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-MLP-S",
          255,
          1255
        ],
        [
          "NB",
          2,
          "LV4-NB-D",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV4-NB-K",
          2,
          "true / false"
        ],
        [
          "NET",
          2,
          "LV4-NET-Q",
          6,
          2
        ],
        [
          "",
          "",
          "LV4-NET-D",
          2,
          "true / false"
        ],
        [
          "RT",
          5,
          "LV4-RT-M",
          64,
          164
        ],
        [
          "",
          "",
          "LV4-RT-K",
          33,
          32
        ],
        [
          "",
          "",
          "LV4-RT-depth",
          21,
          20
        ],
        [
          "",
          "",
          "LV4-RT-N",
          6,
          5
        ],
        [
          "",
          "",
          "LV4-RT-U",
          2,
          "true / false"
        ],
        [
          "SMO",
          1,
          "LV4-SMO-SEL",
          4,
          "Def., N.P.Kernel, P.Kernel, Puk, RBFKernel"
        ]
      ],
      "row_count": 38,
      "column_count": 5
    },
    {
      "table_number": "4",
      "table_title": "Probability Vectors (PVs) for the SVM base classifier's hyper-parameter optimization.",
      "headers": [
        "SMOs <br> L4, L5",
        "PVs <br> SMOs.",
        "PV <br> name",
        "Comp. <br> in PV",
        "Hyper-parameter values"
      ],
      "rows": [
        [
          "def.",
          4,
          "LV5-default-C",
          11,
          "from 0.5 to 1.5"
        ],
        [
          "",
          "",
          "LV5-default-N",
          3,
          2
        ],
        [
          "",
          "",
          "LV5-default-M",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV5-default-K",
          4,
          "N.P.Kernel, P.Kernel, Puk, RBFKernel"
        ],
        [
          "N.P.Kernel",
          6,
          "LV5-NPKernel-C",
          11,
          "from 0.5 to 1.5"
        ],
        [
          "",
          "",
          "LV5-NPKernel-N",
          3,
          2
        ],
        [
          "",
          "",
          "LV5-NPKernel-M",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV5-NPKernel-K",
          4,
          "N.P.Kernel, P.Kernel, Puk, RBFKernel"
        ],
        [
          "",
          "",
          "LV5-NPKernel-E",
          49,
          "from 0.2 to 5.0"
        ],
        [
          "",
          "",
          "LV5-NPKernel-L",
          2,
          "true / false"
        ],
        [
          "PolyKernel",
          6,
          "LV5-PKernel-C",
          11,
          "from 0.5 to 1.5"
        ],
        [
          "",
          "",
          "LV5-PKernel-N",
          3,
          2
        ],
        [
          "",
          "",
          "LV5-PKernel-M",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV5-PKernel-K",
          4,
          "N.P.Kernel, P.Kernel, Puk, RBFKernel"
        ],
        [
          "",
          "",
          "LV5-PKernel-E",
          49,
          "from 0.2 to 5.0"
        ],
        [
          "",
          "",
          "LV5-PKernel-L",
          2,
          "true / false"
        ],
        [
          "Puk",
          6,
          "LV5-Puk-C",
          11,
          "from 0.5 to 1.5"
        ],
        [
          "",
          "",
          "LV5-Puk-N",
          3,
          2
        ],
        [
          "",
          "",
          "LV5-Puk-M",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV5-Puk-K",
          4,
          "N.P.Kernel, P.Kernel, Puk, RBFKernel"
        ],
        [
          "",
          "",
          "LV5-Puk-S",
          100,
          "from 0.1 to 10.0"
        ],
        [
          "",
          "",
          "LV5-Puk-O",
          10,
          "from 0.1 to 1.0"
        ],
        [
          "RBFKernel",
          5,
          "LV5-RBFKernel-C",
          11,
          "from 0.5 to 1.5"
        ],
        [
          "",
          "",
          "LV5-RBFKernel-N",
          3,
          2
        ],
        [
          "",
          "",
          "LV5-RBFKernel-M",
          2,
          "true / false"
        ],
        [
          "",
          "",
          "LV5-RBFKernel-K",
          4,
          "N.P.Kernel, P.Kernel, Puk, RBFKernel"
        ],
        [
          "",
          "",
          "LV5-RBFKernel-G",
          1000,
          "from 0.001 to 1.0"
        ]
      ],
      "row_count": 27,
      "column_count": 5
    },
    {
      "table_number": "5",
      "table_title": "Main characteristics of the datasets used in the experiments.",
      "headers": [
        "Id",
        "Dataset",
        "\\# <br> Instances",
        "\\# Disc. <br> Attr.",
        "\\# Cont. <br> Attr.",
        "\\# <br> Classes"
      ],
      "rows": [
        [
          1,
          "Abalone",
          4177,
          1,
          7,
          28
        ],
        [
          2,
          "Adult",
          32561,
          8,
          6,
          2
        ],
        [
          3,
          "Archythmia",
          452,
          0,
          260,
          13
        ],
        [
          4,
          "Automobile",
          205,
          11,
          15,
          7
        ],
        [
          5,
          "Car",
          1728,
          0,
          6,
          4
        ],
        [
          6,
          "Dermatology",
          366,
          1,
          33,
          6
        ],
        [
          7,
          "Ecoli",
          336,
          0,
          7,
          8
        ],
        [
          8,
          "Flags",
          194,
          20,
          10,
          8
        ],
        [
          9,
          "GermanCredit",
          1000,
          13,
          7,
          2
        ],
        [
          10,
          "Glass Identification",
          214,
          0,
          10,
          7
        ],
        [
          11,
          "Image Segmentation",
          2310,
          0,
          19,
          7
        ],
        [
          12,
          "KR-vs-KP",
          3196,
          36,
          0,
          2
        ],
        [
          13,
          "Madelon",
          2600,
          0,
          500,
          2
        ],
        [
          14,
          "Nursery",
          12960,
          8,
          0,
          5
        ],
        [
          15,
          "Secom",
          1567,
          0,
          590,
          2
        ],
        [
          16,
          "Semeion",
          1593,
          0,
          256,
          10
        ],
        [
          17,
          1,
          323,
          13,
          0,
          8
        ],
        [
          18,
          "Sonar",
          208,
          0,
          60,
          2
        ],
        [
          19,
          "Waveform",
          5000,
          0,
          40,
          3
        ],
        [
          20,
          "Wine",
          4898,
          0,
          11,
          11
        ],
        [
          21,
          "Yeast",
          1484,
          0,
          8,
          10
        ]
      ],
      "row_count": 21,
      "column_count": 6
    },
    {
      "table_number": "6",
      "table_title": "Configurations for both PBIL-Auto-Ens versions.",
      "headers": [
        "Population size",
        "Learning rate",
        "$\\%$ of best individuals selected"
      ],
      "rows": [
        [
          50,
          0.5,
          "$50 \\%$"
        ]
      ],
      "row_count": 1,
      "column_count": 3
    },
    {
      "table_number": "7",
      "table_title": "Error Rate on the test set (mean over 25 runs for each dataset).",
      "headers": [
        "Id",
        "Dataset",
        "Auto- <br> WEKA",
        "Random <br> Forest",
        "PBIL- <br> Auto-Ens-v1",
        "PBIL- <br> Auto-Ens-v2"
      ],
      "rows": [
        [
          1,
          "Abalone",
          0.7316,
          0.7616,
          0.7312,
          0.7459
        ],
        [
          2,
          "Adult",
          0.1452,
          0.1504,
          0.1427,
          0.1426
        ],
        [
          3,
          "Arrhythmia",
          0.2769,
          0.3221,
          0.2743,
          0.2751
        ],
        [
          4,
          "Automobile",
          0.1912,
          0.1824,
          0.1834,
          0.1842
        ],
        [
          5,
          "Car",
          0.0028,
          0.0576,
          0.0102,
          0.0082
        ],
        [
          6,
          "Dermatology",
          0.0294,
          0.0339,
          0.0268,
          0.0284
        ],
        [
          7,
          "Ecoli",
          0.1387,
          0.1542,
          0.142,
          0.1363
        ],
        [
          8,
          "Flags",
          0.3352,
          0.3155,
          0.3455,
          0.3537
        ],
        [
          9,
          "German-Credit",
          0.2716,
          0.2612,
          0.27,
          0.2602
        ],
        [
          10,
          "Glass Identification",
          0.2383,
          0.2142,
          0.2392,
          0.2195
        ],
        [
          11,
          "Image Segmentation",
          0.0199,
          0.0203,
          0.0239,
          0.0231
        ],
        [
          12,
          "KR-vs-KP",
          0.0527,
          0.0091,
          0.0154,
          0.0057
        ],
        [
          13,
          "Madelon",
          0.3009,
          0.3541,
          0.2869,
          0.2991
        ],
        [
          14,
          "Nursery",
          0.0228,
          0.0121,
          0.0098,
          0.0085
        ],
        [
          15,
          "Secom",
          0.0779,
          0.0664,
          0.0691,
          0.0658
        ],
        [
          16,
          "Semeion",
          0.0989,
          0.0637,
          0.0588,
          0.0694
        ],
        [
          17,
          1,
          0.1182,
          0.1251,
          0.114,
          0.1126
        ],
        [
          18,
          "Sonar",
          0.2153,
          0.1788,
          0.1539,
          0.1701
        ],
        [
          19,
          "Waveform",
          0.1333,
          0.1485,
          0.1476,
          0.1349
        ],
        [
          20,
          "Wine-quality",
          0.3393,
          0.322,
          0.321,
          0.3384
        ],
        [
          21,
          "Yeast",
          0.398,
          0.3954,
          0.3952,
          0.395
        ],
        [
          "",
          "Number of wins",
          321,
          321,
          721,
          821
        ],
        [
          "",
          "Average Rank",
          2.95,
          2.86,
          2.19,
          1.95
        ]
      ],
      "row_count": 23,
      "column_count": 6
    },
    {
      "table_number": "8",
      "table_title": "Average Precision on the test set (mean over 25 runs for each dataset).",
      "headers": [
        "Id",
        "Dataset",
        "Auto- <br> WEKA",
        "Random <br> Forest",
        "PBIL- <br> Auto-Ens-v1",
        "PBIL- <br> Auto-Ens-v2"
      ],
      "rows": [
        [
          1,
          "Abalone",
          0.0999,
          0.103,
          0.1075,
          0.1078
        ],
        [
          2,
          "Adult",
          0.8181,
          0.8038,
          0.8208,
          0.8197
        ],
        [
          3,
          "Arrhythmia",
          0.4407,
          0.3061,
          0.4505,
          0.4467
        ],
        [
          4,
          "Automobile",
          0.6662,
          0.6114,
          0.6578,
          0.6861
        ],
        [
          5,
          "Car",
          0.9944,
          0.8589,
          0.9913,
          0.9925
        ],
        [
          6,
          "Dermatology",
          0.9614,
          0.9684,
          0.973,
          0.97
        ],
        [
          7,
          "Ecoli",
          0.6259,
          0.5502,
          0.6227,
          0.6296
        ],
        [
          8,
          "Flags",
          0.4728,
          0.4412,
          0.4443,
          0.4101
        ],
        [
          9,
          "GermanCredit",
          0.6711,
          0.6911,
          0.6693,
          0.6916
        ],
        [
          10,
          "Glass",
          0.7334,
          0.695,
          0.7587,
          0.7636
        ],
        [
          11,
          "Image Seg.",
          0.9768,
          0.9801,
          0.978,
          0.9785
        ],
        [
          12,
          "KR-vs-KP",
          0.9494,
          0.991,
          0.9937,
          0.9944
        ],
        [
          13,
          "Madelon",
          0.7022,
          0.6482,
          0.7167,
          0.7041
        ],
        [
          14,
          "Nursery",
          0.7547,
          0.7712,
          0.7772,
          0.8021
        ],
        [
          15,
          "Secom",
          0.4962,
          0.4834,
          0.4668,
          0.4773
        ],
        [
          16,
          "Semeion",
          0.9056,
          0.9367,
          0.9435,
          0.9339
        ],
        [
          17,
          1,
          0.1351,
          0.1373,
          0.1752,
          0.1488
        ],
        [
          18,
          "Sonar",
          0.7895,
          0.8292,
          0.8555,
          0.8373
        ],
        [
          19,
          "Waveform",
          0.8581,
          0.8524,
          0.8534,
          0.8658
        ],
        [
          20,
          "Wine",
          0.3141,
          0.317,
          0.3137,
          0.3092
        ],
        [
          21,
          "Yeast",
          0.5512,
          0.4751,
          0.5223,
          0.4985
        ],
        [
          "Number of wins",
          "",
          421,
          221,
          721,
          821
        ],
        [
          "Average Rank",
          "",
          2.81,
          3.1,
          2.14,
          1.95
        ]
      ],
      "row_count": 23,
      "column_count": 6
    },
    {
      "table_number": "9",
      "table_title": "Average Recall on the test set (mean over 25 runs for each dataset).",
      "headers": [
        "Id",
        "Dataset",
        "Auto- <br> WEKA",
        "Random <br> Forest",
        "PBIL- <br> Auto-Ens-v1",
        "PBIL- <br> Auto-Ens-v2"
      ],
      "rows": [
        [
          1,
          "Abalone",
          0.1029,
          0.1028,
          0.1089,
          0.1167
        ],
        [
          2,
          "Adult",
          0.7562,
          0.7641,
          0.777,
          0.769
        ],
        [
          3,
          "Archythmia",
          0.4202,
          0.3081,
          0.4198,
          0.4206
        ],
        [
          4,
          "Automobile",
          0.6491,
          0.609,
          0.6449,
          0.6731
        ],
        [
          5,
          "Car",
          0.9891,
          0.8591,
          0.9886,
          0.9888
        ],
        [
          6,
          "Dermatology",
          0.9568,
          0.9565,
          0.9717,
          0.969
        ],
        [
          7,
          "Ecoli",
          0.619,
          0.5483,
          0.6206,
          0.6207
        ],
        [
          8,
          "Flags",
          0.4593,
          0.4472,
          0.4441,
          0.4237
        ],
        [
          9,
          "GermanCredit",
          0.6348,
          0.6452,
          0.6292,
          0.6599
        ],
        [
          10,
          "Glass",
          0.7136,
          0.6931,
          0.7299,
          0.7385
        ],
        [
          11,
          "Image Seg.",
          0.9759,
          0.9799,
          0.9775,
          0.9791
        ],
        [
          12,
          "KR-vs-KP",
          0.9461,
          0.9907,
          0.9935,
          0.9942
        ],
        [
          13,
          "Madelon",
          0.6991,
          0.647,
          0.7131,
          0.7013
        ],
        [
          14,
          "Nursery",
          0.7476,
          0.7713,
          0.7796,
          0.8025
        ],
        [
          15,
          "Secom",
          0.5019,
          0.4835,
          0.4997,
          0.5009
        ],
        [
          16,
          "Semeion",
          0.9006,
          0.9369,
          0.941,
          0.9305
        ],
        [
          17,
          1,
          0.1308,
          0.137,
          0.1372,
          0.1319
        ],
        [
          18,
          "Sonar",
          0.7824,
          0.8185,
          0.8423,
          0.8262
        ],
        [
          19,
          "Waveform",
          0.8558,
          0.852,
          0.8528,
          0.8654
        ],
        [
          20,
          "Wine",
          0.2284,
          0.2659,
          0.24,
          0.2425
        ],
        [
          21,
          "Yeast",
          0.5174,
          0.4775,
          0.4881,
          0.4938
        ],
        [
          "Number of wins",
          "",
          421,
          221,
          621,
          921
        ],
        [
          "Average Rank",
          "",
          2.86,
          3.14,
          2.24,
          1.76
        ]
      ],
      "row_count": 23,
      "column_count": 6
    },
    {
      "table_number": "10",
      "table_title": "Average F-Measure on the test set (mean over 25 runs for each dataset).",
      "headers": [
        "Id",
        "Dataset",
        "Auto- <br> WEKA",
        "Random <br> Forest",
        "PBIL- <br> Auto-Ens-v1",
        "PBIL- <br> Auto-Ens-v2"
      ],
      "rows": [
        [
          1,
          "Abalone",
          0.1012,
          0.1039,
          0.1082,
          0.1086
        ],
        [
          2,
          "Adult",
          0.7877,
          0.7835,
          0.7902,
          0.7895
        ],
        [
          3,
          "Archythmia",
          0.4282,
          0.3075,
          0.4324,
          0.436
        ],
        [
          4,
          "Automobile",
          0.6592,
          0.613,
          0.6511,
          0.6772
        ],
        [
          5,
          "Car",
          0.9917,
          0.8586,
          0.9899,
          0.99
        ],
        [
          6,
          "Dermatology",
          0.9601,
          0.9623,
          0.9724,
          0.9695
        ],
        [
          7,
          "Ecoli",
          0.6219,
          0.5506,
          0.6213,
          0.6247
        ],
        [
          8,
          "Flags",
          0.4646,
          0.4401,
          0.4433,
          0.416
        ],
        [
          9,
          "GermanCredit",
          0.6523,
          0.6742,
          0.6483,
          0.6748
        ],
        [
          10,
          "Glass",
          0.7215,
          0.6947,
          0.7474,
          0.7506
        ],
        [
          11,
          "Image Seg.",
          0.9765,
          0.9805,
          0.9778,
          0.9789
        ],
        [
          12,
          "KR-vs-KP",
          0.9478,
          0.9909,
          0.9938,
          0.9943
        ],
        [
          13,
          "Madelon",
          0.7006,
          0.6476,
          0.7149,
          0.7051
        ],
        [
          14,
          "Nursery",
          0.751,
          0.7722,
          0.7784,
          0.8021
        ],
        [
          15,
          "Secom",
          0.5091,
          0.4831,
          0.4827,
          0.4876
        ],
        [
          16,
          "Semeion",
          0.9031,
          0.9368,
          0.9423,
          0.9322
        ],
        [
          17,
          1,
          0.1315,
          0.1377,
          0.1513,
          0.137
        ],
        [
          18,
          "Sonar",
          0.7859,
          0.8237,
          0.8488,
          0.8317
        ],
        [
          19,
          "Waveform",
          0.8579,
          0.8522,
          0.8531,
          0.8656
        ],
        [
          20,
          "Wine",
          0.2641,
          0.2795,
          0.2767,
          0.278
        ],
        [
          21,
          "Yeast",
          0.5332,
          0.4741,
          0.5036,
          0.4925
        ],
        [
          "Number of wins",
          "",
          421,
          221,
          621,
          921
        ],
        [
          "Average Rank",
          "",
          2.9,
          3.1,
          2.19,
          1.81
        ]
      ],
      "row_count": 23,
      "column_count": 6
    },
    {
      "table_number": "11",
      "table_title": "Pearson correlation between Number of Classes and Accuracy Measures.",
      "headers": [
        "Pearson",
        "Error",
        "Precision",
        "Recall",
        "F-measure"
      ],
      "rows": [
        [
          "Auto-WEKA",
          0.7224,
          -0.6297,
          -0.6167,
          -0.6254
        ],
        [
          "Random Forest",
          0.7308,
          -0.6305,
          -0.6197,
          -0.6253
        ],
        [
          "PBIL-Auto-Ens-v1",
          0.729,
          -0.6259,
          -0.6158,
          -0.6194
        ],
        [
          "PBIL-Auto-Ens-v2",
          0.7355,
          -0.6253,
          -0.6146,
          -0.6209
        ]
      ],
      "row_count": 4,
      "column_count": 5
    }
  ]
}