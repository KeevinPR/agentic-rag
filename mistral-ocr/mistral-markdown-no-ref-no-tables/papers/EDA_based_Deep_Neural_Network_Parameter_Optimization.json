{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2019/EDA based Deep Neural Network Parameter Optimization.md",
    "filename": "EDA based Deep Neural Network Parameter Optimization.md",
    "title": "EDA based Deep Neural Network Parameter Optimization",
    "year": "2019"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] Y. LeCun, Y. Bengio and G. Hinton (2015). Deep learning, Nature, 521, 436444.\n[2] G. E. Hinton and R. R. Salakhutdinov (2006). Reducing the dimensionality of data with neural networks. Science, 313, 504-507.\n[3] F. A. W. M. Mohr (2018). ML-Plan: Automated machine learning via hierarchical planning. Machine Learning, 107, 1495-1515.\n[4] M. Wistuba, A. Rawat and T. Pedapati (2019). A Survey on Neural Architecture Search. arXiv e-prints, 1905.01392.\n[5] W. Dong, T. Chen, P. Tzho, and X. Yao (2013). Scaling Up Estimation of Distribution Algorithms for Continuous Optimization. IEEE Transactions on Evolutionary Computation, 17, 797-822.\n[6] Y. Qiu, W. Zhou, N. Yu, and P. Du (2018). Denoising Sparse Autoencoder Based lctal EEG Classification. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 1-1.\n[7] Y. Bengio, A. Courville and P. Vincent (2013). Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35, 1798-1828.\n[8] M. Hauschild and M. Pelikan (2011). An introduction and survey of estimation of distribution algorithms. Swarm and Evolutionary Computation, 1, 111-128.\n[9] Q. Xu, C. Zhang, J. Sun, and L. Zhang (2016). Adaptive Learning Rate Elitism Estimation of Distribution Algorithm Combining Chaos Perturbation for Large Scale Optimization. Open Cybernetics \\& Systemics Journal, 10, 20-40.\n[10] Q. Xu, C. Zhang and L. Zhang (2014). A Fast Elitism Gaussian Estimation of Distribution Algorithm and Application for PID Optimization. The Scientific World Journal, 2014, 1-14.\n[11] W. Dong, T. Chen, P. Tzho, X. Yao (2013). Scaling Up Estimation of Distribution Algorithms for Continuous Optimization, IEEE Transactions on Evolutionary Computation 17, 797-822.\n[12] A. Kabán, J. Bootkrajang and R. J. Durrant (2016). Toward Large-Scale Continuous EDA: A Random Matrix Theory Perspective. Evolutionary Computation, 24, 255-291.\n[13] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P. Manzagol (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, The Journal of Machine Learning Research 11, $3371-3408$.",
    "references": [
      {
        "ref_id": "1",
        "text": "Y. LeCun, Y. Bengio and G. Hinton (2015). Deep learning, Nature, 521, 436444."
      },
      {
        "ref_id": "2",
        "text": "G. E. Hinton and R. R. Salakhutdinov (2006). Reducing the dimensionality of data with neural networks. Science, 313, 504-507."
      },
      {
        "ref_id": "3",
        "text": "F. A. W. M. Mohr (2018). ML-Plan: Automated machine learning via hierarchical planning. Machine Learning, 107, 1495-1515."
      },
      {
        "ref_id": "4",
        "text": "M. Wistuba, A. Rawat and T. Pedapati (2019). A Survey on Neural Architecture Search. arXiv e-prints, 1905.01392."
      },
      {
        "ref_id": "5",
        "text": "W. Dong, T. Chen, P. Tzho, and X. Yao (2013). Scaling Up Estimation of Distribution Algorithms for Continuous Optimization. IEEE Transactions on Evolutionary Computation, 17, 797-822."
      },
      {
        "ref_id": "6",
        "text": "Y. Qiu, W. Zhou, N. Yu, and P. Du (2018). Denoising Sparse Autoencoder Based lctal EEG Classification. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 1-1."
      },
      {
        "ref_id": "7",
        "text": "Y. Bengio, A. Courville and P. Vincent (2013). Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35, 1798-1828."
      },
      {
        "ref_id": "8",
        "text": "M. Hauschild and M. Pelikan (2011). An introduction and survey of estimation of distribution algorithms. Swarm and Evolutionary Computation, 1, 111-128."
      },
      {
        "ref_id": "9",
        "text": "Q. Xu, C. Zhang, J. Sun, and L. Zhang (2016). Adaptive Learning Rate Elitism Estimation of Distribution Algorithm Combining Chaos Perturbation for Large Scale Optimization. Open Cybernetics \\& Systemics Journal, 10, 20-40."
      },
      {
        "ref_id": "10",
        "text": "Q. Xu, C. Zhang and L. Zhang (2014). A Fast Elitism Gaussian Estimation of Distribution Algorithm and Application for PID Optimization. The Scientific World Journal, 2014, 1-14."
      },
      {
        "ref_id": "11",
        "text": "W. Dong, T. Chen, P. Tzho, X. Yao (2013). Scaling Up Estimation of Distribution Algorithms for Continuous Optimization, IEEE Transactions on Evolutionary Computation 17, 797-822."
      },
      {
        "ref_id": "12",
        "text": "A. Kabán, J. Bootkrajang and R. J. Durrant (2016). Toward Large-Scale Continuous EDA: A Random Matrix Theory Perspective. Evolutionary Computation, 24, 255-291."
      },
      {
        "ref_id": "13",
        "text": "P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P. Manzagol (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, The Journal of Machine Learning Research 11, $3371-3408$."
      }
    ],
    "reference_count": 13,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": []
}