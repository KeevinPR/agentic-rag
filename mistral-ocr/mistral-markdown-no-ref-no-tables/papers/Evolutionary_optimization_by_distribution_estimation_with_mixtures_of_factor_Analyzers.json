{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2002/Evolutionary optimization by distribution estimation with mixtures of factor Analyzers.md",
    "filename": "Evolutionary optimization by distribution estimation with mixtures of factor Analyzers.md",
    "title": "Evolutionary optimization by distribution estimation with mixtures of factor Analyzers",
    "year": "2002"
  },
  "references": {
    "header": "## References",
    "content": "[1] P. Larrañaga and J. A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer Academic Publishers, 2001.\n[2] M. Pelikan, D. E. Goldberg, and F. Lobo, \"A survey of optimization by building and using probabilistic models,\" Computational Optimization and Applications, vol. 21, no. 1, pp. 5-20, 2002.\n[3] M. Pelikan and D. E. Goldberg, \"Genetic algorithms, clustering, and the breaking of symmetry,\" in Parallel Problem Solving from Nature - PPSN VI, Lecture Notes in Computer Science, vol. 1917, pp. 385-394, Springer-Verlag, 2000.\n[4] G. McLachlan and D. Peel, Finite Mixture Models, John Wiley \\& Sons, 2000.\n[5] M. Gallagher, M. Frean, and T. Downs, \"Real-valued evolutionary optimization using a flexible probability density estimator,\", in Proceedings of 1999 Genetic and Evolutionary Computation Conference, vol. 1, pp. 840-846, Morgan Kaufmann Publishers, 1999.\n[6] D. Thierens and P. Bosman, \"Multi-objective optimization with iterated density estimation evolutionary algorithms using mixture models,\" in Proceedings of the Third International Symposium on Adaptive Systems, pp. 129-136, 2001.\n[7] P. Bosman and D. Thierens, \"Advancing continuous IDEAs with mixture distributions and factorization selection metrics,\" in Proceedings of 2001 Genetic and Evolutionary Computation Conference Workshop Program, pp. 208-212, Morgan Kaufmann Publishers, 2001.\n[8] R. Santana, A. Ochoa-Rodriguez, and M. R. Soto, \"The mixture of trees factorized distribution algorithm,\" in Proceedings of 2001 Genetic and Evolutionary Computation Conference, pp. 543-550, Morgan Kaufmann Publishers, 1999.\n[9] S.-Y. Shin, D.-Y. Cho, and B.-T. Zhang, \"Function optimization with latent variable models,\" in Proceedings of the Third International Symposium on Adaptive Systems, pp. 145-152, 2001.\n[10] C. M. Bishop, \"Latent variable models,\" in Learning in Graphical Models, M. I. Jordan, Ed. pp. 371-403, The MIT Press, 1999.\n[11] S.-Y. Shin and B.-T. Zhang, \"Bayesian evolutionary algorithms for continuous function optimization,\" in Proceedings of the 2001 Congress on Evolutionary Computation, vol. 1, pp. 508-515, 2001.\n[12] D.-Y. Cho and B.-T. Zhang, \"Continuous estimation of distribution algorithms with probabilistic principal component analysis,\" in Proceedings of the 2001 Congress on Evolutionary Computation, vol. 1, pp. 521-526, 2001.\n[13] Z. Ghahramani and G. E. Hinton, \"The EM algorithm for mixtures of factor analyzers,\" Technical Report CGG-TR-96-1, Department of Computer Science, University of Toronto, February 1997. [Online] http://www.gatsby.ucl.ac.uk/ zoubin/papers/tr-96-1.ps.gz\n[14] B.-T. Zhang and D.-Y. Cho, \"System identification using evolutionary Markov chain Monte Carlo,\" Journal of Systems Architecture, vol. 47, no. 7, pp. 587-599, 2001.\n[15] D. J. Bartholomew and M. Knott, Latent Variable Models and Factor Analysis, 2nd ed. Arnold, 1999.\n[16] A. P. Dempster, N. M. Laird, and D. B. Rubin, \"Maximum likelihood from incomplete data via the EM algorithm,\" Journal of the Royal Statistical Society B, vol. 39, pp. 1-38, 1977.\n[17] D. B. Rubin and D. T. Thayer, \"EM algorithms for ML factor analysis,\" Psychometrika, vol. 47, no. 1, pp. 69-76, 1982.",
    "references": [
      {
        "ref_id": "1",
        "text": "P. Larrañaga and J. A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer Academic Publishers, 2001."
      },
      {
        "ref_id": "2",
        "text": "M. Pelikan, D. E. Goldberg, and F. Lobo, \"A survey of optimization by building and using probabilistic models,\" Computational Optimization and Applications, vol. 21, no. 1, pp. 5-20, 2002."
      },
      {
        "ref_id": "3",
        "text": "M. Pelikan and D. E. Goldberg, \"Genetic algorithms, clustering, and the breaking of symmetry,\" in Parallel Problem Solving from Nature - PPSN VI, Lecture Notes in Computer Science, vol. 1917, pp. 385-394, Springer-Verlag, 2000."
      },
      {
        "ref_id": "4",
        "text": "G. McLachlan and D. Peel, Finite Mixture Models, John Wiley \\& Sons, 2000."
      },
      {
        "ref_id": "5",
        "text": "M. Gallagher, M. Frean, and T. Downs, \"Real-valued evolutionary optimization using a flexible probability density estimator,\", in Proceedings of 1999 Genetic and Evolutionary Computation Conference, vol. 1, pp. 840-846, Morgan Kaufmann Publishers, 1999."
      },
      {
        "ref_id": "6",
        "text": "D. Thierens and P. Bosman, \"Multi-objective optimization with iterated density estimation evolutionary algorithms using mixture models,\" in Proceedings of the Third International Symposium on Adaptive Systems, pp. 129-136, 2001."
      },
      {
        "ref_id": "7",
        "text": "P. Bosman and D. Thierens, \"Advancing continuous IDEAs with mixture distributions and factorization selection metrics,\" in Proceedings of 2001 Genetic and Evolutionary Computation Conference Workshop Program, pp. 208-212, Morgan Kaufmann Publishers, 2001."
      },
      {
        "ref_id": "8",
        "text": "R. Santana, A. Ochoa-Rodriguez, and M. R. Soto, \"The mixture of trees factorized distribution algorithm,\" in Proceedings of 2001 Genetic and Evolutionary Computation Conference, pp. 543-550, Morgan Kaufmann Publishers, 1999."
      },
      {
        "ref_id": "9",
        "text": "S.-Y. Shin, D.-Y. Cho, and B.-T. Zhang, \"Function optimization with latent variable models,\" in Proceedings of the Third International Symposium on Adaptive Systems, pp. 145-152, 2001."
      },
      {
        "ref_id": "10",
        "text": "C. M. Bishop, \"Latent variable models,\" in Learning in Graphical Models, M. I. Jordan, Ed. pp. 371-403, The MIT Press, 1999."
      },
      {
        "ref_id": "11",
        "text": "S.-Y. Shin and B.-T. Zhang, \"Bayesian evolutionary algorithms for continuous function optimization,\" in Proceedings of the 2001 Congress on Evolutionary Computation, vol. 1, pp. 508-515, 2001."
      },
      {
        "ref_id": "12",
        "text": "D.-Y. Cho and B.-T. Zhang, \"Continuous estimation of distribution algorithms with probabilistic principal component analysis,\" in Proceedings of the 2001 Congress on Evolutionary Computation, vol. 1, pp. 521-526, 2001."
      },
      {
        "ref_id": "13",
        "text": "Z. Ghahramani and G. E. Hinton, \"The EM algorithm for mixtures of factor analyzers,\" Technical Report CGG-TR-96-1, Department of Computer Science, University of Toronto, February 1997. [Online] http://www.gatsby.ucl.ac.uk/ zoubin/papers/tr-96-1.ps.gz"
      },
      {
        "ref_id": "14",
        "text": "B.-T. Zhang and D.-Y. Cho, \"System identification using evolutionary Markov chain Monte Carlo,\" Journal of Systems Architecture, vol. 47, no. 7, pp. 587-599, 2001."
      },
      {
        "ref_id": "15",
        "text": "D. J. Bartholomew and M. Knott, Latent Variable Models and Factor Analysis, 2nd ed. Arnold, 1999."
      },
      {
        "ref_id": "16",
        "text": "A. P. Dempster, N. M. Laird, and D. B. Rubin, \"Maximum likelihood from incomplete data via the EM algorithm,\" Journal of the Royal Statistical Society B, vol. 39, pp. 1-38, 1977."
      },
      {
        "ref_id": "17",
        "text": "D. B. Rubin and D. T. Thayer, \"EM algorithms for ML factor analysis,\" Psychometrika, vol. 47, no. 1, pp. 69-76, 1982."
      }
    ],
    "reference_count": 17,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "I",
      "table_title": "shows the comparative results to other EDAs. Except the eMCMC selection method ( $N=1000$ ), all experiments use a population of 2000 individuals, from which the best 1000 solutions are selected to estimate the distribution. The MFA $(M=10, q=5)$ with eMCMC selection have better performances than those of other EDAs and conventional style MFA.",
      "headers": [
        "",
        "Rosenbrock $\\left(-10.0 \\leq x_{t} \\leq 10.0\\right)$",
        "",
        "Griewank $\\left(-600.0 \\leq x_{t} \\leq 600.0\\right)$",
        ""
      ],
      "rows": [
        [
          "Algorithm",
          "Mean $\\pm$ Stdev",
          "\\# Evaluation",
          "Mean $\\pm$ Stdev",
          "\\# Evaluation"
        ],
        [
          "UMDA $_{c}$",
          "$8.7204 \\pm 0.0382$",
          301850,
          "$6.0783 \\times 10^{-2} \\pm 0.0193$",
          301850
        ],
        [
          "MIMIC $_{c}$",
          "$8.7141 \\pm 0.0164$",
          301850,
          "$7.3994 \\times 10^{-2} \\pm 0.0286$",
          301850
        ],
        [
          "EGNA $_{B I C}$",
          "$8.8217 \\pm 0.16$",
          268067,
          "$3.9271 \\times 10^{-2} \\pm 0.0243$",
          301850
        ],
        [
          "EGNA $_{B G e}$",
          "$8.6807 \\pm 0.0587$",
          164519,
          "$7.6389 \\times 10^{-2} \\pm 0.0293$",
          301850
        ],
        [
          "EGNA $_{e s}$",
          "$8.7366 \\pm 0.0223$",
          301850,
          "$5.6840 \\times 10^{-2} \\pm 0.0382$",
          301850
        ],
        [
          "MFA $_{\\text {half }}$",
          "$8.7048 \\pm 2.5806$",
          300000,
          "$7.7586 \\times 10^{-3} \\pm 0.0082$",
          300000
        ],
        [
          "MFA $_{\\text {eMOMC }}$",
          "$2.5184 \\pm 1.2037$",
          300000,
          "$1.0870 \\times 10^{-3} \\pm 0.0010$",
          300000
        ]
      ],
      "row_count": 8,
      "column_count": 5
    }
  ]
}