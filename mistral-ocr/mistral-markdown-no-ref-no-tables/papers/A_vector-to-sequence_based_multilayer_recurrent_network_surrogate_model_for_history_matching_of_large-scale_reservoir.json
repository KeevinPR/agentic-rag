{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2022/A vector-to-sequence based multilayer recurrent network surrogate model for history matching of large-scale reservoir.md",
    "filename": "A vector-to-sequence based multilayer recurrent network surrogate model for history matching of large-scale reservoir.md",
    "title": "A vector-to-sequence based multilayer recurrent network surrogate model for history matching of large-scale reservoir",
    "year": "2022"
  },
  "references": {
    "header": "## References",
    "content": "Abadi, Martín, Agarwal, Ashish, Barham, Paul, et al., 2016. Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv preprint arXiv: 160304467.\nChen, Yuntian, Zhang, Dongxiao, 2020. Well log generation via ensemble long short-term memory (ExLSTM) network. Geophys. Res. Lett. 47 (23), e2020G1007685 https:// doi.org/10.1029/2020GL087685 https://doi.org/10.1029/2020GL087685.\nChen, Chaohui, Gao, Guohua, Li, Ruijian, et al., 2018. Global-search distributed-gaussNewton optimization method and its integration with the randomized-maximumlikelihood method for uncertainty quantification of reservoir performance. SPE J. 23 (5), 1496-1517. https://doi.org/10.2118/182639-PA.\nCho, Kyunghyun, van Merriënboer, Bart, Bahdanau, Darmiry, et al., 2014a. On the properties of neural machine translation: encoder-decoder approaches. In: Proc.,\n\nProceedings of Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, Doha, Qatar, pp. 103-111.\nCho, Kyunghyun, Van Merriënboer, Bart, Gulcehre, Caglar, et al., 2014b. Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation. arXiv preprint arXiv:14061078.\nChung, Junyoung, Gulcehre, Caglar, Cho, Kyunghyun, et al., 2015. Gated feedback recurrent neural networks. In: Paper Presented at the Proceedings of the 32nd International Conference on International Conference on Machine Learning, vol. 37 (Lille, France).\nDonahue, J., Hendricks, L.A., Rohrbach, M., et al., 2017. Long-term recurrent convolutional networks for visual recognition and description. IEEE Trans. Pattern Anal. Mach. Intell. 39 (4), 677-691.\nFan, Dongyan, Sun, Hai, Yao, Jun, et al., 2021. Well production forecasting based on ARIMA-LSTM model considering manual operations. Energy 220, 119708. https:// www.sciencedirect.com/science/article/pii/S0366544220328152.\nGao, Lujing, Li, Haibo, Liu, Zhijian, et al., 2021. RNN-transducer based Chinese sign language recognition. Neurocomputing 434, 45-54. https://www.sciencedirect.com /science/article/pii/S0925231220318877.\nGraves, A., Jaitly, N., Mohamed, A., 2013. Hybrid speech recognition with deep bidirectional LSTM. In: Proc., 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, 8-12 Dec. 2013, pp. 273-278.\nHe, X., Deng, L., 2017. Deep learning for image-to-text generation: a technical overview. IEEE Signal Process. Mag. 34 (6), 109-116.\nHochreiter, Sepp, Schmidhuber, Jürgen, 1997. Long short-term memory. Neural Comput. 9 (8), 1735-1780.\nKingma, Diederik, P., Ba, Jimmy, 2014. Adam: A Method for Stochastic Optimization. arXiv preprint arXiv:14126980.\nLi, Boxiao, Bhark, Eric W., Groin, Stephen, et al., 2019. Best practices of assisted history matching using design of experiments. SPE J. 24 (4), 1435-1451. https://doi.org/ $10.2118 / 191699-\\mathrm{PA}$.\nLi, Xuechen, Ma, Xinfang, Xiao, Fengchao, et al., 2022. Time-series production forecasting method based on the integration of bidirectional gated recurrent unit (BiGRU) network and sparrow search algorithm (SSA). J. Petrol. Sci. Eng. 208, 109309. https://www.sciencedirect.com/science/article/pii/S0920410521809621.\nMa, Xiaopeng, Zhang, Kai, Wang, Jian, et al., 2021a. An efficient spatial-temporal convolution recurrent neural network surrogate model for history matching. SPE J. 1-16. https://doi.org/10.2118/208604-PA.\nMa, Xiaopeng, Zhang, Kai, Zhang, Liming, et al., 2021b. Data-driven niching differential evolution with adaptive parameters control for history matching and uncertainty quantification. SPE J. 1-18. https://doi.org/10.2118/205014-PA.\nMa, Xiaopeng, Zhang, Kai, Zhang, Jinding, et al., 2022. A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification. J. Petrol. Sci. Eng. 210, 110109. https://www.sciencedirect.com/sci ence/article/pii/S0920410521809621.\nMakin, Joseph G., Moore, David A., Chang, Edward F., 2020. Machine translation of cortical activity to text with an encoder-decoder framework. Nat. Neurosci. 23 (4), 575-582. https://doi.org/10.1038/s41593-020-0608-8.\nMu, Shaoxing, Zaharas, Nicholas, Shi, Xiaoging, et al., 2019. Deep autoregressive neural networks for high-dimensional inverse problems in groundwater contaminant source\n\nidentification. Water Resour. Res. 55 (5), 3856-3881. https://agupubs.onlinelibrary. wiley.com/doi/abs/10.1029/2018WR024638.\nNonsent, J., Eisen, P., Bauswem, W., 2011. Sobol'sensitivity analysis of a complex environmental model. Environ. Model. Software 26 (12), 1515-1525.\nOliver, Dean X., Chen, Yan, 2011. Recent progress on reservoir history matching: a review. Comput. Geosci. 15 (1), 185-221. https://doi.org/10.1007/s10596-010-9194-2.\nPark, J., Yang, G., Satija, A., et al., 2016. DGSA: a Matlab toolbox for distance-based generalized sensitivity analysis of geoseientific computer experiments. Comput. Geosci. 97, 15-29.\nPollack, A., Cladouhos, T.T., Sveyer, M.W., et al., 2021. Stochastic inversion of gravity, magnetic, tracer, lithology, and fault data for geologically realistic structural models: patus Geothermal Field case study. Geothermics 95, 102129.\nRemy, Nicolas, 2005. S-GeMS: the Stanford geostatistical modeling software: a tool for new algorithms development. In: Leuangthong, Oy, Deutsch, Clayton V. (Eds.), Geostatistics Banff 2004. Springer Netherlands, Dordrecht, pp. 865-871.\nSarma, Pallav, Durlofsky, Louis J., Aziz, Khalid, 2008. Kernel principal component analysis for efficient, differentiable parameterization of multipoint geostatistics. Math. Geosci. 40 (1), 3-32. https://doi.org/10.1007/s11004-007-9131-7.\nSong, Xuanyi, Liu, Yustian, Xue, Liang, et al., 2020. Time-series well performance prediction based on Long Short-Term Memory (LSTM) neural network model. J. Petrol. Sci. Eng. 186, 106682. https://www.sciencedirect.com/science/article/ pii/S0920410519311039.\nSun, Shiliang, Luo, Chen, Chen, Junyu, 2017. A review of natural language processing techniques for opinion mining systems. Inf. Fusion 36, 10-25.\nTang, Meng, Liu, Yimin, Durlofsky, Louis J., 2020. A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems. J. Comput. Phys. 413, 109456. https://www.sciencedirect.com/science/article/pii/S0021999 120302308.\n\nWang, Nanzhe, Chang, Haibin, Zhang, Dongxiao, 2021. Efficient uncertainty quantification and data assimilation via theory-guided convolutional neural network. SPE J. 26 (6), 4128-4156. https://doi.org/10.2118/203904-PA.\n\nXiao, Cong, Lin, Hai-Xiang, Leeuwenburgh, Olwijn, et al., 2022. Surrogate-assisted inversion for large-scale history matching: comparative study between projectionbased reduced-order modeling and deep neural network. J. Petrol. Sci. Eng. 208, 109287. https://www.sciencedirect.com/science/article/pii/S0920410521009402.\n\nYang, Q., Chen, W., Li, Y., et al., 2017. Multimodal estimation of distribution algorithms. IEEE Trans. Cybern. 47 (3), 636-650.\nYin, Z., Feng, T., MacBeth, C., 2019. Fast assimilation of frequently acquired 4D seismic data for reservoir history matching. Comput. Geosci. 128, 30-40.\nYin, Z., Sebastian, S., Jef, C., 2020. Automated Monte Carlo-based quantification and updating of geological uncertainty with borehole data (AutoBEl, v1. 0). Geosci. Model Dev. (GMD) 13 (2), 651-672.\nYuan-yuan, Chen, Lv, Y., Li, Z., et al., 2016. Long short-term memory model for traffic congestion prediction with online open data. In: Proc., 2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC), 1-4 Nov. 2016, pp. 132-137.\nZhang, Jiangjiang, Lin, Guang, Li, Weissan, et al., 2018a. An iterative local updating ensemble smoother for estimation and uncertainty assessment of hydrologic model parameters with multimodal distributions. Water Resour. Res. 54 (3), 1716-1733. https://doi.org/10.1002/2017WR020906: https://doi.org/10.1002/ 2017WR020906.\n\nZhang, K., Ma, X., Li, Y., et al., 2018b. Parameter prediction of hydraulic fracture for tight reservoir based on micro-seismic and history matching. Fractals 26 (2), 1840009.\n\nZhang, Kai, Jinding, Zhang, Xiaopeng, Ma, et al., 2021. History matching of naturally fractured reservoirs using a deep queue autowcoder. SPE J. 26 (4), 1700-1721.\nZhong, Zhi, Sun, Alexander Y., Wang, Yanyong, et al., 2020. Predicting field production rates for waterflooding using a machine learning-based proxy model. J. Petrol. Sci. Eng. 194, 107574. https://www.sciencedirect.com/science/article/pii/S0920410 520306422.\n\nZhu, Yinhao, Zabaras, Nicholas, 2018. Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification. J. Comput. Phys. 366, 415-447. https://www.sciencedirect.com/science/article/pii/S0021999 118302341.",
    "references": [
      {
        "ref_id": "1",
        "text": "Abadi, Martín, Agarwal, Ashish, Barham, Paul, et al., 2016. Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv preprint arXiv: 160304467."
      },
      {
        "ref_id": "2",
        "text": "Chen, Yuntian, Zhang, Dongxiao, 2020. Well log generation via ensemble long short-term memory (ExLSTM) network. Geophys. Res. Lett. 47 (23), e2020G1007685 https:// doi.org/10.1029/2020GL087685 https://doi.org/10.1029/2020GL087685."
      },
      {
        "ref_id": "3",
        "text": "Chen, Chaohui, Gao, Guohua, Li, Ruijian, et al., 2018. Global-search distributed-gaussNewton optimization method and its integration with the randomized-maximumlikelihood method for uncertainty quantification of reservoir performance. SPE J. 23 (5), 1496-1517. https://doi.org/10.2118/182639-PA."
      },
      {
        "ref_id": "4",
        "text": "Cho, Kyunghyun, van Merriënboer, Bart, Bahdanau, Darmiry, et al., 2014a. On the properties of neural machine translation: encoder-decoder approaches. In: Proc.,"
      },
      {
        "ref_id": "5",
        "text": "Proceedings of Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, Doha, Qatar, pp. 103-111."
      },
      {
        "ref_id": "6",
        "text": "Cho, Kyunghyun, Van Merriënboer, Bart, Gulcehre, Caglar, et al., 2014b. Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation. arXiv preprint arXiv:14061078."
      },
      {
        "ref_id": "7",
        "text": "Chung, Junyoung, Gulcehre, Caglar, Cho, Kyunghyun, et al., 2015. Gated feedback recurrent neural networks. In: Paper Presented at the Proceedings of the 32nd International Conference on International Conference on Machine Learning, vol. 37 (Lille, France)."
      },
      {
        "ref_id": "8",
        "text": "Donahue, J., Hendricks, L.A., Rohrbach, M., et al., 2017. Long-term recurrent convolutional networks for visual recognition and description. IEEE Trans. Pattern Anal. Mach. Intell. 39 (4), 677-691."
      },
      {
        "ref_id": "9",
        "text": "Fan, Dongyan, Sun, Hai, Yao, Jun, et al., 2021. Well production forecasting based on ARIMA-LSTM model considering manual operations. Energy 220, 119708. https:// www.sciencedirect.com/science/article/pii/S0366544220328152."
      },
      {
        "ref_id": "10",
        "text": "Gao, Lujing, Li, Haibo, Liu, Zhijian, et al., 2021. RNN-transducer based Chinese sign language recognition. Neurocomputing 434, 45-54. https://www.sciencedirect.com /science/article/pii/S0925231220318877."
      },
      {
        "ref_id": "11",
        "text": "Graves, A., Jaitly, N., Mohamed, A., 2013. Hybrid speech recognition with deep bidirectional LSTM. In: Proc., 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, 8-12 Dec. 2013, pp. 273-278."
      },
      {
        "ref_id": "12",
        "text": "He, X., Deng, L., 2017. Deep learning for image-to-text generation: a technical overview. IEEE Signal Process. Mag. 34 (6), 109-116."
      },
      {
        "ref_id": "13",
        "text": "Hochreiter, Sepp, Schmidhuber, Jürgen, 1997. Long short-term memory. Neural Comput. 9 (8), 1735-1780."
      },
      {
        "ref_id": "14",
        "text": "Kingma, Diederik, P., Ba, Jimmy, 2014. Adam: A Method for Stochastic Optimization. arXiv preprint arXiv:14126980."
      },
      {
        "ref_id": "15",
        "text": "Li, Boxiao, Bhark, Eric W., Groin, Stephen, et al., 2019. Best practices of assisted history matching using design of experiments. SPE J. 24 (4), 1435-1451. https://doi.org/ $10.2118 / 191699-\\mathrm{PA}$."
      },
      {
        "ref_id": "16",
        "text": "Li, Xuechen, Ma, Xinfang, Xiao, Fengchao, et al., 2022. Time-series production forecasting method based on the integration of bidirectional gated recurrent unit (BiGRU) network and sparrow search algorithm (SSA). J. Petrol. Sci. Eng. 208, 109309. https://www.sciencedirect.com/science/article/pii/S0920410521809621."
      },
      {
        "ref_id": "17",
        "text": "Ma, Xiaopeng, Zhang, Kai, Wang, Jian, et al., 2021a. An efficient spatial-temporal convolution recurrent neural network surrogate model for history matching. SPE J. 1-16. https://doi.org/10.2118/208604-PA."
      },
      {
        "ref_id": "18",
        "text": "Ma, Xiaopeng, Zhang, Kai, Zhang, Liming, et al., 2021b. Data-driven niching differential evolution with adaptive parameters control for history matching and uncertainty quantification. SPE J. 1-18. https://doi.org/10.2118/205014-PA."
      },
      {
        "ref_id": "19",
        "text": "Ma, Xiaopeng, Zhang, Kai, Zhang, Jinding, et al., 2022. A novel hybrid recurrent convolutional network for surrogate modeling of history matching and uncertainty quantification. J. Petrol. Sci. Eng. 210, 110109. https://www.sciencedirect.com/sci ence/article/pii/S0920410521809621."
      },
      {
        "ref_id": "20",
        "text": "Makin, Joseph G., Moore, David A., Chang, Edward F., 2020. Machine translation of cortical activity to text with an encoder-decoder framework. Nat. Neurosci. 23 (4), 575-582. https://doi.org/10.1038/s41593-020-0608-8."
      },
      {
        "ref_id": "21",
        "text": "Mu, Shaoxing, Zaharas, Nicholas, Shi, Xiaoging, et al., 2019. Deep autoregressive neural networks for high-dimensional inverse problems in groundwater contaminant source"
      },
      {
        "ref_id": "22",
        "text": "Nonsent, J., Eisen, P., Bauswem, W., 2011. Sobol'sensitivity analysis of a complex environmental model. Environ. Model. Software 26 (12), 1515-1525."
      },
      {
        "ref_id": "23",
        "text": "Oliver, Dean X., Chen, Yan, 2011. Recent progress on reservoir history matching: a review. Comput. Geosci. 15 (1), 185-221. https://doi.org/10.1007/s10596-010-9194-2."
      },
      {
        "ref_id": "24",
        "text": "Park, J., Yang, G., Satija, A., et al., 2016. DGSA: a Matlab toolbox for distance-based generalized sensitivity analysis of geoseientific computer experiments. Comput. Geosci. 97, 15-29."
      },
      {
        "ref_id": "25",
        "text": "Pollack, A., Cladouhos, T.T., Sveyer, M.W., et al., 2021. Stochastic inversion of gravity, magnetic, tracer, lithology, and fault data for geologically realistic structural models: patus Geothermal Field case study. Geothermics 95, 102129."
      },
      {
        "ref_id": "26",
        "text": "Remy, Nicolas, 2005. S-GeMS: the Stanford geostatistical modeling software: a tool for new algorithms development. In: Leuangthong, Oy, Deutsch, Clayton V. (Eds.), Geostatistics Banff 2004. Springer Netherlands, Dordrecht, pp. 865-871."
      },
      {
        "ref_id": "27",
        "text": "Sarma, Pallav, Durlofsky, Louis J., Aziz, Khalid, 2008. Kernel principal component analysis for efficient, differentiable parameterization of multipoint geostatistics. Math. Geosci. 40 (1), 3-32. https://doi.org/10.1007/s11004-007-9131-7."
      },
      {
        "ref_id": "28",
        "text": "Song, Xuanyi, Liu, Yustian, Xue, Liang, et al., 2020. Time-series well performance prediction based on Long Short-Term Memory (LSTM) neural network model. J. Petrol. Sci. Eng. 186, 106682. https://www.sciencedirect.com/science/article/ pii/S0920410519311039."
      },
      {
        "ref_id": "29",
        "text": "Sun, Shiliang, Luo, Chen, Chen, Junyu, 2017. A review of natural language processing techniques for opinion mining systems. Inf. Fusion 36, 10-25."
      },
      {
        "ref_id": "30",
        "text": "Tang, Meng, Liu, Yimin, Durlofsky, Louis J., 2020. A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems. J. Comput. Phys. 413, 109456. https://www.sciencedirect.com/science/article/pii/S0021999 120302308."
      },
      {
        "ref_id": "31",
        "text": "Wang, Nanzhe, Chang, Haibin, Zhang, Dongxiao, 2021. Efficient uncertainty quantification and data assimilation via theory-guided convolutional neural network. SPE J. 26 (6), 4128-4156. https://doi.org/10.2118/203904-PA."
      },
      {
        "ref_id": "32",
        "text": "Xiao, Cong, Lin, Hai-Xiang, Leeuwenburgh, Olwijn, et al., 2022. Surrogate-assisted inversion for large-scale history matching: comparative study between projectionbased reduced-order modeling and deep neural network. J. Petrol. Sci. Eng. 208, 109287. https://www.sciencedirect.com/science/article/pii/S0920410521009402."
      },
      {
        "ref_id": "33",
        "text": "Yang, Q., Chen, W., Li, Y., et al., 2017. Multimodal estimation of distribution algorithms. IEEE Trans. Cybern. 47 (3), 636-650."
      },
      {
        "ref_id": "34",
        "text": "Yin, Z., Feng, T., MacBeth, C., 2019. Fast assimilation of frequently acquired 4D seismic data for reservoir history matching. Comput. Geosci. 128, 30-40."
      },
      {
        "ref_id": "35",
        "text": "Yin, Z., Sebastian, S., Jef, C., 2020. Automated Monte Carlo-based quantification and updating of geological uncertainty with borehole data (AutoBEl, v1. 0). Geosci. Model Dev. (GMD) 13 (2), 651-672."
      },
      {
        "ref_id": "36",
        "text": "Yuan-yuan, Chen, Lv, Y., Li, Z., et al., 2016. Long short-term memory model for traffic congestion prediction with online open data. In: Proc., 2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC), 1-4 Nov. 2016, pp. 132-137."
      },
      {
        "ref_id": "37",
        "text": "Zhang, Jiangjiang, Lin, Guang, Li, Weissan, et al., 2018a. An iterative local updating ensemble smoother for estimation and uncertainty assessment of hydrologic model parameters with multimodal distributions. Water Resour. Res. 54 (3), 1716-1733. https://doi.org/10.1002/2017WR020906: https://doi.org/10.1002/ 2017WR020906."
      },
      {
        "ref_id": "38",
        "text": "Zhang, K., Ma, X., Li, Y., et al., 2018b. Parameter prediction of hydraulic fracture for tight reservoir based on micro-seismic and history matching. Fractals 26 (2), 1840009."
      },
      {
        "ref_id": "39",
        "text": "Zhang, Kai, Jinding, Zhang, Xiaopeng, Ma, et al., 2021. History matching of naturally fractured reservoirs using a deep queue autowcoder. SPE J. 26 (4), 1700-1721."
      },
      {
        "ref_id": "40",
        "text": "Zhong, Zhi, Sun, Alexander Y., Wang, Yanyong, et al., 2020. Predicting field production rates for waterflooding using a machine learning-based proxy model. J. Petrol. Sci. Eng. 194, 107574. https://www.sciencedirect.com/science/article/pii/S0920410 520306422."
      },
      {
        "ref_id": "41",
        "text": "Zhu, Yinhao, Zabaras, Nicholas, 2018. Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification. J. Comput. Phys. 366, 415-447. https://www.sciencedirect.com/science/article/pii/S0021999 118302341."
      }
    ],
    "reference_count": 41,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Nine different combination of hyperparameters.",
      "headers": [
        "Combination",
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9"
      ],
      "rows": [
        [
          "$N_{\\text {fqger }}$",
          1,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3
        ],
        [
          "$N_{\\text {untr }}$",
          100,
          500,
          1000,
          100,
          500,
          1000,
          100,
          500,
          1000
        ]
      ],
      "row_count": 2,
      "column_count": 10
    }
  ]
}