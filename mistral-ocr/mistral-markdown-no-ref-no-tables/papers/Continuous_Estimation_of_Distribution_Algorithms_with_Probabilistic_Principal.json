{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2001/Continuous Estimation of Distribution Algorithms with Probabilistic Principal.md",
    "filename": "Continuous Estimation of Distribution Algorithms with Probabilistic Principal.md",
    "title": "Continuous Estimation of Distribution Algorithms with Probabilistic Principal",
    "year": "2001"
  },
  "references": {
    "header": "## Bibliography",
    "content": "[1] Baluja, S. and Caruana, R. (1995) \"Removing the genetics from the standard genetic algorithm,\" Proceedings of the 12th International Conference on Machine Learning, pp. 38-46, Morgan Kaufmann.\n[2] Baluja, S. and Scott, D. (1997) \"Using optimal dependency-trees for combinatorial optimization: Learning the structure of the search space,\" Proceedings of the 14th International Conference on Machine Learning, pp. 30-38, Morgan Kaufmann.\n[3] Bartholomew, D.J. and Knott, M. (1999) Latent Variable Models and Factor Analysis, 2nd Edition, Arnold.\n[4] Bosman, P.A.N. and Thierens, D. (2000) \"Expanding from discrete to continuous estimation of distribution algorithms: The IDEA,\" Lecture Notes in Computer Science 1917: Parallel Problem Solving from Nature - PPSN VI, pp. 767-776, Springer.\n[5] Chickering, D.M. (1996) \"Learning Bayesian networks is NP-Complete,\" Learning from Data: Artificial Intelligence and Statistics V, pp. 121-130, Springer.\n[6] De Bonet, J.S., Isbell, C.L., and Viola, P. (1997) \"MIMIC: Finding optima by estimating probability densities,\" Advances in Neural Information Processing Systems, vol. 9, pp. 424-430, The MIT Press.\n[7] Harik, G.R., Lobo, F.G., and Goldberg, D.E. (1998) \"The compact genetic algorithm,\" Proceedings of the 1998 IEEE International Conference on Evolutionary Computation, pp. 523-528.\n[8] Jolliffe, I.T. (1986) Principal Component Analysis, Springer.\n[9] Larrañaga, P., Etxeberria, R., Lozano, J.A., and Peña, M. (2000) \"Optimization in continuous domains by learning and simulation of Gaussian networks,\" Proceedings of the 2000 Genetic and Evolutionary Computation Conference Workshop Program, pp. 201-204.\n[10] Mühlenbein, H. and Paaß, G. (1996) \"From recombination of genes to the estimation of distributions I. Binary parameters,\" Lecture Notes in Computer Science 1141: Parallel Problem Solving from Nature - PPSN IV, pp. 178-187, Springer.\n[11] Mühlenbein, H., Mahnig, T., and Ochoa Rodriguez, A. (1999) \"Schemata, distributions and graphical models in evolutionary optimization,\" Journal of Heuristics, vol. 5, no. 2, pp. 215-247.\n[12] Mühlenbein, H. and Mahnig, T. (1999) \"FDA - A scalable evolutionary algorithms for the optimization of additively decomposed functions,\" Evolutionary Computation, vol. 7, no. 4, pp. 353-376.\n[13] Pelikan, M. and Mühlenbein, H. (1999) \"The bivariate marginal distribution algorithm,\" Advances in Soft Computing - Engineering Design and Manufacturing, pp. 521-535, Springer.\n[14] Pelikan, M., Goldberg, D.E., and Canti-Paz, E. (2000) \"Linkage Problem, Distribution Estimation, and Bayesian Networks,\" Evolutionary Computation, vol. 8, no. 3, pp. 311-340.\n[15] Sebag, M. and Ducoulombier, A. (1998) \"Extending population-based incremental learning to continuous search spaces,\" Lecture Notes in Computer Science 1498: Parallel Problem Solving from Nature - PPSN V, pp. 418-427, Springer.\n[16] Tipping, M.E. and Bishop, C.M. (1999) \"Probabilistic principal component analysis,\" Journal of the Royal $S$ tatistical Society: Series B, vol. 61, no. 3, pp. 611-622.\n[17] Zhang, B.-T. and Shin, S.-Y. (2000) \"Bayesian evolutionary optimization using Helmholtz machines\" Lecture Notes in Computer Science 1917: Parallel Problem Solving from Nature - PPSN VI, pp. 827-836, Springer.",
    "references": [
      {
        "ref_id": "1",
        "text": "Baluja, S. and Caruana, R. (1995) \"Removing the genetics from the standard genetic algorithm,\" Proceedings of the 12th International Conference on Machine Learning, pp. 38-46, Morgan Kaufmann."
      },
      {
        "ref_id": "2",
        "text": "Baluja, S. and Scott, D. (1997) \"Using optimal dependency-trees for combinatorial optimization: Learning the structure of the search space,\" Proceedings of the 14th International Conference on Machine Learning, pp. 30-38, Morgan Kaufmann."
      },
      {
        "ref_id": "3",
        "text": "Bartholomew, D.J. and Knott, M. (1999) Latent Variable Models and Factor Analysis, 2nd Edition, Arnold."
      },
      {
        "ref_id": "4",
        "text": "Bosman, P.A.N. and Thierens, D. (2000) \"Expanding from discrete to continuous estimation of distribution algorithms: The IDEA,\" Lecture Notes in Computer Science 1917: Parallel Problem Solving from Nature - PPSN VI, pp. 767-776, Springer."
      },
      {
        "ref_id": "5",
        "text": "Chickering, D.M. (1996) \"Learning Bayesian networks is NP-Complete,\" Learning from Data: Artificial Intelligence and Statistics V, pp. 121-130, Springer."
      },
      {
        "ref_id": "6",
        "text": "De Bonet, J.S., Isbell, C.L., and Viola, P. (1997) \"MIMIC: Finding optima by estimating probability densities,\" Advances in Neural Information Processing Systems, vol. 9, pp. 424-430, The MIT Press."
      },
      {
        "ref_id": "7",
        "text": "Harik, G.R., Lobo, F.G., and Goldberg, D.E. (1998) \"The compact genetic algorithm,\" Proceedings of the 1998 IEEE International Conference on Evolutionary Computation, pp. 523-528."
      },
      {
        "ref_id": "8",
        "text": "Jolliffe, I.T. (1986) Principal Component Analysis, Springer."
      },
      {
        "ref_id": "9",
        "text": "Larrañaga, P., Etxeberria, R., Lozano, J.A., and Peña, M. (2000) \"Optimization in continuous domains by learning and simulation of Gaussian networks,\" Proceedings of the 2000 Genetic and Evolutionary Computation Conference Workshop Program, pp. 201-204."
      },
      {
        "ref_id": "10",
        "text": "Mühlenbein, H. and Paaß, G. (1996) \"From recombination of genes to the estimation of distributions I. Binary parameters,\" Lecture Notes in Computer Science 1141: Parallel Problem Solving from Nature - PPSN IV, pp. 178-187, Springer."
      },
      {
        "ref_id": "11",
        "text": "Mühlenbein, H., Mahnig, T., and Ochoa Rodriguez, A. (1999) \"Schemata, distributions and graphical models in evolutionary optimization,\" Journal of Heuristics, vol. 5, no. 2, pp. 215-247."
      },
      {
        "ref_id": "12",
        "text": "Mühlenbein, H. and Mahnig, T. (1999) \"FDA - A scalable evolutionary algorithms for the optimization of additively decomposed functions,\" Evolutionary Computation, vol. 7, no. 4, pp. 353-376."
      },
      {
        "ref_id": "13",
        "text": "Pelikan, M. and Mühlenbein, H. (1999) \"The bivariate marginal distribution algorithm,\" Advances in Soft Computing - Engineering Design and Manufacturing, pp. 521-535, Springer."
      },
      {
        "ref_id": "14",
        "text": "Pelikan, M., Goldberg, D.E., and Canti-Paz, E. (2000) \"Linkage Problem, Distribution Estimation, and Bayesian Networks,\" Evolutionary Computation, vol. 8, no. 3, pp. 311-340."
      },
      {
        "ref_id": "15",
        "text": "Sebag, M. and Ducoulombier, A. (1998) \"Extending population-based incremental learning to continuous search spaces,\" Lecture Notes in Computer Science 1498: Parallel Problem Solving from Nature - PPSN V, pp. 418-427, Springer."
      },
      {
        "ref_id": "16",
        "text": "Tipping, M.E. and Bishop, C.M. (1999) \"Probabilistic principal component analysis,\" Journal of the Royal $S$ tatistical Society: Series B, vol. 61, no. 3, pp. 611-622."
      },
      {
        "ref_id": "17",
        "text": "Zhang, B.-T. and Shin, S.-Y. (2000) \"Bayesian evolutionary optimization using Helmholtz machines\" Lecture Notes in Computer Science 1917: Parallel Problem Solving from Nature - PPSN VI, pp. 827-836, Springer."
      }
    ],
    "reference_count": 17,
    "pattern_matched": "(?:^|\\n)#+\\s*Bibliography\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Characteristics of the functions and parameter settings used in the experiments",
      "headers": [
        "Function",
        "Ackley",
        "Rastrigin",
        "Test 1",
        "Test 2",
        "Test 3",
        "Test 4",
        "Test 5",
        "Test 6"
      ],
      "rows": [
        [
          "Dimension",
          "$20-100$",
          "$20-100$",
          10,
          10,
          10,
          100,
          100,
          100
        ],
        [
          "\\#Max_Eval",
          "-",
          "-",
          300000,
          300000,
          300000,
          200000,
          200000,
          200000
        ],
        [
          "Type",
          "Min",
          "Min",
          "Max",
          "Min",
          "Min",
          "Max",
          "Max",
          "Max"
        ],
        [
          "Optimum",
          0,
          0,
          "$10^{5}$",
          0,
          0,
          "$10^{7}$",
          "$10^{7}$",
          "$10^{7}$"
        ],
        [
          "Pop_Size",
          1000,
          10000,
          10000,
          2000,
          2000,
          2000,
          2000,
          800
        ],
        [
          "Selection Rate",
          0.1,
          0.1,
          0.01,
          0.1,
          0.1,
          0.1,
          0.2,
          0.1
        ],
        [
          "\\#Latent_Variables",
          1,
          1,
          5,
          1,
          1,
          10,
          20,
          1
        ]
      ],
      "row_count": 7,
      "column_count": 9
    },
    {
      "table_number": "2",
      "table_title": "Best fitness values averaged on 100 runs for the test function 1, 2, and 3. Total running time for the PPCA-based approach is also given.",
      "headers": [
        "Methods",
        "UMDA $_{n}^{12}$",
        "$\\operatorname{MIMIC}_{n}^{12}$",
        "EGNA $_{8}$",
        "EGNA $_{\\text {BG }}$",
        "ES",
        "PPCA",
        ""
      ],
      "rows": [
        [
          "Functions",
          "Mean",
          "Mean",
          "Mean",
          "Mean",
          "Mean",
          "Mean",
          "Total Time"
        ],
        [
          1,
          53460,
          58775,
          100000,
          100000,
          5910,
          94063.01,
          25.34
        ],
        [
          2,
          0.13754,
          0.13397,
          0.09914,
          0.025,
          0,
          "$3.68 \\times 10^{-9}$",
          6.01
        ],
        [
          3,
          0.011076,
          0.007794,
          0.008175,
          0.012605,
          0.034477,
          0,
          5.71
        ]
      ],
      "row_count": 4,
      "column_count": 8
    },
    {
      "table_number": "3",
      "table_title": "Best fitness values averaged on 20 runs for the test function 4,5 , and 6 with the standard deviation. Relative time of IDEA and PPCA is also given.",
      "headers": [
        "Methods",
        "$(10+50)$-ES",
        "PBIL $_{n}$",
        "IDEA",
        "",
        "PPCA",
        "",
        "",
        ""
      ],
      "rows": [
        [
          "Functions",
          "Mean $\\pm$ Stdev",
          "Mean $\\pm$ Stdev",
          "Mean",
          "RT",
          "Mean $\\pm$ Stdev",
          "",
          "RT",
          "Total Time"
        ],
        [
          4,
          "$2.91 \\pm 0.45$",
          "$4.76 \\pm 0.78$",
          7.5,
          44.32,
          "$7.83 \\pm 0.75$",
          "",
          6.91,
          102.05
        ],
        [
          5,
          "$7.56 \\pm 1.52$",
          "$11.18 \\pm 1.36$",
          27.73,
          4.95,
          "$18.23 \\pm 1.54$",
          "",
          2.34,
          769.05
        ],
        [
          6,
          "$399.07 \\pm 6.97$",
          "$4803 \\pm 4986$",
          9999999.96,
          130.17,
          "$9997761.50 \\pm 1161.42$",
          "",
          15.86,
          19.8
        ]
      ],
      "row_count": 4,
      "column_count": 9
    }
  ]
}