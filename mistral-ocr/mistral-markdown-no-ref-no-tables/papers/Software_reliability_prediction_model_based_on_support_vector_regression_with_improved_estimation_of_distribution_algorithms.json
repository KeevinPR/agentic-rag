{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2014/Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms.md",
    "filename": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms.md",
    "title": "Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms",
    "year": "2014"
  },
  "references": {
    "header": "## References",
    "content": "[1] V.L. Berardi, P.G. Zhang, An empirical investigation of bias and variance in time-series forecasting: modeling considerations and error evaluation, IEEE Transactions on Neural Networks 14 (3) (2003) 668-679.\n[2] D.K. Chaturvedi, M. Mohan, R.K. Singh, P.K. Karla, Improved generalized neuron model for short-term load forecasting, International Journal on Soft Computing-A Fusion of Foundations, Methodologies and Applications 8 (1) (2004) 10-18.\n[3] M. Khaeber, M. Bijari, An artificial neural network (p. d. q) model for time series forecasting, Expert Systems with Applications 37 (1) (2010) 479-489.\n[4] K. Xu, M. Xie, L.C. Tang, S.L. Ho, Application of neural networks in forecasting engine system reliability, Applied Soft Computing 2 (4) (2003) 255-268.\n[5] L. Tian, A. Noore, Evolutionary neural network modeling for software cumulative failure time prediction, Reliability Engineering and System Safety 87 (1) (2005) 45-51.\n[6] M.C. Liu, T. Sastri, W. Kuo, An exploratory study of a neural network approach for reliability data analysis, Quality and Reliability Engineering International 11 (2) (1995) 107-112.\n[7] P.T. Chang, K.P. Lin, P.F. Pai, Hybrid learning fuzzy neural models in forecasting engine system reliability, in: The Fifth Asia Pacific Industrial Engineering and Management Systems Conference, Australia, Gold Coast, 2004, pp. 2361-2366.\n[8] I. Steinwart, A. Christmann, Support Vector Machines, New York, SpringerVerlag, 2008.\n[9] H.M. Azamathulla, F.C. Wu, Support vector machine approach to for longitudinal dispersion coefficients in streams, Applied Soft Computing 11 (2) (2011) 2902-2905.\n[10] A. Guven, A predictive model for pressure fluctuations on sloping channels using support vector machine, International Journal for Numerical Methods in Fluids 66 (11) (2011) 1371-1382.\n[11] H.M. Azamathulla, A.A. Ghani, A.C.K. Chang, Z.A. Hassan, N.A. Zakaria, Machine learning approach to predict sediment load-a case study, CLEAN - Soil, Air, Water 38 (10) (2010) 969-976.\n[12] V.N. Vapnik, S. Golowich, A. Smola, Support vector method for function approximation, regression estimation and signal processing, in: H.Mozer, et al. (Eds.), Advance in Neural Information Processing System, vol. 9, MIT Press, Cambridge, MA, 1997, pp. 281-287.\n[13] L.J. Cao, F.E.H. Tay, Financial forecasting using support vector machines, Neural Computing \\& Applications 10 (2) (2001) 184-192.\n[14] L. Wang, J. Zhu, Financial market forecasting using a two-step kernel learning method for the support vector regression, Annals of Operations Research 174 (1) (2010) 103-120.\n[15] A.J. Smola, Learning with kernels, Department of Computer Science, Technical University Berlin, Germany, 1998 (PhD thesis).\n[16] P. Larranaga, J.A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer Academic Publishers, Boston, 2001.\n[17] J. Zhang, W.L. Lo, H. Chung, Pseudo-convolutionary genetic algorithms for power electronic circuits optimization, IEEE Transactions on Systems, Man, and Cybernetics, Part C 36 (4) (2006) 590-598.\n[18] C.H. Wu, G.H. Tzeng, R.H. Lin, A novel hybrid genetic algorithm for kernel function and parameter optimization in support vector regression, Expert Systems with Applications 36 (3) (2009) 4725-4735.\n[19] V. Cherkassky, Y.Q. Ma, Practical selection of SVM parameters and noise estimation for SVM regression, Neural Networks 17 (1) (2004) 113-126.\n[20] J.K. Wang, Y. Wang, C.Zhang, W. Du, C.G. Zhou, Y.C. Liang, Parameter selection of support vector regression based on a novel chaotic immune algorithm, in: Fourth International Conference on Innovative Computing, Information and Control, 7-9 December 2009, Kaohsiung, Taiwan, 2009, pp. 652-655.\n[21] V.N. Vapnik, Statistical Learning Theory, John Wiley and Sons, New York, 1998.\n[22] L.D.S. Coelho, A quantum particle swarm optimizer with chaotic mutation operator, Chaos, Solitons and Fractals 37 (5) (2008) 1409-1418.\n[23] H. Handa, The effectiveness of mutation operation in the case of estimation of distribution algorithms, Biosystems 87 (2/3) (2007) 243-251.\n[24] L. Kocarev, G. Jakimoski, Logistic map as a block encryption algorithm, Physics Letters A 289 (4/5) (2001) 199-206.\n\n[25] C. Li, S. Li, G. Chen, L. Hu, Cryptanalysis of a new signal security system for multimedia data transmission, EURASIP Journal on Applied Signal Processing 2005 (8) (2005) 1277-1288.\n[26] P. Richard, C. Dennis, Cross-validation of regression models, Journal of the American Statistical Association 79 (387) (1984) 575-583.\n[27] K. Duan, S. Keerthi, A. Poo, Evaluation of simple performance measures for tuning SVM hyperparameters, Neurocompuing 51 (2003) $41-59$.\n[28] L. Pham, H. Pham, Software reliability models with time-dependent hazard function based on Bayesian approach, IEEE Transactions on Systems, Man, and Cybernetics, Part A 30 (1) (2000) 25-35.\n[29] L.Pham, H.Pham, A Bayesian predictive software reliability model with pseudofailures, IEEE Transactions on Systems, Man, and Cybernetics, Part A 31 (3) (2001) 233-238.\n[30] E.A. Sebakhy, Software reliability identification using functional networks: a comparative study, Expect Systems with Applications 36 (2) (2009) 4013-4020.\n[31] N.D. Singpurwalla, R. Soyer, Assessing (software) reliability growth using a random coefficient autoregressive process and its ramifications, IEEE Transactions on Software Engineering SE-11 (1985) 1456-1464.\n[32] P.F. Pai, W.C. Hong, Software reliability forecasting by support vector machines with simulated annealing algorithms, Journal of Systems and Software 79 (6) (2006) $747-755$.",
    "references": [
      {
        "ref_id": "1",
        "text": "V.L. Berardi, P.G. Zhang, An empirical investigation of bias and variance in time-series forecasting: modeling considerations and error evaluation, IEEE Transactions on Neural Networks 14 (3) (2003) 668-679."
      },
      {
        "ref_id": "2",
        "text": "D.K. Chaturvedi, M. Mohan, R.K. Singh, P.K. Karla, Improved generalized neuron model for short-term load forecasting, International Journal on Soft Computing-A Fusion of Foundations, Methodologies and Applications 8 (1) (2004) 10-18."
      },
      {
        "ref_id": "3",
        "text": "M. Khaeber, M. Bijari, An artificial neural network (p. d. q) model for time series forecasting, Expert Systems with Applications 37 (1) (2010) 479-489."
      },
      {
        "ref_id": "4",
        "text": "K. Xu, M. Xie, L.C. Tang, S.L. Ho, Application of neural networks in forecasting engine system reliability, Applied Soft Computing 2 (4) (2003) 255-268."
      },
      {
        "ref_id": "5",
        "text": "L. Tian, A. Noore, Evolutionary neural network modeling for software cumulative failure time prediction, Reliability Engineering and System Safety 87 (1) (2005) 45-51."
      },
      {
        "ref_id": "6",
        "text": "M.C. Liu, T. Sastri, W. Kuo, An exploratory study of a neural network approach for reliability data analysis, Quality and Reliability Engineering International 11 (2) (1995) 107-112."
      },
      {
        "ref_id": "7",
        "text": "P.T. Chang, K.P. Lin, P.F. Pai, Hybrid learning fuzzy neural models in forecasting engine system reliability, in: The Fifth Asia Pacific Industrial Engineering and Management Systems Conference, Australia, Gold Coast, 2004, pp. 2361-2366."
      },
      {
        "ref_id": "8",
        "text": "I. Steinwart, A. Christmann, Support Vector Machines, New York, SpringerVerlag, 2008."
      },
      {
        "ref_id": "9",
        "text": "H.M. Azamathulla, F.C. Wu, Support vector machine approach to for longitudinal dispersion coefficients in streams, Applied Soft Computing 11 (2) (2011) 2902-2905."
      },
      {
        "ref_id": "10",
        "text": "A. Guven, A predictive model for pressure fluctuations on sloping channels using support vector machine, International Journal for Numerical Methods in Fluids 66 (11) (2011) 1371-1382."
      },
      {
        "ref_id": "11",
        "text": "H.M. Azamathulla, A.A. Ghani, A.C.K. Chang, Z.A. Hassan, N.A. Zakaria, Machine learning approach to predict sediment load-a case study, CLEAN - Soil, Air, Water 38 (10) (2010) 969-976."
      },
      {
        "ref_id": "12",
        "text": "V.N. Vapnik, S. Golowich, A. Smola, Support vector method for function approximation, regression estimation and signal processing, in: H.Mozer, et al. (Eds.), Advance in Neural Information Processing System, vol. 9, MIT Press, Cambridge, MA, 1997, pp. 281-287."
      },
      {
        "ref_id": "13",
        "text": "L.J. Cao, F.E.H. Tay, Financial forecasting using support vector machines, Neural Computing \\& Applications 10 (2) (2001) 184-192."
      },
      {
        "ref_id": "14",
        "text": "L. Wang, J. Zhu, Financial market forecasting using a two-step kernel learning method for the support vector regression, Annals of Operations Research 174 (1) (2010) 103-120."
      },
      {
        "ref_id": "15",
        "text": "A.J. Smola, Learning with kernels, Department of Computer Science, Technical University Berlin, Germany, 1998 (PhD thesis)."
      },
      {
        "ref_id": "16",
        "text": "P. Larranaga, J.A. Lozano, Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation, Kluwer Academic Publishers, Boston, 2001."
      },
      {
        "ref_id": "17",
        "text": "J. Zhang, W.L. Lo, H. Chung, Pseudo-convolutionary genetic algorithms for power electronic circuits optimization, IEEE Transactions on Systems, Man, and Cybernetics, Part C 36 (4) (2006) 590-598."
      },
      {
        "ref_id": "18",
        "text": "C.H. Wu, G.H. Tzeng, R.H. Lin, A novel hybrid genetic algorithm for kernel function and parameter optimization in support vector regression, Expert Systems with Applications 36 (3) (2009) 4725-4735."
      },
      {
        "ref_id": "19",
        "text": "V. Cherkassky, Y.Q. Ma, Practical selection of SVM parameters and noise estimation for SVM regression, Neural Networks 17 (1) (2004) 113-126."
      },
      {
        "ref_id": "20",
        "text": "J.K. Wang, Y. Wang, C.Zhang, W. Du, C.G. Zhou, Y.C. Liang, Parameter selection of support vector regression based on a novel chaotic immune algorithm, in: Fourth International Conference on Innovative Computing, Information and Control, 7-9 December 2009, Kaohsiung, Taiwan, 2009, pp. 652-655."
      },
      {
        "ref_id": "21",
        "text": "V.N. Vapnik, Statistical Learning Theory, John Wiley and Sons, New York, 1998."
      },
      {
        "ref_id": "22",
        "text": "L.D.S. Coelho, A quantum particle swarm optimizer with chaotic mutation operator, Chaos, Solitons and Fractals 37 (5) (2008) 1409-1418."
      },
      {
        "ref_id": "23",
        "text": "H. Handa, The effectiveness of mutation operation in the case of estimation of distribution algorithms, Biosystems 87 (2/3) (2007) 243-251."
      },
      {
        "ref_id": "24",
        "text": "L. Kocarev, G. Jakimoski, Logistic map as a block encryption algorithm, Physics Letters A 289 (4/5) (2001) 199-206."
      },
      {
        "ref_id": "25",
        "text": "C. Li, S. Li, G. Chen, L. Hu, Cryptanalysis of a new signal security system for multimedia data transmission, EURASIP Journal on Applied Signal Processing 2005 (8) (2005) 1277-1288."
      },
      {
        "ref_id": "26",
        "text": "P. Richard, C. Dennis, Cross-validation of regression models, Journal of the American Statistical Association 79 (387) (1984) 575-583."
      },
      {
        "ref_id": "27",
        "text": "K. Duan, S. Keerthi, A. Poo, Evaluation of simple performance measures for tuning SVM hyperparameters, Neurocompuing 51 (2003) $41-59$."
      },
      {
        "ref_id": "28",
        "text": "L. Pham, H. Pham, Software reliability models with time-dependent hazard function based on Bayesian approach, IEEE Transactions on Systems, Man, and Cybernetics, Part A 30 (1) (2000) 25-35."
      },
      {
        "ref_id": "29",
        "text": "L.Pham, H.Pham, A Bayesian predictive software reliability model with pseudofailures, IEEE Transactions on Systems, Man, and Cybernetics, Part A 31 (3) (2001) 233-238."
      },
      {
        "ref_id": "30",
        "text": "E.A. Sebakhy, Software reliability identification using functional networks: a comparative study, Expect Systems with Applications 36 (2) (2009) 4013-4020."
      },
      {
        "ref_id": "31",
        "text": "N.D. Singpurwalla, R. Soyer, Assessing (software) reliability growth using a random coefficient autoregressive process and its ramifications, IEEE Transactions on Software Engineering SE-11 (1985) 1456-1464."
      },
      {
        "ref_id": "32",
        "text": "P.F. Pai, W.C. Hong, Software reliability forecasting by support vector machines with simulated annealing algorithms, Journal of Systems and Software 79 (6) (2006) $747-755$."
      }
    ],
    "reference_count": 32,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Reliability of turbochargers.",
      "headers": [
        "$i$",
        "$T_{i}$",
        "$i$",
        "$T_{i}$",
        "$i$",
        "$T_{i}$",
        "$i$",
        "$T_{i}$"
      ],
      "rows": [
        [
          1,
          5.5,
          7,
          3.47,
          13,
          11.42,
          19,
          0.45
        ],
        [
          2,
          1.83,
          8,
          9.96,
          14,
          18.94,
          20,
          129.31
        ],
        [
          3,
          2.75,
          9,
          11.39,
          15,
          65.3,
          21,
          31.61
        ],
        [
          4,
          70.89,
          10,
          19.88,
          16,
          0.04,
          22,
          47.6
        ],
        [
          5,
          3.94,
          11,
          7.81,
          17,
          125.67,
          "",
          ""
        ],
        [
          6,
          14.98,
          12,
          14.59,
          18,
          82.69,
          "",
          ""
        ]
      ],
      "row_count": 6,
      "column_count": 8
    },
    {
      "table_number": "2",
      "table_title": "Data of software failures.",
      "headers": [
        "$t$",
        "$Y_{t}$",
        "$t$",
        "$Y_{t}$",
        "$t$",
        "$Y_{t}$",
        "$t$",
        "$Y_{t}$",
        "$t$",
        "$Y_{t}$",
        "$t$",
        "$Y_{t}$"
      ],
      "rows": [
        [
          0,
          5.7683,
          17,
          9.6027,
          34,
          10.6301,
          51,
          10.3534,
          68,
          12.5982,
          85,
          12.7206
        ],
        [
          1,
          9.5743,
          18,
          9.3736,
          35,
          8.3333,
          52,
          10.0998,
          69,
          12.0859,
          86,
          14.192
        ],
        [
          2,
          9.105,
          19,
          8.5869,
          36,
          11.315,
          53,
          12.6078,
          70,
          12.2766,
          87,
          11.3704
        ],
        [
          3,
          7.9655,
          20,
          8.7877,
          37,
          9.4871,
          54,
          7.1546,
          71,
          11.9602,
          88,
          12.2021
        ],
        [
          4,
          8.6482,
          21,
          8.7794,
          38,
          8.1391,
          55,
          10.0033,
          72,
          12.0246,
          89,
          12.2793
        ],
        [
          5,
          9.9887,
          22,
          8.0469,
          39,
          8.6713,
          56,
          9.8601,
          73,
          9.2873,
          90,
          11.3667
        ],
        [
          6,
          10.1962,
          23,
          10.8459,
          40,
          6.4615,
          57,
          7.8675,
          74,
          12.495,
          91,
          11.3923
        ],
        [
          7,
          11.6399,
          24,
          8.7416,
          41,
          6.4615,
          58,
          10.5757,
          75,
          14.5569,
          92,
          14.4113
        ],
        [
          8,
          11.6275,
          25,
          7.5443,
          42,
          7.6955,
          59,
          10.9294,
          76,
          13.3279,
          93,
          8.3333
        ],
        [
          9,
          6.4922,
          26,
          8.5941,
          43,
          4.7005,
          60,
          10.6604,
          77,
          8.9464,
          94,
          8.0709
        ],
        [
          10,
          7.901,
          27,
          11.0399,
          44,
          10.0024,
          61,
          12.4972,
          78,
          14.7824,
          95,
          12.2021
        ],
        [
          11,
          10.2679,
          28,
          10.1196,
          45,
          11.0129,
          62,
          11.3745,
          79,
          14.8969,
          96,
          12.7831
        ],
        [
          12,
          7.6839,
          29,
          10.1786,
          46,
          10.8621,
          63,
          11.9158,
          80,
          12.1399,
          97,
          13.1585
        ],
        [
          13,
          8.8905,
          30,
          5.8944,
          47,
          9.4372,
          64,
          9.575,
          81,
          9.7981,
          98,
          12.753
        ],
        [
          14,
          9.2933,
          31,
          9.546,
          48,
          6.6644,
          65,
          10.4504,
          82,
          12.0907,
          99,
          10.3533
        ],
        [
          15,
          8.3499,
          32,
          9.6197,
          49,
          9.2294,
          66,
          10.5866,
          83,
          13.0977,
          100,
          12.4897
        ],
        [
          16,
          9.0431,
          33,
          10.3852,
          50,
          8.9671,
          67,
          12.7201,
          84,
          13.368,
          "",
          ""
        ]
      ],
      "row_count": 17,
      "column_count": 12
    },
    {
      "table_number": "3",
      "table_title": "IEDA-SVR parameters.",
      "headers": [
        "Population size $n$",
        "50"
      ],
      "rows": [
        [
          "Max generations $L$",
          500
        ],
        [
          "Chaotic parameter $\\lambda$",
          3.859
        ],
        [
          "Mutation probability $p_{m}$",
          0.03
        ],
        [
          "Bit number $l$",
          24
        ]
      ],
      "row_count": 4,
      "column_count": 2
    },
    {
      "table_number": "4",
      "table_title": "Predicting results of different models.",
      "headers": [
        "Actual results",
        "IEDA-SVR",
        "EDA-SVR",
        "Weibull Bayes <br> $I^{2}$ (hazard <br> function)",
        "Weibull Bayes <br> $I^{2}$ (hazard <br> function)",
        "Weibull Bayes <br> $I^{2}$ (hazard <br> function)",
        "Weibull Bayes <br> $I^{2}$ (hazard <br> function)"
      ],
      "rows": [
        [
          "SSE",
          2582.282,
          2759.164,
          "$16,084.081$",
          "$16,119.145$",
          9910.025,
          9611.389
        ]
      ],
      "row_count": 1,
      "column_count": 7
    },
    {
      "table_number": "5",
      "table_title": "RMSE values of compared models based on Table1.",
      "headers": [
        "Models",
        "Training set",
        "Testing set"
      ],
      "rows": [
        [
          "MR",
          51.83,
          132.29
        ],
        [
          "FFN",
          29.92,
          50.47
        ],
        [
          "SVM",
          28.79,
          19.56
        ],
        [
          "FunNets $^{\\text {a }}$",
          24.0,
          11.2
        ],
        [
          "EDA-SVR",
          20.15,
          9.63
        ],
        [
          "IEDA-SVR",
          17.35,
          6.37
        ]
      ],
      "row_count": 6,
      "column_count": 3
    },
    {
      "table_number": "6",
      "table_title": "Experiments results for Example 1.",
      "headers": [
        "",
        "IEDA-SVR"
      ],
      "rows": [
        [
          "R",
          0.9621
        ],
        [
          "Mean square error",
          2.2743
        ],
        [
          "Mean absolute error",
          0.6557
        ]
      ],
      "row_count": 3,
      "column_count": 2
    },
    {
      "table_number": "7",
      "table_title": "The compare results with other models.",
      "headers": [
        "Actual results",
        "IEDA-SVR",
        "EDA-SVR",
        "Model I ${ }^{\\text {b }}$ (normal <br> distribution)",
        "Model II ${ }^{\\text {C }}$ (Kalman <br> filter I)",
        "Model III ${ }^{\\text {e }}$ (Kalman <br> filter II)",
        "Model IV ${ }^{\\text {b }}$ (adaptive <br> Kalman filter)"
      ],
      "rows": [
        [
          "NRMSE",
          0.0885,
          0.148,
          0.2095,
          0.3462,
          0.2886,
          0.3237
        ]
      ],
      "row_count": 1,
      "column_count": 7
    },
    {
      "table_number": "8",
      "table_title": "RMSE values of compared models based on Table2.",
      "headers": [
        "$p$ value",
        "Models",
        "Testing set"
      ],
      "rows": [
        [
          5,
          "SVMSA $^{\\mathrm{a}}$",
          0.1823
        ],
        [
          "",
          "EDA-SVR",
          0.1084
        ],
        [
          "",
          "IEDA-SVR",
          0.0806
        ],
        [
          10,
          "SVMSA $^{\\mathrm{a}}$",
          0.1694
        ],
        [
          "",
          "EDA-SVR",
          0.1251
        ],
        [
          "",
          "IEDA-SVR",
          0.0884
        ],
        [
          20,
          "SVMSA $^{\\mathrm{a}}$",
          0.1589
        ],
        [
          "",
          "EDA-SVR",
          0.1283
        ],
        [
          "",
          "IEDA-SVR",
          0.096
        ],
        [
          29,
          "SVMSA $^{\\mathrm{a}}$",
          0.1562
        ],
        [
          "",
          "EDA-SVR",
          0.1381
        ],
        [
          "",
          "IEDA-SVR",
          0.1062
        ]
      ],
      "row_count": 12,
      "column_count": 3
    },
    {
      "table_number": "9",
      "table_title": "Experiment results for Example 2.",
      "headers": [
        "",
        "IEDA-SVR"
      ],
      "rows": [
        [
          "$R$",
          0.9179
        ],
        [
          "Mean square error",
          0.2012
        ],
        [
          "Mean absolute error",
          0.0848
        ]
      ],
      "row_count": 3,
      "column_count": 2
    }
  ]
}