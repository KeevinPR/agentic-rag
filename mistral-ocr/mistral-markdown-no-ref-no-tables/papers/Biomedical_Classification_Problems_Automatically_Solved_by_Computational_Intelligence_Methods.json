{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2020/Biomedical Classification Problems Automatically Solved by Computational Intelligence Methods.md",
    "filename": "Biomedical Classification Problems Automatically Solved by Computational Intelligence Methods.md",
    "title": "Biomedical Classification Problems Automatically Solved by Computational Intelligence Methods",
    "year": "2020"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] W. M. Saltzman, Biomedical Engineering: Bridging Medicine and Technology, Cambridge: Cambridge University Press, 2009.\n[2] S. Cogil and L. Wang, \"Support vector machine model of developmental brain gene expression data for priorization of Autism risk gene candidates,\" Bioinformatics, vol. 32, no. 23, pp. 3611-3618, 2016.\n[3] L. Naranjo, C. J. Pérez, J. Martín and Y. Campos-Roca, \"A two-stage variable selection and classification approach for Parkinson's disease detection by using voice recording replications,\" Computer Methods and Programs in Biomedicine, vol. 142, pp. 147-156, 2017.\n[4] F. A. Spanhol, L. S. Oliveira, C. Petitjean and H. Laurent, \"A Dataset for Breast Cancer Histopathological Image\n\nClassification,\" IEEE Transactions on Biomedical Engineering, vol. 63, no. 7, pp. 1455-1462, 2016.\n[5] M. Adam, E. Y. Ng, S. L. Oh, M. L. Heng, Y. Hagiware, J. H. Tan, J. W. Tong and U. R. Acharya, \"Automated characterization of diabetic foot using nonlinear features extracted from thermograms,\" Infrared Physics \\& Technology, vol. 89, pp. 325-337, 2018.\n[6] I. Yoo, P. Alafaireet, M. Marinov, K. Pena-Hernandez, R. Gopidi, J.-F. Chang and L. Hua, \"Data Mining in Healthcare and Biomedicine: A Survey of the Literature,\" Journal of Medical Systems, vol. 36, pp. 2431-2448, 2012.\n[7] S. Maldonado and J. López, \"Alternative second-order cone programming formulations for support vector classification,\" Information Sciences, vol. 268, pp. 328-341, 2014.\n[8] Y. Xu, Z. Yang and X. Pan, \"A Novel Twin Support-Vector Machine With Pinball Loss,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 28, no. 2, pp. 359-370, 2017.\n[9] V. Vapnik, Statistical Learning Theory, New York: John Wiley and Sons, 1998.\n[10] N. Deng, Y. Tian and C. Zhang, Support Vector Machines, Boca Ratón: CRC Press, 2013.\n[11] C. M. S. M. S. M. T. Gagné, \"Genetic Programming for Kernel-based Learning with Co-evolving Subsets Selection.,\" in Proceedings of Parallel Problem Solving, vol. 4193, T. Runarsson, H. Beyer, E. Burke, J. Merelo-Guervós, L. Whitley and X. Yao, Eds., Reykjavik, Reykjavik, Springer Verlag, 4193 (4193), 2006, pp. 1008-1017.\n[12] P. Koch, B. Bischl, O. Flasch, T. Bartz-Beielstein, C. Weihs and W. Konen, \"Tuning and Evolution of Least-Squares Support Vector Machines.,\" Evolutionary Intelligence, pp. 130, 2011.\n[13] A. Sousa, A. Lorena and M. Basgalupp, \"GEEK: Grammatical Evolution for Automatically Evolving Kernel Functions,\" Trustcom/BigDataSE/ICESS, pp. 941-948, 2017.\n[14] T. Howley and M. Madden, \"The genetic kernel support vector machine: Description and evaluation,\" Artificial Intelligence Review, pp. 379-395, 2005.\n[15] K. Sullivan and S. Luke, \"Evolving kernels for support vector machine classification,\" in Proceedings of the 9th annual Conference on Genetic and Evolutionary Computation, London, 2007.\n[16] A. Majid, A. Khan and A. M. Mirza, \"Combination of support vector machines using genetic programming,\" International Journal of Hybrid Intelligent Systems, vol. 3, no. 2, pp. 109-125, 2006.\n[17] A. Gijsberts, G. Metta and L. Rothkrantz, \"Evolutionary optimization of least-squares support vector machines,\" in Data Mining, New York, Springer, 2010, pp. 277-297.\n[18] L. Dioşan, A. Rogozan and J. Pecuchet, \"Improving classification performance of support vector machine by\ngenetically optimising kernel shape and hyper-parameters,\" Applied Intelligence, vol. 36 , no. 2, pp. 280-294, 2012.\n[19] B. Zamani, A. Akbari and B. Nasersharif, \"Evolutionary combination of kernels for nonlinear feature transformation,\" Information Sciences, pp. 95-107, 2014.\n[20] R. Mantovani, A. Rossi, J. Vanschoren and B. d.-C. A. Bischl, \"Effectiveness of Random Search in SVM hyperparameter tuning,\" in International Joint Conference on Neural Networks (IJCNN), 2015.\n[21] T. Phienthrakul and B. Kijsirikul, \"Evolutionary strategies for hyperparameters of support vector machines based on multi-scale radial basis function kernels,\" Soft Computing, vol. 14, pp. 681-699, 2010.\n[22] M. Zhao, C. Fu, L. Ji, K. Tang and M. Zhou, \"Feature selection and parameter optimization for support vector machines: A new approach based on genetic algorithm with feature chromosomes,\" Expert Systems with Applications, vol. 38, no. 5, pp. 5197-5204, 2011.\n[23] S.-W. Lin, K.-C. Ying, S.-C. Chen and Z.-J. Lee, \"Particle swarm optimization for parameter determination and feature selection of support vector machines,\" Expert Systems with Applications, vol. 35, no. 4, pp. 1817-1824, 2008.\n[24] L. Shen, H. Chen, Yu, W. Kang, B. Zhang, H. Li, Y. Bo and D. Liu, \"Evolving support vector machines using fruit fly optimization for medical data classification,\" KnowledgeBased Systems, vol. 96, no. 15, pp. 61-75, March 2016.\n[25] A. Tharwat, A. E. Hassanien and B. E. Elnaghi, \"A BA-based algorithm for parameter optimization of Support Vector Machine,\" Pattern Recognition Letters, October 2016.\n[26] L. C. Padierna, C. Martin, A. Rojas, H. Puga, R. Baltazar and F. Héctor, \"Hyper-Parameter Tuning for Support Vector Machines by Estimation of Distribution Algorithms,\" in Nature-Inspired Design of Hybrid Intelligent Systems, Vols. Studies in Computational Intelligence, 667, P. Melin, O. Castillo and J. Kacprzyk, Eds., Springer, 2017, pp. 787-800.\n[27] A. Rojas-Domínguez, L. C. Padierna, J. M. Carpio, H. J. Puga and H. Fraire, \"Optimal Hyper-parameter Tuning of SVM Classifiers with Application to Medical Diagnosis,\" IEEE Access, vol. 6, pp. 7164-7176, 2017.\n[28] J. R. Koza, Genetic programming: on the programming of computers by means of natural selection, Massachusetts: MIT press, 1992.\n[29] M. Hauschild and M. Pelikan, \"An introduction and survey of estimation of distribution algorithms,\" Swam and Evolutionary Computation, vol. 1, pp. 111-128, 2011.\n[30] J. Shawe-Taylor and N. Cristianini, Kernel Methods for Pattern Analysis, New York: Cambridge University Press, 2004.\n[31] L. Zhang, W. Zhou and L. Jiao, \"Wavelet Support Vector Machine,\" IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 34, no. 1, pp. 34-39, 2004.\n\n[32] A. D. Essam and T. Hamza, \"New empirical nonparametric kernels for support vector machines classification,\" Applied Soft Computing, no. 13, pp. 1759-1765, 2013.\n[33] Z. Pan, H. Chen and X. You, \"Support vector machine with orthogonal Legendre kernel,\" in International Conference on Wavelet Analysis and Pattern Recognition, Xian, 2012.\n[34] S. Ozer, C. Chen and H. Cirpan, \"A set of new Chebyshev kernel functions for support vector machine pattern classification,\" Pattern Recognition, vol. 44, no. 7, pp. 14351447, 2011.\n[35] V. H. Moghaddam and J. Hamidzadeh, \"New Hermite orthogonal polynomial kernel and combined kernels in Support Vector Machine classifier,\" Pattern Recognition, vol. 60, pp. 921-935, 2016.\n[36] L. C. Padierna, M. Carpio, A. Rojas-Domínguez, H. Puga and H. Fraire, \"A novel formulation of orthogonal polynomial kernel functions for SVM classifiers: The Gegenbauer family,\" Pattern Recognition, vol. 84, pp. 211-225, 2018.\n[37] J. Mercer, \"Functions of Positive and Negative Type, and their Connection with the Theory of Integral Equations,\" Philosophical transactions of the royal society of London. Series A, pp. 415-446, 1909.\n[38] N. Christianini and J. Shawe-Taylor, An Introduction to SVM and other Kernel Based Methods., Cambridge, U.K.: Cambridge University Press, 2000.\n[39] M. Gönen and E. Alpaydin, \"Multiple Kernel Learning Algorithms,\" Journal of Machine Learning Research, pp. 2211-2268, 2011.\n[40] E. Talbi, Metaheuristics: from design to implementation, New Jersey: John Wiley., 2009.\n[41] H. Mühlenbein, \"The equation for response to selection and its use for prediction. Evol. Comput.,\" Evolutionary Computation, vol. 5, no. 3, pp. 303-346, 1997.\n[42] S. I. Valdez, A. Hernández and S. Botello, \"A Boltzmann based estimation of distribution algorithm,\" Information Sciences, vol. 236, pp. 126-137, 2013.\n[43] D. Ashlock, Evolutionary Computation for Modeling and Optimization, New York: Springer, 2006.\n[44] M. Tian and W. Wang, \"Some sets of orthogonal polynomial kernel functions,\" Applied Soft Computing, vol. 61, pp. 742756, 2017.\n[45] S. Luke and L. Panait, \"A Comparison of Bloat Control Methods for Genetic Programming,\" Evolutionary Computation, vol. 14, no. 3, pp. 309-344, 2006.\n[46] D. Dua and C. Graff, UCI Machine Learning Repository [http://archive.ics.uci.edu/ml], Irvine, CA: University of California, School of Information and Computer Science, 2019.\n[47] L. C. Padierna, \"SEEKS Repository,\" University of Guanajuato, 2912 2019. [Online]. Available: https://github.com/padiernacarlos/SEEKS. [Accessed 2602 2020].\n[48] L. C. Padierna, \"Datasets, Results and Figures about Biomedical Classification Problems,\" IEEE Dataport, 15 March 2020. [Online]. Available: https://ieeedataport.org/documents/datasets-results-and-figures-about-biomedical-classification-problems. [Accessed 2020 March 15].\n[49] A. López, X. Li and W. Yu, \"Support Vector Machine Classification for Large Datasets Using Decision Tree and Fisher Linear Discriminant,\" Future Generation Computer Systems (36) 57-65, vol. 36, pp. 57-65, 2014.\n[50] A. Cüvitoglu and Z. Isik, \"Evaluation Machine-Learning Approaches for Classification of Cryotherapy and Immunotherapy Datasets,\" International Journal of Machine Learning and Computing, vol. 8, no. 4, pp. 331-335, 2018.\n[51] L. Sun, K.-A. Toh and Z. Lin, \"A center sliding Bayesian binary classifier adopting orthogonal polynomials,\" Pattern Recognition, vol. 48, no. 6, pp. 2013-2028, 2015.\n[52] H. 1. Chen, B. Yang, S. j. Wang, G. Wang, D. y. Liu, H. z. Li and W. b. Liu, \"Towards an optimal suppport vector machine classifier using a parallel particle swarm optimization strategy,\" Applied Mathematics and Computation, vol. 239, pp. 180-197, 2014.\n[53] Y. F. Hernández-Julio, M. J. Prieto-Guevara, W. NietoBernal, I. Meriño-Fuentes and A. Guerrero-Avendaño, \"Framework for the Development of Data-Driven MamdaniType Fuzzy Clinical Decision Support Systems,\" Diagnostics, vol. 9, no. 2, p. 52, 2019.\n[54] J. Zhao, Z. Yang and X. Yitian, \"Nonparallel least square support vector machine for classification,\" Applied Intelligence, pp. 1-10, 2016.\n[55] M. Li, X. Lu, X. Wang, S. Lu and N. Zhong, \"Biomedical classification application and parameters optimization of mixed kernel SVM based on the information entropy particle swarm optimization,\" Computer Assited Surgery, vol. 21, no. 1, pp. 132-141, 2016.\n[56] C.-C. Chang and L. Chih-Jen, \"LIBSVM: A library for support vector machines,\" ACM Transactions on Intelligent Systems and Technology, 2011.\n[57] I. Tsang, J. Kwok and P.-M. Cheung, \"Core Vector Machines: Fast SVM Training on Very Large Data Sets,\" Journal of Machine Learning Research, pp. 363-392, 2005.\n[58] S. García, A. Fernández, J. Luengo and F. Herrera, \"Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power,\" Information Sciences, vol. 180, pp. 2044-2064, 2010.\n[59] T. Eftimov, G. Petelin and P. Korosec, \"DSCTool: A web-service-based framework for statistical comparison of stochastic optimization algorithms,\" Applied Soft Computing Journal, vol. 87, p. 105977, 2020.\n\n[60] J. Demsar, \"Statistical Comparisons of Classifiers over Multiple Data Sets,\" Journal of Machine Learning Research, vol. 7, pp. 1-30, 2006.\n[61] B. Silverman, Density Estimation for Statistics and Data Analysis, Boca Raton: Routledge, 2018.\n[62] Y. Tang, Y.-Q. Zhang, N. Chawla and S. Krasser, \"SVMs Modeling for Highly Imbalanced Classification,\" IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics, vol. 39, no. 1, pp. 281-288, 2009.\n[63] D. E. Goldberg and D. Kalyanmoy, \"A Comparative Analysis of Selection Schemes Used in Genetic Algorithms,\" in Foundations of Genetic Algorithms, San Mateo, California, Morgan Kaufmann Publishers, 1991, pp. 69-93.\n[64] C.-W. Tsai, S.-P. Tseng, M.-C. Chiang, C.-S. Yang and T.-P. Hong, \"A High-Performance Genetic Algorithm: Using Traveling Salesman Problem as a Case,\" The Scientific World Journal, vol. 2014, pp. 1-14, 2014.\n[65] S. S. Skiena, The Algorithm Design Manual, Second Edition ed., New York: Springer, 2008.\n![img-5.jpeg](img-5.jpeg)\n\nLUIS CARLOS PADIERNA was born in Dolores Hidalgo, Guanajuato, México, in 1985. He received the B.Eng. degree in computer systems engineering from the Celaya Institute of Technology in 2009; the M.Sc. degree in computer science in 2011 from the León Institute of Technology and the Ph.D. in computer science from the Tijuana Institute of Technology in 2018.\nDr. Padierna is now an associate professor at the University of Guanajuato and has authored research works on the designing of support vector machines. His main research interests are: machine\nlearning, pattern recognition, evolutionary algorithms, and deep learning.\n![img-6.jpeg](img-6.jpeg)\n\nCARLOS VILLASEÑOR-MORA was born in Acuitzio del Canje, Michoacán, México, in 1979. He received the B.Eng. degree in electronics engineering from the Morelia Institute of Technology in 2001; the M.Sc. in electronics in 2004 from the Celaya Institute of Technology and the Ph.D. in optical science from the Optical Research Center (CIO) in 2009. He has authored research works on infrared, biomedical and optics applications. His main research interests are on non-invasive\nbiomedical techniques for diagnostics and infrared thermal applications such as diabetic retinopathy and diabetic foot.\n![img-7.jpeg](img-7.jpeg)\n\nSILVIA ALEJANDRA LOPEZ JUAREZ was born in Irapuato, Guanajuato, Mexico in 1980. She received the Bachelor degree in Chemical Pharmaceutical Biology from the Universidad de Guanajuato in 2004; M.Sc. in Neurobiology in 2006 from Universidad Nacional Autonoma de México and the PhD degree from Museum Nationale d'Histoire Naturelle a Paris in 2011.She has authored research Works on Neurobiology and Cellular therapy by using Cell Imaging Analysis. She is particularly interested to apply computational intelligence to analyze cellular\nmarkers in both neurodegenerative (Parkinson's disease) and neuroregenerative (adult neurogenesis) cellular processes.",
    "references": [
      {
        "ref_id": "1",
        "text": "W. M. Saltzman, Biomedical Engineering: Bridging Medicine and Technology, Cambridge: Cambridge University Press, 2009."
      },
      {
        "ref_id": "2",
        "text": "S. Cogil and L. Wang, \"Support vector machine model of developmental brain gene expression data for priorization of Autism risk gene candidates,\" Bioinformatics, vol. 32, no. 23, pp. 3611-3618, 2016."
      },
      {
        "ref_id": "3",
        "text": "L. Naranjo, C. J. Pérez, J. Martín and Y. Campos-Roca, \"A two-stage variable selection and classification approach for Parkinson's disease detection by using voice recording replications,\" Computer Methods and Programs in Biomedicine, vol. 142, pp. 147-156, 2017."
      },
      {
        "ref_id": "4",
        "text": "F. A. Spanhol, L. S. Oliveira, C. Petitjean and H. Laurent, \"A Dataset for Breast Cancer Histopathological Image"
      },
      {
        "ref_id": "5",
        "text": "M. Adam, E. Y. Ng, S. L. Oh, M. L. Heng, Y. Hagiware, J. H. Tan, J. W. Tong and U. R. Acharya, \"Automated characterization of diabetic foot using nonlinear features extracted from thermograms,\" Infrared Physics \\& Technology, vol. 89, pp. 325-337, 2018."
      },
      {
        "ref_id": "6",
        "text": "I. Yoo, P. Alafaireet, M. Marinov, K. Pena-Hernandez, R. Gopidi, J.-F. Chang and L. Hua, \"Data Mining in Healthcare and Biomedicine: A Survey of the Literature,\" Journal of Medical Systems, vol. 36, pp. 2431-2448, 2012."
      },
      {
        "ref_id": "7",
        "text": "S. Maldonado and J. López, \"Alternative second-order cone programming formulations for support vector classification,\" Information Sciences, vol. 268, pp. 328-341, 2014."
      },
      {
        "ref_id": "8",
        "text": "Y. Xu, Z. Yang and X. Pan, \"A Novel Twin Support-Vector Machine With Pinball Loss,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 28, no. 2, pp. 359-370, 2017."
      },
      {
        "ref_id": "9",
        "text": "V. Vapnik, Statistical Learning Theory, New York: John Wiley and Sons, 1998."
      },
      {
        "ref_id": "10",
        "text": "N. Deng, Y. Tian and C. Zhang, Support Vector Machines, Boca Ratón: CRC Press, 2013."
      },
      {
        "ref_id": "11",
        "text": "C. M. S. M. S. M. T. Gagné, \"Genetic Programming for Kernel-based Learning with Co-evolving Subsets Selection.,\" in Proceedings of Parallel Problem Solving, vol. 4193, T. Runarsson, H. Beyer, E. Burke, J. Merelo-Guervós, L. Whitley and X. Yao, Eds., Reykjavik, Reykjavik, Springer Verlag, 4193 (4193), 2006, pp. 1008-1017."
      },
      {
        "ref_id": "12",
        "text": "P. Koch, B. Bischl, O. Flasch, T. Bartz-Beielstein, C. Weihs and W. Konen, \"Tuning and Evolution of Least-Squares Support Vector Machines.,\" Evolutionary Intelligence, pp. 130, 2011."
      },
      {
        "ref_id": "13",
        "text": "A. Sousa, A. Lorena and M. Basgalupp, \"GEEK: Grammatical Evolution for Automatically Evolving Kernel Functions,\" Trustcom/BigDataSE/ICESS, pp. 941-948, 2017."
      },
      {
        "ref_id": "14",
        "text": "T. Howley and M. Madden, \"The genetic kernel support vector machine: Description and evaluation,\" Artificial Intelligence Review, pp. 379-395, 2005."
      },
      {
        "ref_id": "15",
        "text": "K. Sullivan and S. Luke, \"Evolving kernels for support vector machine classification,\" in Proceedings of the 9th annual Conference on Genetic and Evolutionary Computation, London, 2007."
      },
      {
        "ref_id": "16",
        "text": "A. Majid, A. Khan and A. M. Mirza, \"Combination of support vector machines using genetic programming,\" International Journal of Hybrid Intelligent Systems, vol. 3, no. 2, pp. 109-125, 2006."
      },
      {
        "ref_id": "17",
        "text": "A. Gijsberts, G. Metta and L. Rothkrantz, \"Evolutionary optimization of least-squares support vector machines,\" in Data Mining, New York, Springer, 2010, pp. 277-297."
      },
      {
        "ref_id": "18",
        "text": "L. Dioşan, A. Rogozan and J. Pecuchet, \"Improving classification performance of support vector machine by"
      },
      {
        "ref_id": "19",
        "text": "B. Zamani, A. Akbari and B. Nasersharif, \"Evolutionary combination of kernels for nonlinear feature transformation,\" Information Sciences, pp. 95-107, 2014."
      },
      {
        "ref_id": "20",
        "text": "R. Mantovani, A. Rossi, J. Vanschoren and B. d.-C. A. Bischl, \"Effectiveness of Random Search in SVM hyperparameter tuning,\" in International Joint Conference on Neural Networks (IJCNN), 2015."
      },
      {
        "ref_id": "21",
        "text": "T. Phienthrakul and B. Kijsirikul, \"Evolutionary strategies for hyperparameters of support vector machines based on multi-scale radial basis function kernels,\" Soft Computing, vol. 14, pp. 681-699, 2010."
      },
      {
        "ref_id": "22",
        "text": "M. Zhao, C. Fu, L. Ji, K. Tang and M. Zhou, \"Feature selection and parameter optimization for support vector machines: A new approach based on genetic algorithm with feature chromosomes,\" Expert Systems with Applications, vol. 38, no. 5, pp. 5197-5204, 2011."
      },
      {
        "ref_id": "23",
        "text": "S.-W. Lin, K.-C. Ying, S.-C. Chen and Z.-J. Lee, \"Particle swarm optimization for parameter determination and feature selection of support vector machines,\" Expert Systems with Applications, vol. 35, no. 4, pp. 1817-1824, 2008."
      },
      {
        "ref_id": "24",
        "text": "L. Shen, H. Chen, Yu, W. Kang, B. Zhang, H. Li, Y. Bo and D. Liu, \"Evolving support vector machines using fruit fly optimization for medical data classification,\" KnowledgeBased Systems, vol. 96, no. 15, pp. 61-75, March 2016."
      },
      {
        "ref_id": "25",
        "text": "A. Tharwat, A. E. Hassanien and B. E. Elnaghi, \"A BA-based algorithm for parameter optimization of Support Vector Machine,\" Pattern Recognition Letters, October 2016."
      },
      {
        "ref_id": "26",
        "text": "L. C. Padierna, C. Martin, A. Rojas, H. Puga, R. Baltazar and F. Héctor, \"Hyper-Parameter Tuning for Support Vector Machines by Estimation of Distribution Algorithms,\" in Nature-Inspired Design of Hybrid Intelligent Systems, Vols. Studies in Computational Intelligence, 667, P. Melin, O. Castillo and J. Kacprzyk, Eds., Springer, 2017, pp. 787-800."
      },
      {
        "ref_id": "27",
        "text": "A. Rojas-Domínguez, L. C. Padierna, J. M. Carpio, H. J. Puga and H. Fraire, \"Optimal Hyper-parameter Tuning of SVM Classifiers with Application to Medical Diagnosis,\" IEEE Access, vol. 6, pp. 7164-7176, 2017."
      },
      {
        "ref_id": "28",
        "text": "J. R. Koza, Genetic programming: on the programming of computers by means of natural selection, Massachusetts: MIT press, 1992."
      },
      {
        "ref_id": "29",
        "text": "M. Hauschild and M. Pelikan, \"An introduction and survey of estimation of distribution algorithms,\" Swam and Evolutionary Computation, vol. 1, pp. 111-128, 2011."
      },
      {
        "ref_id": "30",
        "text": "J. Shawe-Taylor and N. Cristianini, Kernel Methods for Pattern Analysis, New York: Cambridge University Press, 2004."
      },
      {
        "ref_id": "31",
        "text": "L. Zhang, W. Zhou and L. Jiao, \"Wavelet Support Vector Machine,\" IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 34, no. 1, pp. 34-39, 2004."
      },
      {
        "ref_id": "32",
        "text": "A. D. Essam and T. Hamza, \"New empirical nonparametric kernels for support vector machines classification,\" Applied Soft Computing, no. 13, pp. 1759-1765, 2013."
      },
      {
        "ref_id": "33",
        "text": "Z. Pan, H. Chen and X. You, \"Support vector machine with orthogonal Legendre kernel,\" in International Conference on Wavelet Analysis and Pattern Recognition, Xian, 2012."
      },
      {
        "ref_id": "34",
        "text": "S. Ozer, C. Chen and H. Cirpan, \"A set of new Chebyshev kernel functions for support vector machine pattern classification,\" Pattern Recognition, vol. 44, no. 7, pp. 14351447, 2011."
      },
      {
        "ref_id": "35",
        "text": "V. H. Moghaddam and J. Hamidzadeh, \"New Hermite orthogonal polynomial kernel and combined kernels in Support Vector Machine classifier,\" Pattern Recognition, vol. 60, pp. 921-935, 2016."
      },
      {
        "ref_id": "36",
        "text": "L. C. Padierna, M. Carpio, A. Rojas-Domínguez, H. Puga and H. Fraire, \"A novel formulation of orthogonal polynomial kernel functions for SVM classifiers: The Gegenbauer family,\" Pattern Recognition, vol. 84, pp. 211-225, 2018."
      },
      {
        "ref_id": "37",
        "text": "J. Mercer, \"Functions of Positive and Negative Type, and their Connection with the Theory of Integral Equations,\" Philosophical transactions of the royal society of London. Series A, pp. 415-446, 1909."
      },
      {
        "ref_id": "38",
        "text": "N. Christianini and J. Shawe-Taylor, An Introduction to SVM and other Kernel Based Methods., Cambridge, U.K.: Cambridge University Press, 2000."
      },
      {
        "ref_id": "39",
        "text": "M. Gönen and E. Alpaydin, \"Multiple Kernel Learning Algorithms,\" Journal of Machine Learning Research, pp. 2211-2268, 2011."
      },
      {
        "ref_id": "40",
        "text": "E. Talbi, Metaheuristics: from design to implementation, New Jersey: John Wiley., 2009."
      },
      {
        "ref_id": "41",
        "text": "H. Mühlenbein, \"The equation for response to selection and its use for prediction. Evol. Comput.,\" Evolutionary Computation, vol. 5, no. 3, pp. 303-346, 1997."
      },
      {
        "ref_id": "42",
        "text": "S. I. Valdez, A. Hernández and S. Botello, \"A Boltzmann based estimation of distribution algorithm,\" Information Sciences, vol. 236, pp. 126-137, 2013."
      },
      {
        "ref_id": "43",
        "text": "D. Ashlock, Evolutionary Computation for Modeling and Optimization, New York: Springer, 2006."
      },
      {
        "ref_id": "44",
        "text": "M. Tian and W. Wang, \"Some sets of orthogonal polynomial kernel functions,\" Applied Soft Computing, vol. 61, pp. 742756, 2017."
      },
      {
        "ref_id": "45",
        "text": "S. Luke and L. Panait, \"A Comparison of Bloat Control Methods for Genetic Programming,\" Evolutionary Computation, vol. 14, no. 3, pp. 309-344, 2006."
      },
      {
        "ref_id": "46",
        "text": "D. Dua and C. Graff, UCI Machine Learning Repository [http://archive.ics.uci.edu/ml], Irvine, CA: University of California, School of Information and Computer Science, 2019."
      },
      {
        "ref_id": "47",
        "text": "L. C. Padierna, \"SEEKS Repository,\" University of Guanajuato, 2912 2019. [Online]. Available: https://github.com/padiernacarlos/SEEKS. [Accessed 2602 2020]."
      },
      {
        "ref_id": "48",
        "text": "L. C. Padierna, \"Datasets, Results and Figures about Biomedical Classification Problems,\" IEEE Dataport, 15 March 2020. [Online]. Available: https://ieeedataport.org/documents/datasets-results-and-figures-about-biomedical-classification-problems. [Accessed 2020 March 15]."
      },
      {
        "ref_id": "49",
        "text": "A. López, X. Li and W. Yu, \"Support Vector Machine Classification for Large Datasets Using Decision Tree and Fisher Linear Discriminant,\" Future Generation Computer Systems (36) 57-65, vol. 36, pp. 57-65, 2014."
      },
      {
        "ref_id": "50",
        "text": "A. Cüvitoglu and Z. Isik, \"Evaluation Machine-Learning Approaches for Classification of Cryotherapy and Immunotherapy Datasets,\" International Journal of Machine Learning and Computing, vol. 8, no. 4, pp. 331-335, 2018."
      },
      {
        "ref_id": "51",
        "text": "L. Sun, K.-A. Toh and Z. Lin, \"A center sliding Bayesian binary classifier adopting orthogonal polynomials,\" Pattern Recognition, vol. 48, no. 6, pp. 2013-2028, 2015."
      },
      {
        "ref_id": "52",
        "text": "H. 1. Chen, B. Yang, S. j. Wang, G. Wang, D. y. Liu, H. z. Li and W. b. Liu, \"Towards an optimal suppport vector machine classifier using a parallel particle swarm optimization strategy,\" Applied Mathematics and Computation, vol. 239, pp. 180-197, 2014."
      },
      {
        "ref_id": "53",
        "text": "Y. F. Hernández-Julio, M. J. Prieto-Guevara, W. NietoBernal, I. Meriño-Fuentes and A. Guerrero-Avendaño, \"Framework for the Development of Data-Driven MamdaniType Fuzzy Clinical Decision Support Systems,\" Diagnostics, vol. 9, no. 2, p. 52, 2019."
      },
      {
        "ref_id": "54",
        "text": "J. Zhao, Z. Yang and X. Yitian, \"Nonparallel least square support vector machine for classification,\" Applied Intelligence, pp. 1-10, 2016."
      },
      {
        "ref_id": "55",
        "text": "M. Li, X. Lu, X. Wang, S. Lu and N. Zhong, \"Biomedical classification application and parameters optimization of mixed kernel SVM based on the information entropy particle swarm optimization,\" Computer Assited Surgery, vol. 21, no. 1, pp. 132-141, 2016."
      },
      {
        "ref_id": "56",
        "text": "C.-C. Chang and L. Chih-Jen, \"LIBSVM: A library for support vector machines,\" ACM Transactions on Intelligent Systems and Technology, 2011."
      },
      {
        "ref_id": "57",
        "text": "I. Tsang, J. Kwok and P.-M. Cheung, \"Core Vector Machines: Fast SVM Training on Very Large Data Sets,\" Journal of Machine Learning Research, pp. 363-392, 2005."
      },
      {
        "ref_id": "58",
        "text": "S. García, A. Fernández, J. Luengo and F. Herrera, \"Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power,\" Information Sciences, vol. 180, pp. 2044-2064, 2010."
      },
      {
        "ref_id": "59",
        "text": "T. Eftimov, G. Petelin and P. Korosec, \"DSCTool: A web-service-based framework for statistical comparison of stochastic optimization algorithms,\" Applied Soft Computing Journal, vol. 87, p. 105977, 2020."
      },
      {
        "ref_id": "60",
        "text": "J. Demsar, \"Statistical Comparisons of Classifiers over Multiple Data Sets,\" Journal of Machine Learning Research, vol. 7, pp. 1-30, 2006."
      },
      {
        "ref_id": "61",
        "text": "B. Silverman, Density Estimation for Statistics and Data Analysis, Boca Raton: Routledge, 2018."
      },
      {
        "ref_id": "62",
        "text": "Y. Tang, Y.-Q. Zhang, N. Chawla and S. Krasser, \"SVMs Modeling for Highly Imbalanced Classification,\" IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics, vol. 39, no. 1, pp. 281-288, 2009."
      },
      {
        "ref_id": "63",
        "text": "D. E. Goldberg and D. Kalyanmoy, \"A Comparative Analysis of Selection Schemes Used in Genetic Algorithms,\" in Foundations of Genetic Algorithms, San Mateo, California, Morgan Kaufmann Publishers, 1991, pp. 69-93."
      },
      {
        "ref_id": "64",
        "text": "C.-W. Tsai, S.-P. Tseng, M.-C. Chiang, C.-S. Yang and T.-P. Hong, \"A High-Performance Genetic Algorithm: Using Traveling Salesman Problem as a Case,\" The Scientific World Journal, vol. 2014, pp. 1-14, 2014."
      },
      {
        "ref_id": "65",
        "text": "S. S. Skiena, The Algorithm Design Manual, Second Edition ed., New York: Springer, 2008."
      }
    ],
    "reference_count": 65,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "I",
      "table_title": "CLASSIC, WAVELET, NON-PARAMETRIC, AND ORTHOGONAL POLYNOMIAL KERNELS",
      "headers": [
        "Kernel (short <br> label)",
        "Expression",
        "Eq."
      ],
      "rows": [
        [
          "Linear (L)",
          "$K_{L i n}(\\mathbf{x}, \\mathbf{z})=\\mathbf{x}^{T} \\mathbf{z}$",
          "$(2)$"
        ],
        [
          "Polynomial (P)",
          "$K_{P a l}(\\mathbf{x}, \\mathbf{z})=\\left(a \\mathbf{x}^{T} \\mathbf{z}+\\mathrm{b}\\right)^{\\mathrm{n}}$",
          "$(3)$"
        ],
        [
          "",
          "with $h=\\cos \\left(1.75 \\times\\left(\\mathbf{x}_{i}-\\mathbf{z}_{i}\\right) / a\\right)$",
          ""
        ],
        [
          "Legendre (E)",
          "$K_{\\text {Leg }}(\\mathbf{x}, \\mathbf{z})=\\prod_{i=1}^{d} \\sum_{j=0}^{s} P_{i}\\left(x_{j}\\right) H e_{i}\\left(z_{j}\\right)$",
          "$(8)$"
        ],
        [
          "s-Hermite (H)",
          "$K_{H a r}(\\mathbf{x}, \\mathbf{z})=\\prod_{i=1}^{d} \\sum_{j=0}^{s} P_{i}\\left(x_{j}\\right) H e_{i}\\left(z_{j}\\right)\\left(2^{-2 n}\\right)$",
          "$(9)$"
        ]
      ],
      "row_count": 5,
      "column_count": 3
    },
    {
      "table_number": "II",
      "table_title": "CLOSURES ALLOWING THE VALID COMBINATION OF KERNELS",
      "headers": [
        "$K(x, z)$",
        "Description"
      ],
      "rows": [
        [
          "$K(x, z)=K_{1}(x, z)+K_{2}(x, z)$",
          "Closure under the sum."
        ],
        [
          "$K(x, z)=a K_{1}(x, z)$",
          "Multiplication by a scalar, $a \\in R^{+}$."
        ],
        [
          "$K(x, z)=K_{1}(x, z) K_{2}(x, z)$",
          "Closure under product."
        ],
        [
          "$K(x, z)=f(x) f(z)$",
          "$f(\\cdot)$ is a real-valued function on $X$."
        ],
        [
          "$K(x, z)=K_{2}(\\phi(x), \\phi(z))$",
          "Kernel composition."
        ]
      ],
      "row_count": 5,
      "column_count": 2
    },
    {
      "table_number": null,
      "table_title": null,
      "headers": [
        "LISTING 2. General Genetic Programming Algorithm",
        ""
      ],
      "rows": [
        [
          1,
          "Generate an initial population of solutions: $S^{(0)}=\\left\\{\\mathbf{s}_{i}\\right\\}_{i=1}^{N}$ at iteration $t=0$, uniformly"
        ],
        [
          2,
          "while (stop criteria are not met)"
        ],
        [
          3,
          "Compute objective function of each solution $g\\left(S^{(t)}\\right)$"
        ],
        [
          4,
          "Select $m$ individuals for reproduction $S_{r}^{(t)} \\subset S^{(t)}$"
        ],
        [
          5,
          "Apply variation operators to $S_{r}^{(t)}$ and keep the offspring $S_{o}^{(t)}$"
        ],
        [
          6,
          "Compute objective function of each new candidate solution $g\\left(S_{o}^{(t)}\\right)$"
        ],
        [
          7,
          "Integrate candidates $S_{o}^{(t)}$ to the new population according to replacement operators"
        ],
        [
          8,
          "Update $t=t+1$"
        ],
        [
          9,
          "end while"
        ],
        [
          10,
          "Output the best solution found, $\\mathbf{s}^{*}$, as a result."
        ]
      ],
      "row_count": 10,
      "column_count": 2
    },
    {
      "table_number": "III",
      "table_title": "SUMMARY OF BIOMEDICAL CLASSIFICATION PROBLEMS",
      "headers": [
        "Dataset short label",
        "Total cases (positive - negative)",
        "Fts $^{1}$",
        "Best Accuracy ${ }^{2}$ reported with RBF or Multiple Kernels",
        "References"
      ],
      "rows": [
        [
          2,
          "400 (150-250)",
          24,
          99.6,
          ""
        ],
        [
          4,
          "90 (43-47)",
          6,
          91.0,
          50
        ],
        [
          11,
          "961(445-516)",
          5,
          86.44,
          52
        ]
      ],
      "row_count": 3,
      "column_count": 5
    },
    {
      "table_number": "IV",
      "table_title": "CONFIGURATION OF SEEKS FOR KERNEL EVOLUTION",
      "headers": [
        "Parameter",
        "Koch et al. 2012",
        "Diosan et al. 2012",
        "Souza et al. 2017",
        "SEEKS"
      ],
      "rows": [
        [
          "Population size",
          20,
          50,
          200,
          100
        ],
        [
          "Max Tree depth",
          "---",
          10,
          "$100^{1}$",
          "2-5"
        ],
        [
          "Generations",
          "$2500^{2}$",
          50,
          100,
          15
        ],
        [
          "Mutation rate",
          "--- $^{3}$",
          "$30 \\%$",
          "$30 \\%$",
          "$30 \\%$"
        ],
        [
          "Crossover rate",
          "---",
          "$80 \\%$",
          "$90 \\%$",
          "$90 \\%$"
        ],
        [
          "Function set (FS)",
          "$\\begin{aligned} & +,-, \\times, \\\\ & \\%, \\exp \\\\ & \\text { norm } \\end{aligned}$",
          "$\\times,+, \\exp$",
          "$\\begin{gathered} \\mathrm{x},+, \\exp \\\\ \\log , \\tanh \\end{gathered}$",
          "$\\times,+$"
        ],
        [
          "Initialization",
          "Grow",
          "Grow",
          "GE",
          "Grow"
        ],
        [
          "Selection method",
          -8,
          -2,
          -2,
          -2
        ]
      ],
      "row_count": 8,
      "column_count": 5
    },
    {
      "table_number": null,
      "table_title": null,
      "headers": [
        "TABLE V",
        ""
      ],
      "rows": [
        [
          "CONFIGURATION OF SEEKS FOR HYPER-PARAMETER TUNING",
          ""
        ],
        [
          "Parameter",
          "Experimental Setting"
        ],
        [
          "Previous Works",
          ""
        ],
        [
          "RBF kernel decaying $\\gamma[18]$",
          "$\\begin{gathered} \\gamma_{\\mathrm{gr}}=q \\cdot 10^{4} \\\\ q=\\{1,2, \\ldots, 9\\} \\\\ t=\\{-5,-4, \\ldots,-1\\} \\end{gathered}$"
        ],
        [
          "Polynomial order $n[18]$",
          "$n \\in\\{1,2, \\ldots, 15\\}$"
        ],
        [
          "Regularization $C$,",
          "$C \\in\\left\\{2^{-1}, 1,2^{1}, \\ldots 2^{5}\\right\\}$"
        ],
        [
          "Kernel decaying $\\gamma[51]$",
          "$\\gamma \\in\\left\\{2^{-6}, 2^{-5}, \\ldots, 1\\right\\}$"
        ],
        [
          "Polynomial order $n$",
          "$n \\in\\{2,3, \\ldots, 6\\}$"
        ],
        [
          "Kernel decaying $\\gamma,[51]$",
          "$\\begin{gathered} \\gamma \\\\ \\in\\{0.1,0.25,0.5,1,1.5,2,2.5,3\\} \\end{gathered}$"
        ],
        [
          "SEEKS",
          ""
        ],
        [
          "Regularization $C$",
          "$C \\in(0,32]$"
        ],
        [
          "RBF kernel decaying $\\gamma$",
          "$\\gamma \\in(0,4]$"
        ],
        [
          "Polynomial order $n$",
          "$n \\in\\{1,2, \\ldots, 6\\}$"
        ],
        [
          "Wavelet dilation factor and classic polynomial scale $a$",
          "$a \\in(0,2]$"
        ],
        [
          "Classic polynomial offset $b$",
          "$b \\in[0,5]$"
        ],
        [
          "Gegenbauer $a$",
          "$a \\in(-1,1]$"
        ],
        [
          "UMDA-Sample size $M$",
          "$25 \\%$ of the population"
        ]
      ],
      "row_count": 17,
      "column_count": 2
    },
    {
      "table_number": "VII",
      "table_title": "AVERAGE RANKS AND P-VALUES OF STATISTICAL TESTS ON THE NINE ALGORITHMS FOR KERNEL EVOLUTION",
      "headers": [
        "Test",
        "Friedman",
        "Aligned Friedman",
        "Quade"
      ],
      "rows": [
        [
          "Algorithm",
          "",
          "",
          ""
        ],
        [
          "GP_clas",
          8.033,
          106.033,
          8.092
        ],
        [
          "GP-U_clas",
          5.967,
          90.367,
          6.079
        ],
        [
          "GP-B_clas",
          6.267,
          92.8,
          6.317
        ],
        [
          "GP_mod",
          6.0,
          80.133,
          5.917
        ],
        [
          "GP-U_mod",
          4.067,
          55.267,
          3.838
        ],
        [
          "GP-B_mod",
          "$\\mathbf{2 . 4 0 0}$",
          32.533,
          "$\\mathbf{2 . 4 7 1}$"
        ],
        [
          "GP_all",
          5.833,
          78.033,
          5.829
        ],
        [
          "GP-U_all",
          3.7,
          45.267,
          3.892
        ],
        [
          "GP-B_all",
          2.733,
          "$\\mathbf{3 1 . 5 6 7}$",
          2.567
        ],
        [
          "p-value",
          "$\\mathbf{3 . 1 4 E - 0 9}$",
          0.093,
          "$\\mathbf{8 . 4 1 E - 0 9}$"
        ]
      ],
      "row_count": 11,
      "column_count": 4
    },
    {
      "table_number": "VIII",
      "table_title": "POST HOC TEST FOR THE CONTROL METHOD (GP-B_mod) SUGGESTED BY THE FRIEDMAN TEST. ALGORITHMS ARE SORTED p-VALUE",
      "headers": [
        "Algorithm",
        "Test Bonferroni - <br> Dunn",
        "Holm",
        "Holland",
        "Rom",
        "Finner"
      ],
      "rows": [
        [
          "GP_clas",
          0.0,
          0.0063,
          0.0064,
          0.0066,
          0.0064
        ],
        [
          "GP-B_clas",
          0.0001,
          0.0071,
          0.0073,
          0.0075,
          0.0127
        ],
        [
          "GP_mod",
          0.0003,
          0.0083,
          0.0085,
          0.0088,
          0.0191
        ],
        [
          "GP-U_clas",
          0.0004,
          0.01,
          0.0102,
          0.0105,
          0.0253
        ],
        [
          "GP_all",
          0.0006,
          0.0125,
          0.0127,
          0.0131,
          0.0315
        ],
        [
          "GP-U_mod",
          0.0956,
          0.0167,
          0.017,
          0.0167,
          0.0377
        ],
        [
          "GP-U_all",
          0.1936,
          0.025,
          0.0253,
          0.025,
          0.0439
        ],
        [
          "GP-B_all",
          0.7389,
          0.05,
          0.05,
          0.05,
          0.05
        ],
        [
          "p-threshold",
          0.0063,
          0.0167,
          0.017,
          0.0131,
          0.0377
        ]
      ],
      "row_count": 9,
      "column_count": 6
    },
    {
      "table_number": "IX",
      "table_title": "POST HOC TEST FOR THE CONTROL METHOD (GP-B_mod) SUGGESTED BY THE QUADE TEST. ALGORITHMS ARE SORTED p-VALUE",
      "headers": [
        "",
        "Test Bonferroni - <br> Dunn",
        "Holm",
        "Holland",
        "Rom",
        "Finner"
      ],
      "rows": [
        [
          "Algorithm",
          0.013,
          "$\\mathbf{0 . 0 0 6 3}$",
          "$\\mathbf{0 . 0 0 6 4}$",
          0.0066,
          "$\\mathbf{0 . 0 0 6 4}$"
        ],
        [
          "GP_clas",
          0.091,
          0.0071,
          0.0073,
          0.0075,
          0.0127
        ],
        [
          "GP-U_clas",
          0.112,
          0.0083,
          0.0085,
          0.0088,
          0.0191
        ],
        [
          "GP_mod",
          0.13,
          0.01,
          0.0102,
          0.0105,
          0.0253
        ],
        [
          "GP_all",
          0.14,
          0.0125,
          0.0127,
          0.0131,
          0.0315
        ],
        [
          "GP-U_all",
          0.532,
          0.0167,
          0.017,
          0.0167,
          0.0377
        ],
        [
          "GP-U_mod",
          0.548,
          0.025,
          0.0253,
          0.025,
          0.0439
        ],
        [
          "GP-B_all",
          0.966,
          0.05,
          0.05,
          0.05,
          0.05
        ],
        [
          "p-threshold",
          0.0063,
          0.0063,
          0.0063,
          0.0064,
          0.0064
        ]
      ],
      "row_count": 9,
      "column_count": 6
    },
    {
      "table_number": "X",
      "table_title": "RANKS AND $p$-VALUES OF STATISTICAL TESTS APPLIED TO THE ALGORITHMS FOR KERNEL EVOLUTION",
      "headers": [
        "",
        "Test",
        "Friedman",
        "Aligned Friedman",
        "Quade"
      ],
      "rows": [
        [
          "GP_clas",
          2.6,
          32.2,
          2.61,
          ""
        ],
        [
          "GP_mod",
          1.8,
          20.07,
          1.8,
          ""
        ],
        [
          "GP_all",
          "$\\mathbf{1 . 6 0}$",
          "$\\mathbf{1 6 . 7 3}$",
          "$\\mathbf{1 . 5 9}$",
          ""
        ],
        [
          "$p$-value",
          "$\\mathbf{0 . 0 1 4 9}$",
          "$\\mathbf{0 . 0 0 3 8}$",
          "$\\mathbf{0 . 0 2 7 4}$",
          ""
        ],
        [
          "GP-U_clas",
          2.33,
          32.1,
          2.58,
          ""
        ],
        [
          "GP-U_mod",
          1.93,
          19.87,
          1.78,
          ""
        ],
        [
          "GP-U_all",
          1.73,
          "$\\mathbf{1 7 . 0 3}$",
          "$\\mathbf{1 . 6 4}$",
          ""
        ],
        [
          "$p$-value",
          0.2465,
          "$\\mathbf{0 . 0 0 3 9}$",
          "$\\mathbf{0 . 0 4 4 8}$",
          ""
        ],
        [
          "GP-B_clas",
          2.8,
          35.63,
          2.84,
          ""
        ],
        [
          "GP-B_mod",
          "$\\mathbf{1 . 5 3}$",
          "$\\mathbf{1 6 . 5 7}$",
          "$\\mathbf{1 . 4 9}$",
          ""
        ],
        [
          "GP-B_all",
          1.67,
          16.8,
          1.67,
          ""
        ],
        [
          "$p$-value",
          "$\\mathbf{6 . 9 8 E - 0 4}$",
          "$\\mathbf{0 . 0 0 4 7}$",
          "$\\mathbf{5 . 2 1 E - 0 4}$",
          ""
        ]
      ],
      "row_count": 12,
      "column_count": 5
    },
    {
      "table_number": "XI",
      "table_title": "BONFERRONI-DUNN POST HOC TESTS TO DETERMINE WHICH TERMINAL SETS OF KERNELS ARE STATISTICALLY DIFFERENT.",
      "headers": [
        "Algorithm/Test",
        "Friedman",
        "Aligned Friedman",
        "Quade"
      ],
      "rows": [
        [
          "GP_clas",
          "$\\mathbf{0 . 0 0 6}$",
          "$\\mathbf{0 . 0 0 1}$",
          "$\\mathbf{0 . 0 1 3}$"
        ],
        [
          "GP_mod",
          0.584,
          0.487,
          0.608
        ],
        [
          "$p$-treshold",
          "$\\mathbf{0 . 0 2 5}$",
          "$\\mathbf{0 . 0 2 5}$",
          "$\\mathbf{0 . 0 2 5}$"
        ],
        [
          "GP-U_clas",
          "-",
          "$\\mathbf{0 . 0 0 1 7}$",
          "$\\mathbf{0 . 0 2 3}$"
        ],
        [
          "GP-U_mod",
          "-",
          0.554,
          0.725
        ],
        [
          "$p$-treshold",
          "",
          "$\\mathbf{0 . 0 2 5}$",
          "$\\mathbf{0 . 0 2 5}$"
        ],
        [
          "GP-B_clas",
          "$\\mathbf{5 . 2 3 E - 0 4}$",
          "$\\mathbf{7 . 0 2 E - 0 5}$",
          "$\\mathbf{0 . 0 0 1 1}$"
        ],
        [
          "GP-B_all",
          0.715,
          0.961,
          0.673
        ],
        [
          "$p$-treshold",
          "$\\mathbf{0 . 0 2 5}$",
          "$\\mathbf{0 . 0 2 5}$",
          "$\\mathbf{0 . 0 2 5}$"
        ]
      ],
      "row_count": 9,
      "column_count": 4
    },
    {
      "table_number": "XII",
      "table_title": "BEST KERNELS FOUND ON DIFFERENT RUNS OF THE EVOLUTIONARY METHODS REPORTED IN TABLE VI (HIGHLIGHTED IN GRAY). KERNEL EXPRESSIONS ARE FACTORED WHEN POSSIBLE",
      "headers": [
        "Dataset",
        "Acc.",
        "PSV",
        "Kernels with highest Acc.",
        "Run"
      ],
      "rows": [
        [
          "breast",
          97.81,
          0.254,
          "$W+K_{11}$",
          1
        ],
        [
          "",
          97.95,
          0.23,
          "$W+K_{11}+2 K_{13}$",
          2
        ],
        [
          "",
          97.95,
          0.287,
          "$W+K_{11}$",
          3
        ],
        [
          "chronic",
          100,
          0.091,
          "G",
          1
        ],
        [
          "",
          100,
          0.089,
          "H",
          2
        ],
        [
          "",
          100,
          0.089,
          "G",
          3
        ],
        [
          2,
          88.06,
          0.47,
          "H",
          1
        ],
        [
          "",
          87.42,
          0.346,
          "$G \\times H$",
          2
        ],
        [
          "",
          87.41,
          0.367,
          "$K_{11}+G$",
          3
        ],
        [
          "cryotherapy",
          97.78,
          0.23,
          "$(H \\times G)+L$",
          1
        ],
        [
          "",
          96.72,
          0.369,
          "$H+G$",
          2
        ],
        [
          "",
          97.78,
          0.328,
          "$(H \\times G)+H$",
          3
        ],
        [
          "diabetes",
          80.99,
          0.516,
          "H",
          1
        ],
        [
          "",
          80.46,
          0.551,
          "H",
          2
        ],
        [
          "",
          79.55,
          0.52,
          "H",
          3
        ],
        [
          "fertility",
          92.03,
          0.945,
          "$\\left(E \\times K_{13}\\right) \\times\\left(2+K_{13}\\right)$",
          1
        ],
        [
          "",
          91.03,
          0.364,
          "G",
          2
        ],
        [
          "",
          92.99,
          0.392,
          "$G+K_{11}$",
          3
        ],
        [
          "haberman",
          77.79,
          0.523,
          "$2 H^{2}+E$",
          1
        ],
        [
          "",
          78.11,
          0.522,
          "$E+H$",
          2
        ],
        [
          "",
          79.1,
          0.534,
          "$E+G$",
          3
        ],
        [
          "heart",
          86.67,
          0.498,
          "G",
          1
        ],
        [
          "",
          86.67,
          0.425,
          "H",
          2
        ],
        [
          "",
          86.67,
          0.487,
          "G",
          3
        ],
        [
          "immuno",
          88.82,
          0.417,
          "H",
          1
        ],
        [
          "",
          89.05,
          0.43,
          "$3 G$",
          2
        ],
        [
          "",
          88.99,
          0.491,
          "G",
          3
        ],
        [
          "liver",
          77.97,
          0.636,
          "$3 H+2 G+L$",
          1
        ],
        [
          "",
          73.91,
          0.745,
          "$E+H$",
          2
        ],
        [
          "",
          76.52,
          0.631,
          "$H \\times(2 L+2 H)$",
          3
        ],
        [
          "mammo",
          83.36,
          0.433,
          "$L+H$",
          1
        ],
        [
          "",
          83.15,
          0.418,
          "$L \\times L$",
          2
        ],
        [
          "",
          83.98,
          0.391,
          "G",
          3
        ],
        [
          "parkinsons",
          96.93,
          0.461,
          "$W+\\left(K_{11} \\times L\\right)$",
          1
        ],
        [
          "",
          97.44,
          0.501,
          "$K_{11} \\times(2 L+3 R+P)$",
          2
        ],
        [
          "",
          96.42,
          0.495,
          "$R+W$",
          3
        ],
        [
          "thoracic",
          87.66,
          0.394,
          "H",
          1
        ],
        [
          "",
          87.45,
          0.419,
          "H",
          2
        ],
        [
          "",
          87.23,
          0.415,
          "H",
          3
        ],
        [
          "transfusion",
          80.08,
          0.484,
          "$R^{2} \\times H$",
          1
        ],
        [
          "",
          81.02,
          0.476,
          "$L \\times R \\times G$",
          2
        ],
        [
          "",
          80.74,
          0.478,
          "$L+L \\times(H+R)^{2}$",
          3
        ],
        [
          "wpbc",
          82.52,
          0.66,
          "$L \\times(R+L)^{2}+L^{2} \\times(R+L)$",
          1
        ],
        [
          "",
          83.52,
          0.838,
          "$R \\times(L+P)+L$",
          2
        ],
        [
          "",
          84.03,
          0.628,
          "$6 R+L$",
          3
        ]
      ],
      "row_count": 45,
      "column_count": 5
    },
    {
      "table_number": "XIII",
      "table_title": "EVOLVED KERNEL SELECTION BY THE HIGHEST COMBINED INDEX OF ACCURACY AND PSV",
      "headers": [
        "dataset",
        "Previous Works Acc. ${ }^{\\text {MV }}$",
        "",
        "Acc.",
        "PSV",
        "$\\begin{gathered} 100 \\times \\\\ \\text { Cmbldx } \\end{gathered}$",
        "G_mean",
        "Time (ms)",
        "Kernel",
        "Hyper-parameters"
      ],
      "rows": [
        [
          "breast",
          98.031,
          "--- 1",
          97.22,
          0.087,
          98.27,
          97.07,
          28,
          "$G+G$",
          "$C=23.06, \\alpha=-0.041, n=1$"
        ],
        [
          "chronic",
          "$99.57^{2}$",
          "$0.135^{2}$",
          99.75,
          0.079,
          99.14,
          99.8,
          28,
          "H",
          "$C=08.29, n=3$"
        ],
        [
          2,
          "$86.02^{2}$",
          "$0.416^{2}$",
          87.42,
          0.346,
          78.09,
          90.53,
          70,
          "$G \\times H$",
          "$C=31.15, \\alpha=-0.057, n=3$"
        ],
        [
          "cryotherapy",
          "$91.00^{3}$",
          "--- 3",
          97.78,
          0.197,
          97.05,
          98.97,
          6,
          "$3 G+L+H$",
          "$C=16.45, \\alpha=-0.065, n=2$"
        ],
        [
          "diabetes",
          81.001,
          "--- 1",
          80.99,
          0.517,
          54.17,
          74.71,
          56,
          "H",
          "$C=19.76, n=2$"
        ],
        [
          "fertility",
          "$89.19^{2}$",
          "$0.943^{2}$",
          92.99,
          0.383,
          88.07,
          56.16,
          16,
          "$G+K_{13}$",
          "$C=03.99, \\alpha=0.217, n=6, \\tau=4.759$"
        ],
        [
          "haberman",
          "$75.77^{4}$",
          "--- 4",
          79.1,
          0.534,
          48.34,
          "$0^{1}$",
          78,
          "$G+E$",
          "$C=28.23, \\alpha=0.402, n=2$"
        ],
        [
          "heart",
          "$84.67^{2}$",
          "$0.459^{2}$",
          86.67,
          0.425,
          73.27,
          86.31,
          7878,
          "H",
          "$C=13.29, n=6$"
        ],
        [
          "immuno",
          "$88.00^{3}$",
          "--- 5",
          89.06,
          0.411,
          79.43,
          97.14,
          28,
          "$3 G$",
          "$C=17.97, \\alpha=0.031, n=5$"
        ],
        [
          "liver",
          "$74.15^{2}$",
          "$0.712^{2}$",
          77.97,
          0.636,
          39.07,
          "$0^{1}$",
          249,
          "$3 H+2 G+L$",
          "$C=25.38, \\alpha=0.429, n=1$"
        ],
        [
          "mammo",
          86.444,
          "--- 4",
          83.97,
          0.392,
          68.03,
          91.65,
          846,
          "G",
          "$C=26.77, \\alpha=-0.102, n=5$"
        ],
        [
          "parkinsons",
          "$95.98^{2}$",
          "$0.561^{2}$",
          96.42,
          0.353,
          93.21,
          94.02,
          8,
          "$L+R$",
          "$C=19.30, \\gamma=1.403$"
        ],
        [
          "thoracic",
          "$85.15^{2}$",
          "$0.588^{2}$",
          87.23,
          0.337,
          77.97,
          20,
          11350,
          "H",
          "$C=04.43, n=6$"
        ],
        [
          "transfusion",
          80.534,
          "--- 9",
          80.22,
          0.431,
          56.76,
          49.26,
          322,
          "$G^{2} \\times R \\times L$",
          "$C=25.93, \\alpha=0.464, n=1, \\gamma=2.234$"
        ],
        [
          "wphe",
          "$81.22^{4}$",
          "--- 4",
          81.38,
          0.42,
          60.22,
          67.04,
          14,
          "$L$",
          "$C=16.28$"
        ],
        [
          "${ }^{1}$ Genetic Programing for kernel Evolution and hyper-parameter tuning of SVMs with classic kernels, PSV was not reported [18]. ${ }^{2}$ SVMs hyper-parameter tuning by BUMDA [27]. ${ }^{3}$ Grid Search for hyper-parameter tuning of the RBF kernel function, PSV was not reported [50]. ${ }^{4}$ The Particle Swarm Optimization (PSO) was applied to optimize the RBF kernel hyper-parameters, PSV was not reported [52]. ${ }^{5} \\mathrm{~A}$ zero value in the G -mean index in combination with high accuracy indicates that all test data were assigned to the majority class.",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ]
      ],
      "row_count": 16,
      "column_count": 10
    },
    {
      "table_number": "XIV",
      "table_title": "TIME COMPLEXITY OF SEEKS AND ITS BASE TECHNIQUES",
      "headers": [
        "Algorithm",
        "Time Complexity by steps: $\\mathbf{A}+\\mathbf{B}+\\mathbf{C}+\\mathbf{D}$"
      ],
      "rows": [
        [
          "BUMDA",
          "$\\begin{gathered} O\\left(p N^{3}\\right)+O(p \\log p)+0+G\\left[O\\left(p N^{3}\\right)+\\right. \\\\ O(p \\log (p))] \\end{gathered}$"
        ],
        [
          "UMDA",
          "$\\begin{gathered} O\\left(p N^{3}\\right)+O(p \\log p)+0+G\\left[O\\left(p N^{3}\\right)+\\right. \\\\ O(p \\log (p))] \\end{gathered}$"
        ],
        [
          "GP",
          "$\\begin{gathered} O\\left(p N^{3}\\right)+O(p \\log p)+O(p m G)+G\\left[O\\left(p N^{3}\\right)+\\right. \\\\ O(p \\log (p))] \\end{gathered}$"
        ],
        [
          "SEEKS",
          "$\\begin{gathered} O\\left(p N^{3}\\right)+O(p \\log p)+O(p m G)+G\\left[O\\left(p N^{3}\\right)+\\right. \\\\ O(p \\log (p))]+O(d p) \\end{gathered}$"
        ]
      ],
      "row_count": 4,
      "column_count": 2
    }
  ]
}