{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2021/Random mask-based estimation of the distribution algorithm for stacked auto-encoder one-step pre-training.md",
    "filename": "Random mask-based estimation of the distribution algorithm for stacked auto-encoder one-step pre-training.md",
    "title": "Random mask-based estimation of the distribution algorithm for stacked auto-encoder one-step pre-training",
    "year": "2021"
  },
  "references": {
    "header": "## References",
    "content": "LeCun, Y., Bengio, Y., \\& Hinton, G. (2015). Deep learning. Nature, 521, 436-444.\nKuremoto, T., Kimura, S., Kobayashi, K., \\& Ohayashi, M. (2014). Time series forecasting using a deep belief network with restricted Boltzmann machines. Neurocomputing, 137, 47-56.\nWang, S., Er, M. J., \\& Han, M. (2017). Generalized single-hidden layer feedforward networks for regression problems. IEEE Transactions on Neural Networks \\& Learning Systems, 26, 1161-1176.\nMartin, A., Lara-Cabrera, R., Fuentes-Hurtado, F., Naranjo, V., \\& Camacho, D. (2018). Evolbeep: A new evolutionary approach for automatic Deep Neural Networks parametrisation. Journal of Parallel and Diarrhoeal Computing, 117, 180-191.\nYe, F. (2017). Particle swarm optimization-based automatic parameter selection for deep neural networks and its applications in large-scale and high-dimensional data. PLoS ONE, 12, Article e0188746.\nHinton, G. E., \\& Salakhutdinov, R. R. (2006). Reducing the dimensionality of data with neural networks. Science, 313, 504-507.\nHins, T., Navarroguerrero, N., Magg, S., \\& Wremter, K. (2018). Speeding up the Hyperparameter Optimization of Deep Convolutional Neural Networks. International Journal of Computational Intelligence \\& Applications, 17, 1850008.\nAssunção, F., Laurenço, N., Machado, P., \\& Ribeiro, B. (2019). DENSEB: Deep evolutionary network structured representation. Genetic Programming and Evolvable Machines, 20, 5-35.\nJunior, P. E. F., \\& Yen, G. G. (2019). Particle swarm optimization of deep neural networks architectures for image classification. Swarm and Evolutionary Computation, 49, 62-74.\nBergstra, J., \\& Bengio, Y. (2012). Random search for hyper-parameter optimization. The Journal of Machine Learning Research, 13, 281-305.\nSun, Y., Yen, G. G., \\& Yi, Z. (2019). Evolving Unsupervised Deep Neural Networks for Learning Meaningful Representations. IEEE Transactions on Evolutionary Computation, 23, 89-103.\nZheng, Y., Cheng, S., Shi, Y., Gong, D., \\& Zhao, S. (2019). Cost-sensitive feature selection using two-archive multi-objective artificial bee colony algorithm. Expert Systems with Applications, 137, 46-58.\n2020K. Li, T. Zhang, R. Wang, Deep Reinforcement Learning for Multi-objective Optimization, IEEE T CYBERNETICS, (2020) In Press.\nMa, L., Cheng, S., \\& Shi, Y. (2020). Enhancing Learning Efficiency of Brain Storm Optimization via Orthogonal Learning Design. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 1-20.\nGuo, Y., Zhang, S., Gong, D., Zhang, Z., \\& Yang, J. (2020). Novel Interactive Preference-Based Multiobjective Evolutionary Optimization for Bolt Supporting Networks. IEEE Transactions on Evolutionary Computation, 24, 750-764.\nOong, T. H., \\& Isa, N. A. M. (2011). Adaptive Evolutionary Artificial Neural Networks for Pattern Classification. IEEE Transactions on Neural Networks, 22, 1823-1836.\nAl-Dabbagh, R. D., Mekhdef, S., \\& Baba, M. S. (2015). Parameters' fine tuning of differential evolution algorithm. The Computer Systems Science and Engineering, 30, $125-139$.\nAl-Dabbagh, M. D., Al-Dabbagh, R. D., Abdullah, R. S. A. R., \\& Hashim, F. (2015). A new modified differential evolution algorithm scheme-based linear frequency modulation radar signal de-noising. Optimization and Engineering, 47, 771-787.\nYao, X., \\& Liu, Y. (1997). A new evolutionary system for evolving artificial neural networks. IEEE Transactions on Neural Networks, 8, 694-713.\nHussain, K., Salleh, M. N. M., Cheng, S., \\& Shi, Y. (2019). Metabeuristic research: A comprehensive survey. Artificial Intelligence Review, 52, 2191-2233.\nLv, B., Yang, B., Zhu, X., \\& Li, J. (2019). Operational optimization of transit consolidation in multimodal transport. Computers and Industrial Engineering, 129, 454-464,\nHu, B., \\& Yang, B. (2019). A particle swarm optimization algorithm for multi-row facility layout problem in semiconductor fabrication. Journal of Ambient Intelligence and Humanized Computing, 10, 3201-3210.\nWu, D., Liao, Y., Hu, C., Yu, S., Tian, Q. (2020). An Enhanced Fuzzy Control Strategy for Low-Level Thrusters in Marine Dynamic Positioning Systems Based on Chaotic Random Distribution Harmony Search. The International Journal of Fuzzy Systems. Wu, D., Ren, F., \\& Zhang, W. (2016). An energy optimal thrust allocation method for the marine Dynamic positioning system based on adaptive hybrid artificial bee colony algorithm. Ocean Engineering, 118, 216-226.\nWu, D., Liu, X., Ren, F., \\& Yin, Z. (2016). An Improved Thrust Allocation Method for Marine Dynamic Positioning System. Naval Engineers Journal, 129, 89-98.\nWu, D., Ren, F., Qiao, L., \\& Zhang, W. (2018). Active disturbance rejection controller design for dynamically positioned vessels based on adaptive hybrid biogeographybased optimization and differential evolution. ISA 7, 78, 56-65.\nCheng, S., Ma, L., Lu, H., Lei, X., Shi, Y. (2020). Evolutionary computation for solving search-based data analytics problems. Artificial Intelligence Review.\nStanley, K. O., \\& Mikkalainen, R. (2002). Evolving neural networks through augmenting topologies. Evolutionary Computation, 10, 99-127.\nSnoek, J., Larochelle, H., Adams, R. P. (2012). Practical Bayesian Optimization of Machine Learning Algorithms, Proceedings of the 25th International Conference on Neural Information Processing Systems, USA, pp. 2951-2959.\nBelin, I., Zoph, B., Vansdevan, V., \\& Le, Q. V. (2017). Neural Optimizer Search with Reinforcement Learning, Proceedings of Machine Learning Research (pp. 459-468). Sydney, Australia: International Convention Centre.\nZoph, B., Vansdevan, V., Shlens, J., \\& Le, Q. V. (2018). Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on computer Vision and pattern recognition (pp. 8697-8710).\nZhong, Z., Yan, J., Wu, W., Shao, J., Liu, C. (2018). Practical block-wise neural network architecture generation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, USA, pp. 2423-2432.\nReal, E., Moore, S., Selle, A., Saxena, S., Surmatou, Y.L., Tan, J., Le, Q.V., Kurakin, A. (2017). Large-Scale Evolution of Image Classifiers, Proceedings of Machine Learning Research, Sydney, Australia, 2017, pp. 2902-2911.\nXie, S., Zheng, H., Liu, C., Lin, L., SNAS: stochastic neural architecture search, Proceedings of the International Conference on Learning Representations, New Orleans, Louisiana, USA, 2018.\nCai, H., Zhu, L., Han, S. (2018). Proxylessnas: Direct neural architecture search on target task and hardware, Proceedings of the International Conference on Learning Representations, New Orleans, Louisiana, USA, 2018.\nZhang, C., Ren, M., Urtasun, R. (2018). Graph hypernetworks for neural architecture search, Proceedings of the International Conference on Learning Representations, New Orleans, Louisiana, USA, 2018.\nSun, Y., Xue, B., Zhang, M., \\& Yen, G. G. (2020). Evolving Deep Convolutional Neural Networks for Image Classification. IEEE Transactions on Evolutionary Computation, 24, $394-407$.\nXu, Z., Dai, L., Kemp, A.M., Metz, J. (2019). Learning an Adaptive Learning Rate Schedule, arXiv preprint, (2019) arXiv:1909.09712.\nLopez-Rizoco, A., Tonda, A., Elati, M., Schwander, O., Piwowarski, B., \\& Gallinari, P. (2018). Evolutionary optimization of convolutional neural networks for cancer miRNA biomarkers classification. Applied Soft Computing, 65, 91-100.\nBaldominos, A., Saez, Y., \\& Isasi, P. (2018). Evolutionary convolutional neural networks: An application to handwriting recognition. Neurocomputing, 283, 38-52.\nMinhienbein, H., \\& Paali, G. (1996). In From Recombination of Genes to the Estimation of Distributions I. Binary Parameters (pp. 178-187). London, UK: Springer-Verlag.\nDong, W., Chen, T., Tiao, P., \\& Yao, X. (2013). Scaling Up Estimation of Distribution Algorithms for Continuous Optimization. IEEE Transactions on Evolutionary Computation, 17, 797-822.\nSun, B. Q., Wang, L., \\& Peng, Z. P. (2020). Bound-guided hybrid estimation of distribution algorithm for energy-efficient robotic assembly line balancing. Computers \\& Industrial Engineering, 146.\nWang, H., Chien, C., \\& Gen, M. (2015). An Algorithm of Multi-Subpopulation Parameters With Hybrid Estimation of Distribution for Semiconductor Scheduling With Constrained Waiting Time. IEEE Transactions on Semiconductor Manufacturing, 28, 353-366.\nPérez-Rodríguez, R., \\& Hernández-Aguirre, A. (2019). A hybrid estimation of distribution algorithm for the vehicle routing problem with time windows. Computers \\& Industrial Engineering, 130, 75-96.\nArin, A., \\& Rabadi, G. (2017). Integrating estimation of distribution algorithms versus Qlearning into Meta-RaPS for solving the $0-1$ multidimensional knapsack problem. Computers \\& Industrial Engineering, 112, 706-720.\nWang, L., Wang, S., Xu, Y., Zhou, G., \\& Liu, M. (2012). A bi-population based estimation of distribution algorithm for the flexible job-shop scheduling problem. Computers \\& Industrial Engineering, 62, 917-926.\nChen, T., Tang, K., Chen, G., \\& Yao, X. (2010). Analysis of Computational Time of Simple Estimation of Distribution Algorithms. IEEE T EVO217 COMPUT, 14, 1-22.\nMishra, K. M., \\& Gallagher, M. (2014). A Modified Screening Estimation of Distribution Algorithm for Large-Scale Continuous Optimization, Asia-Pacific Conference on (pp. 119-130). Dunedin, New Zealand: Simulated Evolution and Learning.\nHansen, N., \\& Ostermeier, A. (2001). Completely Derandomized Self-Adaptation in Evolution Strategies. Evolutionary Computation, 9, 159-195.\nWang, Y., Li, R. (2008). A restart univariate estimation of distribution algorithm: sampling under mixed Gaussian and Lévy probability distribution, 2008 IEEE Congress on Evolutionary Computation, Hong Kong, China, 2008, pp. 3917-3924.\nBielau, C., Robins, V., \\& Lortanuga, P. (2009). Estimation of distribution algorithms as logistic regression regularizers of microarray classifiers. Methods of Information in Medicine, 48, 236-241.\n\nKarshenas, H., Santana, R., Bielza, C., \\& Larrañaga, P. (2013). Regularized continuous estimation of distribution algorithms. Applied Soft Computing Journal, 13, $2412-2432$.\nBosman, P.A.N. (2009). On Empirical Memory Design, Faster Selection of Bayesian Factorizations and Parameter-free Gaussian EDAs, Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation, New York, NY, USA, 2009, pp. 389-396.\nKahan, A., Boetkrajang, J., \\& Durrant, R. J. (2016). Toward Large-Scale Continuous EDA: A Random Matrix Theory Perspective. Evolutionary Computation, 24, 255-291.\nOmidvar, M. N., Yang, M., Mei, Y., Li, X., \\& Yao, X. (2017). DG2: A Faster and More Accurate Differential Grouping for Large-Scale Black-Box Optimization. IEEE Transactions on Evolutionary Computation, 21, 929-942,\nHauschild, M., \\& Pelikan, M. (2011). An introduction and survey of estimation of distribution algorithms. Swarm and Evolutionary Computation, 1, 111-128.\nLi, H., Hong, Y., Kwong, S., Ren, Q., \\& Wang, W. (2012). Enhancement of continuous estimation of distribution algorithms by density ensembles. Engineering Optimization, 44, 1303-1320.\nAhmed, A., Khan, Q., Naeem, M., Iqbal, M., Anpalagan, A., \\& Awais, M. (2018). An insight to the performance of estimation of distribution algorithm for multiple line outage identification. Swarm and Evolutionary Computation, 39, 114-122.\nLu, H., Zhou, R., Cheng, S., \\& Shi, Y. (2019). Multi-center variable-scale search algorithm for combinatorial optimization problems with the multimodal property. Applied Soft Computing, 84, Article 105726.\n\nSrivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., \\& Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15, 1929-1958.\nAhn, C. W., \\& Ramakrishna, R. S. (2003). Elitism-based compact genetic algorithms. IEEE Transactions on Evolutionary Computation, 7, 367-385.\nPurshouse, R. C., Fleming, P. J. (2002). Why use elitism and sharing in a multi-objective genetic algorithm, Proceedings of the Genetic and Evolutionary Computation Conference, New York, USA, 2002, pp. 520-527.\nGao, S., \\& de Silva, C. W. (2018). Estimation distribution algorithms on constrained optimization problems. Applied Mathematics and Computation, 339, 323-345.\nRumelhart, D. E., Hinton, G. E., \\& Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323, 533-536.\nXiao, H., Raoul, K., Vollgraf, R. (2017). Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, arXiv, (2017) arXiv/1708.07747.\nLedesma, L., Olveres, J., Escalante-Ram I Rez, B. (2019). Hermite Convolutional Networks, Iberoamerican Congress on Pattern Recognition, Springer, Havana, Cuba, 2019, pp. 398-407.\nSabour, S., Frost, N., \\& Hinton, G. E. (2017). Dynamic Routing Between Capsules, Advances in Neural Information Processing Systems 30 (pp. 3856-3866). Currar Associates: Inc, Zhang, X., Sun, Y., Wang, Y., Li, Z., Li, N., \\& Su, J. (2019). A novel effective and efficient capsule network via bottleneck residual block and automated gradual pruning. Computers A Electrical Engineering, 80, Article 106481.\nChollet, F. (2017). Xception: Deep learning with depthwise separable convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition, Honolulu, Hawaii, USA, 2017, pp. 1251-1258.",
    "references": [
      {
        "ref_id": "1",
        "text": "LeCun, Y., Bengio, Y., \\& Hinton, G. (2015). Deep learning. Nature, 521, 436-444."
      },
      {
        "ref_id": "2",
        "text": "Kuremoto, T., Kimura, S., Kobayashi, K., \\& Ohayashi, M. (2014). Time series forecasting using a deep belief network with restricted Boltzmann machines. Neurocomputing, 137, 47-56."
      },
      {
        "ref_id": "3",
        "text": "Wang, S., Er, M. J., \\& Han, M. (2017). Generalized single-hidden layer feedforward networks for regression problems. IEEE Transactions on Neural Networks \\& Learning Systems, 26, 1161-1176."
      },
      {
        "ref_id": "4",
        "text": "Martin, A., Lara-Cabrera, R., Fuentes-Hurtado, F., Naranjo, V., \\& Camacho, D. (2018). Evolbeep: A new evolutionary approach for automatic Deep Neural Networks parametrisation. Journal of Parallel and Diarrhoeal Computing, 117, 180-191."
      },
      {
        "ref_id": "5",
        "text": "Ye, F. (2017). Particle swarm optimization-based automatic parameter selection for deep neural networks and its applications in large-scale and high-dimensional data. PLoS ONE, 12, Article e0188746."
      },
      {
        "ref_id": "6",
        "text": "Hinton, G. E., \\& Salakhutdinov, R. R. (2006). Reducing the dimensionality of data with neural networks. Science, 313, 504-507."
      },
      {
        "ref_id": "7",
        "text": "Hins, T., Navarroguerrero, N., Magg, S., \\& Wremter, K. (2018). Speeding up the Hyperparameter Optimization of Deep Convolutional Neural Networks. International Journal of Computational Intelligence \\& Applications, 17, 1850008."
      },
      {
        "ref_id": "8",
        "text": "Assunção, F., Laurenço, N., Machado, P., \\& Ribeiro, B. (2019). DENSEB: Deep evolutionary network structured representation. Genetic Programming and Evolvable Machines, 20, 5-35."
      },
      {
        "ref_id": "9",
        "text": "Junior, P. E. F., \\& Yen, G. G. (2019). Particle swarm optimization of deep neural networks architectures for image classification. Swarm and Evolutionary Computation, 49, 62-74."
      },
      {
        "ref_id": "10",
        "text": "Bergstra, J., \\& Bengio, Y. (2012). Random search for hyper-parameter optimization. The Journal of Machine Learning Research, 13, 281-305."
      },
      {
        "ref_id": "11",
        "text": "Sun, Y., Yen, G. G., \\& Yi, Z. (2019). Evolving Unsupervised Deep Neural Networks for Learning Meaningful Representations. IEEE Transactions on Evolutionary Computation, 23, 89-103."
      },
      {
        "ref_id": "12",
        "text": "Zheng, Y., Cheng, S., Shi, Y., Gong, D., \\& Zhao, S. (2019). Cost-sensitive feature selection using two-archive multi-objective artificial bee colony algorithm. Expert Systems with Applications, 137, 46-58."
      },
      {
        "ref_id": "13",
        "text": "Ma, L., Cheng, S., \\& Shi, Y. (2020). Enhancing Learning Efficiency of Brain Storm Optimization via Orthogonal Learning Design. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 1-20."
      },
      {
        "ref_id": "14",
        "text": "Guo, Y., Zhang, S., Gong, D., Zhang, Z., \\& Yang, J. (2020). Novel Interactive Preference-Based Multiobjective Evolutionary Optimization for Bolt Supporting Networks. IEEE Transactions on Evolutionary Computation, 24, 750-764."
      },
      {
        "ref_id": "15",
        "text": "Oong, T. H., \\& Isa, N. A. M. (2011). Adaptive Evolutionary Artificial Neural Networks for Pattern Classification. IEEE Transactions on Neural Networks, 22, 1823-1836."
      },
      {
        "ref_id": "16",
        "text": "Al-Dabbagh, R. D., Mekhdef, S., \\& Baba, M. S. (2015). Parameters' fine tuning of differential evolution algorithm. The Computer Systems Science and Engineering, 30, $125-139$."
      },
      {
        "ref_id": "17",
        "text": "Al-Dabbagh, M. D., Al-Dabbagh, R. D., Abdullah, R. S. A. R., \\& Hashim, F. (2015). A new modified differential evolution algorithm scheme-based linear frequency modulation radar signal de-noising. Optimization and Engineering, 47, 771-787."
      },
      {
        "ref_id": "18",
        "text": "Yao, X., \\& Liu, Y. (1997). A new evolutionary system for evolving artificial neural networks. IEEE Transactions on Neural Networks, 8, 694-713."
      },
      {
        "ref_id": "19",
        "text": "Hussain, K., Salleh, M. N. M., Cheng, S., \\& Shi, Y. (2019). Metabeuristic research: A comprehensive survey. Artificial Intelligence Review, 52, 2191-2233."
      },
      {
        "ref_id": "20",
        "text": "Lv, B., Yang, B., Zhu, X., \\& Li, J. (2019). Operational optimization of transit consolidation in multimodal transport. Computers and Industrial Engineering, 129, 454-464,"
      },
      {
        "ref_id": "21",
        "text": "Hu, B., \\& Yang, B. (2019). A particle swarm optimization algorithm for multi-row facility layout problem in semiconductor fabrication. Journal of Ambient Intelligence and Humanized Computing, 10, 3201-3210."
      },
      {
        "ref_id": "22",
        "text": "Wu, D., Liao, Y., Hu, C., Yu, S., Tian, Q. (2020). An Enhanced Fuzzy Control Strategy for Low-Level Thrusters in Marine Dynamic Positioning Systems Based on Chaotic Random Distribution Harmony Search. The International Journal of Fuzzy Systems. Wu, D., Ren, F., \\& Zhang, W. (2016). An energy optimal thrust allocation method for the marine Dynamic positioning system based on adaptive hybrid artificial bee colony algorithm. Ocean Engineering, 118, 216-226."
      },
      {
        "ref_id": "23",
        "text": "Wu, D., Liu, X., Ren, F., \\& Yin, Z. (2016). An Improved Thrust Allocation Method for Marine Dynamic Positioning System. Naval Engineers Journal, 129, 89-98."
      },
      {
        "ref_id": "24",
        "text": "Wu, D., Ren, F., Qiao, L., \\& Zhang, W. (2018). Active disturbance rejection controller design for dynamically positioned vessels based on adaptive hybrid biogeographybased optimization and differential evolution. ISA 7, 78, 56-65."
      },
      {
        "ref_id": "25",
        "text": "Cheng, S., Ma, L., Lu, H., Lei, X., Shi, Y. (2020). Evolutionary computation for solving search-based data analytics problems. Artificial Intelligence Review."
      },
      {
        "ref_id": "26",
        "text": "Stanley, K. O., \\& Mikkalainen, R. (2002). Evolving neural networks through augmenting topologies. Evolutionary Computation, 10, 99-127."
      },
      {
        "ref_id": "27",
        "text": "Snoek, J., Larochelle, H., Adams, R. P. (2012). Practical Bayesian Optimization of Machine Learning Algorithms, Proceedings of the 25th International Conference on Neural Information Processing Systems, USA, pp. 2951-2959."
      },
      {
        "ref_id": "28",
        "text": "Belin, I., Zoph, B., Vansdevan, V., \\& Le, Q. V. (2017). Neural Optimizer Search with Reinforcement Learning, Proceedings of Machine Learning Research (pp. 459-468). Sydney, Australia: International Convention Centre."
      },
      {
        "ref_id": "29",
        "text": "Zoph, B., Vansdevan, V., Shlens, J., \\& Le, Q. V. (2018). Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on computer Vision and pattern recognition (pp. 8697-8710)."
      },
      {
        "ref_id": "30",
        "text": "Zhong, Z., Yan, J., Wu, W., Shao, J., Liu, C. (2018). Practical block-wise neural network architecture generation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, USA, pp. 2423-2432."
      },
      {
        "ref_id": "31",
        "text": "Real, E., Moore, S., Selle, A., Saxena, S., Surmatou, Y.L., Tan, J., Le, Q.V., Kurakin, A. (2017). Large-Scale Evolution of Image Classifiers, Proceedings of Machine Learning Research, Sydney, Australia, 2017, pp. 2902-2911."
      },
      {
        "ref_id": "32",
        "text": "Xie, S., Zheng, H., Liu, C., Lin, L., SNAS: stochastic neural architecture search, Proceedings of the International Conference on Learning Representations, New Orleans, Louisiana, USA, 2018."
      },
      {
        "ref_id": "33",
        "text": "Cai, H., Zhu, L., Han, S. (2018). Proxylessnas: Direct neural architecture search on target task and hardware, Proceedings of the International Conference on Learning Representations, New Orleans, Louisiana, USA, 2018."
      },
      {
        "ref_id": "34",
        "text": "Zhang, C., Ren, M., Urtasun, R. (2018). Graph hypernetworks for neural architecture search, Proceedings of the International Conference on Learning Representations, New Orleans, Louisiana, USA, 2018."
      },
      {
        "ref_id": "35",
        "text": "Sun, Y., Xue, B., Zhang, M., \\& Yen, G. G. (2020). Evolving Deep Convolutional Neural Networks for Image Classification. IEEE Transactions on Evolutionary Computation, 24, $394-407$."
      },
      {
        "ref_id": "36",
        "text": "Xu, Z., Dai, L., Kemp, A.M., Metz, J. (2019). Learning an Adaptive Learning Rate Schedule, arXiv preprint, (2019) arXiv:1909.09712."
      },
      {
        "ref_id": "37",
        "text": "Lopez-Rizoco, A., Tonda, A., Elati, M., Schwander, O., Piwowarski, B., \\& Gallinari, P. (2018). Evolutionary optimization of convolutional neural networks for cancer miRNA biomarkers classification. Applied Soft Computing, 65, 91-100."
      },
      {
        "ref_id": "38",
        "text": "Baldominos, A., Saez, Y., \\& Isasi, P. (2018). Evolutionary convolutional neural networks: An application to handwriting recognition. Neurocomputing, 283, 38-52."
      },
      {
        "ref_id": "39",
        "text": "Minhienbein, H., \\& Paali, G. (1996). In From Recombination of Genes to the Estimation of Distributions I. Binary Parameters (pp. 178-187). London, UK: Springer-Verlag."
      },
      {
        "ref_id": "40",
        "text": "Dong, W., Chen, T., Tiao, P., \\& Yao, X. (2013). Scaling Up Estimation of Distribution Algorithms for Continuous Optimization. IEEE Transactions on Evolutionary Computation, 17, 797-822."
      },
      {
        "ref_id": "41",
        "text": "Sun, B. Q., Wang, L., \\& Peng, Z. P. (2020). Bound-guided hybrid estimation of distribution algorithm for energy-efficient robotic assembly line balancing. Computers \\& Industrial Engineering, 146."
      },
      {
        "ref_id": "42",
        "text": "Wang, H., Chien, C., \\& Gen, M. (2015). An Algorithm of Multi-Subpopulation Parameters With Hybrid Estimation of Distribution for Semiconductor Scheduling With Constrained Waiting Time. IEEE Transactions on Semiconductor Manufacturing, 28, 353-366."
      },
      {
        "ref_id": "43",
        "text": "Pérez-Rodríguez, R., \\& Hernández-Aguirre, A. (2019). A hybrid estimation of distribution algorithm for the vehicle routing problem with time windows. Computers \\& Industrial Engineering, 130, 75-96."
      },
      {
        "ref_id": "44",
        "text": "Arin, A., \\& Rabadi, G. (2017). Integrating estimation of distribution algorithms versus Qlearning into Meta-RaPS for solving the $0-1$ multidimensional knapsack problem. Computers \\& Industrial Engineering, 112, 706-720."
      },
      {
        "ref_id": "45",
        "text": "Wang, L., Wang, S., Xu, Y., Zhou, G., \\& Liu, M. (2012). A bi-population based estimation of distribution algorithm for the flexible job-shop scheduling problem. Computers \\& Industrial Engineering, 62, 917-926."
      },
      {
        "ref_id": "46",
        "text": "Chen, T., Tang, K., Chen, G., \\& Yao, X. (2010). Analysis of Computational Time of Simple Estimation of Distribution Algorithms. IEEE T EVO217 COMPUT, 14, 1-22."
      },
      {
        "ref_id": "47",
        "text": "Mishra, K. M., \\& Gallagher, M. (2014). A Modified Screening Estimation of Distribution Algorithm for Large-Scale Continuous Optimization, Asia-Pacific Conference on (pp. 119-130). Dunedin, New Zealand: Simulated Evolution and Learning."
      },
      {
        "ref_id": "48",
        "text": "Hansen, N., \\& Ostermeier, A. (2001). Completely Derandomized Self-Adaptation in Evolution Strategies. Evolutionary Computation, 9, 159-195."
      },
      {
        "ref_id": "49",
        "text": "Wang, Y., Li, R. (2008). A restart univariate estimation of distribution algorithm: sampling under mixed Gaussian and Lévy probability distribution, 2008 IEEE Congress on Evolutionary Computation, Hong Kong, China, 2008, pp. 3917-3924."
      },
      {
        "ref_id": "50",
        "text": "Bielau, C., Robins, V., \\& Lortanuga, P. (2009). Estimation of distribution algorithms as logistic regression regularizers of microarray classifiers. Methods of Information in Medicine, 48, 236-241."
      },
      {
        "ref_id": "51",
        "text": "Karshenas, H., Santana, R., Bielza, C., \\& Larrañaga, P. (2013). Regularized continuous estimation of distribution algorithms. Applied Soft Computing Journal, 13, $2412-2432$."
      },
      {
        "ref_id": "52",
        "text": "Bosman, P.A.N. (2009). On Empirical Memory Design, Faster Selection of Bayesian Factorizations and Parameter-free Gaussian EDAs, Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation, New York, NY, USA, 2009, pp. 389-396."
      },
      {
        "ref_id": "53",
        "text": "Kahan, A., Boetkrajang, J., \\& Durrant, R. J. (2016). Toward Large-Scale Continuous EDA: A Random Matrix Theory Perspective. Evolutionary Computation, 24, 255-291."
      },
      {
        "ref_id": "54",
        "text": "Omidvar, M. N., Yang, M., Mei, Y., Li, X., \\& Yao, X. (2017). DG2: A Faster and More Accurate Differential Grouping for Large-Scale Black-Box Optimization. IEEE Transactions on Evolutionary Computation, 21, 929-942,"
      },
      {
        "ref_id": "55",
        "text": "Hauschild, M., \\& Pelikan, M. (2011). An introduction and survey of estimation of distribution algorithms. Swarm and Evolutionary Computation, 1, 111-128."
      },
      {
        "ref_id": "56",
        "text": "Li, H., Hong, Y., Kwong, S., Ren, Q., \\& Wang, W. (2012). Enhancement of continuous estimation of distribution algorithms by density ensembles. Engineering Optimization, 44, 1303-1320."
      },
      {
        "ref_id": "57",
        "text": "Ahmed, A., Khan, Q., Naeem, M., Iqbal, M., Anpalagan, A., \\& Awais, M. (2018). An insight to the performance of estimation of distribution algorithm for multiple line outage identification. Swarm and Evolutionary Computation, 39, 114-122."
      },
      {
        "ref_id": "58",
        "text": "Lu, H., Zhou, R., Cheng, S., \\& Shi, Y. (2019). Multi-center variable-scale search algorithm for combinatorial optimization problems with the multimodal property. Applied Soft Computing, 84, Article 105726."
      },
      {
        "ref_id": "59",
        "text": "Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., \\& Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15, 1929-1958."
      },
      {
        "ref_id": "60",
        "text": "Ahn, C. W., \\& Ramakrishna, R. S. (2003). Elitism-based compact genetic algorithms. IEEE Transactions on Evolutionary Computation, 7, 367-385."
      },
      {
        "ref_id": "61",
        "text": "Purshouse, R. C., Fleming, P. J. (2002). Why use elitism and sharing in a multi-objective genetic algorithm, Proceedings of the Genetic and Evolutionary Computation Conference, New York, USA, 2002, pp. 520-527."
      },
      {
        "ref_id": "62",
        "text": "Gao, S., \\& de Silva, C. W. (2018). Estimation distribution algorithms on constrained optimization problems. Applied Mathematics and Computation, 339, 323-345."
      },
      {
        "ref_id": "63",
        "text": "Rumelhart, D. E., Hinton, G. E., \\& Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323, 533-536."
      },
      {
        "ref_id": "64",
        "text": "Xiao, H., Raoul, K., Vollgraf, R. (2017). Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, arXiv, (2017) arXiv/1708.07747."
      },
      {
        "ref_id": "65",
        "text": "Ledesma, L., Olveres, J., Escalante-Ram I Rez, B. (2019). Hermite Convolutional Networks, Iberoamerican Congress on Pattern Recognition, Springer, Havana, Cuba, 2019, pp. 398-407."
      },
      {
        "ref_id": "66",
        "text": "Sabour, S., Frost, N., \\& Hinton, G. E. (2017). Dynamic Routing Between Capsules, Advances in Neural Information Processing Systems 30 (pp. 3856-3866). Currar Associates: Inc, Zhang, X., Sun, Y., Wang, Y., Li, Z., Li, N., \\& Su, J. (2019). A novel effective and efficient capsule network via bottleneck residual block and automated gradual pruning. Computers A Electrical Engineering, 80, Article 106481."
      },
      {
        "ref_id": "67",
        "text": "Chollet, F. (2017). Xception: Deep learning with depthwise separable convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition, Honolulu, Hawaii, USA, 2017, pp. 1251-1258."
      }
    ],
    "reference_count": 67,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Different heuristic algorithm-based deep neural network optimization.",
      "headers": [
        "",
        "Optimization algorithm",
        "Hyper-parameter",
        "Architectures searching",
        "Weights searching"
      ],
      "rows": [
        [
          0.2012,
          "Genetic algorithm",
          "",
          "$\\sqrt{ }$",
          "$\\sqrt{ }$"
        ],
        [
          "Assun et al. (Assunção et al., 2019)",
          "Genetic algorithm",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Snoek et al. (Bella et al., 2017)",
          "Bayesian",
          "$\\sqrt{ }$",
          "",
          ""
        ],
        [
          "Bello et al. (Zoph et al., 2018)",
          "Reinforcement learning",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Zoph et al. (Zhong et al., 2018)",
          "Random search",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Zhong et al. (Real et al., 2017)",
          "Reinforcement learning",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Real et al. (Xie et al., 2018)",
          "Genetic algorithm",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Xie et al. (Cai et al., 2018)",
          "Reinforcement learning",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Cai et al. (Zhang et al., 2018)",
          "Reinforcement learning",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Zhang et al. (Sun et al., 2020)",
          "Random sampling",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          0.2019,
          "Particle swarm optimization",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Sun et al. (Sun et al., 2019, Xu et al., 2019)",
          "Genetic algorithm",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          "Xu et al. (Lopez-Rincon et al., 2018)",
          "Reinforcement learning",
          "",
          "$\\sqrt{ }$",
          ""
        ],
        [
          2012,
          "Random search",
          "$\\sqrt{ }$",
          "",
          ""
        ],
        [
          "Lopez-Rincon et al. (Baldominus et al., 2018)",
          "Genetic algorithm",
          "$\\sqrt{ }$",
          "",
          ""
        ],
        [
          0.1996,
          "Genetic algorithm",
          "$\\sqrt{ }$",
          "",
          ""
        ],
        [
          "Martin et al. (Martin et al., 2018)",
          "Genetic algorithm",
          "$\\sqrt{ }$",
          "$\\sqrt{ }$",
          ""
        ]
      ],
      "row_count": 17,
      "column_count": 5
    },
    {
      "table_number": "2",
      "table_title": "No. of parameters in pre-training on MNIST.",
      "headers": [
        "Architectures",
        "No. of parameters"
      ],
      "rows": [
        [
          "$784-120-10$",
          189064
        ],
        [
          "$784-300-100-10$",
          344784
        ],
        [
          "$784-1000-500-250-30-10$",
          "$1,442,584$"
        ]
      ],
      "row_count": 3,
      "column_count": 2
    },
    {
      "table_number": "3",
      "table_title": "Comparison of state-of-the-arts.",
      "headers": [
        "Models",
        "Dataset",
        "Accuracy <br> $(\\%)$"
      ],
      "rows": [
        [
          5,
          "Fashion-",
          63.1
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          "MobileNet ${ }^{[* 1}$",
          "Fashion-",
          95.0
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          "DenseNet-BC ${ }^{[* 1}$",
          "Fashion-",
          95.4
        ],
        [
          "",
          "MNIST",
          95.7
        ],
        [
          "Dual path network with wide resnet 28-10 ${ }^{[* 1}$",
          "Fashion-",
          96.3
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          "WRN-28-10 + Random Erasing ${ }^{[* 1}$",
          "Fashion-",
          93.9
        ],
        [
          "",
          "MNIST",
          94.53
        ],
        [
          "Google AutoML ${ }^{[* 1}$",
          "Fashion-",
          94.47
        ],
        [
          "",
          "MNIST",
          97.19
        ],
        [
          0.2019,
          "Fashion-",
          92.01
        ],
        [
          "",
          "MNIST",
          91.92
        ],
        [
          "psoCNN + dropout + BN (best) (Junior and Yen,",
          "Fashion-",
          89.71
        ],
        [
          "",
          "MNIST",
          91.18
        ],
        [
          "Hermite Convolutional Networks (Sabour et al.,",
          "Fashion-",
          92.45
        ],
        [
          2017,
          "MNIST",
          92.03
        ],
        [
          "Adaptive Learning Rate CNN (Lopez-Rincon",
          "Fashion-",
          98.38
        ],
        [
          2018,
          "MNIST",
          98.85
        ],
        [
          "Adaptive Learning Rate ResNet (Lopez-Rincon",
          "MNIST",
          95.74
        ],
        [
          0.2018,
          "MNIST",
          98.92
        ],
        [
          "",
          "Fashion-",
          88.49
        ],
        [
          0.2019,
          "Fashion-",
          90.13
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          2017,
          "Fashion-",
          ""
        ],
        [
          "",
          "",
          ""
        ],
        [
          71,
          "Fashion-",
          ""
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          502017,
          "Fashion-",
          92.03
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          "Our algorithm (784-1000-500-250-30-10)",
          "Fashion-",
          98.85
        ],
        [
          "",
          "MNIST",
          ""
        ],
        [
          "EUDNN (Sun et al., 2019) (784-400-202-106-",
          "MNIST",
          95.74
        ],
        [
          "88-10)",
          "MNIST",
          98.92
        ],
        [
          "SGD based (784-400-202-106-88-10)",
          "Fashion-",
          88.49
        ],
        [
          "Our algorithm (784-400-202-106-88-10)",
          "",
          90.13
        ],
        [
          "SGD based (784-400-202-106-88-10)",
          "Fashion-",
          ""
        ],
        [
          "Our algorithm (784-400-202-106-88-10)",
          "Fashion-",
          ""
        ],
        [
          "",
          "",
          ""
        ]
      ],
      "row_count": 40,
      "column_count": 3
    }
  ]
}