{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2012/A review on probabilistic graphical models in evolutionary computation.md",
    "filename": "A review on probabilistic graphical models in evolutionary computation.md",
    "title": "A review on probabilistic graphical models in evolutionary computation",
    "year": "2012"
  },
  "references": {
    "header": "# References",
    "content": "Ahn, C.W., An, J., Yoo, J.C.: Estimation of particle swarm distribution algorithms: combining the benefits of PSO and EDAs. Inf. Sci. 192, 109-119 (2012)\nAhn, C., Ramakrishna, R., Goldberg, D.: Real-coded Bayesian optimization algorithm: bringing the strength of BOA into the continuous world. In: 6th Annual Conference on Genetic and Evolutionary Computation (GECCO'04), pp. 840-851. Springer, Berlin (2004)\nAkaike, H.: A new look at the statistical model identification. IEEE Trans. Autom. Control 19(6), 716-723 (1974)\n\nAlden, M.E.: MARLEDA: effective distribution estimation through Markov random fields. Ph.D. Thesis, The University of Texas at Austin (2007)\nBaluja, S.: Population-based incremental learning: a method for integrating genetic search based function optimization and competitive learning. Tech. Rep. CMU-CS-94-163, Carnegie-Mellon University (1994)\n\nBaluja, S., Davies, S.: Using optimal dependency-trees for combinational optimization. In: 14th International Conference on Machine Learning, pp. 30-38. Morgan Kaufmann, San Mateo (1997)\nBengoetxea, E., Larrañaga, P.: EDA-PSO: a hybrid paradigm combining estimation of distribution algorithms and particle swarm optimization. In: Swarm Intelligence. Lecture Notes in Computer Science, vol. 6234, pp. 416-423. Springer, Berlin (2010)\nBosman, P.A.N., Grahl, J.: Matching inductive search bias and problem structure in continuous estimation of distribution algorithms. Eur. J. Oper. Res. 185(3), 1246-1264 (2008)\nBosman, P.A.N., Grahl, J., Thierens, D.: Enhancing the performance of maximum-likelihood Gaussian EDAs using anticipated mean shift. In: 10th International Conference on Parallel Problem Solving from Nature (PPSN X), pp. 133-143. Springer, Berlin (2008)\nBosman, P.A.N., Thierens, D.: Advancing continuous IDEAs with mixture distributions and factorization selection metrics. In: Optimization by building and using probabilistic models (OBUPM) Workshop at the Genetic and Evolutionary Computation Conference (GECCO'01), pp. 208-212. ACM, New York (2001)\n\nBosman, P.A.N., de Jong, E.: Adaptation of a success story in GAs: Estimation-of-distribution algorithms for tree-based optimization problems. In: Success in Evolutionary Computation. Studies in Computational Intelligence, vol. 92, pp. 3-18. Springer, Berlin (2008)\nBosman, P.A.N., Thierens, D.: Linkage information processing in distribution estimation algorithms. In: Genetic and Evolutionary Computation Conference (GECCO’99), pp. 60-67. Morgan Kaufmann, San Mateo (1999)\nBosman, P.A.N., Thierens, D.: Continuous iterated density estimation evolutionary algorithms within the IDEA framework. In: Genetic and Evolutionary Computation Conference (GECCO’00) Workshop, pp. 197-200 (2000a)\nBosman, P.A.N., Thierens, D.: Expanding from discrete to continuous estimation of distribution algorithms: the IDEA. In: 6th International Conference on Parallel Problem Solving from Nature (PPSN VI), pp. 767-776. Springer, Berlin (2000b)\nBouckaert, R.R.: Bayesian belief networks: from construction to inference. Ph.D. Thesis, Universiteit Utrecht, Faculteit Wiskunde en Informatica (1995)\nBrownlee, A., McCall, J., Zhang, Q., Brown, D.: Approaches to selection and their effect on fitness modelling in an estimation of distribution algorithm. In: IEEE Congress on Evolutionary Computation (CEC 2008)—IEEE World Congress on Computational Intelligence, pp. 2621-2628. IEEE Comput. Soc., Los Alamitos (2008)\nBrownlee, A.E.I.: Multivariate Markov networks for fitness modelling in an estimation of distribution algorithm. Ph.D. Thesis, The Robert Gordon University. School of Computing (2009)\nBuntine, W.: Theory refinement on Bayesian networks. In: 7th Conference on Uncertainty in Artificial Intelligence (UAI'91), vol. 91, pp. 52-60. Morgan Kaufmann, San Mateo (1991)\nChickering, D.: Learning Bayesian networks is NP-complete. In: Learning from Data: Artificial Intelligence and Statistics V. Lecture Notes in Statistics, vol. 112, pp. 121-130. Springer, Berlin (1996)\nChickering, D., Geiger, D., Heckerman, D.: Learning Bayesian networks is NP-hard. Tech. Rep. MSR-TR-94-17, Microsoft Research (1994)\nChickering, D., Heckerman, D., Meek, C.: Large-sample learning of Bayesian networks is NP-hard. J. Mach. Learn. Res. 5, 1287-1330 (2004)\n\nCho, D.Y., Zhang, B.T.: Evolutionary optimization by distribution estimation with mixtures of factor analyzers. In: IEEE Congress on Evolutionary Computation (CEC'02), vol. 2, pp. 1396-1401. IEEE Comput. Soc., Los Alamitos (2002)\nCho, D.Y., Zhang, B.T.: Evolutionary continuous optimization by distribution estimation with variational Bayesian independent component analyzers mixture model. In: Parallel Problem Solving from Nature (PPSN VIII). Lecture Notes in Computer Science, vol. 3242, pp. 212-221. Springer, Berlin (2004)\nCooper, G., Herskovits, E.: A Bayesian method for the induction of probabilistic networks from data. Mach. Learn. 9(4), 309-347 (1992)\nCosta, M., Minisci, E.: MOPED: a multi-objective Parzen-based estimation of distribution algorithm for continuous problems. In: Evolutionary Multi-Criterion Optimization. Lecture Notes in Computer Science, vol. 2632, p. 71. Springer, Berlin (2003)\nCramer, N.L.: A representation for the adaptive generation of simple sequential programs. In: First International Conference on Genetic Algorithms, pp. 183-187. Erlbaum, Hillsdale (1985)\nCuesta-Infante, A., Santana, R., Hidalgo, J.I., Bielza, C., Larrañaga, P.: Bivariate empirical and $n$-variate Archimedean copulas in estimation of distribution algorithms. In: IEEE Congress on Evolutionary Computation (CEC'10) (2010)\nDawid, A.P.: Conditional independence in statistical theory. J. R. Stat. Soc. B 41(1), 1-31 (1979)\nDe Bonet, J., Isbell, C., Viola, P.M.: Finding optima by estimating probability densities. Adv. Neural Inf. Process. Syst. 9, 424-430 (1997)\nde Castro, P.A.D., Zuben, F.J.V.: BAIS: a Bayesian artificial immune system for the effective handling of building blocks. Inf. Sci. 179(10), 1426-1440 (2009)\nDempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete data via the EM algorithm. J. R. Stat. Soc. B 39(1), 1-38 (1977)\nDing, N., Zhou, S., Sun, Z.: Histogram-based estimation of distribution algorithm: a competent method for continuous optimization. J. Comput. Sci. Technol. 23(1), 35-43 (2008)\nEchegoyen, C., Mendiburu, A., Santana, R., Lozano, J.: Analyzing the probability of the optimum in EDAs based on Bayesian networks. In: IEEE Congress on Evolutionary Computation (CEC'09), pp. 16521659 (2009)\nEtxeberria, R., Larrañaga, P.: Global optimization using Bayesian networks. In: Second Symposium on Artificial Intelligence (CIMAF-99), pp. 332-339 (1999)\n\nFogel, L.J.: Artificial Intelligence Through Simulated Evolution. Wiley, New York (1966)\nFrey, B.J., Dueck, D.: Mixture modeling by affinity propagation. In: Advances in Neural Information Processing Systems, vol. 18, pp. 379-386. MIT Press, Cambridge (2006)\nFrydenberg, M.: The chain graph Markov property. Scand. J. Stat. 17(4), 333-353 (1990)\nGámez, J., Mateo, J., Puerta, J.E.: Estimation of dependency networks algorithm. In: Bio-inspired Modeling of Cognitive Tasks. Lecture Notes in Computer Science, vol. 4527, pp. 427-436. Springer, Berlin (2007)\n\nGeiger, D., Heckerman, D.: Learning Gaussian networks. In: 10th Conference on Uncertainty in Artificial Intelligence (UAI'94), pp. 235-243 (1994)\nGeman, S., Geman, D.: Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Trans. Pattern Anal. Mach. Intell. 6(6), 721-741 (1984)\nGoldberg, D.E.: The Design of Innovation: Lessons from and for Competent Genetic Algorithms. Kluwer Academic, Norwell (2002)\nGonzález, C., Lozano, J., Larrañaga, P.: Mathematical modelling of UMDAc algorithm with tournament selection. Behaviour on linear and quadratic functions. Int. J. Approx. Reason. 31(3), 313-340 (2002)\nGrahl, J., Bosman, P.A.N., Rothlauf, F.: The correlation-triggered adaptive variance scaling IDEA. In: 8th Annual Conference on Genetic and Evolutionary Computation (GECCO’06), pp. 397-404. ACM, New York (2006)\nGrünwald, P.: The minimum description length principle and reasoning under uncertainty. Ph.D. Thesis, University of Amsterdam (1998)\nHansen, N.: The CMA evolution strategy: a comparing review. In: (Lozano et al. 2006), pp. 75-102 (2006)\nHarik, G., Cantú-Paz, E., Goldberg, D., Miller, B.: The gambler's ruin problem, genetic algorithms, and the sizing of populations. Evol. Comput. 7(3), 231-253 (1999)\nHarik, G.R., Lobo, F.G., Sastry, K.: Linkage learning via probabilistic modeling in the Extended Compact Genetic Algorithm (ECGA). In: (Pelikan et al. 2006), pp. 39-61 (2006). Chap. 3\nHarik, G., Lobo, F., Goldberg, D.: The compact genetic algorithm. IEEE Trans. Evol. Comput. 3(4), 287297 (1999)\nHasegawa, Y., Iba, H.: A Bayesian network approach to program generation. IEEE Trans. Evol. Comput. 12(6), 750-764 (2008)\nHeckerman, D., Geiger, D., Chickering, D.: Learning Bayesian networks: the combination of knowledge and statistical data. Mach. Learn. 20(3), 197-243 (1995)\nHeckerman, D., Chickering, D.M., Meek, C., Rounthwaite, R., Kadie, C.: Dependency networks for inference, collaborative filtering, and data visualization. J. Mach. Learn. Res. 1, 49-75 (2001)\nHolland, J.: Adaptation in Natural and Artificial Systems. University of Michigan Press, Ann Arbor (1975)\nHong, Y., Zhu, G., Kwong, S., Ren, Q.: Estimation of distribution algorithms making use of both high quality and low quality individuals. In: IEEE International Conference on Fuzzy Systems (FUZZIEEE'09), pp. 1806-1813. IEEE Comput. Soc., Los Alamitos (2009)\nKarshenas, H., Nikanjam, A., Helmi, B.H., Rahmani, A.T.: Combinatorial effects of local structures and scoring metrics in Bayesian optimization algorithm. In: First ACM/SIGEVO Summit on Genetic and Evolutionary Computation (GEC'09), pp. 263-270. ACM, New York (2009)\nKarshenas, H., Santana, R., Bielza, C., Larrañaga, P.: Multi-objective optimization with joint probabilistic modeling of objectives and variables. In: Evolutionary Multi-Criterion Optimization. Lecture Notes in Computer Science, vol. 6576, pp. 298-312. Springer, Berlin (2011)\nKoller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Techniques. MIT Press, Cambridge (2009)\nKoza, J.R.: Genetic Programming: on the Programming of Computers by Means of Natural Selection. MIT Press, Cambridge (1992)\nLarrañaga, P., Etxeberria, R., Lozano, J., Pena, J.: Optimization by learning and simulation of Bayesian and Gaussian networks. Tech. Rep. EHU-KZAAIK-IK-4/99, Intelligent Systems Group, Department of Computer Science and Artificial Intelligence, University of the Basque Country (1999)\nLarrañaga, P., Etxeberria, R., Lozano, J., Peña, J.: Combinatonal optimization by learning and simulation of Bayesian networks. In: 16th Conference on Uncertainty in Artificial Intelligence (UAI'00), pp. 343352. Morgan Kaufmann, San Mateo (2000a)\n\nLarrañaga, P., Etxeberria, R., Lozano, J., Peña, J.: Optimization in continuous domains by learning and simulation of Gaussian networks. In: Conference on Genetic and Evolutionary Computation (GECCO’00) Workshop Program, pp. 201-204. Morgan Kaufmann, San Mateo (2000b)\nLarrañaga, P., Lozano, J. (eds.): Estimation of Distribution Algorithms: a New Tool for Evolutionary Computation. Kluwer Academic, Norwell (2001)\n\nLarrañaga, P., Moral, S.: Probabilistic graphical models in artificial intelligence. Appl. Soft Comput. 11(2), $1511-1528$ (2011)\nLauritzen, S.L., Spiegelhalter, D.J.: Local computations with probabilities on graphical structures and their application to expert systems. J. R. Stat. Soc. B 50(2), 157-224 (1988)\nLi, B., Zhong, R.T., Wang, X.J., Zhuang, Z.Q.: Continuous optimization based-on boosting Gaussian mixture model. In: 18th International Conference on Pattern Recognition (ICPR’06), vol. 1, pp. 11921195 (2006)\nLima, C., Pelikan, M., Goldberg, D., Lobo, F., Sastry, K., Hauschild, M.: Influence of selection and replacement strategies on linkage learning in BOA. In: CEC 2007, IEEE Congress on Evolutionary Computation, pp. 1083-1090 (2007)\nLima, C., Pelikan, M., Lobo, F., Goldberg, D.: Loopy substructural local search for the Bayesian optimization algorithm. In: Engineering Stochastic Local Search Algorithms. Designing, Implementing and Analyzing Effective Heuristics. Lecture Notes in Computer Science, vol. 5752, pp. 61-75. Springer, Berlin (2009)\nLozano, J., Larrañaga, P., Inza, I., Bengoetxea, E. (eds.): Towards a New Evolutionary Computation: Advances on Estimation of Distribution Algorithms. Studies in Fuzziness and Soft Computing, vol. 192. Springer, Berlin (2006)\nLuo, N., Qian, F.: Evolutionary algorithm using kernel density estimation model in continuous domain. In: 7th Asian Control Conference (ASCC’09), pp. 1526-1531 (2009)\nMartí, L., García, J., Berlanga, A., Coello, C.A.C., Molina, J.M.: MB-GNG: addressing drawbacks in multi-objective optimization estimation of distribution algorithms. Oper. Res. Lett. 39(2), 150-154 (2011)\n\nMcKay, R., Hoai, N., Whigham, P., Shan, Y., O’Neill, M.: Grammar-based genetic programming: a survey. Genet. Program. Evol. Mach. 11, 365-396 (2010)\nMendiburu, A., Santana, R., Lozano, J.A.: Introducing belief propagation in estimation of distribution algorithms: a parallel framework. Tech. Rep. EHU-KAT-IK-11-07, Intelligent Systems Group, University of the Basque Country (2007)\nMichalski, R.S.: Learnable evolution model: evolutionary processes guided by machine learning. Mach. Learn. 38, 9-40 (2000)\nMiquélez, T., Bengoetxea, E., Larrañaga, P.: Evolutionary computation based on Bayesian classifiers. Int. J. Appl. Math. Comput. Sci. 14(3), 335-350 (2004)\n\nMiquélez, T., Bengoetxea, E., Larrañaga, P.: Evolutionary Bayesian classifier-based optimization in continuous domains. In: 6th International Conference on Simulated Evolution and Learning (SEAL’06). Lecture Notes in Computer Science, vol. 4247, pp. 529-536. Springer, Berlin (2006)\nMühlenbein, H., Mahnig, T.: FDA-A scalable evolutionary algorithm for the optimization of additively decomposed functions. Evol. Comput. 7(4), 353-376 (1999)\nMühlenbein, H., Mahnig, T., Ochoa Rodríguez, A.: Schemata, distributions and graphical models in evolutionary optimization. J. Heuristics 5(2), 215-247 (1999)\nMühlenbein, H., Paaß, G.: From recombination of genes to the estimation of distributions I. Binary parameters. In: 4th International Conference on Parallel Problem Solving from Nature (PPSN IV). Lecture Notes in Computer Science, vol. 1141, pp. 178-187. Springer, Berlin (1996)\nOčenášek, J., Schwarz, J.: Estimation distribution algorithm for mixed continuous-discrete optimization problems. In: Intelligent Technologies: Theory and Applications: New Trends in Intelligent Technologies, pp. 227-232. IOS Press, Amsterdam (2002)\nOčenášek, J., Kern, S., Hansen, N., Koumoutsakos, P.: A mixed Bayesian optimization algorithm with variance adaptation. In: Parallel Problem Solving from Nature (PPSN VIII). Lecture Notes in Computer Science, vol. 3242, pp. 352-361. Springer, Berlin (2004)\nPearl, J.: Bayesian networks: a model of self-activated memory for evidential reasoning. In: 7th Conference of the Cognitive Science Society, pp. 329-334 (1985)\nPelikan, M., Goldberg, D., Lobo, F.: A survey of optimization by building and using probabilistic models. Comput. Optim. Appl. 21(1), 5-20 (2002)\nPelikan, M., Mühlenbein, H.: The bivariate marginal distribution algorithm. In: Advances in Soft Computing-Engineering Design and Manufacturing, pp. 521-535 (1999)\nPelikan, M., Sastry, K., Cantú-Paz, E. (eds.): Scalable Optimization via Probabilistic Modeling: from Algorithms to Applications. Springer, Berlin (2006)\nPelikan, M., Sastry, K., Goldberg, D.: Sporadic model building for efficiency enhancement of the hierarchical BOA. Genet. Program. Evol. Mach. 9(1), 53-84 (2008)\nPelikan, M.: Hierarchical Bayesian Optimization Algorithm: Toward a New Generation of Evolutionary Algorithms, 1st edn. Studies in Fuzziness and Soft Computing, vol. 170. Springer, Berlin (2005)\n\nPelikan, M., Goldberg, D.: Genetic algorithms, clustering, and the breaking of symmetry. In: Parallel Problem Solving from Nature (PPSN VI). Lecture Notes in Computer Science, vol. 1917, pp. 385394. Springer, Berlin (2000)\n\nPelikan, M., Goldberg, D.E., Canti-Paz, E.B.: The Bayesian optimization algorithm. In: Conference on Genetic and Evolutionary Computation (GECCO'99), vol. 1, pp. 525-532. Morgan Kaufmann, San Mateo (1999)\nPelikan, M., Hartmann, A.: Searching for ground states of Ising spin glasses with hierarchical BOA and cluster exact approximation. In: (Pelikan et al. 2006), pp. 333-349 (2006)\nPelikan, M., Sastry, K.: Fitness inheritance in the Bayesian optimization algorithm. In: Conference on Genetic and Evolutionary Computation (GECCO'04). Lecture Notes in Computer Science, vol. 3103, pp. 48-59. Springer, Berlin (2004)\nPeña, J.M., Lozano, J.A., Larrañaga, P.: Globally multimodal problem optimization via an estimation of distribution algorithm based on unsupervised learning of Bayesian networks. Evol. Comput. 13(1), $43-66$ (2005)\nPošík, P.: Preventing premature convergence in a simple EDA via global step size setting. In: 10th International Conference on Parallel Problem Solving from Nature (PPSN X). Lecture Notes in Computer Science, vol. 5199, pp. 549-558. Springer, Berlin (2008)\nPošík, P.: BBOB-benchmarking a simple estimation of distribution algorithm with cauchy distribution. In: 11th Annual Conference Companion on Genetic and Evolutionary Computation (GECCO’09), pp. 2309-2314. ACM, New York (2009a)\nPošík, P.: Stochastic local search techniques with unimodal continuous distributions: a survey. In: EvoWorkshops on Applications of Evolutionary Computing (EvoWorkshops'09), pp. 685-694. Springer, Berlin (2009b)\nRechenberg, I.: Evolutionsstrategie-Optimierung Technischer Systeme nach Prinzipien der Biologischen Evolution. Ph.D. Thesis, reprinted by Fromman-Holzboog (1973)\nRissanen, J.: Modeling by shortest data description. Automatica 14(5), 465-471 (1978)\nRobinson, R.: Counting unlabeled acyclic digraphs. In: Combinatorial Mathematics V. Lecture Notes in Mathematics, vol. 622, pp. 28-43. Springer, Berlin (1977)\nSalinas-Gutiérrez, R., Hernández-Aguirre, A., Villa-Diharce, E.: Using copulas in estimation of distribution algorithms. In: Advances in Artificial Intelligence (MICAI'09). Lecture Notes in Computer Science, vol. 5845, pp. 658-668. Springer, Berlin (2009)\nSafustowicz, R.P., Schmidhuber, J.: Probabilistic incremental program evolution: stochastic search through program space. In: 9th European Conference on Machine Learning (ECML'97). Lecture Notes in Computer Science, vol. 1224, pp. 213-220. Springer, Berlin (1997)\nSantana, R., Bielza, C., Lozano, J., Larrañaga, P.: Mining probabilistic models learned by EDAs in the optimization of multi-objective problems. In: 11th Annual Conference on Genetic and Evolutionary Computation (GECCO'09), pp. 445-452. ACM, New York (2009a)\nSantana, R., Larrañaga, P., Lozano, J.: Research topics in discrete estimation of distribution algorithms based on factorizations. Memet. Comput. 1(1), 35-54 (2009b)\nSantana, R., Larrañaga, P., Lozano, J.: Learning factorizations in estimation of distribution algorithms using affinity propagation. Evol. Comput. 18(4), 515-546 (2010)\nSantana, R.: A Markov network based factorized distribution algorithm for optimization. In: 14th European Conference on Machine Learning (ECML'03). Lecture Notes in Computer Science, vol. 2837, pp. 337-348. Springer, Berlin (2003)\nSantana, R.: Estimation of distribution algorithms with Kikuchi approximations. Evol. Comput. 13, 67-97 (2005)\n\nSantana, R.: Estimation of distribution algorithms: from available implementations to potential developments. In: 13th Annual Conference Companion on Genetic and Evolutionary Computation (GECCO'11), pp. 679-686. ACM, New York (2011)\nSantana, R., Bielza, C., Larrañaga, P., Lozano, J.A., Echegoyen, C., Mendiburu, A., Armañanzas, R., Shakya, S.: Mateda-2.0: estimation of distribution algorithms in MATLAB. J. Stat. Softw. 35(7), $1-30(2010)$\nSastry, K., Goldberg, D.E.: Probabilistic model building and competent genetic programming. In: Genetic Programming Theory and Practice, pp. 205-220. Kluwer Academic, Norwell (2003). Chap. 13\nSastry, K., Pelikan, M., Goldberg, D.: Efficiency enhancement of genetic algorithms via building-blockwise fitness estimation. In: IEEE Congress on Evolutionary Computation (CEC'04), vol. 1, pp. 720727 (2004)\nSchwarz, G.: Estimating the dimension of a model. Ann. Stat. 6(2), 461-464 (1978)\n\nSebag, M., Ducoulombier, A.: Extending population-based incremental learning to continuous search spaces. In: 5th International Conference on Parallel Problem Solving from Nature (PPSN V). Lecture Notes in Computer Science, vol. 1498, pp. 418-427. Springer, Berlin (1998)\nShakya, S.: DEUM: a framework for an estimation of distribution algorithm based on Markov random fields. Ph.D. Thesis, The Robert Gordon University (2006)\nShakya, S., Santana, R. (eds.): Markov Networks in Evolutionary Computation. Adaptation, Learning, and Optimization, vol. 14. Springer, Berlin (2012)\nShan, Y., McKay, R., Essam, D., Abbass, H.: a survey of probabilistic model building genetic programming. In: (Pelikan et al. 2006), pp. 121-160 (2006)\nSpirtes, P., Glymour, C.: An algorithm for fast recovery of sparse causal graphs. Soc. Sci. Comput. Rev. 9(1), 62-72 (1991)\nSpirtes, P., Glymour, C., Scheines, R.: Causation, Prediction, and Search, 2nd edn. MIT Press, Cambridge (2001)\n\nSun, J., Zhang, Q., Tsang, E.: DE/EDA: a new evolutionary algorithm for global optimization. Inf. Sci. 169(3-4), 249-262 (2005)\nThierens, D.: The linkage tree genetic algorithm. In: Parallel Problem Solving from Nature (PPSN XI). Lecture Notes in Computer Science, vol. 6238, pp. 264-273. Springer, Berlin (2011)\nTsutsui, S., Pelikan, M., Goldberg, D.: Node histogram vs. edge histogram: a comparison of pmbgas in permutation domains. Tech. Rep. 2006009, Missouri Estimation of Distribution Algorithms Laboratory (MEDAL), Department of Mathematics and Computer Science, University of Missouri-St. Louis (2006)\nTsutsui, S.: Probabilistic model-building genetic algorithms in permutation representation domain using edge histogram. In: Parallel Problem Solving from Nature (PPSN VII). Lecture Notes in Computer Science, vol. 2439, pp. 224-233. Springer, Berlin (2002)\nTsutsui, S., Pelikan, M., Goldberg, D.E.: Evolutionary algorithm using marginal histogram in continuous domain. In: Optimization by Building and Using Probabilistic Models (OBUPM) WorkshopConference on Genetic and Evolutionary Computation (GECCO'01), pp. 230-233 (2001)\nValdez-Peña, S.I., Hernández-Aguirre, A., Botello-Rionda, S.: Approximating the search distribution to the selection distribution in EDAs. In: 11th Annual Conference on Genetic and Evolutionary Computation (GECCO’09), pp. 461-468. ACM, New York (2009)\nWang, L.F., Zeng, J.C.: Estimation of distribution algorithm based on copula theory. In: Exploitation of Linkage Learning in Evolutionary Algorithms. Evolutionary Learning and Optimization, vol. 3, pp. 139-162. Springer, Berlin (2010)\nWang, L.F., Zeng, J.C., Hong, Y.: Estimation of distribution algorithm based on Archimedean copulas. In: First ACM/SIGEVO Summit on Genetic and Evolutionary Computation (GEC'09), pp. 993-996. ACM, New York (2009)\nWang, X., Wang, H.: Evolutionary optimization with Markov random field prior. IEEE Trans. Evol. Comput. 8(6), 567-579 (2004)\nWeise, T., Niemczyk, S., Chiong, R., Wan, M.: A framework for multi-model EDAs with model recombination. In: Applications of Evolutionary Computation. Lecture Notes in Computer Science, vol. 6624, pp. 304-313. Springer, Berlin (2011)\nXiao, J., Yan, Y., Zhang, J.: HPBILc: a histogram-based EDA for continuous optimization. Appl. Math. Comput. 215(3), 973-982 (2009)\nYanai, K., Iba, H.: Estimation of distribution programming based on Bayesian network. In: IEEE Congress on Evolutionary Computation (CEC'03), vol. 3, pp. 1618-1625 (2003)\nZhang, Q.: On stability of fixed points of limit models of univariate marginal distribution algorithm and factorized distribution algorithm. IEEE Trans. Evol. Comput. 8(1), 80-93 (2004)\nZhang, Q., Zhou, A., Jin, Y.: RM-MEDA: a regularity model based multiobjective estimation of distribution algorithm. IEEE Trans. Evol. Comput. 12(1), 41-63 (2008)",
    "references": [
      {
        "ref_id": "1",
        "text": "Ahn, C.W., An, J., Yoo, J.C.: Estimation of particle swarm distribution algorithms: combining the benefits of PSO and EDAs. Inf. Sci. 192, 109-119 (2012)"
      },
      {
        "ref_id": "2",
        "text": "Ahn, C., Ramakrishna, R., Goldberg, D.: Real-coded Bayesian optimization algorithm: bringing the strength of BOA into the continuous world. In: 6th Annual Conference on Genetic and Evolutionary Computation (GECCO'04), pp. 840-851. Springer, Berlin (2004)"
      },
      {
        "ref_id": "3",
        "text": "Akaike, H.: A new look at the statistical model identification. IEEE Trans. Autom. Control 19(6), 716-723 (1974)"
      },
      {
        "ref_id": "4",
        "text": "Alden, M.E.: MARLEDA: effective distribution estimation through Markov random fields. Ph.D. Thesis, The University of Texas at Austin (2007)"
      },
      {
        "ref_id": "5",
        "text": "Baluja, S.: Population-based incremental learning: a method for integrating genetic search based function optimization and competitive learning. Tech. Rep. CMU-CS-94-163, Carnegie-Mellon University (1994)"
      },
      {
        "ref_id": "6",
        "text": "Baluja, S., Davies, S.: Using optimal dependency-trees for combinational optimization. In: 14th International Conference on Machine Learning, pp. 30-38. Morgan Kaufmann, San Mateo (1997)"
      },
      {
        "ref_id": "7",
        "text": "Bengoetxea, E., Larrañaga, P.: EDA-PSO: a hybrid paradigm combining estimation of distribution algorithms and particle swarm optimization. In: Swarm Intelligence. Lecture Notes in Computer Science, vol. 6234, pp. 416-423. Springer, Berlin (2010)"
      },
      {
        "ref_id": "8",
        "text": "Bosman, P.A.N., Grahl, J.: Matching inductive search bias and problem structure in continuous estimation of distribution algorithms. Eur. J. Oper. Res. 185(3), 1246-1264 (2008)"
      },
      {
        "ref_id": "9",
        "text": "Bosman, P.A.N., Grahl, J., Thierens, D.: Enhancing the performance of maximum-likelihood Gaussian EDAs using anticipated mean shift. In: 10th International Conference on Parallel Problem Solving from Nature (PPSN X), pp. 133-143. Springer, Berlin (2008)"
      },
      {
        "ref_id": "10",
        "text": "Bosman, P.A.N., Thierens, D.: Advancing continuous IDEAs with mixture distributions and factorization selection metrics. In: Optimization by building and using probabilistic models (OBUPM) Workshop at the Genetic and Evolutionary Computation Conference (GECCO'01), pp. 208-212. ACM, New York (2001)"
      },
      {
        "ref_id": "11",
        "text": "Bosman, P.A.N., de Jong, E.: Adaptation of a success story in GAs: Estimation-of-distribution algorithms for tree-based optimization problems. In: Success in Evolutionary Computation. Studies in Computational Intelligence, vol. 92, pp. 3-18. Springer, Berlin (2008)"
      },
      {
        "ref_id": "12",
        "text": "Bosman, P.A.N., Thierens, D.: Linkage information processing in distribution estimation algorithms. In: Genetic and Evolutionary Computation Conference (GECCO’99), pp. 60-67. Morgan Kaufmann, San Mateo (1999)"
      },
      {
        "ref_id": "13",
        "text": "Bosman, P.A.N., Thierens, D.: Continuous iterated density estimation evolutionary algorithms within the IDEA framework. In: Genetic and Evolutionary Computation Conference (GECCO’00) Workshop, pp. 197-200 (2000a)"
      },
      {
        "ref_id": "14",
        "text": "Bosman, P.A.N., Thierens, D.: Expanding from discrete to continuous estimation of distribution algorithms: the IDEA. In: 6th International Conference on Parallel Problem Solving from Nature (PPSN VI), pp. 767-776. Springer, Berlin (2000b)"
      },
      {
        "ref_id": "15",
        "text": "Bouckaert, R.R.: Bayesian belief networks: from construction to inference. Ph.D. Thesis, Universiteit Utrecht, Faculteit Wiskunde en Informatica (1995)"
      },
      {
        "ref_id": "16",
        "text": "Brownlee, A., McCall, J., Zhang, Q., Brown, D.: Approaches to selection and their effect on fitness modelling in an estimation of distribution algorithm. In: IEEE Congress on Evolutionary Computation (CEC 2008)—IEEE World Congress on Computational Intelligence, pp. 2621-2628. IEEE Comput. Soc., Los Alamitos (2008)"
      },
      {
        "ref_id": "17",
        "text": "Brownlee, A.E.I.: Multivariate Markov networks for fitness modelling in an estimation of distribution algorithm. Ph.D. Thesis, The Robert Gordon University. School of Computing (2009)"
      },
      {
        "ref_id": "18",
        "text": "Buntine, W.: Theory refinement on Bayesian networks. In: 7th Conference on Uncertainty in Artificial Intelligence (UAI'91), vol. 91, pp. 52-60. Morgan Kaufmann, San Mateo (1991)"
      },
      {
        "ref_id": "19",
        "text": "Chickering, D.: Learning Bayesian networks is NP-complete. In: Learning from Data: Artificial Intelligence and Statistics V. Lecture Notes in Statistics, vol. 112, pp. 121-130. Springer, Berlin (1996)"
      },
      {
        "ref_id": "20",
        "text": "Chickering, D., Geiger, D., Heckerman, D.: Learning Bayesian networks is NP-hard. Tech. Rep. MSR-TR-94-17, Microsoft Research (1994)"
      },
      {
        "ref_id": "21",
        "text": "Chickering, D., Heckerman, D., Meek, C.: Large-sample learning of Bayesian networks is NP-hard. J. Mach. Learn. Res. 5, 1287-1330 (2004)"
      },
      {
        "ref_id": "22",
        "text": "Cho, D.Y., Zhang, B.T.: Evolutionary optimization by distribution estimation with mixtures of factor analyzers. In: IEEE Congress on Evolutionary Computation (CEC'02), vol. 2, pp. 1396-1401. IEEE Comput. Soc., Los Alamitos (2002)"
      },
      {
        "ref_id": "23",
        "text": "Cho, D.Y., Zhang, B.T.: Evolutionary continuous optimization by distribution estimation with variational Bayesian independent component analyzers mixture model. In: Parallel Problem Solving from Nature (PPSN VIII). Lecture Notes in Computer Science, vol. 3242, pp. 212-221. Springer, Berlin (2004)"
      },
      {
        "ref_id": "24",
        "text": "Cooper, G., Herskovits, E.: A Bayesian method for the induction of probabilistic networks from data. Mach. Learn. 9(4), 309-347 (1992)"
      },
      {
        "ref_id": "25",
        "text": "Costa, M., Minisci, E.: MOPED: a multi-objective Parzen-based estimation of distribution algorithm for continuous problems. In: Evolutionary Multi-Criterion Optimization. Lecture Notes in Computer Science, vol. 2632, p. 71. Springer, Berlin (2003)"
      },
      {
        "ref_id": "26",
        "text": "Cramer, N.L.: A representation for the adaptive generation of simple sequential programs. In: First International Conference on Genetic Algorithms, pp. 183-187. Erlbaum, Hillsdale (1985)"
      },
      {
        "ref_id": "27",
        "text": "Cuesta-Infante, A., Santana, R., Hidalgo, J.I., Bielza, C., Larrañaga, P.: Bivariate empirical and $n$-variate Archimedean copulas in estimation of distribution algorithms. In: IEEE Congress on Evolutionary Computation (CEC'10) (2010)"
      },
      {
        "ref_id": "28",
        "text": "Dawid, A.P.: Conditional independence in statistical theory. J. R. Stat. Soc. B 41(1), 1-31 (1979)"
      },
      {
        "ref_id": "29",
        "text": "De Bonet, J., Isbell, C., Viola, P.M.: Finding optima by estimating probability densities. Adv. Neural Inf. Process. Syst. 9, 424-430 (1997)"
      },
      {
        "ref_id": "30",
        "text": "Dempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete data via the EM algorithm. J. R. Stat. Soc. B 39(1), 1-38 (1977)"
      },
      {
        "ref_id": "31",
        "text": "Ding, N., Zhou, S., Sun, Z.: Histogram-based estimation of distribution algorithm: a competent method for continuous optimization. J. Comput. Sci. Technol. 23(1), 35-43 (2008)"
      },
      {
        "ref_id": "32",
        "text": "Echegoyen, C., Mendiburu, A., Santana, R., Lozano, J.: Analyzing the probability of the optimum in EDAs based on Bayesian networks. In: IEEE Congress on Evolutionary Computation (CEC'09), pp. 16521659 (2009)"
      },
      {
        "ref_id": "33",
        "text": "Etxeberria, R., Larrañaga, P.: Global optimization using Bayesian networks. In: Second Symposium on Artificial Intelligence (CIMAF-99), pp. 332-339 (1999)"
      },
      {
        "ref_id": "34",
        "text": "Fogel, L.J.: Artificial Intelligence Through Simulated Evolution. Wiley, New York (1966)"
      },
      {
        "ref_id": "35",
        "text": "Frey, B.J., Dueck, D.: Mixture modeling by affinity propagation. In: Advances in Neural Information Processing Systems, vol. 18, pp. 379-386. MIT Press, Cambridge (2006)"
      },
      {
        "ref_id": "36",
        "text": "Frydenberg, M.: The chain graph Markov property. Scand. J. Stat. 17(4), 333-353 (1990)"
      },
      {
        "ref_id": "37",
        "text": "Gámez, J., Mateo, J., Puerta, J.E.: Estimation of dependency networks algorithm. In: Bio-inspired Modeling of Cognitive Tasks. Lecture Notes in Computer Science, vol. 4527, pp. 427-436. Springer, Berlin (2007)"
      },
      {
        "ref_id": "38",
        "text": "Geiger, D., Heckerman, D.: Learning Gaussian networks. In: 10th Conference on Uncertainty in Artificial Intelligence (UAI'94), pp. 235-243 (1994)"
      },
      {
        "ref_id": "39",
        "text": "Geman, S., Geman, D.: Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Trans. Pattern Anal. Mach. Intell. 6(6), 721-741 (1984)"
      },
      {
        "ref_id": "40",
        "text": "Goldberg, D.E.: The Design of Innovation: Lessons from and for Competent Genetic Algorithms. Kluwer Academic, Norwell (2002)"
      },
      {
        "ref_id": "41",
        "text": "González, C., Lozano, J., Larrañaga, P.: Mathematical modelling of UMDAc algorithm with tournament selection. Behaviour on linear and quadratic functions. Int. J. Approx. Reason. 31(3), 313-340 (2002)"
      },
      {
        "ref_id": "42",
        "text": "Grahl, J., Bosman, P.A.N., Rothlauf, F.: The correlation-triggered adaptive variance scaling IDEA. In: 8th Annual Conference on Genetic and Evolutionary Computation (GECCO’06), pp. 397-404. ACM, New York (2006)"
      },
      {
        "ref_id": "43",
        "text": "Grünwald, P.: The minimum description length principle and reasoning under uncertainty. Ph.D. Thesis, University of Amsterdam (1998)"
      },
      {
        "ref_id": "44",
        "text": "Hansen, N.: The CMA evolution strategy: a comparing review. In: (Lozano et al. 2006), pp. 75-102 (2006)"
      },
      {
        "ref_id": "45",
        "text": "Harik, G., Cantú-Paz, E., Goldberg, D., Miller, B.: The gambler's ruin problem, genetic algorithms, and the sizing of populations. Evol. Comput. 7(3), 231-253 (1999)"
      },
      {
        "ref_id": "46",
        "text": "Harik, G.R., Lobo, F.G., Sastry, K.: Linkage learning via probabilistic modeling in the Extended Compact Genetic Algorithm (ECGA). In: (Pelikan et al. 2006), pp. 39-61 (2006). Chap. 3"
      },
      {
        "ref_id": "47",
        "text": "Harik, G., Lobo, F., Goldberg, D.: The compact genetic algorithm. IEEE Trans. Evol. Comput. 3(4), 287297 (1999)"
      },
      {
        "ref_id": "48",
        "text": "Hasegawa, Y., Iba, H.: A Bayesian network approach to program generation. IEEE Trans. Evol. Comput. 12(6), 750-764 (2008)"
      },
      {
        "ref_id": "49",
        "text": "Heckerman, D., Geiger, D., Chickering, D.: Learning Bayesian networks: the combination of knowledge and statistical data. Mach. Learn. 20(3), 197-243 (1995)"
      },
      {
        "ref_id": "50",
        "text": "Heckerman, D., Chickering, D.M., Meek, C., Rounthwaite, R., Kadie, C.: Dependency networks for inference, collaborative filtering, and data visualization. J. Mach. Learn. Res. 1, 49-75 (2001)"
      },
      {
        "ref_id": "51",
        "text": "Holland, J.: Adaptation in Natural and Artificial Systems. University of Michigan Press, Ann Arbor (1975)"
      },
      {
        "ref_id": "52",
        "text": "Hong, Y., Zhu, G., Kwong, S., Ren, Q.: Estimation of distribution algorithms making use of both high quality and low quality individuals. In: IEEE International Conference on Fuzzy Systems (FUZZIEEE'09), pp. 1806-1813. IEEE Comput. Soc., Los Alamitos (2009)"
      },
      {
        "ref_id": "53",
        "text": "Karshenas, H., Nikanjam, A., Helmi, B.H., Rahmani, A.T.: Combinatorial effects of local structures and scoring metrics in Bayesian optimization algorithm. In: First ACM/SIGEVO Summit on Genetic and Evolutionary Computation (GEC'09), pp. 263-270. ACM, New York (2009)"
      },
      {
        "ref_id": "54",
        "text": "Karshenas, H., Santana, R., Bielza, C., Larrañaga, P.: Multi-objective optimization with joint probabilistic modeling of objectives and variables. In: Evolutionary Multi-Criterion Optimization. Lecture Notes in Computer Science, vol. 6576, pp. 298-312. Springer, Berlin (2011)"
      },
      {
        "ref_id": "55",
        "text": "Koller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Techniques. MIT Press, Cambridge (2009)"
      },
      {
        "ref_id": "56",
        "text": "Koza, J.R.: Genetic Programming: on the Programming of Computers by Means of Natural Selection. MIT Press, Cambridge (1992)"
      },
      {
        "ref_id": "57",
        "text": "Larrañaga, P., Etxeberria, R., Lozano, J., Pena, J.: Optimization by learning and simulation of Bayesian and Gaussian networks. Tech. Rep. EHU-KZAAIK-IK-4/99, Intelligent Systems Group, Department of Computer Science and Artificial Intelligence, University of the Basque Country (1999)"
      },
      {
        "ref_id": "58",
        "text": "Larrañaga, P., Etxeberria, R., Lozano, J., Peña, J.: Combinatonal optimization by learning and simulation of Bayesian networks. In: 16th Conference on Uncertainty in Artificial Intelligence (UAI'00), pp. 343352. Morgan Kaufmann, San Mateo (2000a)"
      },
      {
        "ref_id": "59",
        "text": "Larrañaga, P., Etxeberria, R., Lozano, J., Peña, J.: Optimization in continuous domains by learning and simulation of Gaussian networks. In: Conference on Genetic and Evolutionary Computation (GECCO’00) Workshop Program, pp. 201-204. Morgan Kaufmann, San Mateo (2000b)"
      },
      {
        "ref_id": "60",
        "text": "Larrañaga, P., Lozano, J. (eds.): Estimation of Distribution Algorithms: a New Tool for Evolutionary Computation. Kluwer Academic, Norwell (2001)"
      },
      {
        "ref_id": "61",
        "text": "Larrañaga, P., Moral, S.: Probabilistic graphical models in artificial intelligence. Appl. Soft Comput. 11(2), $1511-1528$ (2011)"
      },
      {
        "ref_id": "62",
        "text": "Lauritzen, S.L., Spiegelhalter, D.J.: Local computations with probabilities on graphical structures and their application to expert systems. J. R. Stat. Soc. B 50(2), 157-224 (1988)"
      },
      {
        "ref_id": "63",
        "text": "Li, B., Zhong, R.T., Wang, X.J., Zhuang, Z.Q.: Continuous optimization based-on boosting Gaussian mixture model. In: 18th International Conference on Pattern Recognition (ICPR’06), vol. 1, pp. 11921195 (2006)"
      },
      {
        "ref_id": "64",
        "text": "Lima, C., Pelikan, M., Goldberg, D., Lobo, F., Sastry, K., Hauschild, M.: Influence of selection and replacement strategies on linkage learning in BOA. In: CEC 2007, IEEE Congress on Evolutionary Computation, pp. 1083-1090 (2007)"
      },
      {
        "ref_id": "65",
        "text": "Lima, C., Pelikan, M., Lobo, F., Goldberg, D.: Loopy substructural local search for the Bayesian optimization algorithm. In: Engineering Stochastic Local Search Algorithms. Designing, Implementing and Analyzing Effective Heuristics. Lecture Notes in Computer Science, vol. 5752, pp. 61-75. Springer, Berlin (2009)"
      },
      {
        "ref_id": "66",
        "text": "Lozano, J., Larrañaga, P., Inza, I., Bengoetxea, E. (eds.): Towards a New Evolutionary Computation: Advances on Estimation of Distribution Algorithms. Studies in Fuzziness and Soft Computing, vol. 192. Springer, Berlin (2006)"
      },
      {
        "ref_id": "67",
        "text": "Luo, N., Qian, F.: Evolutionary algorithm using kernel density estimation model in continuous domain. In: 7th Asian Control Conference (ASCC’09), pp. 1526-1531 (2009)"
      },
      {
        "ref_id": "68",
        "text": "Martí, L., García, J., Berlanga, A., Coello, C.A.C., Molina, J.M.: MB-GNG: addressing drawbacks in multi-objective optimization estimation of distribution algorithms. Oper. Res. Lett. 39(2), 150-154 (2011)"
      },
      {
        "ref_id": "69",
        "text": "McKay, R., Hoai, N., Whigham, P., Shan, Y., O’Neill, M.: Grammar-based genetic programming: a survey. Genet. Program. Evol. Mach. 11, 365-396 (2010)"
      },
      {
        "ref_id": "70",
        "text": "Mendiburu, A., Santana, R., Lozano, J.A.: Introducing belief propagation in estimation of distribution algorithms: a parallel framework. Tech. Rep. EHU-KAT-IK-11-07, Intelligent Systems Group, University of the Basque Country (2007)"
      },
      {
        "ref_id": "71",
        "text": "Michalski, R.S.: Learnable evolution model: evolutionary processes guided by machine learning. Mach. Learn. 38, 9-40 (2000)"
      },
      {
        "ref_id": "72",
        "text": "Miquélez, T., Bengoetxea, E., Larrañaga, P.: Evolutionary computation based on Bayesian classifiers. Int. J. Appl. Math. Comput. Sci. 14(3), 335-350 (2004)"
      },
      {
        "ref_id": "73",
        "text": "Miquélez, T., Bengoetxea, E., Larrañaga, P.: Evolutionary Bayesian classifier-based optimization in continuous domains. In: 6th International Conference on Simulated Evolution and Learning (SEAL’06). Lecture Notes in Computer Science, vol. 4247, pp. 529-536. Springer, Berlin (2006)"
      },
      {
        "ref_id": "74",
        "text": "Mühlenbein, H., Mahnig, T.: FDA-A scalable evolutionary algorithm for the optimization of additively decomposed functions. Evol. Comput. 7(4), 353-376 (1999)"
      },
      {
        "ref_id": "75",
        "text": "Mühlenbein, H., Mahnig, T., Ochoa Rodríguez, A.: Schemata, distributions and graphical models in evolutionary optimization. J. Heuristics 5(2), 215-247 (1999)"
      },
      {
        "ref_id": "76",
        "text": "Mühlenbein, H., Paaß, G.: From recombination of genes to the estimation of distributions I. Binary parameters. In: 4th International Conference on Parallel Problem Solving from Nature (PPSN IV). Lecture Notes in Computer Science, vol. 1141, pp. 178-187. Springer, Berlin (1996)"
      },
      {
        "ref_id": "77",
        "text": "Očenášek, J., Schwarz, J.: Estimation distribution algorithm for mixed continuous-discrete optimization problems. In: Intelligent Technologies: Theory and Applications: New Trends in Intelligent Technologies, pp. 227-232. IOS Press, Amsterdam (2002)"
      },
      {
        "ref_id": "78",
        "text": "Očenášek, J., Kern, S., Hansen, N., Koumoutsakos, P.: A mixed Bayesian optimization algorithm with variance adaptation. In: Parallel Problem Solving from Nature (PPSN VIII). Lecture Notes in Computer Science, vol. 3242, pp. 352-361. Springer, Berlin (2004)"
      },
      {
        "ref_id": "79",
        "text": "Pearl, J.: Bayesian networks: a model of self-activated memory for evidential reasoning. In: 7th Conference of the Cognitive Science Society, pp. 329-334 (1985)"
      },
      {
        "ref_id": "80",
        "text": "Pelikan, M., Goldberg, D., Lobo, F.: A survey of optimization by building and using probabilistic models. Comput. Optim. Appl. 21(1), 5-20 (2002)"
      },
      {
        "ref_id": "81",
        "text": "Pelikan, M., Mühlenbein, H.: The bivariate marginal distribution algorithm. In: Advances in Soft Computing-Engineering Design and Manufacturing, pp. 521-535 (1999)"
      },
      {
        "ref_id": "82",
        "text": "Pelikan, M., Sastry, K., Cantú-Paz, E. (eds.): Scalable Optimization via Probabilistic Modeling: from Algorithms to Applications. Springer, Berlin (2006)"
      },
      {
        "ref_id": "83",
        "text": "Pelikan, M., Sastry, K., Goldberg, D.: Sporadic model building for efficiency enhancement of the hierarchical BOA. Genet. Program. Evol. Mach. 9(1), 53-84 (2008)"
      },
      {
        "ref_id": "84",
        "text": "Pelikan, M.: Hierarchical Bayesian Optimization Algorithm: Toward a New Generation of Evolutionary Algorithms, 1st edn. Studies in Fuzziness and Soft Computing, vol. 170. Springer, Berlin (2005)"
      },
      {
        "ref_id": "85",
        "text": "Pelikan, M., Goldberg, D.: Genetic algorithms, clustering, and the breaking of symmetry. In: Parallel Problem Solving from Nature (PPSN VI). Lecture Notes in Computer Science, vol. 1917, pp. 385394. Springer, Berlin (2000)"
      },
      {
        "ref_id": "86",
        "text": "Pelikan, M., Goldberg, D.E., Canti-Paz, E.B.: The Bayesian optimization algorithm. In: Conference on Genetic and Evolutionary Computation (GECCO'99), vol. 1, pp. 525-532. Morgan Kaufmann, San Mateo (1999)"
      },
      {
        "ref_id": "87",
        "text": "Pelikan, M., Hartmann, A.: Searching for ground states of Ising spin glasses with hierarchical BOA and cluster exact approximation. In: (Pelikan et al. 2006), pp. 333-349 (2006)"
      },
      {
        "ref_id": "88",
        "text": "Pelikan, M., Sastry, K.: Fitness inheritance in the Bayesian optimization algorithm. In: Conference on Genetic and Evolutionary Computation (GECCO'04). Lecture Notes in Computer Science, vol. 3103, pp. 48-59. Springer, Berlin (2004)"
      },
      {
        "ref_id": "89",
        "text": "Peña, J.M., Lozano, J.A., Larrañaga, P.: Globally multimodal problem optimization via an estimation of distribution algorithm based on unsupervised learning of Bayesian networks. Evol. Comput. 13(1), $43-66$ (2005)"
      },
      {
        "ref_id": "90",
        "text": "Pošík, P.: Preventing premature convergence in a simple EDA via global step size setting. In: 10th International Conference on Parallel Problem Solving from Nature (PPSN X). Lecture Notes in Computer Science, vol. 5199, pp. 549-558. Springer, Berlin (2008)"
      },
      {
        "ref_id": "91",
        "text": "Pošík, P.: BBOB-benchmarking a simple estimation of distribution algorithm with cauchy distribution. In: 11th Annual Conference Companion on Genetic and Evolutionary Computation (GECCO’09), pp. 2309-2314. ACM, New York (2009a)"
      },
      {
        "ref_id": "92",
        "text": "Pošík, P.: Stochastic local search techniques with unimodal continuous distributions: a survey. In: EvoWorkshops on Applications of Evolutionary Computing (EvoWorkshops'09), pp. 685-694. Springer, Berlin (2009b)"
      },
      {
        "ref_id": "93",
        "text": "Rechenberg, I.: Evolutionsstrategie-Optimierung Technischer Systeme nach Prinzipien der Biologischen Evolution. Ph.D. Thesis, reprinted by Fromman-Holzboog (1973)"
      },
      {
        "ref_id": "94",
        "text": "Rissanen, J.: Modeling by shortest data description. Automatica 14(5), 465-471 (1978)"
      },
      {
        "ref_id": "95",
        "text": "Robinson, R.: Counting unlabeled acyclic digraphs. In: Combinatorial Mathematics V. Lecture Notes in Mathematics, vol. 622, pp. 28-43. Springer, Berlin (1977)"
      },
      {
        "ref_id": "96",
        "text": "Salinas-Gutiérrez, R., Hernández-Aguirre, A., Villa-Diharce, E.: Using copulas in estimation of distribution algorithms. In: Advances in Artificial Intelligence (MICAI'09). Lecture Notes in Computer Science, vol. 5845, pp. 658-668. Springer, Berlin (2009)"
      },
      {
        "ref_id": "97",
        "text": "Safustowicz, R.P., Schmidhuber, J.: Probabilistic incremental program evolution: stochastic search through program space. In: 9th European Conference on Machine Learning (ECML'97). Lecture Notes in Computer Science, vol. 1224, pp. 213-220. Springer, Berlin (1997)"
      },
      {
        "ref_id": "98",
        "text": "Santana, R., Bielza, C., Lozano, J., Larrañaga, P.: Mining probabilistic models learned by EDAs in the optimization of multi-objective problems. In: 11th Annual Conference on Genetic and Evolutionary Computation (GECCO'09), pp. 445-452. ACM, New York (2009a)"
      },
      {
        "ref_id": "99",
        "text": "Santana, R., Larrañaga, P., Lozano, J.: Research topics in discrete estimation of distribution algorithms based on factorizations. Memet. Comput. 1(1), 35-54 (2009b)"
      },
      {
        "ref_id": "100",
        "text": "Santana, R., Larrañaga, P., Lozano, J.: Learning factorizations in estimation of distribution algorithms using affinity propagation. Evol. Comput. 18(4), 515-546 (2010)"
      },
      {
        "ref_id": "101",
        "text": "Santana, R.: A Markov network based factorized distribution algorithm for optimization. In: 14th European Conference on Machine Learning (ECML'03). Lecture Notes in Computer Science, vol. 2837, pp. 337-348. Springer, Berlin (2003)"
      },
      {
        "ref_id": "102",
        "text": "Santana, R.: Estimation of distribution algorithms with Kikuchi approximations. Evol. Comput. 13, 67-97 (2005)"
      },
      {
        "ref_id": "103",
        "text": "Santana, R.: Estimation of distribution algorithms: from available implementations to potential developments. In: 13th Annual Conference Companion on Genetic and Evolutionary Computation (GECCO'11), pp. 679-686. ACM, New York (2011)"
      },
      {
        "ref_id": "104",
        "text": "Santana, R., Bielza, C., Larrañaga, P., Lozano, J.A., Echegoyen, C., Mendiburu, A., Armañanzas, R., Shakya, S.: Mateda-2.0: estimation of distribution algorithms in MATLAB. J. Stat. Softw. 35(7), $1-30(2010)$"
      },
      {
        "ref_id": "105",
        "text": "Sastry, K., Goldberg, D.E.: Probabilistic model building and competent genetic programming. In: Genetic Programming Theory and Practice, pp. 205-220. Kluwer Academic, Norwell (2003). Chap. 13"
      },
      {
        "ref_id": "106",
        "text": "Sastry, K., Pelikan, M., Goldberg, D.: Efficiency enhancement of genetic algorithms via building-blockwise fitness estimation. In: IEEE Congress on Evolutionary Computation (CEC'04), vol. 1, pp. 720727 (2004)"
      },
      {
        "ref_id": "107",
        "text": "Schwarz, G.: Estimating the dimension of a model. Ann. Stat. 6(2), 461-464 (1978)"
      },
      {
        "ref_id": "108",
        "text": "Sebag, M., Ducoulombier, A.: Extending population-based incremental learning to continuous search spaces. In: 5th International Conference on Parallel Problem Solving from Nature (PPSN V). Lecture Notes in Computer Science, vol. 1498, pp. 418-427. Springer, Berlin (1998)"
      },
      {
        "ref_id": "109",
        "text": "Shakya, S.: DEUM: a framework for an estimation of distribution algorithm based on Markov random fields. Ph.D. Thesis, The Robert Gordon University (2006)"
      },
      {
        "ref_id": "110",
        "text": "Shakya, S., Santana, R. (eds.): Markov Networks in Evolutionary Computation. Adaptation, Learning, and Optimization, vol. 14. Springer, Berlin (2012)"
      },
      {
        "ref_id": "111",
        "text": "Shan, Y., McKay, R., Essam, D., Abbass, H.: a survey of probabilistic model building genetic programming. In: (Pelikan et al. 2006), pp. 121-160 (2006)"
      },
      {
        "ref_id": "112",
        "text": "Spirtes, P., Glymour, C.: An algorithm for fast recovery of sparse causal graphs. Soc. Sci. Comput. Rev. 9(1), 62-72 (1991)"
      },
      {
        "ref_id": "113",
        "text": "Spirtes, P., Glymour, C., Scheines, R.: Causation, Prediction, and Search, 2nd edn. MIT Press, Cambridge (2001)"
      },
      {
        "ref_id": "114",
        "text": "Sun, J., Zhang, Q., Tsang, E.: DE/EDA: a new evolutionary algorithm for global optimization. Inf. Sci. 169(3-4), 249-262 (2005)"
      },
      {
        "ref_id": "115",
        "text": "Thierens, D.: The linkage tree genetic algorithm. In: Parallel Problem Solving from Nature (PPSN XI). Lecture Notes in Computer Science, vol. 6238, pp. 264-273. Springer, Berlin (2011)"
      },
      {
        "ref_id": "116",
        "text": "Tsutsui, S., Pelikan, M., Goldberg, D.: Node histogram vs. edge histogram: a comparison of pmbgas in permutation domains. Tech. Rep. 2006009, Missouri Estimation of Distribution Algorithms Laboratory (MEDAL), Department of Mathematics and Computer Science, University of Missouri-St. Louis (2006)"
      },
      {
        "ref_id": "117",
        "text": "Tsutsui, S.: Probabilistic model-building genetic algorithms in permutation representation domain using edge histogram. In: Parallel Problem Solving from Nature (PPSN VII). Lecture Notes in Computer Science, vol. 2439, pp. 224-233. Springer, Berlin (2002)"
      },
      {
        "ref_id": "118",
        "text": "Tsutsui, S., Pelikan, M., Goldberg, D.E.: Evolutionary algorithm using marginal histogram in continuous domain. In: Optimization by Building and Using Probabilistic Models (OBUPM) WorkshopConference on Genetic and Evolutionary Computation (GECCO'01), pp. 230-233 (2001)"
      },
      {
        "ref_id": "119",
        "text": "Valdez-Peña, S.I., Hernández-Aguirre, A., Botello-Rionda, S.: Approximating the search distribution to the selection distribution in EDAs. In: 11th Annual Conference on Genetic and Evolutionary Computation (GECCO’09), pp. 461-468. ACM, New York (2009)"
      },
      {
        "ref_id": "120",
        "text": "Wang, L.F., Zeng, J.C.: Estimation of distribution algorithm based on copula theory. In: Exploitation of Linkage Learning in Evolutionary Algorithms. Evolutionary Learning and Optimization, vol. 3, pp. 139-162. Springer, Berlin (2010)"
      },
      {
        "ref_id": "121",
        "text": "Wang, L.F., Zeng, J.C., Hong, Y.: Estimation of distribution algorithm based on Archimedean copulas. In: First ACM/SIGEVO Summit on Genetic and Evolutionary Computation (GEC'09), pp. 993-996. ACM, New York (2009)"
      },
      {
        "ref_id": "122",
        "text": "Wang, X., Wang, H.: Evolutionary optimization with Markov random field prior. IEEE Trans. Evol. Comput. 8(6), 567-579 (2004)"
      },
      {
        "ref_id": "123",
        "text": "Weise, T., Niemczyk, S., Chiong, R., Wan, M.: A framework for multi-model EDAs with model recombination. In: Applications of Evolutionary Computation. Lecture Notes in Computer Science, vol. 6624, pp. 304-313. Springer, Berlin (2011)"
      },
      {
        "ref_id": "124",
        "text": "Xiao, J., Yan, Y., Zhang, J.: HPBILc: a histogram-based EDA for continuous optimization. Appl. Math. Comput. 215(3), 973-982 (2009)"
      },
      {
        "ref_id": "125",
        "text": "Yanai, K., Iba, H.: Estimation of distribution programming based on Bayesian network. In: IEEE Congress on Evolutionary Computation (CEC'03), vol. 3, pp. 1618-1625 (2003)"
      },
      {
        "ref_id": "126",
        "text": "Zhang, Q.: On stability of fixed points of limit models of univariate marginal distribution algorithm and factorized distribution algorithm. IEEE Trans. Evol. Comput. 8(1), 80-93 (2004)"
      },
      {
        "ref_id": "127",
        "text": "Zhang, Q., Zhou, A., Jin, Y.: RM-MEDA: a regularity model based multiobjective estimation of distribution algorithm. IEEE Trans. Evol. Comput. 12(1), 41-63 (2008)"
      }
    ],
    "reference_count": 127,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": null,
      "table_title": null,
      "headers": [
        "$X_{1}$",
        "1",
        "1",
        "1",
        "2",
        "2",
        "2"
      ],
      "rows": [
        [
          "$X_{2}$",
          1,
          2,
          3,
          1,
          2,
          3
        ],
        [
          "$\\mathbf{P}\\left(X_{4}=1 \\mid X_{1}, X_{2}\\right)$",
          "$\\theta_{411}$",
          "$\\theta_{421}$",
          "$\\theta_{433}$",
          "$\\theta_{441}$",
          "$\\theta_{451}$",
          "$\\theta_{461}$"
        ],
        [
          "$\\mathbf{P}\\left(X_{4}=2 \\mid X_{1}, X_{2}\\right)$",
          "$\\theta_{412}$",
          "$\\theta_{422}$",
          "$\\theta_{432}$",
          "$\\theta_{442}$",
          "$\\theta_{452}$",
          "$\\theta_{462}$"
        ],
        [
          "$\\mathbf{P}\\left(X_{4}=3 \\mid X_{1}, X_{2}\\right)$",
          "$\\theta_{413}$",
          "$\\theta_{423}$",
          "$\\theta_{433}$",
          "$\\theta_{443}$",
          "$\\theta_{453}$",
          "$\\theta_{463}$"
        ],
        [
          "$\\mathbf{P}\\left(X_{4}=4 \\mid X_{1}, X_{2}\\right)$",
          "$\\theta_{414}$",
          "$\\theta_{424}$",
          "$\\theta_{434}$",
          "$\\theta_{444}$",
          "$\\theta_{454}$",
          "$\\theta_{464}$"
        ],
        [
          "$\\mathbf{P}\\left(X_{4}=5 \\mid X_{1}, X_{2}\\right)$",
          "$\\theta_{415}$",
          "$\\theta_{425}$",
          "$\\theta_{435}$",
          "$\\theta_{445}$",
          "$\\theta_{455}$",
          "$\\theta_{465}$"
        ]
      ],
      "row_count": 6,
      "column_count": 7
    },
    {
      "table_number": null,
      "table_title": null,
      "headers": [
        "$\\boldsymbol{X}_{\\mathbf{1}}$",
        "$\\boldsymbol{X}_{\\mathbf{2}}$",
        "$\\boldsymbol{X}_{\\mathbf{4}}$",
        "$\\boldsymbol{\\Phi}\\left(\\boldsymbol{X}_{\\mathbf{1}}, \\boldsymbol{X}_{\\mathbf{2}}, \\boldsymbol{X}_{\\mathbf{4}}\\right)$"
      ],
      "rows": [
        [
          1,
          1,
          1,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{1}}$"
        ],
        [
          1,
          2,
          2,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{2}}$"
        ],
        [
          1,
          3,
          1,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{3}}$"
        ],
        [
          1,
          1,
          2,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{4}}$"
        ],
        [
          1,
          2,
          1,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{5}}$"
        ],
        [
          1,
          3,
          2,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{6}}$"
        ],
        [
          2,
          1,
          1,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{7}}$"
        ],
        [
          2,
          2,
          2,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{8}}$"
        ],
        [
          2,
          3,
          1,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{9}}$"
        ],
        [
          2,
          1,
          2,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{1 0}}$"
        ],
        [
          2,
          2,
          1,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{1 1}}$"
        ],
        [
          2,
          3,
          2,
          "$\\Phi_{\\mathbf{1}, \\mathbf{2}, \\mathbf{4}-\\mathbf{1 2}}$"
        ]
      ],
      "row_count": 12,
      "column_count": 4
    },
    {
      "table_number": "1",
      "table_title": "Table 1 Full name of EDAs and the models they use. Discrete EDAs are shown on a white, continuous on a green and mixed discrete-continuous on a blue background, respectively (Color table online)",
      "headers": [
        "Algorithm",
        "Complete name",
        "Model used"
      ],
      "rows": [
        [
          "Univariate",
          "",
          ""
        ],
        [
          "PBIL",
          "Population Based Incremental Learning",
          "-"
        ],
        [
          "UMDA",
          "Univariate Marginal Distribution Algorithm",
          "-"
        ],
        [
          "$\\mathrm{IBIC}_{\\mathrm{C}}$",
          "Continuous CBIL",
          "-"
        ],
        [
          "cGA",
          "Compact Genetic Algorithm",
          "-"
        ],
        [
          "$\\mathrm{IMDA}_{\\mathrm{C}}$",
          "Continuous UMDA",
          "-"
        ],
        [
          "Bivariate",
          "",
          ""
        ],
        [
          "HEDA",
          "Histogram-based EDA",
          "Marginal Histograms"
        ],
        [
          "MIMIC",
          "Mutual Information Maximizing Input Clustering",
          "Chain"
        ],
        [
          "COMIT",
          "Combining Optimizers with Mutual Information Trees",
          "Tree"
        ],
        [
          "BMDA",
          "Bivariate Marginal Distribution Algorithm",
          "Forest"
        ],
        [
          "MIMIC $\\mathcal{C}$",
          "Continuous MIMIC",
          "Chain"
        ],
        [
          "TEDA",
          "Copula-based EDA",
          "Copula Functions"
        ],
        [
          "Multivariate",
          "",
          ""
        ],
        [
          "FDA",
          "Factorized Distribution Algorithm",
          "Factor Graph"
        ],
        [
          "EBNA",
          "Estimation of Bayesian Network Algorithm",
          "Bayesian Network"
        ],
        [
          "BOA",
          "Bayesian Optimization Algorithm",
          "Bayesian Network"
        ],
        [
          "MAIA",
          "Estimation of Gaussian Network Algorithm",
          "Gaussian Bayesian Network"
        ],
        [
          "IDEA",
          "Iterated Density Estimation Evolutionary Algorithm",
          "Gaussian Markov Network"
        ],
        [
          "EMNA",
          "Estimation of Multivariate Normal distribution Algorithm",
          "Gaussian Markov Network"
        ],
        [
          "MBOA",
          "Mixed BOA",
          "Decision Graphs"
        ],
        [
          "MN-FDA",
          "Markov Network based FDA",
          "Markov Network"
        ],
        [
          "MOPEDA",
          "MultiObjective Parzan-based EDA",
          "Mixture of Kernels"
        ],
        [
          "iBOA",
          "Real-coded BOA",
          "Gaussian Bayesian Network"
        ],
        [
          "EBCOA",
          "Evolutionary Bayesian Classifier based Optimization Algorithm",
          "Bayesian Network Classifiers"
        ],
        [
          "MN-EDA",
          "Markov Network EDA",
          "Markov Network"
        ],
        [
          "UEBNA",
          "Unsupervised EBNA",
          "Bayesian Network"
        ],
        [
          "EcGA",
          "Extended cGA",
          "Marginal Product Model"
        ],
        [
          "HOMMEDA",
          "Boosting Gaussian Mixture Model based EDA",
          "Mixture of Gaussian Markov Networks"
        ],
        [
          "DEUM",
          "Distribution Estimation Using Markov Random Fields",
          "Markov Network"
        ],
        [
          "MAOPE",
          "Regression Markov ATlog with the Estimation Coefficient",
          "Linear-Markov Recurrence"
        ],
        [
          "MARLEDA",
          "Markovian Learning EDA",
          "Markov Network"
        ],
        [
          "EDNA",
          "Estimation of Dependency Network Algorithm",
          "Dependency Network"
        ],
        [
          "EN-MEDA",
          "Regulatory Model-based Multiobjective EDA",
          "Mixture of hyperplanes"
        ],
        [
          "EEDA",
          "Kernel density-based EDA",
          "Mixture of Gaussian Kernels"
        ],
        [
          "AffEDA",
          "Affinity propagation EDA",
          "Marginal Product Model"
        ],
        [
          "MB-GNG",
          "Model Building Growing Neural Gas",
          "Mixture of Gaussian Markov Networks"
        ],
        [
          "LTGA",
          "Linkage Tree GA",
          "Hierarchical Dependency Tree"
        ],
        [
          "K-BN-EDA",
          "Joint GBN-based EDA",
          "Gaussian Bayesian Network"
        ]
      ],
      "row_count": 39,
      "column_count": 3
    }
  ]
}