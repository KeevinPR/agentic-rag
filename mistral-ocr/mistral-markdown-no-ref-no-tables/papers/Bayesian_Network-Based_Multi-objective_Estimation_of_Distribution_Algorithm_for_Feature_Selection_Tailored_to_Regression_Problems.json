{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2024/Bayesian Network-Based Multi-objective Estimation of Distribution Algorithm for Feature Selection Tailored to Regression Problems.md",
    "filename": "Bayesian Network-Based Multi-objective Estimation of Distribution Algorithm for Feature Selection Tailored to Regression Problems.md",
    "title": "Bayesian Network-Based Multi-objective Estimation of Distribution Algorithm for Feature Selection Tailored to Regression Problems",
    "year": "2024"
  },
  "references": {
    "header": "# References",
    "content": "1. Agrawal, P., Abutarboush, H.F., Ganesh, T., Mohamed, A.W.: Metaheuristic algorithms on feature selection: a survey of one decade of research (2009-2019). IEEE Access 9, 26766-26791 (2021). https://doi.org/10.1109/ACCESS.2021.3056407\n2. Blank, J., Deb, K.: Pymoo: multi-objective optimization in Python. IEEE Access 8, 89497-89509 (2020). https://doi.org/10.1109/ACCESS.2020.2990567\n3. Castro, P.A., Von Zuben, F.J.: Multi-objective feature selection using a Bayesian artificial immune system. Int. J. Intell. Comput. Cybern. 3(2), 235-256 (2010). https://doi.org/10.1108/17563781011049188\n4. Collette, Y., Siarry, P.: Multiobjective Optimization. Principles and Case Studies. Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-662-08883-8\n5. Cormen, T.H., Leiserson, C.E., Rivest, R.L., Stein, C.: Introduction to Algorithms. MIT Press (2002)\n6. Dash, M., Liu, H.: Feature selection for classification. Intell. Data Anal. 1(1-4), 131-156 (1997). https://doi.org/10.1016/S1088-467X(97)00008-5. http:// linkinghub.elsevier.com/retrieve/pii/S1088467X97000085\n7. Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algorithm: NSGA-II. Technical report 2 (2002)\n8. Dhal, P., Azad, C.: A comprehensive survey on feature selection in the various fields of machine learning. Appl. Intell. 52(4), 4543-4581 (2022). https://doi.org/ $10.1007 / \\mathrm{s} 10489-021-02550-9$\n9. Guyon, I., De, A.M.: An introduction to variable and feature selection André Elisseeff. Technical report (2003)\n10. Hamdani, T.M., Won, J.M., Alimi, A.M., Karray, F.: LNCS 4431 - multi-objective feature selection with NSGA II. Technical report (2007)\n11. Inza, I., Larrañaga, P., Etxeberria, R., Sierra, B.: Feature subset selection by Bayesian network-based optimization. Technical report (2000)\n12. Jiao, R., Nguyen, B.H., Xue, B., Zhang, M.: A survey on evolutionary multiobjective feature selection in classification: approaches, applications, and challenges. IEEE Trans. Evol. Comput. (2023). https://doi.org/10.1109/TEVC.2023.3292527. https://ieeexplore.ieee.org/document/10173647/\n13. Kitson, N.K., Constantinou, A.C., Guo, Z., Liu, Y., Chobtham, K.: A survey of Bayesian Network structure learning. Artif. Intell. Rev. 56, 8721-8814 (2023). https://doi.org/10.1007/s10462-022-10351-w\n14. Larragaña, P., Lozano, J.: Genetic algorithms and evolutionary computation. In: OmeGA: A Competent Genetic Algorithm for Solving Permutation and Scheduling Problems (2002)\n15. Markelle, K., Rachel, L., Kolby, N.: The UCI Machine Learning Repository. https://archive.ics.uci.edu\n16. Maza, S., Touahria, M.: Feature selection for intrusion detection using new multiobjective estimation of distribution algorithms. Appl. Intell. 49(12), 4237-4257 (2019). https://doi.org/10.1007/s10489-019-01503-7\n\n17. Mühlenbein, H.: The equation for response to selection and its use for prediction. Evol. Comput. 5(3), 303-346 (1997). https://doi.org/10.1162/EVCO.1997.5.3.303. https://pubmed.ncbi.nlm.nih.gov/10021762/\n18. Panichella, A.: An adaptive evolutionary algorithm based on non-Euclidean geometry for many-objective optimization. In: Proceedings of the 2019 Genetic and Evolutionary Computation Conference, GECCO 2019, July 2019, pp. 595-603. Association for Computing Machinery, Inc. (2019). https://doi.org/10.1145/3321707. 3321839\n19. Rehman, A.U., Nadeem, A., Malik, M.Z.: Fair feature subset selection using multiobjective genetic algorithm. In: Proceedings of the 2022 Genetic and Evolutionary Computation Conference, GECCO 2022 Companion, July 2022, pp. 360-363. Association for Computing Machinery, Inc. (2022). https://doi.org/10.1145/3520304. 3529061\n20. Soliman, O.S., Rassem, A.: Correlation based feature selection using quantum bio inspired estimation of distribution algorithm. Technical report (2012)\n21. Spolaör, N., Lorena, A.C., Lee, H.D.: Multi-objective genetic algorithm evaluation in feature selection. In: Takahashi, R.H.C., Deb, K., Wanner, E.F., Greco, S. (eds.) EMO 2011. LNCS, vol. 6576, pp. 462-476. Springer, Heidelberg (2011). https:// doi.org/10.1007/978-3-642-19893-9_32\n22. Xue, B., Zhang, M., Browne, W.N.: Particle swarm optimization for feature selection in classification: a multi-objective approach. IEEE Trans. Cybern. 43(6), 1656-1671 (2013). https://doi.org/10.1109/TSMCB.2012.2227469\n23. Xue, B., Zhang, M., Browne, W.N., Yao, X.: A survey on evolutionary computation approaches to feature selection. IEEE Trans. Evol. Comput. 20(4), 606-626 (2016). https://doi.org/10.1109/TEVC.2015.2504420\n24. Zhang, Y., Gong, D., Gao, X., Tian, T., Sun, X.: Binary differential evolution with self-learning for multi-objective feature selection. Inf. Sci. 507, 67-85 (2020). https://doi.org/10.1016/J.INS.2019.08.040",
    "references": [
      {
        "ref_id": "1",
        "text": "Agrawal, P., Abutarboush, H.F., Ganesh, T., Mohamed, A.W.: Metaheuristic algorithms on feature selection: a survey of one decade of research (2009-2019). IEEE Access 9, 26766-26791 (2021). https://doi.org/10.1109/ACCESS.2021.3056407"
      },
      {
        "ref_id": "2",
        "text": "Blank, J., Deb, K.: Pymoo: multi-objective optimization in Python. IEEE Access 8, 89497-89509 (2020). https://doi.org/10.1109/ACCESS.2020.2990567"
      },
      {
        "ref_id": "3",
        "text": "Castro, P.A., Von Zuben, F.J.: Multi-objective feature selection using a Bayesian artificial immune system. Int. J. Intell. Comput. Cybern. 3(2), 235-256 (2010). https://doi.org/10.1108/17563781011049188"
      },
      {
        "ref_id": "4",
        "text": "Collette, Y., Siarry, P.: Multiobjective Optimization. Principles and Case Studies. Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-662-08883-8"
      },
      {
        "ref_id": "5",
        "text": "Cormen, T.H., Leiserson, C.E., Rivest, R.L., Stein, C.: Introduction to Algorithms. MIT Press (2002)"
      },
      {
        "ref_id": "6",
        "text": "Dash, M., Liu, H.: Feature selection for classification. Intell. Data Anal. 1(1-4), 131-156 (1997). https://doi.org/10.1016/S1088-467X(97)00008-5. http:// linkinghub.elsevier.com/retrieve/pii/S1088467X97000085"
      },
      {
        "ref_id": "7",
        "text": "Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algorithm: NSGA-II. Technical report 2 (2002)"
      },
      {
        "ref_id": "8",
        "text": "Dhal, P., Azad, C.: A comprehensive survey on feature selection in the various fields of machine learning. Appl. Intell. 52(4), 4543-4581 (2022). https://doi.org/ $10.1007 / \\mathrm{s} 10489-021-02550-9$"
      },
      {
        "ref_id": "9",
        "text": "Guyon, I., De, A.M.: An introduction to variable and feature selection André Elisseeff. Technical report (2003)"
      },
      {
        "ref_id": "10",
        "text": "Hamdani, T.M., Won, J.M., Alimi, A.M., Karray, F.: LNCS 4431 - multi-objective feature selection with NSGA II. Technical report (2007)"
      },
      {
        "ref_id": "11",
        "text": "Inza, I., Larrañaga, P., Etxeberria, R., Sierra, B.: Feature subset selection by Bayesian network-based optimization. Technical report (2000)"
      },
      {
        "ref_id": "12",
        "text": "Jiao, R., Nguyen, B.H., Xue, B., Zhang, M.: A survey on evolutionary multiobjective feature selection in classification: approaches, applications, and challenges. IEEE Trans. Evol. Comput. (2023). https://doi.org/10.1109/TEVC.2023.3292527. https://ieeexplore.ieee.org/document/10173647/"
      },
      {
        "ref_id": "13",
        "text": "Kitson, N.K., Constantinou, A.C., Guo, Z., Liu, Y., Chobtham, K.: A survey of Bayesian Network structure learning. Artif. Intell. Rev. 56, 8721-8814 (2023). https://doi.org/10.1007/s10462-022-10351-w"
      },
      {
        "ref_id": "14",
        "text": "Larragaña, P., Lozano, J.: Genetic algorithms and evolutionary computation. In: OmeGA: A Competent Genetic Algorithm for Solving Permutation and Scheduling Problems (2002)"
      },
      {
        "ref_id": "15",
        "text": "Markelle, K., Rachel, L., Kolby, N.: The UCI Machine Learning Repository. https://archive.ics.uci.edu"
      },
      {
        "ref_id": "16",
        "text": "Maza, S., Touahria, M.: Feature selection for intrusion detection using new multiobjective estimation of distribution algorithms. Appl. Intell. 49(12), 4237-4257 (2019). https://doi.org/10.1007/s10489-019-01503-7"
      },
      {
        "ref_id": "17",
        "text": "Mühlenbein, H.: The equation for response to selection and its use for prediction. Evol. Comput. 5(3), 303-346 (1997). https://doi.org/10.1162/EVCO.1997.5.3.303. https://pubmed.ncbi.nlm.nih.gov/10021762/"
      },
      {
        "ref_id": "18",
        "text": "Panichella, A.: An adaptive evolutionary algorithm based on non-Euclidean geometry for many-objective optimization. In: Proceedings of the 2019 Genetic and Evolutionary Computation Conference, GECCO 2019, July 2019, pp. 595-603. Association for Computing Machinery, Inc. (2019). https://doi.org/10.1145/3321707. 3321839"
      },
      {
        "ref_id": "19",
        "text": "Rehman, A.U., Nadeem, A., Malik, M.Z.: Fair feature subset selection using multiobjective genetic algorithm. In: Proceedings of the 2022 Genetic and Evolutionary Computation Conference, GECCO 2022 Companion, July 2022, pp. 360-363. Association for Computing Machinery, Inc. (2022). https://doi.org/10.1145/3520304. 3529061"
      },
      {
        "ref_id": "20",
        "text": "Soliman, O.S., Rassem, A.: Correlation based feature selection using quantum bio inspired estimation of distribution algorithm. Technical report (2012)"
      },
      {
        "ref_id": "21",
        "text": "Spolaör, N., Lorena, A.C., Lee, H.D.: Multi-objective genetic algorithm evaluation in feature selection. In: Takahashi, R.H.C., Deb, K., Wanner, E.F., Greco, S. (eds.) EMO 2011. LNCS, vol. 6576, pp. 462-476. Springer, Heidelberg (2011). https:// doi.org/10.1007/978-3-642-19893-9_32"
      },
      {
        "ref_id": "22",
        "text": "Xue, B., Zhang, M., Browne, W.N.: Particle swarm optimization for feature selection in classification: a multi-objective approach. IEEE Trans. Cybern. 43(6), 1656-1671 (2013). https://doi.org/10.1109/TSMCB.2012.2227469"
      },
      {
        "ref_id": "23",
        "text": "Xue, B., Zhang, M., Browne, W.N., Yao, X.: A survey on evolutionary computation approaches to feature selection. IEEE Trans. Evol. Comput. 20(4), 606-626 (2016). https://doi.org/10.1109/TEVC.2015.2504420"
      },
      {
        "ref_id": "24",
        "text": "Zhang, Y., Gong, D., Gao, X., Tian, T., Sun, X.: Binary differential evolution with self-learning for multi-objective feature selection. Inf. Sci. 507, 67-85 (2020). https://doi.org/10.1016/J.INS.2019.08.040"
      }
    ],
    "reference_count": 24,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "1",
      "table_title": "Probability distribution of the root vertex $P\\left(V_{r}\\right)$",
      "headers": [
        "$V_{r}$",
        "$P\\left(V_{r}\\right)$"
      ],
      "rows": [
        [
          0,
          "$F\\left(V_{r}=0\\right) /\\left(F\\left(V_{r}=0\\right)+F\\left(V_{r}=1\\right)\\right)$"
        ],
        [
          1,
          "$F\\left(V_{r}=1\\right) /\\left(F\\left(V_{r}=0\\right)+F\\left(V_{r}=1\\right)\\right)$"
        ]
      ],
      "row_count": 2,
      "column_count": 2
    },
    {
      "table_number": "2",
      "table_title": "Probability distribution $P\\left(V_{j} \\mid V_{i}\\right)$",
      "headers": [
        "$V_{i}$",
        "$V_{j}$",
        "$P\\left(V_{j} \\mid V_{i}\\right)$"
      ],
      "rows": [
        [
          0,
          0,
          "$F\\left(V_{i}=0, V_{j}=0\\right) / F\\left(V_{i}=0\\right)$"
        ],
        [
          0,
          1,
          "$F\\left(V_{i}=0, V_{j}=1\\right) / F\\left(V_{i}=0\\right)$"
        ],
        [
          1,
          0,
          "$F\\left(V_{i}=1, V_{j}=0\\right) / F\\left(V_{i}=1\\right)$"
        ],
        [
          1,
          1,
          "$F\\left(V_{i}=1, V_{j}=1\\right) / F\\left(V_{i}=1\\right)$"
        ]
      ],
      "row_count": 4,
      "column_count": 3
    },
    {
      "table_number": "3",
      "table_title": "Hyper-parameters of NSGA II and AGEMOEA",
      "headers": [
        "Algorithm",
        "Population <br> size N",
        "Max <br> Iterations",
        "Sampling",
        "Crossover",
        "Mutation"
      ],
      "rows": [
        [
          "NSGA II",
          50,
          10,
          "Binary <br> random <br> sampling",
          "Two point <br> crossover",
          "Bitflip <br> mutation"
        ],
        [
          "AGEMOEA",
          50,
          10,
          "Binary <br> random <br> sampling",
          "Two point <br> crossover",
          "Bitflip <br> mutation"
        ]
      ],
      "row_count": 2,
      "column_count": 6
    },
    {
      "table_number": "4",
      "table_title": "Hyper-parameters of EDA Bernoulli and EDA Bayesian Network",
      "headers": [
        "Algorithm",
        "Population <br> size $N$",
        "Max <br> iterations",
        "Individuals <br> selected $M$",
        "Probability <br> distribution"
      ],
      "rows": [
        [
          "EDA Bernoulli",
          50,
          5,
          25,
          "Bernoulli"
        ],
        [
          "EDA Bayesian Network",
          50,
          5,
          25,
          "Bayesian <br> Network"
        ]
      ],
      "row_count": 2,
      "column_count": 5
    },
    {
      "table_number": "5",
      "table_title": "Datasets",
      "headers": [
        "Name",
        "Before processing",
        "",
        "After processing",
        ""
      ],
      "rows": [
        [
          "",
          "\\# instances",
          "\\# features",
          "\\# instances",
          "\\# features"
        ],
        [
          "Concrete Compressive Strength",
          1030,
          8,
          1030,
          8
        ],
        [
          "Forest Fires",
          517,
          12,
          517,
          12
        ],
        [
          "Student Performance Math",
          395,
          32,
          395,
          45
        ],
        [
          "YearPredictionMSD",
          515345,
          90,
          515345,
          90
        ],
        [
          "Communities and crime",
          1993,
          127,
          1993,
          100
        ]
      ],
      "row_count": 6,
      "column_count": 5
    },
    {
      "table_number": "6",
      "table_title": "Comparison of time and number of evaluations between algorithms for all datasets. Bold numbers correspond to the smallest values in time or number of evaluations.",
      "headers": [
        "Algorithm",
        "Concrete <br> Compressive",
        "",
        "Forest Fires",
        "",
        "Student <br> Performance",
        "",
        "Year <br> Prediction <br> MSD",
        "",
        "Communities <br> Crime",
        ""
      ],
      "rows": [
        [
          "",
          "Time",
          "Eval",
          "Time",
          "Eval",
          "Time",
          "Eval",
          "Time",
          "Eval",
          "Time",
          "Eval"
        ],
        [
          "AGEMOEA",
          0.39,
          157.96,
          0.71,
          330.55,
          0.97,
          463.41,
          384.15,
          439.37,
          4.67,
          424.49
        ],
        [
          "NSGA-II",
          0.47,
          172.35,
          0.73,
          366.89,
          0.91,
          431.24,
          211.57,
          312.5,
          1.52,
          "$\\mathbf{2 9 8 . 9 0}$"
        ],
        [
          "EDA Bernoulli",
          0.28,
          122.79,
          0.42,
          241.6,
          "$\\mathbf{0 . 5 3}$",
          299.99,
          211.28,
          300.0,
          "$\\mathbf{1 . 3 6}$",
          300.0
        ],
        [
          "EDA BayNet",
          "$\\mathbf{0 . 2 5}$",
          "$\\mathbf{8 8 . 1 0}$",
          "$\\mathbf{0 . 3 2}$",
          "$\\mathbf{1 8 2 . 4 9}$",
          0.57,
          "$\\mathbf{2 9 5 . 6 4}$",
          "$\\mathbf{1 3 2 . 4 5}$",
          "$\\mathbf{2 9 4 . 3 6}$",
          1.5,
          299.97
        ]
      ],
      "row_count": 5,
      "column_count": 11
    }
  ]
}