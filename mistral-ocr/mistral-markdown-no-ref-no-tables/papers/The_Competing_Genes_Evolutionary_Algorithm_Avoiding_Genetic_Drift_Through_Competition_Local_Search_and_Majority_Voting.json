{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2023/The Competing Genes Evolutionary Algorithm Avoiding Genetic Drift Through Competition Local Search and Majority Voting.md",
    "filename": "The Competing Genes Evolutionary Algorithm Avoiding Genetic Drift Through Competition Local Search and Majority Voting.md",
    "title": "The Competing Genes Evolutionary Algorithm Avoiding Genetic Drift Through Competition Local Search and Majority Voting",
    "year": "2023"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] G. R. Harik, F. G. Lobo, and D. E. Goldberg, \"The compact genetic algorithm,\" IEEE Trans. Evol. Comput., vol. 3, no. 4, pp. 287-297, Nov. 1999.\n[2] H. Mühlenbein and G. Paall, \"From recombination of genes to the estimation of distributions I. Binary parameters,\" in Proc. Int. Conf. Parallel Problem Solving Nat., 1996, pp. 178-187.\n[3] S. Baluja, \"Population-based incremental learning. A method for integrating genetic search based function optimization and competitive learning,\" Dept. Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-94-163, 1994.\n[4] F. Neumann, D. Sudholt, and C. Witt, \"A few ants are enough: ACO with iteration-best update,\" in Proc. 12th Annu. Conf. Genet. Evol. Comput., 2010, pp. 63-70.\n[5] M. Pelikan, M. W. Hauschild, and F. G. Lobo, \"Estimation of distribution algorithms,\" in Springer Handbook of Computational Intelligence. Berlin, Germany: Springer, 2015, pp. 899-928.\n[6] B. Doerr and W. Zheng, \"Sharp bounds for genetic drift in estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 24, no. 6, pp. 1140-1149, Dec. 2020.\n[7] M. S. Krejca, \"Theoretical analyses of univariate estimation-of-distribution algorithms,\" Ph.D. dissertation, Dept. Digit. Eng., Universität Potsdam, Brandenburg, Germany, 2019.\n[8] T. Friedrich, T. Kötzing, and M. S. Krejca, \"EDAs cannot be balanced and stable,\" in Proc. Genet. Evol. Comput. Conf., 2016, pp. 1139-1146.\n[9] J. L. Shapiro, \"Drift and scaling in estimation of distribution algorithms,\" Evol. Comput., vol. 13, no. 1, pp. 99-123, Mar. 2005.\n[10] B. Doerr and M. S. Krejca, \"The univariate marginal distribution algorithm copes well with deception and epistasis,\" Evol. Comput., vol. 29, no. 4, pp. 543-563, Dec. 2021.\n[11] P. K. Lehre and P. T. H. Nguyen, \"On the limitations of the univariate marginal distribution algorithm to deception and where bivariate EDAs might help,\" in Proc. 15th ACM/SIGEVO Conf. Found. Genet. Algorithms, 2019, pp. 154-168.\n[12] D.-C. Dang, P. K. Lehre, and P. T. H. Nguyen, \"Level-based analysis of the univariate marginal distribution algorithm,\" Algorithmica, vol. 81, no. 2, pp. 668-702, 2019.\n[13] C. Witt, \"Upper bounds on the running time of the univariate marginal distribution algorithm on OneMax,\" Algorithmica, vol. 81, no. 2, pp. 632-667, 2019.\n[14] M. S. Krejca and C. Witt, \"Lower bounds on the run time of the univariate marginal distribution algorithm on OneMax,\" Theor. Comput. Sci., vol. 832, pp. 143-165, Sep. 2020.\n[15] D. Sudholt and C. Witt, \"On the choice of the update strength in estimation-of-distribution algorithms and ant colony optimization,\" Algorithmica, vol. 81, no. 4, pp. 1450-1489, 2019.\n[16] J. Lengler, D. Sudholt, and C. Witt, \"Medium step sizes are harmful for the compact genetic algorithm,\" in Proc. Genet. Evol. Comput. Conf., 2018, pp. 1499-1506.\n[17] J. Lengler, D. Sudholt, and C. Witt, \"The complex parameter landscape of the compact genetic algorithm,\" Algorithmica, vol. 83, no. 4, pp. 1096-1137, 2021.\n[18] B. Doerr and C. Doerr, \"Theory of parameter control for discrete black-box optimization: Provable performance gains through dynamic parameter choices,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer Int., 2020, pp. 271-321.\n[19] M. Pelikan and T.-K. Lin, \"Parameter-less hierarchical BOA,\" in Proc. Genet. Evol. Comput. Conf., 2004, pp. 24-35.\n[20] B. Doerr, \"The runtime of the compact genetic algorithm on jump functions,\" Algorithmica, vol. 83, no. 10, pp. 3059-3107, 2021.\n[21] B. Doerr and W. Zheng, \"From understanding genetic drift to a smartrestart parameter-less compact genetic algorithm,\" in Proc. Genet. Evol. Comput. Conf., 2020, pp. 805-813.\n[22] H. Mühlenbein, \"The equation for response to selection and its use for prediction,\" Evol. Comput., vol. 5, no. 3, pp. 303-346, Sep. 1997.\n[23] B. Doerr and M. S. Krejca, \"Significance-based estimation-ofdistribution algorithms,\" IEEE Trans. Evol. Comput., vol. 24, no. 6, pp. 1025-1034, Dec. 2020.\n[24] J. E. Rowe and Aishwaryaprajna, \"The benefits and limitations of voting mechanisms in evolutionary optimisation,\" in Proc. 15th ACM/SIGEVO Conf. Found. Genet. Algorithms, 2019, pp. 34-42.\n[25] M. S. Krejca and C. Witt, \"Theory of estimation-of-distribution algorithms,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer, 2020, pp. 405-442.\n[26] A. Auger and N. Hansen, \"A restart CMA evolution strategy with increasing population size,\" in Proc. IEEE Congr. Evol. Comput., vol. 2, 2005, pp. 1769-1776.\n[27] C. Witt, \"On crossing fitness valleys with majority-vote crossover and estimation-of-distribution algorithms,\" in Proc. 16th ACM/SIGEVO Conf. Found. Genet. Algorithms, 2021, pp. 1-15.\n[28] C. Doerr, F. Ye, N. Horesh, H. Wang, O. M. Shir, and T. Bäck, \"Benchmarking discrete optimization heuristics with IOHprofiler,\" Appl. Soft Comput., vol. 88, Mar. 2020, Art. no. 106027.\n[29] W. Hoeffding, \"Probability inequalities for sums of bounded random variables,\" J. Amer. Stat. Assoc., vol. 58, no. 301, pp. 13-30, 1963.\n[30] B. Doerr, \"Probabilistic tools for the analysis of randomized optimization heuristics,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer Int., 2020, pp. 1-87.\n[31] Z. Savvári, \"Inequalities for binomial coefficients,\" J. Math. Anal. Appl., vol. 236, no. 1, pp. 223-226, 1999.\n[32] S.-I. Amari, \"Natural gradient works efficiently in learning,\" Neural Comput., vol. 10, no. 2, pp. 251-276, 1998.\n[33] J. Martens, \"New insights and perspectives on the natural gradient method,\" J. Mach. Learn. Res., vol. 21, no. 1, pp. 1-76, Jan. 2020.\n[34] S.-I. Amari and S. C. Douglas, \"Why natural gradient?\" in Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), vol. 2, 1998, pp. 1213-1216.\n[35] D. Wierstra, T. Schaul, T. Glasmachers, Y. Sun, J. Peters, and J. Schmidhuber, \"Natural evolution strategies,\" J. Mach. Learn. Res., vol. 15, no. 1, pp. 949-980, 2014.\n[36] Y. Ollivier, L. Arnold, A. Auger, and N. Hansen, \"Information-geometric optimization algorithms: A unifying picture via invariance principles,\" J. Mach. Learn. Res., vol. 18, no. 18, pp. 1-65, 2017.\n[37] D. G. Laenberger and Y. Ye, Linear and Nonlinear Programming, 3rd ed. New York, NY, USA: Springer, 2008, p. 253.\n[38] J. Nutini, I. Laradji, and M. Schmidt, \"Let's make block coordinate descent converge faster: Faster greedy rules, message-passing, active-set complexity, and Superlinear convergence,\" J. Mach. Learn. Res., vol. 23, no. 131, pp. 1-74, 2022.\n[39] P. Tseng and S. Yun, \"A coordinate gradient descent method for nonsmooth separable minimization,\" Math. Program., vol. 117, nos. 1-2, pp. 387-423, 2009.\n\nAdetunji David Ajimakin is currently pursuing the Ph.D. degree with the Indian Institute of Science, Bengaluru, India.\n\nHis research interests lie in the intersection of machine learning and evolutionary computation.\nV. Susheda Devi received the Ph.D. degree from the Indian Institute of Science, Bengaluru, India, in 2000.\n\nShe currently serves as a Principal Research Scientist with the Indian Institute of Science. She works in the areas of machine learning, deep learning, artificial intelligence, and soft computing.",
    "references": [
      {
        "ref_id": "1",
        "text": "G. R. Harik, F. G. Lobo, and D. E. Goldberg, \"The compact genetic algorithm,\" IEEE Trans. Evol. Comput., vol. 3, no. 4, pp. 287-297, Nov. 1999."
      },
      {
        "ref_id": "2",
        "text": "H. Mühlenbein and G. Paall, \"From recombination of genes to the estimation of distributions I. Binary parameters,\" in Proc. Int. Conf. Parallel Problem Solving Nat., 1996, pp. 178-187."
      },
      {
        "ref_id": "3",
        "text": "S. Baluja, \"Population-based incremental learning. A method for integrating genetic search based function optimization and competitive learning,\" Dept. Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-94-163, 1994."
      },
      {
        "ref_id": "4",
        "text": "F. Neumann, D. Sudholt, and C. Witt, \"A few ants are enough: ACO with iteration-best update,\" in Proc. 12th Annu. Conf. Genet. Evol. Comput., 2010, pp. 63-70."
      },
      {
        "ref_id": "5",
        "text": "M. Pelikan, M. W. Hauschild, and F. G. Lobo, \"Estimation of distribution algorithms,\" in Springer Handbook of Computational Intelligence. Berlin, Germany: Springer, 2015, pp. 899-928."
      },
      {
        "ref_id": "6",
        "text": "B. Doerr and W. Zheng, \"Sharp bounds for genetic drift in estimation of distribution algorithms,\" IEEE Trans. Evol. Comput., vol. 24, no. 6, pp. 1140-1149, Dec. 2020."
      },
      {
        "ref_id": "7",
        "text": "M. S. Krejca, \"Theoretical analyses of univariate estimation-of-distribution algorithms,\" Ph.D. dissertation, Dept. Digit. Eng., Universität Potsdam, Brandenburg, Germany, 2019."
      },
      {
        "ref_id": "8",
        "text": "T. Friedrich, T. Kötzing, and M. S. Krejca, \"EDAs cannot be balanced and stable,\" in Proc. Genet. Evol. Comput. Conf., 2016, pp. 1139-1146."
      },
      {
        "ref_id": "9",
        "text": "J. L. Shapiro, \"Drift and scaling in estimation of distribution algorithms,\" Evol. Comput., vol. 13, no. 1, pp. 99-123, Mar. 2005."
      },
      {
        "ref_id": "10",
        "text": "B. Doerr and M. S. Krejca, \"The univariate marginal distribution algorithm copes well with deception and epistasis,\" Evol. Comput., vol. 29, no. 4, pp. 543-563, Dec. 2021."
      },
      {
        "ref_id": "11",
        "text": "P. K. Lehre and P. T. H. Nguyen, \"On the limitations of the univariate marginal distribution algorithm to deception and where bivariate EDAs might help,\" in Proc. 15th ACM/SIGEVO Conf. Found. Genet. Algorithms, 2019, pp. 154-168."
      },
      {
        "ref_id": "12",
        "text": "D.-C. Dang, P. K. Lehre, and P. T. H. Nguyen, \"Level-based analysis of the univariate marginal distribution algorithm,\" Algorithmica, vol. 81, no. 2, pp. 668-702, 2019."
      },
      {
        "ref_id": "13",
        "text": "C. Witt, \"Upper bounds on the running time of the univariate marginal distribution algorithm on OneMax,\" Algorithmica, vol. 81, no. 2, pp. 632-667, 2019."
      },
      {
        "ref_id": "14",
        "text": "M. S. Krejca and C. Witt, \"Lower bounds on the run time of the univariate marginal distribution algorithm on OneMax,\" Theor. Comput. Sci., vol. 832, pp. 143-165, Sep. 2020."
      },
      {
        "ref_id": "15",
        "text": "D. Sudholt and C. Witt, \"On the choice of the update strength in estimation-of-distribution algorithms and ant colony optimization,\" Algorithmica, vol. 81, no. 4, pp. 1450-1489, 2019."
      },
      {
        "ref_id": "16",
        "text": "J. Lengler, D. Sudholt, and C. Witt, \"Medium step sizes are harmful for the compact genetic algorithm,\" in Proc. Genet. Evol. Comput. Conf., 2018, pp. 1499-1506."
      },
      {
        "ref_id": "17",
        "text": "J. Lengler, D. Sudholt, and C. Witt, \"The complex parameter landscape of the compact genetic algorithm,\" Algorithmica, vol. 83, no. 4, pp. 1096-1137, 2021."
      },
      {
        "ref_id": "18",
        "text": "B. Doerr and C. Doerr, \"Theory of parameter control for discrete black-box optimization: Provable performance gains through dynamic parameter choices,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer Int., 2020, pp. 271-321."
      },
      {
        "ref_id": "19",
        "text": "M. Pelikan and T.-K. Lin, \"Parameter-less hierarchical BOA,\" in Proc. Genet. Evol. Comput. Conf., 2004, pp. 24-35."
      },
      {
        "ref_id": "20",
        "text": "B. Doerr, \"The runtime of the compact genetic algorithm on jump functions,\" Algorithmica, vol. 83, no. 10, pp. 3059-3107, 2021."
      },
      {
        "ref_id": "21",
        "text": "B. Doerr and W. Zheng, \"From understanding genetic drift to a smartrestart parameter-less compact genetic algorithm,\" in Proc. Genet. Evol. Comput. Conf., 2020, pp. 805-813."
      },
      {
        "ref_id": "22",
        "text": "H. Mühlenbein, \"The equation for response to selection and its use for prediction,\" Evol. Comput., vol. 5, no. 3, pp. 303-346, Sep. 1997."
      },
      {
        "ref_id": "23",
        "text": "B. Doerr and M. S. Krejca, \"Significance-based estimation-ofdistribution algorithms,\" IEEE Trans. Evol. Comput., vol. 24, no. 6, pp. 1025-1034, Dec. 2020."
      },
      {
        "ref_id": "24",
        "text": "J. E. Rowe and Aishwaryaprajna, \"The benefits and limitations of voting mechanisms in evolutionary optimisation,\" in Proc. 15th ACM/SIGEVO Conf. Found. Genet. Algorithms, 2019, pp. 34-42."
      },
      {
        "ref_id": "25",
        "text": "M. S. Krejca and C. Witt, \"Theory of estimation-of-distribution algorithms,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer, 2020, pp. 405-442."
      },
      {
        "ref_id": "26",
        "text": "A. Auger and N. Hansen, \"A restart CMA evolution strategy with increasing population size,\" in Proc. IEEE Congr. Evol. Comput., vol. 2, 2005, pp. 1769-1776."
      },
      {
        "ref_id": "27",
        "text": "C. Witt, \"On crossing fitness valleys with majority-vote crossover and estimation-of-distribution algorithms,\" in Proc. 16th ACM/SIGEVO Conf. Found. Genet. Algorithms, 2021, pp. 1-15."
      },
      {
        "ref_id": "28",
        "text": "C. Doerr, F. Ye, N. Horesh, H. Wang, O. M. Shir, and T. Bäck, \"Benchmarking discrete optimization heuristics with IOHprofiler,\" Appl. Soft Comput., vol. 88, Mar. 2020, Art. no. 106027."
      },
      {
        "ref_id": "29",
        "text": "W. Hoeffding, \"Probability inequalities for sums of bounded random variables,\" J. Amer. Stat. Assoc., vol. 58, no. 301, pp. 13-30, 1963."
      },
      {
        "ref_id": "30",
        "text": "B. Doerr, \"Probabilistic tools for the analysis of randomized optimization heuristics,\" in Theory of Evolutionary Computation. Cham, Switzerland: Springer Int., 2020, pp. 1-87."
      },
      {
        "ref_id": "31",
        "text": "Z. Savvári, \"Inequalities for binomial coefficients,\" J. Math. Anal. Appl., vol. 236, no. 1, pp. 223-226, 1999."
      },
      {
        "ref_id": "32",
        "text": "S.-I. Amari, \"Natural gradient works efficiently in learning,\" Neural Comput., vol. 10, no. 2, pp. 251-276, 1998."
      },
      {
        "ref_id": "33",
        "text": "J. Martens, \"New insights and perspectives on the natural gradient method,\" J. Mach. Learn. Res., vol. 21, no. 1, pp. 1-76, Jan. 2020."
      },
      {
        "ref_id": "34",
        "text": "S.-I. Amari and S. C. Douglas, \"Why natural gradient?\" in Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), vol. 2, 1998, pp. 1213-1216."
      },
      {
        "ref_id": "35",
        "text": "D. Wierstra, T. Schaul, T. Glasmachers, Y. Sun, J. Peters, and J. Schmidhuber, \"Natural evolution strategies,\" J. Mach. Learn. Res., vol. 15, no. 1, pp. 949-980, 2014."
      },
      {
        "ref_id": "36",
        "text": "Y. Ollivier, L. Arnold, A. Auger, and N. Hansen, \"Information-geometric optimization algorithms: A unifying picture via invariance principles,\" J. Mach. Learn. Res., vol. 18, no. 18, pp. 1-65, 2017."
      },
      {
        "ref_id": "37",
        "text": "D. G. Laenberger and Y. Ye, Linear and Nonlinear Programming, 3rd ed. New York, NY, USA: Springer, 2008, p. 253."
      },
      {
        "ref_id": "38",
        "text": "J. Nutini, I. Laradji, and M. Schmidt, \"Let's make block coordinate descent converge faster: Faster greedy rules, message-passing, active-set complexity, and Superlinear convergence,\" J. Mach. Learn. Res., vol. 23, no. 131, pp. 1-74, 2022."
      },
      {
        "ref_id": "39",
        "text": "P. Tseng and S. Yun, \"A coordinate gradient descent method for nonsmooth separable minimization,\" Math. Program., vol. 117, nos. 1-2, pp. 387-423, 2009."
      }
    ],
    "reference_count": 39,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": []
}