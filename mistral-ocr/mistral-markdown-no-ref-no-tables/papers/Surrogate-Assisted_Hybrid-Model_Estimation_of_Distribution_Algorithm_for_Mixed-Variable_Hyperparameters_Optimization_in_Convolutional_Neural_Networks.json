{
  "metadata": {
    "file_path": "/Users/id05309/Documents/tfm/mistral/mistral-markdown/2023/Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks.md",
    "filename": "Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks.md",
    "title": "Surrogate-Assisted Hybrid-Model Estimation of Distribution Algorithm for Mixed-Variable Hyperparameters Optimization in Convolutional Neural Networks",
    "year": "2023"
  },
  "references": {
    "header": "## REFERENCES",
    "content": "[1] Y. LeCun, Y. Bengio, and G. Hinton, \"Deep learning,\" Nature, vol. 521, pp. 436-444, Feb. 2015.\n[2] Z.-Q. Zhao, P. Zheng, S.-T. Xu, and X. Wu, \"Object detection with deep learning: A review,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 11, pp. 3212-3232, Nov. 2019.\n\n[3] Y. Sun, B. Xue, G. G. Yen, and M. Zhang, \"A particle swarm optimization-based flexible convolutional autoencoder for image classification,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 30, no. 8, pp. 2295-2309, Aug. 2019.\n[4] Y. Sun, G. G. Yen, and Z. Yi, \"Evolving unsupervised deep neural networks for learning meaningful representations,\" IEEE Trans. Evol. Comput., vol. 23, no. 1, pp. 89-103, Feb. 2019.\n[5] H. Y. D. Sigaki, E. K. Lenzi, R. S. Zola, M. Perc, and H. V. Ribeiro, \"Learning physical properties of liquid crystals with deep convolutional neural networks,\" Sci. Rep., vol. 10, no. 1, pp. 1-11, May 2020.\n[6] Z. Gao et al., \"Complex networks and deep learning for EEG signal analysis,\" Cognit. Neurorhyn., vol. 15, no. 3, pp. 369-388, Jun. 2021.\n[7] F. E. Fernandes and G. G. Yen, \"Automatic searching and pruning of deep neural networks for medical imaging diagnostic,\" IEEE Trans. Neural Netw. Learn. Syst., early access, Oct. 13, 2020, doi: 10.1109/TNNLS.2020.3027308.\n[8] K. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 770-778.\n[9] S. Zagoruyko and N. Komodakis, \"Wide residual networks,\" in Proc. Procedings Brit. Mach. Vis. Conf., 2016, p. 87.\n[10] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, \"Densely connected convolutional networks,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 2261-2269.\n[11] B. Zoph and Q. V. Le, \"Neural architecture search with reinforcement learning,\" in Proc. Int. Conf. Learn. Represent., 2017, pp. 1-16.\n[12] K. Kandasamy, W. Neiswanger, J. Schneider, B. PÃ³czos, and E. P. Xing, \"Neural architecture search with Bayesian optimisation and optimal transport,\" in Proc. Adv. Neural Inf. Process. Syst., 2018, pp. 2016-2025.\n[13] E. Real et al., \"Large-scale evolution of image classifiers,\" in Proc. 34th Int. Mach. Learn., 2017, pp. 2902-2911.\n[14] H. Liu, K. Simonyan, O. Vinyals, C. Fernando, and K. Kavukcuoglu, \"Hierarchical representations for efficient architecture search,\" in Proc. Int. Conf. Learn. Represent., 2018, pp. 1-13.\n[15] Z.-H. Zhan et al., \"Matrix-based evolutionary computation,\" IEEE Trans. Emerg. Topics Comput. Intell., early access, Jan. 21, 2021, doi: 10.1109/TETCI.2020.3047410.\n[16] J.-Y. Li, Z.-H. Zhan, C. Wang, H. Jin, and J. Zhang, \"Boosting datadriven evolutionary algorithm with localized data generation,\" IEEE Trans. Evol. Comput., vol. 24, no. 5, pp. 923-937, Oct. 2020.\n[17] X. Xia et al., \"Triple archives particle swarm optimization,\" IEEE Trans. Cybern., vol. 50, no. 12, pp. 4862-4875, Dec. 2020.\n[18] Z.-H. Zhan et al., \"Cloudde: A heterogeneous differential evolution algorithm and its distributed cloud version,\" IEEE Trans. Parallel Distrib. Syst., vol. 28, no. 3, pp. 704-716, Mar. 2017.\n[19] M. Suganuma, S. Shirakawa, and T. Nagao, \"A genetic programming approach to designing convolutional neural network architectures,\" in Proc. Genetic Evol. Comput. Conf., Jul. 2017, pp. 497-504.\n[20] Z.-G. Chen, Y. Lin, Y.-J. Gong, Z.-H. Zhan, and J. Zhang, \"Maximizing lifetime of range-adjustable wireless sensor networks: A neighborhoodbased estimation of distribution algorithm,\" IEEE Trans. Cybern., early access, Apr. 1, 2020, doi: 10.1109/TCYB.2020.2977858.\n[21] W. Du et al., \"The networked evolutionary algorithm: A network science perspective,\" Appl. Math. Comput., vol. 338, pp. 33-43, Dec. 2018.\n[22] U. Alvarez-Rodriguez, F. Battiston, G. F. de Arruda, Y. Moreno, M. Perc, and V. Latora, \"Evolutionary dynamics of higher-order interactions in social networks,\" Nature Hum. Behav., vol. 5, no. 5, pp. 586-595, May 2021.\n[23] Y. Sun, B. Xue, M. Zhang, G. G. Yen, and J. Lv, \"Automatically designing CNN architectures using the genetic algorithm for image classification,\" IEEE Trans. Cybern., vol. 50, no. 9, pp. 3840-3854, Sep. 2020.\n[24] Y. Sun, B. Xue, M. Zhang, and G. G. Yen, \"Completely automated CNN architecture design based on blocks,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 31, no. 4, pp. 1242-1254, Apr. 2020.\n[25] Y. Sun, H. Wang, B. Xue, Y. Jin, G. G. Yen, and M. Zhang, \"Surrogateassisted evolutionary deep learning using an end-to-end random forestbased performance predictor,\" IEEE Trans. Evol. Comput., vol. 24, no. 2, pp. 350-364, Apr. 2020.\n[26] A. Darwish, A. E. Hassanien, and S. Das, \"A survey of swarm and evolutionary computing approaches for deep learning,\" Artif. Intell. Rev., vol. 53, no. 3, pp. 1767-1812, Mar. 2020.\n[27] X. F. Liu, Z. H. Zhan, and J. Zhang, \"Resource-aware distributed differential evolution for training expensive neural-network-based controller in power electronic circuit,\" IEEE Trans. Neural Netw. Learn. Syst., early access, May 7, 2021, doi: 10.1109/TNNLS.2021.3075205.\n[28] X. Zheng, R. Ji, L. Tang, B. Zhang, J. Liu, and Q. Tian, \"Multinomial distribution learning for effective neural architecture search,\" in Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 1304-1313.\n[29] A. Krizhevsky and G. Hinton. (2009). Learning Multiple Layers of Features From Tiny Images. [Online]. Available: https://www.cs.toronto.edu/ kriz/cifar.html\n[30] Z. Yang et al., \"CARS: Continuous evolution for efficient neural architecture search,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2020, pp. 1829-1838.\n[31] Z.-H. Zhan, Z.-J. Wang, H. Jin, and J. Zhang, \"Adaptive distributed differential evolution,\" IEEE Trans. Cybern., vol. 50, no. 11, pp. 4633-4647, Nov. 2020.\n[32] N. Xue, I. Triguero, G. P. Figueredo, and D. Landa-Silva, \"Evolving deep CNN-LSTMs for inventory time series prediction,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jun. 2019, pp. 1517-1524.\n[33] B. Wang, Y. Sun, B. Xue, and M. Zhang, \"Evolving deep convolutional neural networks by variable-length particle swarm optimization for image classification,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jul. 2018, pp. 1-8.\n[34] B. Fielding, T. Lawrence, and L. Zhang, \"Evolving and ensembling deep CNN architectures for image classification,\" in Proc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2019, pp. 1-8.\n[35] T. Wu, J. Shi, D. Zhou, Y. Lei, and M. Gong, \"A multi-objective particle swarm optimization for neural networks pruning,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jun. 2019, pp. 570-577.\n[36] Y. Guo, J.-Y. Li, and Z.-H. Zhan, \"Efficient hyperparameter optimization for convolution neural networks in deep learning: A distributed particle swarm optimization approach,\" Cybern. Syst., vol. 52, no. 1, pp. 36-57, Jan. 2021.\n[37] A. Hadjiivanov and A. Blair, \"Epigenetic evolution of deep convolutional models,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jun. 2019, pp. 1478-1486.\n[38] Z.-H. Zhan, J. Zhang, Y. Li, and Y.-H. Shi, \"Orthogonal learning particle swarm optimization,\" IEEE Trans. Evol. Comput., vol. 15, no. 6, pp. 832-847, Dec. 2011.\n[39] J. Tian, Y. Tan, J. Zeng, C. Sun, and Y. Jin, \"Multiobjective infill criterion driven Gaussian process-assisted particle swarm optimization of highdimensional expensive problems,\" IEEE Trans. Evol. Comput., vol. 23, no. 3, pp. 459-472, Jun. 2019.\n[40] X. Cai, L. Gao, and X. Li, \"Efficient generalized surrogate-assisted evolutionary algorithm for high-dimensional expensive problems,\" IEEE Trans. Evol. Comput., vol. 24, no. 2, pp. 365-379, Apr. 2020.\n[41] F. Li, X. Cai, L. Gao, and W. Shen, \"A surrogate-assisted multiswarm optimization algorithm for high-dimensional computationally expensive problems,\" IEEE Trans. Cybern., vol. 51, no. 3, pp. 1390-1402, Mar. 2021.\n[42] Z. Yang, H. Qiu, L. Gao, X. Cai, C. Jiang, and L. Chen, \"Surrogateassisted classification-collaboration differential evolution for expensive constrained optimization problems,\" Inf. Sci., vol. 508, pp. 50-63, Jan. 2020.\n[43] H. Wang and Y. Jin, \"A random forest-assisted evolutionary algorithm for data-driven constrained multiobjective combinatorial optimization of trauma systems,\" IEEE Trans. Cybern., vol. 50, no. 2, pp. 536-549, Feb. 2020.\n[44] I. Radosavovic, R. P. Kosaraju, R. Girshick, K. He, and P. Dollar, \"Designing network design spaces,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2020, pp. 10428-10436.\n[45] W. Shi, W.-N. Chen, Y. Lin, T. Gu, S. Kwong, and J. Zhang, \"An adaptive estimation of distribution algorithm for multipolicy insurance investment planning,\" IEEE Trans. Evol. Comput., vol. 23, no. 1, pp. 1-14, Feb. 2019.\n[46] K. Simonyan and A. Zisserman, \"Very deep convolutional networks for large-scale image recognition,\" in Proc. Int. Conf. Learn. Represent, 2015, pp. 1-14.\n[47] I. J. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville, and Y. Bengio, \"Maxout networks,\" in Proc. Int. Conf. Mach. Learn., 2013, pp. 1319-1327.\n[48] M. Lin, Q. Chen, and S. Yan, \"Network in network,\" in Proc. Int. Conf. Learn. Represent., 2014, pp. 1-10.\n[49] R. K. Srivastava, K. Greff, and J. Schmidhuber, \"Highway networks,\" in Proc. Int. Conf. Learn. Represent., 2015, pp. 1-6.\n[50] J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller, \"Striving for simplicity: The all convolutional net,\" in Proc. Int. Conf. Learn. Represent., 2015, pp. 1-14.\n[51] G. Larsson, M. Maire, and G. Shakhnarovich, \"FractalNet: Ultra-deep neural networks without residuals,\" in Proc. Int. Conf. Learn. Represent., 2016, pp. 1-11.\n\n[52] B. Baker, O. Gupta, N. Naik, and R. Raskar, \"Designing neural network architectures using reinforcement learning,\" in Proc. Int. Conf. Learn. Represent., 2017, pp. 1-18.\n[53] H. Cai, T. Chen, W. Zhang, Y. Yu, and J. Wang, \"Efficient architecture search by network transformation,\" in Proc. 32nd Conf. Artif. Intell., 2018, pp. 2787-2794.\n[54] Z. Zhong, J. Yan, W. Wu, J. Shao, and C.-L. Liu, \"Practical blockwise neural network architecture generation,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 2423-2432.\n[55] L. Xie and A. Yuille, \"Genetic CNN,\" in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Oct. 2017, pp. 1388-1397.\n[56] F. Pedregosa et al., \"Scikit-learn: Machine learning in Python,\" J. Mach. Learn. Res., vol. 12, no. 85, pp. 2825-2830, Oct. 2011.\n[57] C. A. Nienaber et al., \"Aortic dissection,\" Nat. Rev. Dis. Prim., vol. 2, pp. 1-18, Mar. 2016.\n[58] R. J. Harris et al., \"Classification of aortic dissection and rupture on post-contrast CT images using a convolutional neural network,\" J. Digit. Imag., vol. 32, no. 6, pp. 939-946, Sep. 2019.\n[59] C. Xu et al., \"Multifunctional cationic nanosystems for nucleic acid therapy of thoracic aortic dissection,\" Nature Commun., vol. 10, no. 1, pp. 1-15, Jul. 2019.\n[60] S. S. Sumit, D. R. A. Rambli, and S. Mirjalili, \"Vision-based human detection techniques: A descriptive review,\" IEEE Access, vol. 9, pp. 42724-42761, Mar. 2021.\n[61] J.-Y. Li, Z.-H. Zhan, H. Wang, and J. Zhang, \"Data-driven evolutionary algorithm with perturbation-based ensemble surrogates,\" IEEE Trans. Cybern., vol. 51, no. 8, pp. 3925-3937, Aug. 2021.\n[62] Z.-J. Wang, Z.-H. Zhan, S. Kwong, H. Jin, and J. Zhang, \"Adaptive granularity learning distributed particle swarm optimization for largescale optimization,\" IEEE Trans. Cybern., vol. 51, no. 3, pp. 1175-1188, Mar. 2021.\n[63] X.-F. Liu et al., \"Neural network-based information transfer for dynamic optimization,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 31, no. 5, pp. 1557-1570, May 2020.\n[64] X.-F. Liu, Z.-H. Zhan, Y. Gao, J. Zhang, S. Kwong, and J. Zhang, \"Coevolutionary particle swarm optimization with bottleneck objective learning strategy for many-objective optimization,\" IEEE Trans. Evol. Comput., vol. 23, no. 4, pp. 587-602, Aug. 2019.\n[65] Z.-G. Chen, Z.-H. Zhan, H. Wang, and J. Zhang, \"Distributed individuals for multiple peaks: A novel differential evolution for multimodal optimization problems,\" IEEE Trans. Evol. Comput., vol. 24, no. 4, pp. 708-719, Aug. 2020.\n[66] S. H. Wu, Z. H. Zhan, and J. Zhang, \"SAFE: Scale-adaptive fitness evaluation method for expensive optimization problems,\" IEEE Trans. Evol. Comput., vol. 25, no. 3, pp. 479-491, Jun. 2021.\n[67] J.-Y. Li, Z.-H. Zhan, R.-D. Liu, C. Wang, S. Kwong, and J. Zhang, \"Generation-level parallelism for evolutionary computation: A pipelinebased parallel particle swarm optimization,\" IEEE Trans. Cybern., early access, Nov. 4, 2020, doi: 10.1109/TCYB.2020.3028070.\n[68] Y. F. Ge et al., \"Distributed memetic algorithm for outsourced database fragmentation,\" IEEE Trans. Cybern., Nov. 4, 2020, doi: 10.1109/TCYB.2020.3027962.\n[69] J. Too and S. Mirjalili, \"A hyper learning binary dragonfly algorithm for feature selection: A COVID-19 case study,\" Knowl.-Based Syst., vol. 212, pp. 1-16, Jan. 2021.\n[70] S. M. I. Jalali, S. Ahmadian, A. Khoszavi, S. Mirjalili, M. R. Mahmoudi, and S. Nahavandi, \"Neuroevolution-based autonomous robot navigation: A comparative study,\" Cognit. Syst. Res., vol. 62, pp. 35-43, Aug. 2020.\n![img-7.jpeg](img-7.jpeg)\n\nJian-Yu Li (Student Member, IEEE) received the B.S. degree in computer science and technology from South China University of Technology, Guangzhou, China, in 2018, where he is currently pursuing the Ph.D. degree.\nHis research interests mainly include computational intelligence, data-driven optimization, and their applications in real-world problems.\n![img-8.jpeg](img-8.jpeg)\n\nZhi-Hui Zhan (Senior Member, IEEE) received the bachelor's and Ph.D. degrees in computer science from Sun Yat-sen University, Guangzhou, China, in 2007 and 2013, respectively.\nHe is currently a Changjiang Scholar Young Professor with the School of Computer Science and Engineering, South China University of Technology, Guangzhou. His current research interests include evolutionary computation, swarm intelligence, and their applications in real-world problems and in environments of cloud computing and big data.\nDr. Zhan was a recipient of the IEEE Computational Intelligence Society (CIS) Outstanding Early Career Award in 2021, the Outstanding Youth Science Foundation from National Natural Science Foundations of China (NSFC) in 2018, and Wu Wen-Jun Artificial Intelligence Excellent Youth from the Chinese Association for Artificial Intelligence in 2017. His doctoral dissertation was awarded the IEEE CIS Outstanding Ph.D. Dissertation and China Computer Federation Outstanding Ph.D. Dissertation. He is listed as one of the Highly Cited Chinese Researchers in Computer Science. He is currently an Associate Editor of the IEEE Transactions on Evolutionary COMPutation, the Neurocomputing, and the Memetic Computing.\n![img-9.jpeg](img-9.jpeg)\n\nJin Xu received the Ph.D. degree from the Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, USA, in 2012.\nHe is currently a Principal Researcher with WeChat, Tencent Inc., Shenzhen, China. He has published more than 30 peer-reviewed publications in AI research. His current research interests include machine learning, data mining, and their applications in internet product.\n![img-10.jpeg](img-10.jpeg)\n\nSam Kwong (Fellow, IEEE) received the Ph.D. degree from the University of Hagen, Hagen, Germany, in 1996.\nHe is currently a Chair Professor with the Department of Computer Science, City University of Hong Kong, Hong Kong. His research interests include pattern recognition, evolutionary computations, and video analytics.\nProf. Kwong was elevated to an IEEE Fellow for his contributions to optimization techniques for cybernetics and video coding in 2014. He is the President-Elect of the IEEE Systems, Man, and Cybernetics (SMC). He was also appointed as an IEEE Distinguished Lecturer of the IEEE SMC Society in March 2017. He is currently an Associate Editor of the IEEE Transactions on Evolutionary Computation.\n![img-11.jpeg](img-11.jpeg)\n\nJun Zhang (Fellow, IEEE) received the Ph.D. degree from the City University of Hong Kong, in 2002.\nHe is currently a Korea Brain Pool Fellow Professor with Hanyang University, Seoul, South Korea, and a Visiting Professor with Chaoyang University of Technology, Taichung, Taiwan. His current research interests include computational intelligence, cloud computing, operations research, and power electronic circuits. He has published over more than 150 IEEE Transactions articals in his research areas.\nDr. Zhang was a recipient of a Changjiang Chair Professor from the Ministry of Education, China, in 2013, the National Science Fund for Distinguished Young Scholars of China in 2011, and the First-Grade Award in Natural Science Research from the Ministry of Education, China, in 2009. He is currently an Associate Editor of the IEEE Transactions on Evolutionary COMPutation and the IEEE Transactions on Cybernetics.",
    "references": [
      {
        "ref_id": "1",
        "text": "Y. LeCun, Y. Bengio, and G. Hinton, \"Deep learning,\" Nature, vol. 521, pp. 436-444, Feb. 2015."
      },
      {
        "ref_id": "2",
        "text": "Z.-Q. Zhao, P. Zheng, S.-T. Xu, and X. Wu, \"Object detection with deep learning: A review,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 11, pp. 3212-3232, Nov. 2019."
      },
      {
        "ref_id": "3",
        "text": "Y. Sun, B. Xue, G. G. Yen, and M. Zhang, \"A particle swarm optimization-based flexible convolutional autoencoder for image classification,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 30, no. 8, pp. 2295-2309, Aug. 2019."
      },
      {
        "ref_id": "4",
        "text": "Y. Sun, G. G. Yen, and Z. Yi, \"Evolving unsupervised deep neural networks for learning meaningful representations,\" IEEE Trans. Evol. Comput., vol. 23, no. 1, pp. 89-103, Feb. 2019."
      },
      {
        "ref_id": "5",
        "text": "H. Y. D. Sigaki, E. K. Lenzi, R. S. Zola, M. Perc, and H. V. Ribeiro, \"Learning physical properties of liquid crystals with deep convolutional neural networks,\" Sci. Rep., vol. 10, no. 1, pp. 1-11, May 2020."
      },
      {
        "ref_id": "6",
        "text": "Z. Gao et al., \"Complex networks and deep learning for EEG signal analysis,\" Cognit. Neurorhyn., vol. 15, no. 3, pp. 369-388, Jun. 2021."
      },
      {
        "ref_id": "7",
        "text": "F. E. Fernandes and G. G. Yen, \"Automatic searching and pruning of deep neural networks for medical imaging diagnostic,\" IEEE Trans. Neural Netw. Learn. Syst., early access, Oct. 13, 2020, doi: 10.1109/TNNLS.2020.3027308."
      },
      {
        "ref_id": "8",
        "text": "K. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 770-778."
      },
      {
        "ref_id": "9",
        "text": "S. Zagoruyko and N. Komodakis, \"Wide residual networks,\" in Proc. Procedings Brit. Mach. Vis. Conf., 2016, p. 87."
      },
      {
        "ref_id": "10",
        "text": "G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, \"Densely connected convolutional networks,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 2261-2269."
      },
      {
        "ref_id": "11",
        "text": "B. Zoph and Q. V. Le, \"Neural architecture search with reinforcement learning,\" in Proc. Int. Conf. Learn. Represent., 2017, pp. 1-16."
      },
      {
        "ref_id": "12",
        "text": "K. Kandasamy, W. Neiswanger, J. Schneider, B. PÃ³czos, and E. P. Xing, \"Neural architecture search with Bayesian optimisation and optimal transport,\" in Proc. Adv. Neural Inf. Process. Syst., 2018, pp. 2016-2025."
      },
      {
        "ref_id": "13",
        "text": "E. Real et al., \"Large-scale evolution of image classifiers,\" in Proc. 34th Int. Mach. Learn., 2017, pp. 2902-2911."
      },
      {
        "ref_id": "14",
        "text": "H. Liu, K. Simonyan, O. Vinyals, C. Fernando, and K. Kavukcuoglu, \"Hierarchical representations for efficient architecture search,\" in Proc. Int. Conf. Learn. Represent., 2018, pp. 1-13."
      },
      {
        "ref_id": "15",
        "text": "Z.-H. Zhan et al., \"Matrix-based evolutionary computation,\" IEEE Trans. Emerg. Topics Comput. Intell., early access, Jan. 21, 2021, doi: 10.1109/TETCI.2020.3047410."
      },
      {
        "ref_id": "16",
        "text": "J.-Y. Li, Z.-H. Zhan, C. Wang, H. Jin, and J. Zhang, \"Boosting datadriven evolutionary algorithm with localized data generation,\" IEEE Trans. Evol. Comput., vol. 24, no. 5, pp. 923-937, Oct. 2020."
      },
      {
        "ref_id": "17",
        "text": "X. Xia et al., \"Triple archives particle swarm optimization,\" IEEE Trans. Cybern., vol. 50, no. 12, pp. 4862-4875, Dec. 2020."
      },
      {
        "ref_id": "18",
        "text": "Z.-H. Zhan et al., \"Cloudde: A heterogeneous differential evolution algorithm and its distributed cloud version,\" IEEE Trans. Parallel Distrib. Syst., vol. 28, no. 3, pp. 704-716, Mar. 2017."
      },
      {
        "ref_id": "19",
        "text": "M. Suganuma, S. Shirakawa, and T. Nagao, \"A genetic programming approach to designing convolutional neural network architectures,\" in Proc. Genetic Evol. Comput. Conf., Jul. 2017, pp. 497-504."
      },
      {
        "ref_id": "20",
        "text": "Z.-G. Chen, Y. Lin, Y.-J. Gong, Z.-H. Zhan, and J. Zhang, \"Maximizing lifetime of range-adjustable wireless sensor networks: A neighborhoodbased estimation of distribution algorithm,\" IEEE Trans. Cybern., early access, Apr. 1, 2020, doi: 10.1109/TCYB.2020.2977858."
      },
      {
        "ref_id": "21",
        "text": "W. Du et al., \"The networked evolutionary algorithm: A network science perspective,\" Appl. Math. Comput., vol. 338, pp. 33-43, Dec. 2018."
      },
      {
        "ref_id": "22",
        "text": "U. Alvarez-Rodriguez, F. Battiston, G. F. de Arruda, Y. Moreno, M. Perc, and V. Latora, \"Evolutionary dynamics of higher-order interactions in social networks,\" Nature Hum. Behav., vol. 5, no. 5, pp. 586-595, May 2021."
      },
      {
        "ref_id": "23",
        "text": "Y. Sun, B. Xue, M. Zhang, G. G. Yen, and J. Lv, \"Automatically designing CNN architectures using the genetic algorithm for image classification,\" IEEE Trans. Cybern., vol. 50, no. 9, pp. 3840-3854, Sep. 2020."
      },
      {
        "ref_id": "24",
        "text": "Y. Sun, B. Xue, M. Zhang, and G. G. Yen, \"Completely automated CNN architecture design based on blocks,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 31, no. 4, pp. 1242-1254, Apr. 2020."
      },
      {
        "ref_id": "25",
        "text": "Y. Sun, H. Wang, B. Xue, Y. Jin, G. G. Yen, and M. Zhang, \"Surrogateassisted evolutionary deep learning using an end-to-end random forestbased performance predictor,\" IEEE Trans. Evol. Comput., vol. 24, no. 2, pp. 350-364, Apr. 2020."
      },
      {
        "ref_id": "26",
        "text": "A. Darwish, A. E. Hassanien, and S. Das, \"A survey of swarm and evolutionary computing approaches for deep learning,\" Artif. Intell. Rev., vol. 53, no. 3, pp. 1767-1812, Mar. 2020."
      },
      {
        "ref_id": "27",
        "text": "X. F. Liu, Z. H. Zhan, and J. Zhang, \"Resource-aware distributed differential evolution for training expensive neural-network-based controller in power electronic circuit,\" IEEE Trans. Neural Netw. Learn. Syst., early access, May 7, 2021, doi: 10.1109/TNNLS.2021.3075205."
      },
      {
        "ref_id": "28",
        "text": "X. Zheng, R. Ji, L. Tang, B. Zhang, J. Liu, and Q. Tian, \"Multinomial distribution learning for effective neural architecture search,\" in Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 1304-1313."
      },
      {
        "ref_id": "29",
        "text": "A. Krizhevsky and G. Hinton. (2009). Learning Multiple Layers of Features From Tiny Images. [Online]. Available: https://www.cs.toronto.edu/ kriz/cifar.html"
      },
      {
        "ref_id": "30",
        "text": "Z. Yang et al., \"CARS: Continuous evolution for efficient neural architecture search,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2020, pp. 1829-1838."
      },
      {
        "ref_id": "31",
        "text": "Z.-H. Zhan, Z.-J. Wang, H. Jin, and J. Zhang, \"Adaptive distributed differential evolution,\" IEEE Trans. Cybern., vol. 50, no. 11, pp. 4633-4647, Nov. 2020."
      },
      {
        "ref_id": "32",
        "text": "N. Xue, I. Triguero, G. P. Figueredo, and D. Landa-Silva, \"Evolving deep CNN-LSTMs for inventory time series prediction,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jun. 2019, pp. 1517-1524."
      },
      {
        "ref_id": "33",
        "text": "B. Wang, Y. Sun, B. Xue, and M. Zhang, \"Evolving deep convolutional neural networks by variable-length particle swarm optimization for image classification,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jul. 2018, pp. 1-8."
      },
      {
        "ref_id": "34",
        "text": "B. Fielding, T. Lawrence, and L. Zhang, \"Evolving and ensembling deep CNN architectures for image classification,\" in Proc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2019, pp. 1-8."
      },
      {
        "ref_id": "35",
        "text": "T. Wu, J. Shi, D. Zhou, Y. Lei, and M. Gong, \"A multi-objective particle swarm optimization for neural networks pruning,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jun. 2019, pp. 570-577."
      },
      {
        "ref_id": "36",
        "text": "Y. Guo, J.-Y. Li, and Z.-H. Zhan, \"Efficient hyperparameter optimization for convolution neural networks in deep learning: A distributed particle swarm optimization approach,\" Cybern. Syst., vol. 52, no. 1, pp. 36-57, Jan. 2021."
      },
      {
        "ref_id": "37",
        "text": "A. Hadjiivanov and A. Blair, \"Epigenetic evolution of deep convolutional models,\" in Proc. IEEE Congr. Evol. Comput. (CEC), Jun. 2019, pp. 1478-1486."
      },
      {
        "ref_id": "38",
        "text": "Z.-H. Zhan, J. Zhang, Y. Li, and Y.-H. Shi, \"Orthogonal learning particle swarm optimization,\" IEEE Trans. Evol. Comput., vol. 15, no. 6, pp. 832-847, Dec. 2011."
      },
      {
        "ref_id": "39",
        "text": "J. Tian, Y. Tan, J. Zeng, C. Sun, and Y. Jin, \"Multiobjective infill criterion driven Gaussian process-assisted particle swarm optimization of highdimensional expensive problems,\" IEEE Trans. Evol. Comput., vol. 23, no. 3, pp. 459-472, Jun. 2019."
      },
      {
        "ref_id": "40",
        "text": "X. Cai, L. Gao, and X. Li, \"Efficient generalized surrogate-assisted evolutionary algorithm for high-dimensional expensive problems,\" IEEE Trans. Evol. Comput., vol. 24, no. 2, pp. 365-379, Apr. 2020."
      },
      {
        "ref_id": "41",
        "text": "F. Li, X. Cai, L. Gao, and W. Shen, \"A surrogate-assisted multiswarm optimization algorithm for high-dimensional computationally expensive problems,\" IEEE Trans. Cybern., vol. 51, no. 3, pp. 1390-1402, Mar. 2021."
      },
      {
        "ref_id": "42",
        "text": "Z. Yang, H. Qiu, L. Gao, X. Cai, C. Jiang, and L. Chen, \"Surrogateassisted classification-collaboration differential evolution for expensive constrained optimization problems,\" Inf. Sci., vol. 508, pp. 50-63, Jan. 2020."
      },
      {
        "ref_id": "43",
        "text": "H. Wang and Y. Jin, \"A random forest-assisted evolutionary algorithm for data-driven constrained multiobjective combinatorial optimization of trauma systems,\" IEEE Trans. Cybern., vol. 50, no. 2, pp. 536-549, Feb. 2020."
      },
      {
        "ref_id": "44",
        "text": "I. Radosavovic, R. P. Kosaraju, R. Girshick, K. He, and P. Dollar, \"Designing network design spaces,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2020, pp. 10428-10436."
      },
      {
        "ref_id": "45",
        "text": "W. Shi, W.-N. Chen, Y. Lin, T. Gu, S. Kwong, and J. Zhang, \"An adaptive estimation of distribution algorithm for multipolicy insurance investment planning,\" IEEE Trans. Evol. Comput., vol. 23, no. 1, pp. 1-14, Feb. 2019."
      },
      {
        "ref_id": "46",
        "text": "K. Simonyan and A. Zisserman, \"Very deep convolutional networks for large-scale image recognition,\" in Proc. Int. Conf. Learn. Represent, 2015, pp. 1-14."
      },
      {
        "ref_id": "47",
        "text": "I. J. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville, and Y. Bengio, \"Maxout networks,\" in Proc. Int. Conf. Mach. Learn., 2013, pp. 1319-1327."
      },
      {
        "ref_id": "48",
        "text": "M. Lin, Q. Chen, and S. Yan, \"Network in network,\" in Proc. Int. Conf. Learn. Represent., 2014, pp. 1-10."
      },
      {
        "ref_id": "49",
        "text": "R. K. Srivastava, K. Greff, and J. Schmidhuber, \"Highway networks,\" in Proc. Int. Conf. Learn. Represent., 2015, pp. 1-6."
      },
      {
        "ref_id": "50",
        "text": "J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller, \"Striving for simplicity: The all convolutional net,\" in Proc. Int. Conf. Learn. Represent., 2015, pp. 1-14."
      },
      {
        "ref_id": "51",
        "text": "G. Larsson, M. Maire, and G. Shakhnarovich, \"FractalNet: Ultra-deep neural networks without residuals,\" in Proc. Int. Conf. Learn. Represent., 2016, pp. 1-11."
      },
      {
        "ref_id": "52",
        "text": "B. Baker, O. Gupta, N. Naik, and R. Raskar, \"Designing neural network architectures using reinforcement learning,\" in Proc. Int. Conf. Learn. Represent., 2017, pp. 1-18."
      },
      {
        "ref_id": "53",
        "text": "H. Cai, T. Chen, W. Zhang, Y. Yu, and J. Wang, \"Efficient architecture search by network transformation,\" in Proc. 32nd Conf. Artif. Intell., 2018, pp. 2787-2794."
      },
      {
        "ref_id": "54",
        "text": "Z. Zhong, J. Yan, W. Wu, J. Shao, and C.-L. Liu, \"Practical blockwise neural network architecture generation,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 2423-2432."
      },
      {
        "ref_id": "55",
        "text": "L. Xie and A. Yuille, \"Genetic CNN,\" in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Oct. 2017, pp. 1388-1397."
      },
      {
        "ref_id": "56",
        "text": "F. Pedregosa et al., \"Scikit-learn: Machine learning in Python,\" J. Mach. Learn. Res., vol. 12, no. 85, pp. 2825-2830, Oct. 2011."
      },
      {
        "ref_id": "57",
        "text": "C. A. Nienaber et al., \"Aortic dissection,\" Nat. Rev. Dis. Prim., vol. 2, pp. 1-18, Mar. 2016."
      },
      {
        "ref_id": "58",
        "text": "R. J. Harris et al., \"Classification of aortic dissection and rupture on post-contrast CT images using a convolutional neural network,\" J. Digit. Imag., vol. 32, no. 6, pp. 939-946, Sep. 2019."
      },
      {
        "ref_id": "59",
        "text": "C. Xu et al., \"Multifunctional cationic nanosystems for nucleic acid therapy of thoracic aortic dissection,\" Nature Commun., vol. 10, no. 1, pp. 1-15, Jul. 2019."
      },
      {
        "ref_id": "60",
        "text": "S. S. Sumit, D. R. A. Rambli, and S. Mirjalili, \"Vision-based human detection techniques: A descriptive review,\" IEEE Access, vol. 9, pp. 42724-42761, Mar. 2021."
      },
      {
        "ref_id": "61",
        "text": "J.-Y. Li, Z.-H. Zhan, H. Wang, and J. Zhang, \"Data-driven evolutionary algorithm with perturbation-based ensemble surrogates,\" IEEE Trans. Cybern., vol. 51, no. 8, pp. 3925-3937, Aug. 2021."
      },
      {
        "ref_id": "62",
        "text": "Z.-J. Wang, Z.-H. Zhan, S. Kwong, H. Jin, and J. Zhang, \"Adaptive granularity learning distributed particle swarm optimization for largescale optimization,\" IEEE Trans. Cybern., vol. 51, no. 3, pp. 1175-1188, Mar. 2021."
      },
      {
        "ref_id": "63",
        "text": "X.-F. Liu et al., \"Neural network-based information transfer for dynamic optimization,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 31, no. 5, pp. 1557-1570, May 2020."
      },
      {
        "ref_id": "64",
        "text": "X.-F. Liu, Z.-H. Zhan, Y. Gao, J. Zhang, S. Kwong, and J. Zhang, \"Coevolutionary particle swarm optimization with bottleneck objective learning strategy for many-objective optimization,\" IEEE Trans. Evol. Comput., vol. 23, no. 4, pp. 587-602, Aug. 2019."
      },
      {
        "ref_id": "65",
        "text": "Z.-G. Chen, Z.-H. Zhan, H. Wang, and J. Zhang, \"Distributed individuals for multiple peaks: A novel differential evolution for multimodal optimization problems,\" IEEE Trans. Evol. Comput., vol. 24, no. 4, pp. 708-719, Aug. 2020."
      },
      {
        "ref_id": "66",
        "text": "S. H. Wu, Z. H. Zhan, and J. Zhang, \"SAFE: Scale-adaptive fitness evaluation method for expensive optimization problems,\" IEEE Trans. Evol. Comput., vol. 25, no. 3, pp. 479-491, Jun. 2021."
      },
      {
        "ref_id": "67",
        "text": "J.-Y. Li, Z.-H. Zhan, R.-D. Liu, C. Wang, S. Kwong, and J. Zhang, \"Generation-level parallelism for evolutionary computation: A pipelinebased parallel particle swarm optimization,\" IEEE Trans. Cybern., early access, Nov. 4, 2020, doi: 10.1109/TCYB.2020.3028070."
      },
      {
        "ref_id": "68",
        "text": "Y. F. Ge et al., \"Distributed memetic algorithm for outsourced database fragmentation,\" IEEE Trans. Cybern., Nov. 4, 2020, doi: 10.1109/TCYB.2020.3027962."
      },
      {
        "ref_id": "69",
        "text": "J. Too and S. Mirjalili, \"A hyper learning binary dragonfly algorithm for feature selection: A COVID-19 case study,\" Knowl.-Based Syst., vol. 212, pp. 1-16, Jan. 2021."
      },
      {
        "ref_id": "70",
        "text": "S. M. I. Jalali, S. Ahmadian, A. Khoszavi, S. Mirjalili, M. R. Mahmoudi, and S. Nahavandi, \"Neuroevolution-based autonomous robot navigation: A comparative study,\" Cognit. Syst. Res., vol. 62, pp. 35-43, Aug. 2020."
      }
    ],
    "reference_count": 70,
    "pattern_matched": "(?:^|\\n)#+\\s*References?\\s*\\n"
  },
  "tables": [
    {
      "table_number": "I",
      "table_title": "Settings of Mixed-Variable Encoding for Widely Seen Hyperparameters When Designing CNNs",
      "headers": [
        "Hyperparameters",
        "Available Choices",
        "Encoding Way",
        "Search Space After <br> Encoding",
        "Initialization Range <br> Space"
      ],
      "rows": [
        [
          "Number of kernels in convolution layer",
          "$\\{1,2,3, \\ldots,+\\infty\\}$",
          "continuous variable",
          "$\\{1,+\\infty)$",
          "$[64,512]$"
        ],
        [
          "Number of neurons in fully connected layer",
          "$\\{1,2,3, \\ldots,+\\infty\\}$",
          "continuous variable",
          "$\\{1,+\\infty)$",
          "$[64,1024]$"
        ],
        [
          "Kernel size of the convolution layer",
          "$\\{3 \\times 3,5 \\times 5,7 \\times 7,9 \\times 9\\}$",
          "discrete variable",
          "$\\{0,1,2,3\\}$",
          "$\\{0,1,2,3\\}$"
        ],
        [
          "Kind of activation function",
          "$\\{$ Relu, Sigmoid, Tanh $\\}$",
          "discrete variable",
          "$\\{0,1,2\\}$",
          "$\\{0,1,2\\}$"
        ],
        [
          "Kind of pooling layer",
          "$\\{$ Max-pooling, Average-pooling $\\}$",
          "discrete variable",
          "$\\{0,1\\}$",
          "$\\{0,1\\}$"
        ]
      ],
      "row_count": 5,
      "column_count": 5
    },
    {
      "table_number": "II",
      "table_title": "Comparisons With State-of-the-Art Methods on CIFAR10 and CIFAR100",
      "headers": [
        "Methods",
        "Network Models",
        "CIFAR10",
        "CIFAR100",
        "\\# Parameters",
        "GPU days"
      ],
      "rows": [
        [
          "",
          208,
          91.25,
          "-",
          0.27,
          "-"
        ],
        [
          "",
          1108,
          93.57,
          74.84,
          1.7,
          "-"
        ],
        [
          "",
          12028,
          92.07,
          72.18,
          10.2,
          "-"
        ],
        [
          "",
          -10,
          95.49,
          77.72,
          0.8,
          "-"
        ],
        [
          "Manually-design CNNs",
          -46,
          93.34,
          71.95,
          20.04,
          "-"
        ],
        [
          "",
          47,
          90.7,
          61.4,
          "-",
          "-"
        ],
        [
          "",
          48,
          91.19,
          64.32,
          "-",
          "-"
        ],
        [
          "",
          49,
          92.4,
          67.66,
          "-",
          "-"
        ],
        [
          "",
          -50,
          92.75,
          66.29,
          1.3,
          "-"
        ],
        [
          "",
          51,
          94.76,
          77.51,
          22.9,
          "-"
        ],
        [
          "",
          11,
          93.99,
          "-",
          2.5,
          22400
        ],
        [
          "Non-EC-based CNN optimization approaches",
          52,
          93.08,
          72.86,
          "-",
          100
        ],
        [
          "",
          53,
          95.77,
          "-",
          23.4,
          10
        ],
        [
          "",
          "Block-QNN-S [54]",
          95.62,
          79.35,
          6.1,
          90
        ],
        [
          "",
          -13,
          94.6,
          "-",
          5.4,
          2750
        ],
        [
          "",
          -13,
          "-",
          77.0,
          40.4,
          2750
        ],
        [
          "",
          14,
          96.37,
          "-",
          "-",
          300
        ],
        [
          "EC-based CNN optimization approaches",
          -19,
          94.02,
          "-",
          1.68,
          27
        ],
        [
          "",
          -23,
          96.78,
          "-",
          2.9,
          35
        ],
        [
          "",
          -23,
          "-",
          79.47,
          4.1,
          40
        ],
        [
          "",
          -24,
          95.7,
          "-",
          "-",
          27
        ],
        [
          "",
          -24,
          "-",
          79.15,
          "-",
          36
        ],
        [
          "",
          -225,
          94.7,
          77.98,
          "-",
          8.5
        ],
        [
          "",
          55,
          92.9,
          70.97,
          "-",
          817
        ],
        [
          "",
          "SHEDA-CNN",
          96.36,
          "-",
          10.88,
          0.58
        ],
        [
          "",
          "SHEDA-CNN",
          "-",
          78.84,
          18.64,
          0.97
        ]
      ],
      "row_count": 26,
      "column_count": 6
    },
    {
      "table_number": "III",
      "table_title": "Comparisons Among Different Variants of the Proposed Algorithm",
      "headers": [
        "Variants",
        "CIFAR10",
        "",
        "",
        "CIFAR100",
        "",
        ""
      ],
      "rows": [
        [
          "",
          "Accuracy",
          "\\# Parameters",
          "GPU days",
          "Accuracy",
          "\\# Parameters",
          "GPU days"
        ],
        [
          "SHEDA-CNN",
          96.36,
          10.88,
          0.58,
          78.84,
          18.64,
          0.97
        ],
        [
          "SHEDA-w/o-OI-CNN",
          "$95.85(+)$",
          8.49,
          0.6,
          "$77.06(+)$",
          12.31,
          1.05
        ],
        [
          "SHEDA-w/o-AHL-CNN",
          "$96.27(\\mathrm{e})$",
          8.43,
          0.54,
          "$78.65(\\mathrm{e})$",
          11.2,
          1.03
        ],
        [
          "SHEDA-w/o-SME-CNN",
          "$96.15(\\mathrm{e})$",
          7.98,
          4,
          "$78.44(\\mathrm{e})$",
          10.23,
          5
        ],
        [
          "SHEDA-w/o-MLDG-CNN",
          "$96.16(\\mathrm{e})$",
          10.8,
          0.62,
          "$78.48(\\mathrm{e})$",
          11.07,
          1.02
        ]
      ],
      "row_count": 6,
      "column_count": 7
    },
    {
      "table_number": "IV",
      "table_title": "Comparisons With SHEDA Variants With DIFERENT SAMPLING NUMBER",
      "headers": [
        "Variants",
        "Accuracy",
        "\\# Parameters",
        "GPU days"
      ],
      "rows": [
        [
          "$S N=300$ (original)",
          "$\\mathbf{9 6 . 3 6}$",
          10.88,
          0.58
        ],
        [
          "$S N=100$",
          "$95.78(+)$",
          "$\\mathbf{5 . 2 1 M}$",
          "$\\mathbf{0 . 4 7}$"
        ],
        [
          "$S N=200$",
          "$95.82(+)$",
          7.79,
          0.52
        ],
        [
          "$S N=400$",
          "$96.10(\\mathrm{e})$",
          6.12,
          0.58
        ],
        [
          "$S N=500$",
          "$96.26(\\mathrm{e})$",
          8.48,
          0.61
        ]
      ],
      "row_count": 5,
      "column_count": 4
    },
    {
      "table_number": "V",
      "table_title": "Comparisons With SHEDA Variants Using the Different Number of Individuals for Updating Probabilistic Models",
      "headers": [
        "Variants",
        "Accuracy",
        "\\# Parameters",
        "GPU days"
      ],
      "rows": [
        [
          "$N_{b}=0.45 \\times N_{\\text {arch }}$",
          "$\\mathbf{9 6 . 3 6}$",
          10.88,
          0.58
        ],
        [
          "$N_{b}=0.3 \\times N_{\\text {arch }}$",
          "$96.22(\\mathrm{\\sim})$",
          8.43,
          "$\\mathbf{0 . 4 8}$"
        ],
        [
          "$N_{b}=0.4 \\times N_{\\text {arch }}$",
          "$96.13(\\mathrm{\\sim})$",
          8.91,
          0.54
        ],
        [
          "$N_{b}=0.5 \\times N_{\\text {arch }}$",
          "$95.86(\\mathrm{\\div})$",
          "$\\mathbf{7 . 9 0 M}$",
          0.58
        ],
        [
          "$N_{b}=0.6 \\times N_{\\text {arch }}$",
          "$95.68(\\mathrm{\\div})$",
          9.11,
          0.61
        ],
        [
          "$N_{b}=0.7 \\times N_{\\text {arch }}$",
          "$95.65(\\mathrm{\\div})$",
          8.98,
          0.58
        ]
      ],
      "row_count": 6,
      "column_count": 4
    },
    {
      "table_number": "VI",
      "table_title": "Results of the AD Diagnosis in Terms of the Number of True Positive, True Negative, False Positive, and False Negative, ACCURACY, the NUMBer of Parameters, and GPU Days",
      "headers": [
        "Methods",
        "\\#TP",
        "\\#TN",
        "\\#FP",
        "\\#FN",
        "Acc- <br> uracy",
        "\\# Para.",
        "GPU <br> days"
      ],
      "rows": [
        [
          20,
          250,
          132,
          3,
          2,
          98.71,
          "$\\mathbf{2 . 9 3 M}$",
          "-"
        ],
        [
          110,
          250,
          "$\\mathbf{1 3 3}$",
          3,
          "$\\mathbf{1}$",
          98.97,
          10.78,
          "-"
        ],
        [
          "SHEDA-CNN",
          "$\\mathbf{2 5 2}$",
          "$\\mathbf{1 3 3}$",
          "$\\mathbf{1}$",
          "$\\mathbf{1}$",
          "$\\mathbf{9 9 . 4 8}$",
          4.18,
          1.18
        ]
      ],
      "row_count": 3,
      "column_count": 8
    }
  ]
}