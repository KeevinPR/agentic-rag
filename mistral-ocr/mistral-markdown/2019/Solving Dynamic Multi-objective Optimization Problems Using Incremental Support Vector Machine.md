# Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine 

Weizhen HU, Min JIANG*, Senior Member, IEEE, Xing Gao, Kay Chen TAN, Fellow, IEEE, and Yiu-ming Cheung, Fellow, IEEE


#### Abstract

The main feature of the Dynamic Multi-objective Optimization Problems (DMOPs) is that optimization objective functions will change with times or environments. One of the promising approaches for solving the DMOPs is reusing the obtained Pareto optimal set (POS) to train prediction models via machine learning approaches. In this paper, we train an Incremental Support Vector Machine (ISVM) classifier with the past POS, and then the solutions of the DMOP we want to solve at the next moment are filtered through the trained ISVM classifier. A high-quality initial population will be generated by the ISVM classifier, and a variety of different types of population-based dynamic multi-objective optimization algorithms can benefit from the population. To verify this idea, we incorporate the proposed approach into three evolutionary algorithms, the multi-objective particle swarm optimization(MOPSO), Nondominated Sorting Genetic Algorithm II (NSGA-II), and the Regularity Modelbased multi-objective estimation of distribution algorithm(REMEDA). We employ experiment5 to test these algorithms, and experimental results show the effectiveness.

Index Terms-Dynamic Multi-objective Optimization Problems; Incremental Support Vector Machine; Pareto Optimal Set


## I. InTRODUCTION

One of the essential characteristics of Dynamic Multiobjective Optimization Problems (DMOPs) [1] is that the optimization functions will change with environments or times, and it is of great significance for many practical applications [2]. Therefore, efficiently solving DMOPs has become an important direction in the field of evolutionary computation community [3]. For example, when designing a missile, the defense department should consider its range, precision, weight and fuel consumption. This is a four-objective optimization problem, and these optimization objectives will vary depending on environments and times. However, Most of the existing methods do not perform well when dealing with such problems. The main difficulty is how to quickly track the changing Pareto optimal front (POF).
W.Hu and M. JIANG are with the Department of Cognitive Science, Xiamen University, China, Fujian, 361005. X. Gao is with the Software School of Xiamen University. Min JIANG is the corresponding author and email: minjiang@xmu.edu.cn.

KC TAN is with the Department of Computer Science, City University of Hong Kong.
Yiu-ming Cheung is with the Department of Computer Science, Hong Kong Baptist University.
978-1-5386-4362-4/18/531.00 (C)2018 IEEE

In recent years, great progress has been made in this field, and many different algorithms have been proposed. Among those algorithms, the methods based on prediction have attracted special attention, and the basic idea of the method is to solve DMOPs by reusing "experience" effectively. For example, Muruganantham et al. [4] proposed a Kalman Filter prediction based DMOEA(MOEA/D-KF) that utilizes a prediction model based on Kalman Filter based on the multiobjective EA with Decomposition.

In this paper, we argue that Incremental Support Vector Machine (ISVM) [5], [6] can be used to train a prediction model, and the model helps any kind of population-based DMOPs algorithms by generating a high-quality initial population. This method has unique advantages in dealing with DMOPs, because it directly establishes connections between different POS, without requiring more computational resources to repeatedly train SVM classifiers.

The contribution of this research is to propose an algorithm which combining evolutionary multi-objective optimization algorithm with the ISVM technique. This combination has the following two advantages. First, the proposed design can improve the search accuracy in the way of reusing past experience. Second, this method trains the SVM classifier in an online manner, and then obtains the initial population for the next time, which can make more efficient use of computing resources.

The rest of this paper is organized as follows: In Section II, we will introduce some basic concepts of dynamic optimization problems, Incremental Support Vector Machine ( ISVM ) and related work. In Section III, we will propose the Incremental Support Vector Machine based Dynamic Multi-Objective Evolutionary optimization Algorithm, ISVMDMOEA. In Section IV we firstly introduce the evaluation criteria, test examples and comparative methods, and then experimental results are analyzed. In Section V, we conclude the main work of this research and the future research direction are discussed.

## II. Preliminaries and Related Works

## A. Concepts of Dynamic Multi-objective Optimization

For dynamic multi-objective optimization problems, its optimization functions often vary with times or environments.

Mathematically, a DMOP can be described as:

$$
\begin{aligned}
\text { minimize } f(x, t)= & \left\langle f_{1}(x, t), f_{2}(x, t), \ldots, f_{m}(x, t)\right\rangle \\
& \text { s.t. } x \in \Omega
\end{aligned}
$$

where $t$ represents time or environment index and $x=$ $\left\langle x_{1}, x_{2}, \ldots, x_{n}\right\rangle$ is the decision vector. $m$ is the number of objectives, $f_{i}(x, t): \Omega \rightarrow \mathbb{R}(i=1, \ldots, M)$ which is the objective space.

Definition 1. [Dynamic Decision Vector Domination] At a particular moment $t$, a decision vector $x_{b}$ is Pareto dominated by another vector $x_{a}$, it can be expressed as $x_{a} \succ_{t} x_{b}$, if and only if:

$$
\left\{\begin{array}{l}
\forall i=1, \ldots, m, \quad f_{i}\left(x_{a}, t\right) \leq f_{i}\left(x_{b}, t\right) \\
\exists i=1, \ldots, m, \quad f_{i}\left(x_{a}, t\right)<f_{i}\left(x_{b}, t\right)
\end{array}\right.
$$

Definition 2. [Dynamic Pareto-optimal Set] At time $t$, if and only if there is no other decision vector $x$ can Pareto dominate decision vector $x^{*}$, the $x^{*}$ is called Pareto optimal solution. All Pareto optimal solutions make up Dynamic Pareto-optimal Set(DPOS) at time $t$, that is:

$$
D P O S=\left\{x^{*} \mid \nexists x, x \succ_{t} x^{*}\right\}
$$

Definition 3. [Dynamic Pareto-optimal Front] The Dynamic Pareto-Optimal Front (DPOF) is the set of corresponding objective vectors of the Pareto optimal solution at time $t$.

$$
D P O F=\left\{f\left(x^{*}, t\right) \mid x^{*} \in D P O S\right\}
$$

## B. Incremental Support Vector Machines

Support Vector Machine ( SVM ) [7] was proposed in 1964 , developed rapidly after the 1990s and spawned a series of improved and extended algorithms. The SVM becomes a wellknown learning method used for classification problems [8], and it is a generalized linear classifier for binary classification of data in supervised learning. Its decision boundary is the maximum-margin hyperplane that is solved for learning samples. Incremental Support Vector Machine (ISVM) is the combination of Online learning technology and the SVM. Incremental technology has been developed to facilitate bulk SVM learning [9] on very large data sets and has been widely used in the SVM community.

Given the training data $\left\{x_{1}, \cdots, x_{N}\right\}$ and learning objective $\left\{y_{1}, \cdots, y_{N}\right\}$ in the classification problem, where each sample of training data contains multiple features and thus constitutes a feature space. The learning objective is a binary variable $y_{i} \in\{1,-1\}$ representing negative class and positive class. A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane, which can be described as:

$$
\mathbf{w}^{\mathbf{T}} \times x+b=0
$$

where $\mathbf{w} \in \mathbb{R}^{l}$ and $b \in \mathbb{R}$.
In linear inseparable problems, the use of SVM with hard margins will generate classification errors, so a new optimization problem can be constructed by introducing loss function
on the basis of maximizing margins. The optimization problem of soft margin SVM is shown as follows [10]:

$$
\begin{gathered}
\operatorname{Minimize}_{(\mathbf{w}, \mathbf{b})} \frac{1}{2}\|\mathbf{w}\|^{2}+l \cdot \sum_{i=1}^{N} \varepsilon_{i} \\
\text { subj. to : } y_{i}\left(\mathbf{w} \times x_{i}+b\right) \geq 1-\varepsilon_{i}, i=i \cdots N
\end{gathered}
$$

Where $l$ is a constant and the second term of Equation (2) provides an upper bound for the error in the training data, and the first term makes maximum margin of separation between classes.
when learning nonlinear SVMs, to simplify matters and then this quadratic program is typically expressed in its dual form:

$$
\min _{0 \leq \alpha_{i} \leq l} W=\frac{1}{2} \sum_{i, j=1}^{N} \alpha_{i} Q_{i j} \alpha_{j}-\sum_{i=1}^{N} \alpha_{i}+b \sum_{i=1}^{N} y_{i} \alpha_{i}
$$

Where $Q_{i j}=y_{i} y_{j} K\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right), K\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\varphi\left(x_{i}\right) \cdot \varphi\left(x_{j}\right)$ is the given kernel function which to implicitly map into a higher (possibly infinite) dimensional feature space.

The Karush-Kuhn-Tucker (KKT) condition uniquely defines the solution of dual parameters $\{\alpha, b\}$, and minimizes the form (2):

$$
\begin{aligned}
& g_{i}=\frac{\partial W}{\partial \alpha_{i}}=\sum_{j=1}^{N} Q_{i j} \alpha_{j}+y_{i} b-1= \begin{cases}>0 & \alpha_{i}=0 \\
=0 & 0<\alpha_{i}<l \\
<0 & \alpha_{i}=l\end{cases} \\
& h=\frac{\partial W}{\partial b}=\sum_{j=1}^{N} y_{j} \alpha_{j}=0
\end{aligned}
$$

The KKT conditions partition the training data into three parts:
$g_{c}=0$, the set $S$ of margin support vectors;
$g_{c} \leq 0$, the set E of error support vectors;
$g_{c}>0$, the set R of the remaining vectors.
When we increment the unlearned examples into the solution, our goal will be to keep all previously seen training data in KKT conditions simultaneously [5].

## C. Related Works

The DMOPs field has made great progress, and existing algorithms can be generally divided into the following categories: Diversity based Approaches, parallel approaches, Memory based Approaches and Change prediction based Approaches .

An important work of diversity based approaches is the Dynamic NSGA-II (DNSGA-II) proposed by [11] in 2006. Deb et al. extended NSGA-II to deal with DMOPs by introducing diversity in each change detection. If the target or constraint violation value has changed, the problem is considered to have changed. Then, all outdated solutions (that is, reassessment). This process allows for the use of changing objectives and constraint functions to evaluate both offspring and parent solutions. In [12], Chen proposed to maintain genetic diversity by regard it as an additional objective when solving multi-objective optimization. They presented the Individual Diversity Evolutionary Method (IDEM) to add a useful selection pressure for optimizing PS and maintaining diversity

[12]. The results show that the algorithm can converge to the optimal solution effectively and track the change of PFs while maintaining the diversity of solution sets.

Parallel EAs utilize several subpopulations that evolve simultaneously under different processors and then communicate some informations in a structured network [13]. In [14], Camara et al. proposed a method to apply parallel single pregenetic algorithm (PSFGA) to dynamic environment. PSFGA is a master-slave architecture algorithm, which divides the population into subpopulations which performs a certain amount of generations and preserve only non-dominant solutions, and then the main process joins all the solutions to a new population.

The memory-based approach uses additional memory to implicitly or explicitly store useful information from past generations to guide future searches. It has been proved that when the optimal solution returns to the previous position repeatedly or the environment changes periodically, this algorithm will help save computing time and bias search process, thus becoming very efficient. In [15], Azzouz et al. proposed an adaptive hybrid population management strategy, which is based on a technology that can measure the severity of environmental changes, then according to the technology it can adjust memory, local search (LS) and the number of random solutions.

When the behavior of dynamic problems follows a certain trend, a prediction model can be used. In 2014, the author defined a new prediction model [16] to solve DMOPs with Translational optimal POS (DMOP-tps). Dmop-tps is a specific type of DMOP in which POS is converted periodically over time. When the environment changes, the strategy proposed by Deb et al. [11] is used to detect the changes. Then, the population is re-initialized according to the properties of DMOP. Muruganantham et al. [4] proposed a Kalman Filter prediction based DMOEA(MOEA/D-KF) based on the multiobjective EA with Decomposition. When the change of environment is detected, kalman filter is applied to the whole population, which leads the search to the new pareto optimal solution in the decision space. The influence of the severity and frequency of change on the performance of the this algorithms is studied.

## III. INCREMENTAL SUPPORT VECTOR MACHINE BASED DYNAMIC MULTI-OBJECTIVE OPTIMIZATION ALGORITHM

A dynamic multi-objective optimization problem is based on the fact that different environments follow different possible distributions, and these are not independent, but interrelated. For the dynamic multi-objective optimization problem, it is easy to get the solution. However, it is difficult for us to judge whether this solution is good or bad, but the solution already obtained should contain useful information, which can be used to predict POS at the next moment. So in this article, we turn the decision problem into a classification problem. In other words, we are constantly training the ISVM classifier through
the information we have obtained, that is, the POS of past moments.

At the same time, a good initial population is the key to solving the dynamic multi-objective problem. A good initial population not only speeds up the solution, but also improves the quality and accuracy of the solution. By training the SVM classifier in an online way, we can use this continuously improved classifier to filter out the solutions, and then generate the initial population at the next moment.

In this article, we propose a incremental support vector machine (ISVM) based dynamic optimization algorithm. The details of the proposed algorithm is descried in Alg. 1.

This algorithm is mainly divided into two modules. At the initial moment, we combine the solution (positive example) in POS obtained by using multi-objective evolutionary algorithm and the randomly generate some solutions of the problem (non-POS, negative example) into training samples, and then obtain a SVM classifier $S C_{S}$. When the environment changes, we regard the changes as the incremental learning process of SVM classifier for the change process of dynamic multiobjective optimization problems. At each change moment, we consider the obtained POS and non-POS as samples to update the parameters of $S C_{S}$ classifier. At the same time, using $S C_{S}$ classifier, we can classify the solutions in the next moment into two categories, "good" and "bad". And the good solutions is reserved as the initial population of the next moment. Finally, we can get the $S C_{S}$ classification model with the best performance.

Remark 1. In this research, we only used the NSGA-II, the MOPSO and the RM-MEDA algorithms to obtain POS at next time, but in fact, any population-based algorithm can use our proposed method to achieve performance improvements.

Remark 2. The $P S A M P L E S_{t}$ at particular moment are obtained by $P O S_{t}$ while $N S A M P L E S_{t}$ are randomly generate [17], and they have the same number.

Remark 3. At the initial moment, we train a SVM classifier $S C_{S}$ by using $P g \in P O S_{0}$ and $N g \notin P O S_{0}$, and when $t$ change from 1 to $n$, we still train the same $S C_{S}$ using $P g \in$ $P S A M P L E S_{t}$ and $N g \in N S A M P L E S_{t}$.

## IV. EMPIRICAL STUDY

In general, our proposed algorithm is applicable to any kind of population-based optimization algorithm. In our experiment, we chose three representative experiments to prove our method. The first multiobjective optimization algorithm is based on particle swarm optimization [18], it was called MOPSO for short. The second one is the NSGA-II and it is a multiobjective genetic algorithm that applies nondominated sorting and crowding distance. The third one is a distribution estimation algorithm [19] based on global statistical information to construct a probability model, We simply refer to it as the RM-MEDA. Obviously, these three algorithms belong to different categories, and they were not originally designed for dynamic optimization. But they are well developed, so we can

```
Algorithm 1: ISVM-DMOEA:Incremental Support
Vector Machines based Dynamic Multi-objective Evo-
lutionary Algorithm
    Input: The Dynamic Multi-objective Optimaztion
        Function \(F(X)\);
        Output: \(P O S s\) : the POSs of \(F(X)\);
    1 Randomly initiate a Population the \(\operatorname{Pop}_{0}\);
    \(2 \operatorname{POS}_{0}=\) DMOEA \(\left(\operatorname{Pop}_{0}\right)\);
    \(3 \operatorname{POS}_{s}=P O S_{0}\);
    4 Train a SVM classifier \(S C_{S}\) by using \(P g \in P O S_{0}\) and
        \(N g \notin P O S_{0}\);
    5 Randomly generate solutions \(\left\{x y_{1}, \cdots, x y_{p}\right\}\) of the
        function \(F(X)_{1}\);
    6 if \(x y_{i}\) pass the recognition of the SVM \(S C_{S}\) then
    7 Put \(x y_{i}\) into \(\operatorname{Pop}_{1}\)
    8 end
    \(9 \operatorname{POS}_{1}=\) DMOEA \(\left(\operatorname{Pop}_{1}\right)\);
    \(10 \operatorname{POS}_{t}=P O S_{t}\);
    11 for \(t=1\) to \(n\) do
        PSAMPLES \(S_{t}=P O S_{t}\);
        Train \(S C_{S}\) by using \(P g \in P S A M P L E S_{t}\) and
            \(N g \in N S A M P L E S_{t}\);
            Randomly generate solutions \(\left\{x y_{1}, \cdots, x y_{p}\right\}\) of the
                function \(F(X)_{t+1}\);
            if \(x y_{i}\) pass the recognition of the SVM \(S C_{S}\) then
                Put \(x y_{i}\) into \(\operatorname{Pop}_{t+1}\)
            end
            \(\operatorname{POS}_{t+1}=\operatorname{DMOEA}\left(\operatorname{Pop}_{t+1}\right)\);
            \(\operatorname{POSs}=P O S s \cup P O S_{t+1}\);
    end
    return POSs;
```

improve our level of persuasion and confidence in the technologies we propose. The three corresponding algorithms with incremental SVM are called ISVM-MOPSO, ISVM-NSGAII, and ISVM-RMMEDA respectively. It is worth noting that parameters, such as population size, iteration number are all the same. In other words, for the three groups of algorithms, we did not deliberately adjust the experimental parameters for getting better performances.

## A. Performance Metrics, Testing Functions and Settings

In this study, when comparing with other competitive algorithms, we use inversed generational distance (IGD) and its variants as performance indicators to evaluate the quality of solutions obtained by different algorithms.

1) The inverted generational distance (IGD) [21] is an index to measure the distance between the real Pareto Optimal Front expressed by $Q^{*}$, and the approximate Pareto Optimal Front obtained by the algorithm, which we use $Q$ to represent. Then the definition of the IGD can be described as

$$
\operatorname{IGD}\left(Q^{*}, Q, C\right)=\frac{\sum_{p^{*}} \in Q^{*}} \frac{\min _{p \in Q}\left\|p^{*}-p\right\|}{\left|Q^{*}\right|}
$$

It is worth noting that the definition of IGD in this paper is slightly different from the original definition. The main difference is the parameter $C$ in Equation (3), which we call the configuration of the benchmark functions. The configurations used in this experiment are shown in Table I. IGD compares the ideal POF with the POF obtained by other algorithms. If the distance between P and $\mathrm{P}^{*}$ is closer, the smaller the value of IGD, the higher the performance of the algorithm is to some extent. One variant of the IGD, called MIGD, can also be used to evaluate dynamic multiobjective optimization algorithms, and it takes the average of the IGD values in some time steps over a run as the performance metric, given by: [4], [22]. MIGD is the average value of IGD values at a certain time step in each run,described as:

$$
\operatorname{MIGD}\left(Q^{*}, Q, C\right)=\frac{1}{|T|} \sum_{t \in T} \operatorname{IGD}\left(Q_{t}^{*}, Q_{t}, C\right)
$$

Where $T$ represents the set of all moments. At time $\mathrm{t}, Q_{t}^{*}$ represents the point set of the ideal POF, and $Q^{t}$ represents the approximate POF obtained by the algorithm. In addition, we also hope to evaluate these algorithms in a dynamic environment, so we have defined a new indicator DMIGD based on MIGD. The definition of DMIGD is as follows:

$$
\operatorname{DMIGD}\left(Q^{*}, Q, C\right)=\frac{1}{|E|} \sum_{C \in E} \operatorname{MIGD}\left(Q_{t}^{*}, Q_{t}, C\right)
$$

Where $|E|$ is the number of different environments experienced. We used eight different environmental configurations to conduct our experiments. It is worth noting that DMIGD allows us to evaluate the dynamic multi-objective optimization algorithm from a high-level perspective, and MIGD only considers the dynamics in an environment, so it is obviously different from MIGD.

## B. Test Instances and Experimental Settings

In this research, we take the IEEE CEC 2015 benchmark problems set as test functions and the problem set has eleven testing functions. Details of the functions definitions are given in [23]. In the definitions, the decision variables are $x=\left(x_{1}, \ldots, x_{n}\right)$ and $t=\frac{1}{n_{t}}\left\lfloor\frac{\tau_{T}}{\tau_{t}}\right\rfloor$, where $n_{t}, \tau_{T}$, and $\tau_{t}$ are the severity of change, maximum number of iterations, and frequency of change respectively. Table I describes the different combinations of $n_{t}, \tau_{t}$, and $\tau_{T}$ used in our experiments. Please note that, for each $n_{t}-\tau_{T}$ combination, there will be $\frac{\tau_{T}}{\tau_{T}}$ environment changes. In other words, in all of our experiments, every test function requires 20 environmental transformations for each pair of $n_{t}-\tau_{T}$ combination.

The POFs of the testing functions have different shapes and each function belongs to a certain DMOPs type. For example, the POF of dMOP3 and DIMP2 is convex while the POF of HE2 is discontinuous. and for FDA5,the spread of POF solutions changes over time. Table II describes the types of the testing functions. Type I means POS changes, but POF does not; Type II implies that when POS changes, POF changes

TABLE I. Environment Settings

|  | $a_{1}$ | $T_{1}$ | $T_{T}$ |
| :-- | :--: | :--: | :--: |
| C1 | 10 | 5 | 100 |
| C2 | 10 | 10 | 200 |
| C3 | 10 | 25 | 500 |
| C4 | 10 | 50 | 1000 |
| C5 | 1 | 10 | 200 |
| C6 | 1 | 50 | 1000 |
| C7 | 20 | 10 | 200 |
| C8 | 20 | 50 | 1000 |

accordingly; Type III indicates that POF has changed, but POS has not.

TABLE II. Characteristic of the test functions

| Name | Decision <br> Variable <br> Dimension | Objectives | DMOP Type |
| :-- | :--: | :--: | :--: |
| FDA4 | 12 | 3 | TYPE I |
| FDA5 | 12 | 3 | TYPE II |
| DIMP2 | 10 | 2 | TYPE I |
| dMOP2 | 10 | 2 | TYPE II |
| HE7 | 10 | 2 | TYPE III |
| HE9 | 10 | 2 | TYPE III |

As depicted in Table II, the dimensions of the decision variables are 10 and 12, In all experiments, the population size was set to 200 . As mentioned earlier, for each environment configuration, we changed each benchmark function 20 times, and in every change, we let the entire population perform 50 iterations in the evolutionary algorithm. For the incremental Support Vector Machines, we set the kernel type is Gaussian kernel and kernel scale is obtained by the Grid Search method [24].

## C. Experimental Results

In this study, we conducted two different kinds of experiments. In the first kind of experiment, we incorporate the proposed approach into the development of three wellknown evolutionary algorithms, multiojective particle swarm optimization (MOPSO), nondominated sorting genetic algorithm II (NSGA-II), and the regularity model-based multiobjective estimation of distribution algorithm (RM-MEDA). We employ six benchmark functions to test these algorithms. The experimental results are recored in Table. III. In almost all experiments, the proposed method has been significantly improved compared with the original method.

In the second kind of experiment, we compared the ISVM-RM-MEDA with some chosen algorithms, and the results are recorded in Table. IV. The MBN-EDA [25] is an estimation algorithm, in which the dependence between decision variables and target variables is obtained by using a multidimensional Bayesian network. MOEA $\backslash \mathrm{D}-\mathrm{KF}$ was presented in [4] and this idea for solving DMOPs is to predict the decision space by Kalman filter. SVM-NSGA-II was proposed in [26] and it is a support vector machine based dynamic MOPs algorithm.

For incremental SVM, a major iteration corresponds to contain a new example. Therefore, the computational com-
plexity estimates must be multiplied by the number of training instances learned so far. The actual runtime depends on the balance between arithmetic operations and memory access in a small iteration. In our proposed method, when adding new samples incrementally, we can use the SVM classifier that has been obtained in the past moment to simplify the computation cost of searching the solution of the next quadratic programming. By the way, for samples that are not partitioned into the set $s$ of margin support vectors, there is no need to carry out new iterations and update core parameters, which is the key module for computation cost in incremental SVM usage.

## V. CONCLUSION

Evolutionary algorithms can solve dynamic multi-objective optimization problems more effectively through good initial populations, but getting a good initial population is a difficult and resource-consuming problem. In order to avoid wasting valuable computing resources on repeated computing, our basic idea is that incremental training support vector machine classifiers can be trained by using the POS have been obtained at different times, and when changes occur, the parameter of SVM classifier will be updated in an online manner, then the trained classifier will filter the solution at the next moment, and the good individuals will be selected as the initial population. This initial population can help any kind of population-based algorithms to solve the dynamic multi-objective optimization problem quickly and more accurately.

This research is just a new starting point, after which we will learn how to combine incremental support vector machines with transfer learning [27] or imbalanced learning techniques [28]. On the other hand, we also want to study use deep learning methods [20] to automatically generate better samples to solve the real world problems, such as motion generation of Multi-Legged Robot [29] and dynamic path planning [30].

## ACKNOWLEDGMENT

This work was supported by the National Natural Science Foundation of China (Grant No.61673328) and Shenzhen Scientific Research and Development Funding Program ( Grant No. JCYJ20180307123637294).

## REFERENCES

[1] M. Farina, K. Deb, and P. Amato, "Dynamic multiobjective optimization problems: test cases approximations, and applications," IEEE Transactions on Evolutionary Computation, vol. 8, no. 5, pp. 425-442, oct 2004.
[2] C. Cruz, J. R. González, and D. A. Pelta, "Optimization in dynamic environments: a survey on problems methods and measures," Soft Comput, vol. 15, no. 7, pp. 1427-1448, dec 2010.
[3] T. T. Nguyen, S. Yang, and J. Branke, "Evolutionary dynamic optimization: A survey of the state of the art," Swarm and Evolutionary Computation, vol. 6, pp. 1-24, oct 2012.
[4] A. Muruganantham, K. Tan, and P. Vadakkepat, "Evolutionary Dynamic Multiobjective Optimization Via Kalman Filter Prediction," IEEE Transactions on Cybernetics, vol. 46, no. 12, pp. 2862-2873, Dec 2016.
[5] P. Laskov, C. Geld, S. Krger, and K. R. Miller, "Incremental support vector learning: analysis, implementation and applications," Journal of Machine Learning Research, vol. 7, no. 3, p. 2006, 2006.
[6] T. Tufar and B. Filipić, "Differential evolution versus genetic algorithms in multiobjective optimization," in International Conference on Evolutionary Multi-Criterion Optimization. Springer, 2007, pp. 257-271.

TABLE III. The MIGD Values between NSGA-II, ISVM- NSGA-II, MOPSO, ISVM-MOPSO, RM-MEDA and ISVM-RM-MEDA

| DMIGD | NSGA-II | ISVM-NSGAII | MOPSO | ISVM-MOPSO | RM-MEDA | ISVM-RM-MEDA |
| :-- | :--: | :--: | :--: | :--: | :--: | :--: |
| FDA4 | 0.2783 | $\mathbf{0 . 1 8 3 9}$ | 0.0812 | $\mathbf{0 . 0 7 3 1}$ | 0.0684 | $\mathbf{0 . 0 6 3 9}$ |
| FDA5 | 0.3580 | $\mathbf{0 . 2 6 0 4}$ | 0.2510 | $\mathbf{0 . 1 5 8 6}$ | 0.2345 | $\mathbf{0 . 1 1 5 7}$ |
| DIMP2 | 3.9818 | $\mathbf{2 . 5 1 5 4}$ | 2.6386 | $\mathbf{2 . 3 4 1 0}$ | 4.9631 | 5.2002 |
| DMOP2 | 0.6590 | $\mathbf{0 . 0 9 2 2}$ | 0.2984 | $\mathbf{0 . 0 8 8 1}$ | 4.5942 | $\mathbf{4 . 5 2 2 8}$ |
| HE7 | 0.0946 | $\mathbf{0 . 0 5 3 4}$ | 0.0636 | $\mathbf{0 . 0 5 6 1}$ | 0.0428 | $\mathbf{0 . 0 3 4 2}$ |
| HE9 | 0.2945 | $\mathbf{0 . 2 4 7 3}$ | 0.2502 | $\mathbf{0 . 2 4 5 0}$ | 0.2581 | $\mathbf{0 . 2 3 3 7}$ |

TABLE IV. The MIGD Values between MBN-EDA, MOE/D-KESVM-NSGA-II,ISVM-RM-MEDA

| DMIGD | MBN-EDA | MOE/D-KF | SVM-NSGA-II | ISVM-RMMEDA |
| :-- | :--: | :--: | :--: | :--: |
| FDA4 | 0.4300 | 0.1913 | 0.2166 | $\mathbf{0 . 0 6 3 9}$ |
| FDA5 | 0.5100 | 0.4963 | 0.2910 | $\mathbf{0 . 1 1 5 7}$ |
| DIMP2 | 3.9818 | 22.9536 | $\mathbf{2 . 8 4 6 3}$ | 5.2002 |
| DMOP2 | 0.6590 | 3.0619 | $\mathbf{0 . 1 3 5 6}$ | 4.5228 |
| HE7 | 0.2100 | 0.2365 | 0.0728 | $\mathbf{0 . 0 3 4 2}$ |
| HE9 | 0.3600 | 0.4108 | 0.2497 | $\mathbf{0 . 2 3 3 7}$ |

[7] B. E. Boxer, I. M. Guyon, and V. N. Vapnik, "A training algorithm for optimal margin classifiers," in Proceedings of the fifth annual workshop on Computational learning theory. ACM, 1992, pp. 144-152.
[8] E. Osuna, R. Freund, and F. Girosi, "An improved training algorithm for support vector machines," in Neural Networks for Signal Processing VII-Proceedings of the 1997 IEEE Workshop, 1997, pp. 276-285.
[9] G. Cauwenberghs and T. Poggio, "Incremental and decremental support vector machine learning," in International Conference on Neural Information Processing Systems, 2000, pp. 388-394.
[10] C. P. Diehl and G. Cauwenberghs, "Svm incremental learning, adaptation and optimization," in International Joint Conference on Neural Networks, 2003, pp. 2685-2690 vol. 4.
[11] K. Deb, S. Karthik et al., "Dynamic multi-objective optimization and decision-making using modified noga-ii: a case study on hydro-thermal power scheduling," in International Conference on Evolutionary MultiCriterion Optimization. Springer, 2007, pp. 803-817.
[12] H. Chen, M. Li, and X. Chen, "Using diversity as an additional-objective in dynamic multi-objective optimization algorithms," 2009.
[13] E. Alba, "Parallel evolutionary algorithms can achieve super-linear performance," Information Processing Letters, vol. 82, no. 1, pp. 7-13, 2002.
[14] M. Cmara, J. Ortega, and F. D. Toro, "A single front genetic algorithm for parallel multi-objective optimization in dynamic environments," Neurocomputing, vol. 72, no. 16, pp. 3570-3579, 2009.
[15] R. Azzouz, S. Bechikh, and L. B. Said, "A dynamic multi-objective evolutionary algorithm using a change severity-based adaptive population management strategy," Soft Computing, vol. 21, no. 4, pp. 1-22, 2015.
[16] Z. Li, H. Chen, Z. Xie, C. Chen, and A. Sallam, "Dynamic multiobjective optimization algorithm based on average distance linear prediction model," The Scientific World Journal, vol. 2014, 2014.
[17] H. Guo, Y. Li, J. Shang, M. Gu, Y. Huang, and B. Gong, "Learning from class-imbalanced data: Review of methods and applications," Expert Systems with Applications, vol. 73, pp. 220-239, 2016.
[18] C. C. Coello and M. S. Lechuga, "Mopso: A proposal for multiple objective particle swarm optimization," in Evolutionary Computation, 2002. CEC'02. Proceedings of the 2002 Congress on, vol. 2. IEEE, 2002, pp. 1051-1056.
[19] Q. Zhang, A. Zhou, and Y. Jin, "Rm-meda: A regularity model-based multiobjective estimation of distribution algorithm," IEEE Transactions on Evolutionary Computation, vol. 12, no. 1, pp. 41-63, 2008.
[20] M. Jiang, Y. Ding, B. Goertzel, Z. Huang, C. Zhou, and F. Chao, "Improving machine vision via incorporating expectation-maximization into deep spatio-temporal learning," in 2014 International Joint Conference on Neural Networks (IJCNN). IEEE, 2014, pp. 1804-1811.
[21] M. R. Sierra and C. A. C. Coello, "Improving pso-based multiobjective optimization using crowding, mutation and $\epsilon$-dominance," in International Conference on Evolutionary Multi-Criterion Optimization. Springer, 2005, pp. 505-519.
[22] A. Muruganantham, K. C. Tan, and P. Vadakkepat, "Solving the IEEE CEC 2015 dynamic benchmark problems using Kalman filter based dynamic multiobjective evolutionary algorithm," in Proceedings in Adaptation Learning and Optimization. Springer Science matphus Business Media, nov 2015, pp. 239-252.
[23] M. Helbig and A. Engelbrecht, "Benchmark functions for cec 2015 special session and competition on dynamic multi-objective optimization," Tech. Rep., 2015.
[24] S. Fine and K. Scheinberg, "Incremental learning and selective sampling via parametric optimization framework for svm," in Advances in neural information processing systems, 2002, pp. 705-711.
[25] H. Karshanas, R. Santana, C. Bielza, and P. Larraruga, "Multiobjective estimation of distribution algorithm based on joint modeling of objectives and variables," IEEE Transactions on Evolutionary Computation, vol. 18, no. 4, pp. 519-542, 2014.
[26] M. Jiang, W. Hu, L. Qiu, M. Shi, and K. C. Tan, "Solving dynamic multiobjective optimization problems via support vector machine," in 2018 Tenth International Conference on Advanced Computational Intelligence (ICACI), March 2018, pp. 819-824.
[27] M. Jiang, W. Huang, Z. Huang, and G. G. Yen, "Integration of global and local metrics for domain adaptation learning via dimensionality reduction," IEEE Transactions on Cybernetics, vol. 47, no. 1, pp. 38-51, Jan 2017.
[28] M. Jiang, Z. Huang, L. Qiu, W. Huang, and G. G. Yen, "Transfer learning-based dynamic multiobjective optimization algorithms," IEEE Transactions on Evolutionary Computation, vol. 22, no. 4, pp. 501-514, Aug 2018.
[29] M. Jiang, Z. Huang, G. Jiang, M. Shi, and X. Zeng, "Motion generation of multi-legged robot in complex terrains by using estimation of distribution algorithm," in 2017 IEEE Symposium Series on Computational Intelligence (SSCI). IEEE, 2017, pp. 1-6.
[30] M. Jiang, Y. Yu, X. Liu, F. Zhang, and Q. Hong, "Fuzzy neural network based dynamic path planning," in 2012 International Conference on Machine Learning and Cybernetics, vol. 1. IEEE, 2012, pp. 326-330.