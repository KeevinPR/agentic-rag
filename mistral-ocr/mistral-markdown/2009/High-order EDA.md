# HIGH-ORDER EDA 

JIN ZENG ${ }^{1}$, QING-SHENG REN $^{2}$<br>${ }^{1}$ Department of Mathematics, Shanghai Jiao Tong University, Shanghai 200240, P. R. China<br>${ }^{2}$ Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, P. R. China<br>E-MAIL: zengjin@sjtu.edu.cn, ren-qs@cs.sjtu.edu.cn


#### Abstract

: In this paper, we investigate the usage of history information for estimation of distribution algorithm (EDA). In EDA, the distribution is estimated from a set of selected individuals and then the estimated distribution model is used to generate new individuals. It needs large population size to converge to the global optimum. A new algorithm, the high-order EDA, is proposed based on the idea of filter. By the usage of history information, it can converge to the global optimum with high probability even with small population size. Convergence properties are then discussed. We also show the application for constrained optimization problems.


## Keywords:

Estimation of distribution algorithm (EDA); High-order EDA; Convergence; Constraint optimization

## 1. Introduction

Genetic algorithms (GAs) are population-based optimization methods based on the evolutionary theory. Most of the theory of GAs deals with the building blocks [1]. The genetic algorithms implicitly manipulate a large number of building blocks by mechanisms of selection and re-combination, i.e., reproduce and mix building blocks. But two crucial factors of the GA success, a proper growth and mixing of good building blocks, are often not achieved [2]. The fixed mapping from the space of solutions into the internal representation of the solutions in the algorithm and simple two-parent recombination operators soon showed to be insufficiently powerful even for problems that are composed of simpler partial sub-problems. The problem-independent recombination operators often break partial solutions what can sometimes lead to losing these and converge to a local optimum.

Various attempts to prevent the disruption of important partial solutions have been done. An interesting direction is to estimate the distribution of the promising solutions and use this estimate in order to generate new individuals. A general scheme of the algorithms based on this principle is called the Estimation of Distribution Algorithm (EDA) [3],
which is showed as:

1) $\quad \mathrm{t}=0$, randomly generate initial population $P(0)$
2) select a set of promising solutions $P^{s}(t)$ from $P(t)$
3) estimate the distribution of the selected set $P^{s}(t)$
4) create a new population $P(t+1)$ according to the estimate, $t=t+1$
5) if the termination criteria are not met, go to 2 )

EDAs differ in the way of estimating the distribution and using this estimate for generation of new individuals. The simplest way is to assume that the variables are independent and to look at the values of each variable regardless of the remaining solutions, like UMDA [3]. This kind of algorithms works well on linear problems where the variables are not mutually interacting. Pairwise models allow covering some interactions in a problem and are very easy to learn. The algorithms based on pairwise models, such as MIMIC [4], reproduce and mix building blocks of order two very efficiently, and therefore they work very well on both linear and quadratic problems. In order to deal with the problems with multivariate or highly-overlapping building blocks, we need more complex models, such as FDA [5] and BOA [6].

Although EDA is used successfully in many kinds of application, it has the shortcoming of large population size. In order to achieve optima, EDA always needs a critical population size. The determination of a sufficient size of the population turned out to be difficult. Like GAs, EDA only use the information of the selected population and do not use any information of the population before selection. In this paper we will introduce a new algorithm which is called high-order EDA. By using the information of the evolution process, this new algorithm can achieve good results with small population size. The paper is organized as follows. The framework of the high-order EDA is proposed in Section 2. Section 3 gives some convergence results for high-order EDA. In Section 4, we will show how to use high-order EDA to solve constraint optimization problems. Section 5 summarizes the paper.

## 2. High-order EDA

### 2.1. Frame of high-order EDA

In EDA, the new population is normally generated by the distribution of $P^{c}(t)$, i.e.,

$$
P(x, t)=P^{c}(x, t-1)
$$

From this equation we can find that the new population only uses the information of the selected population and has no relation with the last generation. Some researchers noticed this point and proposed some new algorithms, such as IUMDA [7], PBIL [8] and HCwL [9]. Although the realization of these algorithms is different, the basic ideas are the same as the following:

$$
P(x, t)=\lambda P^{c}(x, t-1)+(1-\lambda) P(x, t-1) \quad 0 \leq \lambda \leq 1
$$

i.e., the distribution of the new population not only use the information after selection; but also use the information before selection. When $\lambda=1$, it belongs to the traditional EDA. When $\lambda=0$, the individual probability keeps unchanged and loses the capability of finding optimal solution.

If we consider equation (1) as the description of a linear system, we can get the transformation function of this linear system

$$
H(z)=\frac{\lambda z^{-1}}{1-(1-\lambda) z^{-1}}
$$

Obviously it is an IIR digital low pass filter. It can enhance the low-frequency content and restrain the high-frequency content. In this way the serge near the convergent point will be restrained and at the same time the convergence speed will be improved. Because $0 \leq \lambda \leq 1$, this filter is steady. But when $\lambda$ tends to 0 the inertia will be increased and the function of the selection operator will be decreased. When $\lambda=0$ the selection is useless; In order to prevent this problem, we can limit the range of $\lambda$. We also can use FIR filter. In this situation we let

$$
\begin{gathered}
P(x, t)=\sum_{i=1}^{m} \alpha_{i} P^{c}(x, t-i) \\
0 \leq \alpha_{i} \leq 1, \quad \sum_{i=1}^{m} \alpha_{i}=1
\end{gathered}
$$

We call the algorithm based on equation (2) as high-order EDA and $m$ is the order. The corresponding transformation function is

$$
H(z)=\sum_{i=1}^{m} \alpha_{i} z^{-i}
$$

In the following, we let $m=2$ for simplicity and it can be called as $2^{\text {nd }}$-order EDA. The core equation of
$2^{\text {nd }}$-order EDA can be written as

$$
P(x, t)=\lambda P^{c}(x, t-1)+(1-\lambda) P^{c}(x, t-2) \quad 0 \leq \lambda \leq 1
$$

And the frame of 2-order EDA can be summarized as

1) $t=0$, randomly generate initial population $P(0)$
2) select a set of promising solutions $P^{c}(0)$ from $P(0)$
3) estimate the distribution of the selected set $P^{c}(0)$
4) create a new population $P(1)$ according to the estimate, $t=1$
5) select a set of promising solutions $P^{c}(t)$ from $P(t)$
6) estimate the distribution of the selected set $P^{c}(t)$
7) create a new population according to the estimate $P(x, t)=\lambda P^{c}(x, t-1)+(1-\lambda) P^{c}(x, t-2)$
8) if the termination criteria are not met, $t=t+1$, go to 5)

## 2.2. $2^{\text {nd }}$-order UMDA

In order to implement UMDA, estimates for the univariate marginal distributions are necessary. These estimates can be simply provided by the selected parents. In this case, the new individual $x=\left(x_{1} x_{2} \cdots x_{n}\right)$ is created according to the following equations:

$$
\begin{gathered}
P\left(x_{i}, t\right)=P^{c}\left(x_{i}, t-1\right) \\
P\left(x_{1} x_{2} \cdots x_{n}, t\right)=P\left(x_{1}, t\right) P\left(x_{2}, t\right) \cdots P\left(x_{n}, t\right)
\end{gathered}
$$

But the previous marginal frequencies can also be taken into accounts as well. In IUMDA, the update rule for the $i$ th gene is

$$
P\left(x_{i}, t\right)=\lambda P^{c}\left(x_{i}, t-1\right)+(1-\lambda) P\left(x_{i}, t\right), \quad 0 \leq \lambda \leq 1
$$

When $\lambda=1$, IUMDA is identical to traditional UMDA.
If the UMDA is combined with $2^{\text {nd }}$-order EDA, the estimate for the univariate marginal distribution can be got as the following:

$$
P\left(x_{i}, t\right)=\lambda P^{c}\left(x_{i}, t-1\right)+(1-\lambda) P^{c}\left(x_{i}, t-2\right), \quad 0 \leq \lambda \leq 1
$$

When $\lambda=1,2^{\text {nd }}$-order EDA is also identical to traditional UMDA.
Eg 1(OneMax) $\max \sum_{i=1}^{n} x_{i}, x_{i}=0,1$
This problem, which is called as OneMax problem, is a very simple optimization problem. Because each variable is independent to each other, it can be solved by UMDA.

In Table 1, we compared UMDA with IUMDA and $2^{\text {nd }}$-order EDA. With the given population size $N$ and $\lambda$, 100 independent experiments were made. In each experiment, the population can converge within 100

generations. The experimental results are expressed by the runs it converges the global optimum among these 100 independent runs.
Table 1. Successful rate of UMDA, IUMDA and $2^{\text {nd }}$-order EDA for OneMax

|  |  | $\lambda$ | $\mathrm{n}=500$ | $\mathrm{n}=700$ | $\mathrm{n}=1000$ |
| :--: | :--: | :--: | :--: | :--: | :--: |
| $\mathrm{N}=100$ | UMDA |  | 0 | 0 | 0 |
|  | IUMDA | 0.7 | 1 | 0 | 0 |
|  |  | 0.5 | 0 | 0 | 0 |
|  | $2^{\text {nd }}$-order EDA | 0.7 | 4 | 0 | 0 |
|  |  | 0.5 | 20 | 1 | 0 |
| $\mathrm{N}=150$ | UMDA |  | 28 | 0 | 0 |
|  | IUMDA | 0.7 | 45 | 6 | 0 |
|  |  | 0.5 | 51 | 5 | 0 |
|  | $2^{\text {nd }}$-order EDA | 0.7 | 76 | 28 | 1 |
|  |  | 0.5 | 89 | 68 | 11 |
| $\mathrm{N}=200$ | UMDA |  | 80 | 49 | 4 |
|  | IUMDA | 0.7 | 90 | 68 | 12 |
|  |  | 0.5 | 87 | 46 | 13 |
|  | $2^{\text {nd }}$-order EDA | 0.7 | 97 | 89 | 51 |
|  |  | 0.5 | 100 | 97 | 71 |
| $\mathrm{N}=300$ | UMDA |  | 100 | 99 | 89 |
|  | IUMDA | 0.7 | 99 | 99 | 92 |
|  |  | 0.5 | 100 | 99 | 81 |
|  | $2^{\text {nd }}$-order EDA | 0.7 | 100 | 99 | 99 |
|  |  | 0.5 | 100 | 100 | 99 |

From this table we can see that the performance of UMDA is quite good when the population size N is large enough respective to the problem size n . But with the decreasing of the population size, the performance became
worse. When $\mathrm{n}=1000$ and $\mathrm{N}=200$, we can only converge to the global solution for 4 times. IUMDA performs better. Among 100 runs, we can get the solution in about $10 \%$ runs. But $2^{\text {nd }}$-EDA performs much better, the successful rate is as high as $71 \%$ when $\lambda=0.5$. This means $2^{\text {nd }}$-EDA can get better results with smaller memory storage.

## 3. Further discussion

### 3.1. Convergence

Suppose the search space is represented by

$$
\Omega=\Omega_{1} \times \Omega_{2} \times \cdots \times \Omega_{n}
$$

where $\left|\Omega_{i}\right|=r_{i}$ and n is the length of the individual. The cardinality of the search space is $|\Omega|=r_{1} \times r_{2} \times \cdots \times r_{n}=m$. According to the multi-set sense, the population in the algorithm is a subset of size $M$ of elements of $\Omega$. Each population $D_{w}$ can be represented as a vector

$$
D_{w}=\left(d_{w 1}, d_{w 2}, \ldots, d_{w m}\right)
$$

where $d_{w i}$ is the number of ith individuals in population $D_{w}$ and $\sum_{i=1}^{m} d_{w i}=M$.

A $2^{\text {nd }}$-order EDA can be modelled using a finite Markov chain whose state space is formed from the different populations that the algorithm can take:

$$
E=\left\{D_{1}, D_{2}, \ldots, D_{v}\right\}
$$

where $v=C_{M+m-1}^{n-1}$ is the number of different populations.
A $2^{\text {nd }}$-order Markov chain model can be used here because the population at step $t$ only depends on the populations at step $t-1$ and $t-2$. Moreover, neither operation used for the calculation of the transition probabilities depends on the step parameter $t$, so the Markov chain is homogeneous.
Theorem 1: Let $A$ be an instance of $2^{\text {nd }}$-order EDAs such that

$$
P(x, t) \geq \varepsilon>0
$$

for all $x \in \Omega$ and for all step $t=1,2, \ldots$ Then $A$ visits populations of $D^{*}$, which is the set of populations that contain a global optimum, infinitely often with probability one. If the selection is elitist, then the $2^{\text {nd }}$-order EDA converges to a population that contains the global optimum. Proof: First suppose the selection is not elitist.

The probability of going from population $D_{p}$ (at step $t-1$ ) and $D_{q}$ (at step $t-2$ ) to $D_{v}$ at step $t$ is given by

$P\left(D_{c} \mid D_{p} D_{q}\right)=$
$\sum_{D_{p}^{+} D_{q}^{+}} P^{x}\left(D_{p}^{u d} D_{q}^{u d}\right) \frac{M!}{d_{c 1}!\cdots d_{c m}!} \prod_{n=1}^{m} \frac{\left(\lambda P^{x}\left(x^{(i)}\right)+\left(1-\lambda\right) P^{q}\left(x^{(i)}\right)\right)^{d_{c}}}{c m}$
$>0$
where $P^{x}\left(D_{p}^{u d} D_{q}^{u d}\right)$ is the probability to select $D_{p}^{u d} D_{q}^{u d}$ from $D_{p}$ and $D_{q} . P(x, t-1)$ coincides with some $P^{p}\left(x^{i}\right)$ and $P(x, t-2)$ coincides with some $P^{q}\left(x^{i}\right)$.
Hence the Markov chain is irreducible, i.e., all the states are intercommunicated. And the chain will visit $D^{*}$ infinitely often with probability 1 .

If the selection is elitist, then the global optimum will never be lost when it is found. Therefore the algorithm converges to a population that contains the global optimum.

# 3.2. Convergence speed 

Here we again use OneMax problem to show the relation between $\lambda$ and convergence speed of $2^{\text {nd }}$-order EDA. Because the variables are independent with each other and the initial value is identical, we can give the following assumption without loss of generality

$$
\begin{aligned}
& P\left(x_{i}=1, t\right) \equiv p(t), \quad P\left(x_{i}=0, t\right) \equiv q(t) \\
& P^{x}\left(x_{i}=1, t\right) \equiv r(t) \quad i=1, \ldots, n
\end{aligned}
$$

Obviously

$$
p(t)+q(t) \equiv 1
$$

After the Roulette wheel selection,

$$
r(t)=p(t)+\frac{1-p(t)}{n}=\frac{1}{n}+\left(1-\frac{1}{n}\right) p(t)
$$

So

$$
\begin{aligned}
& p(t)=\lambda r(t-1)+(1-\lambda) r(t-2) \\
& =\lambda\left[\frac{1}{n}+\frac{1}{n} p(t-1)\right]+(1-\lambda)\left[\frac{1}{n}+\frac{1}{n} p(t-2)\right] \\
& =\frac{1}{n}+\left(1-\frac{1}{n}\right)[\lambda p(t-1)+(1-\lambda) p(t-2)] \\
& q(t)=\left(1-\frac{1}{n}\right)[\lambda q(t-1)+(1-\lambda) q(t-2)]
\end{aligned}
$$

According to the theory of difference equation, we have

$$
q(t)=c_{1} x_{1}^{t}+c_{2} x_{2}^{t}
$$

where $c_{1}, c_{2}$ are constants and

$$
x_{1}=\frac{\left(1-\frac{1}{n}\right) \lambda+\sqrt{\left(1-\frac{1}{n}\right)^{2} \lambda^{2}+4\left(1-\frac{1}{n}\right)(1-\lambda)}}{2}>0
$$

$$
x_{2}=\frac{\left(1-\frac{1}{n}\right) \lambda-\sqrt{\left(1-\frac{1}{n}\right)^{2} \lambda^{2}+4\left(1-\frac{1}{n}\right)(1-\lambda)}}{2} \leq 0
$$

Obviously $\left|x_{2}\right| \ll|x_{1}|<1$ and $\lim _{|x_{1}| \rightarrow|x_{0}|} q(t)=0$. It means the algorithm could converge to the global optimum. Then let's see when the algorithm converge fast, i.e.,

$$
\min _{|x_{1}| \rightarrow|x_{0}|} q(t)
$$

By the optimization method we can find the algorithm converges fast when $\lambda=1$. It means the speed of UMDA is faster than $2^{\text {nd }}$-order EDA. In the numerical experiment we find the same results, which can be found in table 2. In table 2 we just consider those runs that converge to the global optimum.
Table 2. Average convergence steps of UMDA and $2^{\text {nd }}$-order EDA for OneMax

|  |  | $\lambda$ | $\mathrm{n}=500$ | $\mathrm{n}=700$ | $\mathrm{n}=1000$ |
| :--: | :--: | :--: | :--: | :--: | :--: |
| $\mathrm{N}=100$ | UMDA |  | -- | -- | -- |
|  | $2^{\text {nd }}$-order | 0.7 | 40.3 | -- | -- |
|  | EDA | 0.5 | 45.8 | 56.0 | -- |
| $\mathrm{N}=150$ | UMDA |  | 30.3 | -- | -- |
|  | $2^{\text {nd }}$-order | 0.7 | 39.3 | 47.2 | 59.0 |
|  | EDA | 0.5 | 44.6 | 53.7 | 66.0 |
| $\mathrm{N}=200$ | UMDA |  | 29.0 | 35.3 | 44.3 |
|  | $2^{\text {nd }}$-order | 0.7 | 37.9 | 46.1 | 56.4 |
|  | EDA | 0.5 | 43.3 | 52.3 | 64.1 |
| $\mathrm{N}=300$ | UMDA |  | 28.4 | 34.1 | 41.9 |
|  | $2^{\text {nd }}$-order | 0.7 | 37.5 | 44.8 | 54.7 |
|  | EDA | 0.5 | 43.0 | 51.3 | 62.3 |

Although high order EDA converges slower than traditional EDA, the probability of convergence of high order EDA is higher, especially for small population size.

## 4. Application of constrained optimization

The constraint problem we discuss here is defined as:

$$
\begin{aligned}
& \max f(X)=\sum_{i} f_{i}\left(S_{i}\right) \\
& \text { s.t. } C_{i}\left(S_{i}\right) \leq 0
\end{aligned}
$$

where $X=\left\{x_{1}, \cdots, x_{n}\right\}$ and the value of $i$ th variable belongs to the set $\left\{x_{i, 1}, \cdots, x_{i, n_{i}}\right\} . C_{i}\left(S_{i}\right) \leq 0$ stands for the $i$ th constraint function (it may be equality or inequality)

and the variable set $S_{i} \subseteq X(i=1, \cdots, l)$. The function $f(x)$ is called additively decomposed function (ADF). This class of functions is of great theoretical and practical importance. Optimisation of an arbitrary function in this space is NP complete.

### 4.1. The frame of the algorithm

To solve the problem, we must get a factorisation of the probability of distribution at first. For convenience, just suppose $X=\bigcup_{i=1}^{l} S_{i}$. Define

$$
d_{i}=\bigcup_{j=1}^{i} S_{j} \quad b_{i}=S_{i} \backslash d_{i-1} \quad c_{i}=S_{i} \cap d_{i-1}
$$

Set $d_{0}=\phi$ and then we get the factorisation as

$$
P(X)=\prod_{i=1}^{l} P\left(x_{b_{i}} \mid x_{c_{i}}\right)
$$

If

$$
\begin{aligned}
& b_{i} \neq \phi, \quad \forall i=1, \cdots l ; \quad d_{i}=X \\
& \forall i \geq 2, \exists j<i \text { such that } c_{i} \subseteq S_{j}
\end{aligned}
$$

we say the factorisation satisfy the running intersection property. At this condition, $P\left(x_{1}, \cdots, x_{n}\right)=\prod_{i=1}^{l} P\left(x_{b_{i}} \mid x_{c_{i}}\right)$ really holds [5]. If the running intersection property is violated, the factorisation might not be exact. But we will show the running intersection property is not necessary by the numerical examples.

We assume the factorisation of the probability distribution is given. The following is the frame of the algorithm $2^{\text {nd }}$-CFA (Constraint Factorisation Algorithm) to solve the constraint problem:

1) Get initial feasible population;
2) select a set of promising solutions;
3) Compute the probabilities $P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-1\right)$ using the selected points;
4) Generate the new population according to $P(x, t)=\prod_{i=1}^{t}\left[\lambda P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-1\right)+(1-\lambda) P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-2\right)\right]$
5) if the termination criteria are not met, go to 2 )

### 4.2. Feasibility

Before the further discussion, we should know if the algorithm $2^{\text {nd }}$-CFA is feasible. This means the final solution should be feasible. The following theorem gives us the
guarantee:
Theorem 2: If the former generation is feasible, the new generation will be feasible too.
Proof: If $\exists x \in P(t)$ and $x$ doesn't satisfy the $k$ th constraint $C_{k}\left(S_{k}\right)$. Then

$$
\begin{aligned}
& 0 \neq P(x, t)= \\
& \prod_{i=1}^{l}\left[\lambda P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-1\right)+(1-\lambda) P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-2\right)\right] \\
& \rightarrow P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-1\right) \neq 0 \text { or } P^{s}\left(x_{b_{i}} \mid x_{c_{i}}, t-2\right) \neq 0 \\
& \rightarrow P^{s}\left(x_{S_{k}}, t-1\right) \neq 0 \text { or } P^{s}\left(x_{S_{k}}, t-2\right) \neq 0 \\
& \exists \bar{x} \in P(t-1), \bar{x}_{S_{k}}=x_{S_{k}} \text { or } \exists x \in P(t-2), \bar{x}_{S_{k}}=x_{S_{k}} \\
& \therefore \bar{x} \text { or } \bar{x} \text { doesn't satisfy } C_{k}\left(S_{k}\right)
\end{aligned}
$$

And it is impossible because we suppose the former generation is feasible.

Although Theorem 2 guarantees that we can get a feasible population from a feasible former, we need a feasible initial population.

### 4.3. Numerical results

In the following examples, the experiment results are expressed by how many runs it gets the global optimum among 100 independent runs. The max generation is 100 and the population size is denoted as $N$.

$$
\begin{aligned}
& \text { Eg2 } \max \sum_{i=1}^{n} x_{i} \\
& \text { s.t. } \begin{array}{l}
x_{2 j-1}+x_{2 j}+x_{2 j+1} \leq 2 \\
x_{1}+x_{n-1}+x_{n} \leq 2
\end{array} \\
& \text { where } n=2 m, x_{i} \in\{0,1\} \quad i=1, \cdots n \quad j=1, \cdots, m-1
\end{aligned}
$$

The table 3 shows the results. This example is a linear programming problem. In order to achieve the same convergence rate, the population size needed for $\lambda=0.5$ is much smaller than that of $\lambda=1$. At the same time we can get the factorisation easily as

$$
\begin{aligned}
& P\left(x_{1}, \cdots, x_{n}\right)= \\
& P\left(x_{1} x_{2} x_{3}\right) P\left(x_{4} x_{5} \mid x_{3}\right) \cdots P\left(x_{n-2} x_{n-1} \mid x_{n-3}\right) P\left(x_{n} \mid x_{1} x_{n-1}\right)
\end{aligned}
$$

Obviously it does not satisfy the running intersection property. But we can still get the global optimum.

Table 3. Successful rate for Example2

| N | 200 |  | 500 |  | 700 |  | 1000 |  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| $\lambda$ | 1 | 0.5 | 1 | 0.5 | 1 | 0.5 | 1 | 0.5 |
| $\mathrm{n}=200$ | 1 | 12 | 81 | 88 | 99 | 100 | 99 | 100 |
| $\mathrm{n}=300$ | 0 | 0 | 45 | 80 | 79 | 97 | 99 | 100 |
| $\mathrm{n}=398$ | 0 | 0 | 41 | 85 | 88 | 100 | 98 | 100 |
| $\mathrm{n}=502$ | 0 | 0 | 8 | 58 | 60 | 98 | 95 | 100 |

$$
\text { Eg3 } \max \sum_{i=1}^{n} x_{i}
$$

$$
\text { s.t. } 2 \leq x_{2 j-1}^{2}+x_{2 j}^{2}+x_{2 j+1}^{2} \leq 8
$$

where $n=2 m+1, x_{i} \in\{0, \pm 1, \pm 2\} \quad i=1, \cdots n \quad j=1, \cdots, m$
The table 4 shows the results. This example is a non-linear programming problem with concave domain and the range of each variable is not small. It needs large population size. But the usage of $\lambda$ can lead to better results with small population size.

Table 4. Successful rate for Example3

| N | 1000 | 2000 | 3000 | 4000 |  |  |  |  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| $\lambda$ | 1 | 0.5 | 1 | 0.5 | 1 | 0.5 | 1 | 0.5 |
| $\mathrm{n}=101$ | 0 | 3 | 46 | 74 | 80 | 97 | 97 | 100 |
| $\mathrm{n}=201$ | 0 | 0 | 0 | 5 | 14 | 66 | 55 | 93 |
| $\mathrm{n}=299$ | 0 | 0 | 0 | 0 | 5 | 50 | 37 | 89 |

## 5. Conclusion

In this paper, a new algorithm, which is called as high-order EDA, is proposed. The basic character is the usage of the history information. From the numerical examples we find that the new algorithm can converge to the global optimum with small population size. Further research includes the choice of the order, the choice of the coefficients, etc.

## Acknowledgements

This paper is supported by NSF 90820018.

## References

[1] Goldberg D. E., Genetic algorithms in search, optimization, and machine learning, Addison-Wesley, 1989.
[2] Thierens D., Analysis and design of genetic algorithms, Leuven, Belgium: Katholieke Universiteit Leuven, 1995.
[3] Mühlenbein H., Paa $\beta$ G., "From recombination of genes to the estimation of distributions I. Binary parameters", Parallel Problem Solving from Nature, PPSN IV, pp.178-187, 1996.
[4] De Bonet J.S., Isbell C.L., Viola, P., "MIMIC: Finding optima by estimating probability densities", Advances in Neural Information Processing Systems 9, pp.424-430, 1997.
[5] Mühlenbein H., Mahnig T., Rodriguez A. O., "Schemata, distributions and graphical models in evolutionary optimization", Journal of Heuristics, Vol 5, No.2, pp. 215-247, 1999.
[6] Pelikan M., Goldberg D.E., Cantú-Paz E., Linkage problem, distribution estimation, and Bayesian networks (IlliGAL Report No.98013). Urbana, IL: University of Illinois at Urbana-Champaign, Illinois genetic Algorithms Laboratory, 1998.
[7] Mühlenbein H., "The equation for response to selection and its use for prediction", Evolutionary Computation, Vol 5, No.3, pp.303-346, 1997
[8] Baluja S., Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning, Tech. Rep. No. CMU-CS-94-163. Pittsburgh, PA: Carnegie Mellon University, 1994.
[9] Kvasnicka V., Pelikan M., Pospichal J., "Hill climbing with learning (An abstraction of genetic algorithm)", Neural Network World 6, 773-796, 1996.